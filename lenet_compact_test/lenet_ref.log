nohup: ignoring input
I1227 14:37:59.670655 12869 caffe.cpp:218] Using GPUs 0, 1, 2, 3
I1227 14:37:59.671711 12869 caffe.cpp:223] GPU 0: Tesla P40
I1227 14:37:59.672111 12869 caffe.cpp:223] GPU 1: Tesla P40
I1227 14:37:59.672497 12869 caffe.cpp:223] GPU 2: Tesla P40
I1227 14:37:59.672879 12869 caffe.cpp:223] GPU 3: Tesla P40
I1227 14:38:00.303599 12869 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "examples/mnist/lenet_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
I1227 14:38:00.303982 12869 solver.cpp:87] Creating training net from net file: examples/mnist/lenet_train_test.prototxt
I1227 14:38:00.304474 12869 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I1227 14:38:00.304494 12869 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1227 14:38:00.304630 12869 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1227 14:38:00.304725 12869 layer_factory.hpp:77] Creating layer mnist
I1227 14:38:00.304877 12869 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I1227 14:38:00.304919 12869 net.cpp:84] Creating Layer mnist
I1227 14:38:00.304934 12869 net.cpp:387] mnist -> data
I1227 14:38:00.304966 12869 net.cpp:387] mnist -> label
I1227 14:38:00.306438 12869 data_layer.cpp:45] output data size: 64,1,28,28
I1227 14:38:00.310200 12869 net.cpp:127] Setting up mnist
I1227 14:38:00.310221 12869 net.cpp:136] Top shape: 64 1 28 28 (50176)
I1227 14:38:00.310228 12869 net.cpp:136] Top shape: 64 (64)
I1227 14:38:00.310232 12869 net.cpp:144] Memory required for data: 200960
I1227 14:38:00.310242 12869 layer_factory.hpp:77] Creating layer conv1
I1227 14:38:00.310359 12869 net.cpp:84] Creating Layer conv1
I1227 14:38:00.310369 12869 net.cpp:413] conv1 <- data
I1227 14:38:00.310389 12869 net.cpp:387] conv1 -> conv1
I1227 14:38:00.651855 12869 net.cpp:127] Setting up conv1
I1227 14:38:00.651914 12869 net.cpp:136] Top shape: 64 20 24 24 (737280)
I1227 14:38:00.651921 12869 net.cpp:144] Memory required for data: 3150080
I1227 14:38:00.651983 12869 layer_factory.hpp:77] Creating layer pool1
I1227 14:38:00.652004 12869 net.cpp:84] Creating Layer pool1
I1227 14:38:00.652010 12869 net.cpp:413] pool1 <- conv1
I1227 14:38:00.652019 12869 net.cpp:387] pool1 -> pool1
I1227 14:38:00.652081 12869 net.cpp:127] Setting up pool1
I1227 14:38:00.652088 12869 net.cpp:136] Top shape: 64 20 12 12 (184320)
I1227 14:38:00.652093 12869 net.cpp:144] Memory required for data: 3887360
I1227 14:38:00.652097 12869 layer_factory.hpp:77] Creating layer conv2
I1227 14:38:00.652113 12869 net.cpp:84] Creating Layer conv2
I1227 14:38:00.652117 12869 net.cpp:413] conv2 <- pool1
I1227 14:38:00.652124 12869 net.cpp:387] conv2 -> conv2
I1227 14:38:00.655442 12869 net.cpp:127] Setting up conv2
I1227 14:38:00.655462 12869 net.cpp:136] Top shape: 64 50 8 8 (204800)
I1227 14:38:00.655467 12869 net.cpp:144] Memory required for data: 4706560
I1227 14:38:00.655478 12869 layer_factory.hpp:77] Creating layer pool2
I1227 14:38:00.655488 12869 net.cpp:84] Creating Layer pool2
I1227 14:38:00.655494 12869 net.cpp:413] pool2 <- conv2
I1227 14:38:00.655501 12869 net.cpp:387] pool2 -> pool2
I1227 14:38:00.655545 12869 net.cpp:127] Setting up pool2
I1227 14:38:00.655553 12869 net.cpp:136] Top shape: 64 50 4 4 (51200)
I1227 14:38:00.655557 12869 net.cpp:144] Memory required for data: 4911360
I1227 14:38:00.655562 12869 layer_factory.hpp:77] Creating layer ip1
I1227 14:38:00.655575 12869 net.cpp:84] Creating Layer ip1
I1227 14:38:00.655580 12869 net.cpp:413] ip1 <- pool2
I1227 14:38:00.655586 12869 net.cpp:387] ip1 -> ip1
I1227 14:38:00.659929 12869 net.cpp:127] Setting up ip1
I1227 14:38:00.659945 12869 net.cpp:136] Top shape: 64 500 (32000)
I1227 14:38:00.659950 12869 net.cpp:144] Memory required for data: 5039360
I1227 14:38:00.659961 12869 layer_factory.hpp:77] Creating layer relu1
I1227 14:38:00.659970 12869 net.cpp:84] Creating Layer relu1
I1227 14:38:00.659976 12869 net.cpp:413] relu1 <- ip1
I1227 14:38:00.659982 12869 net.cpp:374] relu1 -> ip1 (in-place)
I1227 14:38:00.660195 12869 net.cpp:127] Setting up relu1
I1227 14:38:00.660205 12869 net.cpp:136] Top shape: 64 500 (32000)
I1227 14:38:00.660209 12869 net.cpp:144] Memory required for data: 5167360
I1227 14:38:00.660214 12869 layer_factory.hpp:77] Creating layer ip2
I1227 14:38:00.660223 12869 net.cpp:84] Creating Layer ip2
I1227 14:38:00.660228 12869 net.cpp:413] ip2 <- ip1
I1227 14:38:00.660234 12869 net.cpp:387] ip2 -> ip2
I1227 14:38:00.661646 12869 net.cpp:127] Setting up ip2
I1227 14:38:00.661662 12869 net.cpp:136] Top shape: 64 10 (640)
I1227 14:38:00.661667 12869 net.cpp:144] Memory required for data: 5169920
I1227 14:38:00.661676 12869 layer_factory.hpp:77] Creating layer loss
I1227 14:38:00.661689 12869 net.cpp:84] Creating Layer loss
I1227 14:38:00.661695 12869 net.cpp:413] loss <- ip2
I1227 14:38:00.661700 12869 net.cpp:413] loss <- label
I1227 14:38:00.661708 12869 net.cpp:387] loss -> loss
I1227 14:38:00.661731 12869 layer_factory.hpp:77] Creating layer loss
I1227 14:38:00.663172 12869 net.cpp:127] Setting up loss
I1227 14:38:00.663189 12869 net.cpp:136] Top shape: (1)
I1227 14:38:00.663194 12869 net.cpp:139]     with loss weight 1
I1227 14:38:00.663220 12869 net.cpp:144] Memory required for data: 5169924
I1227 14:38:00.663226 12869 net.cpp:205] loss needs backward computation.
I1227 14:38:00.663231 12869 net.cpp:205] ip2 needs backward computation.
I1227 14:38:00.663236 12869 net.cpp:205] relu1 needs backward computation.
I1227 14:38:00.663240 12869 net.cpp:205] ip1 needs backward computation.
I1227 14:38:00.663244 12869 net.cpp:205] pool2 needs backward computation.
I1227 14:38:00.663249 12869 net.cpp:205] conv2 needs backward computation.
I1227 14:38:00.663254 12869 net.cpp:205] pool1 needs backward computation.
I1227 14:38:00.663259 12869 net.cpp:205] conv1 needs backward computation.
I1227 14:38:00.663264 12869 net.cpp:207] mnist does not need backward computation.
I1227 14:38:00.663274 12869 net.cpp:249] This network produces output loss
I1227 14:38:00.663291 12869 net.cpp:262] Network initialization done.
I1227 14:38:00.663698 12869 solver.cpp:172] Creating test net (#0) specified by net file: examples/mnist/lenet_train_test.prototxt
I1227 14:38:00.663730 12869 net.cpp:301] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I1227 14:38:00.663879 12869 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1227 14:38:00.663960 12869 layer_factory.hpp:77] Creating layer mnist
I1227 14:38:00.664032 12869 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I1227 14:38:00.664050 12869 net.cpp:84] Creating Layer mnist
I1227 14:38:00.664057 12869 net.cpp:387] mnist -> data
I1227 14:38:00.664068 12869 net.cpp:387] mnist -> label
I1227 14:38:00.664170 12869 data_layer.cpp:45] output data size: 100,1,28,28
I1227 14:38:00.667162 12869 net.cpp:127] Setting up mnist
I1227 14:38:00.667181 12869 net.cpp:136] Top shape: 100 1 28 28 (78400)
I1227 14:38:00.667187 12869 net.cpp:136] Top shape: 100 (100)
I1227 14:38:00.667192 12869 net.cpp:144] Memory required for data: 314000
I1227 14:38:00.667198 12869 layer_factory.hpp:77] Creating layer label_mnist_1_split
I1227 14:38:00.667210 12869 net.cpp:84] Creating Layer label_mnist_1_split
I1227 14:38:00.667215 12869 net.cpp:413] label_mnist_1_split <- label
I1227 14:38:00.667222 12869 net.cpp:387] label_mnist_1_split -> label_mnist_1_split_0
I1227 14:38:00.667232 12869 net.cpp:387] label_mnist_1_split -> label_mnist_1_split_1
I1227 14:38:00.667332 12869 net.cpp:127] Setting up label_mnist_1_split
I1227 14:38:00.667343 12869 net.cpp:136] Top shape: 100 (100)
I1227 14:38:00.667348 12869 net.cpp:136] Top shape: 100 (100)
I1227 14:38:00.667352 12869 net.cpp:144] Memory required for data: 314800
I1227 14:38:00.667357 12869 layer_factory.hpp:77] Creating layer conv1
I1227 14:38:00.667368 12869 net.cpp:84] Creating Layer conv1
I1227 14:38:00.667373 12869 net.cpp:413] conv1 <- data
I1227 14:38:00.667381 12869 net.cpp:387] conv1 -> conv1
I1227 14:38:00.668400 12869 net.cpp:127] Setting up conv1
I1227 14:38:00.668429 12869 net.cpp:136] Top shape: 100 20 24 24 (1152000)
I1227 14:38:00.668434 12869 net.cpp:144] Memory required for data: 4922800
I1227 14:38:00.668447 12869 layer_factory.hpp:77] Creating layer pool1
I1227 14:38:00.668455 12869 net.cpp:84] Creating Layer pool1
I1227 14:38:00.668460 12869 net.cpp:413] pool1 <- conv1
I1227 14:38:00.668467 12869 net.cpp:387] pool1 -> pool1
I1227 14:38:00.668510 12869 net.cpp:127] Setting up pool1
I1227 14:38:00.668517 12869 net.cpp:136] Top shape: 100 20 12 12 (288000)
I1227 14:38:00.668522 12869 net.cpp:144] Memory required for data: 6074800
I1227 14:38:00.668526 12869 layer_factory.hpp:77] Creating layer conv2
I1227 14:38:00.668537 12869 net.cpp:84] Creating Layer conv2
I1227 14:38:00.668541 12869 net.cpp:413] conv2 <- pool1
I1227 14:38:00.668548 12869 net.cpp:387] conv2 -> conv2
I1227 14:38:00.670970 12869 net.cpp:127] Setting up conv2
I1227 14:38:00.670989 12869 net.cpp:136] Top shape: 100 50 8 8 (320000)
I1227 14:38:00.670994 12869 net.cpp:144] Memory required for data: 7354800
I1227 14:38:00.671005 12869 layer_factory.hpp:77] Creating layer pool2
I1227 14:38:00.671015 12869 net.cpp:84] Creating Layer pool2
I1227 14:38:00.671021 12869 net.cpp:413] pool2 <- conv2
I1227 14:38:00.671030 12869 net.cpp:387] pool2 -> pool2
I1227 14:38:00.671074 12869 net.cpp:127] Setting up pool2
I1227 14:38:00.671082 12869 net.cpp:136] Top shape: 100 50 4 4 (80000)
I1227 14:38:00.671087 12869 net.cpp:144] Memory required for data: 7674800
I1227 14:38:00.671090 12869 layer_factory.hpp:77] Creating layer ip1
I1227 14:38:00.671098 12869 net.cpp:84] Creating Layer ip1
I1227 14:38:00.671103 12869 net.cpp:413] ip1 <- pool2
I1227 14:38:00.671111 12869 net.cpp:387] ip1 -> ip1
I1227 14:38:00.675436 12869 net.cpp:127] Setting up ip1
I1227 14:38:00.675453 12869 net.cpp:136] Top shape: 100 500 (50000)
I1227 14:38:00.675457 12869 net.cpp:144] Memory required for data: 7874800
I1227 14:38:00.675469 12869 layer_factory.hpp:77] Creating layer relu1
I1227 14:38:00.675477 12869 net.cpp:84] Creating Layer relu1
I1227 14:38:00.675483 12869 net.cpp:413] relu1 <- ip1
I1227 14:38:00.675489 12869 net.cpp:374] relu1 -> ip1 (in-place)
I1227 14:38:00.676834 12869 net.cpp:127] Setting up relu1
I1227 14:38:00.676851 12869 net.cpp:136] Top shape: 100 500 (50000)
I1227 14:38:00.676856 12869 net.cpp:144] Memory required for data: 8074800
I1227 14:38:00.676862 12869 layer_factory.hpp:77] Creating layer ip2
I1227 14:38:00.676872 12869 net.cpp:84] Creating Layer ip2
I1227 14:38:00.676877 12869 net.cpp:413] ip2 <- ip1
I1227 14:38:00.676884 12869 net.cpp:387] ip2 -> ip2
I1227 14:38:00.677044 12869 net.cpp:127] Setting up ip2
I1227 14:38:00.677052 12869 net.cpp:136] Top shape: 100 10 (1000)
I1227 14:38:00.677057 12869 net.cpp:144] Memory required for data: 8078800
I1227 14:38:00.677065 12869 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I1227 14:38:00.677072 12869 net.cpp:84] Creating Layer ip2_ip2_0_split
I1227 14:38:00.677076 12869 net.cpp:413] ip2_ip2_0_split <- ip2
I1227 14:38:00.677083 12869 net.cpp:387] ip2_ip2_0_split -> ip2_ip2_0_split_0
I1227 14:38:00.677090 12869 net.cpp:387] ip2_ip2_0_split -> ip2_ip2_0_split_1
I1227 14:38:00.677126 12869 net.cpp:127] Setting up ip2_ip2_0_split
I1227 14:38:00.677134 12869 net.cpp:136] Top shape: 100 10 (1000)
I1227 14:38:00.677139 12869 net.cpp:136] Top shape: 100 10 (1000)
I1227 14:38:00.677142 12869 net.cpp:144] Memory required for data: 8086800
I1227 14:38:00.677146 12869 layer_factory.hpp:77] Creating layer accuracy
I1227 14:38:00.677157 12869 net.cpp:84] Creating Layer accuracy
I1227 14:38:00.677162 12869 net.cpp:413] accuracy <- ip2_ip2_0_split_0
I1227 14:38:00.677167 12869 net.cpp:413] accuracy <- label_mnist_1_split_0
I1227 14:38:00.677173 12869 net.cpp:387] accuracy -> accuracy
I1227 14:38:00.677186 12869 net.cpp:127] Setting up accuracy
I1227 14:38:00.677192 12869 net.cpp:136] Top shape: (1)
I1227 14:38:00.677196 12869 net.cpp:144] Memory required for data: 8086804
I1227 14:38:00.677201 12869 layer_factory.hpp:77] Creating layer loss
I1227 14:38:00.677213 12869 net.cpp:84] Creating Layer loss
I1227 14:38:00.677230 12869 net.cpp:413] loss <- ip2_ip2_0_split_1
I1227 14:38:00.677237 12869 net.cpp:413] loss <- label_mnist_1_split_1
I1227 14:38:00.677242 12869 net.cpp:387] loss -> loss
I1227 14:38:00.677250 12869 layer_factory.hpp:77] Creating layer loss
I1227 14:38:00.677537 12869 net.cpp:127] Setting up loss
I1227 14:38:00.677549 12869 net.cpp:136] Top shape: (1)
I1227 14:38:00.677554 12869 net.cpp:139]     with loss weight 1
I1227 14:38:00.677562 12869 net.cpp:144] Memory required for data: 8086808
I1227 14:38:00.677567 12869 net.cpp:205] loss needs backward computation.
I1227 14:38:00.677572 12869 net.cpp:207] accuracy does not need backward computation.
I1227 14:38:00.677577 12869 net.cpp:205] ip2_ip2_0_split needs backward computation.
I1227 14:38:00.677582 12869 net.cpp:205] ip2 needs backward computation.
I1227 14:38:00.677587 12869 net.cpp:205] relu1 needs backward computation.
I1227 14:38:00.677590 12869 net.cpp:205] ip1 needs backward computation.
I1227 14:38:00.677595 12869 net.cpp:205] pool2 needs backward computation.
I1227 14:38:00.677600 12869 net.cpp:205] conv2 needs backward computation.
I1227 14:38:00.677605 12869 net.cpp:205] pool1 needs backward computation.
I1227 14:38:00.677609 12869 net.cpp:205] conv1 needs backward computation.
I1227 14:38:00.677614 12869 net.cpp:207] label_mnist_1_split does not need backward computation.
I1227 14:38:00.677619 12869 net.cpp:207] mnist does not need backward computation.
I1227 14:38:00.677624 12869 net.cpp:249] This network produces output accuracy
I1227 14:38:00.677628 12869 net.cpp:249] This network produces output loss
I1227 14:38:00.677640 12869 net.cpp:262] Network initialization done.
I1227 14:38:00.677690 12869 solver.cpp:56] Solver scaffolding done.
I1227 14:38:00.678006 12869 caffe.cpp:248] Starting Optimization
I1227 14:38:03.466514 12923 solver.cpp:172] Creating test net (#0) specified by net file: examples/mnist/lenet_train_test.prototxt
I1227 14:38:03.466533 12921 solver.cpp:172] Creating test net (#0) specified by net file: examples/mnist/lenet_train_test.prototxt
I1227 14:38:03.478756 12922 solver.cpp:172] Creating test net (#0) specified by net file: examples/mnist/lenet_train_test.prototxt
I1227 14:38:03.738673 12869 solver.cpp:276] Solving LeNet
I1227 14:38:03.738739 12869 solver.cpp:277] Learning Rate Policy: inv
I1227 14:38:03.738891 12869 solver.cpp:334] Iteration 0, Testing net (#0)
I1227 14:38:03.779162 12869 blocking_queue.cpp:49] Waiting for data
I1227 14:38:03.844034 12920 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:03.845086 12869 solver.cpp:401]     Test net output #0: accuracy = 0.1142
I1227 14:38:03.845124 12869 solver.cpp:401]     Test net output #1: loss = 2.28509 (* 1 = 2.28509 loss)
I1227 14:38:03.864389 12869 solver.cpp:222] Iteration 0 (0 iter/s, 0.125432s/100 iters), loss = 2.34661
I1227 14:38:03.864454 12869 solver.cpp:241]     Train net output #0: loss = 2.34661 (* 1 = 2.34661 loss)
I1227 14:38:03.864485 12869 sgd_solver.cpp:119] Iteration 0, lr = 0.01
I1227 14:38:04.077353 12869 solver.cpp:222] Iteration 100 (469.747 iter/s, 0.21288s/100 iters), loss = 0.4316
I1227 14:38:04.077405 12869 solver.cpp:241]     Train net output #0: loss = 0.4316 (* 1 = 0.4316 loss)
I1227 14:38:04.077420 12869 sgd_solver.cpp:119] Iteration 100, lr = 0.00992565
I1227 14:38:04.263375 12869 solver.cpp:222] Iteration 200 (537.764 iter/s, 0.185955s/100 iters), loss = 0.253447
I1227 14:38:04.263422 12869 solver.cpp:241]     Train net output #0: loss = 0.253447 (* 1 = 0.253447 loss)
I1227 14:38:04.263438 12869 sgd_solver.cpp:119] Iteration 200, lr = 0.00985258
I1227 14:38:04.318131 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:04.443675 12869 solver.cpp:222] Iteration 300 (554.82 iter/s, 0.180238s/100 iters), loss = 0.100515
I1227 14:38:04.443717 12869 solver.cpp:241]     Train net output #0: loss = 0.100515 (* 1 = 0.100515 loss)
I1227 14:38:04.443732 12869 sgd_solver.cpp:119] Iteration 300, lr = 0.00978075
I1227 14:38:04.623922 12869 solver.cpp:222] Iteration 400 (554.965 iter/s, 0.180192s/100 iters), loss = 0.172415
I1227 14:38:04.624001 12869 solver.cpp:241]     Train net output #0: loss = 0.172415 (* 1 = 0.172415 loss)
I1227 14:38:04.624017 12869 sgd_solver.cpp:119] Iteration 400, lr = 0.00971013
I1227 14:38:04.740181 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:04.802951 12869 solver.cpp:334] Iteration 500, Testing net (#0)
I1227 14:38:04.876340 12920 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:04.877209 12869 solver.cpp:401]     Test net output #0: accuracy = 0.9779
I1227 14:38:04.877239 12869 solver.cpp:401]     Test net output #1: loss = 0.0718476 (* 1 = 0.0718476 loss)
I1227 14:38:04.878887 12869 solver.cpp:222] Iteration 500 (392.351 iter/s, 0.254874s/100 iters), loss = 0.263047
I1227 14:38:04.878921 12869 solver.cpp:241]     Train net output #0: loss = 0.263047 (* 1 = 0.263047 loss)
I1227 14:38:04.878934 12869 sgd_solver.cpp:119] Iteration 500, lr = 0.00964069
I1227 14:38:05.067963 12869 solver.cpp:222] Iteration 600 (529.028 iter/s, 0.189026s/100 iters), loss = 0.165608
I1227 14:38:05.068007 12869 solver.cpp:241]     Train net output #0: loss = 0.165608 (* 1 = 0.165608 loss)
I1227 14:38:05.068022 12869 sgd_solver.cpp:119] Iteration 600, lr = 0.0095724
I1227 14:38:05.250902 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:05.252312 12869 solver.cpp:222] Iteration 700 (542.632 iter/s, 0.184287s/100 iters), loss = 0.0182024
I1227 14:38:05.252362 12869 solver.cpp:241]     Train net output #0: loss = 0.0182024 (* 1 = 0.0182024 loss)
I1227 14:38:05.252377 12869 sgd_solver.cpp:119] Iteration 700, lr = 0.00950522
I1227 14:38:05.434618 12869 solver.cpp:222] Iteration 800 (548.728 iter/s, 0.18224s/100 iters), loss = 0.0317198
I1227 14:38:05.434669 12869 solver.cpp:241]     Train net output #0: loss = 0.0317198 (* 1 = 0.0317198 loss)
I1227 14:38:05.434684 12869 sgd_solver.cpp:119] Iteration 800, lr = 0.00943913
I1227 14:38:05.617355 12869 solver.cpp:222] Iteration 900 (547.43 iter/s, 0.182672s/100 iters), loss = 0.0923479
I1227 14:38:05.617408 12869 solver.cpp:241]     Train net output #0: loss = 0.0923478 (* 1 = 0.0923478 loss)
I1227 14:38:05.617424 12869 sgd_solver.cpp:119] Iteration 900, lr = 0.00937411
I1227 14:38:05.679852 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:05.798971 12869 solver.cpp:334] Iteration 1000, Testing net (#0)
I1227 14:38:05.871544 12920 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:05.872500 12869 solver.cpp:401]     Test net output #0: accuracy = 0.982
I1227 14:38:05.872532 12869 solver.cpp:401]     Test net output #1: loss = 0.0524357 (* 1 = 0.0524357 loss)
I1227 14:38:05.879024 12869 solver.cpp:222] Iteration 1000 (382.264 iter/s, 0.261599s/100 iters), loss = 0.0547381
I1227 14:38:05.879063 12869 solver.cpp:241]     Train net output #0: loss = 0.0547381 (* 1 = 0.0547381 loss)
I1227 14:38:05.879081 12869 sgd_solver.cpp:119] Iteration 1000, lr = 0.00931012
I1227 14:38:06.069015 12869 solver.cpp:222] Iteration 1100 (526.493 iter/s, 0.189936s/100 iters), loss = 0.0533819
I1227 14:38:06.069061 12869 solver.cpp:241]     Train net output #0: loss = 0.0533819 (* 1 = 0.0533819 loss)
I1227 14:38:06.069077 12869 sgd_solver.cpp:119] Iteration 1100, lr = 0.00924715
I1227 14:38:06.194667 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:06.253453 12869 solver.cpp:222] Iteration 1200 (542.365 iter/s, 0.184378s/100 iters), loss = 0.0750435
I1227 14:38:06.253496 12869 solver.cpp:241]     Train net output #0: loss = 0.0750435 (* 1 = 0.0750435 loss)
I1227 14:38:06.253511 12869 sgd_solver.cpp:119] Iteration 1200, lr = 0.00918515
I1227 14:38:06.434867 12869 solver.cpp:222] Iteration 1300 (551.409 iter/s, 0.181354s/100 iters), loss = 0.0627871
I1227 14:38:06.434921 12869 solver.cpp:241]     Train net output #0: loss = 0.0627871 (* 1 = 0.0627871 loss)
I1227 14:38:06.434937 12869 sgd_solver.cpp:119] Iteration 1300, lr = 0.00912412
I1227 14:38:06.617548 12869 solver.cpp:222] Iteration 1400 (547.613 iter/s, 0.182611s/100 iters), loss = 0.00657156
I1227 14:38:06.617635 12869 solver.cpp:241]     Train net output #0: loss = 0.00657154 (* 1 = 0.00657154 loss)
I1227 14:38:06.617651 12869 sgd_solver.cpp:119] Iteration 1400, lr = 0.00906403
I1227 14:38:06.621690 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:06.797255 12869 solver.cpp:334] Iteration 1500, Testing net (#0)
I1227 14:38:06.871018 12920 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:06.871860 12869 solver.cpp:401]     Test net output #0: accuracy = 0.9882
I1227 14:38:06.871893 12869 solver.cpp:401]     Test net output #1: loss = 0.0375779 (* 1 = 0.0375779 loss)
I1227 14:38:06.873535 12869 solver.cpp:222] Iteration 1500 (390.799 iter/s, 0.255886s/100 iters), loss = 0.0185748
I1227 14:38:06.873569 12869 solver.cpp:241]     Train net output #0: loss = 0.0185748 (* 1 = 0.0185748 loss)
I1227 14:38:06.873584 12869 sgd_solver.cpp:119] Iteration 1500, lr = 0.00900485
I1227 14:38:07.062088 12869 solver.cpp:222] Iteration 1600 (530.498 iter/s, 0.188502s/100 iters), loss = 0.0681237
I1227 14:38:07.062139 12869 solver.cpp:241]     Train net output #0: loss = 0.0681237 (* 1 = 0.0681237 loss)
I1227 14:38:07.062155 12869 sgd_solver.cpp:119] Iteration 1600, lr = 0.00894657
I1227 14:38:07.127563 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:07.242444 12869 solver.cpp:222] Iteration 1700 (554.655 iter/s, 0.180292s/100 iters), loss = 0.0438257
I1227 14:38:07.242492 12869 solver.cpp:241]     Train net output #0: loss = 0.0438257 (* 1 = 0.0438257 loss)
I1227 14:38:07.242508 12869 sgd_solver.cpp:119] Iteration 1700, lr = 0.00888916
I1227 14:38:07.422921 12869 solver.cpp:222] Iteration 1800 (554.28 iter/s, 0.180414s/100 iters), loss = 0.0655645
I1227 14:38:07.422974 12869 solver.cpp:241]     Train net output #0: loss = 0.0655645 (* 1 = 0.0655645 loss)
I1227 14:38:07.422989 12869 sgd_solver.cpp:119] Iteration 1800, lr = 0.0088326
I1227 14:38:07.550922 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:07.603016 12869 solver.cpp:222] Iteration 1900 (555.468 iter/s, 0.180028s/100 iters), loss = 0.0592631
I1227 14:38:07.603060 12869 solver.cpp:241]     Train net output #0: loss = 0.0592631 (* 1 = 0.0592631 loss)
I1227 14:38:07.603075 12869 sgd_solver.cpp:119] Iteration 1900, lr = 0.00877687
I1227 14:38:07.782240 12869 solver.cpp:334] Iteration 2000, Testing net (#0)
I1227 14:38:07.854408 12920 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:07.855356 12869 solver.cpp:401]     Test net output #0: accuracy = 0.9875
I1227 14:38:07.855391 12869 solver.cpp:401]     Test net output #1: loss = 0.0364493 (* 1 = 0.0364493 loss)
I1227 14:38:07.857054 12869 solver.cpp:222] Iteration 2000 (393.73 iter/s, 0.253981s/100 iters), loss = 0.0342241
I1227 14:38:07.857089 12869 solver.cpp:241]     Train net output #0: loss = 0.0342241 (* 1 = 0.0342241 loss)
I1227 14:38:07.857103 12869 sgd_solver.cpp:119] Iteration 2000, lr = 0.00872196
I1227 14:38:08.038384 12869 solver.cpp:222] Iteration 2100 (551.635 iter/s, 0.181279s/100 iters), loss = 0.0566007
I1227 14:38:08.038435 12869 solver.cpp:241]     Train net output #0: loss = 0.0566006 (* 1 = 0.0566006 loss)
I1227 14:38:08.038451 12869 sgd_solver.cpp:119] Iteration 2100, lr = 0.00866784
I1227 14:38:08.047859 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:08.219053 12869 solver.cpp:222] Iteration 2200 (553.701 iter/s, 0.180603s/100 iters), loss = 0.0131239
I1227 14:38:08.219102 12869 solver.cpp:241]     Train net output #0: loss = 0.0131238 (* 1 = 0.0131238 loss)
I1227 14:38:08.219117 12869 sgd_solver.cpp:119] Iteration 2200, lr = 0.0086145
I1227 14:38:08.399544 12869 solver.cpp:222] Iteration 2300 (554.249 iter/s, 0.180424s/100 iters), loss = 0.0286665
I1227 14:38:08.399595 12869 solver.cpp:241]     Train net output #0: loss = 0.0286665 (* 1 = 0.0286665 loss)
I1227 14:38:08.399610 12869 sgd_solver.cpp:119] Iteration 2300, lr = 0.00856192
I1227 14:38:08.470675 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:08.580260 12869 solver.cpp:222] Iteration 2400 (553.553 iter/s, 0.180651s/100 iters), loss = 0.0317209
I1227 14:38:08.580312 12869 solver.cpp:241]     Train net output #0: loss = 0.0317209 (* 1 = 0.0317209 loss)
I1227 14:38:08.580329 12869 sgd_solver.cpp:119] Iteration 2400, lr = 0.00851008
I1227 14:38:08.759325 12869 solver.cpp:334] Iteration 2500, Testing net (#0)
I1227 14:38:08.831435 12920 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:08.832363 12869 solver.cpp:401]     Test net output #0: accuracy = 0.9886
I1227 14:38:08.832396 12869 solver.cpp:401]     Test net output #1: loss = 0.033961 (* 1 = 0.033961 loss)
I1227 14:38:08.835675 12869 solver.cpp:222] Iteration 2500 (391.623 iter/s, 0.255348s/100 iters), loss = 0.0886284
I1227 14:38:08.835708 12869 solver.cpp:241]     Train net output #0: loss = 0.0886284 (* 1 = 0.0886284 loss)
I1227 14:38:08.835724 12869 sgd_solver.cpp:119] Iteration 2500, lr = 0.00845897
I1227 14:38:08.969795 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:09.017560 12869 solver.cpp:222] Iteration 2600 (549.944 iter/s, 0.181837s/100 iters), loss = 0.0293762
I1227 14:38:09.017603 12869 solver.cpp:241]     Train net output #0: loss = 0.0293761 (* 1 = 0.0293761 loss)
I1227 14:38:09.017618 12869 sgd_solver.cpp:119] Iteration 2600, lr = 0.00840857
I1227 14:38:09.205293 12869 solver.cpp:222] Iteration 2700 (532.844 iter/s, 0.187672s/100 iters), loss = 0.0256299
I1227 14:38:09.205338 12869 solver.cpp:241]     Train net output #0: loss = 0.0256299 (* 1 = 0.0256299 loss)
I1227 14:38:09.205354 12869 sgd_solver.cpp:119] Iteration 2700, lr = 0.00835886
I1227 14:38:09.387296 12869 solver.cpp:222] Iteration 2800 (549.641 iter/s, 0.181937s/100 iters), loss = 0.0167004
I1227 14:38:09.387344 12869 solver.cpp:241]     Train net output #0: loss = 0.0167004 (* 1 = 0.0167004 loss)
I1227 14:38:09.387359 12869 sgd_solver.cpp:119] Iteration 2800, lr = 0.00830984
I1227 14:38:09.402426 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:09.573357 12869 solver.cpp:222] Iteration 2900 (537.648 iter/s, 0.185995s/100 iters), loss = 0.010003
I1227 14:38:09.573400 12869 solver.cpp:241]     Train net output #0: loss = 0.0100029 (* 1 = 0.0100029 loss)
I1227 14:38:09.573412 12869 sgd_solver.cpp:119] Iteration 2900, lr = 0.00826148
I1227 14:38:09.752949 12869 solver.cpp:334] Iteration 3000, Testing net (#0)
I1227 14:38:09.827302 12920 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:09.828115 12869 solver.cpp:401]     Test net output #0: accuracy = 0.9867
I1227 14:38:09.828148 12869 solver.cpp:401]     Test net output #1: loss = 0.0374514 (* 1 = 0.0374514 loss)
I1227 14:38:09.829736 12869 solver.cpp:222] Iteration 3000 (390.135 iter/s, 0.256322s/100 iters), loss = 0.0114608
I1227 14:38:09.829766 12869 solver.cpp:241]     Train net output #0: loss = 0.0114608 (* 1 = 0.0114608 loss)
I1227 14:38:09.829778 12869 sgd_solver.cpp:119] Iteration 3000, lr = 0.00821377
I1227 14:38:09.912046 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:10.015692 12869 solver.cpp:222] Iteration 3100 (537.902 iter/s, 0.185907s/100 iters), loss = 0.00951249
I1227 14:38:10.015736 12869 solver.cpp:241]     Train net output #0: loss = 0.00951247 (* 1 = 0.00951247 loss)
I1227 14:38:10.015748 12869 sgd_solver.cpp:119] Iteration 3100, lr = 0.0081667
I1227 14:38:10.197347 12869 solver.cpp:222] Iteration 3200 (550.676 iter/s, 0.181595s/100 iters), loss = 0.008371
I1227 14:38:10.197388 12869 solver.cpp:241]     Train net output #0: loss = 0.00837099 (* 1 = 0.00837099 loss)
I1227 14:38:10.197401 12869 sgd_solver.cpp:119] Iteration 3200, lr = 0.00812025
I1227 14:38:10.336402 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:10.377352 12869 solver.cpp:222] Iteration 3300 (555.712 iter/s, 0.179949s/100 iters), loss = 0.0150678
I1227 14:38:10.377395 12869 solver.cpp:241]     Train net output #0: loss = 0.0150678 (* 1 = 0.0150678 loss)
I1227 14:38:10.377421 12869 sgd_solver.cpp:119] Iteration 3300, lr = 0.00807442
I1227 14:38:10.558727 12869 solver.cpp:222] Iteration 3400 (551.522 iter/s, 0.181316s/100 iters), loss = 0.0161648
I1227 14:38:10.558768 12869 solver.cpp:241]     Train net output #0: loss = 0.0161648 (* 1 = 0.0161648 loss)
I1227 14:38:10.558780 12869 sgd_solver.cpp:119] Iteration 3400, lr = 0.00802918
I1227 14:38:10.738993 12869 solver.cpp:334] Iteration 3500, Testing net (#0)
I1227 14:38:10.814625 12920 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:10.815416 12869 solver.cpp:401]     Test net output #0: accuracy = 0.9897
I1227 14:38:10.815443 12869 solver.cpp:401]     Test net output #1: loss = 0.0316269 (* 1 = 0.0316269 loss)
I1227 14:38:10.817071 12869 solver.cpp:222] Iteration 3500 (387.165 iter/s, 0.258287s/100 iters), loss = 0.0161754
I1227 14:38:10.817101 12869 solver.cpp:241]     Train net output #0: loss = 0.0161754 (* 1 = 0.0161754 loss)
I1227 14:38:10.817112 12869 sgd_solver.cpp:119] Iteration 3500, lr = 0.00798454
I1227 14:38:10.840330 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:11.003634 12869 solver.cpp:222] Iteration 3600 (536.145 iter/s, 0.186517s/100 iters), loss = 0.00387025
I1227 14:38:11.003679 12869 solver.cpp:241]     Train net output #0: loss = 0.00387025 (* 1 = 0.00387025 loss)
I1227 14:38:11.003690 12869 sgd_solver.cpp:119] Iteration 3600, lr = 0.00794046
I1227 14:38:11.187180 12869 solver.cpp:222] Iteration 3700 (544.999 iter/s, 0.183486s/100 iters), loss = 0.0574895
I1227 14:38:11.187228 12869 solver.cpp:241]     Train net output #0: loss = 0.0574895 (* 1 = 0.0574895 loss)
I1227 14:38:11.187240 12869 sgd_solver.cpp:119] Iteration 3700, lr = 0.00789695
I1227 14:38:11.270504 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:11.367671 12869 solver.cpp:222] Iteration 3800 (554.235 iter/s, 0.180429s/100 iters), loss = 0.0242187
I1227 14:38:11.367712 12869 solver.cpp:241]     Train net output #0: loss = 0.0242187 (* 1 = 0.0242187 loss)
I1227 14:38:11.367723 12869 sgd_solver.cpp:119] Iteration 3800, lr = 0.007854
I1227 14:38:11.547792 12869 solver.cpp:222] Iteration 3900 (555.365 iter/s, 0.180062s/100 iters), loss = 0.0340185
I1227 14:38:11.547837 12869 solver.cpp:241]     Train net output #0: loss = 0.0340185 (* 1 = 0.0340185 loss)
I1227 14:38:11.547848 12869 sgd_solver.cpp:119] Iteration 3900, lr = 0.00781158
I1227 14:38:11.692257 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:11.726094 12869 solver.cpp:334] Iteration 4000, Testing net (#0)
I1227 14:38:11.800024 12920 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:11.800859 12869 solver.cpp:401]     Test net output #0: accuracy = 0.99
I1227 14:38:11.800890 12869 solver.cpp:401]     Test net output #1: loss = 0.0293733 (* 1 = 0.0293733 loss)
I1227 14:38:11.803352 12869 solver.cpp:222] Iteration 4000 (391.441 iter/s, 0.255466s/100 iters), loss = 0.00705198
I1227 14:38:11.803383 12869 solver.cpp:241]     Train net output #0: loss = 0.00705197 (* 1 = 0.00705197 loss)
I1227 14:38:11.803397 12869 sgd_solver.cpp:119] Iteration 4000, lr = 0.0077697
I1227 14:38:11.987289 12869 solver.cpp:222] Iteration 4100 (543.815 iter/s, 0.183886s/100 iters), loss = 0.00963027
I1227 14:38:11.987335 12869 solver.cpp:241]     Train net output #0: loss = 0.00963025 (* 1 = 0.00963025 loss)
I1227 14:38:11.987347 12869 sgd_solver.cpp:119] Iteration 4100, lr = 0.00772833
I1227 14:38:12.167166 12869 solver.cpp:222] Iteration 4200 (556.125 iter/s, 0.179816s/100 iters), loss = 0.0963897
I1227 14:38:12.167210 12869 solver.cpp:241]     Train net output #0: loss = 0.0963897 (* 1 = 0.0963897 loss)
I1227 14:38:12.167222 12869 sgd_solver.cpp:119] Iteration 4200, lr = 0.00768748
I1227 14:38:12.193248 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:12.348407 12869 solver.cpp:222] Iteration 4300 (551.938 iter/s, 0.18118s/100 iters), loss = 0.0168838
I1227 14:38:12.348450 12869 solver.cpp:241]     Train net output #0: loss = 0.0168838 (* 1 = 0.0168838 loss)
I1227 14:38:12.348475 12869 sgd_solver.cpp:119] Iteration 4300, lr = 0.00764712
I1227 14:38:12.528476 12869 solver.cpp:222] Iteration 4400 (555.52 iter/s, 0.180011s/100 iters), loss = 0.00812517
I1227 14:38:12.528517 12869 solver.cpp:241]     Train net output #0: loss = 0.00812518 (* 1 = 0.00812518 loss)
I1227 14:38:12.528528 12869 sgd_solver.cpp:119] Iteration 4400, lr = 0.00760726
I1227 14:38:12.616655 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:12.709187 12869 solver.cpp:334] Iteration 4500, Testing net (#0)
I1227 14:38:12.783329 12920 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:12.784139 12869 solver.cpp:401]     Test net output #0: accuracy = 0.9898
I1227 14:38:12.784168 12869 solver.cpp:401]     Test net output #1: loss = 0.0305407 (* 1 = 0.0305407 loss)
I1227 14:38:12.785773 12869 solver.cpp:222] Iteration 4500 (388.744 iter/s, 0.257239s/100 iters), loss = 0.0177639
I1227 14:38:12.785804 12869 solver.cpp:241]     Train net output #0: loss = 0.0177639 (* 1 = 0.0177639 loss)
I1227 14:38:12.785816 12869 sgd_solver.cpp:119] Iteration 4500, lr = 0.00756788
I1227 14:38:12.971535 12869 solver.cpp:222] Iteration 4600 (538.46 iter/s, 0.185715s/100 iters), loss = 0.0192059
I1227 14:38:12.971576 12869 solver.cpp:241]     Train net output #0: loss = 0.0192059 (* 1 = 0.0192059 loss)
I1227 14:38:12.971587 12869 sgd_solver.cpp:119] Iteration 4600, lr = 0.00752897
I1227 14:38:13.123013 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:13.152909 12869 solver.cpp:222] Iteration 4700 (551.518 iter/s, 0.181318s/100 iters), loss = 0.00684469
I1227 14:38:13.152950 12869 solver.cpp:241]     Train net output #0: loss = 0.00684471 (* 1 = 0.00684471 loss)
I1227 14:38:13.152961 12869 sgd_solver.cpp:119] Iteration 4700, lr = 0.00749052
I1227 14:38:13.333423 12869 solver.cpp:222] Iteration 4800 (554.142 iter/s, 0.180459s/100 iters), loss = 0.0112676
I1227 14:38:13.333464 12869 solver.cpp:241]     Train net output #0: loss = 0.0112676 (* 1 = 0.0112676 loss)
I1227 14:38:13.333477 12869 sgd_solver.cpp:119] Iteration 4800, lr = 0.00745253
I1227 14:38:13.514977 12869 solver.cpp:222] Iteration 4900 (550.974 iter/s, 0.181497s/100 iters), loss = 0.00841654
I1227 14:38:13.515023 12869 solver.cpp:241]     Train net output #0: loss = 0.00841655 (* 1 = 0.00841655 loss)
I1227 14:38:13.515035 12869 sgd_solver.cpp:119] Iteration 4900, lr = 0.00741498
I1227 14:38:13.546250 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:13.692828 12869 solver.cpp:451] Snapshotting to binary proto file examples/mnist/lenet_iter_5000.caffemodel
I1227 14:38:13.716908 12869 sgd_solver.cpp:343] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_5000.solverstate
I1227 14:38:13.720333 12869 solver.cpp:334] Iteration 5000, Testing net (#0)
I1227 14:38:13.795414 12920 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:13.796147 12869 solver.cpp:401]     Test net output #0: accuracy = 0.9904
I1227 14:38:13.796178 12869 solver.cpp:401]     Test net output #1: loss = 0.0276145 (* 1 = 0.0276145 loss)
I1227 14:38:13.797819 12869 solver.cpp:222] Iteration 5000 (353.632 iter/s, 0.28278s/100 iters), loss = 0.0114988
I1227 14:38:13.797852 12869 solver.cpp:241]     Train net output #0: loss = 0.0114988 (* 1 = 0.0114988 loss)
I1227 14:38:13.797866 12869 sgd_solver.cpp:119] Iteration 5000, lr = 0.00737788
I1227 14:38:13.982936 12869 solver.cpp:222] Iteration 5100 (540.342 iter/s, 0.185068s/100 iters), loss = 0.0116805
I1227 14:38:13.982980 12869 solver.cpp:241]     Train net output #0: loss = 0.0116805 (* 1 = 0.0116805 loss)
I1227 14:38:13.982993 12869 sgd_solver.cpp:119] Iteration 5100, lr = 0.0073412
I1227 14:38:14.076175 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:14.161463 12869 solver.cpp:222] Iteration 5200 (560.324 iter/s, 0.178468s/100 iters), loss = 0.00310459
I1227 14:38:14.161501 12869 solver.cpp:241]     Train net output #0: loss = 0.00310459 (* 1 = 0.00310459 loss)
I1227 14:38:14.161528 12869 sgd_solver.cpp:119] Iteration 5200, lr = 0.00730495
I1227 14:38:14.341334 12869 solver.cpp:222] Iteration 5300 (556.121 iter/s, 0.179817s/100 iters), loss = 0.00348821
I1227 14:38:14.341382 12869 solver.cpp:241]     Train net output #0: loss = 0.00348822 (* 1 = 0.00348822 loss)
I1227 14:38:14.341393 12869 sgd_solver.cpp:119] Iteration 5300, lr = 0.00726911
I1227 14:38:14.495461 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:14.519896 12869 solver.cpp:222] Iteration 5400 (560.218 iter/s, 0.178502s/100 iters), loss = 0.00769628
I1227 14:38:14.519933 12869 solver.cpp:241]     Train net output #0: loss = 0.00769629 (* 1 = 0.00769629 loss)
I1227 14:38:14.519946 12869 sgd_solver.cpp:119] Iteration 5400, lr = 0.00723368
I1227 14:38:14.697288 12869 solver.cpp:334] Iteration 5500, Testing net (#0)
I1227 14:38:14.772063 12920 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:14.772835 12869 solver.cpp:401]     Test net output #0: accuracy = 0.9908
I1227 14:38:14.772863 12869 solver.cpp:401]     Test net output #1: loss = 0.0270024 (* 1 = 0.0270024 loss)
I1227 14:38:14.774441 12869 solver.cpp:222] Iteration 5500 (392.94 iter/s, 0.254492s/100 iters), loss = 0.00300272
I1227 14:38:14.774471 12869 solver.cpp:241]     Train net output #0: loss = 0.00300274 (* 1 = 0.00300274 loss)
I1227 14:38:14.774484 12869 sgd_solver.cpp:119] Iteration 5500, lr = 0.00719865
I1227 14:38:14.958228 12869 solver.cpp:222] Iteration 5600 (544.25 iter/s, 0.183739s/100 iters), loss = 0.0235059
I1227 14:38:14.958276 12869 solver.cpp:241]     Train net output #0: loss = 0.0235059 (* 1 = 0.0235059 loss)
I1227 14:38:14.958305 12869 sgd_solver.cpp:119] Iteration 5600, lr = 0.00716402
I1227 14:38:14.996039 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:15.137145 12869 solver.cpp:222] Iteration 5700 (559.184 iter/s, 0.178832s/100 iters), loss = 0.016494
I1227 14:38:15.137190 12869 solver.cpp:241]     Train net output #0: loss = 0.016494 (* 1 = 0.016494 loss)
I1227 14:38:15.137203 12869 sgd_solver.cpp:119] Iteration 5700, lr = 0.00712977
I1227 14:38:15.315923 12869 solver.cpp:222] Iteration 5800 (559.54 iter/s, 0.178718s/100 iters), loss = 0.00344209
I1227 14:38:15.315970 12869 solver.cpp:241]     Train net output #0: loss = 0.00344207 (* 1 = 0.00344207 loss)
I1227 14:38:15.315982 12869 sgd_solver.cpp:119] Iteration 5800, lr = 0.0070959
I1227 14:38:15.414990 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:15.496518 12869 solver.cpp:222] Iteration 5900 (553.914 iter/s, 0.180534s/100 iters), loss = 0.00144116
I1227 14:38:15.496558 12869 solver.cpp:241]     Train net output #0: loss = 0.00144116 (* 1 = 0.00144116 loss)
I1227 14:38:15.496572 12869 sgd_solver.cpp:119] Iteration 5900, lr = 0.0070624
I1227 14:38:15.673981 12869 solver.cpp:334] Iteration 6000, Testing net (#0)
I1227 14:38:15.747221 12920 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:15.748010 12869 solver.cpp:401]     Test net output #0: accuracy = 0.9903
I1227 14:38:15.748044 12869 solver.cpp:401]     Test net output #1: loss = 0.027252 (* 1 = 0.027252 loss)
I1227 14:38:15.749665 12869 solver.cpp:222] Iteration 6000 (395.117 iter/s, 0.253089s/100 iters), loss = 0.0249395
I1227 14:38:15.749696 12869 solver.cpp:241]     Train net output #0: loss = 0.0249395 (* 1 = 0.0249395 loss)
I1227 14:38:15.749708 12869 sgd_solver.cpp:119] Iteration 6000, lr = 0.00702927
I1227 14:38:15.917735 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:15.936707 12869 solver.cpp:222] Iteration 6100 (534.772 iter/s, 0.186996s/100 iters), loss = 0.0245533
I1227 14:38:15.936744 12869 solver.cpp:241]     Train net output #0: loss = 0.0245533 (* 1 = 0.0245533 loss)
I1227 14:38:15.936756 12869 sgd_solver.cpp:119] Iteration 6100, lr = 0.0069965
I1227 14:38:16.115440 12869 solver.cpp:222] Iteration 6200 (559.66 iter/s, 0.17868s/100 iters), loss = 0.0149716
I1227 14:38:16.115485 12869 solver.cpp:241]     Train net output #0: loss = 0.0149716 (* 1 = 0.0149716 loss)
I1227 14:38:16.115514 12869 sgd_solver.cpp:119] Iteration 6200, lr = 0.00696408
I1227 14:38:16.295217 12869 solver.cpp:222] Iteration 6300 (556.447 iter/s, 0.179712s/100 iters), loss = 0.0247725
I1227 14:38:16.295262 12869 solver.cpp:241]     Train net output #0: loss = 0.0247725 (* 1 = 0.0247725 loss)
I1227 14:38:16.295275 12869 sgd_solver.cpp:119] Iteration 6300, lr = 0.00693201
I1227 14:38:16.338392 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:16.473753 12869 solver.cpp:222] Iteration 6400 (560.297 iter/s, 0.178477s/100 iters), loss = 0.00588913
I1227 14:38:16.473798 12869 solver.cpp:241]     Train net output #0: loss = 0.00588915 (* 1 = 0.00588915 loss)
I1227 14:38:16.473809 12869 sgd_solver.cpp:119] Iteration 6400, lr = 0.00690029
I1227 14:38:16.650684 12869 solver.cpp:334] Iteration 6500, Testing net (#0)
I1227 14:38:16.696511 12869 blocking_queue.cpp:49] Waiting for data
I1227 14:38:16.724697 12920 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:16.725554 12869 solver.cpp:401]     Test net output #0: accuracy = 0.991
I1227 14:38:16.725581 12869 solver.cpp:401]     Test net output #1: loss = 0.0276472 (* 1 = 0.0276472 loss)
I1227 14:38:16.727224 12869 solver.cpp:222] Iteration 6500 (394.616 iter/s, 0.253411s/100 iters), loss = 0.00516394
I1227 14:38:16.727255 12869 solver.cpp:241]     Train net output #0: loss = 0.00516397 (* 1 = 0.00516397 loss)
I1227 14:38:16.727267 12869 sgd_solver.cpp:119] Iteration 6500, lr = 0.0068689
I1227 14:38:16.840225 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:16.914754 12869 solver.cpp:222] Iteration 6600 (533.375 iter/s, 0.187485s/100 iters), loss = 0.00302637
I1227 14:38:16.914793 12869 solver.cpp:241]     Train net output #0: loss = 0.00302639 (* 1 = 0.00302639 loss)
I1227 14:38:16.914805 12869 sgd_solver.cpp:119] Iteration 6600, lr = 0.00683784
I1227 14:38:17.093257 12869 solver.cpp:222] Iteration 6700 (560.385 iter/s, 0.178449s/100 iters), loss = 0.00537305
I1227 14:38:17.093308 12869 solver.cpp:241]     Train net output #0: loss = 0.00537306 (* 1 = 0.00537306 loss)
I1227 14:38:17.093322 12869 sgd_solver.cpp:119] Iteration 6700, lr = 0.00680711
I1227 14:38:17.258440 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:17.271963 12869 solver.cpp:222] Iteration 6800 (559.782 iter/s, 0.178641s/100 iters), loss = 0.00674307
I1227 14:38:17.272001 12869 solver.cpp:241]     Train net output #0: loss = 0.00674309 (* 1 = 0.00674309 loss)
I1227 14:38:17.272013 12869 sgd_solver.cpp:119] Iteration 6800, lr = 0.0067767
I1227 14:38:17.452064 12869 solver.cpp:222] Iteration 6900 (555.408 iter/s, 0.180048s/100 iters), loss = 0.118842
I1227 14:38:17.452112 12869 solver.cpp:241]     Train net output #0: loss = 0.118842 (* 1 = 0.118842 loss)
I1227 14:38:17.452124 12869 sgd_solver.cpp:119] Iteration 6900, lr = 0.0067466
I1227 14:38:17.629140 12869 solver.cpp:334] Iteration 7000, Testing net (#0)
I1227 14:38:17.703035 12920 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:17.703797 12869 solver.cpp:401]     Test net output #0: accuracy = 0.9903
I1227 14:38:17.703826 12869 solver.cpp:401]     Test net output #1: loss = 0.0274389 (* 1 = 0.0274389 loss)
I1227 14:38:17.705440 12869 solver.cpp:222] Iteration 7000 (394.771 iter/s, 0.253312s/100 iters), loss = 0.00317657
I1227 14:38:17.705469 12869 solver.cpp:241]     Train net output #0: loss = 0.00317658 (* 1 = 0.00317658 loss)
I1227 14:38:17.705485 12869 sgd_solver.cpp:119] Iteration 7000, lr = 0.00671681
I1227 14:38:17.761319 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:17.893779 12869 solver.cpp:222] Iteration 7100 (531.089 iter/s, 0.188292s/100 iters), loss = 0.00709548
I1227 14:38:17.893820 12869 solver.cpp:241]     Train net output #0: loss = 0.0070955 (* 1 = 0.0070955 loss)
I1227 14:38:17.893831 12869 sgd_solver.cpp:119] Iteration 7100, lr = 0.00668733
I1227 14:38:18.072872 12869 solver.cpp:222] Iteration 7200 (558.542 iter/s, 0.179038s/100 iters), loss = 0.00387562
I1227 14:38:18.072933 12869 solver.cpp:241]     Train net output #0: loss = 0.00387563 (* 1 = 0.00387563 loss)
I1227 14:38:18.072973 12869 sgd_solver.cpp:119] Iteration 7200, lr = 0.00665815
I1227 14:38:18.183996 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:18.253257 12869 solver.cpp:222] Iteration 7300 (554.601 iter/s, 0.18031s/100 iters), loss = 0.00188311
I1227 14:38:18.253302 12869 solver.cpp:241]     Train net output #0: loss = 0.00188312 (* 1 = 0.00188312 loss)
I1227 14:38:18.253315 12869 sgd_solver.cpp:119] Iteration 7300, lr = 0.00662927
I1227 14:38:18.432030 12869 solver.cpp:222] Iteration 7400 (559.557 iter/s, 0.178713s/100 iters), loss = 0.0117642
I1227 14:38:18.432075 12869 solver.cpp:241]     Train net output #0: loss = 0.0117642 (* 1 = 0.0117642 loss)
I1227 14:38:18.432087 12869 sgd_solver.cpp:119] Iteration 7400, lr = 0.00660067
I1227 14:38:18.603838 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:18.609189 12869 solver.cpp:334] Iteration 7500, Testing net (#0)
I1227 14:38:18.684144 12920 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:18.685024 12869 solver.cpp:401]     Test net output #0: accuracy = 0.9897
I1227 14:38:18.685051 12869 solver.cpp:401]     Test net output #1: loss = 0.0304525 (* 1 = 0.0304525 loss)
I1227 14:38:18.686615 12869 solver.cpp:222] Iteration 7500 (392.889 iter/s, 0.254525s/100 iters), loss = 0.0339477
I1227 14:38:18.686652 12869 solver.cpp:241]     Train net output #0: loss = 0.0339477 (* 1 = 0.0339477 loss)
I1227 14:38:18.686664 12869 sgd_solver.cpp:119] Iteration 7500, lr = 0.00657236
I1227 14:38:18.875442 12869 solver.cpp:222] Iteration 7600 (529.739 iter/s, 0.188772s/100 iters), loss = 0.00810453
I1227 14:38:18.875486 12869 solver.cpp:241]     Train net output #0: loss = 0.00810455 (* 1 = 0.00810455 loss)
I1227 14:38:18.875499 12869 sgd_solver.cpp:119] Iteration 7600, lr = 0.00654433
I1227 14:38:19.053771 12869 solver.cpp:222] Iteration 7700 (560.95 iter/s, 0.178269s/100 iters), loss = 0.0631735
I1227 14:38:19.053817 12869 solver.cpp:241]     Train net output #0: loss = 0.0631735 (* 1 = 0.0631735 loss)
I1227 14:38:19.053829 12869 sgd_solver.cpp:119] Iteration 7700, lr = 0.00651658
I1227 14:38:19.108089 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:19.232715 12869 solver.cpp:222] Iteration 7800 (559.021 iter/s, 0.178884s/100 iters), loss = 0.00490885
I1227 14:38:19.232756 12869 solver.cpp:241]     Train net output #0: loss = 0.00490888 (* 1 = 0.00490888 loss)
I1227 14:38:19.232769 12869 sgd_solver.cpp:119] Iteration 7800, lr = 0.00648911
I1227 14:38:19.411494 12869 solver.cpp:222] Iteration 7900 (559.526 iter/s, 0.178723s/100 iters), loss = 0.00561823
I1227 14:38:19.411540 12869 solver.cpp:241]     Train net output #0: loss = 0.00561825 (* 1 = 0.00561825 loss)
I1227 14:38:19.411551 12869 sgd_solver.cpp:119] Iteration 7900, lr = 0.0064619
I1227 14:38:19.529527 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:19.591794 12869 solver.cpp:334] Iteration 8000, Testing net (#0)
I1227 14:38:19.666491 12920 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:19.667351 12869 solver.cpp:401]     Test net output #0: accuracy = 0.99
I1227 14:38:19.667378 12869 solver.cpp:401]     Test net output #1: loss = 0.0290009 (* 1 = 0.0290009 loss)
I1227 14:38:19.668959 12869 solver.cpp:222] Iteration 8000 (388.493 iter/s, 0.257405s/100 iters), loss = 0.0128358
I1227 14:38:19.668988 12869 solver.cpp:241]     Train net output #0: loss = 0.0128358 (* 1 = 0.0128358 loss)
I1227 14:38:19.669001 12869 sgd_solver.cpp:119] Iteration 8000, lr = 0.00643496
I1227 14:38:19.857131 12869 solver.cpp:222] Iteration 8100 (531.562 iter/s, 0.188125s/100 iters), loss = 0.00537155
I1227 14:38:19.857174 12869 solver.cpp:241]     Train net output #0: loss = 0.00537156 (* 1 = 0.00537156 loss)
I1227 14:38:19.857187 12869 sgd_solver.cpp:119] Iteration 8100, lr = 0.00640827
I1227 14:38:20.034386 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:20.035828 12869 solver.cpp:222] Iteration 8200 (559.785 iter/s, 0.17864s/100 iters), loss = 0.000354901
I1227 14:38:20.035894 12869 solver.cpp:241]     Train net output #0: loss = 0.000354918 (* 1 = 0.000354918 loss)
I1227 14:38:20.035907 12869 sgd_solver.cpp:119] Iteration 8200, lr = 0.00638185
I1227 14:38:20.214926 12869 solver.cpp:222] Iteration 8300 (558.611 iter/s, 0.179016s/100 iters), loss = 0.00357543
I1227 14:38:20.214972 12869 solver.cpp:241]     Train net output #0: loss = 0.00357545 (* 1 = 0.00357545 loss)
I1227 14:38:20.214983 12869 sgd_solver.cpp:119] Iteration 8300, lr = 0.00635567
I1227 14:38:20.393725 12869 solver.cpp:222] Iteration 8400 (559.478 iter/s, 0.178738s/100 iters), loss = 0.00947218
I1227 14:38:20.393771 12869 solver.cpp:241]     Train net output #0: loss = 0.00947219 (* 1 = 0.00947219 loss)
I1227 14:38:20.393784 12869 sgd_solver.cpp:119] Iteration 8400, lr = 0.00632975
I1227 14:38:20.453335 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:20.571789 12869 solver.cpp:334] Iteration 8500, Testing net (#0)
I1227 14:38:20.645977 12920 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:20.646786 12869 solver.cpp:401]     Test net output #0: accuracy = 0.9904
I1227 14:38:20.646816 12869 solver.cpp:401]     Test net output #1: loss = 0.0276612 (* 1 = 0.0276612 loss)
I1227 14:38:20.648394 12869 solver.cpp:222] Iteration 8500 (392.765 iter/s, 0.254605s/100 iters), loss = 0.00209696
I1227 14:38:20.648422 12869 solver.cpp:241]     Train net output #0: loss = 0.00209697 (* 1 = 0.00209697 loss)
I1227 14:38:20.648443 12869 sgd_solver.cpp:119] Iteration 8500, lr = 0.00630407
I1227 14:38:20.837337 12869 solver.cpp:222] Iteration 8600 (529.401 iter/s, 0.188893s/100 iters), loss = 0.00367515
I1227 14:38:20.837378 12869 solver.cpp:241]     Train net output #0: loss = 0.00367515 (* 1 = 0.00367515 loss)
I1227 14:38:20.837389 12869 sgd_solver.cpp:119] Iteration 8600, lr = 0.00627864
I1227 14:38:20.958833 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:21.017163 12869 solver.cpp:222] Iteration 8700 (556.266 iter/s, 0.17977s/100 iters), loss = 0.00990998
I1227 14:38:21.017204 12869 solver.cpp:241]     Train net output #0: loss = 0.00990998 (* 1 = 0.00990998 loss)
I1227 14:38:21.017215 12869 sgd_solver.cpp:119] Iteration 8700, lr = 0.00625344
I1227 14:38:21.196729 12869 solver.cpp:222] Iteration 8800 (557.073 iter/s, 0.17951s/100 iters), loss = 0.0054206
I1227 14:38:21.196771 12869 solver.cpp:241]     Train net output #0: loss = 0.00542061 (* 1 = 0.00542061 loss)
I1227 14:38:21.196784 12869 sgd_solver.cpp:119] Iteration 8800, lr = 0.00622847
I1227 14:38:21.376591 12869 solver.cpp:222] Iteration 8900 (556.162 iter/s, 0.179804s/100 iters), loss = 0.0038842
I1227 14:38:21.376632 12869 solver.cpp:241]     Train net output #0: loss = 0.0038842 (* 1 = 0.0038842 loss)
I1227 14:38:21.376644 12869 sgd_solver.cpp:119] Iteration 8900, lr = 0.00620374
I1227 14:38:21.381520 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:21.555858 12869 solver.cpp:334] Iteration 9000, Testing net (#0)
I1227 14:38:21.630933 12920 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:21.631693 12869 solver.cpp:401]     Test net output #0: accuracy = 0.9906
I1227 14:38:21.631722 12869 solver.cpp:401]     Test net output #1: loss = 0.0263198 (* 1 = 0.0263198 loss)
I1227 14:38:21.633291 12869 solver.cpp:222] Iteration 9000 (389.655 iter/s, 0.256637s/100 iters), loss = 0.00269878
I1227 14:38:21.633321 12869 solver.cpp:241]     Train net output #0: loss = 0.00269878 (* 1 = 0.00269878 loss)
I1227 14:38:21.633333 12869 sgd_solver.cpp:119] Iteration 9000, lr = 0.00617924
I1227 14:38:21.821383 12869 solver.cpp:222] Iteration 9100 (531.779 iter/s, 0.188048s/100 iters), loss = 0.0103357
I1227 14:38:21.821424 12869 solver.cpp:241]     Train net output #0: loss = 0.0103357 (* 1 = 0.0103357 loss)
I1227 14:38:21.821435 12869 sgd_solver.cpp:119] Iteration 9100, lr = 0.00615496
I1227 14:38:21.886977 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:22.001538 12869 solver.cpp:222] Iteration 9200 (555.246 iter/s, 0.1801s/100 iters), loss = 0.00395356
I1227 14:38:22.001615 12869 solver.cpp:241]     Train net output #0: loss = 0.00395357 (* 1 = 0.00395357 loss)
I1227 14:38:22.001627 12869 sgd_solver.cpp:119] Iteration 9200, lr = 0.0061309
I1227 14:38:22.181497 12869 solver.cpp:222] Iteration 9300 (555.962 iter/s, 0.179868s/100 iters), loss = 0.0109755
I1227 14:38:22.181538 12869 solver.cpp:241]     Train net output #0: loss = 0.0109755 (* 1 = 0.0109755 loss)
I1227 14:38:22.181550 12869 sgd_solver.cpp:119] Iteration 9300, lr = 0.00610706
I1227 14:38:22.309751 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:22.361641 12869 solver.cpp:222] Iteration 9400 (555.283 iter/s, 0.180088s/100 iters), loss = 0.00525331
I1227 14:38:22.361682 12869 solver.cpp:241]     Train net output #0: loss = 0.00525332 (* 1 = 0.00525332 loss)
I1227 14:38:22.361694 12869 sgd_solver.cpp:119] Iteration 9400, lr = 0.00608343
I1227 14:38:22.539808 12869 solver.cpp:334] Iteration 9500, Testing net (#0)
I1227 14:38:22.614854 12920 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:22.615671 12869 solver.cpp:401]     Test net output #0: accuracy = 0.9904
I1227 14:38:22.615700 12869 solver.cpp:401]     Test net output #1: loss = 0.027354 (* 1 = 0.027354 loss)
I1227 14:38:22.617249 12869 solver.cpp:222] Iteration 9500 (391.313 iter/s, 0.25555s/100 iters), loss = 0.00737805
I1227 14:38:22.617280 12869 solver.cpp:241]     Train net output #0: loss = 0.00737806 (* 1 = 0.00737806 loss)
I1227 14:38:22.617297 12869 sgd_solver.cpp:119] Iteration 9500, lr = 0.00606002
I1227 14:38:22.804607 12869 solver.cpp:222] Iteration 9600 (533.87 iter/s, 0.187312s/100 iters), loss = 0.0107198
I1227 14:38:22.804653 12869 solver.cpp:241]     Train net output #0: loss = 0.0107198 (* 1 = 0.0107198 loss)
I1227 14:38:22.804666 12869 sgd_solver.cpp:119] Iteration 9600, lr = 0.00603682
I1227 14:38:22.814028 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:22.983425 12869 solver.cpp:222] Iteration 9700 (559.418 iter/s, 0.178757s/100 iters), loss = 0.00102777
I1227 14:38:22.983469 12869 solver.cpp:241]     Train net output #0: loss = 0.00102776 (* 1 = 0.00102776 loss)
I1227 14:38:22.983480 12869 sgd_solver.cpp:119] Iteration 9700, lr = 0.00601382
I1227 14:38:23.162451 12869 solver.cpp:222] Iteration 9800 (558.762 iter/s, 0.178967s/100 iters), loss = 0.00456772
I1227 14:38:23.162497 12869 solver.cpp:241]     Train net output #0: loss = 0.00456773 (* 1 = 0.00456773 loss)
I1227 14:38:23.162509 12869 sgd_solver.cpp:119] Iteration 9800, lr = 0.00599102
I1227 14:38:23.232771 12919 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:23.341045 12869 solver.cpp:222] Iteration 9900 (560.115 iter/s, 0.178535s/100 iters), loss = 0.0112619
I1227 14:38:23.341086 12869 solver.cpp:241]     Train net output #0: loss = 0.0112619 (* 1 = 0.0112619 loss)
I1227 14:38:23.341099 12869 sgd_solver.cpp:119] Iteration 9900, lr = 0.00596843
I1227 14:38:23.521296 12869 solver.cpp:451] Snapshotting to binary proto file examples/mnist/lenet_iter_10000.caffemodel
I1227 14:38:23.528242 12869 sgd_solver.cpp:343] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_10000.solverstate
I1227 14:38:23.532061 12869 solver.cpp:314] Iteration 10000, loss = 0.0100959
I1227 14:38:23.532085 12869 solver.cpp:334] Iteration 10000, Testing net (#0)
I1227 14:38:23.607342 12920 data_layer.cpp:73] Restarting data prefetching from start.
I1227 14:38:23.608155 12869 solver.cpp:401]     Test net output #0: accuracy = 0.9907
I1227 14:38:23.608180 12869 solver.cpp:401]     Test net output #1: loss = 0.0262057 (* 1 = 0.0262057 loss)
I1227 14:38:23.608186 12869 solver.cpp:319] Optimization Done.
I1227 14:38:23.724969 12869 caffe.cpp:259] Optimization Done.
