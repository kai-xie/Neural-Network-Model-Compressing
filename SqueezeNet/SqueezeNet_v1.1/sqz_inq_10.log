nohup: ignoring input
I1026 14:57:57.888679 20580 caffe.cpp:218] Using GPUs 0, 1, 2, 3
I1026 14:57:57.889449 20580 caffe.cpp:223] GPU 0: Tesla P40
I1026 14:57:57.889852 20580 caffe.cpp:223] GPU 1: Tesla P40
I1026 14:57:57.890236 20580 caffe.cpp:223] GPU 2: Tesla P40
I1026 14:57:57.890625 20580 caffe.cpp:223] GPU 3: Tesla P40
I1026 14:57:58.540566 20580 solver.cpp:44] Initializing solver from parameters: 
test_iter: 500
test_interval: 500
base_lr: 0.01
display: 40
max_iter: 170000
lr_policy: "poly"
power: 1
momentum: 0.9
weight_decay: 0.0002
snapshot: 1000
snapshot_prefix: "SqueezeNet/SqueezeNet_v1.1/sqznet_inq_10"
solver_mode: GPU
device_id: 0
random_seed: 42
net: "SqueezeNet/SqueezeNet_v1.1/train_val_inq_10.prototxt"
train_state {
  level: 0
  stage: ""
}
I1026 14:57:58.540957 20580 solver.cpp:87] Creating training net from net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_10.prototxt
I1026 14:57:58.542937 20580 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1026 14:57:58.543004 20580 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top1
I1026 14:57:58.543014 20580 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top5
I1026 14:57:58.543725 20580 net.cpp:51] Initializing net from parameters: 
name: "SqueezeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/data/caffe-imagenet/ilsvrc12_train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "INQConvolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "fire3/concat"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire4/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool3"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "fire5/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire4/concat"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "fire5/concat"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire6/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool5"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "fire9/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire8/concat"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "INQConvolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "pool10"
  bottom: "label"
  top: "loss"
}
I1026 14:57:58.544149 20580 layer_factory.hpp:77] Creating layer data
I1026 14:57:58.544312 20580 db_lmdb.cpp:35] Opened lmdb /home/data/caffe-imagenet/ilsvrc12_train_lmdb
I1026 14:57:58.544364 20580 net.cpp:84] Creating Layer data
I1026 14:57:58.544378 20580 net.cpp:387] data -> data
I1026 14:57:58.544409 20580 net.cpp:387] data -> label
I1026 14:57:58.546216 20580 data_layer.cpp:45] output data size: 128,3,227,227
I1026 14:57:58.752892 20580 net.cpp:127] Setting up data
I1026 14:57:58.752946 20580 net.cpp:136] Top shape: 128 3 227 227 (19787136)
I1026 14:57:58.752960 20580 net.cpp:136] Top shape: 128 (128)
I1026 14:57:58.752967 20580 net.cpp:144] Memory required for data: 79149056
I1026 14:57:58.752985 20580 layer_factory.hpp:77] Creating layer conv1
I1026 14:57:58.753011 20580 net.cpp:84] Creating Layer conv1
I1026 14:57:58.753023 20580 net.cpp:413] conv1 <- data
I1026 14:57:58.753042 20580 net.cpp:387] conv1 -> conv1
I1026 14:57:58.756284 20580 net.cpp:127] Setting up conv1
I1026 14:57:58.756311 20580 net.cpp:136] Top shape: 128 64 113 113 (104603648)
I1026 14:57:58.756319 20580 net.cpp:144] Memory required for data: 497563648
I1026 14:57:58.756338 20580 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1026 14:57:58.756351 20580 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1026 14:57:58.756363 20580 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1026 14:57:58.756371 20580 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1026 14:57:58.756376 20580 layer_factory.hpp:77] Creating layer relu_conv1
I1026 14:57:58.756392 20580 net.cpp:84] Creating Layer relu_conv1
I1026 14:57:58.756397 20580 net.cpp:413] relu_conv1 <- conv1
I1026 14:57:58.756405 20580 net.cpp:374] relu_conv1 -> conv1 (in-place)
I1026 14:57:59.151679 20580 net.cpp:127] Setting up relu_conv1
I1026 14:57:59.151748 20580 net.cpp:136] Top shape: 128 64 113 113 (104603648)
I1026 14:57:59.151757 20580 net.cpp:144] Memory required for data: 915978240
I1026 14:57:59.151803 20580 layer_factory.hpp:77] Creating layer pool1
I1026 14:57:59.151839 20580 net.cpp:84] Creating Layer pool1
I1026 14:57:59.151847 20580 net.cpp:413] pool1 <- conv1
I1026 14:57:59.151870 20580 net.cpp:387] pool1 -> pool1
I1026 14:57:59.151964 20580 net.cpp:127] Setting up pool1
I1026 14:57:59.151988 20580 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1026 14:57:59.152024 20580 net.cpp:144] Memory required for data: 1018738688
I1026 14:57:59.152030 20580 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I1026 14:57:59.152076 20580 net.cpp:84] Creating Layer fire2/squeeze1x1
I1026 14:57:59.152086 20580 net.cpp:413] fire2/squeeze1x1 <- pool1
I1026 14:57:59.152094 20580 net.cpp:387] fire2/squeeze1x1 -> fire2/squeeze1x1
I1026 14:57:59.154520 20580 net.cpp:127] Setting up fire2/squeeze1x1
I1026 14:57:59.154541 20580 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1026 14:57:59.154548 20580 net.cpp:144] Memory required for data: 1044428800
I1026 14:57:59.154559 20580 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1026 14:57:59.154572 20580 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1026 14:57:59.154583 20580 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1026 14:57:59.154589 20580 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1026 14:57:59.154595 20580 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I1026 14:57:59.154623 20580 net.cpp:84] Creating Layer fire2/relu_squeeze1x1
I1026 14:57:59.154630 20580 net.cpp:413] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I1026 14:57:59.154639 20580 net.cpp:374] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I1026 14:57:59.156003 20580 net.cpp:127] Setting up fire2/relu_squeeze1x1
I1026 14:57:59.156023 20580 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1026 14:57:59.156028 20580 net.cpp:144] Memory required for data: 1070118912
I1026 14:57:59.156034 20580 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1026 14:57:59.156049 20580 net.cpp:84] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1026 14:57:59.156055 20580 net.cpp:413] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I1026 14:57:59.156075 20580 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1026 14:57:59.156087 20580 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1026 14:57:59.156139 20580 net.cpp:127] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1026 14:57:59.156149 20580 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1026 14:57:59.156155 20580 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1026 14:57:59.156160 20580 net.cpp:144] Memory required for data: 1121499136
I1026 14:57:59.156168 20580 layer_factory.hpp:77] Creating layer fire2/expand1x1
I1026 14:57:59.156178 20580 net.cpp:84] Creating Layer fire2/expand1x1
I1026 14:57:59.156184 20580 net.cpp:413] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1026 14:57:59.156191 20580 net.cpp:387] fire2/expand1x1 -> fire2/expand1x1
I1026 14:57:59.156524 20580 net.cpp:127] Setting up fire2/expand1x1
I1026 14:57:59.156538 20580 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1026 14:57:59.156543 20580 net.cpp:144] Memory required for data: 1224259584
I1026 14:57:59.156553 20580 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1026 14:57:59.156560 20580 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1026 14:57:59.156568 20580 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1026 14:57:59.156574 20580 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1026 14:57:59.156579 20580 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I1026 14:57:59.156589 20580 net.cpp:84] Creating Layer fire2/relu_expand1x1
I1026 14:57:59.156596 20580 net.cpp:413] fire2/relu_expand1x1 <- fire2/expand1x1
I1026 14:57:59.156603 20580 net.cpp:374] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I1026 14:57:59.156795 20580 net.cpp:127] Setting up fire2/relu_expand1x1
I1026 14:57:59.156807 20580 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1026 14:57:59.156821 20580 net.cpp:144] Memory required for data: 1327020032
I1026 14:57:59.156828 20580 layer_factory.hpp:77] Creating layer fire2/expand3x3
I1026 14:57:59.156867 20580 net.cpp:84] Creating Layer fire2/expand3x3
I1026 14:57:59.156873 20580 net.cpp:413] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1026 14:57:59.156883 20580 net.cpp:387] fire2/expand3x3 -> fire2/expand3x3
I1026 14:57:59.157330 20580 net.cpp:127] Setting up fire2/expand3x3
I1026 14:57:59.157344 20580 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1026 14:57:59.157351 20580 net.cpp:144] Memory required for data: 1429780480
I1026 14:57:59.157361 20580 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1026 14:57:59.157368 20580 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1026 14:57:59.157374 20580 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1026 14:57:59.157382 20580 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1026 14:57:59.157399 20580 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I1026 14:57:59.157409 20580 net.cpp:84] Creating Layer fire2/relu_expand3x3
I1026 14:57:59.157415 20580 net.cpp:413] fire2/relu_expand3x3 <- fire2/expand3x3
I1026 14:57:59.157423 20580 net.cpp:374] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I1026 14:57:59.157620 20580 net.cpp:127] Setting up fire2/relu_expand3x3
I1026 14:57:59.157632 20580 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1026 14:57:59.157639 20580 net.cpp:144] Memory required for data: 1532540928
I1026 14:57:59.157644 20580 layer_factory.hpp:77] Creating layer fire2/concat
I1026 14:57:59.157667 20580 net.cpp:84] Creating Layer fire2/concat
I1026 14:57:59.157675 20580 net.cpp:413] fire2/concat <- fire2/expand1x1
I1026 14:57:59.157682 20580 net.cpp:413] fire2/concat <- fire2/expand3x3
I1026 14:57:59.157688 20580 net.cpp:387] fire2/concat -> fire2/concat
I1026 14:57:59.157721 20580 net.cpp:127] Setting up fire2/concat
I1026 14:57:59.157732 20580 net.cpp:136] Top shape: 128 128 56 56 (51380224)
I1026 14:57:59.157737 20580 net.cpp:144] Memory required for data: 1738061824
I1026 14:57:59.157755 20580 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I1026 14:57:59.157773 20580 net.cpp:84] Creating Layer fire3/squeeze1x1
I1026 14:57:59.157781 20580 net.cpp:413] fire3/squeeze1x1 <- fire2/concat
I1026 14:57:59.157788 20580 net.cpp:387] fire3/squeeze1x1 -> fire3/squeeze1x1
I1026 14:57:59.158118 20580 net.cpp:127] Setting up fire3/squeeze1x1
I1026 14:57:59.158130 20580 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1026 14:57:59.158135 20580 net.cpp:144] Memory required for data: 1763751936
I1026 14:57:59.158144 20580 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1026 14:57:59.158152 20580 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1026 14:57:59.158159 20580 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1026 14:57:59.158165 20580 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1026 14:57:59.158169 20580 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I1026 14:57:59.158179 20580 net.cpp:84] Creating Layer fire3/relu_squeeze1x1
I1026 14:57:59.158196 20580 net.cpp:413] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I1026 14:57:59.158206 20580 net.cpp:374] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I1026 14:57:59.159577 20580 net.cpp:127] Setting up fire3/relu_squeeze1x1
I1026 14:57:59.159596 20580 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1026 14:57:59.159602 20580 net.cpp:144] Memory required for data: 1789442048
I1026 14:57:59.159607 20580 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1026 14:57:59.159615 20580 net.cpp:84] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1026 14:57:59.159621 20580 net.cpp:413] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I1026 14:57:59.159631 20580 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1026 14:57:59.159659 20580 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1026 14:57:59.159713 20580 net.cpp:127] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1026 14:57:59.159723 20580 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1026 14:57:59.159729 20580 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1026 14:57:59.159735 20580 net.cpp:144] Memory required for data: 1840822272
I1026 14:57:59.159750 20580 layer_factory.hpp:77] Creating layer fire3/expand1x1
I1026 14:57:59.159765 20580 net.cpp:84] Creating Layer fire3/expand1x1
I1026 14:57:59.159771 20580 net.cpp:413] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1026 14:57:59.159778 20580 net.cpp:387] fire3/expand1x1 -> fire3/expand1x1
I1026 14:57:59.160117 20580 net.cpp:127] Setting up fire3/expand1x1
I1026 14:57:59.160130 20580 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1026 14:57:59.160135 20580 net.cpp:144] Memory required for data: 1943582720
I1026 14:57:59.160141 20580 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1026 14:57:59.160147 20580 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1026 14:57:59.160153 20580 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1026 14:57:59.160158 20580 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1026 14:57:59.160164 20580 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I1026 14:57:59.160185 20580 net.cpp:84] Creating Layer fire3/relu_expand1x1
I1026 14:57:59.160192 20580 net.cpp:413] fire3/relu_expand1x1 <- fire3/expand1x1
I1026 14:57:59.160198 20580 net.cpp:374] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I1026 14:57:59.160424 20580 net.cpp:127] Setting up fire3/relu_expand1x1
I1026 14:57:59.160437 20580 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1026 14:57:59.160444 20580 net.cpp:144] Memory required for data: 2046343168
I1026 14:57:59.160452 20580 layer_factory.hpp:77] Creating layer fire3/expand3x3
I1026 14:57:59.160465 20580 net.cpp:84] Creating Layer fire3/expand3x3
I1026 14:57:59.160472 20580 net.cpp:413] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1026 14:57:59.160481 20580 net.cpp:387] fire3/expand3x3 -> fire3/expand3x3
I1026 14:57:59.160889 20580 net.cpp:127] Setting up fire3/expand3x3
I1026 14:57:59.160900 20580 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1026 14:57:59.160907 20580 net.cpp:144] Memory required for data: 2149103616
I1026 14:57:59.160913 20580 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1026 14:57:59.160923 20580 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1026 14:57:59.160928 20580 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1026 14:57:59.160933 20580 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1026 14:57:59.160938 20580 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I1026 14:57:59.160956 20580 net.cpp:84] Creating Layer fire3/relu_expand3x3
I1026 14:57:59.160964 20580 net.cpp:413] fire3/relu_expand3x3 <- fire3/expand3x3
I1026 14:57:59.160969 20580 net.cpp:374] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I1026 14:57:59.161185 20580 net.cpp:127] Setting up fire3/relu_expand3x3
I1026 14:57:59.161200 20580 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1026 14:57:59.161206 20580 net.cpp:144] Memory required for data: 2251864064
I1026 14:57:59.161222 20580 layer_factory.hpp:77] Creating layer fire3/concat
I1026 14:57:59.161229 20580 net.cpp:84] Creating Layer fire3/concat
I1026 14:57:59.161234 20580 net.cpp:413] fire3/concat <- fire3/expand1x1
I1026 14:57:59.161242 20580 net.cpp:413] fire3/concat <- fire3/expand3x3
I1026 14:57:59.161249 20580 net.cpp:387] fire3/concat -> fire3/concat
I1026 14:57:59.161283 20580 net.cpp:127] Setting up fire3/concat
I1026 14:57:59.161310 20580 net.cpp:136] Top shape: 128 128 56 56 (51380224)
I1026 14:57:59.161329 20580 net.cpp:144] Memory required for data: 2457384960
I1026 14:57:59.161334 20580 layer_factory.hpp:77] Creating layer pool3
I1026 14:57:59.161347 20580 net.cpp:84] Creating Layer pool3
I1026 14:57:59.161352 20580 net.cpp:413] pool3 <- fire3/concat
I1026 14:57:59.161360 20580 net.cpp:387] pool3 -> pool3
I1026 14:57:59.161412 20580 net.cpp:127] Setting up pool3
I1026 14:57:59.161422 20580 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1026 14:57:59.161427 20580 net.cpp:144] Memory required for data: 2508765184
I1026 14:57:59.161432 20580 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I1026 14:57:59.161451 20580 net.cpp:84] Creating Layer fire4/squeeze1x1
I1026 14:57:59.161459 20580 net.cpp:413] fire4/squeeze1x1 <- pool3
I1026 14:57:59.161469 20580 net.cpp:387] fire4/squeeze1x1 -> fire4/squeeze1x1
I1026 14:57:59.161870 20580 net.cpp:127] Setting up fire4/squeeze1x1
I1026 14:57:59.161883 20580 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1026 14:57:59.161888 20580 net.cpp:144] Memory required for data: 2521610240
I1026 14:57:59.161895 20580 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1026 14:57:59.161901 20580 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1026 14:57:59.161907 20580 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1026 14:57:59.161912 20580 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1026 14:57:59.161924 20580 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I1026 14:57:59.161932 20580 net.cpp:84] Creating Layer fire4/relu_squeeze1x1
I1026 14:57:59.161937 20580 net.cpp:413] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I1026 14:57:59.161943 20580 net.cpp:374] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I1026 14:57:59.162161 20580 net.cpp:127] Setting up fire4/relu_squeeze1x1
I1026 14:57:59.162174 20580 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1026 14:57:59.162179 20580 net.cpp:144] Memory required for data: 2534455296
I1026 14:57:59.162184 20580 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1026 14:57:59.162194 20580 net.cpp:84] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1026 14:57:59.162201 20580 net.cpp:413] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I1026 14:57:59.162209 20580 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1026 14:57:59.162220 20580 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1026 14:57:59.162271 20580 net.cpp:127] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1026 14:57:59.162281 20580 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1026 14:57:59.162286 20580 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1026 14:57:59.162291 20580 net.cpp:144] Memory required for data: 2560145408
I1026 14:57:59.162294 20580 layer_factory.hpp:77] Creating layer fire4/expand1x1
I1026 14:57:59.162312 20580 net.cpp:84] Creating Layer fire4/expand1x1
I1026 14:57:59.162318 20580 net.cpp:413] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1026 14:57:59.162328 20580 net.cpp:387] fire4/expand1x1 -> fire4/expand1x1
I1026 14:57:59.162672 20580 net.cpp:127] Setting up fire4/expand1x1
I1026 14:57:59.162683 20580 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1026 14:57:59.162686 20580 net.cpp:144] Memory required for data: 2611525632
I1026 14:57:59.162698 20580 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1026 14:57:59.162709 20580 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1026 14:57:59.162715 20580 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1026 14:57:59.162721 20580 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1026 14:57:59.162729 20580 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I1026 14:57:59.162750 20580 net.cpp:84] Creating Layer fire4/relu_expand1x1
I1026 14:57:59.162767 20580 net.cpp:413] fire4/relu_expand1x1 <- fire4/expand1x1
I1026 14:57:59.162775 20580 net.cpp:374] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I1026 14:57:59.164144 20580 net.cpp:127] Setting up fire4/relu_expand1x1
I1026 14:57:59.164163 20580 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1026 14:57:59.164170 20580 net.cpp:144] Memory required for data: 2662905856
I1026 14:57:59.164185 20580 layer_factory.hpp:77] Creating layer fire4/expand3x3
I1026 14:57:59.164199 20580 net.cpp:84] Creating Layer fire4/expand3x3
I1026 14:57:59.164206 20580 net.cpp:413] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1026 14:57:59.164217 20580 net.cpp:387] fire4/expand3x3 -> fire4/expand3x3
I1026 14:57:59.166210 20580 net.cpp:127] Setting up fire4/expand3x3
I1026 14:57:59.166230 20580 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1026 14:57:59.166235 20580 net.cpp:144] Memory required for data: 2714286080
I1026 14:57:59.166242 20580 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1026 14:57:59.166249 20580 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1026 14:57:59.166255 20580 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1026 14:57:59.166261 20580 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1026 14:57:59.166267 20580 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I1026 14:57:59.166275 20580 net.cpp:84] Creating Layer fire4/relu_expand3x3
I1026 14:57:59.166282 20580 net.cpp:413] fire4/relu_expand3x3 <- fire4/expand3x3
I1026 14:57:59.166291 20580 net.cpp:374] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I1026 14:57:59.166513 20580 net.cpp:127] Setting up fire4/relu_expand3x3
I1026 14:57:59.166527 20580 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1026 14:57:59.166533 20580 net.cpp:144] Memory required for data: 2765666304
I1026 14:57:59.166538 20580 layer_factory.hpp:77] Creating layer fire4/concat
I1026 14:57:59.166555 20580 net.cpp:84] Creating Layer fire4/concat
I1026 14:57:59.166564 20580 net.cpp:413] fire4/concat <- fire4/expand1x1
I1026 14:57:59.166570 20580 net.cpp:413] fire4/concat <- fire4/expand3x3
I1026 14:57:59.166579 20580 net.cpp:387] fire4/concat -> fire4/concat
I1026 14:57:59.166610 20580 net.cpp:127] Setting up fire4/concat
I1026 14:57:59.166618 20580 net.cpp:136] Top shape: 128 256 28 28 (25690112)
I1026 14:57:59.166623 20580 net.cpp:144] Memory required for data: 2868426752
I1026 14:57:59.166627 20580 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I1026 14:57:59.166657 20580 net.cpp:84] Creating Layer fire5/squeeze1x1
I1026 14:57:59.166666 20580 net.cpp:413] fire5/squeeze1x1 <- fire4/concat
I1026 14:57:59.166672 20580 net.cpp:387] fire5/squeeze1x1 -> fire5/squeeze1x1
I1026 14:57:59.167070 20580 net.cpp:127] Setting up fire5/squeeze1x1
I1026 14:57:59.167081 20580 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1026 14:57:59.167085 20580 net.cpp:144] Memory required for data: 2881271808
I1026 14:57:59.167093 20580 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1026 14:57:59.167099 20580 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1026 14:57:59.167104 20580 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1026 14:57:59.167109 20580 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1026 14:57:59.167114 20580 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I1026 14:57:59.167122 20580 net.cpp:84] Creating Layer fire5/relu_squeeze1x1
I1026 14:57:59.167127 20580 net.cpp:413] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I1026 14:57:59.167135 20580 net.cpp:374] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I1026 14:57:59.167358 20580 net.cpp:127] Setting up fire5/relu_squeeze1x1
I1026 14:57:59.167371 20580 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1026 14:57:59.167383 20580 net.cpp:144] Memory required for data: 2894116864
I1026 14:57:59.167402 20580 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1026 14:57:59.167412 20580 net.cpp:84] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1026 14:57:59.167420 20580 net.cpp:413] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I1026 14:57:59.167428 20580 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1026 14:57:59.167436 20580 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1026 14:57:59.167486 20580 net.cpp:127] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1026 14:57:59.167496 20580 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1026 14:57:59.167502 20580 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1026 14:57:59.167508 20580 net.cpp:144] Memory required for data: 2919806976
I1026 14:57:59.167513 20580 layer_factory.hpp:77] Creating layer fire5/expand1x1
I1026 14:57:59.167536 20580 net.cpp:84] Creating Layer fire5/expand1x1
I1026 14:57:59.167542 20580 net.cpp:413] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1026 14:57:59.167552 20580 net.cpp:387] fire5/expand1x1 -> fire5/expand1x1
I1026 14:57:59.167913 20580 net.cpp:127] Setting up fire5/expand1x1
I1026 14:57:59.167924 20580 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1026 14:57:59.167929 20580 net.cpp:144] Memory required for data: 2971187200
I1026 14:57:59.167937 20580 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1026 14:57:59.167943 20580 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1026 14:57:59.167948 20580 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1026 14:57:59.167953 20580 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1026 14:57:59.167958 20580 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I1026 14:57:59.167976 20580 net.cpp:84] Creating Layer fire5/relu_expand1x1
I1026 14:57:59.167981 20580 net.cpp:413] fire5/relu_expand1x1 <- fire5/expand1x1
I1026 14:57:59.167989 20580 net.cpp:374] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I1026 14:57:59.168203 20580 net.cpp:127] Setting up fire5/relu_expand1x1
I1026 14:57:59.168215 20580 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1026 14:57:59.168221 20580 net.cpp:144] Memory required for data: 3022567424
I1026 14:57:59.168226 20580 layer_factory.hpp:77] Creating layer fire5/expand3x3
I1026 14:57:59.168241 20580 net.cpp:84] Creating Layer fire5/expand3x3
I1026 14:57:59.168248 20580 net.cpp:413] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1026 14:57:59.168257 20580 net.cpp:387] fire5/expand3x3 -> fire5/expand3x3
I1026 14:57:59.168876 20580 net.cpp:127] Setting up fire5/expand3x3
I1026 14:57:59.168889 20580 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1026 14:57:59.168895 20580 net.cpp:144] Memory required for data: 3073947648
I1026 14:57:59.168902 20580 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1026 14:57:59.168908 20580 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1026 14:57:59.168915 20580 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1026 14:57:59.168920 20580 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1026 14:57:59.168926 20580 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I1026 14:57:59.168943 20580 net.cpp:84] Creating Layer fire5/relu_expand3x3
I1026 14:57:59.168951 20580 net.cpp:413] fire5/relu_expand3x3 <- fire5/expand3x3
I1026 14:57:59.168958 20580 net.cpp:374] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I1026 14:57:59.170189 20580 net.cpp:127] Setting up fire5/relu_expand3x3
I1026 14:57:59.170210 20580 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1026 14:57:59.170217 20580 net.cpp:144] Memory required for data: 3125327872
I1026 14:57:59.170228 20580 layer_factory.hpp:77] Creating layer fire5/concat
I1026 14:57:59.170251 20580 net.cpp:84] Creating Layer fire5/concat
I1026 14:57:59.170258 20580 net.cpp:413] fire5/concat <- fire5/expand1x1
I1026 14:57:59.170264 20580 net.cpp:413] fire5/concat <- fire5/expand3x3
I1026 14:57:59.170274 20580 net.cpp:387] fire5/concat -> fire5/concat
I1026 14:57:59.170315 20580 net.cpp:127] Setting up fire5/concat
I1026 14:57:59.170325 20580 net.cpp:136] Top shape: 128 256 28 28 (25690112)
I1026 14:57:59.170328 20580 net.cpp:144] Memory required for data: 3228088320
I1026 14:57:59.170343 20580 layer_factory.hpp:77] Creating layer pool5
I1026 14:57:59.170354 20580 net.cpp:84] Creating Layer pool5
I1026 14:57:59.170361 20580 net.cpp:413] pool5 <- fire5/concat
I1026 14:57:59.170368 20580 net.cpp:387] pool5 -> pool5
I1026 14:57:59.170419 20580 net.cpp:127] Setting up pool5
I1026 14:57:59.170430 20580 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1026 14:57:59.170435 20580 net.cpp:144] Memory required for data: 3253778432
I1026 14:57:59.170439 20580 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I1026 14:57:59.170464 20580 net.cpp:84] Creating Layer fire6/squeeze1x1
I1026 14:57:59.170471 20580 net.cpp:413] fire6/squeeze1x1 <- pool5
I1026 14:57:59.170481 20580 net.cpp:387] fire6/squeeze1x1 -> fire6/squeeze1x1
I1026 14:57:59.170977 20580 net.cpp:127] Setting up fire6/squeeze1x1
I1026 14:57:59.170989 20580 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1026 14:57:59.170994 20580 net.cpp:144] Memory required for data: 3258595328
I1026 14:57:59.171001 20580 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1026 14:57:59.171007 20580 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1026 14:57:59.171013 20580 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1026 14:57:59.171020 20580 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1026 14:57:59.171023 20580 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I1026 14:57:59.171033 20580 net.cpp:84] Creating Layer fire6/relu_squeeze1x1
I1026 14:57:59.171038 20580 net.cpp:413] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I1026 14:57:59.171046 20580 net.cpp:374] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I1026 14:57:59.171262 20580 net.cpp:127] Setting up fire6/relu_squeeze1x1
I1026 14:57:59.171274 20580 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1026 14:57:59.171280 20580 net.cpp:144] Memory required for data: 3263412224
I1026 14:57:59.171286 20580 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1026 14:57:59.171310 20580 net.cpp:84] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1026 14:57:59.171315 20580 net.cpp:413] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I1026 14:57:59.171324 20580 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1026 14:57:59.171334 20580 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1026 14:57:59.171422 20580 net.cpp:127] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1026 14:57:59.171432 20580 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1026 14:57:59.171439 20580 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1026 14:57:59.171444 20580 net.cpp:144] Memory required for data: 3273046016
I1026 14:57:59.171448 20580 layer_factory.hpp:77] Creating layer fire6/expand1x1
I1026 14:57:59.171468 20580 net.cpp:84] Creating Layer fire6/expand1x1
I1026 14:57:59.171473 20580 net.cpp:413] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1026 14:57:59.171483 20580 net.cpp:387] fire6/expand1x1 -> fire6/expand1x1
I1026 14:57:59.171878 20580 net.cpp:127] Setting up fire6/expand1x1
I1026 14:57:59.171891 20580 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1026 14:57:59.171896 20580 net.cpp:144] Memory required for data: 3292313600
I1026 14:57:59.171911 20580 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1026 14:57:59.171929 20580 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1026 14:57:59.171936 20580 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1026 14:57:59.171941 20580 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1026 14:57:59.171946 20580 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I1026 14:57:59.171952 20580 net.cpp:84] Creating Layer fire6/relu_expand1x1
I1026 14:57:59.171957 20580 net.cpp:413] fire6/relu_expand1x1 <- fire6/expand1x1
I1026 14:57:59.171963 20580 net.cpp:374] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I1026 14:57:59.172176 20580 net.cpp:127] Setting up fire6/relu_expand1x1
I1026 14:57:59.172190 20580 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1026 14:57:59.172195 20580 net.cpp:144] Memory required for data: 3311581184
I1026 14:57:59.172200 20580 layer_factory.hpp:77] Creating layer fire6/expand3x3
I1026 14:57:59.172209 20580 net.cpp:84] Creating Layer fire6/expand3x3
I1026 14:57:59.172215 20580 net.cpp:413] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1026 14:57:59.172224 20580 net.cpp:387] fire6/expand3x3 -> fire6/expand3x3
I1026 14:57:59.174597 20580 net.cpp:127] Setting up fire6/expand3x3
I1026 14:57:59.174618 20580 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1026 14:57:59.174623 20580 net.cpp:144] Memory required for data: 3330848768
I1026 14:57:59.174629 20580 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1026 14:57:59.174636 20580 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1026 14:57:59.174643 20580 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1026 14:57:59.174649 20580 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1026 14:57:59.174664 20580 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I1026 14:57:59.174682 20580 net.cpp:84] Creating Layer fire6/relu_expand3x3
I1026 14:57:59.174690 20580 net.cpp:413] fire6/relu_expand3x3 <- fire6/expand3x3
I1026 14:57:59.174696 20580 net.cpp:374] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I1026 14:57:59.174927 20580 net.cpp:127] Setting up fire6/relu_expand3x3
I1026 14:57:59.174939 20580 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1026 14:57:59.174944 20580 net.cpp:144] Memory required for data: 3350116352
I1026 14:57:59.174949 20580 layer_factory.hpp:77] Creating layer fire6/concat
I1026 14:57:59.174959 20580 net.cpp:84] Creating Layer fire6/concat
I1026 14:57:59.174965 20580 net.cpp:413] fire6/concat <- fire6/expand1x1
I1026 14:57:59.174971 20580 net.cpp:413] fire6/concat <- fire6/expand3x3
I1026 14:57:59.174978 20580 net.cpp:387] fire6/concat -> fire6/concat
I1026 14:57:59.175017 20580 net.cpp:127] Setting up fire6/concat
I1026 14:57:59.175026 20580 net.cpp:136] Top shape: 128 384 14 14 (9633792)
I1026 14:57:59.175031 20580 net.cpp:144] Memory required for data: 3388651520
I1026 14:57:59.175036 20580 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I1026 14:57:59.175047 20580 net.cpp:84] Creating Layer fire7/squeeze1x1
I1026 14:57:59.175052 20580 net.cpp:413] fire7/squeeze1x1 <- fire6/concat
I1026 14:57:59.175061 20580 net.cpp:387] fire7/squeeze1x1 -> fire7/squeeze1x1
I1026 14:57:59.175545 20580 net.cpp:127] Setting up fire7/squeeze1x1
I1026 14:57:59.175557 20580 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1026 14:57:59.175562 20580 net.cpp:144] Memory required for data: 3393468416
I1026 14:57:59.175578 20580 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1026 14:57:59.175590 20580 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1026 14:57:59.175595 20580 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1026 14:57:59.175602 20580 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1026 14:57:59.175613 20580 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I1026 14:57:59.175644 20580 net.cpp:84] Creating Layer fire7/relu_squeeze1x1
I1026 14:57:59.175652 20580 net.cpp:413] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I1026 14:57:59.175660 20580 net.cpp:374] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I1026 14:57:59.177049 20580 net.cpp:127] Setting up fire7/relu_squeeze1x1
I1026 14:57:59.177068 20580 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1026 14:57:59.177073 20580 net.cpp:144] Memory required for data: 3398285312
I1026 14:57:59.177093 20580 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1026 14:57:59.177104 20580 net.cpp:84] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1026 14:57:59.177109 20580 net.cpp:413] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I1026 14:57:59.177119 20580 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1026 14:57:59.177129 20580 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1026 14:57:59.177181 20580 net.cpp:127] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1026 14:57:59.177192 20580 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1026 14:57:59.177198 20580 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1026 14:57:59.177203 20580 net.cpp:144] Memory required for data: 3407919104
I1026 14:57:59.177207 20580 layer_factory.hpp:77] Creating layer fire7/expand1x1
I1026 14:57:59.177217 20580 net.cpp:84] Creating Layer fire7/expand1x1
I1026 14:57:59.177222 20580 net.cpp:413] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1026 14:57:59.177232 20580 net.cpp:387] fire7/expand1x1 -> fire7/expand1x1
I1026 14:57:59.177646 20580 net.cpp:127] Setting up fire7/expand1x1
I1026 14:57:59.177659 20580 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1026 14:57:59.177664 20580 net.cpp:144] Memory required for data: 3427186688
I1026 14:57:59.177670 20580 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1026 14:57:59.177677 20580 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1026 14:57:59.177682 20580 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1026 14:57:59.177688 20580 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1026 14:57:59.177693 20580 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I1026 14:57:59.177702 20580 net.cpp:84] Creating Layer fire7/relu_expand1x1
I1026 14:57:59.177708 20580 net.cpp:413] fire7/relu_expand1x1 <- fire7/expand1x1
I1026 14:57:59.177716 20580 net.cpp:374] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I1026 14:57:59.177927 20580 net.cpp:127] Setting up fire7/relu_expand1x1
I1026 14:57:59.177939 20580 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1026 14:57:59.177944 20580 net.cpp:144] Memory required for data: 3446454272
I1026 14:57:59.177958 20580 layer_factory.hpp:77] Creating layer fire7/expand3x3
I1026 14:57:59.177978 20580 net.cpp:84] Creating Layer fire7/expand3x3
I1026 14:57:59.177983 20580 net.cpp:413] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1026 14:57:59.177994 20580 net.cpp:387] fire7/expand3x3 -> fire7/expand3x3
I1026 14:57:59.178994 20580 net.cpp:127] Setting up fire7/expand3x3
I1026 14:57:59.179008 20580 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1026 14:57:59.179013 20580 net.cpp:144] Memory required for data: 3465721856
I1026 14:57:59.179019 20580 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1026 14:57:59.179026 20580 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1026 14:57:59.179031 20580 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1026 14:57:59.179038 20580 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1026 14:57:59.179042 20580 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I1026 14:57:59.179055 20580 net.cpp:84] Creating Layer fire7/relu_expand3x3
I1026 14:57:59.179074 20580 net.cpp:413] fire7/relu_expand3x3 <- fire7/expand3x3
I1026 14:57:59.179082 20580 net.cpp:374] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I1026 14:57:59.179293 20580 net.cpp:127] Setting up fire7/relu_expand3x3
I1026 14:57:59.179312 20580 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1026 14:57:59.179319 20580 net.cpp:144] Memory required for data: 3484989440
I1026 14:57:59.179324 20580 layer_factory.hpp:77] Creating layer fire7/concat
I1026 14:57:59.179334 20580 net.cpp:84] Creating Layer fire7/concat
I1026 14:57:59.179339 20580 net.cpp:413] fire7/concat <- fire7/expand1x1
I1026 14:57:59.179345 20580 net.cpp:413] fire7/concat <- fire7/expand3x3
I1026 14:57:59.179352 20580 net.cpp:387] fire7/concat -> fire7/concat
I1026 14:57:59.179383 20580 net.cpp:127] Setting up fire7/concat
I1026 14:57:59.179391 20580 net.cpp:136] Top shape: 128 384 14 14 (9633792)
I1026 14:57:59.179395 20580 net.cpp:144] Memory required for data: 3523524608
I1026 14:57:59.179400 20580 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I1026 14:57:59.179425 20580 net.cpp:84] Creating Layer fire8/squeeze1x1
I1026 14:57:59.179430 20580 net.cpp:413] fire8/squeeze1x1 <- fire7/concat
I1026 14:57:59.179437 20580 net.cpp:387] fire8/squeeze1x1 -> fire8/squeeze1x1
I1026 14:57:59.179960 20580 net.cpp:127] Setting up fire8/squeeze1x1
I1026 14:57:59.179971 20580 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1026 14:57:59.179976 20580 net.cpp:144] Memory required for data: 3529947136
I1026 14:57:59.179982 20580 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1026 14:57:59.179989 20580 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1026 14:57:59.179994 20580 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1026 14:57:59.179999 20580 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1026 14:57:59.180013 20580 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I1026 14:57:59.180022 20580 net.cpp:84] Creating Layer fire8/relu_squeeze1x1
I1026 14:57:59.180028 20580 net.cpp:413] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I1026 14:57:59.180034 20580 net.cpp:374] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I1026 14:57:59.181447 20580 net.cpp:127] Setting up fire8/relu_squeeze1x1
I1026 14:57:59.181468 20580 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1026 14:57:59.181473 20580 net.cpp:144] Memory required for data: 3536369664
I1026 14:57:59.181479 20580 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1026 14:57:59.181486 20580 net.cpp:84] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1026 14:57:59.181493 20580 net.cpp:413] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I1026 14:57:59.181501 20580 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1026 14:57:59.181510 20580 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1026 14:57:59.181565 20580 net.cpp:127] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1026 14:57:59.181573 20580 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1026 14:57:59.181579 20580 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1026 14:57:59.181583 20580 net.cpp:144] Memory required for data: 3549214720
I1026 14:57:59.181588 20580 layer_factory.hpp:77] Creating layer fire8/expand1x1
I1026 14:57:59.181609 20580 net.cpp:84] Creating Layer fire8/expand1x1
I1026 14:57:59.181617 20580 net.cpp:413] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1026 14:57:59.181627 20580 net.cpp:387] fire8/expand1x1 -> fire8/expand1x1
I1026 14:57:59.182091 20580 net.cpp:127] Setting up fire8/expand1x1
I1026 14:57:59.182102 20580 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1026 14:57:59.182107 20580 net.cpp:144] Memory required for data: 3574904832
I1026 14:57:59.182121 20580 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1026 14:57:59.182142 20580 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1026 14:57:59.182147 20580 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1026 14:57:59.182152 20580 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1026 14:57:59.182165 20580 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I1026 14:57:59.182175 20580 net.cpp:84] Creating Layer fire8/relu_expand1x1
I1026 14:57:59.182180 20580 net.cpp:413] fire8/relu_expand1x1 <- fire8/expand1x1
I1026 14:57:59.182188 20580 net.cpp:374] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I1026 14:57:59.182405 20580 net.cpp:127] Setting up fire8/relu_expand1x1
I1026 14:57:59.182418 20580 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1026 14:57:59.182425 20580 net.cpp:144] Memory required for data: 3600594944
I1026 14:57:59.182430 20580 layer_factory.hpp:77] Creating layer fire8/expand3x3
I1026 14:57:59.182440 20580 net.cpp:84] Creating Layer fire8/expand3x3
I1026 14:57:59.182446 20580 net.cpp:413] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1026 14:57:59.182456 20580 net.cpp:387] fire8/expand3x3 -> fire8/expand3x3
I1026 14:57:59.185322 20580 net.cpp:127] Setting up fire8/expand3x3
I1026 14:57:59.185341 20580 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1026 14:57:59.185346 20580 net.cpp:144] Memory required for data: 3626285056
I1026 14:57:59.185353 20580 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1026 14:57:59.185360 20580 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1026 14:57:59.185366 20580 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1026 14:57:59.185371 20580 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1026 14:57:59.185376 20580 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I1026 14:57:59.185395 20580 net.cpp:84] Creating Layer fire8/relu_expand3x3
I1026 14:57:59.185400 20580 net.cpp:413] fire8/relu_expand3x3 <- fire8/expand3x3
I1026 14:57:59.185407 20580 net.cpp:374] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I1026 14:57:59.185647 20580 net.cpp:127] Setting up fire8/relu_expand3x3
I1026 14:57:59.185659 20580 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1026 14:57:59.185665 20580 net.cpp:144] Memory required for data: 3651975168
I1026 14:57:59.185670 20580 layer_factory.hpp:77] Creating layer fire8/concat
I1026 14:57:59.185678 20580 net.cpp:84] Creating Layer fire8/concat
I1026 14:57:59.185683 20580 net.cpp:413] fire8/concat <- fire8/expand1x1
I1026 14:57:59.185689 20580 net.cpp:413] fire8/concat <- fire8/expand3x3
I1026 14:57:59.185698 20580 net.cpp:387] fire8/concat -> fire8/concat
I1026 14:57:59.185732 20580 net.cpp:127] Setting up fire8/concat
I1026 14:57:59.185742 20580 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1026 14:57:59.185747 20580 net.cpp:144] Memory required for data: 3703355392
I1026 14:57:59.185760 20580 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I1026 14:57:59.185770 20580 net.cpp:84] Creating Layer fire9/squeeze1x1
I1026 14:57:59.185775 20580 net.cpp:413] fire9/squeeze1x1 <- fire8/concat
I1026 14:57:59.185786 20580 net.cpp:387] fire9/squeeze1x1 -> fire9/squeeze1x1
I1026 14:57:59.186379 20580 net.cpp:127] Setting up fire9/squeeze1x1
I1026 14:57:59.186393 20580 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1026 14:57:59.186398 20580 net.cpp:144] Memory required for data: 3709777920
I1026 14:57:59.186404 20580 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1026 14:57:59.186410 20580 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1026 14:57:59.186416 20580 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1026 14:57:59.186422 20580 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1026 14:57:59.186436 20580 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I1026 14:57:59.186470 20580 net.cpp:84] Creating Layer fire9/relu_squeeze1x1
I1026 14:57:59.186478 20580 net.cpp:413] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I1026 14:57:59.186486 20580 net.cpp:374] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I1026 14:57:59.186702 20580 net.cpp:127] Setting up fire9/relu_squeeze1x1
I1026 14:57:59.186713 20580 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1026 14:57:59.186718 20580 net.cpp:144] Memory required for data: 3716200448
I1026 14:57:59.186724 20580 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1026 14:57:59.186738 20580 net.cpp:84] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1026 14:57:59.186743 20580 net.cpp:413] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I1026 14:57:59.186753 20580 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1026 14:57:59.186763 20580 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1026 14:57:59.186810 20580 net.cpp:127] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1026 14:57:59.186820 20580 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1026 14:57:59.186826 20580 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1026 14:57:59.186830 20580 net.cpp:144] Memory required for data: 3729045504
I1026 14:57:59.186836 20580 layer_factory.hpp:77] Creating layer fire9/expand1x1
I1026 14:57:59.186847 20580 net.cpp:84] Creating Layer fire9/expand1x1
I1026 14:57:59.186853 20580 net.cpp:413] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1026 14:57:59.186861 20580 net.cpp:387] fire9/expand1x1 -> fire9/expand1x1
I1026 14:57:59.187332 20580 net.cpp:127] Setting up fire9/expand1x1
I1026 14:57:59.187345 20580 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1026 14:57:59.187350 20580 net.cpp:144] Memory required for data: 3754735616
I1026 14:57:59.187356 20580 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1026 14:57:59.187363 20580 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1026 14:57:59.187368 20580 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1026 14:57:59.187373 20580 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1026 14:57:59.187378 20580 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I1026 14:57:59.187386 20580 net.cpp:84] Creating Layer fire9/relu_expand1x1
I1026 14:57:59.187392 20580 net.cpp:413] fire9/relu_expand1x1 <- fire9/expand1x1
I1026 14:57:59.187398 20580 net.cpp:374] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I1026 14:57:59.188791 20580 net.cpp:127] Setting up fire9/relu_expand1x1
I1026 14:57:59.188812 20580 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1026 14:57:59.188817 20580 net.cpp:144] Memory required for data: 3780425728
I1026 14:57:59.188822 20580 layer_factory.hpp:77] Creating layer fire9/expand3x3
I1026 14:57:59.188845 20580 net.cpp:84] Creating Layer fire9/expand3x3
I1026 14:57:59.188853 20580 net.cpp:413] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1026 14:57:59.188860 20580 net.cpp:387] fire9/expand3x3 -> fire9/expand3x3
I1026 14:57:59.190366 20580 net.cpp:127] Setting up fire9/expand3x3
I1026 14:57:59.190381 20580 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1026 14:57:59.190384 20580 net.cpp:144] Memory required for data: 3806115840
I1026 14:57:59.190392 20580 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1026 14:57:59.190398 20580 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1026 14:57:59.190404 20580 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1026 14:57:59.190410 20580 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1026 14:57:59.190415 20580 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I1026 14:57:59.190438 20580 net.cpp:84] Creating Layer fire9/relu_expand3x3
I1026 14:57:59.190454 20580 net.cpp:413] fire9/relu_expand3x3 <- fire9/expand3x3
I1026 14:57:59.190464 20580 net.cpp:374] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I1026 14:57:59.190680 20580 net.cpp:127] Setting up fire9/relu_expand3x3
I1026 14:57:59.190691 20580 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1026 14:57:59.190696 20580 net.cpp:144] Memory required for data: 3831805952
I1026 14:57:59.190701 20580 layer_factory.hpp:77] Creating layer fire9/concat
I1026 14:57:59.190709 20580 net.cpp:84] Creating Layer fire9/concat
I1026 14:57:59.190714 20580 net.cpp:413] fire9/concat <- fire9/expand1x1
I1026 14:57:59.190721 20580 net.cpp:413] fire9/concat <- fire9/expand3x3
I1026 14:57:59.190729 20580 net.cpp:387] fire9/concat -> fire9/concat
I1026 14:57:59.190763 20580 net.cpp:127] Setting up fire9/concat
I1026 14:57:59.190771 20580 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1026 14:57:59.190775 20580 net.cpp:144] Memory required for data: 3883186176
I1026 14:57:59.190780 20580 layer_factory.hpp:77] Creating layer drop9
I1026 14:57:59.190801 20580 net.cpp:84] Creating Layer drop9
I1026 14:57:59.190807 20580 net.cpp:413] drop9 <- fire9/concat
I1026 14:57:59.190814 20580 net.cpp:374] drop9 -> fire9/concat (in-place)
I1026 14:57:59.190850 20580 net.cpp:127] Setting up drop9
I1026 14:57:59.190860 20580 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1026 14:57:59.190865 20580 net.cpp:144] Memory required for data: 3934566400
I1026 14:57:59.190870 20580 layer_factory.hpp:77] Creating layer conv10
I1026 14:57:59.190881 20580 net.cpp:84] Creating Layer conv10
I1026 14:57:59.190887 20580 net.cpp:413] conv10 <- fire9/concat
I1026 14:57:59.190897 20580 net.cpp:387] conv10 -> conv10
I1026 14:57:59.200469 20580 net.cpp:127] Setting up conv10
I1026 14:57:59.200489 20580 net.cpp:136] Top shape: 128 1000 14 14 (25088000)
I1026 14:57:59.200495 20580 net.cpp:144] Memory required for data: 4034918400
I1026 14:57:59.200502 20580 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1026 14:57:59.200510 20580 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1026 14:57:59.200515 20580 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1026 14:57:59.200522 20580 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1026 14:57:59.200527 20580 layer_factory.hpp:77] Creating layer relu_conv10
I1026 14:57:59.200537 20580 net.cpp:84] Creating Layer relu_conv10
I1026 14:57:59.200543 20580 net.cpp:413] relu_conv10 <- conv10
I1026 14:57:59.200558 20580 net.cpp:374] relu_conv10 -> conv10 (in-place)
I1026 14:57:59.200788 20580 net.cpp:127] Setting up relu_conv10
I1026 14:57:59.200804 20580 net.cpp:136] Top shape: 128 1000 14 14 (25088000)
I1026 14:57:59.200809 20580 net.cpp:144] Memory required for data: 4135270400
I1026 14:57:59.200815 20580 layer_factory.hpp:77] Creating layer pool10
I1026 14:57:59.200841 20580 net.cpp:84] Creating Layer pool10
I1026 14:57:59.200847 20580 net.cpp:413] pool10 <- conv10
I1026 14:57:59.200855 20580 net.cpp:387] pool10 -> pool10
I1026 14:57:59.201100 20580 net.cpp:127] Setting up pool10
I1026 14:57:59.201113 20580 net.cpp:136] Top shape: 128 1000 1 1 (128000)
I1026 14:57:59.201118 20580 net.cpp:144] Memory required for data: 4135782400
I1026 14:57:59.201123 20580 layer_factory.hpp:77] Creating layer loss
I1026 14:57:59.201136 20580 net.cpp:84] Creating Layer loss
I1026 14:57:59.201141 20580 net.cpp:413] loss <- pool10
I1026 14:57:59.201148 20580 net.cpp:413] loss <- label
I1026 14:57:59.201158 20580 net.cpp:387] loss -> loss
I1026 14:57:59.201172 20580 layer_factory.hpp:77] Creating layer loss
I1026 14:57:59.204128 20580 net.cpp:127] Setting up loss
I1026 14:57:59.204147 20580 net.cpp:136] Top shape: (1)
I1026 14:57:59.204154 20580 net.cpp:139]     with loss weight 1
I1026 14:57:59.204182 20580 net.cpp:144] Memory required for data: 4135782404
I1026 14:57:59.204187 20580 net.cpp:205] loss needs backward computation.
I1026 14:57:59.204200 20580 net.cpp:205] pool10 needs backward computation.
I1026 14:57:59.204216 20580 net.cpp:205] relu_conv10 needs backward computation.
I1026 14:57:59.204221 20580 net.cpp:205] conv10 needs backward computation.
I1026 14:57:59.204226 20580 net.cpp:205] drop9 needs backward computation.
I1026 14:57:59.204231 20580 net.cpp:205] fire9/concat needs backward computation.
I1026 14:57:59.204236 20580 net.cpp:205] fire9/relu_expand3x3 needs backward computation.
I1026 14:57:59.204241 20580 net.cpp:205] fire9/expand3x3 needs backward computation.
I1026 14:57:59.204246 20580 net.cpp:205] fire9/relu_expand1x1 needs backward computation.
I1026 14:57:59.204249 20580 net.cpp:205] fire9/expand1x1 needs backward computation.
I1026 14:57:59.204254 20580 net.cpp:205] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I1026 14:57:59.204259 20580 net.cpp:205] fire9/relu_squeeze1x1 needs backward computation.
I1026 14:57:59.204263 20580 net.cpp:205] fire9/squeeze1x1 needs backward computation.
I1026 14:57:59.204268 20580 net.cpp:205] fire8/concat needs backward computation.
I1026 14:57:59.204273 20580 net.cpp:205] fire8/relu_expand3x3 needs backward computation.
I1026 14:57:59.204277 20580 net.cpp:205] fire8/expand3x3 needs backward computation.
I1026 14:57:59.204282 20580 net.cpp:205] fire8/relu_expand1x1 needs backward computation.
I1026 14:57:59.204286 20580 net.cpp:205] fire8/expand1x1 needs backward computation.
I1026 14:57:59.204291 20580 net.cpp:205] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I1026 14:57:59.204300 20580 net.cpp:205] fire8/relu_squeeze1x1 needs backward computation.
I1026 14:57:59.204306 20580 net.cpp:205] fire8/squeeze1x1 needs backward computation.
I1026 14:57:59.204310 20580 net.cpp:205] fire7/concat needs backward computation.
I1026 14:57:59.204316 20580 net.cpp:205] fire7/relu_expand3x3 needs backward computation.
I1026 14:57:59.204320 20580 net.cpp:205] fire7/expand3x3 needs backward computation.
I1026 14:57:59.204324 20580 net.cpp:205] fire7/relu_expand1x1 needs backward computation.
I1026 14:57:59.204329 20580 net.cpp:205] fire7/expand1x1 needs backward computation.
I1026 14:57:59.204334 20580 net.cpp:205] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I1026 14:57:59.204339 20580 net.cpp:205] fire7/relu_squeeze1x1 needs backward computation.
I1026 14:57:59.204342 20580 net.cpp:205] fire7/squeeze1x1 needs backward computation.
I1026 14:57:59.204347 20580 net.cpp:205] fire6/concat needs backward computation.
I1026 14:57:59.204351 20580 net.cpp:205] fire6/relu_expand3x3 needs backward computation.
I1026 14:57:59.204356 20580 net.cpp:205] fire6/expand3x3 needs backward computation.
I1026 14:57:59.204360 20580 net.cpp:205] fire6/relu_expand1x1 needs backward computation.
I1026 14:57:59.204365 20580 net.cpp:205] fire6/expand1x1 needs backward computation.
I1026 14:57:59.204370 20580 net.cpp:205] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I1026 14:57:59.204373 20580 net.cpp:205] fire6/relu_squeeze1x1 needs backward computation.
I1026 14:57:59.204378 20580 net.cpp:205] fire6/squeeze1x1 needs backward computation.
I1026 14:57:59.204382 20580 net.cpp:205] pool5 needs backward computation.
I1026 14:57:59.204387 20580 net.cpp:205] fire5/concat needs backward computation.
I1026 14:57:59.204391 20580 net.cpp:205] fire5/relu_expand3x3 needs backward computation.
I1026 14:57:59.204396 20580 net.cpp:205] fire5/expand3x3 needs backward computation.
I1026 14:57:59.204401 20580 net.cpp:205] fire5/relu_expand1x1 needs backward computation.
I1026 14:57:59.204406 20580 net.cpp:205] fire5/expand1x1 needs backward computation.
I1026 14:57:59.204409 20580 net.cpp:205] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I1026 14:57:59.204416 20580 net.cpp:205] fire5/relu_squeeze1x1 needs backward computation.
I1026 14:57:59.204421 20580 net.cpp:205] fire5/squeeze1x1 needs backward computation.
I1026 14:57:59.204426 20580 net.cpp:205] fire4/concat needs backward computation.
I1026 14:57:59.204435 20580 net.cpp:205] fire4/relu_expand3x3 needs backward computation.
I1026 14:57:59.204447 20580 net.cpp:205] fire4/expand3x3 needs backward computation.
I1026 14:57:59.204452 20580 net.cpp:205] fire4/relu_expand1x1 needs backward computation.
I1026 14:57:59.204455 20580 net.cpp:205] fire4/expand1x1 needs backward computation.
I1026 14:57:59.204460 20580 net.cpp:205] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I1026 14:57:59.204464 20580 net.cpp:205] fire4/relu_squeeze1x1 needs backward computation.
I1026 14:57:59.204468 20580 net.cpp:205] fire4/squeeze1x1 needs backward computation.
I1026 14:57:59.204473 20580 net.cpp:205] pool3 needs backward computation.
I1026 14:57:59.204478 20580 net.cpp:205] fire3/concat needs backward computation.
I1026 14:57:59.204483 20580 net.cpp:205] fire3/relu_expand3x3 needs backward computation.
I1026 14:57:59.204488 20580 net.cpp:205] fire3/expand3x3 needs backward computation.
I1026 14:57:59.204491 20580 net.cpp:205] fire3/relu_expand1x1 needs backward computation.
I1026 14:57:59.204495 20580 net.cpp:205] fire3/expand1x1 needs backward computation.
I1026 14:57:59.204500 20580 net.cpp:205] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I1026 14:57:59.204505 20580 net.cpp:205] fire3/relu_squeeze1x1 needs backward computation.
I1026 14:57:59.204509 20580 net.cpp:205] fire3/squeeze1x1 needs backward computation.
I1026 14:57:59.204514 20580 net.cpp:205] fire2/concat needs backward computation.
I1026 14:57:59.204519 20580 net.cpp:205] fire2/relu_expand3x3 needs backward computation.
I1026 14:57:59.204524 20580 net.cpp:205] fire2/expand3x3 needs backward computation.
I1026 14:57:59.204527 20580 net.cpp:205] fire2/relu_expand1x1 needs backward computation.
I1026 14:57:59.204532 20580 net.cpp:205] fire2/expand1x1 needs backward computation.
I1026 14:57:59.204536 20580 net.cpp:205] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I1026 14:57:59.204540 20580 net.cpp:205] fire2/relu_squeeze1x1 needs backward computation.
I1026 14:57:59.204545 20580 net.cpp:205] fire2/squeeze1x1 needs backward computation.
I1026 14:57:59.204550 20580 net.cpp:205] pool1 needs backward computation.
I1026 14:57:59.204555 20580 net.cpp:205] relu_conv1 needs backward computation.
I1026 14:57:59.204560 20580 net.cpp:205] conv1 needs backward computation.
I1026 14:57:59.204566 20580 net.cpp:207] data does not need backward computation.
I1026 14:57:59.204571 20580 net.cpp:249] This network produces output loss
I1026 14:57:59.204629 20580 net.cpp:262] Network initialization done.
I1026 14:57:59.206657 20580 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_10.prototxt
I1026 14:57:59.206768 20580 net.cpp:301] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1026 14:57:59.207510 20580 net.cpp:51] Initializing net from parameters: 
name: "SqueezeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/data/caffe-imagenet/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "INQConvolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "fire3/concat"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire4/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool3"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "fire5/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire4/concat"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "fire5/concat"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire6/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool5"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "fire9/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire8/concat"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "INQConvolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.1
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "pool10"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy_top1"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy_top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy_top5"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy_top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I1026 14:57:59.207908 20580 layer_factory.hpp:77] Creating layer data
I1026 14:57:59.207988 20580 db_lmdb.cpp:35] Opened lmdb /home/data/caffe-imagenet/ilsvrc12_val_lmdb
I1026 14:57:59.208009 20580 net.cpp:84] Creating Layer data
I1026 14:57:59.208019 20580 net.cpp:387] data -> data
I1026 14:57:59.208030 20580 net.cpp:387] data -> label
I1026 14:57:59.208467 20580 data_layer.cpp:45] output data size: 50,3,227,227
I1026 14:57:59.294282 20580 net.cpp:127] Setting up data
I1026 14:57:59.294337 20580 net.cpp:136] Top shape: 50 3 227 227 (7729350)
I1026 14:57:59.294374 20580 net.cpp:136] Top shape: 50 (50)
I1026 14:57:59.294380 20580 net.cpp:144] Memory required for data: 30917600
I1026 14:57:59.294389 20580 layer_factory.hpp:77] Creating layer label_data_1_split
I1026 14:57:59.294410 20580 net.cpp:84] Creating Layer label_data_1_split
I1026 14:57:59.294416 20580 net.cpp:413] label_data_1_split <- label
I1026 14:57:59.294427 20580 net.cpp:387] label_data_1_split -> label_data_1_split_0
I1026 14:57:59.294442 20580 net.cpp:387] label_data_1_split -> label_data_1_split_1
I1026 14:57:59.294450 20580 net.cpp:387] label_data_1_split -> label_data_1_split_2
I1026 14:57:59.294548 20580 net.cpp:127] Setting up label_data_1_split
I1026 14:57:59.294559 20580 net.cpp:136] Top shape: 50 (50)
I1026 14:57:59.294565 20580 net.cpp:136] Top shape: 50 (50)
I1026 14:57:59.294571 20580 net.cpp:136] Top shape: 50 (50)
I1026 14:57:59.294575 20580 net.cpp:144] Memory required for data: 30918200
I1026 14:57:59.294580 20580 layer_factory.hpp:77] Creating layer conv1
I1026 14:57:59.294598 20580 net.cpp:84] Creating Layer conv1
I1026 14:57:59.294605 20580 net.cpp:413] conv1 <- data
I1026 14:57:59.294613 20580 net.cpp:387] conv1 -> conv1
I1026 14:57:59.295039 20580 net.cpp:127] Setting up conv1
I1026 14:57:59.295050 20580 net.cpp:136] Top shape: 50 64 113 113 (40860800)
I1026 14:57:59.295055 20580 net.cpp:144] Memory required for data: 194361400
I1026 14:57:59.295065 20580 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1026 14:57:59.295075 20580 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1026 14:57:59.295084 20580 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1026 14:57:59.295092 20580 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1026 14:57:59.295099 20580 layer_factory.hpp:77] Creating layer relu_conv1
I1026 14:57:59.295109 20580 net.cpp:84] Creating Layer relu_conv1
I1026 14:57:59.295114 20580 net.cpp:413] relu_conv1 <- conv1
I1026 14:57:59.295122 20580 net.cpp:374] relu_conv1 -> conv1 (in-place)
I1026 14:57:59.295397 20580 net.cpp:127] Setting up relu_conv1
I1026 14:57:59.295410 20580 net.cpp:136] Top shape: 50 64 113 113 (40860800)
I1026 14:57:59.295415 20580 net.cpp:144] Memory required for data: 357804600
I1026 14:57:59.295423 20580 layer_factory.hpp:77] Creating layer pool1
I1026 14:57:59.295434 20580 net.cpp:84] Creating Layer pool1
I1026 14:57:59.295439 20580 net.cpp:413] pool1 <- conv1
I1026 14:57:59.295447 20580 net.cpp:387] pool1 -> pool1
I1026 14:57:59.295508 20580 net.cpp:127] Setting up pool1
I1026 14:57:59.295518 20580 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1026 14:57:59.295523 20580 net.cpp:144] Memory required for data: 397945400
I1026 14:57:59.295528 20580 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I1026 14:57:59.295541 20580 net.cpp:84] Creating Layer fire2/squeeze1x1
I1026 14:57:59.295545 20580 net.cpp:413] fire2/squeeze1x1 <- pool1
I1026 14:57:59.295553 20580 net.cpp:387] fire2/squeeze1x1 -> fire2/squeeze1x1
I1026 14:57:59.295946 20580 net.cpp:127] Setting up fire2/squeeze1x1
I1026 14:57:59.295958 20580 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1026 14:57:59.295963 20580 net.cpp:144] Memory required for data: 407980600
I1026 14:57:59.295970 20580 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1026 14:57:59.295979 20580 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1026 14:57:59.295986 20580 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1026 14:57:59.295992 20580 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1026 14:57:59.295999 20580 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I1026 14:57:59.296007 20580 net.cpp:84] Creating Layer fire2/relu_squeeze1x1
I1026 14:57:59.296012 20580 net.cpp:413] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I1026 14:57:59.296020 20580 net.cpp:374] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I1026 14:57:59.298630 20580 net.cpp:127] Setting up fire2/relu_squeeze1x1
I1026 14:57:59.298645 20580 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1026 14:57:59.298650 20580 net.cpp:144] Memory required for data: 418015800
I1026 14:57:59.298655 20580 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1026 14:57:59.298663 20580 net.cpp:84] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1026 14:57:59.298668 20580 net.cpp:413] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I1026 14:57:59.298676 20580 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1026 14:57:59.298687 20580 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1026 14:57:59.298738 20580 net.cpp:127] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1026 14:57:59.298746 20580 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1026 14:57:59.298753 20580 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1026 14:57:59.298758 20580 net.cpp:144] Memory required for data: 438086200
I1026 14:57:59.298763 20580 layer_factory.hpp:77] Creating layer fire2/expand1x1
I1026 14:57:59.298774 20580 net.cpp:84] Creating Layer fire2/expand1x1
I1026 14:57:59.298784 20580 net.cpp:413] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1026 14:57:59.298792 20580 net.cpp:387] fire2/expand1x1 -> fire2/expand1x1
I1026 14:57:59.299154 20580 net.cpp:127] Setting up fire2/expand1x1
I1026 14:57:59.299163 20580 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1026 14:57:59.299170 20580 net.cpp:144] Memory required for data: 478227000
I1026 14:57:59.299177 20580 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1026 14:57:59.299186 20580 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1026 14:57:59.299193 20580 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1026 14:57:59.299199 20580 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1026 14:57:59.299204 20580 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I1026 14:57:59.299212 20580 net.cpp:84] Creating Layer fire2/relu_expand1x1
I1026 14:57:59.299217 20580 net.cpp:413] fire2/relu_expand1x1 <- fire2/expand1x1
I1026 14:57:59.299224 20580 net.cpp:374] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I1026 14:57:59.300652 20580 net.cpp:127] Setting up fire2/relu_expand1x1
I1026 14:57:59.300671 20580 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1026 14:57:59.300678 20580 net.cpp:144] Memory required for data: 518367800
I1026 14:57:59.300683 20580 layer_factory.hpp:77] Creating layer fire2/expand3x3
I1026 14:57:59.300694 20580 net.cpp:84] Creating Layer fire2/expand3x3
I1026 14:57:59.300701 20580 net.cpp:413] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1026 14:57:59.300712 20580 net.cpp:387] fire2/expand3x3 -> fire2/expand3x3
I1026 14:57:59.301161 20580 net.cpp:127] Setting up fire2/expand3x3
I1026 14:57:59.301172 20580 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1026 14:57:59.301177 20580 net.cpp:144] Memory required for data: 558508600
I1026 14:57:59.301183 20580 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1026 14:57:59.301189 20580 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1026 14:57:59.301195 20580 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1026 14:57:59.301200 20580 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1026 14:57:59.301205 20580 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I1026 14:57:59.301213 20580 net.cpp:84] Creating Layer fire2/relu_expand3x3
I1026 14:57:59.301218 20580 net.cpp:413] fire2/relu_expand3x3 <- fire2/expand3x3
I1026 14:57:59.301226 20580 net.cpp:374] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I1026 14:57:59.301460 20580 net.cpp:127] Setting up fire2/relu_expand3x3
I1026 14:57:59.301475 20580 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1026 14:57:59.301491 20580 net.cpp:144] Memory required for data: 598649400
I1026 14:57:59.301497 20580 layer_factory.hpp:77] Creating layer fire2/concat
I1026 14:57:59.301506 20580 net.cpp:84] Creating Layer fire2/concat
I1026 14:57:59.301512 20580 net.cpp:413] fire2/concat <- fire2/expand1x1
I1026 14:57:59.301517 20580 net.cpp:413] fire2/concat <- fire2/expand3x3
I1026 14:57:59.301524 20580 net.cpp:387] fire2/concat -> fire2/concat
I1026 14:57:59.301563 20580 net.cpp:127] Setting up fire2/concat
I1026 14:57:59.301574 20580 net.cpp:136] Top shape: 50 128 56 56 (20070400)
I1026 14:57:59.301579 20580 net.cpp:144] Memory required for data: 678931000
I1026 14:57:59.301584 20580 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I1026 14:57:59.301595 20580 net.cpp:84] Creating Layer fire3/squeeze1x1
I1026 14:57:59.301601 20580 net.cpp:413] fire3/squeeze1x1 <- fire2/concat
I1026 14:57:59.301610 20580 net.cpp:387] fire3/squeeze1x1 -> fire3/squeeze1x1
I1026 14:57:59.301982 20580 net.cpp:127] Setting up fire3/squeeze1x1
I1026 14:57:59.301993 20580 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1026 14:57:59.301997 20580 net.cpp:144] Memory required for data: 688966200
I1026 14:57:59.302006 20580 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1026 14:57:59.302018 20580 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1026 14:57:59.302024 20580 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1026 14:57:59.302031 20580 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1026 14:57:59.302036 20580 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I1026 14:57:59.302043 20580 net.cpp:84] Creating Layer fire3/relu_squeeze1x1
I1026 14:57:59.302048 20580 net.cpp:413] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I1026 14:57:59.302054 20580 net.cpp:374] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I1026 14:57:59.302268 20580 net.cpp:127] Setting up fire3/relu_squeeze1x1
I1026 14:57:59.302280 20580 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1026 14:57:59.302289 20580 net.cpp:144] Memory required for data: 699001400
I1026 14:57:59.302294 20580 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1026 14:57:59.302305 20580 net.cpp:84] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1026 14:57:59.302314 20580 net.cpp:413] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I1026 14:57:59.302320 20580 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1026 14:57:59.302330 20580 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1026 14:57:59.302382 20580 net.cpp:127] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1026 14:57:59.302392 20580 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1026 14:57:59.302397 20580 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1026 14:57:59.302402 20580 net.cpp:144] Memory required for data: 719071800
I1026 14:57:59.302407 20580 layer_factory.hpp:77] Creating layer fire3/expand1x1
I1026 14:57:59.302420 20580 net.cpp:84] Creating Layer fire3/expand1x1
I1026 14:57:59.302425 20580 net.cpp:413] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1026 14:57:59.302435 20580 net.cpp:387] fire3/expand1x1 -> fire3/expand1x1
I1026 14:57:59.302796 20580 net.cpp:127] Setting up fire3/expand1x1
I1026 14:57:59.302809 20580 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1026 14:57:59.302812 20580 net.cpp:144] Memory required for data: 759212600
I1026 14:57:59.302819 20580 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1026 14:57:59.302826 20580 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1026 14:57:59.302831 20580 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1026 14:57:59.302842 20580 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1026 14:57:59.302858 20580 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I1026 14:57:59.302865 20580 net.cpp:84] Creating Layer fire3/relu_expand1x1
I1026 14:57:59.302870 20580 net.cpp:413] fire3/relu_expand1x1 <- fire3/expand1x1
I1026 14:57:59.302878 20580 net.cpp:374] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I1026 14:57:59.303094 20580 net.cpp:127] Setting up fire3/relu_expand1x1
I1026 14:57:59.303107 20580 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1026 14:57:59.303112 20580 net.cpp:144] Memory required for data: 799353400
I1026 14:57:59.303117 20580 layer_factory.hpp:77] Creating layer fire3/expand3x3
I1026 14:57:59.303128 20580 net.cpp:84] Creating Layer fire3/expand3x3
I1026 14:57:59.303134 20580 net.cpp:413] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1026 14:57:59.303149 20580 net.cpp:387] fire3/expand3x3 -> fire3/expand3x3
I1026 14:57:59.303596 20580 net.cpp:127] Setting up fire3/expand3x3
I1026 14:57:59.303606 20580 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1026 14:57:59.303611 20580 net.cpp:144] Memory required for data: 839494200
I1026 14:57:59.303618 20580 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1026 14:57:59.303624 20580 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1026 14:57:59.303632 20580 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1026 14:57:59.303638 20580 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1026 14:57:59.303643 20580 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I1026 14:57:59.303650 20580 net.cpp:84] Creating Layer fire3/relu_expand3x3
I1026 14:57:59.303655 20580 net.cpp:413] fire3/relu_expand3x3 <- fire3/expand3x3
I1026 14:57:59.303664 20580 net.cpp:374] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I1026 14:57:59.305075 20580 net.cpp:127] Setting up fire3/relu_expand3x3
I1026 14:57:59.305094 20580 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1026 14:57:59.305100 20580 net.cpp:144] Memory required for data: 879635000
I1026 14:57:59.305106 20580 layer_factory.hpp:77] Creating layer fire3/concat
I1026 14:57:59.305114 20580 net.cpp:84] Creating Layer fire3/concat
I1026 14:57:59.305120 20580 net.cpp:413] fire3/concat <- fire3/expand1x1
I1026 14:57:59.305128 20580 net.cpp:413] fire3/concat <- fire3/expand3x3
I1026 14:57:59.305137 20580 net.cpp:387] fire3/concat -> fire3/concat
I1026 14:57:59.305173 20580 net.cpp:127] Setting up fire3/concat
I1026 14:57:59.305182 20580 net.cpp:136] Top shape: 50 128 56 56 (20070400)
I1026 14:57:59.305187 20580 net.cpp:144] Memory required for data: 959916600
I1026 14:57:59.305191 20580 layer_factory.hpp:77] Creating layer pool3
I1026 14:57:59.305202 20580 net.cpp:84] Creating Layer pool3
I1026 14:57:59.305207 20580 net.cpp:413] pool3 <- fire3/concat
I1026 14:57:59.305215 20580 net.cpp:387] pool3 -> pool3
I1026 14:57:59.305264 20580 net.cpp:127] Setting up pool3
I1026 14:57:59.305274 20580 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1026 14:57:59.305279 20580 net.cpp:144] Memory required for data: 979987000
I1026 14:57:59.305284 20580 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I1026 14:57:59.305295 20580 net.cpp:84] Creating Layer fire4/squeeze1x1
I1026 14:57:59.305308 20580 net.cpp:413] fire4/squeeze1x1 <- pool3
I1026 14:57:59.305318 20580 net.cpp:387] fire4/squeeze1x1 -> fire4/squeeze1x1
I1026 14:57:59.305721 20580 net.cpp:127] Setting up fire4/squeeze1x1
I1026 14:57:59.305732 20580 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1026 14:57:59.305737 20580 net.cpp:144] Memory required for data: 985004600
I1026 14:57:59.305745 20580 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1026 14:57:59.305752 20580 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1026 14:57:59.305757 20580 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1026 14:57:59.305778 20580 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1026 14:57:59.305794 20580 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I1026 14:57:59.305802 20580 net.cpp:84] Creating Layer fire4/relu_squeeze1x1
I1026 14:57:59.305807 20580 net.cpp:413] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I1026 14:57:59.305816 20580 net.cpp:374] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I1026 14:57:59.306033 20580 net.cpp:127] Setting up fire4/relu_squeeze1x1
I1026 14:57:59.306046 20580 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1026 14:57:59.306051 20580 net.cpp:144] Memory required for data: 990022200
I1026 14:57:59.306056 20580 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1026 14:57:59.306063 20580 net.cpp:84] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1026 14:57:59.306069 20580 net.cpp:413] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I1026 14:57:59.306079 20580 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1026 14:57:59.306088 20580 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1026 14:57:59.306138 20580 net.cpp:127] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1026 14:57:59.306150 20580 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1026 14:57:59.306156 20580 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1026 14:57:59.306161 20580 net.cpp:144] Memory required for data: 1000057400
I1026 14:57:59.306166 20580 layer_factory.hpp:77] Creating layer fire4/expand1x1
I1026 14:57:59.306175 20580 net.cpp:84] Creating Layer fire4/expand1x1
I1026 14:57:59.306181 20580 net.cpp:413] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1026 14:57:59.306190 20580 net.cpp:387] fire4/expand1x1 -> fire4/expand1x1
I1026 14:57:59.306572 20580 net.cpp:127] Setting up fire4/expand1x1
I1026 14:57:59.306584 20580 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1026 14:57:59.306591 20580 net.cpp:144] Memory required for data: 1020127800
I1026 14:57:59.306605 20580 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1026 14:57:59.306615 20580 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1026 14:57:59.306622 20580 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1026 14:57:59.306627 20580 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1026 14:57:59.306632 20580 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I1026 14:57:59.306640 20580 net.cpp:84] Creating Layer fire4/relu_expand1x1
I1026 14:57:59.306645 20580 net.cpp:413] fire4/relu_expand1x1 <- fire4/expand1x1
I1026 14:57:59.306651 20580 net.cpp:374] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I1026 14:57:59.306872 20580 net.cpp:127] Setting up fire4/relu_expand1x1
I1026 14:57:59.306885 20580 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1026 14:57:59.306890 20580 net.cpp:144] Memory required for data: 1040198200
I1026 14:57:59.306895 20580 layer_factory.hpp:77] Creating layer fire4/expand3x3
I1026 14:57:59.306911 20580 net.cpp:84] Creating Layer fire4/expand3x3
I1026 14:57:59.306917 20580 net.cpp:413] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1026 14:57:59.306927 20580 net.cpp:387] fire4/expand3x3 -> fire4/expand3x3
I1026 14:57:59.307600 20580 net.cpp:127] Setting up fire4/expand3x3
I1026 14:57:59.307611 20580 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1026 14:57:59.307616 20580 net.cpp:144] Memory required for data: 1060268600
I1026 14:57:59.307624 20580 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1026 14:57:59.307631 20580 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1026 14:57:59.307637 20580 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1026 14:57:59.307648 20580 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1026 14:57:59.307663 20580 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I1026 14:57:59.307672 20580 net.cpp:84] Creating Layer fire4/relu_expand3x3
I1026 14:57:59.307677 20580 net.cpp:413] fire4/relu_expand3x3 <- fire4/expand3x3
I1026 14:57:59.307687 20580 net.cpp:374] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I1026 14:57:59.307899 20580 net.cpp:127] Setting up fire4/relu_expand3x3
I1026 14:57:59.307911 20580 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1026 14:57:59.307916 20580 net.cpp:144] Memory required for data: 1080339000
I1026 14:57:59.307921 20580 layer_factory.hpp:77] Creating layer fire4/concat
I1026 14:57:59.307929 20580 net.cpp:84] Creating Layer fire4/concat
I1026 14:57:59.307934 20580 net.cpp:413] fire4/concat <- fire4/expand1x1
I1026 14:57:59.307940 20580 net.cpp:413] fire4/concat <- fire4/expand3x3
I1026 14:57:59.307948 20580 net.cpp:387] fire4/concat -> fire4/concat
I1026 14:57:59.307981 20580 net.cpp:127] Setting up fire4/concat
I1026 14:57:59.307988 20580 net.cpp:136] Top shape: 50 256 28 28 (10035200)
I1026 14:57:59.307992 20580 net.cpp:144] Memory required for data: 1120479800
I1026 14:57:59.307997 20580 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I1026 14:57:59.308012 20580 net.cpp:84] Creating Layer fire5/squeeze1x1
I1026 14:57:59.308017 20580 net.cpp:413] fire5/squeeze1x1 <- fire4/concat
I1026 14:57:59.308025 20580 net.cpp:387] fire5/squeeze1x1 -> fire5/squeeze1x1
I1026 14:57:59.308459 20580 net.cpp:127] Setting up fire5/squeeze1x1
I1026 14:57:59.308471 20580 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1026 14:57:59.308476 20580 net.cpp:144] Memory required for data: 1125497400
I1026 14:57:59.308482 20580 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1026 14:57:59.308490 20580 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1026 14:57:59.308496 20580 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1026 14:57:59.308502 20580 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1026 14:57:59.308506 20580 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I1026 14:57:59.308513 20580 net.cpp:84] Creating Layer fire5/relu_squeeze1x1
I1026 14:57:59.308519 20580 net.cpp:413] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I1026 14:57:59.308531 20580 net.cpp:374] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I1026 14:57:59.309944 20580 net.cpp:127] Setting up fire5/relu_squeeze1x1
I1026 14:57:59.309963 20580 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1026 14:57:59.309969 20580 net.cpp:144] Memory required for data: 1130515000
I1026 14:57:59.309974 20580 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1026 14:57:59.309988 20580 net.cpp:84] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1026 14:57:59.309994 20580 net.cpp:413] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I1026 14:57:59.310003 20580 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1026 14:57:59.310014 20580 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1026 14:57:59.310066 20580 net.cpp:127] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1026 14:57:59.310076 20580 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1026 14:57:59.310082 20580 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1026 14:57:59.310087 20580 net.cpp:144] Memory required for data: 1140550200
I1026 14:57:59.310091 20580 layer_factory.hpp:77] Creating layer fire5/expand1x1
I1026 14:57:59.310104 20580 net.cpp:84] Creating Layer fire5/expand1x1
I1026 14:57:59.310109 20580 net.cpp:413] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1026 14:57:59.310119 20580 net.cpp:387] fire5/expand1x1 -> fire5/expand1x1
I1026 14:57:59.310516 20580 net.cpp:127] Setting up fire5/expand1x1
I1026 14:57:59.310537 20580 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1026 14:57:59.310554 20580 net.cpp:144] Memory required for data: 1160620600
I1026 14:57:59.310561 20580 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1026 14:57:59.310569 20580 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1026 14:57:59.310573 20580 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1026 14:57:59.310580 20580 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1026 14:57:59.310585 20580 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I1026 14:57:59.310592 20580 net.cpp:84] Creating Layer fire5/relu_expand1x1
I1026 14:57:59.310597 20580 net.cpp:413] fire5/relu_expand1x1 <- fire5/expand1x1
I1026 14:57:59.310605 20580 net.cpp:374] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I1026 14:57:59.310818 20580 net.cpp:127] Setting up fire5/relu_expand1x1
I1026 14:57:59.310837 20580 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1026 14:57:59.310843 20580 net.cpp:144] Memory required for data: 1180691000
I1026 14:57:59.310848 20580 layer_factory.hpp:77] Creating layer fire5/expand3x3
I1026 14:57:59.310858 20580 net.cpp:84] Creating Layer fire5/expand3x3
I1026 14:57:59.310864 20580 net.cpp:413] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1026 14:57:59.310875 20580 net.cpp:387] fire5/expand3x3 -> fire5/expand3x3
I1026 14:57:59.311545 20580 net.cpp:127] Setting up fire5/expand3x3
I1026 14:57:59.311558 20580 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1026 14:57:59.311563 20580 net.cpp:144] Memory required for data: 1200761400
I1026 14:57:59.311570 20580 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1026 14:57:59.311576 20580 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1026 14:57:59.311583 20580 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1026 14:57:59.311589 20580 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1026 14:57:59.311592 20580 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I1026 14:57:59.311602 20580 net.cpp:84] Creating Layer fire5/relu_expand3x3
I1026 14:57:59.311607 20580 net.cpp:413] fire5/relu_expand3x3 <- fire5/expand3x3
I1026 14:57:59.311614 20580 net.cpp:374] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I1026 14:57:59.311830 20580 net.cpp:127] Setting up fire5/relu_expand3x3
I1026 14:57:59.311844 20580 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1026 14:57:59.311849 20580 net.cpp:144] Memory required for data: 1220831800
I1026 14:57:59.311856 20580 layer_factory.hpp:77] Creating layer fire5/concat
I1026 14:57:59.311863 20580 net.cpp:84] Creating Layer fire5/concat
I1026 14:57:59.311868 20580 net.cpp:413] fire5/concat <- fire5/expand1x1
I1026 14:57:59.311874 20580 net.cpp:413] fire5/concat <- fire5/expand3x3
I1026 14:57:59.311883 20580 net.cpp:387] fire5/concat -> fire5/concat
I1026 14:57:59.311915 20580 net.cpp:127] Setting up fire5/concat
I1026 14:57:59.311923 20580 net.cpp:136] Top shape: 50 256 28 28 (10035200)
I1026 14:57:59.311928 20580 net.cpp:144] Memory required for data: 1260972600
I1026 14:57:59.311933 20580 layer_factory.hpp:77] Creating layer pool5
I1026 14:57:59.311941 20580 net.cpp:84] Creating Layer pool5
I1026 14:57:59.311947 20580 net.cpp:413] pool5 <- fire5/concat
I1026 14:57:59.311954 20580 net.cpp:387] pool5 -> pool5
I1026 14:57:59.312003 20580 net.cpp:127] Setting up pool5
I1026 14:57:59.312016 20580 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1026 14:57:59.312021 20580 net.cpp:144] Memory required for data: 1271007800
I1026 14:57:59.312026 20580 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I1026 14:57:59.312036 20580 net.cpp:84] Creating Layer fire6/squeeze1x1
I1026 14:57:59.312041 20580 net.cpp:413] fire6/squeeze1x1 <- pool5
I1026 14:57:59.312052 20580 net.cpp:387] fire6/squeeze1x1 -> fire6/squeeze1x1
I1026 14:57:59.312515 20580 net.cpp:127] Setting up fire6/squeeze1x1
I1026 14:57:59.312538 20580 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1026 14:57:59.312556 20580 net.cpp:144] Memory required for data: 1272889400
I1026 14:57:59.312563 20580 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1026 14:57:59.312571 20580 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1026 14:57:59.312575 20580 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1026 14:57:59.312580 20580 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1026 14:57:59.312585 20580 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I1026 14:57:59.312592 20580 net.cpp:84] Creating Layer fire6/relu_squeeze1x1
I1026 14:57:59.312598 20580 net.cpp:413] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I1026 14:57:59.312607 20580 net.cpp:374] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I1026 14:57:59.312821 20580 net.cpp:127] Setting up fire6/relu_squeeze1x1
I1026 14:57:59.312834 20580 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1026 14:57:59.312839 20580 net.cpp:144] Memory required for data: 1274771000
I1026 14:57:59.312844 20580 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1026 14:57:59.312855 20580 net.cpp:84] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1026 14:57:59.312860 20580 net.cpp:413] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I1026 14:57:59.312866 20580 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1026 14:57:59.312875 20580 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1026 14:57:59.312937 20580 net.cpp:127] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1026 14:57:59.312947 20580 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1026 14:57:59.312952 20580 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1026 14:57:59.312958 20580 net.cpp:144] Memory required for data: 1278534200
I1026 14:57:59.312963 20580 layer_factory.hpp:77] Creating layer fire6/expand1x1
I1026 14:57:59.312973 20580 net.cpp:84] Creating Layer fire6/expand1x1
I1026 14:57:59.312979 20580 net.cpp:413] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1026 14:57:59.312988 20580 net.cpp:387] fire6/expand1x1 -> fire6/expand1x1
I1026 14:57:59.313421 20580 net.cpp:127] Setting up fire6/expand1x1
I1026 14:57:59.313436 20580 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1026 14:57:59.313439 20580 net.cpp:144] Memory required for data: 1286060600
I1026 14:57:59.313446 20580 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1026 14:57:59.313453 20580 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1026 14:57:59.313459 20580 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1026 14:57:59.313464 20580 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1026 14:57:59.313469 20580 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I1026 14:57:59.313477 20580 net.cpp:84] Creating Layer fire6/relu_expand1x1
I1026 14:57:59.313482 20580 net.cpp:413] fire6/relu_expand1x1 <- fire6/expand1x1
I1026 14:57:59.313488 20580 net.cpp:374] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I1026 14:57:59.314908 20580 net.cpp:127] Setting up fire6/relu_expand1x1
I1026 14:57:59.314927 20580 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1026 14:57:59.314932 20580 net.cpp:144] Memory required for data: 1293587000
I1026 14:57:59.314937 20580 layer_factory.hpp:77] Creating layer fire6/expand3x3
I1026 14:57:59.314954 20580 net.cpp:84] Creating Layer fire6/expand3x3
I1026 14:57:59.314960 20580 net.cpp:413] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1026 14:57:59.314968 20580 net.cpp:387] fire6/expand3x3 -> fire6/expand3x3
I1026 14:57:59.316052 20580 net.cpp:127] Setting up fire6/expand3x3
I1026 14:57:59.316066 20580 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1026 14:57:59.316076 20580 net.cpp:144] Memory required for data: 1301113400
I1026 14:57:59.316100 20580 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1026 14:57:59.316107 20580 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1026 14:57:59.316121 20580 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1026 14:57:59.316128 20580 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1026 14:57:59.316133 20580 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I1026 14:57:59.316139 20580 net.cpp:84] Creating Layer fire6/relu_expand3x3
I1026 14:57:59.316145 20580 net.cpp:413] fire6/relu_expand3x3 <- fire6/expand3x3
I1026 14:57:59.316154 20580 net.cpp:374] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I1026 14:57:59.316377 20580 net.cpp:127] Setting up fire6/relu_expand3x3
I1026 14:57:59.316390 20580 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1026 14:57:59.316395 20580 net.cpp:144] Memory required for data: 1308639800
I1026 14:57:59.316401 20580 layer_factory.hpp:77] Creating layer fire6/concat
I1026 14:57:59.316412 20580 net.cpp:84] Creating Layer fire6/concat
I1026 14:57:59.316417 20580 net.cpp:413] fire6/concat <- fire6/expand1x1
I1026 14:57:59.316424 20580 net.cpp:413] fire6/concat <- fire6/expand3x3
I1026 14:57:59.316431 20580 net.cpp:387] fire6/concat -> fire6/concat
I1026 14:57:59.316478 20580 net.cpp:127] Setting up fire6/concat
I1026 14:57:59.316488 20580 net.cpp:136] Top shape: 50 384 14 14 (3763200)
I1026 14:57:59.316493 20580 net.cpp:144] Memory required for data: 1323692600
I1026 14:57:59.316540 20580 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I1026 14:57:59.316553 20580 net.cpp:84] Creating Layer fire7/squeeze1x1
I1026 14:57:59.316560 20580 net.cpp:413] fire7/squeeze1x1 <- fire6/concat
I1026 14:57:59.316570 20580 net.cpp:387] fire7/squeeze1x1 -> fire7/squeeze1x1
I1026 14:57:59.317095 20580 net.cpp:127] Setting up fire7/squeeze1x1
I1026 14:57:59.317106 20580 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1026 14:57:59.317111 20580 net.cpp:144] Memory required for data: 1325574200
I1026 14:57:59.317126 20580 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1026 14:57:59.317138 20580 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1026 14:57:59.317144 20580 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1026 14:57:59.317150 20580 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1026 14:57:59.317155 20580 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I1026 14:57:59.317163 20580 net.cpp:84] Creating Layer fire7/relu_squeeze1x1
I1026 14:57:59.317168 20580 net.cpp:413] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I1026 14:57:59.317175 20580 net.cpp:374] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I1026 14:57:59.317404 20580 net.cpp:127] Setting up fire7/relu_squeeze1x1
I1026 14:57:59.317416 20580 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1026 14:57:59.317422 20580 net.cpp:144] Memory required for data: 1327455800
I1026 14:57:59.317428 20580 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1026 14:57:59.317435 20580 net.cpp:84] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1026 14:57:59.317440 20580 net.cpp:413] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I1026 14:57:59.317448 20580 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1026 14:57:59.317456 20580 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1026 14:57:59.317509 20580 net.cpp:127] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1026 14:57:59.317526 20580 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1026 14:57:59.317533 20580 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1026 14:57:59.317538 20580 net.cpp:144] Memory required for data: 1331219000
I1026 14:57:59.317549 20580 layer_factory.hpp:77] Creating layer fire7/expand1x1
I1026 14:57:59.317571 20580 net.cpp:84] Creating Layer fire7/expand1x1
I1026 14:57:59.317577 20580 net.cpp:413] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1026 14:57:59.317587 20580 net.cpp:387] fire7/expand1x1 -> fire7/expand1x1
I1026 14:57:59.318017 20580 net.cpp:127] Setting up fire7/expand1x1
I1026 14:57:59.318027 20580 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1026 14:57:59.318032 20580 net.cpp:144] Memory required for data: 1338745400
I1026 14:57:59.318038 20580 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1026 14:57:59.318045 20580 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1026 14:57:59.318053 20580 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1026 14:57:59.318058 20580 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1026 14:57:59.318063 20580 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I1026 14:57:59.318069 20580 net.cpp:84] Creating Layer fire7/relu_expand1x1
I1026 14:57:59.318074 20580 net.cpp:413] fire7/relu_expand1x1 <- fire7/expand1x1
I1026 14:57:59.318084 20580 net.cpp:374] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I1026 14:57:59.319500 20580 net.cpp:127] Setting up fire7/relu_expand1x1
I1026 14:57:59.319519 20580 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1026 14:57:59.319525 20580 net.cpp:144] Memory required for data: 1346271800
I1026 14:57:59.319530 20580 layer_factory.hpp:77] Creating layer fire7/expand3x3
I1026 14:57:59.319545 20580 net.cpp:84] Creating Layer fire7/expand3x3
I1026 14:57:59.319552 20580 net.cpp:413] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1026 14:57:59.319563 20580 net.cpp:387] fire7/expand3x3 -> fire7/expand3x3
I1026 14:57:59.320636 20580 net.cpp:127] Setting up fire7/expand3x3
I1026 14:57:59.320649 20580 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1026 14:57:59.320654 20580 net.cpp:144] Memory required for data: 1353798200
I1026 14:57:59.320662 20580 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1026 14:57:59.320669 20580 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1026 14:57:59.320675 20580 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1026 14:57:59.320682 20580 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1026 14:57:59.320685 20580 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I1026 14:57:59.320695 20580 net.cpp:84] Creating Layer fire7/relu_expand3x3
I1026 14:57:59.320701 20580 net.cpp:413] fire7/relu_expand3x3 <- fire7/expand3x3
I1026 14:57:59.320711 20580 net.cpp:374] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I1026 14:57:59.320930 20580 net.cpp:127] Setting up fire7/relu_expand3x3
I1026 14:57:59.320941 20580 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1026 14:57:59.320946 20580 net.cpp:144] Memory required for data: 1361324600
I1026 14:57:59.320951 20580 layer_factory.hpp:77] Creating layer fire7/concat
I1026 14:57:59.320960 20580 net.cpp:84] Creating Layer fire7/concat
I1026 14:57:59.320964 20580 net.cpp:413] fire7/concat <- fire7/expand1x1
I1026 14:57:59.320971 20580 net.cpp:413] fire7/concat <- fire7/expand3x3
I1026 14:57:59.320979 20580 net.cpp:387] fire7/concat -> fire7/concat
I1026 14:57:59.321013 20580 net.cpp:127] Setting up fire7/concat
I1026 14:57:59.321020 20580 net.cpp:136] Top shape: 50 384 14 14 (3763200)
I1026 14:57:59.321027 20580 net.cpp:144] Memory required for data: 1376377400
I1026 14:57:59.321032 20580 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I1026 14:57:59.321044 20580 net.cpp:84] Creating Layer fire8/squeeze1x1
I1026 14:57:59.321049 20580 net.cpp:413] fire8/squeeze1x1 <- fire7/concat
I1026 14:57:59.321059 20580 net.cpp:387] fire8/squeeze1x1 -> fire8/squeeze1x1
I1026 14:57:59.323026 20580 net.cpp:127] Setting up fire8/squeeze1x1
I1026 14:57:59.323051 20580 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1026 14:57:59.323056 20580 net.cpp:144] Memory required for data: 1378886200
I1026 14:57:59.323076 20580 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1026 14:57:59.323083 20580 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1026 14:57:59.323089 20580 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1026 14:57:59.323094 20580 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1026 14:57:59.323099 20580 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I1026 14:57:59.323110 20580 net.cpp:84] Creating Layer fire8/relu_squeeze1x1
I1026 14:57:59.323122 20580 net.cpp:413] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I1026 14:57:59.323129 20580 net.cpp:374] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I1026 14:57:59.323367 20580 net.cpp:127] Setting up fire8/relu_squeeze1x1
I1026 14:57:59.323384 20580 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1026 14:57:59.323390 20580 net.cpp:144] Memory required for data: 1381395000
I1026 14:57:59.323395 20580 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1026 14:57:59.323402 20580 net.cpp:84] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1026 14:57:59.323408 20580 net.cpp:413] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I1026 14:57:59.323416 20580 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1026 14:57:59.323426 20580 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1026 14:57:59.323488 20580 net.cpp:127] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1026 14:57:59.323498 20580 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1026 14:57:59.323504 20580 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1026 14:57:59.323509 20580 net.cpp:144] Memory required for data: 1386412600
I1026 14:57:59.323513 20580 layer_factory.hpp:77] Creating layer fire8/expand1x1
I1026 14:57:59.323525 20580 net.cpp:84] Creating Layer fire8/expand1x1
I1026 14:57:59.323531 20580 net.cpp:413] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1026 14:57:59.323540 20580 net.cpp:387] fire8/expand1x1 -> fire8/expand1x1
I1026 14:57:59.324029 20580 net.cpp:127] Setting up fire8/expand1x1
I1026 14:57:59.324040 20580 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1026 14:57:59.324046 20580 net.cpp:144] Memory required for data: 1396447800
I1026 14:57:59.324053 20580 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1026 14:57:59.324059 20580 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1026 14:57:59.324065 20580 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1026 14:57:59.324070 20580 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1026 14:57:59.324074 20580 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I1026 14:57:59.324084 20580 net.cpp:84] Creating Layer fire8/relu_expand1x1
I1026 14:57:59.324090 20580 net.cpp:413] fire8/relu_expand1x1 <- fire8/expand1x1
I1026 14:57:59.324097 20580 net.cpp:374] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I1026 14:57:59.324321 20580 net.cpp:127] Setting up fire8/relu_expand1x1
I1026 14:57:59.324334 20580 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1026 14:57:59.324339 20580 net.cpp:144] Memory required for data: 1406483000
I1026 14:57:59.324345 20580 layer_factory.hpp:77] Creating layer fire8/expand3x3
I1026 14:57:59.324357 20580 net.cpp:84] Creating Layer fire8/expand3x3
I1026 14:57:59.324363 20580 net.cpp:413] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1026 14:57:59.324373 20580 net.cpp:387] fire8/expand3x3 -> fire8/expand3x3
I1026 14:57:59.327280 20580 net.cpp:127] Setting up fire8/expand3x3
I1026 14:57:59.327303 20580 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1026 14:57:59.327316 20580 net.cpp:144] Memory required for data: 1416518200
I1026 14:57:59.327337 20580 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1026 14:57:59.327349 20580 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1026 14:57:59.327355 20580 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1026 14:57:59.327361 20580 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1026 14:57:59.327366 20580 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I1026 14:57:59.327374 20580 net.cpp:84] Creating Layer fire8/relu_expand3x3
I1026 14:57:59.327380 20580 net.cpp:413] fire8/relu_expand3x3 <- fire8/expand3x3
I1026 14:57:59.327388 20580 net.cpp:374] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I1026 14:57:59.328809 20580 net.cpp:127] Setting up fire8/relu_expand3x3
I1026 14:57:59.328829 20580 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1026 14:57:59.328833 20580 net.cpp:144] Memory required for data: 1426553400
I1026 14:57:59.328840 20580 layer_factory.hpp:77] Creating layer fire8/concat
I1026 14:57:59.328850 20580 net.cpp:84] Creating Layer fire8/concat
I1026 14:57:59.328855 20580 net.cpp:413] fire8/concat <- fire8/expand1x1
I1026 14:57:59.328863 20580 net.cpp:413] fire8/concat <- fire8/expand3x3
I1026 14:57:59.328872 20580 net.cpp:387] fire8/concat -> fire8/concat
I1026 14:57:59.328910 20580 net.cpp:127] Setting up fire8/concat
I1026 14:57:59.328919 20580 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1026 14:57:59.328924 20580 net.cpp:144] Memory required for data: 1446623800
I1026 14:57:59.328929 20580 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I1026 14:57:59.328941 20580 net.cpp:84] Creating Layer fire9/squeeze1x1
I1026 14:57:59.328948 20580 net.cpp:413] fire9/squeeze1x1 <- fire8/concat
I1026 14:57:59.328956 20580 net.cpp:387] fire9/squeeze1x1 -> fire9/squeeze1x1
I1026 14:57:59.329586 20580 net.cpp:127] Setting up fire9/squeeze1x1
I1026 14:57:59.329598 20580 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1026 14:57:59.329603 20580 net.cpp:144] Memory required for data: 1449132600
I1026 14:57:59.329610 20580 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1026 14:57:59.329617 20580 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1026 14:57:59.329623 20580 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1026 14:57:59.329628 20580 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1026 14:57:59.329633 20580 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I1026 14:57:59.329648 20580 net.cpp:84] Creating Layer fire9/relu_squeeze1x1
I1026 14:57:59.329653 20580 net.cpp:413] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I1026 14:57:59.329663 20580 net.cpp:374] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I1026 14:57:59.329881 20580 net.cpp:127] Setting up fire9/relu_squeeze1x1
I1026 14:57:59.329893 20580 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1026 14:57:59.329900 20580 net.cpp:144] Memory required for data: 1451641400
I1026 14:57:59.329905 20580 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1026 14:57:59.329912 20580 net.cpp:84] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1026 14:57:59.329917 20580 net.cpp:413] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I1026 14:57:59.329926 20580 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1026 14:57:59.329934 20580 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1026 14:57:59.329987 20580 net.cpp:127] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1026 14:57:59.329999 20580 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1026 14:57:59.330005 20580 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1026 14:57:59.330009 20580 net.cpp:144] Memory required for data: 1456659000
I1026 14:57:59.330020 20580 layer_factory.hpp:77] Creating layer fire9/expand1x1
I1026 14:57:59.330041 20580 net.cpp:84] Creating Layer fire9/expand1x1
I1026 14:57:59.330047 20580 net.cpp:413] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1026 14:57:59.330057 20580 net.cpp:387] fire9/expand1x1 -> fire9/expand1x1
I1026 14:57:59.330555 20580 net.cpp:127] Setting up fire9/expand1x1
I1026 14:57:59.330569 20580 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1026 14:57:59.330574 20580 net.cpp:144] Memory required for data: 1466694200
I1026 14:57:59.330579 20580 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1026 14:57:59.330586 20580 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1026 14:57:59.330592 20580 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1026 14:57:59.330598 20580 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1026 14:57:59.330602 20580 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I1026 14:57:59.330612 20580 net.cpp:84] Creating Layer fire9/relu_expand1x1
I1026 14:57:59.330617 20580 net.cpp:413] fire9/relu_expand1x1 <- fire9/expand1x1
I1026 14:57:59.330624 20580 net.cpp:374] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I1026 14:57:59.330847 20580 net.cpp:127] Setting up fire9/relu_expand1x1
I1026 14:57:59.330858 20580 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1026 14:57:59.330863 20580 net.cpp:144] Memory required for data: 1476729400
I1026 14:57:59.330868 20580 layer_factory.hpp:77] Creating layer fire9/expand3x3
I1026 14:57:59.330883 20580 net.cpp:84] Creating Layer fire9/expand3x3
I1026 14:57:59.330890 20580 net.cpp:413] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1026 14:57:59.330899 20580 net.cpp:387] fire9/expand3x3 -> fire9/expand3x3
I1026 14:57:59.333803 20580 net.cpp:127] Setting up fire9/expand3x3
I1026 14:57:59.333823 20580 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1026 14:57:59.333828 20580 net.cpp:144] Memory required for data: 1486764600
I1026 14:57:59.333835 20580 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1026 14:57:59.333842 20580 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1026 14:57:59.333849 20580 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1026 14:57:59.333854 20580 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1026 14:57:59.333858 20580 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I1026 14:57:59.333866 20580 net.cpp:84] Creating Layer fire9/relu_expand3x3
I1026 14:57:59.333878 20580 net.cpp:413] fire9/relu_expand3x3 <- fire9/expand3x3
I1026 14:57:59.333886 20580 net.cpp:374] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I1026 14:57:59.334115 20580 net.cpp:127] Setting up fire9/relu_expand3x3
I1026 14:57:59.334127 20580 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1026 14:57:59.334132 20580 net.cpp:144] Memory required for data: 1496799800
I1026 14:57:59.334138 20580 layer_factory.hpp:77] Creating layer fire9/concat
I1026 14:57:59.334148 20580 net.cpp:84] Creating Layer fire9/concat
I1026 14:57:59.334153 20580 net.cpp:413] fire9/concat <- fire9/expand1x1
I1026 14:57:59.334159 20580 net.cpp:413] fire9/concat <- fire9/expand3x3
I1026 14:57:59.334167 20580 net.cpp:387] fire9/concat -> fire9/concat
I1026 14:57:59.334204 20580 net.cpp:127] Setting up fire9/concat
I1026 14:57:59.334213 20580 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1026 14:57:59.334218 20580 net.cpp:144] Memory required for data: 1516870200
I1026 14:57:59.334223 20580 layer_factory.hpp:77] Creating layer drop9
I1026 14:57:59.334240 20580 net.cpp:84] Creating Layer drop9
I1026 14:57:59.334245 20580 net.cpp:413] drop9 <- fire9/concat
I1026 14:57:59.334254 20580 net.cpp:374] drop9 -> fire9/concat (in-place)
I1026 14:57:59.334283 20580 net.cpp:127] Setting up drop9
I1026 14:57:59.334290 20580 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1026 14:57:59.334306 20580 net.cpp:144] Memory required for data: 1536940600
I1026 14:57:59.334323 20580 layer_factory.hpp:77] Creating layer conv10
I1026 14:57:59.334336 20580 net.cpp:84] Creating Layer conv10
I1026 14:57:59.334342 20580 net.cpp:413] conv10 <- fire9/concat
I1026 14:57:59.334350 20580 net.cpp:387] conv10 -> conv10
I1026 14:57:59.343981 20580 net.cpp:127] Setting up conv10
I1026 14:57:59.344003 20580 net.cpp:136] Top shape: 50 1000 14 14 (9800000)
I1026 14:57:59.344009 20580 net.cpp:144] Memory required for data: 1576140600
I1026 14:57:59.344017 20580 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1026 14:57:59.344024 20580 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1026 14:57:59.344030 20580 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1026 14:57:59.344035 20580 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1026 14:57:59.344039 20580 layer_factory.hpp:77] Creating layer relu_conv10
I1026 14:57:59.344050 20580 net.cpp:84] Creating Layer relu_conv10
I1026 14:57:59.344055 20580 net.cpp:413] relu_conv10 <- conv10
I1026 14:57:59.344063 20580 net.cpp:374] relu_conv10 -> conv10 (in-place)
I1026 14:57:59.345495 20580 net.cpp:127] Setting up relu_conv10
I1026 14:57:59.345516 20580 net.cpp:136] Top shape: 50 1000 14 14 (9800000)
I1026 14:57:59.345522 20580 net.cpp:144] Memory required for data: 1615340600
I1026 14:57:59.345527 20580 layer_factory.hpp:77] Creating layer pool10
I1026 14:57:59.345536 20580 net.cpp:84] Creating Layer pool10
I1026 14:57:59.345542 20580 net.cpp:413] pool10 <- conv10
I1026 14:57:59.345551 20580 net.cpp:387] pool10 -> pool10
I1026 14:57:59.345791 20580 net.cpp:127] Setting up pool10
I1026 14:57:59.345804 20580 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1026 14:57:59.345810 20580 net.cpp:144] Memory required for data: 1615540600
I1026 14:57:59.345815 20580 layer_factory.hpp:77] Creating layer pool10_pool10_0_split
I1026 14:57:59.345824 20580 net.cpp:84] Creating Layer pool10_pool10_0_split
I1026 14:57:59.345829 20580 net.cpp:413] pool10_pool10_0_split <- pool10
I1026 14:57:59.345837 20580 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_0
I1026 14:57:59.345846 20580 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_1
I1026 14:57:59.345854 20580 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_2
I1026 14:57:59.345919 20580 net.cpp:127] Setting up pool10_pool10_0_split
I1026 14:57:59.345928 20580 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1026 14:57:59.345935 20580 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1026 14:57:59.345940 20580 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1026 14:57:59.345944 20580 net.cpp:144] Memory required for data: 1616140600
I1026 14:57:59.345949 20580 layer_factory.hpp:77] Creating layer loss
I1026 14:57:59.345958 20580 net.cpp:84] Creating Layer loss
I1026 14:57:59.345964 20580 net.cpp:413] loss <- pool10_pool10_0_split_0
I1026 14:57:59.345970 20580 net.cpp:413] loss <- label_data_1_split_0
I1026 14:57:59.345978 20580 net.cpp:387] loss -> loss
I1026 14:57:59.345986 20580 layer_factory.hpp:77] Creating layer loss
I1026 14:57:59.346354 20580 net.cpp:127] Setting up loss
I1026 14:57:59.346369 20580 net.cpp:136] Top shape: (1)
I1026 14:57:59.346374 20580 net.cpp:139]     with loss weight 1
I1026 14:57:59.346386 20580 net.cpp:144] Memory required for data: 1616140604
I1026 14:57:59.346391 20580 layer_factory.hpp:77] Creating layer accuracy_top1
I1026 14:57:59.346406 20580 net.cpp:84] Creating Layer accuracy_top1
I1026 14:57:59.346415 20580 net.cpp:413] accuracy_top1 <- pool10_pool10_0_split_1
I1026 14:57:59.346421 20580 net.cpp:413] accuracy_top1 <- label_data_1_split_1
I1026 14:57:59.346428 20580 net.cpp:387] accuracy_top1 -> accuracy_top1
I1026 14:57:59.346446 20580 net.cpp:127] Setting up accuracy_top1
I1026 14:57:59.346451 20580 net.cpp:136] Top shape: (1)
I1026 14:57:59.346456 20580 net.cpp:144] Memory required for data: 1616140608
I1026 14:57:59.346460 20580 layer_factory.hpp:77] Creating layer accuracy_top5
I1026 14:57:59.346489 20580 net.cpp:84] Creating Layer accuracy_top5
I1026 14:57:59.346496 20580 net.cpp:413] accuracy_top5 <- pool10_pool10_0_split_2
I1026 14:57:59.346514 20580 net.cpp:413] accuracy_top5 <- label_data_1_split_2
I1026 14:57:59.346521 20580 net.cpp:387] accuracy_top5 -> accuracy_top5
I1026 14:57:59.346544 20580 net.cpp:127] Setting up accuracy_top5
I1026 14:57:59.346551 20580 net.cpp:136] Top shape: (1)
I1026 14:57:59.346556 20580 net.cpp:144] Memory required for data: 1616140612
I1026 14:57:59.346561 20580 net.cpp:207] accuracy_top5 does not need backward computation.
I1026 14:57:59.346566 20580 net.cpp:207] accuracy_top1 does not need backward computation.
I1026 14:57:59.346571 20580 net.cpp:205] loss needs backward computation.
I1026 14:57:59.346576 20580 net.cpp:205] pool10_pool10_0_split needs backward computation.
I1026 14:57:59.346581 20580 net.cpp:205] pool10 needs backward computation.
I1026 14:57:59.346585 20580 net.cpp:205] relu_conv10 needs backward computation.
I1026 14:57:59.346590 20580 net.cpp:205] conv10 needs backward computation.
I1026 14:57:59.346596 20580 net.cpp:205] drop9 needs backward computation.
I1026 14:57:59.346599 20580 net.cpp:205] fire9/concat needs backward computation.
I1026 14:57:59.346604 20580 net.cpp:205] fire9/relu_expand3x3 needs backward computation.
I1026 14:57:59.346609 20580 net.cpp:205] fire9/expand3x3 needs backward computation.
I1026 14:57:59.346614 20580 net.cpp:205] fire9/relu_expand1x1 needs backward computation.
I1026 14:57:59.346618 20580 net.cpp:205] fire9/expand1x1 needs backward computation.
I1026 14:57:59.346623 20580 net.cpp:205] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I1026 14:57:59.346628 20580 net.cpp:205] fire9/relu_squeeze1x1 needs backward computation.
I1026 14:57:59.346633 20580 net.cpp:205] fire9/squeeze1x1 needs backward computation.
I1026 14:57:59.346637 20580 net.cpp:205] fire8/concat needs backward computation.
I1026 14:57:59.346643 20580 net.cpp:205] fire8/relu_expand3x3 needs backward computation.
I1026 14:57:59.346647 20580 net.cpp:205] fire8/expand3x3 needs backward computation.
I1026 14:57:59.346652 20580 net.cpp:205] fire8/relu_expand1x1 needs backward computation.
I1026 14:57:59.346657 20580 net.cpp:205] fire8/expand1x1 needs backward computation.
I1026 14:57:59.346662 20580 net.cpp:205] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I1026 14:57:59.346665 20580 net.cpp:205] fire8/relu_squeeze1x1 needs backward computation.
I1026 14:57:59.346670 20580 net.cpp:205] fire8/squeeze1x1 needs backward computation.
I1026 14:57:59.346675 20580 net.cpp:205] fire7/concat needs backward computation.
I1026 14:57:59.346679 20580 net.cpp:205] fire7/relu_expand3x3 needs backward computation.
I1026 14:57:59.346684 20580 net.cpp:205] fire7/expand3x3 needs backward computation.
I1026 14:57:59.346688 20580 net.cpp:205] fire7/relu_expand1x1 needs backward computation.
I1026 14:57:59.346695 20580 net.cpp:205] fire7/expand1x1 needs backward computation.
I1026 14:57:59.346699 20580 net.cpp:205] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I1026 14:57:59.346704 20580 net.cpp:205] fire7/relu_squeeze1x1 needs backward computation.
I1026 14:57:59.346709 20580 net.cpp:205] fire7/squeeze1x1 needs backward computation.
I1026 14:57:59.346714 20580 net.cpp:205] fire6/concat needs backward computation.
I1026 14:57:59.346719 20580 net.cpp:205] fire6/relu_expand3x3 needs backward computation.
I1026 14:57:59.346722 20580 net.cpp:205] fire6/expand3x3 needs backward computation.
I1026 14:57:59.346727 20580 net.cpp:205] fire6/relu_expand1x1 needs backward computation.
I1026 14:57:59.346731 20580 net.cpp:205] fire6/expand1x1 needs backward computation.
I1026 14:57:59.346735 20580 net.cpp:205] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I1026 14:57:59.346740 20580 net.cpp:205] fire6/relu_squeeze1x1 needs backward computation.
I1026 14:57:59.346745 20580 net.cpp:205] fire6/squeeze1x1 needs backward computation.
I1026 14:57:59.346750 20580 net.cpp:205] pool5 needs backward computation.
I1026 14:57:59.346758 20580 net.cpp:205] fire5/concat needs backward computation.
I1026 14:57:59.346768 20580 net.cpp:205] fire5/relu_expand3x3 needs backward computation.
I1026 14:57:59.346773 20580 net.cpp:205] fire5/expand3x3 needs backward computation.
I1026 14:57:59.346777 20580 net.cpp:205] fire5/relu_expand1x1 needs backward computation.
I1026 14:57:59.346782 20580 net.cpp:205] fire5/expand1x1 needs backward computation.
I1026 14:57:59.346786 20580 net.cpp:205] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I1026 14:57:59.346791 20580 net.cpp:205] fire5/relu_squeeze1x1 needs backward computation.
I1026 14:57:59.346796 20580 net.cpp:205] fire5/squeeze1x1 needs backward computation.
I1026 14:57:59.346801 20580 net.cpp:205] fire4/concat needs backward computation.
I1026 14:57:59.346804 20580 net.cpp:205] fire4/relu_expand3x3 needs backward computation.
I1026 14:57:59.346809 20580 net.cpp:205] fire4/expand3x3 needs backward computation.
I1026 14:57:59.346813 20580 net.cpp:205] fire4/relu_expand1x1 needs backward computation.
I1026 14:57:59.346817 20580 net.cpp:205] fire4/expand1x1 needs backward computation.
I1026 14:57:59.346822 20580 net.cpp:205] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I1026 14:57:59.346827 20580 net.cpp:205] fire4/relu_squeeze1x1 needs backward computation.
I1026 14:57:59.346832 20580 net.cpp:205] fire4/squeeze1x1 needs backward computation.
I1026 14:57:59.346835 20580 net.cpp:205] pool3 needs backward computation.
I1026 14:57:59.346840 20580 net.cpp:205] fire3/concat needs backward computation.
I1026 14:57:59.346845 20580 net.cpp:205] fire3/relu_expand3x3 needs backward computation.
I1026 14:57:59.346849 20580 net.cpp:205] fire3/expand3x3 needs backward computation.
I1026 14:57:59.346853 20580 net.cpp:205] fire3/relu_expand1x1 needs backward computation.
I1026 14:57:59.346858 20580 net.cpp:205] fire3/expand1x1 needs backward computation.
I1026 14:57:59.346863 20580 net.cpp:205] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I1026 14:57:59.346868 20580 net.cpp:205] fire3/relu_squeeze1x1 needs backward computation.
I1026 14:57:59.346871 20580 net.cpp:205] fire3/squeeze1x1 needs backward computation.
I1026 14:57:59.346875 20580 net.cpp:205] fire2/concat needs backward computation.
I1026 14:57:59.346880 20580 net.cpp:205] fire2/relu_expand3x3 needs backward computation.
I1026 14:57:59.346884 20580 net.cpp:205] fire2/expand3x3 needs backward computation.
I1026 14:57:59.346889 20580 net.cpp:205] fire2/relu_expand1x1 needs backward computation.
I1026 14:57:59.346894 20580 net.cpp:205] fire2/expand1x1 needs backward computation.
I1026 14:57:59.346899 20580 net.cpp:205] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I1026 14:57:59.346902 20580 net.cpp:205] fire2/relu_squeeze1x1 needs backward computation.
I1026 14:57:59.346906 20580 net.cpp:205] fire2/squeeze1x1 needs backward computation.
I1026 14:57:59.346911 20580 net.cpp:205] pool1 needs backward computation.
I1026 14:57:59.346916 20580 net.cpp:205] relu_conv1 needs backward computation.
I1026 14:57:59.346920 20580 net.cpp:205] conv1 needs backward computation.
I1026 14:57:59.346926 20580 net.cpp:207] label_data_1_split does not need backward computation.
I1026 14:57:59.346931 20580 net.cpp:207] data does not need backward computation.
I1026 14:57:59.346936 20580 net.cpp:249] This network produces output accuracy_top1
I1026 14:57:59.346941 20580 net.cpp:249] This network produces output accuracy_top5
I1026 14:57:59.346946 20580 net.cpp:249] This network produces output loss
I1026 14:57:59.347002 20580 net.cpp:262] Network initialization done.
I1026 14:57:59.347267 20580 solver.cpp:56] Solver scaffolding done.
I1026 14:57:59.351899 20580 caffe.cpp:155] Finetuning from SqueezeNet/SqueezeNet_v1.1/sqz_inq_raw.caffemodel
I1026 14:57:59.362438 20580 net.cpp:778] Ignoring source layer label_data_1_split
I1026 14:57:59.364439 20580 net.cpp:778] Ignoring source layer pool10_pool10_0_split
I1026 14:57:59.364452 20580 net.cpp:778] Ignoring source layer accuracy_top1
I1026 14:57:59.364467 20580 net.cpp:778] Ignoring source layer accuracy_top5
I1026 14:57:59.371006 20580 caffe.cpp:248] Starting Optimization
I1026 14:58:03.283788 20633 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_10.prototxt
I1026 14:58:03.309882 20632 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_10.prototxt
I1026 14:58:03.309932 20631 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_10.prototxt
I1026 14:58:04.088570 20580 solver.cpp:275] Solving SqueezeNet
I1026 14:58:04.088624 20580 solver.cpp:276] Learning Rate Policy: poly
I1026 14:58:04.089135 20580 solver.cpp:333] Iteration 0, Testing net (#0)
I1026 14:58:35.510895 20580 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.58488
I1026 14:58:35.511068 20580 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.80788
I1026 14:58:35.511087 20580 solver.cpp:400]     Test net output #2: loss = 1.83354 (* 1 = 1.83354 loss)
I1026 14:58:35.511198 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.511256 20580 inq_conv_layer.cpp:260] Max_power = 0
I1026 14:58:35.511265 20580 inq_conv_layer.cpp:261] Min_power = -6
I1026 14:58:35.511286 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10.0116%)
I1026 14:58:35.511306 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 1728/1728
I1026 14:58:35.511312 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 173/1555/1728
I1026 14:58:35.511453 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.511490 20580 inq_conv_layer.cpp:260] Max_power = -2
I1026 14:58:35.511499 20580 inq_conv_layer.cpp:261] Min_power = -8
I1026 14:58:35.511508 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 9.375%)
I1026 14:58:35.511521 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 64/64
I1026 14:58:35.511526 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 6/58/64
I1026 14:58:35.525509 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.543117 20580 inq_conv_layer.cpp:260] Max_power = 0
I1026 14:58:35.543128 20580 inq_conv_layer.cpp:261] Min_power = -6
I1026 14:58:35.543149 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 9.96094%)
I1026 14:58:35.543164 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 1024/1024
I1026 14:58:35.543170 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 102/922/1024
I1026 14:58:35.543251 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.543283 20580 inq_conv_layer.cpp:260] Max_power = -2
I1026 14:58:35.543292 20580 inq_conv_layer.cpp:261] Min_power = -8
I1026 14:58:35.543304 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 12.5%)
I1026 14:58:35.543316 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 16/16
I1026 14:58:35.543324 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 2/14/16
I1026 14:58:35.546845 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.547117 20580 inq_conv_layer.cpp:260] Max_power = 0
I1026 14:58:35.547127 20580 inq_conv_layer.cpp:261] Min_power = -6
I1026 14:58:35.547147 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 9.96094%)
I1026 14:58:35.547161 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 1024/1024
I1026 14:58:35.547168 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 102/922/1024
I1026 14:58:35.547250 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.547281 20580 inq_conv_layer.cpp:260] Max_power = -3
I1026 14:58:35.547291 20580 inq_conv_layer.cpp:261] Min_power = -9
I1026 14:58:35.547304 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 9.375%)
I1026 14:58:35.547317 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 64/64
I1026 14:58:35.547332 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 6/58/64
I1026 14:58:35.551435 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.552597 20580 inq_conv_layer.cpp:260] Max_power = -1
I1026 14:58:35.552608 20580 inq_conv_layer.cpp:261] Min_power = -7
I1026 14:58:35.552682 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10.0043%)
I1026 14:58:35.552698 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 9216/9216
I1026 14:58:35.552703 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 922/8294/9216
I1026 14:58:35.553561 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.553601 20580 inq_conv_layer.cpp:260] Max_power = -4
I1026 14:58:35.553608 20580 inq_conv_layer.cpp:261] Min_power = -10
I1026 14:58:35.553617 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 9.375%)
I1026 14:58:35.553647 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 64/64
I1026 14:58:35.553653 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 6/58/64
I1026 14:58:35.562937 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.566164 20580 inq_conv_layer.cpp:260] Max_power = 0
I1026 14:58:35.566175 20580 inq_conv_layer.cpp:261] Min_power = -6
I1026 14:58:35.566192 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10.0098%)
I1026 14:58:35.566206 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 2048/2048
I1026 14:58:35.566210 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 205/1843/2048
I1026 14:58:35.566385 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.566426 20580 inq_conv_layer.cpp:260] Max_power = -2
I1026 14:58:35.566433 20580 inq_conv_layer.cpp:261] Min_power = -8
I1026 14:58:35.566442 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 12.5%)
I1026 14:58:35.566453 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 16/16
I1026 14:58:35.566458 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 2/14/16
I1026 14:58:35.569905 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.570673 20580 inq_conv_layer.cpp:260] Max_power = 0
I1026 14:58:35.570683 20580 inq_conv_layer.cpp:261] Min_power = -6
I1026 14:58:35.570696 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 9.96094%)
I1026 14:58:35.570708 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 1024/1024
I1026 14:58:35.570713 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 102/922/1024
I1026 14:58:35.570794 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.570829 20580 inq_conv_layer.cpp:260] Max_power = -2
I1026 14:58:35.570837 20580 inq_conv_layer.cpp:261] Min_power = -8
I1026 14:58:35.570844 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 9.375%)
I1026 14:58:35.570857 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 64/64
I1026 14:58:35.570861 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 6/58/64
I1026 14:58:35.574924 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.576095 20580 inq_conv_layer.cpp:260] Max_power = 0
I1026 14:58:35.576107 20580 inq_conv_layer.cpp:261] Min_power = -6
I1026 14:58:35.576160 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10.0043%)
I1026 14:58:35.576177 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 9216/9216
I1026 14:58:35.576182 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 922/8294/9216
I1026 14:58:35.577038 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.577075 20580 inq_conv_layer.cpp:260] Max_power = -3
I1026 14:58:35.577082 20580 inq_conv_layer.cpp:261] Min_power = -9
I1026 14:58:35.577090 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 9.375%)
I1026 14:58:35.577101 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 64/64
I1026 14:58:35.577114 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 6/58/64
I1026 14:58:35.589928 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.592002 20580 inq_conv_layer.cpp:260] Max_power = 0
I1026 14:58:35.592013 20580 inq_conv_layer.cpp:261] Min_power = -6
I1026 14:58:35.592038 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10.0098%)
I1026 14:58:35.592051 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 4096/4096
I1026 14:58:35.592057 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 410/3686/4096
I1026 14:58:35.592417 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.592453 20580 inq_conv_layer.cpp:260] Max_power = -3
I1026 14:58:35.592461 20580 inq_conv_layer.cpp:261] Min_power = -9
I1026 14:58:35.592468 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 9.375%)
I1026 14:58:35.592492 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 32/32
I1026 14:58:35.592497 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 3/29/32
I1026 14:58:35.596027 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.597169 20580 inq_conv_layer.cpp:260] Max_power = -1
I1026 14:58:35.597180 20580 inq_conv_layer.cpp:261] Min_power = -7
I1026 14:58:35.597205 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10.0098%)
I1026 14:58:35.597218 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 4096/4096
I1026 14:58:35.597223 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 410/3686/4096
I1026 14:58:35.597589 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.597623 20580 inq_conv_layer.cpp:260] Max_power = -4
I1026 14:58:35.597630 20580 inq_conv_layer.cpp:261] Min_power = -10
I1026 14:58:35.597640 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10.1562%)
I1026 14:58:35.597651 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 128/128
I1026 14:58:35.597654 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 13/115/128
I1026 14:58:35.601507 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.602284 20580 inq_conv_layer.cpp:260] Max_power = -1
I1026 14:58:35.602294 20580 inq_conv_layer.cpp:261] Min_power = -7
I1026 14:58:35.602541 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 9.99891%)
I1026 14:58:35.602557 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 36864/36864
I1026 14:58:35.602562 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 3686/33178/36864
I1026 14:58:35.606343 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.606384 20580 inq_conv_layer.cpp:260] Max_power = -4
I1026 14:58:35.606390 20580 inq_conv_layer.cpp:261] Min_power = -10
I1026 14:58:35.606400 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10.1562%)
I1026 14:58:35.606411 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 128/128
I1026 14:58:35.606416 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 13/115/128
I1026 14:58:35.613152 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.615180 20580 inq_conv_layer.cpp:260] Max_power = -1
I1026 14:58:35.615190 20580 inq_conv_layer.cpp:261] Min_power = -7
I1026 14:58:35.615231 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 9.99756%)
I1026 14:58:35.615244 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 8192/8192
I1026 14:58:35.615249 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 819/7373/8192
I1026 14:58:35.616015 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.616052 20580 inq_conv_layer.cpp:260] Max_power = -2
I1026 14:58:35.616060 20580 inq_conv_layer.cpp:261] Min_power = -8
I1026 14:58:35.616067 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 9.375%)
I1026 14:58:35.616077 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 32/32
I1026 14:58:35.616092 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 3/29/32
I1026 14:58:35.621366 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.623193 20580 inq_conv_layer.cpp:260] Max_power = -1
I1026 14:58:35.623204 20580 inq_conv_layer.cpp:261] Min_power = -7
I1026 14:58:35.623229 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10.0098%)
I1026 14:58:35.623242 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 4096/4096
I1026 14:58:35.623247 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 410/3686/4096
I1026 14:58:35.623607 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.623646 20580 inq_conv_layer.cpp:260] Max_power = -3
I1026 14:58:35.623654 20580 inq_conv_layer.cpp:261] Min_power = -9
I1026 14:58:35.623663 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10.1562%)
I1026 14:58:35.623687 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 128/128
I1026 14:58:35.623693 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 13/115/128
I1026 14:58:35.627537 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.628314 20580 inq_conv_layer.cpp:260] Max_power = 0
I1026 14:58:35.628324 20580 inq_conv_layer.cpp:261] Min_power = -6
I1026 14:58:35.628489 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 9.99891%)
I1026 14:58:35.628504 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 36864/36864
I1026 14:58:35.628509 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 3686/33178/36864
I1026 14:58:35.632266 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.632310 20580 inq_conv_layer.cpp:260] Max_power = -5
I1026 14:58:35.632319 20580 inq_conv_layer.cpp:261] Min_power = -11
I1026 14:58:35.632329 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10.1562%)
I1026 14:58:35.632340 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 128/128
I1026 14:58:35.632345 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 13/115/128
I1026 14:58:35.642345 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.643283 20580 inq_conv_layer.cpp:260] Max_power = -1
I1026 14:58:35.643293 20580 inq_conv_layer.cpp:261] Min_power = -7
I1026 14:58:35.643353 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10.0016%)
I1026 14:58:35.643373 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 12288/12288
I1026 14:58:35.643378 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 1229/11059/12288
I1026 14:58:35.644539 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.644577 20580 inq_conv_layer.cpp:260] Max_power = -3
I1026 14:58:35.644584 20580 inq_conv_layer.cpp:261] Min_power = -9
I1026 14:58:35.644593 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10.4167%)
I1026 14:58:35.644603 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 48/48
I1026 14:58:35.644608 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 5/43/48
I1026 14:58:35.648402 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.650665 20580 inq_conv_layer.cpp:260] Max_power = -1
I1026 14:58:35.650674 20580 inq_conv_layer.cpp:261] Min_power = -7
I1026 14:58:35.650720 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10.0043%)
I1026 14:58:35.650734 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 9216/9216
I1026 14:58:35.650740 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 922/8294/9216
I1026 14:58:35.651583 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.651620 20580 inq_conv_layer.cpp:260] Max_power = -5
I1026 14:58:35.651628 20580 inq_conv_layer.cpp:261] Min_power = -11
I1026 14:58:35.651636 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 9.89583%)
I1026 14:58:35.651646 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 192/192
I1026 14:58:35.651660 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 19/173/192
I1026 14:58:35.655338 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.656002 20580 inq_conv_layer.cpp:260] Max_power = -1
I1026 14:58:35.656011 20580 inq_conv_layer.cpp:261] Min_power = -7
I1026 14:58:35.656468 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 9.99952%)
I1026 14:58:35.656486 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 82944/82944
I1026 14:58:35.656491 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 8294/74650/82944
I1026 14:58:35.665446 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.665488 20580 inq_conv_layer.cpp:260] Max_power = -5
I1026 14:58:35.665494 20580 inq_conv_layer.cpp:261] Min_power = -11
I1026 14:58:35.665504 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 9.89583%)
I1026 14:58:35.665530 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 192/192
I1026 14:58:35.665535 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 19/173/192
I1026 14:58:35.672035 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.673888 20580 inq_conv_layer.cpp:260] Max_power = -1
I1026 14:58:35.673900 20580 inq_conv_layer.cpp:261] Min_power = -7
I1026 14:58:35.673981 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 9.99891%)
I1026 14:58:35.673996 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 18432/18432
I1026 14:58:35.674001 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 1843/16589/18432
I1026 14:58:35.675815 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.675853 20580 inq_conv_layer.cpp:260] Max_power = -2
I1026 14:58:35.675860 20580 inq_conv_layer.cpp:261] Min_power = -8
I1026 14:58:35.675868 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10.4167%)
I1026 14:58:35.675881 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 48/48
I1026 14:58:35.675886 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 5/43/48
I1026 14:58:35.679497 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.683024 20580 inq_conv_layer.cpp:260] Max_power = -1
I1026 14:58:35.683037 20580 inq_conv_layer.cpp:261] Min_power = -7
I1026 14:58:35.683082 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10.0043%)
I1026 14:58:35.683097 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 9216/9216
I1026 14:58:35.683102 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 922/8294/9216
I1026 14:58:35.683950 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.683986 20580 inq_conv_layer.cpp:260] Max_power = -2
I1026 14:58:35.683993 20580 inq_conv_layer.cpp:261] Min_power = -8
I1026 14:58:35.684002 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 9.89583%)
I1026 14:58:35.684013 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 192/192
I1026 14:58:35.684018 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 19/173/192
I1026 14:58:35.687628 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.688307 20580 inq_conv_layer.cpp:260] Max_power = -1
I1026 14:58:35.688318 20580 inq_conv_layer.cpp:261] Min_power = -7
I1026 14:58:35.688652 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 9.99952%)
I1026 14:58:35.688668 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 82944/82944
I1026 14:58:35.688673 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 8294/74650/82944
I1026 14:58:35.697562 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.697603 20580 inq_conv_layer.cpp:260] Max_power = -4
I1026 14:58:35.697610 20580 inq_conv_layer.cpp:261] Min_power = -10
I1026 14:58:35.697620 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 9.89583%)
I1026 14:58:35.697638 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 192/192
I1026 14:58:35.697643 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 19/173/192
I1026 14:58:35.704102 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.706012 20580 inq_conv_layer.cpp:260] Max_power = -1
I1026 14:58:35.706023 20580 inq_conv_layer.cpp:261] Min_power = -7
I1026 14:58:35.706125 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10.0016%)
I1026 14:58:35.706140 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 24576/24576
I1026 14:58:35.706146 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 2458/22118/24576
I1026 14:58:35.708604 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.708642 20580 inq_conv_layer.cpp:260] Max_power = 3
I1026 14:58:35.708648 20580 inq_conv_layer.cpp:261] Min_power = -3
I1026 14:58:35.708670 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 9.375%)
I1026 14:58:35.708681 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 64/64
I1026 14:58:35.708685 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 6/58/64
I1026 14:58:35.712299 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.715925 20580 inq_conv_layer.cpp:260] Max_power = -1
I1026 14:58:35.715936 20580 inq_conv_layer.cpp:261] Min_power = -7
I1026 14:58:35.716006 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 9.99756%)
I1026 14:58:35.716027 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 16384/16384
I1026 14:58:35.716032 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 1638/14746/16384
I1026 14:58:35.717631 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.717669 20580 inq_conv_layer.cpp:260] Max_power = -1
I1026 14:58:35.717677 20580 inq_conv_layer.cpp:261] Min_power = -7
I1026 14:58:35.717686 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10.1562%)
I1026 14:58:35.717699 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 256/256
I1026 14:58:35.717702 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 26/230/256
I1026 14:58:35.721357 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.722422 20580 inq_conv_layer.cpp:260] Max_power = -1
I1026 14:58:35.722434 20580 inq_conv_layer.cpp:261] Min_power = -7
I1026 14:58:35.723222 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10.0003%)
I1026 14:58:35.723237 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 147456/147456
I1026 14:58:35.723242 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 14746/132710/147456
I1026 14:58:35.739822 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.739861 20580 inq_conv_layer.cpp:260] Max_power = -1
I1026 14:58:35.739869 20580 inq_conv_layer.cpp:261] Min_power = -7
I1026 14:58:35.739879 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10.1562%)
I1026 14:58:35.739890 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 256/256
I1026 14:58:35.739895 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 26/230/256
I1026 14:58:35.747182 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.750571 20580 inq_conv_layer.cpp:260] Max_power = -1
I1026 14:58:35.750582 20580 inq_conv_layer.cpp:261] Min_power = -7
I1026 14:58:35.750710 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10.0006%)
I1026 14:58:35.750727 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 32768/32768
I1026 14:58:35.750732 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 3277/29491/32768
I1026 14:58:35.754029 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.754067 20580 inq_conv_layer.cpp:260] Max_power = 0
I1026 14:58:35.754076 20580 inq_conv_layer.cpp:261] Min_power = -6
I1026 14:58:35.754083 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 9.375%)
I1026 14:58:35.754101 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 64/64
I1026 14:58:35.754106 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 6/58/64
I1026 14:58:35.757745 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.762578 20580 inq_conv_layer.cpp:260] Max_power = -1
I1026 14:58:35.762589 20580 inq_conv_layer.cpp:261] Min_power = -7
I1026 14:58:35.762658 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 9.99756%)
I1026 14:58:35.762679 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 16384/16384
I1026 14:58:35.762684 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 1638/14746/16384
I1026 14:58:35.764261 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.764303 20580 inq_conv_layer.cpp:260] Max_power = -4
I1026 14:58:35.764312 20580 inq_conv_layer.cpp:261] Min_power = -10
I1026 14:58:35.764335 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10.1562%)
I1026 14:58:35.764346 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 256/256
I1026 14:58:35.764351 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 26/230/256
I1026 14:58:35.768049 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.769049 20580 inq_conv_layer.cpp:260] Max_power = -1
I1026 14:58:35.769060 20580 inq_conv_layer.cpp:261] Min_power = -7
I1026 14:58:35.769667 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10.0003%)
I1026 14:58:35.769685 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 147456/147456
I1026 14:58:35.769688 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 14746/132710/147456
I1026 14:58:35.786213 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.786253 20580 inq_conv_layer.cpp:260] Max_power = -5
I1026 14:58:35.786260 20580 inq_conv_layer.cpp:261] Min_power = -11
I1026 14:58:35.786270 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10.1562%)
I1026 14:58:35.786281 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 256/256
I1026 14:58:35.786286 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 26/230/256
I1026 14:58:35.800439 20580 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 14:58:35.802438 20580 inq_conv_layer.cpp:260] Max_power = -2
I1026 14:58:35.802448 20580 inq_conv_layer.cpp:261] Min_power = -8
I1026 14:58:35.804919 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10%)
I1026 14:58:35.804936 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 512000/512000
I1026 14:58:35.804941 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 51200/460800/512000
I1026 14:58:35.867311 20580 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 14:58:35.867354 20580 inq_conv_layer.cpp:260] Max_power = -2
I1026 14:58:35.867362 20580 inq_conv_layer.cpp:261] Min_power = -8
I1026 14:58:35.867377 20580 inq_conv_layer.cpp:304] portions: 0% -> 10% (total: 0% -> 10%)
I1026 14:58:35.867388 20580 inq_conv_layer.cpp:310] init_not_quantized/total: 1000/1000
I1026 14:58:35.867393 20580 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 100/900/1000
I1026 14:58:36.753635 20580 solver.cpp:221] Iteration 0 (-1.67573e-33 iter/s, 32.6628s/40 iters), loss = 3.90116
I1026 14:58:36.753679 20580 solver.cpp:240]     Train net output #0: loss = 3.90116 (* 1 = 3.90116 loss)
I1026 14:58:36.753695 20580 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I1026 14:59:07.683125 20580 solver.cpp:221] Iteration 40 (1.29331 iter/s, 30.9283s/40 iters), loss = 2.48234
I1026 14:59:07.683441 20580 solver.cpp:240]     Train net output #0: loss = 2.48234 (* 1 = 2.48234 loss)
I1026 14:59:07.683461 20580 sgd_solver.cpp:105] Iteration 40, lr = 0.00999765
I1026 14:59:38.785058 20580 solver.cpp:221] Iteration 80 (1.28615 iter/s, 31.1005s/40 iters), loss = 2.30499
I1026 14:59:38.785284 20580 solver.cpp:240]     Train net output #0: loss = 2.30499 (* 1 = 2.30499 loss)
I1026 14:59:38.785322 20580 sgd_solver.cpp:105] Iteration 80, lr = 0.00999529
I1026 15:00:09.829746 20580 solver.cpp:221] Iteration 120 (1.28852 iter/s, 31.0433s/40 iters), loss = 2.17869
I1026 15:00:09.829918 20580 solver.cpp:240]     Train net output #0: loss = 2.17869 (* 1 = 2.17869 loss)
I1026 15:00:09.829936 20580 sgd_solver.cpp:105] Iteration 120, lr = 0.00999294
I1026 15:00:40.816192 20580 solver.cpp:221] Iteration 160 (1.29097 iter/s, 30.9846s/40 iters), loss = 1.8761
I1026 15:00:40.816452 20580 solver.cpp:240]     Train net output #0: loss = 1.8761 (* 1 = 1.8761 loss)
I1026 15:00:40.816471 20580 sgd_solver.cpp:105] Iteration 160, lr = 0.00999059
I1026 15:01:11.642227 20580 solver.cpp:221] Iteration 200 (1.29766 iter/s, 30.8246s/40 iters), loss = 2.0342
I1026 15:01:11.642424 20580 solver.cpp:240]     Train net output #0: loss = 2.0342 (* 1 = 2.0342 loss)
I1026 15:01:11.642442 20580 sgd_solver.cpp:105] Iteration 200, lr = 0.00998824
I1026 15:01:42.559134 20580 solver.cpp:221] Iteration 240 (1.29385 iter/s, 30.9155s/40 iters), loss = 1.86049
I1026 15:01:42.559340 20580 solver.cpp:240]     Train net output #0: loss = 1.86049 (* 1 = 1.86049 loss)
I1026 15:01:42.559360 20580 sgd_solver.cpp:105] Iteration 240, lr = 0.00998588
I1026 15:02:13.468389 20580 solver.cpp:221] Iteration 280 (1.29417 iter/s, 30.9079s/40 iters), loss = 1.92358
I1026 15:02:13.468577 20580 solver.cpp:240]     Train net output #0: loss = 1.92358 (* 1 = 1.92358 loss)
I1026 15:02:13.468600 20580 sgd_solver.cpp:105] Iteration 280, lr = 0.00998353
I1026 15:02:44.379032 20580 solver.cpp:221] Iteration 320 (1.29411 iter/s, 30.9093s/40 iters), loss = 2.15588
I1026 15:02:44.379215 20580 solver.cpp:240]     Train net output #0: loss = 2.15588 (* 1 = 2.15588 loss)
I1026 15:02:44.379237 20580 sgd_solver.cpp:105] Iteration 320, lr = 0.00998118
I1026 15:03:15.009927 20580 solver.cpp:221] Iteration 360 (1.30593 iter/s, 30.6296s/40 iters), loss = 2.00828
I1026 15:03:15.010100 20580 solver.cpp:240]     Train net output #0: loss = 2.00828 (* 1 = 2.00828 loss)
I1026 15:03:15.010118 20580 sgd_solver.cpp:105] Iteration 360, lr = 0.00997882
I1026 15:03:45.621320 20580 solver.cpp:221] Iteration 400 (1.30676 iter/s, 30.6101s/40 iters), loss = 2.01457
I1026 15:03:45.621479 20580 solver.cpp:240]     Train net output #0: loss = 2.01457 (* 1 = 2.01457 loss)
I1026 15:03:45.621496 20580 sgd_solver.cpp:105] Iteration 400, lr = 0.00997647
I1026 15:04:16.391499 20580 solver.cpp:221] Iteration 440 (1.30002 iter/s, 30.7689s/40 iters), loss = 1.98103
I1026 15:04:16.391670 20580 solver.cpp:240]     Train net output #0: loss = 1.98103 (* 1 = 1.98103 loss)
I1026 15:04:16.391691 20580 sgd_solver.cpp:105] Iteration 440, lr = 0.00997412
I1026 15:04:47.017554 20580 solver.cpp:221] Iteration 480 (1.30613 iter/s, 30.6247s/40 iters), loss = 1.83677
I1026 15:04:47.017724 20580 solver.cpp:240]     Train net output #0: loss = 1.83677 (* 1 = 1.83677 loss)
I1026 15:04:47.017742 20580 sgd_solver.cpp:105] Iteration 480, lr = 0.00997176
I1026 15:05:01.629511 20580 solver.cpp:333] Iteration 500, Testing net (#0)
I1026 15:05:32.612782 20630 data_layer.cpp:73] Restarting data prefetching from start.
I1026 15:05:32.819051 20580 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.49848
I1026 15:05:32.819099 20580 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.75084
I1026 15:05:32.819113 20580 solver.cpp:400]     Test net output #2: loss = 2.22246 (* 1 = 2.22246 loss)
I1026 15:05:48.867702 20580 solver.cpp:221] Iteration 520 (0.646751 iter/s, 61.8477s/40 iters), loss = 1.98951
I1026 15:05:48.867776 20580 solver.cpp:240]     Train net output #0: loss = 1.98951 (* 1 = 1.98951 loss)
I1026 15:05:48.867797 20580 sgd_solver.cpp:105] Iteration 520, lr = 0.00996941
I1026 15:06:19.781198 20580 solver.cpp:221] Iteration 560 (1.29399 iter/s, 30.9123s/40 iters), loss = 2.42721
I1026 15:06:19.781392 20580 solver.cpp:240]     Train net output #0: loss = 2.42721 (* 1 = 2.42721 loss)
I1026 15:06:19.781411 20580 sgd_solver.cpp:105] Iteration 560, lr = 0.00996706
I1026 15:06:50.539520 20580 solver.cpp:221] Iteration 600 (1.30052 iter/s, 30.7569s/40 iters), loss = 1.97887
I1026 15:06:50.539737 20580 solver.cpp:240]     Train net output #0: loss = 1.97887 (* 1 = 1.97887 loss)
I1026 15:06:50.539759 20580 sgd_solver.cpp:105] Iteration 600, lr = 0.00996471
I1026 15:07:21.046470 20580 solver.cpp:221] Iteration 640 (1.31124 iter/s, 30.5056s/40 iters), loss = 1.81269
I1026 15:07:21.046635 20580 solver.cpp:240]     Train net output #0: loss = 1.81269 (* 1 = 1.81269 loss)
I1026 15:07:21.046658 20580 sgd_solver.cpp:105] Iteration 640, lr = 0.00996235
I1026 15:07:51.530529 20580 solver.cpp:221] Iteration 680 (1.31222 iter/s, 30.4827s/40 iters), loss = 2.11018
I1026 15:07:51.530720 20580 solver.cpp:240]     Train net output #0: loss = 2.11018 (* 1 = 2.11018 loss)
I1026 15:07:51.530741 20580 sgd_solver.cpp:105] Iteration 680, lr = 0.00996
I1026 15:08:22.080449 20580 solver.cpp:221] Iteration 720 (1.30939 iter/s, 30.5486s/40 iters), loss = 2.02818
I1026 15:08:22.080662 20580 solver.cpp:240]     Train net output #0: loss = 2.02818 (* 1 = 2.02818 loss)
I1026 15:08:22.080683 20580 sgd_solver.cpp:105] Iteration 720, lr = 0.00995765
I1026 15:08:52.631718 20580 solver.cpp:221] Iteration 760 (1.30933 iter/s, 30.5499s/40 iters), loss = 2.12811
I1026 15:08:52.631898 20580 solver.cpp:240]     Train net output #0: loss = 2.12811 (* 1 = 2.12811 loss)
I1026 15:08:52.631916 20580 sgd_solver.cpp:105] Iteration 760, lr = 0.00995529
I1026 15:09:23.752104 20580 solver.cpp:221] Iteration 800 (1.28539 iter/s, 31.119s/40 iters), loss = 1.86146
I1026 15:09:23.752336 20580 solver.cpp:240]     Train net output #0: loss = 1.86146 (* 1 = 1.86146 loss)
I1026 15:09:23.752360 20580 sgd_solver.cpp:105] Iteration 800, lr = 0.00995294
I1026 15:09:54.425292 20580 solver.cpp:221] Iteration 840 (1.30413 iter/s, 30.6718s/40 iters), loss = 2.10663
I1026 15:09:54.425482 20580 solver.cpp:240]     Train net output #0: loss = 2.10663 (* 1 = 2.10663 loss)
I1026 15:09:54.425503 20580 sgd_solver.cpp:105] Iteration 840, lr = 0.00995059
I1026 15:10:25.183100 20580 solver.cpp:221] Iteration 880 (1.30054 iter/s, 30.7565s/40 iters), loss = 2.12891
I1026 15:10:25.183311 20580 solver.cpp:240]     Train net output #0: loss = 2.12891 (* 1 = 2.12891 loss)
I1026 15:10:25.183332 20580 sgd_solver.cpp:105] Iteration 880, lr = 0.00994824
I1026 15:10:56.163554 20580 solver.cpp:221] Iteration 920 (1.29119 iter/s, 30.9791s/40 iters), loss = 1.94067
I1026 15:10:56.163733 20580 solver.cpp:240]     Train net output #0: loss = 1.94067 (* 1 = 1.94067 loss)
I1026 15:10:56.163755 20580 sgd_solver.cpp:105] Iteration 920, lr = 0.00994588
I1026 15:11:26.930402 20580 solver.cpp:221] Iteration 960 (1.30016 iter/s, 30.7655s/40 iters), loss = 1.94945
I1026 15:11:26.930558 20580 solver.cpp:240]     Train net output #0: loss = 1.94945 (* 1 = 1.94945 loss)
I1026 15:11:26.930578 20580 sgd_solver.cpp:105] Iteration 960, lr = 0.00994353
I1026 15:11:56.714543 20580 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_10_iter_1000.caffemodel
I1026 15:11:56.903699 20580 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_10_iter_1000.solverstate
I1026 15:11:56.923085 20580 solver.cpp:333] Iteration 1000, Testing net (#0)
I1026 15:12:28.251971 20580 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.49744
I1026 15:12:28.252130 20580 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.74636
I1026 15:12:28.252146 20580 solver.cpp:400]     Test net output #2: loss = 2.30063 (* 1 = 2.30063 loss)
I1026 15:12:29.016006 20580 solver.cpp:221] Iteration 1000 (0.644297 iter/s, 62.0831s/40 iters), loss = 1.43527
I1026 15:12:29.016052 20580 solver.cpp:240]     Train net output #0: loss = 1.43527 (* 1 = 1.43527 loss)
I1026 15:12:29.016072 20580 sgd_solver.cpp:105] Iteration 1000, lr = 0.00994118
I1026 15:12:59.807665 20580 solver.cpp:221] Iteration 1040 (1.2991 iter/s, 30.7904s/40 iters), loss = 2.27937
I1026 15:12:59.807929 20580 solver.cpp:240]     Train net output #0: loss = 2.27937 (* 1 = 2.27937 loss)
I1026 15:12:59.807957 20580 sgd_solver.cpp:105] Iteration 1040, lr = 0.00993882
I1026 15:13:30.678894 20580 solver.cpp:221] Iteration 1080 (1.29576 iter/s, 30.8698s/40 iters), loss = 2.19905
I1026 15:13:30.679075 20580 solver.cpp:240]     Train net output #0: loss = 2.19905 (* 1 = 2.19905 loss)
I1026 15:13:30.679095 20580 sgd_solver.cpp:105] Iteration 1080, lr = 0.00993647
I1026 15:14:01.349148 20580 solver.cpp:221] Iteration 1120 (1.30425 iter/s, 30.6689s/40 iters), loss = 1.98027
I1026 15:14:01.349319 20580 solver.cpp:240]     Train net output #0: loss = 1.98027 (* 1 = 1.98027 loss)
I1026 15:14:01.349337 20580 sgd_solver.cpp:105] Iteration 1120, lr = 0.00993412
I1026 15:14:31.956387 20580 solver.cpp:221] Iteration 1160 (1.30694 iter/s, 30.6059s/40 iters), loss = 1.85588
I1026 15:14:31.956568 20580 solver.cpp:240]     Train net output #0: loss = 1.85588 (* 1 = 1.85588 loss)
I1026 15:14:31.956585 20580 sgd_solver.cpp:105] Iteration 1160, lr = 0.00993176
I1026 15:15:02.681219 20580 solver.cpp:221] Iteration 1200 (1.30194 iter/s, 30.7235s/40 iters), loss = 1.65834
I1026 15:15:02.681388 20580 solver.cpp:240]     Train net output #0: loss = 1.65834 (* 1 = 1.65834 loss)
I1026 15:15:02.681406 20580 sgd_solver.cpp:105] Iteration 1200, lr = 0.00992941
I1026 15:15:33.299805 20580 solver.cpp:221] Iteration 1240 (1.30645 iter/s, 30.6173s/40 iters), loss = 1.86534
I1026 15:15:33.299969 20580 solver.cpp:240]     Train net output #0: loss = 1.86534 (* 1 = 1.86534 loss)
I1026 15:15:33.299988 20580 sgd_solver.cpp:105] Iteration 1240, lr = 0.00992706
I1026 15:16:04.142395 20580 solver.cpp:221] Iteration 1280 (1.29696 iter/s, 30.8413s/40 iters), loss = 1.82678
I1026 15:16:04.142624 20580 solver.cpp:240]     Train net output #0: loss = 1.82678 (* 1 = 1.82678 loss)
I1026 15:16:04.142643 20580 sgd_solver.cpp:105] Iteration 1280, lr = 0.00992471
I1026 15:16:34.585553 20580 solver.cpp:221] Iteration 1320 (1.31398 iter/s, 30.4418s/40 iters), loss = 2.04682
I1026 15:16:34.585788 20580 solver.cpp:240]     Train net output #0: loss = 2.04682 (* 1 = 2.04682 loss)
I1026 15:16:34.585810 20580 sgd_solver.cpp:105] Iteration 1320, lr = 0.00992235
I1026 15:17:04.898653 20580 solver.cpp:221] Iteration 1360 (1.31962 iter/s, 30.3117s/40 iters), loss = 2.10253
I1026 15:17:04.898877 20580 solver.cpp:240]     Train net output #0: loss = 2.10253 (* 1 = 2.10253 loss)
I1026 15:17:04.898896 20580 sgd_solver.cpp:105] Iteration 1360, lr = 0.00992
I1026 15:17:35.702432 20580 solver.cpp:221] Iteration 1400 (1.2986 iter/s, 30.8024s/40 iters), loss = 1.85144
I1026 15:17:35.702628 20580 solver.cpp:240]     Train net output #0: loss = 1.85144 (* 1 = 1.85144 loss)
I1026 15:17:35.702647 20580 sgd_solver.cpp:105] Iteration 1400, lr = 0.00991765
I1026 15:18:06.644243 20580 solver.cpp:221] Iteration 1440 (1.29281 iter/s, 30.9404s/40 iters), loss = 1.99742
I1026 15:18:06.644448 20580 solver.cpp:240]     Train net output #0: loss = 1.99742 (* 1 = 1.99742 loss)
I1026 15:18:06.644467 20580 sgd_solver.cpp:105] Iteration 1440, lr = 0.00991529
I1026 15:18:37.596706 20580 solver.cpp:221] Iteration 1480 (1.29236 iter/s, 30.9511s/40 iters), loss = 2.20269
I1026 15:18:37.596925 20580 solver.cpp:240]     Train net output #0: loss = 2.20269 (* 1 = 2.20269 loss)
I1026 15:18:37.596947 20580 sgd_solver.cpp:105] Iteration 1480, lr = 0.00991294
I1026 15:18:52.210145 20580 solver.cpp:333] Iteration 1500, Testing net (#0)
I1026 15:19:23.234015 20630 data_layer.cpp:73] Restarting data prefetching from start.
I1026 15:19:23.445660 20580 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.51328
I1026 15:19:23.445704 20580 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76168
I1026 15:19:23.445719 20580 solver.cpp:400]     Test net output #2: loss = 2.17242 (* 1 = 2.17242 loss)
I1026 15:19:39.450960 20580 solver.cpp:221] Iteration 1520 (0.646708 iter/s, 61.8517s/40 iters), loss = 2.1982
I1026 15:19:39.451010 20580 solver.cpp:240]     Train net output #0: loss = 2.1982 (* 1 = 2.1982 loss)
I1026 15:19:39.451027 20580 sgd_solver.cpp:105] Iteration 1520, lr = 0.00991059
I1026 15:20:09.855546 20580 solver.cpp:221] Iteration 1560 (1.31564 iter/s, 30.4034s/40 iters), loss = 2.00182
I1026 15:20:09.855792 20580 solver.cpp:240]     Train net output #0: loss = 2.00182 (* 1 = 2.00182 loss)
I1026 15:20:09.855813 20580 sgd_solver.cpp:105] Iteration 1560, lr = 0.00990823
I1026 15:20:40.477560 20580 solver.cpp:221] Iteration 1600 (1.30631 iter/s, 30.6206s/40 iters), loss = 2.10705
I1026 15:20:40.477785 20580 solver.cpp:240]     Train net output #0: loss = 2.10705 (* 1 = 2.10705 loss)
I1026 15:20:40.477804 20580 sgd_solver.cpp:105] Iteration 1600, lr = 0.00990588
I1026 15:21:11.220508 20580 solver.cpp:221] Iteration 1640 (1.30117 iter/s, 30.7416s/40 iters), loss = 1.86228
I1026 15:21:11.220708 20580 solver.cpp:240]     Train net output #0: loss = 1.86228 (* 1 = 1.86228 loss)
I1026 15:21:11.220726 20580 sgd_solver.cpp:105] Iteration 1640, lr = 0.00990353
I1026 15:21:41.776540 20580 solver.cpp:221] Iteration 1680 (1.30913 iter/s, 30.5547s/40 iters), loss = 1.87497
I1026 15:21:41.776739 20580 solver.cpp:240]     Train net output #0: loss = 1.87497 (* 1 = 1.87497 loss)
I1026 15:21:41.776757 20580 sgd_solver.cpp:105] Iteration 1680, lr = 0.00990118
I1026 15:22:13.093621 20580 solver.cpp:221] Iteration 1720 (1.27731 iter/s, 31.3157s/40 iters), loss = 1.84497
I1026 15:22:13.093788 20580 solver.cpp:240]     Train net output #0: loss = 1.84497 (* 1 = 1.84497 loss)
I1026 15:22:13.093807 20580 sgd_solver.cpp:105] Iteration 1720, lr = 0.00989882
I1026 15:22:44.169019 20580 solver.cpp:221] Iteration 1760 (1.28725 iter/s, 31.0741s/40 iters), loss = 1.98454
I1026 15:22:44.169231 20580 solver.cpp:240]     Train net output #0: loss = 1.98454 (* 1 = 1.98454 loss)
I1026 15:22:44.169256 20580 sgd_solver.cpp:105] Iteration 1760, lr = 0.00989647
I1026 15:23:15.148337 20580 solver.cpp:221] Iteration 1800 (1.29124 iter/s, 30.9779s/40 iters), loss = 2.33876
I1026 15:23:15.148486 20580 solver.cpp:240]     Train net output #0: loss = 2.33876 (* 1 = 2.33876 loss)
I1026 15:23:15.148504 20580 sgd_solver.cpp:105] Iteration 1800, lr = 0.00989412
I1026 15:23:45.892002 20580 solver.cpp:221] Iteration 1840 (1.30114 iter/s, 30.7423s/40 iters), loss = 1.95227
I1026 15:23:45.892174 20580 solver.cpp:240]     Train net output #0: loss = 1.95227 (* 1 = 1.95227 loss)
I1026 15:23:45.892196 20580 sgd_solver.cpp:105] Iteration 1840, lr = 0.00989176
I1026 15:24:17.187177 20580 solver.cpp:221] Iteration 1880 (1.27821 iter/s, 31.2938s/40 iters), loss = 1.90704
I1026 15:24:17.187425 20580 solver.cpp:240]     Train net output #0: loss = 1.90704 (* 1 = 1.90704 loss)
I1026 15:24:17.187453 20580 sgd_solver.cpp:105] Iteration 1880, lr = 0.00988941
I1026 15:24:50.101538 20580 solver.cpp:221] Iteration 1920 (1.21533 iter/s, 32.9129s/40 iters), loss = 2.04495
I1026 15:24:50.101810 20580 solver.cpp:240]     Train net output #0: loss = 2.04495 (* 1 = 2.04495 loss)
I1026 15:24:50.101836 20580 sgd_solver.cpp:105] Iteration 1920, lr = 0.00988706
I1026 15:25:20.912936 20580 solver.cpp:221] Iteration 1960 (1.29828 iter/s, 30.81s/40 iters), loss = 1.86185
I1026 15:25:20.913154 20580 solver.cpp:240]     Train net output #0: loss = 1.86185 (* 1 = 1.86185 loss)
I1026 15:25:20.913175 20580 sgd_solver.cpp:105] Iteration 1960, lr = 0.00988471
I1026 15:25:50.556340 20580 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_10_iter_2000.caffemodel
I1026 15:25:50.597827 20580 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_10_iter_2000.solverstate
I1026 15:25:50.617498 20580 solver.cpp:333] Iteration 2000, Testing net (#0)
I1026 15:26:21.798943 20580 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.51088
I1026 15:26:21.799165 20580 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.75772
I1026 15:26:21.799183 20580 solver.cpp:400]     Test net output #2: loss = 2.17662 (* 1 = 2.17662 loss)
I1026 15:26:22.565094 20580 solver.cpp:221] Iteration 2000 (0.648828 iter/s, 61.6496s/40 iters), loss = 1.62493
I1026 15:26:22.565166 20580 solver.cpp:240]     Train net output #0: loss = 1.62493 (* 1 = 1.62493 loss)
I1026 15:26:22.565201 20580 sgd_solver.cpp:105] Iteration 2000, lr = 0.00988235
I1026 15:26:53.329529 20580 solver.cpp:221] Iteration 2040 (1.30025 iter/s, 30.7632s/40 iters), loss = 2.24066
I1026 15:26:53.329757 20580 solver.cpp:240]     Train net output #0: loss = 2.24066 (* 1 = 2.24066 loss)
I1026 15:26:53.329777 20580 sgd_solver.cpp:105] Iteration 2040, lr = 0.00988
I1026 15:27:23.969671 20580 solver.cpp:221] Iteration 2080 (1.30554 iter/s, 30.6387s/40 iters), loss = 2.11699
I1026 15:27:23.969851 20580 solver.cpp:240]     Train net output #0: loss = 2.11699 (* 1 = 2.11699 loss)
I1026 15:27:23.969868 20580 sgd_solver.cpp:105] Iteration 2080, lr = 0.00987765
I1026 15:27:54.592475 20580 solver.cpp:221] Iteration 2120 (1.30627 iter/s, 30.6215s/40 iters), loss = 1.70931
I1026 15:27:54.592675 20580 solver.cpp:240]     Train net output #0: loss = 1.70931 (* 1 = 1.70931 loss)
I1026 15:27:54.592694 20580 sgd_solver.cpp:105] Iteration 2120, lr = 0.00987529
I1026 15:28:25.605675 20580 solver.cpp:221] Iteration 2160 (1.28983 iter/s, 31.0118s/40 iters), loss = 1.82007
I1026 15:28:25.605875 20580 solver.cpp:240]     Train net output #0: loss = 1.82007 (* 1 = 1.82007 loss)
I1026 15:28:25.605896 20580 sgd_solver.cpp:105] Iteration 2160, lr = 0.00987294
I1026 15:28:56.795056 20580 solver.cpp:221] Iteration 2200 (1.28254 iter/s, 31.188s/40 iters), loss = 2.09628
I1026 15:28:56.795264 20580 solver.cpp:240]     Train net output #0: loss = 2.09628 (* 1 = 2.09628 loss)
I1026 15:28:56.795287 20580 sgd_solver.cpp:105] Iteration 2200, lr = 0.00987059
I1026 15:29:27.689806 20580 solver.cpp:221] Iteration 2240 (1.29478 iter/s, 30.8934s/40 iters), loss = 2.0406
I1026 15:29:27.690002 20580 solver.cpp:240]     Train net output #0: loss = 2.0406 (* 1 = 2.0406 loss)
I1026 15:29:27.690021 20580 sgd_solver.cpp:105] Iteration 2240, lr = 0.00986824
I1026 15:29:58.560757 20580 solver.cpp:221] Iteration 2280 (1.29577 iter/s, 30.8696s/40 iters), loss = 1.7004
I1026 15:29:58.560936 20580 solver.cpp:240]     Train net output #0: loss = 1.7004 (* 1 = 1.7004 loss)
I1026 15:29:58.560957 20580 sgd_solver.cpp:105] Iteration 2280, lr = 0.00986588
I1026 15:30:29.399926 20580 solver.cpp:221] Iteration 2320 (1.29711 iter/s, 30.8378s/40 iters), loss = 1.99154
I1026 15:30:29.400106 20580 solver.cpp:240]     Train net output #0: loss = 1.99154 (* 1 = 1.99154 loss)
I1026 15:30:29.400125 20580 sgd_solver.cpp:105] Iteration 2320, lr = 0.00986353
I1026 15:31:00.154031 20580 solver.cpp:221] Iteration 2360 (1.3007 iter/s, 30.7527s/40 iters), loss = 1.8578
I1026 15:31:00.154202 20580 solver.cpp:240]     Train net output #0: loss = 1.8578 (* 1 = 1.8578 loss)
I1026 15:31:00.154224 20580 sgd_solver.cpp:105] Iteration 2360, lr = 0.00986118
I1026 15:31:30.965456 20580 solver.cpp:221] Iteration 2400 (1.29828 iter/s, 30.8101s/40 iters), loss = 1.79413
I1026 15:31:30.965651 20580 solver.cpp:240]     Train net output #0: loss = 1.79413 (* 1 = 1.79413 loss)
I1026 15:31:30.965673 20580 sgd_solver.cpp:105] Iteration 2400, lr = 0.00985882
I1026 15:32:01.932729 20580 solver.cpp:221] Iteration 2440 (1.29174 iter/s, 30.9659s/40 iters), loss = 2.46505
I1026 15:32:01.932924 20580 solver.cpp:240]     Train net output #0: loss = 2.46505 (* 1 = 2.46505 loss)
I1026 15:32:01.932942 20580 sgd_solver.cpp:105] Iteration 2440, lr = 0.00985647
I1026 15:32:32.801842 20580 solver.cpp:221] Iteration 2480 (1.29585 iter/s, 30.8678s/40 iters), loss = 2.1094
I1026 15:32:32.802019 20580 solver.cpp:240]     Train net output #0: loss = 2.1094 (* 1 = 2.1094 loss)
I1026 15:32:32.802037 20580 sgd_solver.cpp:105] Iteration 2480, lr = 0.00985412
I1026 15:32:46.714471 20629 data_layer.cpp:73] Restarting data prefetching from start.
I1026 15:32:47.409332 20580 solver.cpp:333] Iteration 2500, Testing net (#0)
I1026 15:33:17.216892 20580 solver.cpp:382] Test interrupted.
I1026 15:33:17.217069 20580 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_10_iter_2500.caffemodel
I1026 15:33:17.254531 20580 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_10_iter_2500.solverstate
I1026 15:33:17.279984 20580 solver.cpp:297] Optimization stopped early.
*** Aborted at 1509046623 (unix time) try "date -d @1509046623" if you are using GNU date ***
PC: @     0x7f04ca564705 __pthread_cond_wait
*** SIGTERM (@0x3ed00004f84) received by PID 20580 (TID 0x7f04dd5df740) from PID 20356; stack trace: ***
    @     0x7f04ca568130 (unknown)
    @     0x7f04ca564705 __pthread_cond_wait
    @     0x7f04dc8b8b34 boost::condition_variable::wait()
    @     0x7f04d2e2e8d4 boost::thread::join_noexcept()
    @     0x7f04dc8a3aca caffe::InternalThread::StopInternalThread()
    @     0x7f04dc8bc632 caffe::NCCL<>::Run()
    @           0x40adef train()
    @           0x4082ec main
    @     0x7f04ca1b9af5 __libc_start_main
    @           0x408bf5 (unknown)
nohup: ignoring input
I1027 09:56:03.987077 38132 caffe.cpp:218] Using GPUs 0, 1, 2, 3
I1027 09:56:03.988242 38132 caffe.cpp:223] GPU 0: Tesla P40
I1027 09:56:03.988652 38132 caffe.cpp:223] GPU 1: Tesla P40
I1027 09:56:03.989044 38132 caffe.cpp:223] GPU 2: Tesla P40
I1027 09:56:03.989439 38132 caffe.cpp:223] GPU 3: Tesla P40
I1027 09:56:05.029597 38132 solver.cpp:44] Initializing solver from parameters: 
test_iter: 500
test_interval: 500
base_lr: 0.01
display: 40
max_iter: 170000
lr_policy: "poly"
power: 1.2
momentum: 0.9
weight_decay: 0.0002
snapshot: 1000
snapshot_prefix: "SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_10"
solver_mode: GPU
device_id: 0
random_seed: 42
net: "SqueezeNet/SqueezeNet_v1.1/train_val_inq_0.prototxt"
train_state {
  level: 0
  stage: ""
}
I1027 09:56:05.029939 38132 solver.cpp:87] Creating training net from net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_0.prototxt
I1027 09:56:05.032935 38132 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1027 09:56:05.033046 38132 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top1
I1027 09:56:05.033069 38132 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top5
I1027 09:56:05.034240 38132 net.cpp:51] Initializing net from parameters: 
name: "SqueezeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/data/caffe-imagenet/ilsvrc12_train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "INQConvolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "fire3/concat"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire4/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool3"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "fire5/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire4/concat"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "fire5/concat"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire6/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool5"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "fire9/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire8/concat"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "INQConvolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "pool10"
  bottom: "label"
  top: "loss"
}
I1027 09:56:05.034898 38132 layer_factory.hpp:77] Creating layer data
I1027 09:56:05.041273 38132 db_lmdb.cpp:35] Opened lmdb /home/data/caffe-imagenet/ilsvrc12_train_lmdb
I1027 09:56:05.041376 38132 net.cpp:84] Creating Layer data
I1027 09:56:05.041407 38132 net.cpp:387] data -> data
I1027 09:56:05.041455 38132 net.cpp:387] data -> label
I1027 09:56:05.044122 38132 data_layer.cpp:45] output data size: 128,3,227,227
I1027 09:56:05.267474 38132 net.cpp:127] Setting up data
I1027 09:56:05.267529 38132 net.cpp:136] Top shape: 128 3 227 227 (19787136)
I1027 09:56:05.267540 38132 net.cpp:136] Top shape: 128 (128)
I1027 09:56:05.267547 38132 net.cpp:144] Memory required for data: 79149056
I1027 09:56:05.267566 38132 layer_factory.hpp:77] Creating layer conv1
I1027 09:56:05.267601 38132 net.cpp:84] Creating Layer conv1
I1027 09:56:05.267614 38132 net.cpp:413] conv1 <- data
I1027 09:56:05.267639 38132 net.cpp:387] conv1 -> conv1
I1027 09:56:05.271195 38132 net.cpp:127] Setting up conv1
I1027 09:56:05.271219 38132 net.cpp:136] Top shape: 128 64 113 113 (104603648)
I1027 09:56:05.271227 38132 net.cpp:144] Memory required for data: 497563648
I1027 09:56:05.271251 38132 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1027 09:56:05.271268 38132 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1027 09:56:05.271281 38132 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1027 09:56:05.271289 38132 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1027 09:56:05.271314 38132 layer_factory.hpp:77] Creating layer relu_conv1
I1027 09:56:05.271342 38132 net.cpp:84] Creating Layer relu_conv1
I1027 09:56:05.271350 38132 net.cpp:413] relu_conv1 <- conv1
I1027 09:56:05.271360 38132 net.cpp:374] relu_conv1 -> conv1 (in-place)
I1027 09:56:06.197983 38132 net.cpp:127] Setting up relu_conv1
I1027 09:56:06.198041 38132 net.cpp:136] Top shape: 128 64 113 113 (104603648)
I1027 09:56:06.198055 38132 net.cpp:144] Memory required for data: 915978240
I1027 09:56:06.198070 38132 layer_factory.hpp:77] Creating layer pool1
I1027 09:56:06.198096 38132 net.cpp:84] Creating Layer pool1
I1027 09:56:06.198106 38132 net.cpp:413] pool1 <- conv1
I1027 09:56:06.198117 38132 net.cpp:387] pool1 -> pool1
I1027 09:56:06.198216 38132 net.cpp:127] Setting up pool1
I1027 09:56:06.198230 38132 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 09:56:06.198236 38132 net.cpp:144] Memory required for data: 1018738688
I1027 09:56:06.198276 38132 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I1027 09:56:06.198318 38132 net.cpp:84] Creating Layer fire2/squeeze1x1
I1027 09:56:06.198329 38132 net.cpp:413] fire2/squeeze1x1 <- pool1
I1027 09:56:06.198343 38132 net.cpp:387] fire2/squeeze1x1 -> fire2/squeeze1x1
I1027 09:56:06.201002 38132 net.cpp:127] Setting up fire2/squeeze1x1
I1027 09:56:06.201040 38132 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1027 09:56:06.201051 38132 net.cpp:144] Memory required for data: 1044428800
I1027 09:56:06.201071 38132 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1027 09:56:06.201090 38132 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1027 09:56:06.201104 38132 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1027 09:56:06.201118 38132 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1027 09:56:06.201128 38132 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I1027 09:56:06.201148 38132 net.cpp:84] Creating Layer fire2/relu_squeeze1x1
I1027 09:56:06.201160 38132 net.cpp:413] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I1027 09:56:06.201175 38132 net.cpp:374] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I1027 09:56:06.203585 38132 net.cpp:127] Setting up fire2/relu_squeeze1x1
I1027 09:56:06.203616 38132 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1027 09:56:06.203626 38132 net.cpp:144] Memory required for data: 1070118912
I1027 09:56:06.203642 38132 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1027 09:56:06.203665 38132 net.cpp:84] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1027 09:56:06.203678 38132 net.cpp:413] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I1027 09:56:06.203696 38132 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1027 09:56:06.203716 38132 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1027 09:56:06.203804 38132 net.cpp:127] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1027 09:56:06.203819 38132 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1027 09:56:06.203832 38132 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1027 09:56:06.203841 38132 net.cpp:144] Memory required for data: 1121499136
I1027 09:56:06.203851 38132 layer_factory.hpp:77] Creating layer fire2/expand1x1
I1027 09:56:06.203876 38132 net.cpp:84] Creating Layer fire2/expand1x1
I1027 09:56:06.203888 38132 net.cpp:413] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1027 09:56:06.203902 38132 net.cpp:387] fire2/expand1x1 -> fire2/expand1x1
I1027 09:56:06.204509 38132 net.cpp:127] Setting up fire2/expand1x1
I1027 09:56:06.204530 38132 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 09:56:06.204540 38132 net.cpp:144] Memory required for data: 1224259584
I1027 09:56:06.204560 38132 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1027 09:56:06.204591 38132 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1027 09:56:06.204603 38132 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1027 09:56:06.204618 38132 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1027 09:56:06.204629 38132 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I1027 09:56:06.204649 38132 net.cpp:84] Creating Layer fire2/relu_expand1x1
I1027 09:56:06.204663 38132 net.cpp:413] fire2/relu_expand1x1 <- fire2/expand1x1
I1027 09:56:06.204679 38132 net.cpp:374] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I1027 09:56:06.205040 38132 net.cpp:127] Setting up fire2/relu_expand1x1
I1027 09:56:06.205060 38132 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 09:56:06.205071 38132 net.cpp:144] Memory required for data: 1327020032
I1027 09:56:06.205082 38132 layer_factory.hpp:77] Creating layer fire2/expand3x3
I1027 09:56:06.205121 38132 net.cpp:84] Creating Layer fire2/expand3x3
I1027 09:56:06.205133 38132 net.cpp:413] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1027 09:56:06.205152 38132 net.cpp:387] fire2/expand3x3 -> fire2/expand3x3
I1027 09:56:06.205878 38132 net.cpp:127] Setting up fire2/expand3x3
I1027 09:56:06.205900 38132 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 09:56:06.205912 38132 net.cpp:144] Memory required for data: 1429780480
I1027 09:56:06.205927 38132 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1027 09:56:06.205941 38132 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1027 09:56:06.205956 38132 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1027 09:56:06.205968 38132 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1027 09:56:06.205981 38132 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I1027 09:56:06.205996 38132 net.cpp:84] Creating Layer fire2/relu_expand3x3
I1027 09:56:06.206007 38132 net.cpp:413] fire2/relu_expand3x3 <- fire2/expand3x3
I1027 09:56:06.206022 38132 net.cpp:374] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I1027 09:56:06.206372 38132 net.cpp:127] Setting up fire2/relu_expand3x3
I1027 09:56:06.206393 38132 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 09:56:06.206403 38132 net.cpp:144] Memory required for data: 1532540928
I1027 09:56:06.206413 38132 layer_factory.hpp:77] Creating layer fire2/concat
I1027 09:56:06.206430 38132 net.cpp:84] Creating Layer fire2/concat
I1027 09:56:06.206445 38132 net.cpp:413] fire2/concat <- fire2/expand1x1
I1027 09:56:06.206456 38132 net.cpp:413] fire2/concat <- fire2/expand3x3
I1027 09:56:06.206470 38132 net.cpp:387] fire2/concat -> fire2/concat
I1027 09:56:06.206528 38132 net.cpp:127] Setting up fire2/concat
I1027 09:56:06.206543 38132 net.cpp:136] Top shape: 128 128 56 56 (51380224)
I1027 09:56:06.206553 38132 net.cpp:144] Memory required for data: 1738061824
I1027 09:56:06.206562 38132 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I1027 09:56:06.206580 38132 net.cpp:84] Creating Layer fire3/squeeze1x1
I1027 09:56:06.206591 38132 net.cpp:413] fire3/squeeze1x1 <- fire2/concat
I1027 09:56:06.206605 38132 net.cpp:387] fire3/squeeze1x1 -> fire3/squeeze1x1
I1027 09:56:06.207171 38132 net.cpp:127] Setting up fire3/squeeze1x1
I1027 09:56:06.207190 38132 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1027 09:56:06.207202 38132 net.cpp:144] Memory required for data: 1763751936
I1027 09:56:06.207219 38132 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1027 09:56:06.207237 38132 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1027 09:56:06.207249 38132 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1027 09:56:06.207262 38132 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1027 09:56:06.207271 38132 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I1027 09:56:06.207284 38132 net.cpp:84] Creating Layer fire3/relu_squeeze1x1
I1027 09:56:06.207315 38132 net.cpp:413] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I1027 09:56:06.207334 38132 net.cpp:374] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I1027 09:56:06.209542 38132 net.cpp:127] Setting up fire3/relu_squeeze1x1
I1027 09:56:06.209571 38132 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1027 09:56:06.209584 38132 net.cpp:144] Memory required for data: 1789442048
I1027 09:56:06.209597 38132 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1027 09:56:06.209614 38132 net.cpp:84] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1027 09:56:06.209625 38132 net.cpp:413] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I1027 09:56:06.209640 38132 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1027 09:56:06.209657 38132 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1027 09:56:06.209754 38132 net.cpp:127] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1027 09:56:06.209769 38132 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1027 09:56:06.209782 38132 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1027 09:56:06.209790 38132 net.cpp:144] Memory required for data: 1840822272
I1027 09:56:06.209801 38132 layer_factory.hpp:77] Creating layer fire3/expand1x1
I1027 09:56:06.209820 38132 net.cpp:84] Creating Layer fire3/expand1x1
I1027 09:56:06.209830 38132 net.cpp:413] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1027 09:56:06.209843 38132 net.cpp:387] fire3/expand1x1 -> fire3/expand1x1
I1027 09:56:06.210368 38132 net.cpp:127] Setting up fire3/expand1x1
I1027 09:56:06.210387 38132 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 09:56:06.210399 38132 net.cpp:144] Memory required for data: 1943582720
I1027 09:56:06.210412 38132 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1027 09:56:06.210427 38132 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1027 09:56:06.210439 38132 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1027 09:56:06.210448 38132 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1027 09:56:06.210458 38132 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I1027 09:56:06.210474 38132 net.cpp:84] Creating Layer fire3/relu_expand1x1
I1027 09:56:06.210484 38132 net.cpp:413] fire3/relu_expand1x1 <- fire3/expand1x1
I1027 09:56:06.210496 38132 net.cpp:374] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I1027 09:56:06.210808 38132 net.cpp:127] Setting up fire3/relu_expand1x1
I1027 09:56:06.210825 38132 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 09:56:06.210834 38132 net.cpp:144] Memory required for data: 2046343168
I1027 09:56:06.210844 38132 layer_factory.hpp:77] Creating layer fire3/expand3x3
I1027 09:56:06.210865 38132 net.cpp:84] Creating Layer fire3/expand3x3
I1027 09:56:06.210875 38132 net.cpp:413] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1027 09:56:06.210888 38132 net.cpp:387] fire3/expand3x3 -> fire3/expand3x3
I1027 09:56:06.211541 38132 net.cpp:127] Setting up fire3/expand3x3
I1027 09:56:06.211560 38132 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 09:56:06.211570 38132 net.cpp:144] Memory required for data: 2149103616
I1027 09:56:06.211581 38132 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1027 09:56:06.211592 38132 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1027 09:56:06.211603 38132 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1027 09:56:06.211614 38132 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1027 09:56:06.211621 38132 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I1027 09:56:06.211635 38132 net.cpp:84] Creating Layer fire3/relu_expand3x3
I1027 09:56:06.211658 38132 net.cpp:413] fire3/relu_expand3x3 <- fire3/expand3x3
I1027 09:56:06.211670 38132 net.cpp:374] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I1027 09:56:06.211984 38132 net.cpp:127] Setting up fire3/relu_expand3x3
I1027 09:56:06.212002 38132 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 09:56:06.212013 38132 net.cpp:144] Memory required for data: 2251864064
I1027 09:56:06.212023 38132 layer_factory.hpp:77] Creating layer fire3/concat
I1027 09:56:06.212036 38132 net.cpp:84] Creating Layer fire3/concat
I1027 09:56:06.212049 38132 net.cpp:413] fire3/concat <- fire3/expand1x1
I1027 09:56:06.212060 38132 net.cpp:413] fire3/concat <- fire3/expand3x3
I1027 09:56:06.212074 38132 net.cpp:387] fire3/concat -> fire3/concat
I1027 09:56:06.212123 38132 net.cpp:127] Setting up fire3/concat
I1027 09:56:06.212141 38132 net.cpp:136] Top shape: 128 128 56 56 (51380224)
I1027 09:56:06.212152 38132 net.cpp:144] Memory required for data: 2457384960
I1027 09:56:06.212178 38132 layer_factory.hpp:77] Creating layer pool3
I1027 09:56:06.212193 38132 net.cpp:84] Creating Layer pool3
I1027 09:56:06.212203 38132 net.cpp:413] pool3 <- fire3/concat
I1027 09:56:06.212216 38132 net.cpp:387] pool3 -> pool3
I1027 09:56:06.212288 38132 net.cpp:127] Setting up pool3
I1027 09:56:06.212311 38132 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 09:56:06.212324 38132 net.cpp:144] Memory required for data: 2508765184
I1027 09:56:06.212337 38132 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I1027 09:56:06.212357 38132 net.cpp:84] Creating Layer fire4/squeeze1x1
I1027 09:56:06.212366 38132 net.cpp:413] fire4/squeeze1x1 <- pool3
I1027 09:56:06.212380 38132 net.cpp:387] fire4/squeeze1x1 -> fire4/squeeze1x1
I1027 09:56:06.212951 38132 net.cpp:127] Setting up fire4/squeeze1x1
I1027 09:56:06.212967 38132 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1027 09:56:06.212977 38132 net.cpp:144] Memory required for data: 2521610240
I1027 09:56:06.212988 38132 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1027 09:56:06.213001 38132 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1027 09:56:06.213011 38132 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1027 09:56:06.213021 38132 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1027 09:56:06.213028 38132 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I1027 09:56:06.213042 38132 net.cpp:84] Creating Layer fire4/relu_squeeze1x1
I1027 09:56:06.213052 38132 net.cpp:413] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I1027 09:56:06.213063 38132 net.cpp:374] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I1027 09:56:06.213385 38132 net.cpp:127] Setting up fire4/relu_squeeze1x1
I1027 09:56:06.213405 38132 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1027 09:56:06.213414 38132 net.cpp:144] Memory required for data: 2534455296
I1027 09:56:06.213423 38132 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1027 09:56:06.213434 38132 net.cpp:84] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1027 09:56:06.213443 38132 net.cpp:413] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I1027 09:56:06.213455 38132 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1027 09:56:06.213470 38132 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1027 09:56:06.213541 38132 net.cpp:127] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1027 09:56:06.213554 38132 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1027 09:56:06.213567 38132 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1027 09:56:06.213575 38132 net.cpp:144] Memory required for data: 2560145408
I1027 09:56:06.213585 38132 layer_factory.hpp:77] Creating layer fire4/expand1x1
I1027 09:56:06.213604 38132 net.cpp:84] Creating Layer fire4/expand1x1
I1027 09:56:06.213615 38132 net.cpp:413] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1027 09:56:06.213641 38132 net.cpp:387] fire4/expand1x1 -> fire4/expand1x1
I1027 09:56:06.214190 38132 net.cpp:127] Setting up fire4/expand1x1
I1027 09:56:06.214207 38132 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 09:56:06.214218 38132 net.cpp:144] Memory required for data: 2611525632
I1027 09:56:06.214237 38132 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1027 09:56:06.214254 38132 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1027 09:56:06.214267 38132 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1027 09:56:06.214278 38132 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1027 09:56:06.214288 38132 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I1027 09:56:06.214308 38132 net.cpp:84] Creating Layer fire4/relu_expand1x1
I1027 09:56:06.214339 38132 net.cpp:413] fire4/relu_expand1x1 <- fire4/expand1x1
I1027 09:56:06.214354 38132 net.cpp:374] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I1027 09:56:06.216557 38132 net.cpp:127] Setting up fire4/relu_expand1x1
I1027 09:56:06.216585 38132 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 09:56:06.216598 38132 net.cpp:144] Memory required for data: 2662905856
I1027 09:56:06.216608 38132 layer_factory.hpp:77] Creating layer fire4/expand3x3
I1027 09:56:06.216626 38132 net.cpp:84] Creating Layer fire4/expand3x3
I1027 09:56:06.216639 38132 net.cpp:413] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1027 09:56:06.216653 38132 net.cpp:387] fire4/expand3x3 -> fire4/expand3x3
I1027 09:56:06.219445 38132 net.cpp:127] Setting up fire4/expand3x3
I1027 09:56:06.219472 38132 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 09:56:06.219483 38132 net.cpp:144] Memory required for data: 2714286080
I1027 09:56:06.219496 38132 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1027 09:56:06.219511 38132 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1027 09:56:06.219521 38132 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1027 09:56:06.219532 38132 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1027 09:56:06.219539 38132 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I1027 09:56:06.219559 38132 net.cpp:84] Creating Layer fire4/relu_expand3x3
I1027 09:56:06.219571 38132 net.cpp:413] fire4/relu_expand3x3 <- fire4/expand3x3
I1027 09:56:06.219583 38132 net.cpp:374] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I1027 09:56:06.219887 38132 net.cpp:127] Setting up fire4/relu_expand3x3
I1027 09:56:06.219903 38132 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 09:56:06.219913 38132 net.cpp:144] Memory required for data: 2765666304
I1027 09:56:06.219921 38132 layer_factory.hpp:77] Creating layer fire4/concat
I1027 09:56:06.219938 38132 net.cpp:84] Creating Layer fire4/concat
I1027 09:56:06.219946 38132 net.cpp:413] fire4/concat <- fire4/expand1x1
I1027 09:56:06.219955 38132 net.cpp:413] fire4/concat <- fire4/expand3x3
I1027 09:56:06.219965 38132 net.cpp:387] fire4/concat -> fire4/concat
I1027 09:56:06.220011 38132 net.cpp:127] Setting up fire4/concat
I1027 09:56:06.220024 38132 net.cpp:136] Top shape: 128 256 28 28 (25690112)
I1027 09:56:06.220032 38132 net.cpp:144] Memory required for data: 2868426752
I1027 09:56:06.220041 38132 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I1027 09:56:06.220058 38132 net.cpp:84] Creating Layer fire5/squeeze1x1
I1027 09:56:06.220068 38132 net.cpp:413] fire5/squeeze1x1 <- fire4/concat
I1027 09:56:06.220082 38132 net.cpp:387] fire5/squeeze1x1 -> fire5/squeeze1x1
I1027 09:56:06.220669 38132 net.cpp:127] Setting up fire5/squeeze1x1
I1027 09:56:06.220686 38132 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1027 09:56:06.220695 38132 net.cpp:144] Memory required for data: 2881271808
I1027 09:56:06.220708 38132 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1027 09:56:06.220732 38132 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1027 09:56:06.220743 38132 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1027 09:56:06.220754 38132 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1027 09:56:06.220762 38132 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I1027 09:56:06.220777 38132 net.cpp:84] Creating Layer fire5/relu_squeeze1x1
I1027 09:56:06.220788 38132 net.cpp:413] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I1027 09:56:06.220800 38132 net.cpp:374] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I1027 09:56:06.221097 38132 net.cpp:127] Setting up fire5/relu_squeeze1x1
I1027 09:56:06.221113 38132 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1027 09:56:06.221124 38132 net.cpp:144] Memory required for data: 2894116864
I1027 09:56:06.221133 38132 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1027 09:56:06.221166 38132 net.cpp:84] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1027 09:56:06.221177 38132 net.cpp:413] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I1027 09:56:06.221189 38132 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1027 09:56:06.221204 38132 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1027 09:56:06.221274 38132 net.cpp:127] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1027 09:56:06.221287 38132 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1027 09:56:06.221305 38132 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1027 09:56:06.221314 38132 net.cpp:144] Memory required for data: 2919806976
I1027 09:56:06.221323 38132 layer_factory.hpp:77] Creating layer fire5/expand1x1
I1027 09:56:06.221343 38132 net.cpp:84] Creating Layer fire5/expand1x1
I1027 09:56:06.221354 38132 net.cpp:413] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1027 09:56:06.221365 38132 net.cpp:387] fire5/expand1x1 -> fire5/expand1x1
I1027 09:56:06.221873 38132 net.cpp:127] Setting up fire5/expand1x1
I1027 09:56:06.221889 38132 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 09:56:06.221899 38132 net.cpp:144] Memory required for data: 2971187200
I1027 09:56:06.221911 38132 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1027 09:56:06.221925 38132 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1027 09:56:06.221935 38132 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1027 09:56:06.221946 38132 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1027 09:56:06.221954 38132 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I1027 09:56:06.221967 38132 net.cpp:84] Creating Layer fire5/relu_expand1x1
I1027 09:56:06.221977 38132 net.cpp:413] fire5/relu_expand1x1 <- fire5/expand1x1
I1027 09:56:06.221989 38132 net.cpp:374] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I1027 09:56:06.222276 38132 net.cpp:127] Setting up fire5/relu_expand1x1
I1027 09:56:06.222292 38132 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 09:56:06.222316 38132 net.cpp:144] Memory required for data: 3022567424
I1027 09:56:06.222324 38132 layer_factory.hpp:77] Creating layer fire5/expand3x3
I1027 09:56:06.222343 38132 net.cpp:84] Creating Layer fire5/expand3x3
I1027 09:56:06.222353 38132 net.cpp:413] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1027 09:56:06.222368 38132 net.cpp:387] fire5/expand3x3 -> fire5/expand3x3
I1027 09:56:06.223276 38132 net.cpp:127] Setting up fire5/expand3x3
I1027 09:56:06.223294 38132 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 09:56:06.223312 38132 net.cpp:144] Memory required for data: 3073947648
I1027 09:56:06.223325 38132 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1027 09:56:06.223346 38132 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1027 09:56:06.223356 38132 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1027 09:56:06.223367 38132 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1027 09:56:06.223376 38132 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I1027 09:56:06.223390 38132 net.cpp:84] Creating Layer fire5/relu_expand3x3
I1027 09:56:06.223400 38132 net.cpp:413] fire5/relu_expand3x3 <- fire5/expand3x3
I1027 09:56:06.223412 38132 net.cpp:374] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I1027 09:56:06.225464 38132 net.cpp:127] Setting up fire5/relu_expand3x3
I1027 09:56:06.225492 38132 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 09:56:06.225500 38132 net.cpp:144] Memory required for data: 3125327872
I1027 09:56:06.225509 38132 layer_factory.hpp:77] Creating layer fire5/concat
I1027 09:56:06.225544 38132 net.cpp:84] Creating Layer fire5/concat
I1027 09:56:06.225555 38132 net.cpp:413] fire5/concat <- fire5/expand1x1
I1027 09:56:06.225569 38132 net.cpp:413] fire5/concat <- fire5/expand3x3
I1027 09:56:06.225580 38132 net.cpp:387] fire5/concat -> fire5/concat
I1027 09:56:06.225631 38132 net.cpp:127] Setting up fire5/concat
I1027 09:56:06.225646 38132 net.cpp:136] Top shape: 128 256 28 28 (25690112)
I1027 09:56:06.225654 38132 net.cpp:144] Memory required for data: 3228088320
I1027 09:56:06.225663 38132 layer_factory.hpp:77] Creating layer pool5
I1027 09:56:06.225677 38132 net.cpp:84] Creating Layer pool5
I1027 09:56:06.225687 38132 net.cpp:413] pool5 <- fire5/concat
I1027 09:56:06.225699 38132 net.cpp:387] pool5 -> pool5
I1027 09:56:06.225762 38132 net.cpp:127] Setting up pool5
I1027 09:56:06.225776 38132 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 09:56:06.225786 38132 net.cpp:144] Memory required for data: 3253778432
I1027 09:56:06.225795 38132 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I1027 09:56:06.225809 38132 net.cpp:84] Creating Layer fire6/squeeze1x1
I1027 09:56:06.225819 38132 net.cpp:413] fire6/squeeze1x1 <- pool5
I1027 09:56:06.225832 38132 net.cpp:387] fire6/squeeze1x1 -> fire6/squeeze1x1
I1027 09:56:06.226477 38132 net.cpp:127] Setting up fire6/squeeze1x1
I1027 09:56:06.226496 38132 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1027 09:56:06.226506 38132 net.cpp:144] Memory required for data: 3258595328
I1027 09:56:06.226521 38132 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1027 09:56:06.226534 38132 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1027 09:56:06.226544 38132 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1027 09:56:06.226555 38132 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1027 09:56:06.226567 38132 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I1027 09:56:06.226582 38132 net.cpp:84] Creating Layer fire6/relu_squeeze1x1
I1027 09:56:06.226593 38132 net.cpp:413] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I1027 09:56:06.226604 38132 net.cpp:374] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I1027 09:56:06.226893 38132 net.cpp:127] Setting up fire6/relu_squeeze1x1
I1027 09:56:06.226910 38132 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1027 09:56:06.226919 38132 net.cpp:144] Memory required for data: 3263412224
I1027 09:56:06.226928 38132 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1027 09:56:06.226943 38132 net.cpp:84] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1027 09:56:06.226951 38132 net.cpp:413] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I1027 09:56:06.226961 38132 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1027 09:56:06.226975 38132 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1027 09:56:06.227051 38132 net.cpp:127] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1027 09:56:06.227075 38132 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1027 09:56:06.227088 38132 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1027 09:56:06.227098 38132 net.cpp:144] Memory required for data: 3273046016
I1027 09:56:06.227107 38132 layer_factory.hpp:77] Creating layer fire6/expand1x1
I1027 09:56:06.227120 38132 net.cpp:84] Creating Layer fire6/expand1x1
I1027 09:56:06.227128 38132 net.cpp:413] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1027 09:56:06.227141 38132 net.cpp:387] fire6/expand1x1 -> fire6/expand1x1
I1027 09:56:06.227731 38132 net.cpp:127] Setting up fire6/expand1x1
I1027 09:56:06.227748 38132 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1027 09:56:06.227756 38132 net.cpp:144] Memory required for data: 3292313600
I1027 09:56:06.227767 38132 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1027 09:56:06.227777 38132 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1027 09:56:06.227805 38132 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1027 09:56:06.227814 38132 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1027 09:56:06.227823 38132 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I1027 09:56:06.227835 38132 net.cpp:84] Creating Layer fire6/relu_expand1x1
I1027 09:56:06.227846 38132 net.cpp:413] fire6/relu_expand1x1 <- fire6/expand1x1
I1027 09:56:06.227859 38132 net.cpp:374] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I1027 09:56:06.228147 38132 net.cpp:127] Setting up fire6/relu_expand1x1
I1027 09:56:06.228164 38132 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1027 09:56:06.228174 38132 net.cpp:144] Memory required for data: 3311581184
I1027 09:56:06.228185 38132 layer_factory.hpp:77] Creating layer fire6/expand3x3
I1027 09:56:06.228204 38132 net.cpp:84] Creating Layer fire6/expand3x3
I1027 09:56:06.228215 38132 net.cpp:413] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1027 09:56:06.228229 38132 net.cpp:387] fire6/expand3x3 -> fire6/expand3x3
I1027 09:56:06.231393 38132 net.cpp:127] Setting up fire6/expand3x3
I1027 09:56:06.231420 38132 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1027 09:56:06.231431 38132 net.cpp:144] Memory required for data: 3330848768
I1027 09:56:06.231443 38132 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1027 09:56:06.231456 38132 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1027 09:56:06.231468 38132 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1027 09:56:06.231477 38132 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1027 09:56:06.231485 38132 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I1027 09:56:06.231498 38132 net.cpp:84] Creating Layer fire6/relu_expand3x3
I1027 09:56:06.231506 38132 net.cpp:413] fire6/relu_expand3x3 <- fire6/expand3x3
I1027 09:56:06.231518 38132 net.cpp:374] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I1027 09:56:06.231811 38132 net.cpp:127] Setting up fire6/relu_expand3x3
I1027 09:56:06.231827 38132 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1027 09:56:06.231835 38132 net.cpp:144] Memory required for data: 3350116352
I1027 09:56:06.231851 38132 layer_factory.hpp:77] Creating layer fire6/concat
I1027 09:56:06.231863 38132 net.cpp:84] Creating Layer fire6/concat
I1027 09:56:06.231875 38132 net.cpp:413] fire6/concat <- fire6/expand1x1
I1027 09:56:06.231885 38132 net.cpp:413] fire6/concat <- fire6/expand3x3
I1027 09:56:06.231896 38132 net.cpp:387] fire6/concat -> fire6/concat
I1027 09:56:06.231941 38132 net.cpp:127] Setting up fire6/concat
I1027 09:56:06.231954 38132 net.cpp:136] Top shape: 128 384 14 14 (9633792)
I1027 09:56:06.231962 38132 net.cpp:144] Memory required for data: 3388651520
I1027 09:56:06.231972 38132 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I1027 09:56:06.231987 38132 net.cpp:84] Creating Layer fire7/squeeze1x1
I1027 09:56:06.232007 38132 net.cpp:413] fire7/squeeze1x1 <- fire6/concat
I1027 09:56:06.232018 38132 net.cpp:387] fire7/squeeze1x1 -> fire7/squeeze1x1
I1027 09:56:06.232679 38132 net.cpp:127] Setting up fire7/squeeze1x1
I1027 09:56:06.232697 38132 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1027 09:56:06.232705 38132 net.cpp:144] Memory required for data: 3393468416
I1027 09:56:06.232724 38132 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1027 09:56:06.232740 38132 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1027 09:56:06.232750 38132 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1027 09:56:06.232760 38132 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1027 09:56:06.232769 38132 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I1027 09:56:06.232780 38132 net.cpp:84] Creating Layer fire7/relu_squeeze1x1
I1027 09:56:06.232806 38132 net.cpp:413] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I1027 09:56:06.232818 38132 net.cpp:374] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I1027 09:56:06.234750 38132 net.cpp:127] Setting up fire7/relu_squeeze1x1
I1027 09:56:06.234776 38132 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1027 09:56:06.234784 38132 net.cpp:144] Memory required for data: 3398285312
I1027 09:56:06.234794 38132 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1027 09:56:06.234807 38132 net.cpp:84] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1027 09:56:06.234817 38132 net.cpp:413] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I1027 09:56:06.234830 38132 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1027 09:56:06.234844 38132 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1027 09:56:06.234915 38132 net.cpp:127] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1027 09:56:06.234930 38132 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1027 09:56:06.234939 38132 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1027 09:56:06.234946 38132 net.cpp:144] Memory required for data: 3407919104
I1027 09:56:06.234954 38132 layer_factory.hpp:77] Creating layer fire7/expand1x1
I1027 09:56:06.234968 38132 net.cpp:84] Creating Layer fire7/expand1x1
I1027 09:56:06.234978 38132 net.cpp:413] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1027 09:56:06.234990 38132 net.cpp:387] fire7/expand1x1 -> fire7/expand1x1
I1027 09:56:06.235550 38132 net.cpp:127] Setting up fire7/expand1x1
I1027 09:56:06.235568 38132 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1027 09:56:06.235577 38132 net.cpp:144] Memory required for data: 3427186688
I1027 09:56:06.235589 38132 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1027 09:56:06.235599 38132 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1027 09:56:06.235610 38132 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1027 09:56:06.235620 38132 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1027 09:56:06.235630 38132 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I1027 09:56:06.235642 38132 net.cpp:84] Creating Layer fire7/relu_expand1x1
I1027 09:56:06.235651 38132 net.cpp:413] fire7/relu_expand1x1 <- fire7/expand1x1
I1027 09:56:06.235663 38132 net.cpp:374] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I1027 09:56:06.235931 38132 net.cpp:127] Setting up fire7/relu_expand1x1
I1027 09:56:06.235947 38132 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1027 09:56:06.235955 38132 net.cpp:144] Memory required for data: 3446454272
I1027 09:56:06.235965 38132 layer_factory.hpp:77] Creating layer fire7/expand3x3
I1027 09:56:06.235978 38132 net.cpp:84] Creating Layer fire7/expand3x3
I1027 09:56:06.235987 38132 net.cpp:413] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1027 09:56:06.236011 38132 net.cpp:387] fire7/expand3x3 -> fire7/expand3x3
I1027 09:56:06.237426 38132 net.cpp:127] Setting up fire7/expand3x3
I1027 09:56:06.237444 38132 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1027 09:56:06.237453 38132 net.cpp:144] Memory required for data: 3465721856
I1027 09:56:06.237464 38132 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1027 09:56:06.237476 38132 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1027 09:56:06.237486 38132 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1027 09:56:06.237495 38132 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1027 09:56:06.237502 38132 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I1027 09:56:06.237515 38132 net.cpp:84] Creating Layer fire7/relu_expand3x3
I1027 09:56:06.237524 38132 net.cpp:413] fire7/relu_expand3x3 <- fire7/expand3x3
I1027 09:56:06.237553 38132 net.cpp:374] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I1027 09:56:06.237820 38132 net.cpp:127] Setting up fire7/relu_expand3x3
I1027 09:56:06.237836 38132 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1027 09:56:06.237844 38132 net.cpp:144] Memory required for data: 3484989440
I1027 09:56:06.237854 38132 layer_factory.hpp:77] Creating layer fire7/concat
I1027 09:56:06.237865 38132 net.cpp:84] Creating Layer fire7/concat
I1027 09:56:06.237874 38132 net.cpp:413] fire7/concat <- fire7/expand1x1
I1027 09:56:06.237884 38132 net.cpp:413] fire7/concat <- fire7/expand3x3
I1027 09:56:06.237895 38132 net.cpp:387] fire7/concat -> fire7/concat
I1027 09:56:06.237941 38132 net.cpp:127] Setting up fire7/concat
I1027 09:56:06.237952 38132 net.cpp:136] Top shape: 128 384 14 14 (9633792)
I1027 09:56:06.237960 38132 net.cpp:144] Memory required for data: 3523524608
I1027 09:56:06.237968 38132 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I1027 09:56:06.237982 38132 net.cpp:84] Creating Layer fire8/squeeze1x1
I1027 09:56:06.237990 38132 net.cpp:413] fire8/squeeze1x1 <- fire7/concat
I1027 09:56:06.238003 38132 net.cpp:387] fire8/squeeze1x1 -> fire8/squeeze1x1
I1027 09:56:06.238723 38132 net.cpp:127] Setting up fire8/squeeze1x1
I1027 09:56:06.238740 38132 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1027 09:56:06.238749 38132 net.cpp:144] Memory required for data: 3529947136
I1027 09:56:06.238759 38132 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1027 09:56:06.238770 38132 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1027 09:56:06.238778 38132 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1027 09:56:06.238787 38132 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1027 09:56:06.238795 38132 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I1027 09:56:06.238806 38132 net.cpp:84] Creating Layer fire8/relu_squeeze1x1
I1027 09:56:06.238814 38132 net.cpp:413] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I1027 09:56:06.238826 38132 net.cpp:374] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I1027 09:56:06.240649 38132 net.cpp:127] Setting up fire8/relu_squeeze1x1
I1027 09:56:06.240674 38132 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1027 09:56:06.240684 38132 net.cpp:144] Memory required for data: 3536369664
I1027 09:56:06.240691 38132 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1027 09:56:06.240705 38132 net.cpp:84] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1027 09:56:06.240725 38132 net.cpp:413] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I1027 09:56:06.240736 38132 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1027 09:56:06.240749 38132 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1027 09:56:06.240813 38132 net.cpp:127] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1027 09:56:06.240835 38132 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1027 09:56:06.240845 38132 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1027 09:56:06.240852 38132 net.cpp:144] Memory required for data: 3549214720
I1027 09:56:06.240861 38132 layer_factory.hpp:77] Creating layer fire8/expand1x1
I1027 09:56:06.240876 38132 net.cpp:84] Creating Layer fire8/expand1x1
I1027 09:56:06.240886 38132 net.cpp:413] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1027 09:56:06.240898 38132 net.cpp:387] fire8/expand1x1 -> fire8/expand1x1
I1027 09:56:06.241493 38132 net.cpp:127] Setting up fire8/expand1x1
I1027 09:56:06.241509 38132 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 09:56:06.241518 38132 net.cpp:144] Memory required for data: 3574904832
I1027 09:56:06.241529 38132 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1027 09:56:06.241556 38132 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1027 09:56:06.241566 38132 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1027 09:56:06.241575 38132 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1027 09:56:06.241582 38132 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I1027 09:56:06.241593 38132 net.cpp:84] Creating Layer fire8/relu_expand1x1
I1027 09:56:06.241602 38132 net.cpp:413] fire8/relu_expand1x1 <- fire8/expand1x1
I1027 09:56:06.241613 38132 net.cpp:374] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I1027 09:56:06.241865 38132 net.cpp:127] Setting up fire8/relu_expand1x1
I1027 09:56:06.241880 38132 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 09:56:06.241888 38132 net.cpp:144] Memory required for data: 3600594944
I1027 09:56:06.241895 38132 layer_factory.hpp:77] Creating layer fire8/expand3x3
I1027 09:56:06.241911 38132 net.cpp:84] Creating Layer fire8/expand3x3
I1027 09:56:06.241920 38132 net.cpp:413] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1027 09:56:06.241933 38132 net.cpp:387] fire8/expand3x3 -> fire8/expand3x3
I1027 09:56:06.245563 38132 net.cpp:127] Setting up fire8/expand3x3
I1027 09:56:06.245587 38132 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 09:56:06.245596 38132 net.cpp:144] Memory required for data: 3626285056
I1027 09:56:06.245607 38132 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1027 09:56:06.245620 38132 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1027 09:56:06.245628 38132 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1027 09:56:06.245636 38132 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1027 09:56:06.245645 38132 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I1027 09:56:06.245657 38132 net.cpp:84] Creating Layer fire8/relu_expand3x3
I1027 09:56:06.245667 38132 net.cpp:413] fire8/relu_expand3x3 <- fire8/expand3x3
I1027 09:56:06.245678 38132 net.cpp:374] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I1027 09:56:06.245944 38132 net.cpp:127] Setting up fire8/relu_expand3x3
I1027 09:56:06.245959 38132 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 09:56:06.245967 38132 net.cpp:144] Memory required for data: 3651975168
I1027 09:56:06.245976 38132 layer_factory.hpp:77] Creating layer fire8/concat
I1027 09:56:06.245987 38132 net.cpp:84] Creating Layer fire8/concat
I1027 09:56:06.245998 38132 net.cpp:413] fire8/concat <- fire8/expand1x1
I1027 09:56:06.246008 38132 net.cpp:413] fire8/concat <- fire8/expand3x3
I1027 09:56:06.246018 38132 net.cpp:387] fire8/concat -> fire8/concat
I1027 09:56:06.246062 38132 net.cpp:127] Setting up fire8/concat
I1027 09:56:06.246073 38132 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1027 09:56:06.246080 38132 net.cpp:144] Memory required for data: 3703355392
I1027 09:56:06.246088 38132 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I1027 09:56:06.246103 38132 net.cpp:84] Creating Layer fire9/squeeze1x1
I1027 09:56:06.246122 38132 net.cpp:413] fire9/squeeze1x1 <- fire8/concat
I1027 09:56:06.246134 38132 net.cpp:387] fire9/squeeze1x1 -> fire9/squeeze1x1
I1027 09:56:06.246912 38132 net.cpp:127] Setting up fire9/squeeze1x1
I1027 09:56:06.246927 38132 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1027 09:56:06.246935 38132 net.cpp:144] Memory required for data: 3709777920
I1027 09:56:06.246945 38132 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1027 09:56:06.246955 38132 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1027 09:56:06.246964 38132 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1027 09:56:06.246973 38132 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1027 09:56:06.246980 38132 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I1027 09:56:06.246991 38132 net.cpp:84] Creating Layer fire9/relu_squeeze1x1
I1027 09:56:06.247020 38132 net.cpp:413] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I1027 09:56:06.247030 38132 net.cpp:374] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I1027 09:56:06.247288 38132 net.cpp:127] Setting up fire9/relu_squeeze1x1
I1027 09:56:06.247310 38132 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1027 09:56:06.247321 38132 net.cpp:144] Memory required for data: 3716200448
I1027 09:56:06.247329 38132 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1027 09:56:06.247347 38132 net.cpp:84] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1027 09:56:06.247356 38132 net.cpp:413] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I1027 09:56:06.247367 38132 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1027 09:56:06.247380 38132 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1027 09:56:06.247443 38132 net.cpp:127] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1027 09:56:06.247455 38132 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1027 09:56:06.247464 38132 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1027 09:56:06.247472 38132 net.cpp:144] Memory required for data: 3729045504
I1027 09:56:06.247479 38132 layer_factory.hpp:77] Creating layer fire9/expand1x1
I1027 09:56:06.247493 38132 net.cpp:84] Creating Layer fire9/expand1x1
I1027 09:56:06.247500 38132 net.cpp:413] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1027 09:56:06.247512 38132 net.cpp:387] fire9/expand1x1 -> fire9/expand1x1
I1027 09:56:06.248095 38132 net.cpp:127] Setting up fire9/expand1x1
I1027 09:56:06.248109 38132 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 09:56:06.248117 38132 net.cpp:144] Memory required for data: 3754735616
I1027 09:56:06.248127 38132 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1027 09:56:06.248138 38132 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1027 09:56:06.248147 38132 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1027 09:56:06.248154 38132 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1027 09:56:06.248162 38132 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I1027 09:56:06.248174 38132 net.cpp:84] Creating Layer fire9/relu_expand1x1
I1027 09:56:06.248184 38132 net.cpp:413] fire9/relu_expand1x1 <- fire9/expand1x1
I1027 09:56:06.248195 38132 net.cpp:374] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I1027 09:56:06.249984 38132 net.cpp:127] Setting up fire9/relu_expand1x1
I1027 09:56:06.250006 38132 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 09:56:06.250015 38132 net.cpp:144] Memory required for data: 3780425728
I1027 09:56:06.250023 38132 layer_factory.hpp:77] Creating layer fire9/expand3x3
I1027 09:56:06.250038 38132 net.cpp:84] Creating Layer fire9/expand3x3
I1027 09:56:06.250048 38132 net.cpp:413] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1027 09:56:06.250071 38132 net.cpp:387] fire9/expand3x3 -> fire9/expand3x3
I1027 09:56:06.251976 38132 net.cpp:127] Setting up fire9/expand3x3
I1027 09:56:06.251992 38132 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 09:56:06.252001 38132 net.cpp:144] Memory required for data: 3806115840
I1027 09:56:06.252010 38132 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1027 09:56:06.252022 38132 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1027 09:56:06.252030 38132 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1027 09:56:06.252038 38132 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1027 09:56:06.252044 38132 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I1027 09:56:06.252054 38132 net.cpp:84] Creating Layer fire9/relu_expand3x3
I1027 09:56:06.252077 38132 net.cpp:413] fire9/relu_expand3x3 <- fire9/expand3x3
I1027 09:56:06.252089 38132 net.cpp:374] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I1027 09:56:06.252333 38132 net.cpp:127] Setting up fire9/relu_expand3x3
I1027 09:56:06.252349 38132 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 09:56:06.252358 38132 net.cpp:144] Memory required for data: 3831805952
I1027 09:56:06.252365 38132 layer_factory.hpp:77] Creating layer fire9/concat
I1027 09:56:06.252378 38132 net.cpp:84] Creating Layer fire9/concat
I1027 09:56:06.252385 38132 net.cpp:413] fire9/concat <- fire9/expand1x1
I1027 09:56:06.252395 38132 net.cpp:413] fire9/concat <- fire9/expand3x3
I1027 09:56:06.252403 38132 net.cpp:387] fire9/concat -> fire9/concat
I1027 09:56:06.252442 38132 net.cpp:127] Setting up fire9/concat
I1027 09:56:06.252454 38132 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1027 09:56:06.252461 38132 net.cpp:144] Memory required for data: 3883186176
I1027 09:56:06.252468 38132 layer_factory.hpp:77] Creating layer drop9
I1027 09:56:06.252481 38132 net.cpp:84] Creating Layer drop9
I1027 09:56:06.252490 38132 net.cpp:413] drop9 <- fire9/concat
I1027 09:56:06.252498 38132 net.cpp:374] drop9 -> fire9/concat (in-place)
I1027 09:56:06.252539 38132 net.cpp:127] Setting up drop9
I1027 09:56:06.252552 38132 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1027 09:56:06.252558 38132 net.cpp:144] Memory required for data: 3934566400
I1027 09:56:06.252565 38132 layer_factory.hpp:77] Creating layer conv10
I1027 09:56:06.252578 38132 net.cpp:84] Creating Layer conv10
I1027 09:56:06.252585 38132 net.cpp:413] conv10 <- fire9/concat
I1027 09:56:06.252595 38132 net.cpp:387] conv10 -> conv10
I1027 09:56:06.264168 38132 net.cpp:127] Setting up conv10
I1027 09:56:06.264192 38132 net.cpp:136] Top shape: 128 1000 14 14 (25088000)
I1027 09:56:06.264201 38132 net.cpp:144] Memory required for data: 4034918400
I1027 09:56:06.264212 38132 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1027 09:56:06.264221 38132 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1027 09:56:06.264230 38132 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1027 09:56:06.264236 38132 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1027 09:56:06.264243 38132 layer_factory.hpp:77] Creating layer relu_conv10
I1027 09:56:06.264252 38132 net.cpp:84] Creating Layer relu_conv10
I1027 09:56:06.264259 38132 net.cpp:413] relu_conv10 <- conv10
I1027 09:56:06.264269 38132 net.cpp:374] relu_conv10 -> conv10 (in-place)
I1027 09:56:06.264523 38132 net.cpp:127] Setting up relu_conv10
I1027 09:56:06.264540 38132 net.cpp:136] Top shape: 128 1000 14 14 (25088000)
I1027 09:56:06.264549 38132 net.cpp:144] Memory required for data: 4135270400
I1027 09:56:06.264556 38132 layer_factory.hpp:77] Creating layer pool10
I1027 09:56:06.264567 38132 net.cpp:84] Creating Layer pool10
I1027 09:56:06.264575 38132 net.cpp:413] pool10 <- conv10
I1027 09:56:06.264587 38132 net.cpp:387] pool10 -> pool10
I1027 09:56:06.264849 38132 net.cpp:127] Setting up pool10
I1027 09:56:06.264873 38132 net.cpp:136] Top shape: 128 1000 1 1 (128000)
I1027 09:56:06.264883 38132 net.cpp:144] Memory required for data: 4135782400
I1027 09:56:06.264890 38132 layer_factory.hpp:77] Creating layer loss
I1027 09:56:06.264904 38132 net.cpp:84] Creating Layer loss
I1027 09:56:06.264914 38132 net.cpp:413] loss <- pool10
I1027 09:56:06.264924 38132 net.cpp:413] loss <- label
I1027 09:56:06.264935 38132 net.cpp:387] loss -> loss
I1027 09:56:06.264951 38132 layer_factory.hpp:77] Creating layer loss
I1027 09:56:06.268337 38132 net.cpp:127] Setting up loss
I1027 09:56:06.268360 38132 net.cpp:136] Top shape: (1)
I1027 09:56:06.268369 38132 net.cpp:139]     with loss weight 1
I1027 09:56:06.268400 38132 net.cpp:144] Memory required for data: 4135782404
I1027 09:56:06.268409 38132 net.cpp:205] loss needs backward computation.
I1027 09:56:06.268417 38132 net.cpp:205] pool10 needs backward computation.
I1027 09:56:06.268424 38132 net.cpp:205] relu_conv10 needs backward computation.
I1027 09:56:06.268446 38132 net.cpp:205] conv10 needs backward computation.
I1027 09:56:06.268455 38132 net.cpp:205] drop9 needs backward computation.
I1027 09:56:06.268461 38132 net.cpp:205] fire9/concat needs backward computation.
I1027 09:56:06.268470 38132 net.cpp:205] fire9/relu_expand3x3 needs backward computation.
I1027 09:56:06.268474 38132 net.cpp:205] fire9/expand3x3 needs backward computation.
I1027 09:56:06.268481 38132 net.cpp:205] fire9/relu_expand1x1 needs backward computation.
I1027 09:56:06.268487 38132 net.cpp:205] fire9/expand1x1 needs backward computation.
I1027 09:56:06.268494 38132 net.cpp:205] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I1027 09:56:06.268501 38132 net.cpp:205] fire9/relu_squeeze1x1 needs backward computation.
I1027 09:56:06.268507 38132 net.cpp:205] fire9/squeeze1x1 needs backward computation.
I1027 09:56:06.268513 38132 net.cpp:205] fire8/concat needs backward computation.
I1027 09:56:06.268522 38132 net.cpp:205] fire8/relu_expand3x3 needs backward computation.
I1027 09:56:06.268527 38132 net.cpp:205] fire8/expand3x3 needs backward computation.
I1027 09:56:06.268533 38132 net.cpp:205] fire8/relu_expand1x1 needs backward computation.
I1027 09:56:06.268540 38132 net.cpp:205] fire8/expand1x1 needs backward computation.
I1027 09:56:06.268548 38132 net.cpp:205] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I1027 09:56:06.268553 38132 net.cpp:205] fire8/relu_squeeze1x1 needs backward computation.
I1027 09:56:06.268575 38132 net.cpp:205] fire8/squeeze1x1 needs backward computation.
I1027 09:56:06.268581 38132 net.cpp:205] fire7/concat needs backward computation.
I1027 09:56:06.268587 38132 net.cpp:205] fire7/relu_expand3x3 needs backward computation.
I1027 09:56:06.268594 38132 net.cpp:205] fire7/expand3x3 needs backward computation.
I1027 09:56:06.268599 38132 net.cpp:205] fire7/relu_expand1x1 needs backward computation.
I1027 09:56:06.268604 38132 net.cpp:205] fire7/expand1x1 needs backward computation.
I1027 09:56:06.268610 38132 net.cpp:205] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I1027 09:56:06.268616 38132 net.cpp:205] fire7/relu_squeeze1x1 needs backward computation.
I1027 09:56:06.268622 38132 net.cpp:205] fire7/squeeze1x1 needs backward computation.
I1027 09:56:06.268628 38132 net.cpp:205] fire6/concat needs backward computation.
I1027 09:56:06.268635 38132 net.cpp:205] fire6/relu_expand3x3 needs backward computation.
I1027 09:56:06.268640 38132 net.cpp:205] fire6/expand3x3 needs backward computation.
I1027 09:56:06.268646 38132 net.cpp:205] fire6/relu_expand1x1 needs backward computation.
I1027 09:56:06.268651 38132 net.cpp:205] fire6/expand1x1 needs backward computation.
I1027 09:56:06.268656 38132 net.cpp:205] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I1027 09:56:06.268662 38132 net.cpp:205] fire6/relu_squeeze1x1 needs backward computation.
I1027 09:56:06.268667 38132 net.cpp:205] fire6/squeeze1x1 needs backward computation.
I1027 09:56:06.268673 38132 net.cpp:205] pool5 needs backward computation.
I1027 09:56:06.268685 38132 net.cpp:205] fire5/concat needs backward computation.
I1027 09:56:06.268692 38132 net.cpp:205] fire5/relu_expand3x3 needs backward computation.
I1027 09:56:06.268697 38132 net.cpp:205] fire5/expand3x3 needs backward computation.
I1027 09:56:06.268703 38132 net.cpp:205] fire5/relu_expand1x1 needs backward computation.
I1027 09:56:06.268708 38132 net.cpp:205] fire5/expand1x1 needs backward computation.
I1027 09:56:06.268714 38132 net.cpp:205] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I1027 09:56:06.268721 38132 net.cpp:205] fire5/relu_squeeze1x1 needs backward computation.
I1027 09:56:06.268726 38132 net.cpp:205] fire5/squeeze1x1 needs backward computation.
I1027 09:56:06.268733 38132 net.cpp:205] fire4/concat needs backward computation.
I1027 09:56:06.268739 38132 net.cpp:205] fire4/relu_expand3x3 needs backward computation.
I1027 09:56:06.268745 38132 net.cpp:205] fire4/expand3x3 needs backward computation.
I1027 09:56:06.268757 38132 net.cpp:205] fire4/relu_expand1x1 needs backward computation.
I1027 09:56:06.268764 38132 net.cpp:205] fire4/expand1x1 needs backward computation.
I1027 09:56:06.268770 38132 net.cpp:205] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I1027 09:56:06.268776 38132 net.cpp:205] fire4/relu_squeeze1x1 needs backward computation.
I1027 09:56:06.268782 38132 net.cpp:205] fire4/squeeze1x1 needs backward computation.
I1027 09:56:06.268790 38132 net.cpp:205] pool3 needs backward computation.
I1027 09:56:06.268795 38132 net.cpp:205] fire3/concat needs backward computation.
I1027 09:56:06.268802 38132 net.cpp:205] fire3/relu_expand3x3 needs backward computation.
I1027 09:56:06.268808 38132 net.cpp:205] fire3/expand3x3 needs backward computation.
I1027 09:56:06.268813 38132 net.cpp:205] fire3/relu_expand1x1 needs backward computation.
I1027 09:56:06.268821 38132 net.cpp:205] fire3/expand1x1 needs backward computation.
I1027 09:56:06.268826 38132 net.cpp:205] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I1027 09:56:06.268831 38132 net.cpp:205] fire3/relu_squeeze1x1 needs backward computation.
I1027 09:56:06.268837 38132 net.cpp:205] fire3/squeeze1x1 needs backward computation.
I1027 09:56:06.268842 38132 net.cpp:205] fire2/concat needs backward computation.
I1027 09:56:06.268849 38132 net.cpp:205] fire2/relu_expand3x3 needs backward computation.
I1027 09:56:06.268854 38132 net.cpp:205] fire2/expand3x3 needs backward computation.
I1027 09:56:06.268860 38132 net.cpp:205] fire2/relu_expand1x1 needs backward computation.
I1027 09:56:06.268867 38132 net.cpp:205] fire2/expand1x1 needs backward computation.
I1027 09:56:06.268872 38132 net.cpp:205] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I1027 09:56:06.268877 38132 net.cpp:205] fire2/relu_squeeze1x1 needs backward computation.
I1027 09:56:06.268883 38132 net.cpp:205] fire2/squeeze1x1 needs backward computation.
I1027 09:56:06.268889 38132 net.cpp:205] pool1 needs backward computation.
I1027 09:56:06.268895 38132 net.cpp:205] relu_conv1 needs backward computation.
I1027 09:56:06.268901 38132 net.cpp:205] conv1 needs backward computation.
I1027 09:56:06.268908 38132 net.cpp:207] data does not need backward computation.
I1027 09:56:06.268914 38132 net.cpp:249] This network produces output loss
I1027 09:56:06.268971 38132 net.cpp:262] Network initialization done.
I1027 09:56:06.271087 38132 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_0.prototxt
I1027 09:56:06.271209 38132 net.cpp:301] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1027 09:56:06.272069 38132 net.cpp:51] Initializing net from parameters: 
name: "SqueezeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/data/caffe-imagenet/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "INQConvolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "fire3/concat"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire4/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool3"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "fire5/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire4/concat"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "fire5/concat"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire6/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool5"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "fire9/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire8/concat"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "INQConvolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "pool10"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy_top1"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy_top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy_top5"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy_top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I1027 09:56:06.272506 38132 layer_factory.hpp:77] Creating layer data
I1027 09:56:06.285354 38132 db_lmdb.cpp:35] Opened lmdb /home/data/caffe-imagenet/ilsvrc12_val_lmdb
I1027 09:56:06.285408 38132 net.cpp:84] Creating Layer data
I1027 09:56:06.285430 38132 net.cpp:387] data -> data
I1027 09:56:06.285454 38132 net.cpp:387] data -> label
I1027 09:56:06.285858 38132 data_layer.cpp:45] output data size: 50,3,227,227
I1027 09:56:06.385363 38132 net.cpp:127] Setting up data
I1027 09:56:06.385414 38132 net.cpp:136] Top shape: 50 3 227 227 (7729350)
I1027 09:56:06.385430 38132 net.cpp:136] Top shape: 50 (50)
I1027 09:56:06.385465 38132 net.cpp:144] Memory required for data: 30917600
I1027 09:56:06.385476 38132 layer_factory.hpp:77] Creating layer label_data_1_split
I1027 09:56:06.385495 38132 net.cpp:84] Creating Layer label_data_1_split
I1027 09:56:06.385504 38132 net.cpp:413] label_data_1_split <- label
I1027 09:56:06.385517 38132 net.cpp:387] label_data_1_split -> label_data_1_split_0
I1027 09:56:06.385534 38132 net.cpp:387] label_data_1_split -> label_data_1_split_1
I1027 09:56:06.385542 38132 net.cpp:387] label_data_1_split -> label_data_1_split_2
I1027 09:56:06.385635 38132 net.cpp:127] Setting up label_data_1_split
I1027 09:56:06.385645 38132 net.cpp:136] Top shape: 50 (50)
I1027 09:56:06.385653 38132 net.cpp:136] Top shape: 50 (50)
I1027 09:56:06.385659 38132 net.cpp:136] Top shape: 50 (50)
I1027 09:56:06.385664 38132 net.cpp:144] Memory required for data: 30918200
I1027 09:56:06.385670 38132 layer_factory.hpp:77] Creating layer conv1
I1027 09:56:06.385686 38132 net.cpp:84] Creating Layer conv1
I1027 09:56:06.385692 38132 net.cpp:413] conv1 <- data
I1027 09:56:06.385702 38132 net.cpp:387] conv1 -> conv1
I1027 09:56:06.386137 38132 net.cpp:127] Setting up conv1
I1027 09:56:06.386150 38132 net.cpp:136] Top shape: 50 64 113 113 (40860800)
I1027 09:56:06.386157 38132 net.cpp:144] Memory required for data: 194361400
I1027 09:56:06.386169 38132 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1027 09:56:06.386180 38132 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1027 09:56:06.386193 38132 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1027 09:56:06.386201 38132 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1027 09:56:06.386207 38132 layer_factory.hpp:77] Creating layer relu_conv1
I1027 09:56:06.386217 38132 net.cpp:84] Creating Layer relu_conv1
I1027 09:56:06.386224 38132 net.cpp:413] relu_conv1 <- conv1
I1027 09:56:06.386230 38132 net.cpp:374] relu_conv1 -> conv1 (in-place)
I1027 09:56:06.386589 38132 net.cpp:127] Setting up relu_conv1
I1027 09:56:06.386605 38132 net.cpp:136] Top shape: 50 64 113 113 (40860800)
I1027 09:56:06.386612 38132 net.cpp:144] Memory required for data: 357804600
I1027 09:56:06.386620 38132 layer_factory.hpp:77] Creating layer pool1
I1027 09:56:06.386632 38132 net.cpp:84] Creating Layer pool1
I1027 09:56:06.386639 38132 net.cpp:413] pool1 <- conv1
I1027 09:56:06.386647 38132 net.cpp:387] pool1 -> pool1
I1027 09:56:06.386708 38132 net.cpp:127] Setting up pool1
I1027 09:56:06.386718 38132 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 09:56:06.386725 38132 net.cpp:144] Memory required for data: 397945400
I1027 09:56:06.386731 38132 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I1027 09:56:06.386744 38132 net.cpp:84] Creating Layer fire2/squeeze1x1
I1027 09:56:06.386749 38132 net.cpp:413] fire2/squeeze1x1 <- pool1
I1027 09:56:06.386759 38132 net.cpp:387] fire2/squeeze1x1 -> fire2/squeeze1x1
I1027 09:56:06.389524 38132 net.cpp:127] Setting up fire2/squeeze1x1
I1027 09:56:06.389539 38132 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1027 09:56:06.389564 38132 net.cpp:144] Memory required for data: 407980600
I1027 09:56:06.389575 38132 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1027 09:56:06.389585 38132 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1027 09:56:06.389592 38132 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1027 09:56:06.389600 38132 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1027 09:56:06.389605 38132 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I1027 09:56:06.389613 38132 net.cpp:84] Creating Layer fire2/relu_squeeze1x1
I1027 09:56:06.389619 38132 net.cpp:413] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I1027 09:56:06.389627 38132 net.cpp:374] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I1027 09:56:06.389855 38132 net.cpp:127] Setting up fire2/relu_squeeze1x1
I1027 09:56:06.389868 38132 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1027 09:56:06.389886 38132 net.cpp:144] Memory required for data: 418015800
I1027 09:56:06.389894 38132 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1027 09:56:06.389902 38132 net.cpp:84] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1027 09:56:06.389909 38132 net.cpp:413] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I1027 09:56:06.389917 38132 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1027 09:56:06.389930 38132 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1027 09:56:06.389981 38132 net.cpp:127] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1027 09:56:06.389991 38132 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1027 09:56:06.389997 38132 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1027 09:56:06.390003 38132 net.cpp:144] Memory required for data: 438086200
I1027 09:56:06.390008 38132 layer_factory.hpp:77] Creating layer fire2/expand1x1
I1027 09:56:06.390022 38132 net.cpp:84] Creating Layer fire2/expand1x1
I1027 09:56:06.390027 38132 net.cpp:413] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1027 09:56:06.390039 38132 net.cpp:387] fire2/expand1x1 -> fire2/expand1x1
I1027 09:56:06.390400 38132 net.cpp:127] Setting up fire2/expand1x1
I1027 09:56:06.390413 38132 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 09:56:06.390420 38132 net.cpp:144] Memory required for data: 478227000
I1027 09:56:06.390430 38132 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1027 09:56:06.390440 38132 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1027 09:56:06.390447 38132 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1027 09:56:06.390453 38132 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1027 09:56:06.390460 38132 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I1027 09:56:06.390468 38132 net.cpp:84] Creating Layer fire2/relu_expand1x1
I1027 09:56:06.390473 38132 net.cpp:413] fire2/relu_expand1x1 <- fire2/expand1x1
I1027 09:56:06.390481 38132 net.cpp:374] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I1027 09:56:06.391888 38132 net.cpp:127] Setting up fire2/relu_expand1x1
I1027 09:56:06.391907 38132 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 09:56:06.391916 38132 net.cpp:144] Memory required for data: 518367800
I1027 09:56:06.391921 38132 layer_factory.hpp:77] Creating layer fire2/expand3x3
I1027 09:56:06.391934 38132 net.cpp:84] Creating Layer fire2/expand3x3
I1027 09:56:06.391945 38132 net.cpp:413] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1027 09:56:06.391957 38132 net.cpp:387] fire2/expand3x3 -> fire2/expand3x3
I1027 09:56:06.392407 38132 net.cpp:127] Setting up fire2/expand3x3
I1027 09:56:06.392421 38132 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 09:56:06.392428 38132 net.cpp:144] Memory required for data: 558508600
I1027 09:56:06.392444 38132 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1027 09:56:06.392452 38132 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1027 09:56:06.392458 38132 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1027 09:56:06.392464 38132 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1027 09:56:06.392468 38132 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I1027 09:56:06.392477 38132 net.cpp:84] Creating Layer fire2/relu_expand3x3
I1027 09:56:06.392483 38132 net.cpp:413] fire2/relu_expand3x3 <- fire2/expand3x3
I1027 09:56:06.392491 38132 net.cpp:374] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I1027 09:56:06.392700 38132 net.cpp:127] Setting up fire2/relu_expand3x3
I1027 09:56:06.392711 38132 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 09:56:06.392717 38132 net.cpp:144] Memory required for data: 598649400
I1027 09:56:06.392735 38132 layer_factory.hpp:77] Creating layer fire2/concat
I1027 09:56:06.392745 38132 net.cpp:84] Creating Layer fire2/concat
I1027 09:56:06.392750 38132 net.cpp:413] fire2/concat <- fire2/expand1x1
I1027 09:56:06.392757 38132 net.cpp:413] fire2/concat <- fire2/expand3x3
I1027 09:56:06.392765 38132 net.cpp:387] fire2/concat -> fire2/concat
I1027 09:56:06.392802 38132 net.cpp:127] Setting up fire2/concat
I1027 09:56:06.392812 38132 net.cpp:136] Top shape: 50 128 56 56 (20070400)
I1027 09:56:06.392817 38132 net.cpp:144] Memory required for data: 678931000
I1027 09:56:06.392822 38132 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I1027 09:56:06.392834 38132 net.cpp:84] Creating Layer fire3/squeeze1x1
I1027 09:56:06.392839 38132 net.cpp:413] fire3/squeeze1x1 <- fire2/concat
I1027 09:56:06.392849 38132 net.cpp:387] fire3/squeeze1x1 -> fire3/squeeze1x1
I1027 09:56:06.393203 38132 net.cpp:127] Setting up fire3/squeeze1x1
I1027 09:56:06.393215 38132 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1027 09:56:06.393221 38132 net.cpp:144] Memory required for data: 688966200
I1027 09:56:06.393231 38132 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1027 09:56:06.393241 38132 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1027 09:56:06.393249 38132 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1027 09:56:06.393254 38132 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1027 09:56:06.393260 38132 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I1027 09:56:06.393268 38132 net.cpp:84] Creating Layer fire3/relu_squeeze1x1
I1027 09:56:06.393275 38132 net.cpp:413] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I1027 09:56:06.393282 38132 net.cpp:374] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I1027 09:56:06.393481 38132 net.cpp:127] Setting up fire3/relu_squeeze1x1
I1027 09:56:06.393496 38132 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1027 09:56:06.393501 38132 net.cpp:144] Memory required for data: 699001400
I1027 09:56:06.393507 38132 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1027 09:56:06.393515 38132 net.cpp:84] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1027 09:56:06.393520 38132 net.cpp:413] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I1027 09:56:06.393528 38132 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1027 09:56:06.393537 38132 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1027 09:56:06.393585 38132 net.cpp:127] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1027 09:56:06.393594 38132 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1027 09:56:06.393601 38132 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1027 09:56:06.393607 38132 net.cpp:144] Memory required for data: 719071800
I1027 09:56:06.393612 38132 layer_factory.hpp:77] Creating layer fire3/expand1x1
I1027 09:56:06.393632 38132 net.cpp:84] Creating Layer fire3/expand1x1
I1027 09:56:06.393638 38132 net.cpp:413] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1027 09:56:06.393648 38132 net.cpp:387] fire3/expand1x1 -> fire3/expand1x1
I1027 09:56:06.393990 38132 net.cpp:127] Setting up fire3/expand1x1
I1027 09:56:06.394002 38132 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 09:56:06.394008 38132 net.cpp:144] Memory required for data: 759212600
I1027 09:56:06.394016 38132 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1027 09:56:06.394023 38132 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1027 09:56:06.394031 38132 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1027 09:56:06.394035 38132 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1027 09:56:06.394042 38132 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I1027 09:56:06.394060 38132 net.cpp:84] Creating Layer fire3/relu_expand1x1
I1027 09:56:06.394068 38132 net.cpp:413] fire3/relu_expand1x1 <- fire3/expand1x1
I1027 09:56:06.394076 38132 net.cpp:374] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I1027 09:56:06.394269 38132 net.cpp:127] Setting up fire3/relu_expand1x1
I1027 09:56:06.394282 38132 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 09:56:06.394289 38132 net.cpp:144] Memory required for data: 799353400
I1027 09:56:06.394294 38132 layer_factory.hpp:77] Creating layer fire3/expand3x3
I1027 09:56:06.394315 38132 net.cpp:84] Creating Layer fire3/expand3x3
I1027 09:56:06.394320 38132 net.cpp:413] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1027 09:56:06.394330 38132 net.cpp:387] fire3/expand3x3 -> fire3/expand3x3
I1027 09:56:06.394752 38132 net.cpp:127] Setting up fire3/expand3x3
I1027 09:56:06.394765 38132 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 09:56:06.394771 38132 net.cpp:144] Memory required for data: 839494200
I1027 09:56:06.394779 38132 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1027 09:56:06.394786 38132 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1027 09:56:06.394793 38132 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1027 09:56:06.394798 38132 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1027 09:56:06.394804 38132 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I1027 09:56:06.394812 38132 net.cpp:84] Creating Layer fire3/relu_expand3x3
I1027 09:56:06.394817 38132 net.cpp:413] fire3/relu_expand3x3 <- fire3/expand3x3
I1027 09:56:06.394825 38132 net.cpp:374] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I1027 09:56:06.396198 38132 net.cpp:127] Setting up fire3/relu_expand3x3
I1027 09:56:06.396217 38132 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 09:56:06.396224 38132 net.cpp:144] Memory required for data: 879635000
I1027 09:56:06.396231 38132 layer_factory.hpp:77] Creating layer fire3/concat
I1027 09:56:06.396240 38132 net.cpp:84] Creating Layer fire3/concat
I1027 09:56:06.396248 38132 net.cpp:413] fire3/concat <- fire3/expand1x1
I1027 09:56:06.396255 38132 net.cpp:413] fire3/concat <- fire3/expand3x3
I1027 09:56:06.396263 38132 net.cpp:387] fire3/concat -> fire3/concat
I1027 09:56:06.396307 38132 net.cpp:127] Setting up fire3/concat
I1027 09:56:06.396318 38132 net.cpp:136] Top shape: 50 128 56 56 (20070400)
I1027 09:56:06.396325 38132 net.cpp:144] Memory required for data: 959916600
I1027 09:56:06.396330 38132 layer_factory.hpp:77] Creating layer pool3
I1027 09:56:06.396339 38132 net.cpp:84] Creating Layer pool3
I1027 09:56:06.396345 38132 net.cpp:413] pool3 <- fire3/concat
I1027 09:56:06.396353 38132 net.cpp:387] pool3 -> pool3
I1027 09:56:06.396399 38132 net.cpp:127] Setting up pool3
I1027 09:56:06.396409 38132 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 09:56:06.396414 38132 net.cpp:144] Memory required for data: 979987000
I1027 09:56:06.396420 38132 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I1027 09:56:06.396437 38132 net.cpp:84] Creating Layer fire4/squeeze1x1
I1027 09:56:06.396443 38132 net.cpp:413] fire4/squeeze1x1 <- pool3
I1027 09:56:06.396453 38132 net.cpp:387] fire4/squeeze1x1 -> fire4/squeeze1x1
I1027 09:56:06.396833 38132 net.cpp:127] Setting up fire4/squeeze1x1
I1027 09:56:06.396844 38132 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1027 09:56:06.396852 38132 net.cpp:144] Memory required for data: 985004600
I1027 09:56:06.396859 38132 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1027 09:56:06.396867 38132 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1027 09:56:06.396873 38132 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1027 09:56:06.396879 38132 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1027 09:56:06.396883 38132 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I1027 09:56:06.396904 38132 net.cpp:84] Creating Layer fire4/relu_squeeze1x1
I1027 09:56:06.396911 38132 net.cpp:413] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I1027 09:56:06.396919 38132 net.cpp:374] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I1027 09:56:06.397119 38132 net.cpp:127] Setting up fire4/relu_squeeze1x1
I1027 09:56:06.397130 38132 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1027 09:56:06.397137 38132 net.cpp:144] Memory required for data: 990022200
I1027 09:56:06.397143 38132 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1027 09:56:06.397151 38132 net.cpp:84] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1027 09:56:06.397157 38132 net.cpp:413] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I1027 09:56:06.397166 38132 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1027 09:56:06.397174 38132 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1027 09:56:06.397222 38132 net.cpp:127] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1027 09:56:06.397233 38132 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1027 09:56:06.397239 38132 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1027 09:56:06.397246 38132 net.cpp:144] Memory required for data: 1000057400
I1027 09:56:06.397251 38132 layer_factory.hpp:77] Creating layer fire4/expand1x1
I1027 09:56:06.397263 38132 net.cpp:84] Creating Layer fire4/expand1x1
I1027 09:56:06.397269 38132 net.cpp:413] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1027 09:56:06.397277 38132 net.cpp:387] fire4/expand1x1 -> fire4/expand1x1
I1027 09:56:06.397645 38132 net.cpp:127] Setting up fire4/expand1x1
I1027 09:56:06.397657 38132 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 09:56:06.397665 38132 net.cpp:144] Memory required for data: 1020127800
I1027 09:56:06.397676 38132 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1027 09:56:06.397686 38132 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1027 09:56:06.397693 38132 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1027 09:56:06.397701 38132 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1027 09:56:06.397706 38132 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I1027 09:56:06.397716 38132 net.cpp:84] Creating Layer fire4/relu_expand1x1
I1027 09:56:06.397722 38132 net.cpp:413] fire4/relu_expand1x1 <- fire4/expand1x1
I1027 09:56:06.397728 38132 net.cpp:374] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I1027 09:56:06.397924 38132 net.cpp:127] Setting up fire4/relu_expand1x1
I1027 09:56:06.397935 38132 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 09:56:06.397943 38132 net.cpp:144] Memory required for data: 1040198200
I1027 09:56:06.397948 38132 layer_factory.hpp:77] Creating layer fire4/expand3x3
I1027 09:56:06.397960 38132 net.cpp:84] Creating Layer fire4/expand3x3
I1027 09:56:06.397991 38132 net.cpp:413] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1027 09:56:06.398003 38132 net.cpp:387] fire4/expand3x3 -> fire4/expand3x3
I1027 09:56:06.398671 38132 net.cpp:127] Setting up fire4/expand3x3
I1027 09:56:06.398684 38132 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 09:56:06.398691 38132 net.cpp:144] Memory required for data: 1060268600
I1027 09:56:06.398699 38132 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1027 09:56:06.398706 38132 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1027 09:56:06.398712 38132 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1027 09:56:06.398718 38132 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1027 09:56:06.398723 38132 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I1027 09:56:06.398742 38132 net.cpp:84] Creating Layer fire4/relu_expand3x3
I1027 09:56:06.398749 38132 net.cpp:413] fire4/relu_expand3x3 <- fire4/expand3x3
I1027 09:56:06.398757 38132 net.cpp:374] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I1027 09:56:06.398955 38132 net.cpp:127] Setting up fire4/relu_expand3x3
I1027 09:56:06.398967 38132 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 09:56:06.398973 38132 net.cpp:144] Memory required for data: 1080339000
I1027 09:56:06.398979 38132 layer_factory.hpp:77] Creating layer fire4/concat
I1027 09:56:06.398988 38132 net.cpp:84] Creating Layer fire4/concat
I1027 09:56:06.398993 38132 net.cpp:413] fire4/concat <- fire4/expand1x1
I1027 09:56:06.398999 38132 net.cpp:413] fire4/concat <- fire4/expand3x3
I1027 09:56:06.399008 38132 net.cpp:387] fire4/concat -> fire4/concat
I1027 09:56:06.399039 38132 net.cpp:127] Setting up fire4/concat
I1027 09:56:06.399049 38132 net.cpp:136] Top shape: 50 256 28 28 (10035200)
I1027 09:56:06.399055 38132 net.cpp:144] Memory required for data: 1120479800
I1027 09:56:06.399060 38132 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I1027 09:56:06.399070 38132 net.cpp:84] Creating Layer fire5/squeeze1x1
I1027 09:56:06.399075 38132 net.cpp:413] fire5/squeeze1x1 <- fire4/concat
I1027 09:56:06.399085 38132 net.cpp:387] fire5/squeeze1x1 -> fire5/squeeze1x1
I1027 09:56:06.399504 38132 net.cpp:127] Setting up fire5/squeeze1x1
I1027 09:56:06.399518 38132 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1027 09:56:06.399523 38132 net.cpp:144] Memory required for data: 1125497400
I1027 09:56:06.399531 38132 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1027 09:56:06.399538 38132 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1027 09:56:06.399545 38132 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1027 09:56:06.399551 38132 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1027 09:56:06.399556 38132 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I1027 09:56:06.399564 38132 net.cpp:84] Creating Layer fire5/relu_squeeze1x1
I1027 09:56:06.399570 38132 net.cpp:413] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I1027 09:56:06.399579 38132 net.cpp:374] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I1027 09:56:06.400964 38132 net.cpp:127] Setting up fire5/relu_squeeze1x1
I1027 09:56:06.400984 38132 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1027 09:56:06.400990 38132 net.cpp:144] Memory required for data: 1130515000
I1027 09:56:06.400997 38132 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1027 09:56:06.401010 38132 net.cpp:84] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1027 09:56:06.401018 38132 net.cpp:413] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I1027 09:56:06.401028 38132 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1027 09:56:06.401038 38132 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1027 09:56:06.401099 38132 net.cpp:127] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1027 09:56:06.401110 38132 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1027 09:56:06.401118 38132 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1027 09:56:06.401124 38132 net.cpp:144] Memory required for data: 1140550200
I1027 09:56:06.401129 38132 layer_factory.hpp:77] Creating layer fire5/expand1x1
I1027 09:56:06.401139 38132 net.cpp:84] Creating Layer fire5/expand1x1
I1027 09:56:06.401145 38132 net.cpp:413] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1027 09:56:06.401154 38132 net.cpp:387] fire5/expand1x1 -> fire5/expand1x1
I1027 09:56:06.401526 38132 net.cpp:127] Setting up fire5/expand1x1
I1027 09:56:06.401538 38132 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 09:56:06.401546 38132 net.cpp:144] Memory required for data: 1160620600
I1027 09:56:06.401554 38132 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1027 09:56:06.401576 38132 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1027 09:56:06.401582 38132 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1027 09:56:06.401588 38132 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1027 09:56:06.401594 38132 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I1027 09:56:06.401602 38132 net.cpp:84] Creating Layer fire5/relu_expand1x1
I1027 09:56:06.401608 38132 net.cpp:413] fire5/relu_expand1x1 <- fire5/expand1x1
I1027 09:56:06.401617 38132 net.cpp:374] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I1027 09:56:06.401815 38132 net.cpp:127] Setting up fire5/relu_expand1x1
I1027 09:56:06.401828 38132 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 09:56:06.401834 38132 net.cpp:144] Memory required for data: 1180691000
I1027 09:56:06.401840 38132 layer_factory.hpp:77] Creating layer fire5/expand3x3
I1027 09:56:06.401851 38132 net.cpp:84] Creating Layer fire5/expand3x3
I1027 09:56:06.401857 38132 net.cpp:413] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1027 09:56:06.401867 38132 net.cpp:387] fire5/expand3x3 -> fire5/expand3x3
I1027 09:56:06.402518 38132 net.cpp:127] Setting up fire5/expand3x3
I1027 09:56:06.402530 38132 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 09:56:06.402537 38132 net.cpp:144] Memory required for data: 1200761400
I1027 09:56:06.402545 38132 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1027 09:56:06.402552 38132 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1027 09:56:06.402559 38132 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1027 09:56:06.402565 38132 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1027 09:56:06.402570 38132 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I1027 09:56:06.402577 38132 net.cpp:84] Creating Layer fire5/relu_expand3x3
I1027 09:56:06.402583 38132 net.cpp:413] fire5/relu_expand3x3 <- fire5/expand3x3
I1027 09:56:06.402590 38132 net.cpp:374] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I1027 09:56:06.402786 38132 net.cpp:127] Setting up fire5/relu_expand3x3
I1027 09:56:06.402797 38132 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 09:56:06.402803 38132 net.cpp:144] Memory required for data: 1220831800
I1027 09:56:06.402809 38132 layer_factory.hpp:77] Creating layer fire5/concat
I1027 09:56:06.402818 38132 net.cpp:84] Creating Layer fire5/concat
I1027 09:56:06.402824 38132 net.cpp:413] fire5/concat <- fire5/expand1x1
I1027 09:56:06.402830 38132 net.cpp:413] fire5/concat <- fire5/expand3x3
I1027 09:56:06.402838 38132 net.cpp:387] fire5/concat -> fire5/concat
I1027 09:56:06.402870 38132 net.cpp:127] Setting up fire5/concat
I1027 09:56:06.402880 38132 net.cpp:136] Top shape: 50 256 28 28 (10035200)
I1027 09:56:06.402886 38132 net.cpp:144] Memory required for data: 1260972600
I1027 09:56:06.402891 38132 layer_factory.hpp:77] Creating layer pool5
I1027 09:56:06.402907 38132 net.cpp:84] Creating Layer pool5
I1027 09:56:06.402914 38132 net.cpp:413] pool5 <- fire5/concat
I1027 09:56:06.402921 38132 net.cpp:387] pool5 -> pool5
I1027 09:56:06.402969 38132 net.cpp:127] Setting up pool5
I1027 09:56:06.402979 38132 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 09:56:06.402987 38132 net.cpp:144] Memory required for data: 1271007800
I1027 09:56:06.402992 38132 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I1027 09:56:06.403003 38132 net.cpp:84] Creating Layer fire6/squeeze1x1
I1027 09:56:06.403009 38132 net.cpp:413] fire6/squeeze1x1 <- pool5
I1027 09:56:06.403017 38132 net.cpp:387] fire6/squeeze1x1 -> fire6/squeeze1x1
I1027 09:56:06.403465 38132 net.cpp:127] Setting up fire6/squeeze1x1
I1027 09:56:06.403477 38132 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1027 09:56:06.403484 38132 net.cpp:144] Memory required for data: 1272889400
I1027 09:56:06.403491 38132 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1027 09:56:06.403512 38132 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1027 09:56:06.403520 38132 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1027 09:56:06.403527 38132 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1027 09:56:06.403532 38132 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I1027 09:56:06.403539 38132 net.cpp:84] Creating Layer fire6/relu_squeeze1x1
I1027 09:56:06.403544 38132 net.cpp:413] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I1027 09:56:06.403553 38132 net.cpp:374] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I1027 09:56:06.403751 38132 net.cpp:127] Setting up fire6/relu_squeeze1x1
I1027 09:56:06.403764 38132 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1027 09:56:06.403769 38132 net.cpp:144] Memory required for data: 1274771000
I1027 09:56:06.403776 38132 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1027 09:56:06.403784 38132 net.cpp:84] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1027 09:56:06.403789 38132 net.cpp:413] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I1027 09:56:06.403797 38132 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1027 09:56:06.403806 38132 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1027 09:56:06.403867 38132 net.cpp:127] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1027 09:56:06.403877 38132 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1027 09:56:06.403883 38132 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1027 09:56:06.403888 38132 net.cpp:144] Memory required for data: 1278534200
I1027 09:56:06.403893 38132 layer_factory.hpp:77] Creating layer fire6/expand1x1
I1027 09:56:06.403904 38132 net.cpp:84] Creating Layer fire6/expand1x1
I1027 09:56:06.403910 38132 net.cpp:413] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1027 09:56:06.403918 38132 net.cpp:387] fire6/expand1x1 -> fire6/expand1x1
I1027 09:56:06.404335 38132 net.cpp:127] Setting up fire6/expand1x1
I1027 09:56:06.404346 38132 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1027 09:56:06.404353 38132 net.cpp:144] Memory required for data: 1286060600
I1027 09:56:06.404361 38132 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1027 09:56:06.404368 38132 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1027 09:56:06.404374 38132 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1027 09:56:06.404381 38132 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1027 09:56:06.404386 38132 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I1027 09:56:06.404392 38132 net.cpp:84] Creating Layer fire6/relu_expand1x1
I1027 09:56:06.404398 38132 net.cpp:413] fire6/relu_expand1x1 <- fire6/expand1x1
I1027 09:56:06.404415 38132 net.cpp:374] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I1027 09:56:06.405823 38132 net.cpp:127] Setting up fire6/relu_expand1x1
I1027 09:56:06.405843 38132 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1027 09:56:06.405849 38132 net.cpp:144] Memory required for data: 1293587000
I1027 09:56:06.405858 38132 layer_factory.hpp:77] Creating layer fire6/expand3x3
I1027 09:56:06.405869 38132 net.cpp:84] Creating Layer fire6/expand3x3
I1027 09:56:06.405876 38132 net.cpp:413] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1027 09:56:06.405886 38132 net.cpp:387] fire6/expand3x3 -> fire6/expand3x3
I1027 09:56:06.406942 38132 net.cpp:127] Setting up fire6/expand3x3
I1027 09:56:06.406958 38132 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1027 09:56:06.406966 38132 net.cpp:144] Memory required for data: 1301113400
I1027 09:56:06.406975 38132 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1027 09:56:06.407001 38132 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1027 09:56:06.407007 38132 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1027 09:56:06.407014 38132 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1027 09:56:06.407019 38132 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I1027 09:56:06.407027 38132 net.cpp:84] Creating Layer fire6/relu_expand3x3
I1027 09:56:06.407033 38132 net.cpp:413] fire6/relu_expand3x3 <- fire6/expand3x3
I1027 09:56:06.407042 38132 net.cpp:374] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I1027 09:56:06.407244 38132 net.cpp:127] Setting up fire6/relu_expand3x3
I1027 09:56:06.407258 38132 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1027 09:56:06.407264 38132 net.cpp:144] Memory required for data: 1308639800
I1027 09:56:06.407271 38132 layer_factory.hpp:77] Creating layer fire6/concat
I1027 09:56:06.407279 38132 net.cpp:84] Creating Layer fire6/concat
I1027 09:56:06.407285 38132 net.cpp:413] fire6/concat <- fire6/expand1x1
I1027 09:56:06.407292 38132 net.cpp:413] fire6/concat <- fire6/expand3x3
I1027 09:56:06.407306 38132 net.cpp:387] fire6/concat -> fire6/concat
I1027 09:56:06.407341 38132 net.cpp:127] Setting up fire6/concat
I1027 09:56:06.407352 38132 net.cpp:136] Top shape: 50 384 14 14 (3763200)
I1027 09:56:06.407358 38132 net.cpp:144] Memory required for data: 1323692600
I1027 09:56:06.407363 38132 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I1027 09:56:06.407374 38132 net.cpp:84] Creating Layer fire7/squeeze1x1
I1027 09:56:06.407380 38132 net.cpp:413] fire7/squeeze1x1 <- fire6/concat
I1027 09:56:06.407389 38132 net.cpp:387] fire7/squeeze1x1 -> fire7/squeeze1x1
I1027 09:56:06.407881 38132 net.cpp:127] Setting up fire7/squeeze1x1
I1027 09:56:06.407893 38132 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1027 09:56:06.407899 38132 net.cpp:144] Memory required for data: 1325574200
I1027 09:56:06.407915 38132 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1027 09:56:06.407927 38132 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1027 09:56:06.407935 38132 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1027 09:56:06.407943 38132 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1027 09:56:06.407948 38132 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I1027 09:56:06.407955 38132 net.cpp:84] Creating Layer fire7/relu_squeeze1x1
I1027 09:56:06.407961 38132 net.cpp:413] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I1027 09:56:06.407968 38132 net.cpp:374] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I1027 09:56:06.408172 38132 net.cpp:127] Setting up fire7/relu_squeeze1x1
I1027 09:56:06.408185 38132 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1027 09:56:06.408190 38132 net.cpp:144] Memory required for data: 1327455800
I1027 09:56:06.408196 38132 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1027 09:56:06.408215 38132 net.cpp:84] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1027 09:56:06.408221 38132 net.cpp:413] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I1027 09:56:06.408228 38132 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1027 09:56:06.408238 38132 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1027 09:56:06.408289 38132 net.cpp:127] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1027 09:56:06.408306 38132 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1027 09:56:06.408314 38132 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1027 09:56:06.408319 38132 net.cpp:144] Memory required for data: 1331219000
I1027 09:56:06.408324 38132 layer_factory.hpp:77] Creating layer fire7/expand1x1
I1027 09:56:06.408335 38132 net.cpp:84] Creating Layer fire7/expand1x1
I1027 09:56:06.408354 38132 net.cpp:413] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1027 09:56:06.408363 38132 net.cpp:387] fire7/expand1x1 -> fire7/expand1x1
I1027 09:56:06.408776 38132 net.cpp:127] Setting up fire7/expand1x1
I1027 09:56:06.408787 38132 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1027 09:56:06.408793 38132 net.cpp:144] Memory required for data: 1338745400
I1027 09:56:06.408802 38132 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1027 09:56:06.408808 38132 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1027 09:56:06.408814 38132 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1027 09:56:06.408820 38132 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1027 09:56:06.408825 38132 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I1027 09:56:06.408833 38132 net.cpp:84] Creating Layer fire7/relu_expand1x1
I1027 09:56:06.408839 38132 net.cpp:413] fire7/relu_expand1x1 <- fire7/expand1x1
I1027 09:56:06.408846 38132 net.cpp:374] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I1027 09:56:06.410231 38132 net.cpp:127] Setting up fire7/relu_expand1x1
I1027 09:56:06.410249 38132 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1027 09:56:06.410257 38132 net.cpp:144] Memory required for data: 1346271800
I1027 09:56:06.410264 38132 layer_factory.hpp:77] Creating layer fire7/expand3x3
I1027 09:56:06.410275 38132 net.cpp:84] Creating Layer fire7/expand3x3
I1027 09:56:06.410282 38132 net.cpp:413] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1027 09:56:06.410292 38132 net.cpp:387] fire7/expand3x3 -> fire7/expand3x3
I1027 09:56:06.411361 38132 net.cpp:127] Setting up fire7/expand3x3
I1027 09:56:06.411376 38132 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1027 09:56:06.411383 38132 net.cpp:144] Memory required for data: 1353798200
I1027 09:56:06.411392 38132 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1027 09:56:06.411401 38132 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1027 09:56:06.411408 38132 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1027 09:56:06.411415 38132 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1027 09:56:06.411422 38132 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I1027 09:56:06.411429 38132 net.cpp:84] Creating Layer fire7/relu_expand3x3
I1027 09:56:06.411437 38132 net.cpp:413] fire7/relu_expand3x3 <- fire7/expand3x3
I1027 09:56:06.411444 38132 net.cpp:374] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I1027 09:56:06.411643 38132 net.cpp:127] Setting up fire7/relu_expand3x3
I1027 09:56:06.411655 38132 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1027 09:56:06.411661 38132 net.cpp:144] Memory required for data: 1361324600
I1027 09:56:06.411669 38132 layer_factory.hpp:77] Creating layer fire7/concat
I1027 09:56:06.411676 38132 net.cpp:84] Creating Layer fire7/concat
I1027 09:56:06.411682 38132 net.cpp:413] fire7/concat <- fire7/expand1x1
I1027 09:56:06.411700 38132 net.cpp:413] fire7/concat <- fire7/expand3x3
I1027 09:56:06.411707 38132 net.cpp:387] fire7/concat -> fire7/concat
I1027 09:56:06.411742 38132 net.cpp:127] Setting up fire7/concat
I1027 09:56:06.411752 38132 net.cpp:136] Top shape: 50 384 14 14 (3763200)
I1027 09:56:06.411758 38132 net.cpp:144] Memory required for data: 1376377400
I1027 09:56:06.411763 38132 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I1027 09:56:06.411773 38132 net.cpp:84] Creating Layer fire8/squeeze1x1
I1027 09:56:06.411778 38132 net.cpp:413] fire8/squeeze1x1 <- fire7/concat
I1027 09:56:06.411787 38132 net.cpp:387] fire8/squeeze1x1 -> fire8/squeeze1x1
I1027 09:56:06.413715 38132 net.cpp:127] Setting up fire8/squeeze1x1
I1027 09:56:06.413735 38132 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1027 09:56:06.413743 38132 net.cpp:144] Memory required for data: 1378886200
I1027 09:56:06.413753 38132 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1027 09:56:06.413774 38132 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1027 09:56:06.413782 38132 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1027 09:56:06.413789 38132 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1027 09:56:06.413794 38132 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I1027 09:56:06.413802 38132 net.cpp:84] Creating Layer fire8/relu_squeeze1x1
I1027 09:56:06.413808 38132 net.cpp:413] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I1027 09:56:06.413817 38132 net.cpp:374] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I1027 09:56:06.414029 38132 net.cpp:127] Setting up fire8/relu_squeeze1x1
I1027 09:56:06.414041 38132 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1027 09:56:06.414048 38132 net.cpp:144] Memory required for data: 1381395000
I1027 09:56:06.414054 38132 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1027 09:56:06.414063 38132 net.cpp:84] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1027 09:56:06.414069 38132 net.cpp:413] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I1027 09:56:06.414077 38132 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1027 09:56:06.414088 38132 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1027 09:56:06.414139 38132 net.cpp:127] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1027 09:56:06.414149 38132 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1027 09:56:06.414155 38132 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1027 09:56:06.414161 38132 net.cpp:144] Memory required for data: 1386412600
I1027 09:56:06.414166 38132 layer_factory.hpp:77] Creating layer fire8/expand1x1
I1027 09:56:06.414176 38132 net.cpp:84] Creating Layer fire8/expand1x1
I1027 09:56:06.414182 38132 net.cpp:413] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1027 09:56:06.414192 38132 net.cpp:387] fire8/expand1x1 -> fire8/expand1x1
I1027 09:56:06.414669 38132 net.cpp:127] Setting up fire8/expand1x1
I1027 09:56:06.414682 38132 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 09:56:06.414690 38132 net.cpp:144] Memory required for data: 1396447800
I1027 09:56:06.414697 38132 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1027 09:56:06.414705 38132 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1027 09:56:06.414711 38132 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1027 09:56:06.414717 38132 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1027 09:56:06.414722 38132 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I1027 09:56:06.414731 38132 net.cpp:84] Creating Layer fire8/relu_expand1x1
I1027 09:56:06.414736 38132 net.cpp:413] fire8/relu_expand1x1 <- fire8/expand1x1
I1027 09:56:06.414743 38132 net.cpp:374] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I1027 09:56:06.414954 38132 net.cpp:127] Setting up fire8/relu_expand1x1
I1027 09:56:06.414966 38132 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 09:56:06.414973 38132 net.cpp:144] Memory required for data: 1406483000
I1027 09:56:06.414978 38132 layer_factory.hpp:77] Creating layer fire8/expand3x3
I1027 09:56:06.414989 38132 net.cpp:84] Creating Layer fire8/expand3x3
I1027 09:56:06.414995 38132 net.cpp:413] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1027 09:56:06.415005 38132 net.cpp:387] fire8/expand3x3 -> fire8/expand3x3
I1027 09:56:06.417840 38132 net.cpp:127] Setting up fire8/expand3x3
I1027 09:56:06.417861 38132 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 09:56:06.417868 38132 net.cpp:144] Memory required for data: 1416518200
I1027 09:56:06.417877 38132 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1027 09:56:06.417898 38132 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1027 09:56:06.417906 38132 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1027 09:56:06.417912 38132 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1027 09:56:06.417917 38132 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I1027 09:56:06.417927 38132 net.cpp:84] Creating Layer fire8/relu_expand3x3
I1027 09:56:06.417932 38132 net.cpp:413] fire8/relu_expand3x3 <- fire8/expand3x3
I1027 09:56:06.417942 38132 net.cpp:374] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I1027 09:56:06.419345 38132 net.cpp:127] Setting up fire8/relu_expand3x3
I1027 09:56:06.419365 38132 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 09:56:06.419373 38132 net.cpp:144] Memory required for data: 1426553400
I1027 09:56:06.419379 38132 layer_factory.hpp:77] Creating layer fire8/concat
I1027 09:56:06.419389 38132 net.cpp:84] Creating Layer fire8/concat
I1027 09:56:06.419394 38132 net.cpp:413] fire8/concat <- fire8/expand1x1
I1027 09:56:06.419401 38132 net.cpp:413] fire8/concat <- fire8/expand3x3
I1027 09:56:06.419409 38132 net.cpp:387] fire8/concat -> fire8/concat
I1027 09:56:06.419448 38132 net.cpp:127] Setting up fire8/concat
I1027 09:56:06.419459 38132 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1027 09:56:06.419466 38132 net.cpp:144] Memory required for data: 1446623800
I1027 09:56:06.419471 38132 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I1027 09:56:06.419481 38132 net.cpp:84] Creating Layer fire9/squeeze1x1
I1027 09:56:06.419487 38132 net.cpp:413] fire9/squeeze1x1 <- fire8/concat
I1027 09:56:06.419495 38132 net.cpp:387] fire9/squeeze1x1 -> fire9/squeeze1x1
I1027 09:56:06.420102 38132 net.cpp:127] Setting up fire9/squeeze1x1
I1027 09:56:06.420115 38132 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1027 09:56:06.420121 38132 net.cpp:144] Memory required for data: 1449132600
I1027 09:56:06.420130 38132 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1027 09:56:06.420137 38132 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1027 09:56:06.420143 38132 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1027 09:56:06.420150 38132 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1027 09:56:06.420155 38132 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I1027 09:56:06.420169 38132 net.cpp:84] Creating Layer fire9/relu_squeeze1x1
I1027 09:56:06.420179 38132 net.cpp:413] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I1027 09:56:06.420187 38132 net.cpp:374] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I1027 09:56:06.420398 38132 net.cpp:127] Setting up fire9/relu_squeeze1x1
I1027 09:56:06.420411 38132 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1027 09:56:06.420418 38132 net.cpp:144] Memory required for data: 1451641400
I1027 09:56:06.420425 38132 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1027 09:56:06.420433 38132 net.cpp:84] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1027 09:56:06.420446 38132 net.cpp:413] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I1027 09:56:06.420454 38132 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1027 09:56:06.420464 38132 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1027 09:56:06.420516 38132 net.cpp:127] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1027 09:56:06.420526 38132 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1027 09:56:06.420532 38132 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1027 09:56:06.420538 38132 net.cpp:144] Memory required for data: 1456659000
I1027 09:56:06.420543 38132 layer_factory.hpp:77] Creating layer fire9/expand1x1
I1027 09:56:06.420554 38132 net.cpp:84] Creating Layer fire9/expand1x1
I1027 09:56:06.420560 38132 net.cpp:413] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1027 09:56:06.420583 38132 net.cpp:387] fire9/expand1x1 -> fire9/expand1x1
I1027 09:56:06.421061 38132 net.cpp:127] Setting up fire9/expand1x1
I1027 09:56:06.421075 38132 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 09:56:06.421082 38132 net.cpp:144] Memory required for data: 1466694200
I1027 09:56:06.421089 38132 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1027 09:56:06.421097 38132 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1027 09:56:06.421103 38132 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1027 09:56:06.421108 38132 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1027 09:56:06.421114 38132 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I1027 09:56:06.421121 38132 net.cpp:84] Creating Layer fire9/relu_expand1x1
I1027 09:56:06.421128 38132 net.cpp:413] fire9/relu_expand1x1 <- fire9/expand1x1
I1027 09:56:06.421134 38132 net.cpp:374] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I1027 09:56:06.421357 38132 net.cpp:127] Setting up fire9/relu_expand1x1
I1027 09:56:06.421371 38132 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 09:56:06.421378 38132 net.cpp:144] Memory required for data: 1476729400
I1027 09:56:06.421385 38132 layer_factory.hpp:77] Creating layer fire9/expand3x3
I1027 09:56:06.421396 38132 net.cpp:84] Creating Layer fire9/expand3x3
I1027 09:56:06.421402 38132 net.cpp:413] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1027 09:56:06.421411 38132 net.cpp:387] fire9/expand3x3 -> fire9/expand3x3
I1027 09:56:06.424284 38132 net.cpp:127] Setting up fire9/expand3x3
I1027 09:56:06.424309 38132 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 09:56:06.424317 38132 net.cpp:144] Memory required for data: 1486764600
I1027 09:56:06.424325 38132 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1027 09:56:06.424334 38132 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1027 09:56:06.424340 38132 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1027 09:56:06.424345 38132 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1027 09:56:06.424350 38132 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I1027 09:56:06.424360 38132 net.cpp:84] Creating Layer fire9/relu_expand3x3
I1027 09:56:06.424365 38132 net.cpp:413] fire9/relu_expand3x3 <- fire9/expand3x3
I1027 09:56:06.424374 38132 net.cpp:374] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I1027 09:56:06.424598 38132 net.cpp:127] Setting up fire9/relu_expand3x3
I1027 09:56:06.424610 38132 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 09:56:06.424616 38132 net.cpp:144] Memory required for data: 1496799800
I1027 09:56:06.424623 38132 layer_factory.hpp:77] Creating layer fire9/concat
I1027 09:56:06.424630 38132 net.cpp:84] Creating Layer fire9/concat
I1027 09:56:06.424636 38132 net.cpp:413] fire9/concat <- fire9/expand1x1
I1027 09:56:06.424651 38132 net.cpp:413] fire9/concat <- fire9/expand3x3
I1027 09:56:06.424661 38132 net.cpp:387] fire9/concat -> fire9/concat
I1027 09:56:06.424695 38132 net.cpp:127] Setting up fire9/concat
I1027 09:56:06.424705 38132 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1027 09:56:06.424710 38132 net.cpp:144] Memory required for data: 1516870200
I1027 09:56:06.424715 38132 layer_factory.hpp:77] Creating layer drop9
I1027 09:56:06.424726 38132 net.cpp:84] Creating Layer drop9
I1027 09:56:06.424731 38132 net.cpp:413] drop9 <- fire9/concat
I1027 09:56:06.424737 38132 net.cpp:374] drop9 -> fire9/concat (in-place)
I1027 09:56:06.424768 38132 net.cpp:127] Setting up drop9
I1027 09:56:06.424777 38132 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1027 09:56:06.424783 38132 net.cpp:144] Memory required for data: 1536940600
I1027 09:56:06.424788 38132 layer_factory.hpp:77] Creating layer conv10
I1027 09:56:06.424801 38132 net.cpp:84] Creating Layer conv10
I1027 09:56:06.424819 38132 net.cpp:413] conv10 <- fire9/concat
I1027 09:56:06.424829 38132 net.cpp:387] conv10 -> conv10
I1027 09:56:06.434347 38132 net.cpp:127] Setting up conv10
I1027 09:56:06.434367 38132 net.cpp:136] Top shape: 50 1000 14 14 (9800000)
I1027 09:56:06.434376 38132 net.cpp:144] Memory required for data: 1576140600
I1027 09:56:06.434386 38132 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1027 09:56:06.434394 38132 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1027 09:56:06.434401 38132 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1027 09:56:06.434407 38132 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1027 09:56:06.434412 38132 layer_factory.hpp:77] Creating layer relu_conv10
I1027 09:56:06.434423 38132 net.cpp:84] Creating Layer relu_conv10
I1027 09:56:06.434428 38132 net.cpp:413] relu_conv10 <- conv10
I1027 09:56:06.434435 38132 net.cpp:374] relu_conv10 -> conv10 (in-place)
I1027 09:56:06.435830 38132 net.cpp:127] Setting up relu_conv10
I1027 09:56:06.435852 38132 net.cpp:136] Top shape: 50 1000 14 14 (9800000)
I1027 09:56:06.435858 38132 net.cpp:144] Memory required for data: 1615340600
I1027 09:56:06.435864 38132 layer_factory.hpp:77] Creating layer pool10
I1027 09:56:06.435875 38132 net.cpp:84] Creating Layer pool10
I1027 09:56:06.435883 38132 net.cpp:413] pool10 <- conv10
I1027 09:56:06.435892 38132 net.cpp:387] pool10 -> pool10
I1027 09:56:06.436130 38132 net.cpp:127] Setting up pool10
I1027 09:56:06.436142 38132 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1027 09:56:06.436149 38132 net.cpp:144] Memory required for data: 1615540600
I1027 09:56:06.436156 38132 layer_factory.hpp:77] Creating layer pool10_pool10_0_split
I1027 09:56:06.436164 38132 net.cpp:84] Creating Layer pool10_pool10_0_split
I1027 09:56:06.436170 38132 net.cpp:413] pool10_pool10_0_split <- pool10
I1027 09:56:06.436179 38132 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_0
I1027 09:56:06.436188 38132 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_1
I1027 09:56:06.436197 38132 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_2
I1027 09:56:06.436260 38132 net.cpp:127] Setting up pool10_pool10_0_split
I1027 09:56:06.436269 38132 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1027 09:56:06.436277 38132 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1027 09:56:06.436283 38132 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1027 09:56:06.436288 38132 net.cpp:144] Memory required for data: 1616140600
I1027 09:56:06.436292 38132 layer_factory.hpp:77] Creating layer loss
I1027 09:56:06.436309 38132 net.cpp:84] Creating Layer loss
I1027 09:56:06.436317 38132 net.cpp:413] loss <- pool10_pool10_0_split_0
I1027 09:56:06.436324 38132 net.cpp:413] loss <- label_data_1_split_0
I1027 09:56:06.436331 38132 net.cpp:387] loss -> loss
I1027 09:56:06.436341 38132 layer_factory.hpp:77] Creating layer loss
I1027 09:56:06.436692 38132 net.cpp:127] Setting up loss
I1027 09:56:06.436707 38132 net.cpp:136] Top shape: (1)
I1027 09:56:06.436712 38132 net.cpp:139]     with loss weight 1
I1027 09:56:06.436734 38132 net.cpp:144] Memory required for data: 1616140604
I1027 09:56:06.436740 38132 layer_factory.hpp:77] Creating layer accuracy_top1
I1027 09:56:06.436754 38132 net.cpp:84] Creating Layer accuracy_top1
I1027 09:56:06.436761 38132 net.cpp:413] accuracy_top1 <- pool10_pool10_0_split_1
I1027 09:56:06.436769 38132 net.cpp:413] accuracy_top1 <- label_data_1_split_1
I1027 09:56:06.436776 38132 net.cpp:387] accuracy_top1 -> accuracy_top1
I1027 09:56:06.436790 38132 net.cpp:127] Setting up accuracy_top1
I1027 09:56:06.436800 38132 net.cpp:136] Top shape: (1)
I1027 09:56:06.436805 38132 net.cpp:144] Memory required for data: 1616140608
I1027 09:56:06.436810 38132 layer_factory.hpp:77] Creating layer accuracy_top5
I1027 09:56:06.436820 38132 net.cpp:84] Creating Layer accuracy_top5
I1027 09:56:06.436826 38132 net.cpp:413] accuracy_top5 <- pool10_pool10_0_split_2
I1027 09:56:06.436832 38132 net.cpp:413] accuracy_top5 <- label_data_1_split_2
I1027 09:56:06.436854 38132 net.cpp:387] accuracy_top5 -> accuracy_top5
I1027 09:56:06.436873 38132 net.cpp:127] Setting up accuracy_top5
I1027 09:56:06.436882 38132 net.cpp:136] Top shape: (1)
I1027 09:56:06.436888 38132 net.cpp:144] Memory required for data: 1616140612
I1027 09:56:06.436893 38132 net.cpp:207] accuracy_top5 does not need backward computation.
I1027 09:56:06.436898 38132 net.cpp:207] accuracy_top1 does not need backward computation.
I1027 09:56:06.436903 38132 net.cpp:205] loss needs backward computation.
I1027 09:56:06.436909 38132 net.cpp:205] pool10_pool10_0_split needs backward computation.
I1027 09:56:06.436914 38132 net.cpp:205] pool10 needs backward computation.
I1027 09:56:06.436919 38132 net.cpp:205] relu_conv10 needs backward computation.
I1027 09:56:06.436924 38132 net.cpp:205] conv10 needs backward computation.
I1027 09:56:06.436929 38132 net.cpp:205] drop9 needs backward computation.
I1027 09:56:06.436934 38132 net.cpp:205] fire9/concat needs backward computation.
I1027 09:56:06.436939 38132 net.cpp:205] fire9/relu_expand3x3 needs backward computation.
I1027 09:56:06.436944 38132 net.cpp:205] fire9/expand3x3 needs backward computation.
I1027 09:56:06.436949 38132 net.cpp:205] fire9/relu_expand1x1 needs backward computation.
I1027 09:56:06.436954 38132 net.cpp:205] fire9/expand1x1 needs backward computation.
I1027 09:56:06.436960 38132 net.cpp:205] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I1027 09:56:06.436965 38132 net.cpp:205] fire9/relu_squeeze1x1 needs backward computation.
I1027 09:56:06.436969 38132 net.cpp:205] fire9/squeeze1x1 needs backward computation.
I1027 09:56:06.436975 38132 net.cpp:205] fire8/concat needs backward computation.
I1027 09:56:06.436980 38132 net.cpp:205] fire8/relu_expand3x3 needs backward computation.
I1027 09:56:06.436985 38132 net.cpp:205] fire8/expand3x3 needs backward computation.
I1027 09:56:06.436990 38132 net.cpp:205] fire8/relu_expand1x1 needs backward computation.
I1027 09:56:06.436995 38132 net.cpp:205] fire8/expand1x1 needs backward computation.
I1027 09:56:06.437000 38132 net.cpp:205] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I1027 09:56:06.437005 38132 net.cpp:205] fire8/relu_squeeze1x1 needs backward computation.
I1027 09:56:06.437010 38132 net.cpp:205] fire8/squeeze1x1 needs backward computation.
I1027 09:56:06.437013 38132 net.cpp:205] fire7/concat needs backward computation.
I1027 09:56:06.437018 38132 net.cpp:205] fire7/relu_expand3x3 needs backward computation.
I1027 09:56:06.437023 38132 net.cpp:205] fire7/expand3x3 needs backward computation.
I1027 09:56:06.437027 38132 net.cpp:205] fire7/relu_expand1x1 needs backward computation.
I1027 09:56:06.437032 38132 net.cpp:205] fire7/expand1x1 needs backward computation.
I1027 09:56:06.437037 38132 net.cpp:205] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I1027 09:56:06.437041 38132 net.cpp:205] fire7/relu_squeeze1x1 needs backward computation.
I1027 09:56:06.437047 38132 net.cpp:205] fire7/squeeze1x1 needs backward computation.
I1027 09:56:06.437055 38132 net.cpp:205] fire6/concat needs backward computation.
I1027 09:56:06.437062 38132 net.cpp:205] fire6/relu_expand3x3 needs backward computation.
I1027 09:56:06.437068 38132 net.cpp:205] fire6/expand3x3 needs backward computation.
I1027 09:56:06.437072 38132 net.cpp:205] fire6/relu_expand1x1 needs backward computation.
I1027 09:56:06.437077 38132 net.cpp:205] fire6/expand1x1 needs backward computation.
I1027 09:56:06.437081 38132 net.cpp:205] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I1027 09:56:06.437086 38132 net.cpp:205] fire6/relu_squeeze1x1 needs backward computation.
I1027 09:56:06.437091 38132 net.cpp:205] fire6/squeeze1x1 needs backward computation.
I1027 09:56:06.437096 38132 net.cpp:205] pool5 needs backward computation.
I1027 09:56:06.437101 38132 net.cpp:205] fire5/concat needs backward computation.
I1027 09:56:06.437106 38132 net.cpp:205] fire5/relu_expand3x3 needs backward computation.
I1027 09:56:06.437115 38132 net.cpp:205] fire5/expand3x3 needs backward computation.
I1027 09:56:06.437120 38132 net.cpp:205] fire5/relu_expand1x1 needs backward computation.
I1027 09:56:06.437125 38132 net.cpp:205] fire5/expand1x1 needs backward computation.
I1027 09:56:06.437130 38132 net.cpp:205] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I1027 09:56:06.437134 38132 net.cpp:205] fire5/relu_squeeze1x1 needs backward computation.
I1027 09:56:06.437139 38132 net.cpp:205] fire5/squeeze1x1 needs backward computation.
I1027 09:56:06.437144 38132 net.cpp:205] fire4/concat needs backward computation.
I1027 09:56:06.437149 38132 net.cpp:205] fire4/relu_expand3x3 needs backward computation.
I1027 09:56:06.437153 38132 net.cpp:205] fire4/expand3x3 needs backward computation.
I1027 09:56:06.437158 38132 net.cpp:205] fire4/relu_expand1x1 needs backward computation.
I1027 09:56:06.437162 38132 net.cpp:205] fire4/expand1x1 needs backward computation.
I1027 09:56:06.437167 38132 net.cpp:205] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I1027 09:56:06.437171 38132 net.cpp:205] fire4/relu_squeeze1x1 needs backward computation.
I1027 09:56:06.437176 38132 net.cpp:205] fire4/squeeze1x1 needs backward computation.
I1027 09:56:06.437180 38132 net.cpp:205] pool3 needs backward computation.
I1027 09:56:06.437186 38132 net.cpp:205] fire3/concat needs backward computation.
I1027 09:56:06.437191 38132 net.cpp:205] fire3/relu_expand3x3 needs backward computation.
I1027 09:56:06.437196 38132 net.cpp:205] fire3/expand3x3 needs backward computation.
I1027 09:56:06.437199 38132 net.cpp:205] fire3/relu_expand1x1 needs backward computation.
I1027 09:56:06.437204 38132 net.cpp:205] fire3/expand1x1 needs backward computation.
I1027 09:56:06.437208 38132 net.cpp:205] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I1027 09:56:06.437213 38132 net.cpp:205] fire3/relu_squeeze1x1 needs backward computation.
I1027 09:56:06.437217 38132 net.cpp:205] fire3/squeeze1x1 needs backward computation.
I1027 09:56:06.437223 38132 net.cpp:205] fire2/concat needs backward computation.
I1027 09:56:06.437227 38132 net.cpp:205] fire2/relu_expand3x3 needs backward computation.
I1027 09:56:06.437232 38132 net.cpp:205] fire2/expand3x3 needs backward computation.
I1027 09:56:06.437237 38132 net.cpp:205] fire2/relu_expand1x1 needs backward computation.
I1027 09:56:06.437242 38132 net.cpp:205] fire2/expand1x1 needs backward computation.
I1027 09:56:06.437245 38132 net.cpp:205] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I1027 09:56:06.437250 38132 net.cpp:205] fire2/relu_squeeze1x1 needs backward computation.
I1027 09:56:06.437254 38132 net.cpp:205] fire2/squeeze1x1 needs backward computation.
I1027 09:56:06.437259 38132 net.cpp:205] pool1 needs backward computation.
I1027 09:56:06.437264 38132 net.cpp:205] relu_conv1 needs backward computation.
I1027 09:56:06.437269 38132 net.cpp:205] conv1 needs backward computation.
I1027 09:56:06.437275 38132 net.cpp:207] label_data_1_split does not need backward computation.
I1027 09:56:06.437284 38132 net.cpp:207] data does not need backward computation.
I1027 09:56:06.437289 38132 net.cpp:249] This network produces output accuracy_top1
I1027 09:56:06.437294 38132 net.cpp:249] This network produces output accuracy_top5
I1027 09:56:06.437307 38132 net.cpp:249] This network produces output loss
I1027 09:56:06.437371 38132 net.cpp:262] Network initialization done.
I1027 09:56:06.437631 38132 solver.cpp:56] Solver scaffolding done.
I1027 09:56:06.442198 38132 caffe.cpp:242] Resuming from SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_64500.solverstate
I1027 09:56:06.463568 38132 sgd_solver.cpp:372] SGDSolver: restoring history
I1027 09:56:06.475080 38132 caffe.cpp:248] Starting Optimization
I1027 09:56:10.460104 38184 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_0.prototxt
I1027 09:56:10.464848 38185 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_0.prototxt
I1027 09:56:10.468632 38186 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_0.prototxt
I1027 09:56:11.118397 38186 sgd_solver.cpp:372] SGDSolver: restoring history
I1027 09:56:11.118398 38184 sgd_solver.cpp:372] SGDSolver: restoring history
I1027 09:56:11.118995 38185 sgd_solver.cpp:372] SGDSolver: restoring history
I1027 09:56:11.349828 38132 solver.cpp:276] Solving SqueezeNet
I1027 09:56:11.349879 38132 solver.cpp:277] Learning Rate Policy: poly
I1027 09:56:11.350410 38132 solver.cpp:334] Iteration 64500, Testing net (#0)
I1027 09:56:42.759312 38132 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54216
I1027 09:56:42.759577 38132 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77984
I1027 09:56:42.759603 38132 solver.cpp:401]     Test net output #2: loss = 2.05084 (* 1 = 2.05084 loss)
I1027 09:56:58.870702 38132 solver.cpp:222] Iteration 64520 (1357.8 iter/s, 47.518s/40 iters), loss = 1.54545
I1027 09:56:58.870769 38132 solver.cpp:241]     Train net output #0: loss = 1.54545 (* 1 = 1.54545 loss)
I1027 09:56:58.870786 38132 sgd_solver.cpp:105] Iteration 64520, lr = 0.00563982
I1027 09:57:29.391028 38132 solver.cpp:222] Iteration 64560 (1.31065 iter/s, 30.5191s/40 iters), loss = 1.42419
I1027 09:57:29.391218 38132 solver.cpp:241]     Train net output #0: loss = 1.42419 (* 1 = 1.42419 loss)
I1027 09:57:29.391235 38132 sgd_solver.cpp:105] Iteration 64560, lr = 0.00563726
I1027 09:57:58.937875 38132 solver.cpp:222] Iteration 64600 (1.35384 iter/s, 29.5456s/40 iters), loss = 1.77421
I1027 09:57:58.937943 38132 solver.cpp:241]     Train net output #0: loss = 1.77421 (* 1 = 1.77421 loss)
I1027 09:57:58.937959 38132 sgd_solver.cpp:105] Iteration 64600, lr = 0.00563469
I1027 09:58:28.375020 38132 solver.cpp:222] Iteration 64640 (1.35888 iter/s, 29.436s/40 iters), loss = 1.73137
I1027 09:58:28.375242 38132 solver.cpp:241]     Train net output #0: loss = 1.73137 (* 1 = 1.73137 loss)
I1027 09:58:28.375259 38132 sgd_solver.cpp:105] Iteration 64640, lr = 0.00563212
I1027 09:58:57.981523 38132 solver.cpp:222] Iteration 64680 (1.35112 iter/s, 29.6051s/40 iters), loss = 2.13066
I1027 09:58:57.981608 38132 solver.cpp:241]     Train net output #0: loss = 2.13066 (* 1 = 2.13066 loss)
I1027 09:58:57.981623 38132 sgd_solver.cpp:105] Iteration 64680, lr = 0.00562956
I1027 09:59:27.437065 38132 solver.cpp:222] Iteration 64720 (1.35803 iter/s, 29.4543s/40 iters), loss = 1.75645
I1027 09:59:27.437271 38132 solver.cpp:241]     Train net output #0: loss = 1.75645 (* 1 = 1.75645 loss)
I1027 09:59:27.437288 38132 sgd_solver.cpp:105] Iteration 64720, lr = 0.00562699
I1027 09:59:56.970018 38132 solver.cpp:222] Iteration 64760 (1.35448 iter/s, 29.5316s/40 iters), loss = 1.86828
I1027 09:59:56.970111 38132 solver.cpp:241]     Train net output #0: loss = 1.86828 (* 1 = 1.86828 loss)
I1027 09:59:56.970134 38132 sgd_solver.cpp:105] Iteration 64760, lr = 0.00562443
I1027 10:00:26.404088 38132 solver.cpp:222] Iteration 64800 (1.35903 iter/s, 29.4329s/40 iters), loss = 1.86407
I1027 10:00:26.404309 38132 solver.cpp:241]     Train net output #0: loss = 1.86407 (* 1 = 1.86407 loss)
I1027 10:00:26.404330 38132 sgd_solver.cpp:105] Iteration 64800, lr = 0.00562186
I1027 10:00:43.278195 38132 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_10_iter_64824.caffemodel
I1027 10:00:43.314569 38132 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_10_iter_64824.solverstate
I1027 10:00:43.331046 38132 solver.cpp:298] Optimization stopped early.
*** Aborted at 1509112883 (unix time) try "date -d @1509112883" if you are using GNU date ***
PC: @     0x7f2395dcc705 __pthread_cond_wait
*** SIGTERM (@0x3ed000089d2) received by PID 38132 (TID 0x7f23a8e4d740) from PID 35282; stack trace: ***
    @     0x7f2395dd0130 (unknown)
    @     0x7f2395dcc705 __pthread_cond_wait
    @     0x7f23a8126804 boost::condition_variable::wait()
    @     0x7f239e6968d4 boost::thread::join_noexcept()
    @     0x7f23a8111b8a caffe::InternalThread::StopInternalThread()
    @     0x7f23a812a302 caffe::NCCL<>::Run()
    @           0x40adef train()
    @           0x4082ec main
    @     0x7f2395a21af5 __libc_start_main
    @           0x408bf5 (unknown)
