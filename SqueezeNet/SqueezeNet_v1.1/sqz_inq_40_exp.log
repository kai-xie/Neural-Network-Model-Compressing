nohup: ignoring input
I1028 18:09:30.625854 12309 caffe.cpp:218] Using GPUs 0, 1, 2, 3
I1028 18:09:30.626659 12309 caffe.cpp:223] GPU 0: Tesla P40
I1028 18:09:30.627074 12309 caffe.cpp:223] GPU 1: Tesla P40
I1028 18:09:30.627470 12309 caffe.cpp:223] GPU 2: Tesla P40
I1028 18:09:30.627862 12309 caffe.cpp:223] GPU 3: Tesla P40
I1028 18:09:31.390259 12309 solver.cpp:44] Initializing solver from parameters: 
test_iter: 500
test_interval: 500
base_lr: 0.01
display: 40
max_iter: 100000
lr_policy: "exp"
gamma: 0.9999
momentum: 0.9
weight_decay: 0.0002
snapshot: 500
snapshot_prefix: "SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp"
solver_mode: GPU
device_id: 0
random_seed: 42
net: "SqueezeNet/SqueezeNet_v1.1/train_val_inq_40.prototxt"
train_state {
  level: 0
  stage: ""
}
I1028 18:09:31.391803 12309 solver.cpp:87] Creating training net from net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_40.prototxt
I1028 18:09:31.395534 12309 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1028 18:09:31.395627 12309 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top1
I1028 18:09:31.395635 12309 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top5
I1028 18:09:31.396630 12309 net.cpp:51] Initializing net from parameters: 
name: "SqueezeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/data/caffe-imagenet/ilsvrc12_train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "INQConvolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "fire3/concat"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire4/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool3"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "fire5/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire4/concat"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "fire5/concat"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire6/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool5"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "fire9/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire8/concat"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "INQConvolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "pool10"
  bottom: "label"
  top: "loss"
}
I1028 18:09:31.397192 12309 layer_factory.hpp:77] Creating layer data
I1028 18:09:31.397903 12309 db_lmdb.cpp:35] Opened lmdb /home/data/caffe-imagenet/ilsvrc12_train_lmdb
I1028 18:09:31.397975 12309 net.cpp:84] Creating Layer data
I1028 18:09:31.397989 12309 net.cpp:387] data -> data
I1028 18:09:31.398025 12309 net.cpp:387] data -> label
I1028 18:09:31.400394 12309 data_layer.cpp:45] output data size: 128,3,227,227
I1028 18:09:31.620085 12309 net.cpp:127] Setting up data
I1028 18:09:31.620126 12309 net.cpp:136] Top shape: 128 3 227 227 (19787136)
I1028 18:09:31.620133 12309 net.cpp:136] Top shape: 128 (128)
I1028 18:09:31.620137 12309 net.cpp:144] Memory required for data: 79149056
I1028 18:09:31.620151 12309 layer_factory.hpp:77] Creating layer conv1
I1028 18:09:31.620175 12309 net.cpp:84] Creating Layer conv1
I1028 18:09:31.620183 12309 net.cpp:413] conv1 <- data
I1028 18:09:31.620201 12309 net.cpp:387] conv1 -> conv1
I1028 18:09:31.623431 12309 net.cpp:127] Setting up conv1
I1028 18:09:31.623448 12309 net.cpp:136] Top shape: 128 64 113 113 (104603648)
I1028 18:09:31.623453 12309 net.cpp:144] Memory required for data: 497563648
I1028 18:09:31.623472 12309 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1028 18:09:31.623483 12309 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1028 18:09:31.623492 12309 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1028 18:09:31.623497 12309 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1028 18:09:31.623502 12309 layer_factory.hpp:77] Creating layer relu_conv1
I1028 18:09:31.623517 12309 net.cpp:84] Creating Layer relu_conv1
I1028 18:09:31.623520 12309 net.cpp:413] relu_conv1 <- conv1
I1028 18:09:31.623528 12309 net.cpp:374] relu_conv1 -> conv1 (in-place)
I1028 18:09:32.087132 12309 net.cpp:127] Setting up relu_conv1
I1028 18:09:32.087175 12309 net.cpp:136] Top shape: 128 64 113 113 (104603648)
I1028 18:09:32.087182 12309 net.cpp:144] Memory required for data: 915978240
I1028 18:09:32.087188 12309 layer_factory.hpp:77] Creating layer pool1
I1028 18:09:32.087206 12309 net.cpp:84] Creating Layer pool1
I1028 18:09:32.087213 12309 net.cpp:413] pool1 <- conv1
I1028 18:09:32.087222 12309 net.cpp:387] pool1 -> pool1
I1028 18:09:32.087312 12309 net.cpp:127] Setting up pool1
I1028 18:09:32.087321 12309 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 18:09:32.087355 12309 net.cpp:144] Memory required for data: 1018738688
I1028 18:09:32.087360 12309 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I1028 18:09:32.087375 12309 net.cpp:84] Creating Layer fire2/squeeze1x1
I1028 18:09:32.087380 12309 net.cpp:413] fire2/squeeze1x1 <- pool1
I1028 18:09:32.087388 12309 net.cpp:387] fire2/squeeze1x1 -> fire2/squeeze1x1
I1028 18:09:32.089166 12309 net.cpp:127] Setting up fire2/squeeze1x1
I1028 18:09:32.089184 12309 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 18:09:32.089187 12309 net.cpp:144] Memory required for data: 1044428800
I1028 18:09:32.089198 12309 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1028 18:09:32.089207 12309 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1028 18:09:32.089212 12309 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1028 18:09:32.089217 12309 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1028 18:09:32.089221 12309 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I1028 18:09:32.089229 12309 net.cpp:84] Creating Layer fire2/relu_squeeze1x1
I1028 18:09:32.089233 12309 net.cpp:413] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I1028 18:09:32.089239 12309 net.cpp:374] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I1028 18:09:32.090602 12309 net.cpp:127] Setting up fire2/relu_squeeze1x1
I1028 18:09:32.090617 12309 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 18:09:32.090621 12309 net.cpp:144] Memory required for data: 1070118912
I1028 18:09:32.090626 12309 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1028 18:09:32.090637 12309 net.cpp:84] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1028 18:09:32.090641 12309 net.cpp:413] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I1028 18:09:32.090648 12309 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1028 18:09:32.090656 12309 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1028 18:09:32.090703 12309 net.cpp:127] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1028 18:09:32.090710 12309 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 18:09:32.090715 12309 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 18:09:32.090718 12309 net.cpp:144] Memory required for data: 1121499136
I1028 18:09:32.090723 12309 layer_factory.hpp:77] Creating layer fire2/expand1x1
I1028 18:09:32.090730 12309 net.cpp:84] Creating Layer fire2/expand1x1
I1028 18:09:32.090735 12309 net.cpp:413] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1028 18:09:32.090741 12309 net.cpp:387] fire2/expand1x1 -> fire2/expand1x1
I1028 18:09:32.091059 12309 net.cpp:127] Setting up fire2/expand1x1
I1028 18:09:32.091068 12309 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 18:09:32.091073 12309 net.cpp:144] Memory required for data: 1224259584
I1028 18:09:32.091080 12309 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1028 18:09:32.091089 12309 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1028 18:09:32.091094 12309 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1028 18:09:32.091099 12309 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1028 18:09:32.091102 12309 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I1028 18:09:32.091110 12309 net.cpp:84] Creating Layer fire2/relu_expand1x1
I1028 18:09:32.091114 12309 net.cpp:413] fire2/relu_expand1x1 <- fire2/expand1x1
I1028 18:09:32.091120 12309 net.cpp:374] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I1028 18:09:32.091310 12309 net.cpp:127] Setting up fire2/relu_expand1x1
I1028 18:09:32.091318 12309 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 18:09:32.091326 12309 net.cpp:144] Memory required for data: 1327020032
I1028 18:09:32.091342 12309 layer_factory.hpp:77] Creating layer fire2/expand3x3
I1028 18:09:32.091351 12309 net.cpp:84] Creating Layer fire2/expand3x3
I1028 18:09:32.091356 12309 net.cpp:413] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1028 18:09:32.091363 12309 net.cpp:387] fire2/expand3x3 -> fire2/expand3x3
I1028 18:09:32.091784 12309 net.cpp:127] Setting up fire2/expand3x3
I1028 18:09:32.091794 12309 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 18:09:32.091797 12309 net.cpp:144] Memory required for data: 1429780480
I1028 18:09:32.091804 12309 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1028 18:09:32.091809 12309 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1028 18:09:32.091812 12309 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1028 18:09:32.091817 12309 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1028 18:09:32.091820 12309 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I1028 18:09:32.091826 12309 net.cpp:84] Creating Layer fire2/relu_expand3x3
I1028 18:09:32.091830 12309 net.cpp:413] fire2/relu_expand3x3 <- fire2/expand3x3
I1028 18:09:32.091838 12309 net.cpp:374] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I1028 18:09:32.092053 12309 net.cpp:127] Setting up fire2/relu_expand3x3
I1028 18:09:32.092062 12309 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 18:09:32.092067 12309 net.cpp:144] Memory required for data: 1532540928
I1028 18:09:32.092070 12309 layer_factory.hpp:77] Creating layer fire2/concat
I1028 18:09:32.092079 12309 net.cpp:84] Creating Layer fire2/concat
I1028 18:09:32.092083 12309 net.cpp:413] fire2/concat <- fire2/expand1x1
I1028 18:09:32.092088 12309 net.cpp:413] fire2/concat <- fire2/expand3x3
I1028 18:09:32.092097 12309 net.cpp:387] fire2/concat -> fire2/concat
I1028 18:09:32.092128 12309 net.cpp:127] Setting up fire2/concat
I1028 18:09:32.092134 12309 net.cpp:136] Top shape: 128 128 56 56 (51380224)
I1028 18:09:32.092137 12309 net.cpp:144] Memory required for data: 1738061824
I1028 18:09:32.092141 12309 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I1028 18:09:32.092154 12309 net.cpp:84] Creating Layer fire3/squeeze1x1
I1028 18:09:32.092157 12309 net.cpp:413] fire3/squeeze1x1 <- fire2/concat
I1028 18:09:32.092164 12309 net.cpp:387] fire3/squeeze1x1 -> fire3/squeeze1x1
I1028 18:09:32.092486 12309 net.cpp:127] Setting up fire3/squeeze1x1
I1028 18:09:32.092495 12309 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 18:09:32.092499 12309 net.cpp:144] Memory required for data: 1763751936
I1028 18:09:32.092506 12309 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1028 18:09:32.092515 12309 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1028 18:09:32.092520 12309 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1028 18:09:32.092525 12309 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1028 18:09:32.092530 12309 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I1028 18:09:32.092535 12309 net.cpp:84] Creating Layer fire3/relu_squeeze1x1
I1028 18:09:32.092540 12309 net.cpp:413] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I1028 18:09:32.092545 12309 net.cpp:374] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I1028 18:09:32.093904 12309 net.cpp:127] Setting up fire3/relu_squeeze1x1
I1028 18:09:32.093917 12309 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 18:09:32.093927 12309 net.cpp:144] Memory required for data: 1789442048
I1028 18:09:32.093932 12309 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1028 18:09:32.093940 12309 net.cpp:84] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1028 18:09:32.093945 12309 net.cpp:413] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I1028 18:09:32.093955 12309 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1028 18:09:32.093977 12309 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1028 18:09:32.094027 12309 net.cpp:127] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1028 18:09:32.094033 12309 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 18:09:32.094038 12309 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 18:09:32.094041 12309 net.cpp:144] Memory required for data: 1840822272
I1028 18:09:32.094044 12309 layer_factory.hpp:77] Creating layer fire3/expand1x1
I1028 18:09:32.094055 12309 net.cpp:84] Creating Layer fire3/expand1x1
I1028 18:09:32.094059 12309 net.cpp:413] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1028 18:09:32.094068 12309 net.cpp:387] fire3/expand1x1 -> fire3/expand1x1
I1028 18:09:32.094383 12309 net.cpp:127] Setting up fire3/expand1x1
I1028 18:09:32.094391 12309 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 18:09:32.094394 12309 net.cpp:144] Memory required for data: 1943582720
I1028 18:09:32.094400 12309 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1028 18:09:32.094406 12309 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1028 18:09:32.094410 12309 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1028 18:09:32.094415 12309 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1028 18:09:32.094419 12309 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I1028 18:09:32.094431 12309 net.cpp:84] Creating Layer fire3/relu_expand1x1
I1028 18:09:32.094435 12309 net.cpp:413] fire3/relu_expand1x1 <- fire3/expand1x1
I1028 18:09:32.094441 12309 net.cpp:374] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I1028 18:09:32.094640 12309 net.cpp:127] Setting up fire3/relu_expand1x1
I1028 18:09:32.094650 12309 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 18:09:32.094652 12309 net.cpp:144] Memory required for data: 2046343168
I1028 18:09:32.094656 12309 layer_factory.hpp:77] Creating layer fire3/expand3x3
I1028 18:09:32.094667 12309 net.cpp:84] Creating Layer fire3/expand3x3
I1028 18:09:32.094671 12309 net.cpp:413] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1028 18:09:32.094681 12309 net.cpp:387] fire3/expand3x3 -> fire3/expand3x3
I1028 18:09:32.095088 12309 net.cpp:127] Setting up fire3/expand3x3
I1028 18:09:32.095096 12309 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 18:09:32.095100 12309 net.cpp:144] Memory required for data: 2149103616
I1028 18:09:32.095106 12309 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1028 18:09:32.095111 12309 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1028 18:09:32.095116 12309 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1028 18:09:32.095120 12309 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1028 18:09:32.095124 12309 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I1028 18:09:32.095129 12309 net.cpp:84] Creating Layer fire3/relu_expand3x3
I1028 18:09:32.095134 12309 net.cpp:413] fire3/relu_expand3x3 <- fire3/expand3x3
I1028 18:09:32.095140 12309 net.cpp:374] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I1028 18:09:32.095341 12309 net.cpp:127] Setting up fire3/relu_expand3x3
I1028 18:09:32.095350 12309 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 18:09:32.095355 12309 net.cpp:144] Memory required for data: 2251864064
I1028 18:09:32.095357 12309 layer_factory.hpp:77] Creating layer fire3/concat
I1028 18:09:32.095365 12309 net.cpp:84] Creating Layer fire3/concat
I1028 18:09:32.095367 12309 net.cpp:413] fire3/concat <- fire3/expand1x1
I1028 18:09:32.095372 12309 net.cpp:413] fire3/concat <- fire3/expand3x3
I1028 18:09:32.095379 12309 net.cpp:387] fire3/concat -> fire3/concat
I1028 18:09:32.095413 12309 net.cpp:127] Setting up fire3/concat
I1028 18:09:32.095420 12309 net.cpp:136] Top shape: 128 128 56 56 (51380224)
I1028 18:09:32.095434 12309 net.cpp:144] Memory required for data: 2457384960
I1028 18:09:32.095438 12309 layer_factory.hpp:77] Creating layer pool3
I1028 18:09:32.095444 12309 net.cpp:84] Creating Layer pool3
I1028 18:09:32.095448 12309 net.cpp:413] pool3 <- fire3/concat
I1028 18:09:32.095456 12309 net.cpp:387] pool3 -> pool3
I1028 18:09:32.095500 12309 net.cpp:127] Setting up pool3
I1028 18:09:32.095506 12309 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 18:09:32.095510 12309 net.cpp:144] Memory required for data: 2508765184
I1028 18:09:32.095515 12309 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I1028 18:09:32.095525 12309 net.cpp:84] Creating Layer fire4/squeeze1x1
I1028 18:09:32.095530 12309 net.cpp:413] fire4/squeeze1x1 <- pool3
I1028 18:09:32.095535 12309 net.cpp:387] fire4/squeeze1x1 -> fire4/squeeze1x1
I1028 18:09:32.095881 12309 net.cpp:127] Setting up fire4/squeeze1x1
I1028 18:09:32.095890 12309 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 18:09:32.095893 12309 net.cpp:144] Memory required for data: 2521610240
I1028 18:09:32.095898 12309 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1028 18:09:32.095903 12309 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1028 18:09:32.095908 12309 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1028 18:09:32.095912 12309 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1028 18:09:32.095916 12309 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I1028 18:09:32.095927 12309 net.cpp:84] Creating Layer fire4/relu_squeeze1x1
I1028 18:09:32.095932 12309 net.cpp:413] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I1028 18:09:32.095938 12309 net.cpp:374] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I1028 18:09:32.096145 12309 net.cpp:127] Setting up fire4/relu_squeeze1x1
I1028 18:09:32.096154 12309 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 18:09:32.096160 12309 net.cpp:144] Memory required for data: 2534455296
I1028 18:09:32.096165 12309 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1028 18:09:32.096170 12309 net.cpp:84] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1028 18:09:32.096174 12309 net.cpp:413] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I1028 18:09:32.096180 12309 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1028 18:09:32.096186 12309 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1028 18:09:32.096232 12309 net.cpp:127] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1028 18:09:32.096238 12309 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 18:09:32.096243 12309 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 18:09:32.096246 12309 net.cpp:144] Memory required for data: 2560145408
I1028 18:09:32.096251 12309 layer_factory.hpp:77] Creating layer fire4/expand1x1
I1028 18:09:32.096259 12309 net.cpp:84] Creating Layer fire4/expand1x1
I1028 18:09:32.096263 12309 net.cpp:413] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1028 18:09:32.096271 12309 net.cpp:387] fire4/expand1x1 -> fire4/expand1x1
I1028 18:09:32.096602 12309 net.cpp:127] Setting up fire4/expand1x1
I1028 18:09:32.096611 12309 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 18:09:32.096614 12309 net.cpp:144] Memory required for data: 2611525632
I1028 18:09:32.096626 12309 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1028 18:09:32.096633 12309 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1028 18:09:32.096638 12309 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1028 18:09:32.096642 12309 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1028 18:09:32.096649 12309 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I1028 18:09:32.096668 12309 net.cpp:84] Creating Layer fire4/relu_expand1x1
I1028 18:09:32.096673 12309 net.cpp:413] fire4/relu_expand1x1 <- fire4/expand1x1
I1028 18:09:32.096678 12309 net.cpp:374] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I1028 18:09:32.098052 12309 net.cpp:127] Setting up fire4/relu_expand1x1
I1028 18:09:32.098067 12309 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 18:09:32.098071 12309 net.cpp:144] Memory required for data: 2662905856
I1028 18:09:32.098076 12309 layer_factory.hpp:77] Creating layer fire4/expand3x3
I1028 18:09:32.098088 12309 net.cpp:84] Creating Layer fire4/expand3x3
I1028 18:09:32.098093 12309 net.cpp:413] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1028 18:09:32.098101 12309 net.cpp:387] fire4/expand3x3 -> fire4/expand3x3
I1028 18:09:32.100044 12309 net.cpp:127] Setting up fire4/expand3x3
I1028 18:09:32.100060 12309 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 18:09:32.100065 12309 net.cpp:144] Memory required for data: 2714286080
I1028 18:09:32.100071 12309 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1028 18:09:32.100077 12309 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1028 18:09:32.100082 12309 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1028 18:09:32.100087 12309 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1028 18:09:32.100090 12309 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I1028 18:09:32.100098 12309 net.cpp:84] Creating Layer fire4/relu_expand3x3
I1028 18:09:32.100102 12309 net.cpp:413] fire4/relu_expand3x3 <- fire4/expand3x3
I1028 18:09:32.100108 12309 net.cpp:374] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I1028 18:09:32.100327 12309 net.cpp:127] Setting up fire4/relu_expand3x3
I1028 18:09:32.100337 12309 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 18:09:32.100339 12309 net.cpp:144] Memory required for data: 2765666304
I1028 18:09:32.100344 12309 layer_factory.hpp:77] Creating layer fire4/concat
I1028 18:09:32.100350 12309 net.cpp:84] Creating Layer fire4/concat
I1028 18:09:32.100354 12309 net.cpp:413] fire4/concat <- fire4/expand1x1
I1028 18:09:32.100359 12309 net.cpp:413] fire4/concat <- fire4/expand3x3
I1028 18:09:32.100364 12309 net.cpp:387] fire4/concat -> fire4/concat
I1028 18:09:32.100395 12309 net.cpp:127] Setting up fire4/concat
I1028 18:09:32.100401 12309 net.cpp:136] Top shape: 128 256 28 28 (25690112)
I1028 18:09:32.100404 12309 net.cpp:144] Memory required for data: 2868426752
I1028 18:09:32.100409 12309 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I1028 18:09:32.100419 12309 net.cpp:84] Creating Layer fire5/squeeze1x1
I1028 18:09:32.100422 12309 net.cpp:413] fire5/squeeze1x1 <- fire4/concat
I1028 18:09:32.100430 12309 net.cpp:387] fire5/squeeze1x1 -> fire5/squeeze1x1
I1028 18:09:32.100817 12309 net.cpp:127] Setting up fire5/squeeze1x1
I1028 18:09:32.100826 12309 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 18:09:32.100829 12309 net.cpp:144] Memory required for data: 2881271808
I1028 18:09:32.100836 12309 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1028 18:09:32.100841 12309 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1028 18:09:32.100844 12309 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1028 18:09:32.100849 12309 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1028 18:09:32.100852 12309 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I1028 18:09:32.100858 12309 net.cpp:84] Creating Layer fire5/relu_squeeze1x1
I1028 18:09:32.100862 12309 net.cpp:413] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I1028 18:09:32.100870 12309 net.cpp:374] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I1028 18:09:32.101083 12309 net.cpp:127] Setting up fire5/relu_squeeze1x1
I1028 18:09:32.101094 12309 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 18:09:32.101112 12309 net.cpp:144] Memory required for data: 2894116864
I1028 18:09:32.101116 12309 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1028 18:09:32.101125 12309 net.cpp:84] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1028 18:09:32.101130 12309 net.cpp:413] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I1028 18:09:32.101135 12309 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1028 18:09:32.101142 12309 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1028 18:09:32.101189 12309 net.cpp:127] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1028 18:09:32.101196 12309 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 18:09:32.101200 12309 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 18:09:32.101203 12309 net.cpp:144] Memory required for data: 2919806976
I1028 18:09:32.101207 12309 layer_factory.hpp:77] Creating layer fire5/expand1x1
I1028 18:09:32.101220 12309 net.cpp:84] Creating Layer fire5/expand1x1
I1028 18:09:32.101224 12309 net.cpp:413] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1028 18:09:32.101233 12309 net.cpp:387] fire5/expand1x1 -> fire5/expand1x1
I1028 18:09:32.101578 12309 net.cpp:127] Setting up fire5/expand1x1
I1028 18:09:32.101588 12309 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 18:09:32.101590 12309 net.cpp:144] Memory required for data: 2971187200
I1028 18:09:32.101596 12309 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1028 18:09:32.101601 12309 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1028 18:09:32.101606 12309 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1028 18:09:32.101610 12309 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1028 18:09:32.101614 12309 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I1028 18:09:32.101622 12309 net.cpp:84] Creating Layer fire5/relu_expand1x1
I1028 18:09:32.101626 12309 net.cpp:413] fire5/relu_expand1x1 <- fire5/expand1x1
I1028 18:09:32.101632 12309 net.cpp:374] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I1028 18:09:32.101835 12309 net.cpp:127] Setting up fire5/relu_expand1x1
I1028 18:09:32.101843 12309 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 18:09:32.101846 12309 net.cpp:144] Memory required for data: 3022567424
I1028 18:09:32.101850 12309 layer_factory.hpp:77] Creating layer fire5/expand3x3
I1028 18:09:32.101861 12309 net.cpp:84] Creating Layer fire5/expand3x3
I1028 18:09:32.101864 12309 net.cpp:413] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1028 18:09:32.101873 12309 net.cpp:387] fire5/expand3x3 -> fire5/expand3x3
I1028 18:09:32.102479 12309 net.cpp:127] Setting up fire5/expand3x3
I1028 18:09:32.102488 12309 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 18:09:32.102491 12309 net.cpp:144] Memory required for data: 3073947648
I1028 18:09:32.102497 12309 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1028 18:09:32.102502 12309 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1028 18:09:32.102506 12309 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1028 18:09:32.102510 12309 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1028 18:09:32.102514 12309 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I1028 18:09:32.102522 12309 net.cpp:84] Creating Layer fire5/relu_expand3x3
I1028 18:09:32.102526 12309 net.cpp:413] fire5/relu_expand3x3 <- fire5/expand3x3
I1028 18:09:32.102532 12309 net.cpp:374] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I1028 18:09:32.103899 12309 net.cpp:127] Setting up fire5/relu_expand3x3
I1028 18:09:32.103926 12309 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 18:09:32.103934 12309 net.cpp:144] Memory required for data: 3125327872
I1028 18:09:32.103950 12309 layer_factory.hpp:77] Creating layer fire5/concat
I1028 18:09:32.103957 12309 net.cpp:84] Creating Layer fire5/concat
I1028 18:09:32.103962 12309 net.cpp:413] fire5/concat <- fire5/expand1x1
I1028 18:09:32.103967 12309 net.cpp:413] fire5/concat <- fire5/expand3x3
I1028 18:09:32.103973 12309 net.cpp:387] fire5/concat -> fire5/concat
I1028 18:09:32.104008 12309 net.cpp:127] Setting up fire5/concat
I1028 18:09:32.104015 12309 net.cpp:136] Top shape: 128 256 28 28 (25690112)
I1028 18:09:32.104018 12309 net.cpp:144] Memory required for data: 3228088320
I1028 18:09:32.104022 12309 layer_factory.hpp:77] Creating layer pool5
I1028 18:09:32.104030 12309 net.cpp:84] Creating Layer pool5
I1028 18:09:32.104034 12309 net.cpp:413] pool5 <- fire5/concat
I1028 18:09:32.104040 12309 net.cpp:387] pool5 -> pool5
I1028 18:09:32.104082 12309 net.cpp:127] Setting up pool5
I1028 18:09:32.104089 12309 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 18:09:32.104091 12309 net.cpp:144] Memory required for data: 3253778432
I1028 18:09:32.104094 12309 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I1028 18:09:32.104104 12309 net.cpp:84] Creating Layer fire6/squeeze1x1
I1028 18:09:32.104109 12309 net.cpp:413] fire6/squeeze1x1 <- pool5
I1028 18:09:32.104116 12309 net.cpp:387] fire6/squeeze1x1 -> fire6/squeeze1x1
I1028 18:09:32.104537 12309 net.cpp:127] Setting up fire6/squeeze1x1
I1028 18:09:32.104547 12309 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 18:09:32.104552 12309 net.cpp:144] Memory required for data: 3258595328
I1028 18:09:32.104557 12309 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1028 18:09:32.104562 12309 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1028 18:09:32.104568 12309 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1028 18:09:32.104571 12309 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1028 18:09:32.104575 12309 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I1028 18:09:32.104581 12309 net.cpp:84] Creating Layer fire6/relu_squeeze1x1
I1028 18:09:32.104585 12309 net.cpp:413] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I1028 18:09:32.104590 12309 net.cpp:374] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I1028 18:09:32.104791 12309 net.cpp:127] Setting up fire6/relu_squeeze1x1
I1028 18:09:32.104804 12309 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 18:09:32.104807 12309 net.cpp:144] Memory required for data: 3263412224
I1028 18:09:32.104810 12309 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1028 18:09:32.104816 12309 net.cpp:84] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1028 18:09:32.104820 12309 net.cpp:413] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I1028 18:09:32.104826 12309 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1028 18:09:32.104832 12309 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1028 18:09:32.104887 12309 net.cpp:127] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1028 18:09:32.104892 12309 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 18:09:32.104898 12309 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 18:09:32.104902 12309 net.cpp:144] Memory required for data: 3273046016
I1028 18:09:32.104905 12309 layer_factory.hpp:77] Creating layer fire6/expand1x1
I1028 18:09:32.104917 12309 net.cpp:84] Creating Layer fire6/expand1x1
I1028 18:09:32.104925 12309 net.cpp:413] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1028 18:09:32.104933 12309 net.cpp:387] fire6/expand1x1 -> fire6/expand1x1
I1028 18:09:32.105319 12309 net.cpp:127] Setting up fire6/expand1x1
I1028 18:09:32.105329 12309 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 18:09:32.105334 12309 net.cpp:144] Memory required for data: 3292313600
I1028 18:09:32.105340 12309 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1028 18:09:32.105357 12309 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1028 18:09:32.105361 12309 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1028 18:09:32.105366 12309 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1028 18:09:32.105370 12309 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I1028 18:09:32.105381 12309 net.cpp:84] Creating Layer fire6/relu_expand1x1
I1028 18:09:32.105386 12309 net.cpp:413] fire6/relu_expand1x1 <- fire6/expand1x1
I1028 18:09:32.105391 12309 net.cpp:374] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I1028 18:09:32.105592 12309 net.cpp:127] Setting up fire6/relu_expand1x1
I1028 18:09:32.105599 12309 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 18:09:32.105603 12309 net.cpp:144] Memory required for data: 3311581184
I1028 18:09:32.105607 12309 layer_factory.hpp:77] Creating layer fire6/expand3x3
I1028 18:09:32.105618 12309 net.cpp:84] Creating Layer fire6/expand3x3
I1028 18:09:32.105623 12309 net.cpp:413] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1028 18:09:32.105629 12309 net.cpp:387] fire6/expand3x3 -> fire6/expand3x3
I1028 18:09:32.107990 12309 net.cpp:127] Setting up fire6/expand3x3
I1028 18:09:32.108006 12309 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 18:09:32.108011 12309 net.cpp:144] Memory required for data: 3330848768
I1028 18:09:32.108016 12309 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1028 18:09:32.108022 12309 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1028 18:09:32.108026 12309 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1028 18:09:32.108031 12309 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1028 18:09:32.108034 12309 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I1028 18:09:32.108042 12309 net.cpp:84] Creating Layer fire6/relu_expand3x3
I1028 18:09:32.108047 12309 net.cpp:413] fire6/relu_expand3x3 <- fire6/expand3x3
I1028 18:09:32.108052 12309 net.cpp:374] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I1028 18:09:32.108278 12309 net.cpp:127] Setting up fire6/relu_expand3x3
I1028 18:09:32.108289 12309 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 18:09:32.108292 12309 net.cpp:144] Memory required for data: 3350116352
I1028 18:09:32.108296 12309 layer_factory.hpp:77] Creating layer fire6/concat
I1028 18:09:32.108304 12309 net.cpp:84] Creating Layer fire6/concat
I1028 18:09:32.108307 12309 net.cpp:413] fire6/concat <- fire6/expand1x1
I1028 18:09:32.108312 12309 net.cpp:413] fire6/concat <- fire6/expand3x3
I1028 18:09:32.108317 12309 net.cpp:387] fire6/concat -> fire6/concat
I1028 18:09:32.108350 12309 net.cpp:127] Setting up fire6/concat
I1028 18:09:32.108357 12309 net.cpp:136] Top shape: 128 384 14 14 (9633792)
I1028 18:09:32.108361 12309 net.cpp:144] Memory required for data: 3388651520
I1028 18:09:32.108364 12309 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I1028 18:09:32.108374 12309 net.cpp:84] Creating Layer fire7/squeeze1x1
I1028 18:09:32.108378 12309 net.cpp:413] fire7/squeeze1x1 <- fire6/concat
I1028 18:09:32.108386 12309 net.cpp:387] fire7/squeeze1x1 -> fire7/squeeze1x1
I1028 18:09:32.108857 12309 net.cpp:127] Setting up fire7/squeeze1x1
I1028 18:09:32.108865 12309 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 18:09:32.108870 12309 net.cpp:144] Memory required for data: 3393468416
I1028 18:09:32.108882 12309 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1028 18:09:32.108893 12309 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1028 18:09:32.108898 12309 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1028 18:09:32.108903 12309 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1028 18:09:32.108911 12309 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I1028 18:09:32.108934 12309 net.cpp:84] Creating Layer fire7/relu_squeeze1x1
I1028 18:09:32.108939 12309 net.cpp:413] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I1028 18:09:32.108947 12309 net.cpp:374] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I1028 18:09:32.110323 12309 net.cpp:127] Setting up fire7/relu_squeeze1x1
I1028 18:09:32.110337 12309 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 18:09:32.110342 12309 net.cpp:144] Memory required for data: 3398285312
I1028 18:09:32.110345 12309 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1028 18:09:32.110352 12309 net.cpp:84] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1028 18:09:32.110357 12309 net.cpp:413] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I1028 18:09:32.110365 12309 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1028 18:09:32.110373 12309 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1028 18:09:32.110424 12309 net.cpp:127] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1028 18:09:32.110430 12309 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 18:09:32.110435 12309 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 18:09:32.110438 12309 net.cpp:144] Memory required for data: 3407919104
I1028 18:09:32.110442 12309 layer_factory.hpp:77] Creating layer fire7/expand1x1
I1028 18:09:32.110455 12309 net.cpp:84] Creating Layer fire7/expand1x1
I1028 18:09:32.110458 12309 net.cpp:413] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1028 18:09:32.110465 12309 net.cpp:387] fire7/expand1x1 -> fire7/expand1x1
I1028 18:09:32.110863 12309 net.cpp:127] Setting up fire7/expand1x1
I1028 18:09:32.110872 12309 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 18:09:32.110875 12309 net.cpp:144] Memory required for data: 3427186688
I1028 18:09:32.110882 12309 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1028 18:09:32.110888 12309 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1028 18:09:32.110891 12309 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1028 18:09:32.110895 12309 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1028 18:09:32.110899 12309 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I1028 18:09:32.110905 12309 net.cpp:84] Creating Layer fire7/relu_expand1x1
I1028 18:09:32.110909 12309 net.cpp:413] fire7/relu_expand1x1 <- fire7/expand1x1
I1028 18:09:32.110916 12309 net.cpp:374] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I1028 18:09:32.111127 12309 net.cpp:127] Setting up fire7/relu_expand1x1
I1028 18:09:32.111136 12309 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 18:09:32.111140 12309 net.cpp:144] Memory required for data: 3446454272
I1028 18:09:32.111145 12309 layer_factory.hpp:77] Creating layer fire7/expand3x3
I1028 18:09:32.111155 12309 net.cpp:84] Creating Layer fire7/expand3x3
I1028 18:09:32.111158 12309 net.cpp:413] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1028 18:09:32.111168 12309 net.cpp:387] fire7/expand3x3 -> fire7/expand3x3
I1028 18:09:32.112161 12309 net.cpp:127] Setting up fire7/expand3x3
I1028 18:09:32.112170 12309 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 18:09:32.112174 12309 net.cpp:144] Memory required for data: 3465721856
I1028 18:09:32.112180 12309 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1028 18:09:32.112185 12309 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1028 18:09:32.112190 12309 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1028 18:09:32.112195 12309 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1028 18:09:32.112202 12309 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I1028 18:09:32.112221 12309 net.cpp:84] Creating Layer fire7/relu_expand3x3
I1028 18:09:32.112226 12309 net.cpp:413] fire7/relu_expand3x3 <- fire7/expand3x3
I1028 18:09:32.112232 12309 net.cpp:374] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I1028 18:09:32.112437 12309 net.cpp:127] Setting up fire7/relu_expand3x3
I1028 18:09:32.112445 12309 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 18:09:32.112448 12309 net.cpp:144] Memory required for data: 3484989440
I1028 18:09:32.112452 12309 layer_factory.hpp:77] Creating layer fire7/concat
I1028 18:09:32.112458 12309 net.cpp:84] Creating Layer fire7/concat
I1028 18:09:32.112462 12309 net.cpp:413] fire7/concat <- fire7/expand1x1
I1028 18:09:32.112468 12309 net.cpp:413] fire7/concat <- fire7/expand3x3
I1028 18:09:32.112475 12309 net.cpp:387] fire7/concat -> fire7/concat
I1028 18:09:32.112506 12309 net.cpp:127] Setting up fire7/concat
I1028 18:09:32.112512 12309 net.cpp:136] Top shape: 128 384 14 14 (9633792)
I1028 18:09:32.112515 12309 net.cpp:144] Memory required for data: 3523524608
I1028 18:09:32.112519 12309 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I1028 18:09:32.112529 12309 net.cpp:84] Creating Layer fire8/squeeze1x1
I1028 18:09:32.112534 12309 net.cpp:413] fire8/squeeze1x1 <- fire7/concat
I1028 18:09:32.112540 12309 net.cpp:387] fire8/squeeze1x1 -> fire8/squeeze1x1
I1028 18:09:32.113061 12309 net.cpp:127] Setting up fire8/squeeze1x1
I1028 18:09:32.113072 12309 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 18:09:32.113076 12309 net.cpp:144] Memory required for data: 3529947136
I1028 18:09:32.113081 12309 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1028 18:09:32.113087 12309 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1028 18:09:32.113091 12309 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1028 18:09:32.113096 12309 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1028 18:09:32.113099 12309 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I1028 18:09:32.113106 12309 net.cpp:84] Creating Layer fire8/relu_squeeze1x1
I1028 18:09:32.113109 12309 net.cpp:413] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I1028 18:09:32.113116 12309 net.cpp:374] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I1028 18:09:32.114491 12309 net.cpp:127] Setting up fire8/relu_squeeze1x1
I1028 18:09:32.114506 12309 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 18:09:32.114511 12309 net.cpp:144] Memory required for data: 3536369664
I1028 18:09:32.114514 12309 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1028 18:09:32.114523 12309 net.cpp:84] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1028 18:09:32.114528 12309 net.cpp:413] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I1028 18:09:32.114534 12309 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1028 18:09:32.114542 12309 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1028 18:09:32.114593 12309 net.cpp:127] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1028 18:09:32.114599 12309 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 18:09:32.114604 12309 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 18:09:32.114608 12309 net.cpp:144] Memory required for data: 3549214720
I1028 18:09:32.114611 12309 layer_factory.hpp:77] Creating layer fire8/expand1x1
I1028 18:09:32.114622 12309 net.cpp:84] Creating Layer fire8/expand1x1
I1028 18:09:32.114626 12309 net.cpp:413] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1028 18:09:32.114634 12309 net.cpp:387] fire8/expand1x1 -> fire8/expand1x1
I1028 18:09:32.115092 12309 net.cpp:127] Setting up fire8/expand1x1
I1028 18:09:32.115100 12309 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 18:09:32.115108 12309 net.cpp:144] Memory required for data: 3574904832
I1028 18:09:32.115126 12309 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1028 18:09:32.115133 12309 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1028 18:09:32.115136 12309 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1028 18:09:32.115141 12309 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1028 18:09:32.115144 12309 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I1028 18:09:32.115151 12309 net.cpp:84] Creating Layer fire8/relu_expand1x1
I1028 18:09:32.115155 12309 net.cpp:413] fire8/relu_expand1x1 <- fire8/expand1x1
I1028 18:09:32.115164 12309 net.cpp:374] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I1028 18:09:32.115368 12309 net.cpp:127] Setting up fire8/relu_expand1x1
I1028 18:09:32.115377 12309 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 18:09:32.115381 12309 net.cpp:144] Memory required for data: 3600594944
I1028 18:09:32.115386 12309 layer_factory.hpp:77] Creating layer fire8/expand3x3
I1028 18:09:32.115396 12309 net.cpp:84] Creating Layer fire8/expand3x3
I1028 18:09:32.115399 12309 net.cpp:413] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1028 18:09:32.115407 12309 net.cpp:387] fire8/expand3x3 -> fire8/expand3x3
I1028 18:09:32.118233 12309 net.cpp:127] Setting up fire8/expand3x3
I1028 18:09:32.118247 12309 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 18:09:32.118252 12309 net.cpp:144] Memory required for data: 3626285056
I1028 18:09:32.118258 12309 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1028 18:09:32.118264 12309 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1028 18:09:32.118268 12309 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1028 18:09:32.118273 12309 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1028 18:09:32.118276 12309 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I1028 18:09:32.118283 12309 net.cpp:84] Creating Layer fire8/relu_expand3x3
I1028 18:09:32.118288 12309 net.cpp:413] fire8/relu_expand3x3 <- fire8/expand3x3
I1028 18:09:32.118296 12309 net.cpp:374] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I1028 18:09:32.118521 12309 net.cpp:127] Setting up fire8/relu_expand3x3
I1028 18:09:32.118531 12309 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 18:09:32.118535 12309 net.cpp:144] Memory required for data: 3651975168
I1028 18:09:32.118540 12309 layer_factory.hpp:77] Creating layer fire8/concat
I1028 18:09:32.118546 12309 net.cpp:84] Creating Layer fire8/concat
I1028 18:09:32.118549 12309 net.cpp:413] fire8/concat <- fire8/expand1x1
I1028 18:09:32.118554 12309 net.cpp:413] fire8/concat <- fire8/expand3x3
I1028 18:09:32.118561 12309 net.cpp:387] fire8/concat -> fire8/concat
I1028 18:09:32.118592 12309 net.cpp:127] Setting up fire8/concat
I1028 18:09:32.118598 12309 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1028 18:09:32.118602 12309 net.cpp:144] Memory required for data: 3703355392
I1028 18:09:32.118605 12309 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I1028 18:09:32.118615 12309 net.cpp:84] Creating Layer fire9/squeeze1x1
I1028 18:09:32.118621 12309 net.cpp:413] fire9/squeeze1x1 <- fire8/concat
I1028 18:09:32.118628 12309 net.cpp:387] fire9/squeeze1x1 -> fire9/squeeze1x1
I1028 18:09:32.119220 12309 net.cpp:127] Setting up fire9/squeeze1x1
I1028 18:09:32.119230 12309 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 18:09:32.119233 12309 net.cpp:144] Memory required for data: 3709777920
I1028 18:09:32.119240 12309 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1028 18:09:32.119244 12309 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1028 18:09:32.119248 12309 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1028 18:09:32.119252 12309 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1028 18:09:32.119274 12309 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I1028 18:09:32.119282 12309 net.cpp:84] Creating Layer fire9/relu_squeeze1x1
I1028 18:09:32.119285 12309 net.cpp:413] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I1028 18:09:32.119293 12309 net.cpp:374] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I1028 18:09:32.119501 12309 net.cpp:127] Setting up fire9/relu_squeeze1x1
I1028 18:09:32.119509 12309 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 18:09:32.119513 12309 net.cpp:144] Memory required for data: 3716200448
I1028 18:09:32.119518 12309 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1028 18:09:32.119534 12309 net.cpp:84] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1028 18:09:32.119539 12309 net.cpp:413] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I1028 18:09:32.119545 12309 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1028 18:09:32.119554 12309 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1028 18:09:32.119606 12309 net.cpp:127] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1028 18:09:32.119613 12309 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 18:09:32.119618 12309 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 18:09:32.119621 12309 net.cpp:144] Memory required for data: 3729045504
I1028 18:09:32.119626 12309 layer_factory.hpp:77] Creating layer fire9/expand1x1
I1028 18:09:32.119633 12309 net.cpp:84] Creating Layer fire9/expand1x1
I1028 18:09:32.119637 12309 net.cpp:413] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1028 18:09:32.119645 12309 net.cpp:387] fire9/expand1x1 -> fire9/expand1x1
I1028 18:09:32.120103 12309 net.cpp:127] Setting up fire9/expand1x1
I1028 18:09:32.120111 12309 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 18:09:32.120115 12309 net.cpp:144] Memory required for data: 3754735616
I1028 18:09:32.120121 12309 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1028 18:09:32.120126 12309 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1028 18:09:32.120131 12309 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1028 18:09:32.120136 12309 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1028 18:09:32.120138 12309 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I1028 18:09:32.120146 12309 net.cpp:84] Creating Layer fire9/relu_expand1x1
I1028 18:09:32.120149 12309 net.cpp:413] fire9/relu_expand1x1 <- fire9/expand1x1
I1028 18:09:32.120157 12309 net.cpp:374] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I1028 18:09:32.121551 12309 net.cpp:127] Setting up fire9/relu_expand1x1
I1028 18:09:32.121565 12309 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 18:09:32.121570 12309 net.cpp:144] Memory required for data: 3780425728
I1028 18:09:32.121574 12309 layer_factory.hpp:77] Creating layer fire9/expand3x3
I1028 18:09:32.121587 12309 net.cpp:84] Creating Layer fire9/expand3x3
I1028 18:09:32.121592 12309 net.cpp:413] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1028 18:09:32.121600 12309 net.cpp:387] fire9/expand3x3 -> fire9/expand3x3
I1028 18:09:32.123100 12309 net.cpp:127] Setting up fire9/expand3x3
I1028 18:09:32.123109 12309 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 18:09:32.123113 12309 net.cpp:144] Memory required for data: 3806115840
I1028 18:09:32.123119 12309 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1028 18:09:32.123124 12309 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1028 18:09:32.123129 12309 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1028 18:09:32.123133 12309 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1028 18:09:32.123142 12309 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I1028 18:09:32.123159 12309 net.cpp:84] Creating Layer fire9/relu_expand3x3
I1028 18:09:32.123164 12309 net.cpp:413] fire9/relu_expand3x3 <- fire9/expand3x3
I1028 18:09:32.123172 12309 net.cpp:374] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I1028 18:09:32.123383 12309 net.cpp:127] Setting up fire9/relu_expand3x3
I1028 18:09:32.123391 12309 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 18:09:32.123394 12309 net.cpp:144] Memory required for data: 3831805952
I1028 18:09:32.123399 12309 layer_factory.hpp:77] Creating layer fire9/concat
I1028 18:09:32.123405 12309 net.cpp:84] Creating Layer fire9/concat
I1028 18:09:32.123411 12309 net.cpp:413] fire9/concat <- fire9/expand1x1
I1028 18:09:32.123416 12309 net.cpp:413] fire9/concat <- fire9/expand3x3
I1028 18:09:32.123421 12309 net.cpp:387] fire9/concat -> fire9/concat
I1028 18:09:32.123451 12309 net.cpp:127] Setting up fire9/concat
I1028 18:09:32.123457 12309 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1028 18:09:32.123461 12309 net.cpp:144] Memory required for data: 3883186176
I1028 18:09:32.123464 12309 layer_factory.hpp:77] Creating layer drop9
I1028 18:09:32.123476 12309 net.cpp:84] Creating Layer drop9
I1028 18:09:32.123479 12309 net.cpp:413] drop9 <- fire9/concat
I1028 18:09:32.123486 12309 net.cpp:374] drop9 -> fire9/concat (in-place)
I1028 18:09:32.123515 12309 net.cpp:127] Setting up drop9
I1028 18:09:32.123522 12309 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1028 18:09:32.123524 12309 net.cpp:144] Memory required for data: 3934566400
I1028 18:09:32.123528 12309 layer_factory.hpp:77] Creating layer conv10
I1028 18:09:32.123539 12309 net.cpp:84] Creating Layer conv10
I1028 18:09:32.123543 12309 net.cpp:413] conv10 <- fire9/concat
I1028 18:09:32.123551 12309 net.cpp:387] conv10 -> conv10
I1028 18:09:32.137145 12309 net.cpp:127] Setting up conv10
I1028 18:09:32.137161 12309 net.cpp:136] Top shape: 128 1000 14 14 (25088000)
I1028 18:09:32.137164 12309 net.cpp:144] Memory required for data: 4034918400
I1028 18:09:32.137171 12309 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1028 18:09:32.137177 12309 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1028 18:09:32.137181 12309 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1028 18:09:32.137186 12309 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1028 18:09:32.137189 12309 layer_factory.hpp:77] Creating layer relu_conv10
I1028 18:09:32.137198 12309 net.cpp:84] Creating Layer relu_conv10
I1028 18:09:32.137203 12309 net.cpp:413] relu_conv10 <- conv10
I1028 18:09:32.137209 12309 net.cpp:374] relu_conv10 -> conv10 (in-place)
I1028 18:09:32.137439 12309 net.cpp:127] Setting up relu_conv10
I1028 18:09:32.137449 12309 net.cpp:136] Top shape: 128 1000 14 14 (25088000)
I1028 18:09:32.137452 12309 net.cpp:144] Memory required for data: 4135270400
I1028 18:09:32.137456 12309 layer_factory.hpp:77] Creating layer pool10
I1028 18:09:32.137470 12309 net.cpp:84] Creating Layer pool10
I1028 18:09:32.137473 12309 net.cpp:413] pool10 <- conv10
I1028 18:09:32.137481 12309 net.cpp:387] pool10 -> pool10
I1028 18:09:32.137717 12309 net.cpp:127] Setting up pool10
I1028 18:09:32.137725 12309 net.cpp:136] Top shape: 128 1000 1 1 (128000)
I1028 18:09:32.137729 12309 net.cpp:144] Memory required for data: 4135782400
I1028 18:09:32.137733 12309 layer_factory.hpp:77] Creating layer loss
I1028 18:09:32.137742 12309 net.cpp:84] Creating Layer loss
I1028 18:09:32.137745 12309 net.cpp:413] loss <- pool10
I1028 18:09:32.137750 12309 net.cpp:413] loss <- label
I1028 18:09:32.137759 12309 net.cpp:387] loss -> loss
I1028 18:09:32.137771 12309 layer_factory.hpp:77] Creating layer loss
I1028 18:09:32.140697 12309 net.cpp:127] Setting up loss
I1028 18:09:32.140710 12309 net.cpp:136] Top shape: (1)
I1028 18:09:32.140714 12309 net.cpp:139]     with loss weight 1
I1028 18:09:32.140741 12309 net.cpp:144] Memory required for data: 4135782404
I1028 18:09:32.140749 12309 net.cpp:205] loss needs backward computation.
I1028 18:09:32.140765 12309 net.cpp:205] pool10 needs backward computation.
I1028 18:09:32.140769 12309 net.cpp:205] relu_conv10 needs backward computation.
I1028 18:09:32.140774 12309 net.cpp:205] conv10 needs backward computation.
I1028 18:09:32.140776 12309 net.cpp:205] drop9 needs backward computation.
I1028 18:09:32.140780 12309 net.cpp:205] fire9/concat needs backward computation.
I1028 18:09:32.140784 12309 net.cpp:205] fire9/relu_expand3x3 needs backward computation.
I1028 18:09:32.140787 12309 net.cpp:205] fire9/expand3x3 needs backward computation.
I1028 18:09:32.140791 12309 net.cpp:205] fire9/relu_expand1x1 needs backward computation.
I1028 18:09:32.140794 12309 net.cpp:205] fire9/expand1x1 needs backward computation.
I1028 18:09:32.140799 12309 net.cpp:205] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I1028 18:09:32.140802 12309 net.cpp:205] fire9/relu_squeeze1x1 needs backward computation.
I1028 18:09:32.140806 12309 net.cpp:205] fire9/squeeze1x1 needs backward computation.
I1028 18:09:32.140810 12309 net.cpp:205] fire8/concat needs backward computation.
I1028 18:09:32.140813 12309 net.cpp:205] fire8/relu_expand3x3 needs backward computation.
I1028 18:09:32.140817 12309 net.cpp:205] fire8/expand3x3 needs backward computation.
I1028 18:09:32.140821 12309 net.cpp:205] fire8/relu_expand1x1 needs backward computation.
I1028 18:09:32.140825 12309 net.cpp:205] fire8/expand1x1 needs backward computation.
I1028 18:09:32.140828 12309 net.cpp:205] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I1028 18:09:32.140831 12309 net.cpp:205] fire8/relu_squeeze1x1 needs backward computation.
I1028 18:09:32.140836 12309 net.cpp:205] fire8/squeeze1x1 needs backward computation.
I1028 18:09:32.140838 12309 net.cpp:205] fire7/concat needs backward computation.
I1028 18:09:32.140842 12309 net.cpp:205] fire7/relu_expand3x3 needs backward computation.
I1028 18:09:32.140846 12309 net.cpp:205] fire7/expand3x3 needs backward computation.
I1028 18:09:32.140849 12309 net.cpp:205] fire7/relu_expand1x1 needs backward computation.
I1028 18:09:32.140852 12309 net.cpp:205] fire7/expand1x1 needs backward computation.
I1028 18:09:32.140856 12309 net.cpp:205] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I1028 18:09:32.140859 12309 net.cpp:205] fire7/relu_squeeze1x1 needs backward computation.
I1028 18:09:32.140863 12309 net.cpp:205] fire7/squeeze1x1 needs backward computation.
I1028 18:09:32.140866 12309 net.cpp:205] fire6/concat needs backward computation.
I1028 18:09:32.140871 12309 net.cpp:205] fire6/relu_expand3x3 needs backward computation.
I1028 18:09:32.140874 12309 net.cpp:205] fire6/expand3x3 needs backward computation.
I1028 18:09:32.140877 12309 net.cpp:205] fire6/relu_expand1x1 needs backward computation.
I1028 18:09:32.140880 12309 net.cpp:205] fire6/expand1x1 needs backward computation.
I1028 18:09:32.140884 12309 net.cpp:205] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I1028 18:09:32.140887 12309 net.cpp:205] fire6/relu_squeeze1x1 needs backward computation.
I1028 18:09:32.140892 12309 net.cpp:205] fire6/squeeze1x1 needs backward computation.
I1028 18:09:32.140894 12309 net.cpp:205] pool5 needs backward computation.
I1028 18:09:32.140898 12309 net.cpp:205] fire5/concat needs backward computation.
I1028 18:09:32.140902 12309 net.cpp:205] fire5/relu_expand3x3 needs backward computation.
I1028 18:09:32.140905 12309 net.cpp:205] fire5/expand3x3 needs backward computation.
I1028 18:09:32.140909 12309 net.cpp:205] fire5/relu_expand1x1 needs backward computation.
I1028 18:09:32.140913 12309 net.cpp:205] fire5/expand1x1 needs backward computation.
I1028 18:09:32.140916 12309 net.cpp:205] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I1028 18:09:32.140925 12309 net.cpp:205] fire5/relu_squeeze1x1 needs backward computation.
I1028 18:09:32.140928 12309 net.cpp:205] fire5/squeeze1x1 needs backward computation.
I1028 18:09:32.140933 12309 net.cpp:205] fire4/concat needs backward computation.
I1028 18:09:32.140938 12309 net.cpp:205] fire4/relu_expand3x3 needs backward computation.
I1028 18:09:32.140949 12309 net.cpp:205] fire4/expand3x3 needs backward computation.
I1028 18:09:32.140952 12309 net.cpp:205] fire4/relu_expand1x1 needs backward computation.
I1028 18:09:32.140955 12309 net.cpp:205] fire4/expand1x1 needs backward computation.
I1028 18:09:32.140965 12309 net.cpp:205] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I1028 18:09:32.140969 12309 net.cpp:205] fire4/relu_squeeze1x1 needs backward computation.
I1028 18:09:32.140972 12309 net.cpp:205] fire4/squeeze1x1 needs backward computation.
I1028 18:09:32.140976 12309 net.cpp:205] pool3 needs backward computation.
I1028 18:09:32.140980 12309 net.cpp:205] fire3/concat needs backward computation.
I1028 18:09:32.140983 12309 net.cpp:205] fire3/relu_expand3x3 needs backward computation.
I1028 18:09:32.140987 12309 net.cpp:205] fire3/expand3x3 needs backward computation.
I1028 18:09:32.140991 12309 net.cpp:205] fire3/relu_expand1x1 needs backward computation.
I1028 18:09:32.140995 12309 net.cpp:205] fire3/expand1x1 needs backward computation.
I1028 18:09:32.140997 12309 net.cpp:205] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I1028 18:09:32.141001 12309 net.cpp:205] fire3/relu_squeeze1x1 needs backward computation.
I1028 18:09:32.141005 12309 net.cpp:205] fire3/squeeze1x1 needs backward computation.
I1028 18:09:32.141008 12309 net.cpp:205] fire2/concat needs backward computation.
I1028 18:09:32.141012 12309 net.cpp:205] fire2/relu_expand3x3 needs backward computation.
I1028 18:09:32.141016 12309 net.cpp:205] fire2/expand3x3 needs backward computation.
I1028 18:09:32.141019 12309 net.cpp:205] fire2/relu_expand1x1 needs backward computation.
I1028 18:09:32.141022 12309 net.cpp:205] fire2/expand1x1 needs backward computation.
I1028 18:09:32.141026 12309 net.cpp:205] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I1028 18:09:32.141029 12309 net.cpp:205] fire2/relu_squeeze1x1 needs backward computation.
I1028 18:09:32.141033 12309 net.cpp:205] fire2/squeeze1x1 needs backward computation.
I1028 18:09:32.141037 12309 net.cpp:205] pool1 needs backward computation.
I1028 18:09:32.141041 12309 net.cpp:205] relu_conv1 needs backward computation.
I1028 18:09:32.141044 12309 net.cpp:205] conv1 needs backward computation.
I1028 18:09:32.141048 12309 net.cpp:207] data does not need backward computation.
I1028 18:09:32.141052 12309 net.cpp:249] This network produces output loss
I1028 18:09:32.141104 12309 net.cpp:262] Network initialization done.
I1028 18:09:32.144320 12309 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_40.prototxt
I1028 18:09:32.144511 12309 net.cpp:301] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1028 18:09:32.145982 12309 net.cpp:51] Initializing net from parameters: 
name: "SqueezeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/data/caffe-imagenet/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "INQConvolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "fire3/concat"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire4/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool3"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "fire5/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire4/concat"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "fire5/concat"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire6/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool5"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "fire9/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire8/concat"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "INQConvolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "pool10"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy_top1"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy_top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy_top5"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy_top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I1028 18:09:32.146654 12309 layer_factory.hpp:77] Creating layer data
I1028 18:09:32.146769 12309 db_lmdb.cpp:35] Opened lmdb /home/data/caffe-imagenet/ilsvrc12_val_lmdb
I1028 18:09:32.146801 12309 net.cpp:84] Creating Layer data
I1028 18:09:32.146816 12309 net.cpp:387] data -> data
I1028 18:09:32.146838 12309 net.cpp:387] data -> label
I1028 18:09:32.147526 12309 data_layer.cpp:45] output data size: 50,3,227,227
I1028 18:09:32.246062 12309 net.cpp:127] Setting up data
I1028 18:09:32.246104 12309 net.cpp:136] Top shape: 50 3 227 227 (7729350)
I1028 18:09:32.246111 12309 net.cpp:136] Top shape: 50 (50)
I1028 18:09:32.246115 12309 net.cpp:144] Memory required for data: 30917600
I1028 18:09:32.246124 12309 layer_factory.hpp:77] Creating layer label_data_1_split
I1028 18:09:32.246140 12309 net.cpp:84] Creating Layer label_data_1_split
I1028 18:09:32.246145 12309 net.cpp:413] label_data_1_split <- label
I1028 18:09:32.246155 12309 net.cpp:387] label_data_1_split -> label_data_1_split_0
I1028 18:09:32.246166 12309 net.cpp:387] label_data_1_split -> label_data_1_split_1
I1028 18:09:32.246173 12309 net.cpp:387] label_data_1_split -> label_data_1_split_2
I1028 18:09:32.246310 12309 net.cpp:127] Setting up label_data_1_split
I1028 18:09:32.246320 12309 net.cpp:136] Top shape: 50 (50)
I1028 18:09:32.246325 12309 net.cpp:136] Top shape: 50 (50)
I1028 18:09:32.246330 12309 net.cpp:136] Top shape: 50 (50)
I1028 18:09:32.246333 12309 net.cpp:144] Memory required for data: 30918200
I1028 18:09:32.246338 12309 layer_factory.hpp:77] Creating layer conv1
I1028 18:09:32.246353 12309 net.cpp:84] Creating Layer conv1
I1028 18:09:32.246357 12309 net.cpp:413] conv1 <- data
I1028 18:09:32.246366 12309 net.cpp:387] conv1 -> conv1
I1028 18:09:32.246779 12309 net.cpp:127] Setting up conv1
I1028 18:09:32.246788 12309 net.cpp:136] Top shape: 50 64 113 113 (40860800)
I1028 18:09:32.246791 12309 net.cpp:144] Memory required for data: 194361400
I1028 18:09:32.246800 12309 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1028 18:09:32.246809 12309 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1028 18:09:32.246817 12309 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1028 18:09:32.246822 12309 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1028 18:09:32.246827 12309 layer_factory.hpp:77] Creating layer relu_conv1
I1028 18:09:32.246835 12309 net.cpp:84] Creating Layer relu_conv1
I1028 18:09:32.246840 12309 net.cpp:413] relu_conv1 <- conv1
I1028 18:09:32.246846 12309 net.cpp:374] relu_conv1 -> conv1 (in-place)
I1028 18:09:32.247112 12309 net.cpp:127] Setting up relu_conv1
I1028 18:09:32.247123 12309 net.cpp:136] Top shape: 50 64 113 113 (40860800)
I1028 18:09:32.247126 12309 net.cpp:144] Memory required for data: 357804600
I1028 18:09:32.247130 12309 layer_factory.hpp:77] Creating layer pool1
I1028 18:09:32.247141 12309 net.cpp:84] Creating Layer pool1
I1028 18:09:32.247145 12309 net.cpp:413] pool1 <- conv1
I1028 18:09:32.247153 12309 net.cpp:387] pool1 -> pool1
I1028 18:09:32.247205 12309 net.cpp:127] Setting up pool1
I1028 18:09:32.247210 12309 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 18:09:32.247215 12309 net.cpp:144] Memory required for data: 397945400
I1028 18:09:32.247218 12309 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I1028 18:09:32.247228 12309 net.cpp:84] Creating Layer fire2/squeeze1x1
I1028 18:09:32.247232 12309 net.cpp:413] fire2/squeeze1x1 <- pool1
I1028 18:09:32.247239 12309 net.cpp:387] fire2/squeeze1x1 -> fire2/squeeze1x1
I1028 18:09:32.247725 12309 net.cpp:127] Setting up fire2/squeeze1x1
I1028 18:09:32.247735 12309 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 18:09:32.247740 12309 net.cpp:144] Memory required for data: 407980600
I1028 18:09:32.247747 12309 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1028 18:09:32.247756 12309 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1028 18:09:32.247761 12309 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1028 18:09:32.247766 12309 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1028 18:09:32.247769 12309 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I1028 18:09:32.247776 12309 net.cpp:84] Creating Layer fire2/relu_squeeze1x1
I1028 18:09:32.247786 12309 net.cpp:413] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I1028 18:09:32.247820 12309 net.cpp:374] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I1028 18:09:32.248064 12309 net.cpp:127] Setting up fire2/relu_squeeze1x1
I1028 18:09:32.248073 12309 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 18:09:32.248077 12309 net.cpp:144] Memory required for data: 418015800
I1028 18:09:32.248081 12309 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1028 18:09:32.248088 12309 net.cpp:84] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1028 18:09:32.248092 12309 net.cpp:413] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I1028 18:09:32.248100 12309 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1028 18:09:32.248107 12309 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1028 18:09:32.248159 12309 net.cpp:127] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1028 18:09:32.248167 12309 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 18:09:32.248172 12309 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 18:09:32.248175 12309 net.cpp:144] Memory required for data: 438086200
I1028 18:09:32.248178 12309 layer_factory.hpp:77] Creating layer fire2/expand1x1
I1028 18:09:32.248189 12309 net.cpp:84] Creating Layer fire2/expand1x1
I1028 18:09:32.248193 12309 net.cpp:413] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1028 18:09:32.248201 12309 net.cpp:387] fire2/expand1x1 -> fire2/expand1x1
I1028 18:09:32.250970 12309 net.cpp:127] Setting up fire2/expand1x1
I1028 18:09:32.250989 12309 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 18:09:32.250993 12309 net.cpp:144] Memory required for data: 478227000
I1028 18:09:32.251003 12309 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1028 18:09:32.251011 12309 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1028 18:09:32.251016 12309 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1028 18:09:32.251021 12309 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1028 18:09:32.251024 12309 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I1028 18:09:32.251034 12309 net.cpp:84] Creating Layer fire2/relu_expand1x1
I1028 18:09:32.251037 12309 net.cpp:413] fire2/relu_expand1x1 <- fire2/expand1x1
I1028 18:09:32.251044 12309 net.cpp:374] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I1028 18:09:32.252516 12309 net.cpp:127] Setting up fire2/relu_expand1x1
I1028 18:09:32.252532 12309 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 18:09:32.252537 12309 net.cpp:144] Memory required for data: 518367800
I1028 18:09:32.252540 12309 layer_factory.hpp:77] Creating layer fire2/expand3x3
I1028 18:09:32.252552 12309 net.cpp:84] Creating Layer fire2/expand3x3
I1028 18:09:32.252557 12309 net.cpp:413] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1028 18:09:32.252565 12309 net.cpp:387] fire2/expand3x3 -> fire2/expand3x3
I1028 18:09:32.253021 12309 net.cpp:127] Setting up fire2/expand3x3
I1028 18:09:32.253031 12309 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 18:09:32.253034 12309 net.cpp:144] Memory required for data: 558508600
I1028 18:09:32.253041 12309 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1028 18:09:32.253046 12309 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1028 18:09:32.253051 12309 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1028 18:09:32.253054 12309 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1028 18:09:32.253058 12309 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I1028 18:09:32.253065 12309 net.cpp:84] Creating Layer fire2/relu_expand3x3
I1028 18:09:32.253069 12309 net.cpp:413] fire2/relu_expand3x3 <- fire2/expand3x3
I1028 18:09:32.253079 12309 net.cpp:374] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I1028 18:09:32.253311 12309 net.cpp:127] Setting up fire2/relu_expand3x3
I1028 18:09:32.253322 12309 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 18:09:32.253326 12309 net.cpp:144] Memory required for data: 598649400
I1028 18:09:32.253330 12309 layer_factory.hpp:77] Creating layer fire2/concat
I1028 18:09:32.253338 12309 net.cpp:84] Creating Layer fire2/concat
I1028 18:09:32.253342 12309 net.cpp:413] fire2/concat <- fire2/expand1x1
I1028 18:09:32.253347 12309 net.cpp:413] fire2/concat <- fire2/expand3x3
I1028 18:09:32.253355 12309 net.cpp:387] fire2/concat -> fire2/concat
I1028 18:09:32.253387 12309 net.cpp:127] Setting up fire2/concat
I1028 18:09:32.253392 12309 net.cpp:136] Top shape: 50 128 56 56 (20070400)
I1028 18:09:32.253396 12309 net.cpp:144] Memory required for data: 678931000
I1028 18:09:32.253399 12309 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I1028 18:09:32.253409 12309 net.cpp:84] Creating Layer fire3/squeeze1x1
I1028 18:09:32.253413 12309 net.cpp:413] fire3/squeeze1x1 <- fire2/concat
I1028 18:09:32.253422 12309 net.cpp:387] fire3/squeeze1x1 -> fire3/squeeze1x1
I1028 18:09:32.253783 12309 net.cpp:127] Setting up fire3/squeeze1x1
I1028 18:09:32.253792 12309 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 18:09:32.253794 12309 net.cpp:144] Memory required for data: 688966200
I1028 18:09:32.253803 12309 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1028 18:09:32.253813 12309 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1028 18:09:32.253818 12309 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1028 18:09:32.253823 12309 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1028 18:09:32.253826 12309 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I1028 18:09:32.253832 12309 net.cpp:84] Creating Layer fire3/relu_squeeze1x1
I1028 18:09:32.253836 12309 net.cpp:413] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I1028 18:09:32.253841 12309 net.cpp:374] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I1028 18:09:32.254056 12309 net.cpp:127] Setting up fire3/relu_squeeze1x1
I1028 18:09:32.254066 12309 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 18:09:32.254070 12309 net.cpp:144] Memory required for data: 699001400
I1028 18:09:32.254073 12309 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1028 18:09:32.254082 12309 net.cpp:84] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1028 18:09:32.254086 12309 net.cpp:413] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I1028 18:09:32.254091 12309 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1028 18:09:32.254101 12309 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1028 18:09:32.254148 12309 net.cpp:127] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1028 18:09:32.254155 12309 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 18:09:32.254159 12309 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 18:09:32.254163 12309 net.cpp:144] Memory required for data: 719071800
I1028 18:09:32.254166 12309 layer_factory.hpp:77] Creating layer fire3/expand1x1
I1028 18:09:32.254178 12309 net.cpp:84] Creating Layer fire3/expand1x1
I1028 18:09:32.254181 12309 net.cpp:413] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1028 18:09:32.254189 12309 net.cpp:387] fire3/expand1x1 -> fire3/expand1x1
I1028 18:09:32.254549 12309 net.cpp:127] Setting up fire3/expand1x1
I1028 18:09:32.254559 12309 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 18:09:32.254562 12309 net.cpp:144] Memory required for data: 759212600
I1028 18:09:32.254567 12309 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1028 18:09:32.254573 12309 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1028 18:09:32.254580 12309 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1028 18:09:32.254595 12309 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1028 18:09:32.254600 12309 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I1028 18:09:32.254606 12309 net.cpp:84] Creating Layer fire3/relu_expand1x1
I1028 18:09:32.254609 12309 net.cpp:413] fire3/relu_expand1x1 <- fire3/expand1x1
I1028 18:09:32.254616 12309 net.cpp:374] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I1028 18:09:32.254827 12309 net.cpp:127] Setting up fire3/relu_expand1x1
I1028 18:09:32.254837 12309 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 18:09:32.254839 12309 net.cpp:144] Memory required for data: 799353400
I1028 18:09:32.254843 12309 layer_factory.hpp:77] Creating layer fire3/expand3x3
I1028 18:09:32.254853 12309 net.cpp:84] Creating Layer fire3/expand3x3
I1028 18:09:32.254856 12309 net.cpp:413] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1028 18:09:32.254864 12309 net.cpp:387] fire3/expand3x3 -> fire3/expand3x3
I1028 18:09:32.255301 12309 net.cpp:127] Setting up fire3/expand3x3
I1028 18:09:32.255309 12309 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 18:09:32.255313 12309 net.cpp:144] Memory required for data: 839494200
I1028 18:09:32.255318 12309 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1028 18:09:32.255323 12309 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1028 18:09:32.255328 12309 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1028 18:09:32.255332 12309 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1028 18:09:32.255336 12309 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I1028 18:09:32.255344 12309 net.cpp:84] Creating Layer fire3/relu_expand3x3
I1028 18:09:32.255348 12309 net.cpp:413] fire3/relu_expand3x3 <- fire3/expand3x3
I1028 18:09:32.255353 12309 net.cpp:374] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I1028 18:09:32.256763 12309 net.cpp:127] Setting up fire3/relu_expand3x3
I1028 18:09:32.256778 12309 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 18:09:32.256781 12309 net.cpp:144] Memory required for data: 879635000
I1028 18:09:32.256785 12309 layer_factory.hpp:77] Creating layer fire3/concat
I1028 18:09:32.256795 12309 net.cpp:84] Creating Layer fire3/concat
I1028 18:09:32.256799 12309 net.cpp:413] fire3/concat <- fire3/expand1x1
I1028 18:09:32.256805 12309 net.cpp:413] fire3/concat <- fire3/expand3x3
I1028 18:09:32.256811 12309 net.cpp:387] fire3/concat -> fire3/concat
I1028 18:09:32.256847 12309 net.cpp:127] Setting up fire3/concat
I1028 18:09:32.256855 12309 net.cpp:136] Top shape: 50 128 56 56 (20070400)
I1028 18:09:32.256857 12309 net.cpp:144] Memory required for data: 959916600
I1028 18:09:32.256861 12309 layer_factory.hpp:77] Creating layer pool3
I1028 18:09:32.256867 12309 net.cpp:84] Creating Layer pool3
I1028 18:09:32.256871 12309 net.cpp:413] pool3 <- fire3/concat
I1028 18:09:32.256880 12309 net.cpp:387] pool3 -> pool3
I1028 18:09:32.256930 12309 net.cpp:127] Setting up pool3
I1028 18:09:32.256937 12309 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 18:09:32.256940 12309 net.cpp:144] Memory required for data: 979987000
I1028 18:09:32.256944 12309 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I1028 18:09:32.256954 12309 net.cpp:84] Creating Layer fire4/squeeze1x1
I1028 18:09:32.256960 12309 net.cpp:413] fire4/squeeze1x1 <- pool3
I1028 18:09:32.256966 12309 net.cpp:387] fire4/squeeze1x1 -> fire4/squeeze1x1
I1028 18:09:32.257354 12309 net.cpp:127] Setting up fire4/squeeze1x1
I1028 18:09:32.257364 12309 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 18:09:32.257367 12309 net.cpp:144] Memory required for data: 985004600
I1028 18:09:32.257374 12309 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1028 18:09:32.257378 12309 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1028 18:09:32.257386 12309 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1028 18:09:32.257405 12309 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1028 18:09:32.257410 12309 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I1028 18:09:32.257416 12309 net.cpp:84] Creating Layer fire4/relu_squeeze1x1
I1028 18:09:32.257421 12309 net.cpp:413] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I1028 18:09:32.257428 12309 net.cpp:374] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I1028 18:09:32.257638 12309 net.cpp:127] Setting up fire4/relu_squeeze1x1
I1028 18:09:32.257647 12309 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 18:09:32.257650 12309 net.cpp:144] Memory required for data: 990022200
I1028 18:09:32.257654 12309 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1028 18:09:32.257660 12309 net.cpp:84] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1028 18:09:32.257664 12309 net.cpp:413] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I1028 18:09:32.257673 12309 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1028 18:09:32.257679 12309 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1028 18:09:32.257735 12309 net.cpp:127] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1028 18:09:32.257740 12309 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 18:09:32.257745 12309 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 18:09:32.257748 12309 net.cpp:144] Memory required for data: 1000057400
I1028 18:09:32.257751 12309 layer_factory.hpp:77] Creating layer fire4/expand1x1
I1028 18:09:32.257761 12309 net.cpp:84] Creating Layer fire4/expand1x1
I1028 18:09:32.257767 12309 net.cpp:413] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1028 18:09:32.257776 12309 net.cpp:387] fire4/expand1x1 -> fire4/expand1x1
I1028 18:09:32.258147 12309 net.cpp:127] Setting up fire4/expand1x1
I1028 18:09:32.258157 12309 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 18:09:32.258159 12309 net.cpp:144] Memory required for data: 1020127800
I1028 18:09:32.258170 12309 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1028 18:09:32.258178 12309 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1028 18:09:32.258183 12309 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1028 18:09:32.258188 12309 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1028 18:09:32.258191 12309 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I1028 18:09:32.258200 12309 net.cpp:84] Creating Layer fire4/relu_expand1x1
I1028 18:09:32.258204 12309 net.cpp:413] fire4/relu_expand1x1 <- fire4/expand1x1
I1028 18:09:32.258209 12309 net.cpp:374] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I1028 18:09:32.258417 12309 net.cpp:127] Setting up fire4/relu_expand1x1
I1028 18:09:32.258425 12309 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 18:09:32.258430 12309 net.cpp:144] Memory required for data: 1040198200
I1028 18:09:32.258432 12309 layer_factory.hpp:77] Creating layer fire4/expand3x3
I1028 18:09:32.258443 12309 net.cpp:84] Creating Layer fire4/expand3x3
I1028 18:09:32.258447 12309 net.cpp:413] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1028 18:09:32.258455 12309 net.cpp:387] fire4/expand3x3 -> fire4/expand3x3
I1028 18:09:32.259121 12309 net.cpp:127] Setting up fire4/expand3x3
I1028 18:09:32.259130 12309 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 18:09:32.259133 12309 net.cpp:144] Memory required for data: 1060268600
I1028 18:09:32.259140 12309 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1028 18:09:32.259145 12309 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1028 18:09:32.259151 12309 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1028 18:09:32.259167 12309 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1028 18:09:32.259171 12309 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I1028 18:09:32.259177 12309 net.cpp:84] Creating Layer fire4/relu_expand3x3
I1028 18:09:32.259181 12309 net.cpp:413] fire4/relu_expand3x3 <- fire4/expand3x3
I1028 18:09:32.259188 12309 net.cpp:374] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I1028 18:09:32.259400 12309 net.cpp:127] Setting up fire4/relu_expand3x3
I1028 18:09:32.259408 12309 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 18:09:32.259413 12309 net.cpp:144] Memory required for data: 1080339000
I1028 18:09:32.259416 12309 layer_factory.hpp:77] Creating layer fire4/concat
I1028 18:09:32.259424 12309 net.cpp:84] Creating Layer fire4/concat
I1028 18:09:32.259428 12309 net.cpp:413] fire4/concat <- fire4/expand1x1
I1028 18:09:32.259433 12309 net.cpp:413] fire4/concat <- fire4/expand3x3
I1028 18:09:32.259438 12309 net.cpp:387] fire4/concat -> fire4/concat
I1028 18:09:32.259470 12309 net.cpp:127] Setting up fire4/concat
I1028 18:09:32.259476 12309 net.cpp:136] Top shape: 50 256 28 28 (10035200)
I1028 18:09:32.259480 12309 net.cpp:144] Memory required for data: 1120479800
I1028 18:09:32.259483 12309 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I1028 18:09:32.259492 12309 net.cpp:84] Creating Layer fire5/squeeze1x1
I1028 18:09:32.259496 12309 net.cpp:413] fire5/squeeze1x1 <- fire4/concat
I1028 18:09:32.259505 12309 net.cpp:387] fire5/squeeze1x1 -> fire5/squeeze1x1
I1028 18:09:32.259925 12309 net.cpp:127] Setting up fire5/squeeze1x1
I1028 18:09:32.259933 12309 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 18:09:32.259937 12309 net.cpp:144] Memory required for data: 1125497400
I1028 18:09:32.259943 12309 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1028 18:09:32.259948 12309 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1028 18:09:32.259951 12309 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1028 18:09:32.259956 12309 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1028 18:09:32.259959 12309 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I1028 18:09:32.259965 12309 net.cpp:84] Creating Layer fire5/relu_squeeze1x1
I1028 18:09:32.259969 12309 net.cpp:413] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I1028 18:09:32.259974 12309 net.cpp:374] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I1028 18:09:32.261412 12309 net.cpp:127] Setting up fire5/relu_squeeze1x1
I1028 18:09:32.261426 12309 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 18:09:32.261430 12309 net.cpp:144] Memory required for data: 1130515000
I1028 18:09:32.261435 12309 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1028 18:09:32.261447 12309 net.cpp:84] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1028 18:09:32.261453 12309 net.cpp:413] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I1028 18:09:32.261461 12309 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1028 18:09:32.261468 12309 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1028 18:09:32.261529 12309 net.cpp:127] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1028 18:09:32.261538 12309 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 18:09:32.261543 12309 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 18:09:32.261545 12309 net.cpp:144] Memory required for data: 1140550200
I1028 18:09:32.261549 12309 layer_factory.hpp:77] Creating layer fire5/expand1x1
I1028 18:09:32.261559 12309 net.cpp:84] Creating Layer fire5/expand1x1
I1028 18:09:32.261564 12309 net.cpp:413] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1028 18:09:32.261570 12309 net.cpp:387] fire5/expand1x1 -> fire5/expand1x1
I1028 18:09:32.261960 12309 net.cpp:127] Setting up fire5/expand1x1
I1028 18:09:32.261981 12309 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 18:09:32.261986 12309 net.cpp:144] Memory required for data: 1160620600
I1028 18:09:32.261991 12309 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1028 18:09:32.261997 12309 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1028 18:09:32.262002 12309 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1028 18:09:32.262006 12309 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1028 18:09:32.262010 12309 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I1028 18:09:32.262017 12309 net.cpp:84] Creating Layer fire5/relu_expand1x1
I1028 18:09:32.262022 12309 net.cpp:413] fire5/relu_expand1x1 <- fire5/expand1x1
I1028 18:09:32.262028 12309 net.cpp:374] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I1028 18:09:32.262238 12309 net.cpp:127] Setting up fire5/relu_expand1x1
I1028 18:09:32.262246 12309 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 18:09:32.262250 12309 net.cpp:144] Memory required for data: 1180691000
I1028 18:09:32.262254 12309 layer_factory.hpp:77] Creating layer fire5/expand3x3
I1028 18:09:32.262264 12309 net.cpp:84] Creating Layer fire5/expand3x3
I1028 18:09:32.262269 12309 net.cpp:413] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1028 18:09:32.262277 12309 net.cpp:387] fire5/expand3x3 -> fire5/expand3x3
I1028 18:09:32.262938 12309 net.cpp:127] Setting up fire5/expand3x3
I1028 18:09:32.262948 12309 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 18:09:32.262950 12309 net.cpp:144] Memory required for data: 1200761400
I1028 18:09:32.262956 12309 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1028 18:09:32.262961 12309 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1028 18:09:32.262966 12309 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1028 18:09:32.262970 12309 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1028 18:09:32.262974 12309 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I1028 18:09:32.262981 12309 net.cpp:84] Creating Layer fire5/relu_expand3x3
I1028 18:09:32.262985 12309 net.cpp:413] fire5/relu_expand3x3 <- fire5/expand3x3
I1028 18:09:32.262993 12309 net.cpp:374] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I1028 18:09:32.263204 12309 net.cpp:127] Setting up fire5/relu_expand3x3
I1028 18:09:32.263213 12309 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 18:09:32.263217 12309 net.cpp:144] Memory required for data: 1220831800
I1028 18:09:32.263221 12309 layer_factory.hpp:77] Creating layer fire5/concat
I1028 18:09:32.263227 12309 net.cpp:84] Creating Layer fire5/concat
I1028 18:09:32.263231 12309 net.cpp:413] fire5/concat <- fire5/expand1x1
I1028 18:09:32.263236 12309 net.cpp:413] fire5/concat <- fire5/expand3x3
I1028 18:09:32.263243 12309 net.cpp:387] fire5/concat -> fire5/concat
I1028 18:09:32.263275 12309 net.cpp:127] Setting up fire5/concat
I1028 18:09:32.263281 12309 net.cpp:136] Top shape: 50 256 28 28 (10035200)
I1028 18:09:32.263284 12309 net.cpp:144] Memory required for data: 1260972600
I1028 18:09:32.263288 12309 layer_factory.hpp:77] Creating layer pool5
I1028 18:09:32.263294 12309 net.cpp:84] Creating Layer pool5
I1028 18:09:32.263298 12309 net.cpp:413] pool5 <- fire5/concat
I1028 18:09:32.263305 12309 net.cpp:387] pool5 -> pool5
I1028 18:09:32.263351 12309 net.cpp:127] Setting up pool5
I1028 18:09:32.263360 12309 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 18:09:32.263363 12309 net.cpp:144] Memory required for data: 1271007800
I1028 18:09:32.263366 12309 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I1028 18:09:32.263377 12309 net.cpp:84] Creating Layer fire6/squeeze1x1
I1028 18:09:32.263381 12309 net.cpp:413] fire6/squeeze1x1 <- pool5
I1028 18:09:32.263387 12309 net.cpp:387] fire6/squeeze1x1 -> fire6/squeeze1x1
I1028 18:09:32.263839 12309 net.cpp:127] Setting up fire6/squeeze1x1
I1028 18:09:32.263859 12309 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 18:09:32.263862 12309 net.cpp:144] Memory required for data: 1272889400
I1028 18:09:32.263867 12309 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1028 18:09:32.263872 12309 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1028 18:09:32.263877 12309 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1028 18:09:32.263881 12309 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1028 18:09:32.263885 12309 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I1028 18:09:32.263895 12309 net.cpp:84] Creating Layer fire6/relu_squeeze1x1
I1028 18:09:32.263898 12309 net.cpp:413] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I1028 18:09:32.263903 12309 net.cpp:374] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I1028 18:09:32.264122 12309 net.cpp:127] Setting up fire6/relu_squeeze1x1
I1028 18:09:32.264129 12309 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 18:09:32.264133 12309 net.cpp:144] Memory required for data: 1274771000
I1028 18:09:32.264137 12309 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1028 18:09:32.264147 12309 net.cpp:84] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1028 18:09:32.264150 12309 net.cpp:413] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I1028 18:09:32.264156 12309 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1028 18:09:32.264170 12309 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1028 18:09:32.264225 12309 net.cpp:127] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1028 18:09:32.264230 12309 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 18:09:32.264235 12309 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 18:09:32.264238 12309 net.cpp:144] Memory required for data: 1278534200
I1028 18:09:32.264242 12309 layer_factory.hpp:77] Creating layer fire6/expand1x1
I1028 18:09:32.264251 12309 net.cpp:84] Creating Layer fire6/expand1x1
I1028 18:09:32.264256 12309 net.cpp:413] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1028 18:09:32.264264 12309 net.cpp:387] fire6/expand1x1 -> fire6/expand1x1
I1028 18:09:32.264681 12309 net.cpp:127] Setting up fire6/expand1x1
I1028 18:09:32.264689 12309 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 18:09:32.264693 12309 net.cpp:144] Memory required for data: 1286060600
I1028 18:09:32.264698 12309 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1028 18:09:32.264703 12309 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1028 18:09:32.264708 12309 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1028 18:09:32.264713 12309 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1028 18:09:32.264716 12309 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I1028 18:09:32.264722 12309 net.cpp:84] Creating Layer fire6/relu_expand1x1
I1028 18:09:32.264726 12309 net.cpp:413] fire6/relu_expand1x1 <- fire6/expand1x1
I1028 18:09:32.264734 12309 net.cpp:374] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I1028 18:09:32.266144 12309 net.cpp:127] Setting up fire6/relu_expand1x1
I1028 18:09:32.266158 12309 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 18:09:32.266162 12309 net.cpp:144] Memory required for data: 1293587000
I1028 18:09:32.266166 12309 layer_factory.hpp:77] Creating layer fire6/expand3x3
I1028 18:09:32.266178 12309 net.cpp:84] Creating Layer fire6/expand3x3
I1028 18:09:32.266183 12309 net.cpp:413] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1028 18:09:32.266192 12309 net.cpp:387] fire6/expand3x3 -> fire6/expand3x3
I1028 18:09:32.267262 12309 net.cpp:127] Setting up fire6/expand3x3
I1028 18:09:32.267271 12309 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 18:09:32.267294 12309 net.cpp:144] Memory required for data: 1301113400
I1028 18:09:32.267302 12309 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1028 18:09:32.267307 12309 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1028 18:09:32.267312 12309 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1028 18:09:32.267315 12309 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1028 18:09:32.267319 12309 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I1028 18:09:32.267326 12309 net.cpp:84] Creating Layer fire6/relu_expand3x3
I1028 18:09:32.267331 12309 net.cpp:413] fire6/relu_expand3x3 <- fire6/expand3x3
I1028 18:09:32.267336 12309 net.cpp:374] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I1028 18:09:32.267549 12309 net.cpp:127] Setting up fire6/relu_expand3x3
I1028 18:09:32.267557 12309 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 18:09:32.267561 12309 net.cpp:144] Memory required for data: 1308639800
I1028 18:09:32.267565 12309 layer_factory.hpp:77] Creating layer fire6/concat
I1028 18:09:32.267571 12309 net.cpp:84] Creating Layer fire6/concat
I1028 18:09:32.267575 12309 net.cpp:413] fire6/concat <- fire6/expand1x1
I1028 18:09:32.267580 12309 net.cpp:413] fire6/concat <- fire6/expand3x3
I1028 18:09:32.267585 12309 net.cpp:387] fire6/concat -> fire6/concat
I1028 18:09:32.267621 12309 net.cpp:127] Setting up fire6/concat
I1028 18:09:32.267627 12309 net.cpp:136] Top shape: 50 384 14 14 (3763200)
I1028 18:09:32.267630 12309 net.cpp:144] Memory required for data: 1323692600
I1028 18:09:32.267634 12309 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I1028 18:09:32.267644 12309 net.cpp:84] Creating Layer fire7/squeeze1x1
I1028 18:09:32.267648 12309 net.cpp:413] fire7/squeeze1x1 <- fire6/concat
I1028 18:09:32.267657 12309 net.cpp:387] fire7/squeeze1x1 -> fire7/squeeze1x1
I1028 18:09:32.268167 12309 net.cpp:127] Setting up fire7/squeeze1x1
I1028 18:09:32.268175 12309 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 18:09:32.268179 12309 net.cpp:144] Memory required for data: 1325574200
I1028 18:09:32.268193 12309 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1028 18:09:32.268204 12309 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1028 18:09:32.268209 12309 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1028 18:09:32.268214 12309 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1028 18:09:32.268218 12309 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I1028 18:09:32.268224 12309 net.cpp:84] Creating Layer fire7/relu_squeeze1x1
I1028 18:09:32.268229 12309 net.cpp:413] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I1028 18:09:32.268234 12309 net.cpp:374] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I1028 18:09:32.268443 12309 net.cpp:127] Setting up fire7/relu_squeeze1x1
I1028 18:09:32.268452 12309 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 18:09:32.268455 12309 net.cpp:144] Memory required for data: 1327455800
I1028 18:09:32.268460 12309 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1028 18:09:32.268467 12309 net.cpp:84] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1028 18:09:32.268471 12309 net.cpp:413] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I1028 18:09:32.268477 12309 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1028 18:09:32.268484 12309 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1028 18:09:32.268538 12309 net.cpp:127] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1028 18:09:32.268544 12309 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 18:09:32.268553 12309 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 18:09:32.268555 12309 net.cpp:144] Memory required for data: 1331219000
I1028 18:09:32.268569 12309 layer_factory.hpp:77] Creating layer fire7/expand1x1
I1028 18:09:32.268579 12309 net.cpp:84] Creating Layer fire7/expand1x1
I1028 18:09:32.268584 12309 net.cpp:413] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1028 18:09:32.268592 12309 net.cpp:387] fire7/expand1x1 -> fire7/expand1x1
I1028 18:09:32.269016 12309 net.cpp:127] Setting up fire7/expand1x1
I1028 18:09:32.269026 12309 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 18:09:32.269029 12309 net.cpp:144] Memory required for data: 1338745400
I1028 18:09:32.269034 12309 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1028 18:09:32.269040 12309 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1028 18:09:32.269044 12309 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1028 18:09:32.269048 12309 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1028 18:09:32.269052 12309 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I1028 18:09:32.269058 12309 net.cpp:84] Creating Layer fire7/relu_expand1x1
I1028 18:09:32.269062 12309 net.cpp:413] fire7/relu_expand1x1 <- fire7/expand1x1
I1028 18:09:32.269068 12309 net.cpp:374] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I1028 18:09:32.270478 12309 net.cpp:127] Setting up fire7/relu_expand1x1
I1028 18:09:32.270491 12309 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 18:09:32.270495 12309 net.cpp:144] Memory required for data: 1346271800
I1028 18:09:32.270500 12309 layer_factory.hpp:77] Creating layer fire7/expand3x3
I1028 18:09:32.270514 12309 net.cpp:84] Creating Layer fire7/expand3x3
I1028 18:09:32.270519 12309 net.cpp:413] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1028 18:09:32.270525 12309 net.cpp:387] fire7/expand3x3 -> fire7/expand3x3
I1028 18:09:32.271600 12309 net.cpp:127] Setting up fire7/expand3x3
I1028 18:09:32.271610 12309 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 18:09:32.271613 12309 net.cpp:144] Memory required for data: 1353798200
I1028 18:09:32.271620 12309 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1028 18:09:32.271625 12309 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1028 18:09:32.271630 12309 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1028 18:09:32.271633 12309 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1028 18:09:32.271637 12309 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I1028 18:09:32.271643 12309 net.cpp:84] Creating Layer fire7/relu_expand3x3
I1028 18:09:32.271648 12309 net.cpp:413] fire7/relu_expand3x3 <- fire7/expand3x3
I1028 18:09:32.271657 12309 net.cpp:374] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I1028 18:09:32.271867 12309 net.cpp:127] Setting up fire7/relu_expand3x3
I1028 18:09:32.271875 12309 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 18:09:32.271878 12309 net.cpp:144] Memory required for data: 1361324600
I1028 18:09:32.271883 12309 layer_factory.hpp:77] Creating layer fire7/concat
I1028 18:09:32.271890 12309 net.cpp:84] Creating Layer fire7/concat
I1028 18:09:32.271894 12309 net.cpp:413] fire7/concat <- fire7/expand1x1
I1028 18:09:32.271899 12309 net.cpp:413] fire7/concat <- fire7/expand3x3
I1028 18:09:32.271904 12309 net.cpp:387] fire7/concat -> fire7/concat
I1028 18:09:32.271946 12309 net.cpp:127] Setting up fire7/concat
I1028 18:09:32.271952 12309 net.cpp:136] Top shape: 50 384 14 14 (3763200)
I1028 18:09:32.271955 12309 net.cpp:144] Memory required for data: 1376377400
I1028 18:09:32.271960 12309 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I1028 18:09:32.271970 12309 net.cpp:84] Creating Layer fire8/squeeze1x1
I1028 18:09:32.271973 12309 net.cpp:413] fire8/squeeze1x1 <- fire7/concat
I1028 18:09:32.271981 12309 net.cpp:387] fire8/squeeze1x1 -> fire8/squeeze1x1
I1028 18:09:32.273933 12309 net.cpp:127] Setting up fire8/squeeze1x1
I1028 18:09:32.273959 12309 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 18:09:32.273963 12309 net.cpp:144] Memory required for data: 1378886200
I1028 18:09:32.273970 12309 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1028 18:09:32.273977 12309 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1028 18:09:32.273980 12309 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1028 18:09:32.273985 12309 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1028 18:09:32.273988 12309 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I1028 18:09:32.273995 12309 net.cpp:84] Creating Layer fire8/relu_squeeze1x1
I1028 18:09:32.274000 12309 net.cpp:413] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I1028 18:09:32.274008 12309 net.cpp:374] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I1028 18:09:32.274235 12309 net.cpp:127] Setting up fire8/relu_squeeze1x1
I1028 18:09:32.274245 12309 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 18:09:32.274248 12309 net.cpp:144] Memory required for data: 1381395000
I1028 18:09:32.274252 12309 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1028 18:09:32.274258 12309 net.cpp:84] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1028 18:09:32.274262 12309 net.cpp:413] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I1028 18:09:32.274271 12309 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1028 18:09:32.274278 12309 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1028 18:09:32.274329 12309 net.cpp:127] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1028 18:09:32.274338 12309 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 18:09:32.274343 12309 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 18:09:32.274345 12309 net.cpp:144] Memory required for data: 1386412600
I1028 18:09:32.274349 12309 layer_factory.hpp:77] Creating layer fire8/expand1x1
I1028 18:09:32.274358 12309 net.cpp:84] Creating Layer fire8/expand1x1
I1028 18:09:32.274363 12309 net.cpp:413] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1028 18:09:32.274371 12309 net.cpp:387] fire8/expand1x1 -> fire8/expand1x1
I1028 18:09:32.274852 12309 net.cpp:127] Setting up fire8/expand1x1
I1028 18:09:32.274860 12309 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 18:09:32.274864 12309 net.cpp:144] Memory required for data: 1396447800
I1028 18:09:32.274869 12309 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1028 18:09:32.274875 12309 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1028 18:09:32.274879 12309 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1028 18:09:32.274884 12309 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1028 18:09:32.274888 12309 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I1028 18:09:32.274893 12309 net.cpp:84] Creating Layer fire8/relu_expand1x1
I1028 18:09:32.274899 12309 net.cpp:413] fire8/relu_expand1x1 <- fire8/expand1x1
I1028 18:09:32.274905 12309 net.cpp:374] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I1028 18:09:32.275131 12309 net.cpp:127] Setting up fire8/relu_expand1x1
I1028 18:09:32.275141 12309 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 18:09:32.275143 12309 net.cpp:144] Memory required for data: 1406483000
I1028 18:09:32.275147 12309 layer_factory.hpp:77] Creating layer fire8/expand3x3
I1028 18:09:32.275159 12309 net.cpp:84] Creating Layer fire8/expand3x3
I1028 18:09:32.275163 12309 net.cpp:413] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1028 18:09:32.275172 12309 net.cpp:387] fire8/expand3x3 -> fire8/expand3x3
I1028 18:09:32.278044 12309 net.cpp:127] Setting up fire8/expand3x3
I1028 18:09:32.278061 12309 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 18:09:32.278076 12309 net.cpp:144] Memory required for data: 1416518200
I1028 18:09:32.278084 12309 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1028 18:09:32.278090 12309 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1028 18:09:32.278095 12309 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1028 18:09:32.278098 12309 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1028 18:09:32.278102 12309 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I1028 18:09:32.278112 12309 net.cpp:84] Creating Layer fire8/relu_expand3x3
I1028 18:09:32.278116 12309 net.cpp:413] fire8/relu_expand3x3 <- fire8/expand3x3
I1028 18:09:32.278122 12309 net.cpp:374] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I1028 18:09:32.279546 12309 net.cpp:127] Setting up fire8/relu_expand3x3
I1028 18:09:32.279559 12309 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 18:09:32.279564 12309 net.cpp:144] Memory required for data: 1426553400
I1028 18:09:32.279568 12309 layer_factory.hpp:77] Creating layer fire8/concat
I1028 18:09:32.279577 12309 net.cpp:84] Creating Layer fire8/concat
I1028 18:09:32.279582 12309 net.cpp:413] fire8/concat <- fire8/expand1x1
I1028 18:09:32.279587 12309 net.cpp:413] fire8/concat <- fire8/expand3x3
I1028 18:09:32.279593 12309 net.cpp:387] fire8/concat -> fire8/concat
I1028 18:09:32.279631 12309 net.cpp:127] Setting up fire8/concat
I1028 18:09:32.279639 12309 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1028 18:09:32.279641 12309 net.cpp:144] Memory required for data: 1446623800
I1028 18:09:32.279645 12309 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I1028 18:09:32.279655 12309 net.cpp:84] Creating Layer fire9/squeeze1x1
I1028 18:09:32.279659 12309 net.cpp:413] fire9/squeeze1x1 <- fire8/concat
I1028 18:09:32.279667 12309 net.cpp:387] fire9/squeeze1x1 -> fire9/squeeze1x1
I1028 18:09:32.280289 12309 net.cpp:127] Setting up fire9/squeeze1x1
I1028 18:09:32.280298 12309 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 18:09:32.280302 12309 net.cpp:144] Memory required for data: 1449132600
I1028 18:09:32.280308 12309 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1028 18:09:32.280313 12309 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1028 18:09:32.280318 12309 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1028 18:09:32.280321 12309 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1028 18:09:32.280325 12309 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I1028 18:09:32.280339 12309 net.cpp:84] Creating Layer fire9/relu_squeeze1x1
I1028 18:09:32.280344 12309 net.cpp:413] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I1028 18:09:32.280349 12309 net.cpp:374] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I1028 18:09:32.280566 12309 net.cpp:127] Setting up fire9/relu_squeeze1x1
I1028 18:09:32.280575 12309 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 18:09:32.280580 12309 net.cpp:144] Memory required for data: 1451641400
I1028 18:09:32.280583 12309 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1028 18:09:32.280591 12309 net.cpp:84] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1028 18:09:32.280596 12309 net.cpp:413] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I1028 18:09:32.280601 12309 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1028 18:09:32.280607 12309 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1028 18:09:32.280658 12309 net.cpp:127] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1028 18:09:32.280664 12309 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 18:09:32.280668 12309 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 18:09:32.280676 12309 net.cpp:144] Memory required for data: 1456659000
I1028 18:09:32.280692 12309 layer_factory.hpp:77] Creating layer fire9/expand1x1
I1028 18:09:32.280702 12309 net.cpp:84] Creating Layer fire9/expand1x1
I1028 18:09:32.280706 12309 net.cpp:413] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1028 18:09:32.280714 12309 net.cpp:387] fire9/expand1x1 -> fire9/expand1x1
I1028 18:09:32.281205 12309 net.cpp:127] Setting up fire9/expand1x1
I1028 18:09:32.281213 12309 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 18:09:32.281217 12309 net.cpp:144] Memory required for data: 1466694200
I1028 18:09:32.281224 12309 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1028 18:09:32.281229 12309 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1028 18:09:32.281234 12309 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1028 18:09:32.281237 12309 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1028 18:09:32.281241 12309 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I1028 18:09:32.281247 12309 net.cpp:84] Creating Layer fire9/relu_expand1x1
I1028 18:09:32.281251 12309 net.cpp:413] fire9/relu_expand1x1 <- fire9/expand1x1
I1028 18:09:32.281260 12309 net.cpp:374] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I1028 18:09:32.281472 12309 net.cpp:127] Setting up fire9/relu_expand1x1
I1028 18:09:32.281481 12309 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 18:09:32.281486 12309 net.cpp:144] Memory required for data: 1476729400
I1028 18:09:32.281489 12309 layer_factory.hpp:77] Creating layer fire9/expand3x3
I1028 18:09:32.281498 12309 net.cpp:84] Creating Layer fire9/expand3x3
I1028 18:09:32.281502 12309 net.cpp:413] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1028 18:09:32.281512 12309 net.cpp:387] fire9/expand3x3 -> fire9/expand3x3
I1028 18:09:32.284400 12309 net.cpp:127] Setting up fire9/expand3x3
I1028 18:09:32.284415 12309 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 18:09:32.284418 12309 net.cpp:144] Memory required for data: 1486764600
I1028 18:09:32.284425 12309 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1028 18:09:32.284430 12309 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1028 18:09:32.284435 12309 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1028 18:09:32.284440 12309 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1028 18:09:32.284443 12309 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I1028 18:09:32.284451 12309 net.cpp:84] Creating Layer fire9/relu_expand3x3
I1028 18:09:32.284454 12309 net.cpp:413] fire9/relu_expand3x3 <- fire9/expand3x3
I1028 18:09:32.284463 12309 net.cpp:374] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I1028 18:09:32.284685 12309 net.cpp:127] Setting up fire9/relu_expand3x3
I1028 18:09:32.284694 12309 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 18:09:32.284698 12309 net.cpp:144] Memory required for data: 1496799800
I1028 18:09:32.284703 12309 layer_factory.hpp:77] Creating layer fire9/concat
I1028 18:09:32.284708 12309 net.cpp:84] Creating Layer fire9/concat
I1028 18:09:32.284713 12309 net.cpp:413] fire9/concat <- fire9/expand1x1
I1028 18:09:32.284718 12309 net.cpp:413] fire9/concat <- fire9/expand3x3
I1028 18:09:32.284725 12309 net.cpp:387] fire9/concat -> fire9/concat
I1028 18:09:32.284757 12309 net.cpp:127] Setting up fire9/concat
I1028 18:09:32.284763 12309 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1028 18:09:32.284767 12309 net.cpp:144] Memory required for data: 1516870200
I1028 18:09:32.284770 12309 layer_factory.hpp:77] Creating layer drop9
I1028 18:09:32.284780 12309 net.cpp:84] Creating Layer drop9
I1028 18:09:32.284783 12309 net.cpp:413] drop9 <- fire9/concat
I1028 18:09:32.284790 12309 net.cpp:374] drop9 -> fire9/concat (in-place)
I1028 18:09:32.284822 12309 net.cpp:127] Setting up drop9
I1028 18:09:32.284831 12309 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1028 18:09:32.284845 12309 net.cpp:144] Memory required for data: 1536940600
I1028 18:09:32.284849 12309 layer_factory.hpp:77] Creating layer conv10
I1028 18:09:32.284859 12309 net.cpp:84] Creating Layer conv10
I1028 18:09:32.284863 12309 net.cpp:413] conv10 <- fire9/concat
I1028 18:09:32.284871 12309 net.cpp:387] conv10 -> conv10
I1028 18:09:32.294481 12309 net.cpp:127] Setting up conv10
I1028 18:09:32.294497 12309 net.cpp:136] Top shape: 50 1000 14 14 (9800000)
I1028 18:09:32.294502 12309 net.cpp:144] Memory required for data: 1576140600
I1028 18:09:32.294507 12309 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1028 18:09:32.294513 12309 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1028 18:09:32.294518 12309 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1028 18:09:32.294523 12309 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1028 18:09:32.294526 12309 layer_factory.hpp:77] Creating layer relu_conv10
I1028 18:09:32.294533 12309 net.cpp:84] Creating Layer relu_conv10
I1028 18:09:32.294538 12309 net.cpp:413] relu_conv10 <- conv10
I1028 18:09:32.294546 12309 net.cpp:374] relu_conv10 -> conv10 (in-place)
I1028 18:09:32.295972 12309 net.cpp:127] Setting up relu_conv10
I1028 18:09:32.295986 12309 net.cpp:136] Top shape: 50 1000 14 14 (9800000)
I1028 18:09:32.295990 12309 net.cpp:144] Memory required for data: 1615340600
I1028 18:09:32.295995 12309 layer_factory.hpp:77] Creating layer pool10
I1028 18:09:32.296005 12309 net.cpp:84] Creating Layer pool10
I1028 18:09:32.296010 12309 net.cpp:413] pool10 <- conv10
I1028 18:09:32.296015 12309 net.cpp:387] pool10 -> pool10
I1028 18:09:32.296252 12309 net.cpp:127] Setting up pool10
I1028 18:09:32.296262 12309 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1028 18:09:32.296267 12309 net.cpp:144] Memory required for data: 1615540600
I1028 18:09:32.296270 12309 layer_factory.hpp:77] Creating layer pool10_pool10_0_split
I1028 18:09:32.296278 12309 net.cpp:84] Creating Layer pool10_pool10_0_split
I1028 18:09:32.296283 12309 net.cpp:413] pool10_pool10_0_split <- pool10
I1028 18:09:32.296288 12309 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_0
I1028 18:09:32.296298 12309 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_1
I1028 18:09:32.296304 12309 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_2
I1028 18:09:32.296368 12309 net.cpp:127] Setting up pool10_pool10_0_split
I1028 18:09:32.296375 12309 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1028 18:09:32.296380 12309 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1028 18:09:32.296383 12309 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1028 18:09:32.296386 12309 net.cpp:144] Memory required for data: 1616140600
I1028 18:09:32.296391 12309 layer_factory.hpp:77] Creating layer loss
I1028 18:09:32.296396 12309 net.cpp:84] Creating Layer loss
I1028 18:09:32.296401 12309 net.cpp:413] loss <- pool10_pool10_0_split_0
I1028 18:09:32.296406 12309 net.cpp:413] loss <- label_data_1_split_0
I1028 18:09:32.296413 12309 net.cpp:387] loss -> loss
I1028 18:09:32.296422 12309 layer_factory.hpp:77] Creating layer loss
I1028 18:09:32.296789 12309 net.cpp:127] Setting up loss
I1028 18:09:32.296800 12309 net.cpp:136] Top shape: (1)
I1028 18:09:32.296803 12309 net.cpp:139]     with loss weight 1
I1028 18:09:32.296816 12309 net.cpp:144] Memory required for data: 1616140604
I1028 18:09:32.296820 12309 layer_factory.hpp:77] Creating layer accuracy_top1
I1028 18:09:32.296833 12309 net.cpp:84] Creating Layer accuracy_top1
I1028 18:09:32.296836 12309 net.cpp:413] accuracy_top1 <- pool10_pool10_0_split_1
I1028 18:09:32.296842 12309 net.cpp:413] accuracy_top1 <- label_data_1_split_1
I1028 18:09:32.296850 12309 net.cpp:387] accuracy_top1 -> accuracy_top1
I1028 18:09:32.296864 12309 net.cpp:127] Setting up accuracy_top1
I1028 18:09:32.296869 12309 net.cpp:136] Top shape: (1)
I1028 18:09:32.296872 12309 net.cpp:144] Memory required for data: 1616140608
I1028 18:09:32.296880 12309 layer_factory.hpp:77] Creating layer accuracy_top5
I1028 18:09:32.296900 12309 net.cpp:84] Creating Layer accuracy_top5
I1028 18:09:32.296903 12309 net.cpp:413] accuracy_top5 <- pool10_pool10_0_split_2
I1028 18:09:32.296910 12309 net.cpp:413] accuracy_top5 <- label_data_1_split_2
I1028 18:09:32.296916 12309 net.cpp:387] accuracy_top5 -> accuracy_top5
I1028 18:09:32.296939 12309 net.cpp:127] Setting up accuracy_top5
I1028 18:09:32.296946 12309 net.cpp:136] Top shape: (1)
I1028 18:09:32.296949 12309 net.cpp:144] Memory required for data: 1616140612
I1028 18:09:32.296952 12309 net.cpp:207] accuracy_top5 does not need backward computation.
I1028 18:09:32.296957 12309 net.cpp:207] accuracy_top1 does not need backward computation.
I1028 18:09:32.296962 12309 net.cpp:205] loss needs backward computation.
I1028 18:09:32.296965 12309 net.cpp:205] pool10_pool10_0_split needs backward computation.
I1028 18:09:32.296969 12309 net.cpp:205] pool10 needs backward computation.
I1028 18:09:32.296973 12309 net.cpp:205] relu_conv10 needs backward computation.
I1028 18:09:32.296977 12309 net.cpp:205] conv10 needs backward computation.
I1028 18:09:32.296980 12309 net.cpp:205] drop9 needs backward computation.
I1028 18:09:32.296984 12309 net.cpp:205] fire9/concat needs backward computation.
I1028 18:09:32.296988 12309 net.cpp:205] fire9/relu_expand3x3 needs backward computation.
I1028 18:09:32.296993 12309 net.cpp:205] fire9/expand3x3 needs backward computation.
I1028 18:09:32.296996 12309 net.cpp:205] fire9/relu_expand1x1 needs backward computation.
I1028 18:09:32.296999 12309 net.cpp:205] fire9/expand1x1 needs backward computation.
I1028 18:09:32.297003 12309 net.cpp:205] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I1028 18:09:32.297008 12309 net.cpp:205] fire9/relu_squeeze1x1 needs backward computation.
I1028 18:09:32.297011 12309 net.cpp:205] fire9/squeeze1x1 needs backward computation.
I1028 18:09:32.297015 12309 net.cpp:205] fire8/concat needs backward computation.
I1028 18:09:32.297019 12309 net.cpp:205] fire8/relu_expand3x3 needs backward computation.
I1028 18:09:32.297024 12309 net.cpp:205] fire8/expand3x3 needs backward computation.
I1028 18:09:32.297027 12309 net.cpp:205] fire8/relu_expand1x1 needs backward computation.
I1028 18:09:32.297030 12309 net.cpp:205] fire8/expand1x1 needs backward computation.
I1028 18:09:32.297034 12309 net.cpp:205] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I1028 18:09:32.297039 12309 net.cpp:205] fire8/relu_squeeze1x1 needs backward computation.
I1028 18:09:32.297041 12309 net.cpp:205] fire8/squeeze1x1 needs backward computation.
I1028 18:09:32.297045 12309 net.cpp:205] fire7/concat needs backward computation.
I1028 18:09:32.297049 12309 net.cpp:205] fire7/relu_expand3x3 needs backward computation.
I1028 18:09:32.297052 12309 net.cpp:205] fire7/expand3x3 needs backward computation.
I1028 18:09:32.297056 12309 net.cpp:205] fire7/relu_expand1x1 needs backward computation.
I1028 18:09:32.297060 12309 net.cpp:205] fire7/expand1x1 needs backward computation.
I1028 18:09:32.297063 12309 net.cpp:205] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I1028 18:09:32.297067 12309 net.cpp:205] fire7/relu_squeeze1x1 needs backward computation.
I1028 18:09:32.297070 12309 net.cpp:205] fire7/squeeze1x1 needs backward computation.
I1028 18:09:32.297075 12309 net.cpp:205] fire6/concat needs backward computation.
I1028 18:09:32.297078 12309 net.cpp:205] fire6/relu_expand3x3 needs backward computation.
I1028 18:09:32.297081 12309 net.cpp:205] fire6/expand3x3 needs backward computation.
I1028 18:09:32.297085 12309 net.cpp:205] fire6/relu_expand1x1 needs backward computation.
I1028 18:09:32.297088 12309 net.cpp:205] fire6/expand1x1 needs backward computation.
I1028 18:09:32.297091 12309 net.cpp:205] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I1028 18:09:32.297096 12309 net.cpp:205] fire6/relu_squeeze1x1 needs backward computation.
I1028 18:09:32.297098 12309 net.cpp:205] fire6/squeeze1x1 needs backward computation.
I1028 18:09:32.297104 12309 net.cpp:205] pool5 needs backward computation.
I1028 18:09:32.297117 12309 net.cpp:205] fire5/concat needs backward computation.
I1028 18:09:32.297122 12309 net.cpp:205] fire5/relu_expand3x3 needs backward computation.
I1028 18:09:32.297124 12309 net.cpp:205] fire5/expand3x3 needs backward computation.
I1028 18:09:32.297128 12309 net.cpp:205] fire5/relu_expand1x1 needs backward computation.
I1028 18:09:32.297132 12309 net.cpp:205] fire5/expand1x1 needs backward computation.
I1028 18:09:32.297135 12309 net.cpp:205] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I1028 18:09:32.297142 12309 net.cpp:205] fire5/relu_squeeze1x1 needs backward computation.
I1028 18:09:32.297144 12309 net.cpp:205] fire5/squeeze1x1 needs backward computation.
I1028 18:09:32.297148 12309 net.cpp:205] fire4/concat needs backward computation.
I1028 18:09:32.297152 12309 net.cpp:205] fire4/relu_expand3x3 needs backward computation.
I1028 18:09:32.297155 12309 net.cpp:205] fire4/expand3x3 needs backward computation.
I1028 18:09:32.297158 12309 net.cpp:205] fire4/relu_expand1x1 needs backward computation.
I1028 18:09:32.297163 12309 net.cpp:205] fire4/expand1x1 needs backward computation.
I1028 18:09:32.297165 12309 net.cpp:205] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I1028 18:09:32.297169 12309 net.cpp:205] fire4/relu_squeeze1x1 needs backward computation.
I1028 18:09:32.297173 12309 net.cpp:205] fire4/squeeze1x1 needs backward computation.
I1028 18:09:32.297176 12309 net.cpp:205] pool3 needs backward computation.
I1028 18:09:32.297179 12309 net.cpp:205] fire3/concat needs backward computation.
I1028 18:09:32.297183 12309 net.cpp:205] fire3/relu_expand3x3 needs backward computation.
I1028 18:09:32.297188 12309 net.cpp:205] fire3/expand3x3 needs backward computation.
I1028 18:09:32.297190 12309 net.cpp:205] fire3/relu_expand1x1 needs backward computation.
I1028 18:09:32.297194 12309 net.cpp:205] fire3/expand1x1 needs backward computation.
I1028 18:09:32.297197 12309 net.cpp:205] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I1028 18:09:32.297201 12309 net.cpp:205] fire3/relu_squeeze1x1 needs backward computation.
I1028 18:09:32.297204 12309 net.cpp:205] fire3/squeeze1x1 needs backward computation.
I1028 18:09:32.297209 12309 net.cpp:205] fire2/concat needs backward computation.
I1028 18:09:32.297212 12309 net.cpp:205] fire2/relu_expand3x3 needs backward computation.
I1028 18:09:32.297215 12309 net.cpp:205] fire2/expand3x3 needs backward computation.
I1028 18:09:32.297219 12309 net.cpp:205] fire2/relu_expand1x1 needs backward computation.
I1028 18:09:32.297222 12309 net.cpp:205] fire2/expand1x1 needs backward computation.
I1028 18:09:32.297226 12309 net.cpp:205] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I1028 18:09:32.297230 12309 net.cpp:205] fire2/relu_squeeze1x1 needs backward computation.
I1028 18:09:32.297233 12309 net.cpp:205] fire2/squeeze1x1 needs backward computation.
I1028 18:09:32.297237 12309 net.cpp:205] pool1 needs backward computation.
I1028 18:09:32.297240 12309 net.cpp:205] relu_conv1 needs backward computation.
I1028 18:09:32.297245 12309 net.cpp:205] conv1 needs backward computation.
I1028 18:09:32.297250 12309 net.cpp:207] label_data_1_split does not need backward computation.
I1028 18:09:32.297253 12309 net.cpp:207] data does not need backward computation.
I1028 18:09:32.297257 12309 net.cpp:249] This network produces output accuracy_top1
I1028 18:09:32.297261 12309 net.cpp:249] This network produces output accuracy_top5
I1028 18:09:32.297266 12309 net.cpp:249] This network produces output loss
I1028 18:09:32.297319 12309 net.cpp:262] Network initialization done.
I1028 18:09:32.297580 12309 solver.cpp:56] Solver scaffolding done.
I1028 18:09:32.302186 12309 caffe.cpp:155] Finetuning from SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_170000.caffemodel
I1028 18:09:32.401909 12309 caffe.cpp:248] Starting Optimization
I1028 18:09:53.122678 12364 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_40.prototxt
I1028 18:09:53.125798 12362 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_40.prototxt
I1028 18:09:53.129151 12363 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_40.prototxt
I1028 18:09:54.023999 12309 solver.cpp:276] Solving SqueezeNet
I1028 18:09:54.024039 12309 solver.cpp:277] Learning Rate Policy: exp
I1028 18:09:54.024525 12309 solver.cpp:334] Iteration 0, Testing net (#0)
I1028 18:10:25.315057 12309 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.59
I1028 18:10:25.315259 12309 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.811479
I1028 18:10:25.315274 12309 solver.cpp:401]     Test net output #2: loss = 1.81772 (* 1 = 1.81772 loss)
I1028 18:10:25.315398 12309 inq_conv_layer.cu:52] conv1 (INQConvolution):  Shaping the weights...
I1028 18:10:25.315455 12309 inq_conv_layer.cpp:263] Max_power = 0
I1028 18:10:25.315461 12309 inq_conv_layer.cpp:264] Min_power = -6
I1028 18:10:25.315481 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0231% -> 39.9884%)
I1028 18:10:25.315491 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 1728/1728
I1028 18:10:25.315495 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 345/1037/1382
I1028 18:10:25.315651 12309 inq_conv_layer.cu:62] conv1 (INQConvolution):  Shaping the bias...
I1028 18:10:25.315690 12309 inq_conv_layer.cpp:263] Max_power = -2
I1028 18:10:25.315695 12309 inq_conv_layer.cpp:264] Min_power = -8
I1028 18:10:25.315701 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.3125% -> 40.625%)
I1028 18:10:25.315709 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 64/64
I1028 18:10:25.315712 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 13/38/51
I1028 18:10:25.328963 12309 inq_conv_layer.cu:52] fire2/squeeze1x1 (INQConvolution):  Shaping the weights...
I1028 18:10:25.346626 12309 inq_conv_layer.cpp:263] Max_power = 0
I1028 18:10:25.346632 12309 inq_conv_layer.cpp:264] Min_power = -6
I1028 18:10:25.346653 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0195% -> 40.0391%)
I1028 18:10:25.346664 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 1024/1024
I1028 18:10:25.346668 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 205/614/819
I1028 18:10:25.346755 12309 inq_conv_layer.cu:62] fire2/squeeze1x1 (INQConvolution):  Shaping the bias...
I1028 18:10:25.346784 12309 inq_conv_layer.cpp:263] Max_power = -2
I1028 18:10:25.346788 12309 inq_conv_layer.cpp:264] Min_power = -8
I1028 18:10:25.346794 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 18.75% -> 37.5%)
I1028 18:10:25.346802 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 16/16
I1028 18:10:25.346806 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 3/10/13
I1028 18:10:25.350266 12309 inq_conv_layer.cu:52] fire2/expand1x1 (INQConvolution):  Shaping the weights...
I1028 18:10:25.350535 12309 inq_conv_layer.cpp:263] Max_power = 0
I1028 18:10:25.350541 12309 inq_conv_layer.cpp:264] Min_power = -6
I1028 18:10:25.350559 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0195% -> 40.0391%)
I1028 18:10:25.350570 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 1024/1024
I1028 18:10:25.350574 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 205/614/819
I1028 18:10:25.350661 12309 inq_conv_layer.cu:62] fire2/expand1x1 (INQConvolution):  Shaping the bias...
I1028 18:10:25.350688 12309 inq_conv_layer.cpp:263] Max_power = -3
I1028 18:10:25.350693 12309 inq_conv_layer.cpp:264] Min_power = -9
I1028 18:10:25.350699 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.3125% -> 40.625%)
I1028 18:10:25.350708 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 64/64
I1028 18:10:25.350711 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 13/38/51
I1028 18:10:25.354792 12309 inq_conv_layer.cu:52] fire2/expand3x3 (INQConvolution):  Shaping the weights...
I1028 18:10:25.355964 12309 inq_conv_layer.cpp:263] Max_power = -1
I1028 18:10:25.355971 12309 inq_conv_layer.cpp:264] Min_power = -7
I1028 18:10:25.356050 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9978% -> 39.9957%)
I1028 18:10:25.356062 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 9216/9216
I1028 18:10:25.356066 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 1843/5530/7373
I1028 18:10:25.356930 12309 inq_conv_layer.cu:62] fire2/expand3x3 (INQConvolution):  Shaping the bias...
I1028 18:10:25.356966 12309 inq_conv_layer.cpp:263] Max_power = -4
I1028 18:10:25.356984 12309 inq_conv_layer.cpp:264] Min_power = -10
I1028 18:10:25.356992 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.3125% -> 40.625%)
I1028 18:10:25.357000 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 64/64
I1028 18:10:25.357003 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 13/38/51
I1028 18:10:25.365975 12309 inq_conv_layer.cu:52] fire3/squeeze1x1 (INQConvolution):  Shaping the weights...
I1028 18:10:25.369555 12309 inq_conv_layer.cpp:263] Max_power = 0
I1028 18:10:25.369562 12309 inq_conv_layer.cpp:264] Min_power = -6
I1028 18:10:25.369581 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0195% -> 39.9902%)
I1028 18:10:25.369592 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 2048/2048
I1028 18:10:25.369596 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 409/1229/1638
I1028 18:10:25.369772 12309 inq_conv_layer.cu:62] fire3/squeeze1x1 (INQConvolution):  Shaping the bias...
I1028 18:10:25.369802 12309 inq_conv_layer.cpp:263] Max_power = -2
I1028 18:10:25.369807 12309 inq_conv_layer.cpp:264] Min_power = -8
I1028 18:10:25.369812 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 18.75% -> 37.5%)
I1028 18:10:25.369819 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 16/16
I1028 18:10:25.369822 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 3/10/13
I1028 18:10:25.373257 12309 inq_conv_layer.cu:52] fire3/expand1x1 (INQConvolution):  Shaping the weights...
I1028 18:10:25.374002 12309 inq_conv_layer.cpp:263] Max_power = 0
I1028 18:10:25.374008 12309 inq_conv_layer.cpp:264] Min_power = -6
I1028 18:10:25.374022 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0195% -> 40.0391%)
I1028 18:10:25.374032 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 1024/1024
I1028 18:10:25.374037 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 205/614/819
I1028 18:10:25.374121 12309 inq_conv_layer.cu:62] fire3/expand1x1 (INQConvolution):  Shaping the bias...
I1028 18:10:25.374150 12309 inq_conv_layer.cpp:263] Max_power = -2
I1028 18:10:25.374153 12309 inq_conv_layer.cpp:264] Min_power = -8
I1028 18:10:25.374159 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.3125% -> 40.625%)
I1028 18:10:25.374167 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 64/64
I1028 18:10:25.374171 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 13/38/51
I1028 18:10:25.378219 12309 inq_conv_layer.cu:52] fire3/expand3x3 (INQConvolution):  Shaping the weights...
I1028 18:10:25.379384 12309 inq_conv_layer.cpp:263] Max_power = 0
I1028 18:10:25.379390 12309 inq_conv_layer.cpp:264] Min_power = -6
I1028 18:10:25.379457 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9978% -> 39.9957%)
I1028 18:10:25.379469 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 9216/9216
I1028 18:10:25.379472 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 1843/5530/7373
I1028 18:10:25.380338 12309 inq_conv_layer.cu:62] fire3/expand3x3 (INQConvolution):  Shaping the bias...
I1028 18:10:25.380370 12309 inq_conv_layer.cpp:263] Max_power = -3
I1028 18:10:25.380375 12309 inq_conv_layer.cpp:264] Min_power = -9
I1028 18:10:25.380381 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.3125% -> 40.625%)
I1028 18:10:25.380393 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 64/64
I1028 18:10:25.380398 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 13/38/51
I1028 18:10:25.392756 12309 inq_conv_layer.cu:52] fire4/squeeze1x1 (INQConvolution):  Shaping the weights...
I1028 18:10:25.395089 12309 inq_conv_layer.cpp:263] Max_power = 0
I1028 18:10:25.395097 12309 inq_conv_layer.cpp:264] Min_power = -6
I1028 18:10:25.395128 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9951% -> 39.9902%)
I1028 18:10:25.395140 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 4096/4096
I1028 18:10:25.395144 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 819/2458/3277
I1028 18:10:25.395519 12309 inq_conv_layer.cu:62] fire4/squeeze1x1 (INQConvolution):  Shaping the bias...
I1028 18:10:25.395551 12309 inq_conv_layer.cpp:263] Max_power = -3
I1028 18:10:25.395556 12309 inq_conv_layer.cpp:264] Min_power = -9
I1028 18:10:25.395562 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 18.75% -> 37.5%)
I1028 18:10:25.395570 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 33/32
I1028 18:10:25.395573 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 6/20/26
I1028 18:10:25.399063 12309 inq_conv_layer.cu:52] fire4/expand1x1 (INQConvolution):  Shaping the weights...
I1028 18:10:25.400243 12309 inq_conv_layer.cpp:263] Max_power = -1
I1028 18:10:25.400249 12309 inq_conv_layer.cpp:264] Min_power = -7
I1028 18:10:25.400281 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9951% -> 39.9902%)
I1028 18:10:25.400292 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 4096/4096
I1028 18:10:25.400296 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 819/2458/3277
I1028 18:10:25.400657 12309 inq_conv_layer.cu:62] fire4/expand1x1 (INQConvolution):  Shaping the bias...
I1028 18:10:25.400687 12309 inq_conv_layer.cpp:263] Max_power = -4
I1028 18:10:25.400692 12309 inq_conv_layer.cpp:264] Min_power = -10
I1028 18:10:25.400698 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.3125% -> 39.8438%)
I1028 18:10:25.400707 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 128/128
I1028 18:10:25.400710 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 25/77/102
I1028 18:10:25.404516 12309 inq_conv_layer.cu:52] fire4/expand3x3 (INQConvolution):  Shaping the weights...
I1028 18:10:25.405396 12309 inq_conv_layer.cpp:263] Max_power = -1
I1028 18:10:25.405403 12309 inq_conv_layer.cpp:264] Min_power = -7
I1028 18:10:25.405666 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0005% -> 40.0011%)
I1028 18:10:25.405678 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 36864/36864
I1028 18:10:25.405683 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 7373/22118/29491
I1028 18:10:25.409422 12309 inq_conv_layer.cu:62] fire4/expand3x3 (INQConvolution):  Shaping the bias...
I1028 18:10:25.409457 12309 inq_conv_layer.cpp:263] Max_power = -4
I1028 18:10:25.409461 12309 inq_conv_layer.cpp:264] Min_power = -10
I1028 18:10:25.409469 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.3125% -> 39.8438%)
I1028 18:10:25.409477 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 128/128
I1028 18:10:25.409482 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 25/77/102
I1028 18:10:25.416076 12309 inq_conv_layer.cu:52] fire5/squeeze1x1 (INQConvolution):  Shaping the weights...
I1028 18:10:25.418231 12309 inq_conv_layer.cpp:263] Max_power = -1
I1028 18:10:25.418238 12309 inq_conv_layer.cpp:264] Min_power = -7
I1028 18:10:25.418292 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9951% -> 39.9902%)
I1028 18:10:25.418303 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 8193/8192
I1028 18:10:25.418308 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 1638/4916/6554
I1028 18:10:25.419080 12309 inq_conv_layer.cu:62] fire5/squeeze1x1 (INQConvolution):  Shaping the bias...
I1028 18:10:25.419113 12309 inq_conv_layer.cpp:263] Max_power = -2
I1028 18:10:25.419118 12309 inq_conv_layer.cpp:264] Min_power = -8
I1028 18:10:25.419124 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 18.75% -> 37.5%)
I1028 18:10:25.419131 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 33/32
I1028 18:10:25.419136 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 6/20/26
I1028 18:10:25.424167 12309 inq_conv_layer.cu:52] fire5/expand1x1 (INQConvolution):  Shaping the weights...
I1028 18:10:25.426151 12309 inq_conv_layer.cpp:263] Max_power = -1
I1028 18:10:25.426157 12309 inq_conv_layer.cpp:264] Min_power = -7
I1028 18:10:25.426199 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9951% -> 39.9902%)
I1028 18:10:25.426211 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 4096/4096
I1028 18:10:25.426214 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 819/2458/3277
I1028 18:10:25.426581 12309 inq_conv_layer.cu:62] fire5/expand1x1 (INQConvolution):  Shaping the bias...
I1028 18:10:25.426614 12309 inq_conv_layer.cpp:263] Max_power = -3
I1028 18:10:25.426618 12309 inq_conv_layer.cpp:264] Min_power = -9
I1028 18:10:25.426625 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.3125% -> 39.8438%)
I1028 18:10:25.426633 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 128/128
I1028 18:10:25.426636 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 25/77/102
I1028 18:10:25.430433 12309 inq_conv_layer.cu:52] fire5/expand3x3 (INQConvolution):  Shaping the weights...
I1028 18:10:25.431321 12309 inq_conv_layer.cpp:263] Max_power = 0
I1028 18:10:25.431329 12309 inq_conv_layer.cpp:264] Min_power = -6
I1028 18:10:25.431541 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0005% -> 40.0011%)
I1028 18:10:25.431553 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 36864/36864
I1028 18:10:25.431557 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 7373/22118/29491
I1028 18:10:25.435295 12309 inq_conv_layer.cu:62] fire5/expand3x3 (INQConvolution):  Shaping the bias...
I1028 18:10:25.435328 12309 inq_conv_layer.cpp:263] Max_power = -5
I1028 18:10:25.435333 12309 inq_conv_layer.cpp:264] Min_power = -11
I1028 18:10:25.435340 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.3125% -> 39.8438%)
I1028 18:10:25.435349 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 128/128
I1028 18:10:25.435353 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 25/77/102
I1028 18:10:25.445225 12309 inq_conv_layer.cu:52] fire6/squeeze1x1 (INQConvolution):  Shaping the weights...
I1028 18:10:25.446202 12309 inq_conv_layer.cpp:263] Max_power = -1
I1028 18:10:25.446208 12309 inq_conv_layer.cpp:264] Min_power = -7
I1028 18:10:25.446283 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0033% -> 39.9984%)
I1028 18:10:25.446295 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 12288/12288
I1028 18:10:25.446300 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 2457/7373/9830
I1028 18:10:25.447473 12309 inq_conv_layer.cu:62] fire6/squeeze1x1 (INQConvolution):  Shaping the bias...
I1028 18:10:25.447504 12309 inq_conv_layer.cpp:263] Max_power = -3
I1028 18:10:25.447509 12309 inq_conv_layer.cpp:264] Min_power = -9
I1028 18:10:25.447515 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.8333% -> 39.5833%)
I1028 18:10:25.447523 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 48/48
I1028 18:10:25.447526 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 9/29/38
I1028 18:10:25.451272 12309 inq_conv_layer.cu:52] fire6/expand1x1 (INQConvolution):  Shaping the weights...
I1028 18:10:25.453616 12309 inq_conv_layer.cpp:263] Max_power = -1
I1028 18:10:25.453622 12309 inq_conv_layer.cpp:264] Min_power = -7
I1028 18:10:25.453680 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9978% -> 39.9957%)
I1028 18:10:25.453696 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 9216/9216
I1028 18:10:25.453701 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 1843/5530/7373
I1028 18:10:25.454566 12309 inq_conv_layer.cu:62] fire6/expand1x1 (INQConvolution):  Shaping the bias...
I1028 18:10:25.454596 12309 inq_conv_layer.cpp:263] Max_power = -5
I1028 18:10:25.454602 12309 inq_conv_layer.cpp:264] Min_power = -11
I1028 18:10:25.454609 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.7917% -> 39.5833%)
I1028 18:10:25.454618 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 193/192
I1028 18:10:25.454622 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 38/116/154
I1028 18:10:25.458214 12309 inq_conv_layer.cu:52] fire6/expand3x3 (INQConvolution):  Shaping the weights...
I1028 18:10:25.459151 12309 inq_conv_layer.cpp:263] Max_power = -1
I1028 18:10:25.459157 12309 inq_conv_layer.cpp:264] Min_power = -7
I1028 18:10:25.459792 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0002% -> 40.0005%)
I1028 18:10:25.459805 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 82944/82944
I1028 18:10:25.459808 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 16589/49766/66355
I1028 18:10:25.468701 12309 inq_conv_layer.cu:62] fire6/expand3x3 (INQConvolution):  Shaping the bias...
I1028 18:10:25.468737 12309 inq_conv_layer.cpp:263] Max_power = -5
I1028 18:10:25.468742 12309 inq_conv_layer.cpp:264] Min_power = -11
I1028 18:10:25.468750 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.7917% -> 39.5833%)
I1028 18:10:25.468760 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 193/192
I1028 18:10:25.468762 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 38/116/154
I1028 18:10:25.475070 12309 inq_conv_layer.cu:52] fire7/squeeze1x1 (INQConvolution):  Shaping the weights...
I1028 18:10:25.477131 12309 inq_conv_layer.cpp:263] Max_power = -1
I1028 18:10:25.477138 12309 inq_conv_layer.cpp:264] Min_power = -7
I1028 18:10:25.477243 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9978% -> 39.9957%)
I1028 18:10:25.477257 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 18433/18432
I1028 18:10:25.477260 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 3686/11060/14746
I1028 18:10:25.479068 12309 inq_conv_layer.cu:62] fire7/squeeze1x1 (INQConvolution):  Shaping the bias...
I1028 18:10:25.479099 12309 inq_conv_layer.cpp:263] Max_power = -2
I1028 18:10:25.479104 12309 inq_conv_layer.cpp:264] Min_power = -8
I1028 18:10:25.479110 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.8333% -> 39.5833%)
I1028 18:10:25.479118 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 48/48
I1028 18:10:25.479121 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 9/29/38
I1028 18:10:25.482703 12309 inq_conv_layer.cu:52] fire7/expand1x1 (INQConvolution):  Shaping the weights...
I1028 18:10:25.486261 12309 inq_conv_layer.cpp:263] Max_power = -1
I1028 18:10:25.486268 12309 inq_conv_layer.cpp:264] Min_power = -7
I1028 18:10:25.486326 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9978% -> 39.9957%)
I1028 18:10:25.486337 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 9216/9216
I1028 18:10:25.486341 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 1843/5530/7373
I1028 18:10:25.487213 12309 inq_conv_layer.cu:62] fire7/expand1x1 (INQConvolution):  Shaping the bias...
I1028 18:10:25.487243 12309 inq_conv_layer.cpp:263] Max_power = -2
I1028 18:10:25.487247 12309 inq_conv_layer.cpp:264] Min_power = -8
I1028 18:10:25.487256 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.7917% -> 39.5833%)
I1028 18:10:25.487263 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 193/192
I1028 18:10:25.487267 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 38/116/154
I1028 18:10:25.490831 12309 inq_conv_layer.cu:52] fire7/expand3x3 (INQConvolution):  Shaping the weights...
I1028 18:10:25.491767 12309 inq_conv_layer.cpp:263] Max_power = -1
I1028 18:10:25.491775 12309 inq_conv_layer.cpp:264] Min_power = -7
I1028 18:10:25.492266 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0002% -> 40.0005%)
I1028 18:10:25.492278 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 82944/82944
I1028 18:10:25.492282 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 16589/49766/66355
I1028 18:10:25.501103 12309 inq_conv_layer.cu:62] fire7/expand3x3 (INQConvolution):  Shaping the bias...
I1028 18:10:25.501138 12309 inq_conv_layer.cpp:263] Max_power = -4
I1028 18:10:25.501142 12309 inq_conv_layer.cpp:264] Min_power = -10
I1028 18:10:25.501152 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.7917% -> 39.5833%)
I1028 18:10:25.501173 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 193/192
I1028 18:10:25.501176 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 38/116/154
I1028 18:10:25.507608 12309 inq_conv_layer.cu:52] fire8/squeeze1x1 (INQConvolution):  Shaping the weights...
I1028 18:10:25.509711 12309 inq_conv_layer.cpp:263] Max_power = -1
I1028 18:10:25.509718 12309 inq_conv_layer.cpp:264] Min_power = -7
I1028 18:10:25.509860 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9992% -> 39.9984%)
I1028 18:10:25.509873 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 24576/24576
I1028 18:10:25.509877 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 4915/14746/19661
I1028 18:10:25.512328 12309 inq_conv_layer.cu:62] fire8/squeeze1x1 (INQConvolution):  Shaping the bias...
I1028 18:10:25.512358 12309 inq_conv_layer.cpp:263] Max_power = 3
I1028 18:10:25.512363 12309 inq_conv_layer.cpp:264] Min_power = -3
I1028 18:10:25.512369 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.3125% -> 40.625%)
I1028 18:10:25.512378 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 64/64
I1028 18:10:25.512382 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 13/38/51
I1028 18:10:25.515944 12309 inq_conv_layer.cu:52] fire8/expand1x1 (INQConvolution):  Shaping the weights...
I1028 18:10:25.519618 12309 inq_conv_layer.cpp:263] Max_power = -1
I1028 18:10:25.519625 12309 inq_conv_layer.cpp:264] Min_power = -7
I1028 18:10:25.519722 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0012% -> 40.0024%)
I1028 18:10:25.519734 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 16384/16384
I1028 18:10:25.519738 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 3277/9830/13107
I1028 18:10:25.521342 12309 inq_conv_layer.cu:62] fire8/expand1x1 (INQConvolution):  Shaping the bias...
I1028 18:10:25.521375 12309 inq_conv_layer.cpp:263] Max_power = -1
I1028 18:10:25.521379 12309 inq_conv_layer.cpp:264] Min_power = -7
I1028 18:10:25.521389 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9219% -> 39.8438%)
I1028 18:10:25.521397 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 256/256
I1028 18:10:25.521400 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 51/154/205
I1028 18:10:25.525063 12309 inq_conv_layer.cu:52] fire8/expand3x3 (INQConvolution):  Shaping the weights...
I1028 18:10:25.526528 12309 inq_conv_layer.cpp:263] Max_power = -1
I1028 18:10:25.526535 12309 inq_conv_layer.cpp:264] Min_power = -7
I1028 18:10:25.527380 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9999% -> 39.9997%)
I1028 18:10:25.527393 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 147456/147456
I1028 18:10:25.527397 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 29491/88474/117965
I1028 18:10:25.543583 12309 inq_conv_layer.cu:62] fire8/expand3x3 (INQConvolution):  Shaping the bias...
I1028 18:10:25.543617 12309 inq_conv_layer.cpp:263] Max_power = -1
I1028 18:10:25.543622 12309 inq_conv_layer.cpp:264] Min_power = -7
I1028 18:10:25.543629 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9219% -> 39.8438%)
I1028 18:10:25.543642 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 256/256
I1028 18:10:25.543647 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 51/154/205
I1028 18:10:25.550627 12309 inq_conv_layer.cu:52] fire9/squeeze1x1 (INQConvolution):  Shaping the weights...
I1028 18:10:25.554257 12309 inq_conv_layer.cpp:263] Max_power = -1
I1028 18:10:25.554265 12309 inq_conv_layer.cpp:264] Min_power = -7
I1028 18:10:25.554447 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0012% -> 39.9994%)
I1028 18:10:25.554461 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 32768/32768
I1028 18:10:25.554464 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 6553/19661/26214
I1028 18:10:25.557782 12309 inq_conv_layer.cu:62] fire9/squeeze1x1 (INQConvolution):  Shaping the bias...
I1028 18:10:25.557816 12309 inq_conv_layer.cpp:263] Max_power = 0
I1028 18:10:25.557821 12309 inq_conv_layer.cpp:264] Min_power = -6
I1028 18:10:25.557826 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.3125% -> 40.625%)
I1028 18:10:25.557835 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 64/64
I1028 18:10:25.557838 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 13/38/51
I1028 18:10:25.561420 12309 inq_conv_layer.cu:52] fire9/expand1x1 (INQConvolution):  Shaping the weights...
I1028 18:10:25.566334 12309 inq_conv_layer.cpp:263] Max_power = -1
I1028 18:10:25.566339 12309 inq_conv_layer.cpp:264] Min_power = -7
I1028 18:10:25.566439 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0012% -> 40.0024%)
I1028 18:10:25.566452 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 16384/16384
I1028 18:10:25.566455 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 3277/9830/13107
I1028 18:10:25.568039 12309 inq_conv_layer.cu:62] fire9/expand1x1 (INQConvolution):  Shaping the bias...
I1028 18:10:25.568073 12309 inq_conv_layer.cpp:263] Max_power = -4
I1028 18:10:25.568078 12309 inq_conv_layer.cpp:264] Min_power = -10
I1028 18:10:25.568086 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9219% -> 39.8438%)
I1028 18:10:25.568095 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 256/256
I1028 18:10:25.568099 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 51/154/205
I1028 18:10:25.571719 12309 inq_conv_layer.cu:52] fire9/expand3x3 (INQConvolution):  Shaping the weights...
I1028 18:10:25.573189 12309 inq_conv_layer.cpp:263] Max_power = -1
I1028 18:10:25.573196 12309 inq_conv_layer.cpp:264] Min_power = -7
I1028 18:10:25.573989 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9999% -> 39.9997%)
I1028 18:10:25.574002 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 147456/147456
I1028 18:10:25.574005 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 29491/88474/117965
I1028 18:10:25.590216 12309 inq_conv_layer.cu:62] fire9/expand3x3 (INQConvolution):  Shaping the bias...
I1028 18:10:25.590250 12309 inq_conv_layer.cpp:263] Max_power = -5
I1028 18:10:25.590255 12309 inq_conv_layer.cpp:264] Min_power = -11
I1028 18:10:25.590263 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9219% -> 39.8438%)
I1028 18:10:25.590272 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 256/256
I1028 18:10:25.590276 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 51/154/205
I1028 18:10:25.604284 12309 inq_conv_layer.cu:52] conv10 (INQConvolution):  Shaping the weights...
I1028 18:10:25.607836 12309 inq_conv_layer.cpp:263] Max_power = -2
I1028 18:10:25.607843 12309 inq_conv_layer.cpp:264] Min_power = -8
I1028 18:10:25.611336 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20% -> 40%)
I1028 18:10:25.611349 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 512000/512000
I1028 18:10:25.611352 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 102400/307200/409600
I1028 18:10:25.671335 12309 inq_conv_layer.cu:62] conv10 (INQConvolution):  Shaping the bias...
I1028 18:10:25.671378 12309 inq_conv_layer.cpp:263] Max_power = -2
I1028 18:10:25.671385 12309 inq_conv_layer.cpp:264] Min_power = -8
I1028 18:10:25.671398 12309 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20% -> 40%)
I1028 18:10:25.671406 12309 inq_conv_layer.cpp:313] init_not_quantized/total: 1000/1000
I1028 18:10:25.671409 12309 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 200/600/800
I1028 18:10:26.560968 12309 solver.cpp:222] Iteration 0 (-2.96702e-34 iter/s, 32.5351s/40 iters), loss = 1.90886
I1028 18:10:26.561010 12309 solver.cpp:241]     Train net output #0: loss = 1.90886 (* 1 = 1.90886 loss)
I1028 18:10:26.561024 12309 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I1028 18:10:57.124580 12309 solver.cpp:222] Iteration 40 (1.30878 iter/s, 30.5629s/40 iters), loss = 2.22199
I1028 18:10:57.124868 12309 solver.cpp:241]     Train net output #0: loss = 2.22199 (* 1 = 2.22199 loss)
I1028 18:10:57.124889 12309 sgd_solver.cpp:105] Iteration 40, lr = 0.00996007
I1028 18:11:27.850952 12309 solver.cpp:222] Iteration 80 (1.30185 iter/s, 30.7254s/40 iters), loss = 2.08814
I1028 18:11:27.851125 12309 solver.cpp:241]     Train net output #0: loss = 2.08814 (* 1 = 2.08814 loss)
I1028 18:11:27.851142 12309 sgd_solver.cpp:105] Iteration 80, lr = 0.0099203
I1028 18:11:58.459537 12309 solver.cpp:222] Iteration 120 (1.30686 iter/s, 30.6077s/40 iters), loss = 1.92663
I1028 18:11:58.459657 12309 solver.cpp:241]     Train net output #0: loss = 1.92663 (* 1 = 1.92663 loss)
I1028 18:11:58.459674 12309 sgd_solver.cpp:105] Iteration 120, lr = 0.00988069
I1028 18:12:29.196768 12309 solver.cpp:222] Iteration 160 (1.30139 iter/s, 30.7364s/40 iters), loss = 1.6523
I1028 18:12:29.197000 12309 solver.cpp:241]     Train net output #0: loss = 1.6523 (* 1 = 1.6523 loss)
I1028 18:12:29.197017 12309 sgd_solver.cpp:105] Iteration 160, lr = 0.00984124
I1028 18:12:59.808027 12309 solver.cpp:222] Iteration 200 (1.30675 iter/s, 30.6103s/40 iters), loss = 1.92943
I1028 18:12:59.808189 12309 solver.cpp:241]     Train net output #0: loss = 1.92943 (* 1 = 1.92943 loss)
I1028 18:12:59.808203 12309 sgd_solver.cpp:105] Iteration 200, lr = 0.00980194
I1028 18:13:30.668905 12309 solver.cpp:222] Iteration 240 (1.29618 iter/s, 30.86s/40 iters), loss = 1.79413
I1028 18:13:30.669081 12309 solver.cpp:241]     Train net output #0: loss = 1.79413 (* 1 = 1.79413 loss)
I1028 18:13:30.669098 12309 sgd_solver.cpp:105] Iteration 240, lr = 0.00976281
I1028 18:14:01.179167 12309 solver.cpp:222] Iteration 280 (1.31107 iter/s, 30.5094s/40 iters), loss = 1.61814
I1028 18:14:01.179329 12309 solver.cpp:241]     Train net output #0: loss = 1.61814 (* 1 = 1.61814 loss)
I1028 18:14:01.179347 12309 sgd_solver.cpp:105] Iteration 280, lr = 0.00972382
I1028 18:14:31.794765 12309 solver.cpp:222] Iteration 320 (1.30656 iter/s, 30.6147s/40 iters), loss = 1.9037
I1028 18:14:31.794945 12309 solver.cpp:241]     Train net output #0: loss = 1.9037 (* 1 = 1.9037 loss)
I1028 18:14:31.794962 12309 sgd_solver.cpp:105] Iteration 320, lr = 0.009685
I1028 18:15:02.257539 12309 solver.cpp:222] Iteration 360 (1.31312 iter/s, 30.4619s/40 iters), loss = 1.7763
I1028 18:15:02.257725 12309 solver.cpp:241]     Train net output #0: loss = 1.7763 (* 1 = 1.7763 loss)
I1028 18:15:02.257741 12309 sgd_solver.cpp:105] Iteration 360, lr = 0.00964633
I1028 18:15:32.986878 12309 solver.cpp:222] Iteration 400 (1.30173 iter/s, 30.7284s/40 iters), loss = 1.84117
I1028 18:15:32.987068 12309 solver.cpp:241]     Train net output #0: loss = 1.84117 (* 1 = 1.84117 loss)
I1028 18:15:32.987085 12309 sgd_solver.cpp:105] Iteration 400, lr = 0.00960781
I1028 18:16:03.826344 12309 solver.cpp:222] Iteration 440 (1.29708 iter/s, 30.8385s/40 iters), loss = 1.72254
I1028 18:16:03.826539 12309 solver.cpp:241]     Train net output #0: loss = 1.72254 (* 1 = 1.72254 loss)
I1028 18:16:03.826552 12309 sgd_solver.cpp:105] Iteration 440, lr = 0.00956945
I1028 18:16:34.885640 12309 solver.cpp:222] Iteration 480 (1.2879 iter/s, 31.0584s/40 iters), loss = 1.59878
I1028 18:16:34.885871 12309 solver.cpp:241]     Train net output #0: loss = 1.59878 (* 1 = 1.59878 loss)
I1028 18:16:34.885891 12309 sgd_solver.cpp:105] Iteration 480, lr = 0.00953124
I1028 18:16:49.421809 12309 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_500.caffemodel
I1028 18:16:49.628259 12309 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_500.solverstate
I1028 18:16:49.740129 12309 solver.cpp:334] Iteration 500, Testing net (#0)
I1028 18:17:20.660045 12361 data_layer.cpp:73] Restarting data prefetching from start.
I1028 18:17:20.867666 12309 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.52376
I1028 18:17:20.867722 12309 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77168
I1028 18:17:20.867733 12309 solver.cpp:401]     Test net output #2: loss = 2.09088 (* 1 = 2.09088 loss)
I1028 18:17:37.027246 12309 solver.cpp:222] Iteration 520 (0.643709 iter/s, 62.1399s/40 iters), loss = 1.78072
I1028 18:17:37.027304 12309 solver.cpp:241]     Train net output #0: loss = 1.78072 (* 1 = 1.78072 loss)
I1028 18:17:37.027325 12309 sgd_solver.cpp:105] Iteration 520, lr = 0.00949318
I1028 18:18:08.060688 12309 solver.cpp:222] Iteration 560 (1.28897 iter/s, 31.0326s/40 iters), loss = 2.08204
I1028 18:18:08.060878 12309 solver.cpp:241]     Train net output #0: loss = 2.08204 (* 1 = 2.08204 loss)
I1028 18:18:08.060899 12309 sgd_solver.cpp:105] Iteration 560, lr = 0.00945528
I1028 18:18:37.969310 12309 solver.cpp:222] Iteration 600 (1.33745 iter/s, 29.9077s/40 iters), loss = 1.72854
I1028 18:18:37.969364 12309 solver.cpp:241]     Train net output #0: loss = 1.72854 (* 1 = 1.72854 loss)
I1028 18:18:37.969378 12309 sgd_solver.cpp:105] Iteration 600, lr = 0.00941752
I1028 18:19:07.704658 12309 solver.cpp:222] Iteration 640 (1.34524 iter/s, 29.7345s/40 iters), loss = 1.59051
I1028 18:19:07.704871 12309 solver.cpp:241]     Train net output #0: loss = 1.59051 (* 1 = 1.59051 loss)
I1028 18:19:07.704898 12309 sgd_solver.cpp:105] Iteration 640, lr = 0.00937992
I1028 18:19:38.364225 12309 solver.cpp:222] Iteration 680 (1.30469 iter/s, 30.6586s/40 iters), loss = 1.74334
I1028 18:19:38.364406 12309 solver.cpp:241]     Train net output #0: loss = 1.74334 (* 1 = 1.74334 loss)
I1028 18:19:38.364423 12309 sgd_solver.cpp:105] Iteration 680, lr = 0.00934247
I1028 18:20:09.093369 12309 solver.cpp:222] Iteration 720 (1.30174 iter/s, 30.7282s/40 iters), loss = 1.75407
I1028 18:20:09.093564 12309 solver.cpp:241]     Train net output #0: loss = 1.75407 (* 1 = 1.75407 loss)
I1028 18:20:09.093583 12309 sgd_solver.cpp:105] Iteration 720, lr = 0.00930516
I1028 18:20:39.832121 12309 solver.cpp:222] Iteration 760 (1.30133 iter/s, 30.7378s/40 iters), loss = 1.91558
I1028 18:20:39.832321 12309 solver.cpp:241]     Train net output #0: loss = 1.91558 (* 1 = 1.91558 loss)
I1028 18:20:39.832340 12309 sgd_solver.cpp:105] Iteration 760, lr = 0.00926801
I1028 18:21:10.903918 12309 solver.cpp:222] Iteration 800 (1.28738 iter/s, 31.0708s/40 iters), loss = 1.66305
I1028 18:21:10.904125 12309 solver.cpp:241]     Train net output #0: loss = 1.66305 (* 1 = 1.66305 loss)
I1028 18:21:10.904144 12309 sgd_solver.cpp:105] Iteration 800, lr = 0.009231
I1028 18:21:41.750775 12309 solver.cpp:222] Iteration 840 (1.29677 iter/s, 30.8459s/40 iters), loss = 1.82409
I1028 18:21:41.750953 12309 solver.cpp:241]     Train net output #0: loss = 1.82409 (* 1 = 1.82409 loss)
I1028 18:21:41.750970 12309 sgd_solver.cpp:105] Iteration 840, lr = 0.00919415
I1028 18:22:12.759932 12309 solver.cpp:222] Iteration 880 (1.28998 iter/s, 31.0082s/40 iters), loss = 1.89802
I1028 18:22:12.760094 12309 solver.cpp:241]     Train net output #0: loss = 1.89802 (* 1 = 1.89802 loss)
I1028 18:22:12.760110 12309 sgd_solver.cpp:105] Iteration 880, lr = 0.00915743
I1028 18:22:43.433851 12309 solver.cpp:222] Iteration 920 (1.30408 iter/s, 30.673s/40 iters), loss = 1.59531
I1028 18:22:43.434018 12309 solver.cpp:241]     Train net output #0: loss = 1.59531 (* 1 = 1.59531 loss)
I1028 18:22:43.434034 12309 sgd_solver.cpp:105] Iteration 920, lr = 0.00912087
I1028 18:23:14.149452 12309 solver.cpp:222] Iteration 960 (1.30231 iter/s, 30.7147s/40 iters), loss = 1.79732
I1028 18:23:14.149683 12309 solver.cpp:241]     Train net output #0: loss = 1.79732 (* 1 = 1.79732 loss)
I1028 18:23:14.149704 12309 sgd_solver.cpp:105] Iteration 960, lr = 0.00908445
I1028 18:23:44.188098 12309 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_1000.caffemodel
I1028 18:23:44.358909 12309 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_1000.solverstate
I1028 18:23:44.496284 12309 solver.cpp:334] Iteration 1000, Testing net (#0)
I1028 18:24:15.914090 12309 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53144
I1028 18:24:15.914240 12309 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.773879
I1028 18:24:15.914253 12309 solver.cpp:401]     Test net output #2: loss = 2.09441 (* 1 = 2.09441 loss)
I1028 18:24:16.676796 12309 solver.cpp:222] Iteration 1000 (0.639738 iter/s, 62.5256s/40 iters), loss = 1.08829
I1028 18:24:16.676870 12309 solver.cpp:241]     Train net output #0: loss = 1.08829 (* 1 = 1.08829 loss)
I1028 18:24:16.676888 12309 sgd_solver.cpp:105] Iteration 1000, lr = 0.00904818
I1028 18:24:47.784865 12309 solver.cpp:222] Iteration 1040 (1.28588 iter/s, 31.1072s/40 iters), loss = 2.07279
I1028 18:24:47.785042 12309 solver.cpp:241]     Train net output #0: loss = 2.07279 (* 1 = 2.07279 loss)
I1028 18:24:47.785058 12309 sgd_solver.cpp:105] Iteration 1040, lr = 0.00901205
I1028 18:25:18.677207 12309 solver.cpp:222] Iteration 1080 (1.29486 iter/s, 30.8913s/40 iters), loss = 2.00274
I1028 18:25:18.677397 12309 solver.cpp:241]     Train net output #0: loss = 2.00274 (* 1 = 2.00274 loss)
I1028 18:25:18.677414 12309 sgd_solver.cpp:105] Iteration 1080, lr = 0.00897607
I1028 18:25:49.525408 12309 solver.cpp:222] Iteration 1120 (1.29671 iter/s, 30.8472s/40 iters), loss = 1.6599
I1028 18:25:49.525594 12309 solver.cpp:241]     Train net output #0: loss = 1.6599 (* 1 = 1.6599 loss)
I1028 18:25:49.525611 12309 sgd_solver.cpp:105] Iteration 1120, lr = 0.00894023
I1028 18:26:20.697929 12309 solver.cpp:222] Iteration 1160 (1.28322 iter/s, 31.1715s/40 iters), loss = 1.61393
I1028 18:26:20.698119 12309 solver.cpp:241]     Train net output #0: loss = 1.61393 (* 1 = 1.61393 loss)
I1028 18:26:20.698137 12309 sgd_solver.cpp:105] Iteration 1160, lr = 0.00890453
I1028 18:26:51.479961 12309 solver.cpp:222] Iteration 1200 (1.2995 iter/s, 30.7811s/40 iters), loss = 1.46422
I1028 18:26:51.480140 12309 solver.cpp:241]     Train net output #0: loss = 1.46422 (* 1 = 1.46422 loss)
I1028 18:26:51.480159 12309 sgd_solver.cpp:105] Iteration 1200, lr = 0.00886897
I1028 18:27:22.302819 12309 solver.cpp:222] Iteration 1240 (1.29778 iter/s, 30.8219s/40 iters), loss = 1.70824
I1028 18:27:22.302999 12309 solver.cpp:241]     Train net output #0: loss = 1.70824 (* 1 = 1.70824 loss)
I1028 18:27:22.303014 12309 sgd_solver.cpp:105] Iteration 1240, lr = 0.00883356
I1028 18:27:53.182986 12309 solver.cpp:222] Iteration 1280 (1.29537 iter/s, 30.8792s/40 iters), loss = 1.64984
I1028 18:27:53.183172 12309 solver.cpp:241]     Train net output #0: loss = 1.64984 (* 1 = 1.64984 loss)
I1028 18:27:53.183188 12309 sgd_solver.cpp:105] Iteration 1280, lr = 0.00879829
I1028 18:28:23.846560 12309 solver.cpp:222] Iteration 1320 (1.30452 iter/s, 30.6626s/40 iters), loss = 1.83913
I1028 18:28:23.846751 12309 solver.cpp:241]     Train net output #0: loss = 1.83913 (* 1 = 1.83913 loss)
I1028 18:28:23.846768 12309 sgd_solver.cpp:105] Iteration 1320, lr = 0.00876316
I1028 18:28:54.837872 12309 solver.cpp:222] Iteration 1360 (1.29073 iter/s, 30.9903s/40 iters), loss = 1.90068
I1028 18:28:54.838047 12309 solver.cpp:241]     Train net output #0: loss = 1.90068 (* 1 = 1.90068 loss)
I1028 18:28:54.838066 12309 sgd_solver.cpp:105] Iteration 1360, lr = 0.00872817
I1028 18:29:25.846465 12309 solver.cpp:222] Iteration 1400 (1.29001 iter/s, 31.0076s/40 iters), loss = 1.62291
I1028 18:29:25.846694 12309 solver.cpp:241]     Train net output #0: loss = 1.62291 (* 1 = 1.62291 loss)
I1028 18:29:25.846716 12309 sgd_solver.cpp:105] Iteration 1400, lr = 0.00869332
I1028 18:29:56.657886 12309 solver.cpp:222] Iteration 1440 (1.29826 iter/s, 30.8105s/40 iters), loss = 1.8166
I1028 18:29:56.658090 12309 solver.cpp:241]     Train net output #0: loss = 1.8166 (* 1 = 1.8166 loss)
I1028 18:29:56.658107 12309 sgd_solver.cpp:105] Iteration 1440, lr = 0.00865861
I1028 18:30:27.402568 12309 solver.cpp:222] Iteration 1480 (1.30108 iter/s, 30.7437s/40 iters), loss = 1.81698
I1028 18:30:27.402763 12309 solver.cpp:241]     Train net output #0: loss = 1.81698 (* 1 = 1.81698 loss)
I1028 18:30:27.402779 12309 sgd_solver.cpp:105] Iteration 1480, lr = 0.00862403
I1028 18:30:42.056277 12309 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_1500.caffemodel
I1028 18:30:42.197374 12309 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_1500.solverstate
I1028 18:30:42.329120 12309 solver.cpp:334] Iteration 1500, Testing net (#0)
I1028 18:31:13.613924 12361 data_layer.cpp:73] Restarting data prefetching from start.
I1028 18:31:13.830214 12309 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53748
I1028 18:31:13.830267 12309 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77804
I1028 18:31:13.830278 12309 solver.cpp:401]     Test net output #2: loss = 2.08565 (* 1 = 2.08565 loss)
I1028 18:31:29.899480 12309 solver.cpp:222] Iteration 1520 (0.640049 iter/s, 62.4952s/40 iters), loss = 2.05821
I1028 18:31:29.899544 12309 solver.cpp:241]     Train net output #0: loss = 2.05821 (* 1 = 2.05821 loss)
I1028 18:31:29.899557 12309 sgd_solver.cpp:105] Iteration 1520, lr = 0.0085896
I1028 18:32:00.456883 12309 solver.cpp:222] Iteration 1560 (1.30905 iter/s, 30.5566s/40 iters), loss = 1.81972
I1028 18:32:00.457105 12309 solver.cpp:241]     Train net output #0: loss = 1.81972 (* 1 = 1.81972 loss)
I1028 18:32:00.457123 12309 sgd_solver.cpp:105] Iteration 1560, lr = 0.0085553
I1028 18:32:30.120029 12309 solver.cpp:222] Iteration 1600 (1.34852 iter/s, 29.6622s/40 iters), loss = 1.88418
I1028 18:32:30.120085 12309 solver.cpp:241]     Train net output #0: loss = 1.88418 (* 1 = 1.88418 loss)
I1028 18:32:30.120098 12309 sgd_solver.cpp:105] Iteration 1600, lr = 0.00852114
I1028 18:33:00.067574 12309 solver.cpp:222] Iteration 1640 (1.33571 iter/s, 29.9467s/40 iters), loss = 1.70764
I1028 18:33:00.067780 12309 solver.cpp:241]     Train net output #0: loss = 1.70764 (* 1 = 1.70764 loss)
I1028 18:33:00.067796 12309 sgd_solver.cpp:105] Iteration 1640, lr = 0.00848712
I1028 18:33:29.809293 12309 solver.cpp:222] Iteration 1680 (1.34495 iter/s, 29.7408s/40 iters), loss = 1.66869
I1028 18:33:29.809352 12309 solver.cpp:241]     Train net output #0: loss = 1.66869 (* 1 = 1.66869 loss)
I1028 18:33:29.809367 12309 sgd_solver.cpp:105] Iteration 1680, lr = 0.00845323
I1028 18:33:59.870138 12309 solver.cpp:222] Iteration 1720 (1.33067 iter/s, 30.06s/40 iters), loss = 1.5749
I1028 18:33:59.870321 12309 solver.cpp:241]     Train net output #0: loss = 1.5749 (* 1 = 1.5749 loss)
I1028 18:33:59.870337 12309 sgd_solver.cpp:105] Iteration 1720, lr = 0.00841948
I1028 18:34:30.166568 12309 solver.cpp:222] Iteration 1760 (1.32033 iter/s, 30.2955s/40 iters), loss = 1.78809
I1028 18:34:30.166719 12309 solver.cpp:241]     Train net output #0: loss = 1.78809 (* 1 = 1.78809 loss)
I1028 18:34:30.166735 12309 sgd_solver.cpp:105] Iteration 1760, lr = 0.00838586
I1028 18:35:00.693199 12309 solver.cpp:222] Iteration 1800 (1.31037 iter/s, 30.5258s/40 iters), loss = 2.03749
I1028 18:35:00.693361 12309 solver.cpp:241]     Train net output #0: loss = 2.03749 (* 1 = 2.03749 loss)
I1028 18:35:00.693377 12309 sgd_solver.cpp:105] Iteration 1800, lr = 0.00835238
I1028 18:35:30.877626 12309 solver.cpp:222] Iteration 1840 (1.32523 iter/s, 30.1835s/40 iters), loss = 1.76848
I1028 18:35:30.877845 12309 solver.cpp:241]     Train net output #0: loss = 1.76848 (* 1 = 1.76848 loss)
I1028 18:35:30.877861 12309 sgd_solver.cpp:105] Iteration 1840, lr = 0.00831903
I1028 18:36:00.878232 12309 solver.cpp:222] Iteration 1880 (1.33335 iter/s, 29.9996s/40 iters), loss = 1.65008
I1028 18:36:00.878386 12309 solver.cpp:241]     Train net output #0: loss = 1.65008 (* 1 = 1.65008 loss)
I1028 18:36:00.878403 12309 sgd_solver.cpp:105] Iteration 1880, lr = 0.00828581
I1028 18:36:30.844642 12309 solver.cpp:222] Iteration 1920 (1.33487 iter/s, 29.9655s/40 iters), loss = 1.93461
I1028 18:36:30.844705 12309 solver.cpp:241]     Train net output #0: loss = 1.93461 (* 1 = 1.93461 loss)
I1028 18:36:30.844719 12309 sgd_solver.cpp:105] Iteration 1920, lr = 0.00825273
I1028 18:37:01.770864 12309 solver.cpp:222] Iteration 1960 (1.29343 iter/s, 30.9254s/40 iters), loss = 1.71367
I1028 18:37:01.771044 12309 solver.cpp:241]     Train net output #0: loss = 1.71367 (* 1 = 1.71367 loss)
I1028 18:37:01.771062 12309 sgd_solver.cpp:105] Iteration 1960, lr = 0.00821977
I1028 18:37:32.376547 12309 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_2000.caffemodel
I1028 18:37:32.513753 12309 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_2000.solverstate
I1028 18:37:32.625885 12309 solver.cpp:334] Iteration 2000, Testing net (#0)
I1028 18:38:04.049263 12309 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54108
I1028 18:38:04.049429 12309 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77816
I1028 18:38:04.049444 12309 solver.cpp:401]     Test net output #2: loss = 2.06384 (* 1 = 2.06384 loss)
I1028 18:38:04.826894 12309 solver.cpp:222] Iteration 2000 (0.634373 iter/s, 63.0544s/40 iters), loss = 1.51284
I1028 18:38:04.826972 12309 solver.cpp:241]     Train net output #0: loss = 1.51284 (* 1 = 1.51284 loss)
I1028 18:38:04.826994 12309 sgd_solver.cpp:105] Iteration 2000, lr = 0.00818695
I1028 18:38:36.008549 12309 solver.cpp:222] Iteration 2040 (1.28284 iter/s, 31.1808s/40 iters), loss = 1.87962
I1028 18:38:36.008715 12309 solver.cpp:241]     Train net output #0: loss = 1.87962 (* 1 = 1.87962 loss)
I1028 18:38:36.008733 12309 sgd_solver.cpp:105] Iteration 2040, lr = 0.00815426
I1028 18:39:07.616786 12309 solver.cpp:222] Iteration 2080 (1.26553 iter/s, 31.6072s/40 iters), loss = 1.95974
I1028 18:39:07.616988 12309 solver.cpp:241]     Train net output #0: loss = 1.95974 (* 1 = 1.95974 loss)
I1028 18:39:07.617007 12309 sgd_solver.cpp:105] Iteration 2080, lr = 0.00812171
I1028 18:39:39.021868 12309 solver.cpp:222] Iteration 2120 (1.27372 iter/s, 31.4041s/40 iters), loss = 1.50918
I1028 18:39:39.022101 12309 solver.cpp:241]     Train net output #0: loss = 1.50918 (* 1 = 1.50918 loss)
I1028 18:39:39.022126 12309 sgd_solver.cpp:105] Iteration 2120, lr = 0.00808928
I1028 18:40:10.400763 12309 solver.cpp:222] Iteration 2160 (1.27478 iter/s, 31.3779s/40 iters), loss = 1.61213
I1028 18:40:10.401044 12309 solver.cpp:241]     Train net output #0: loss = 1.61213 (* 1 = 1.61213 loss)
I1028 18:40:10.401059 12309 sgd_solver.cpp:105] Iteration 2160, lr = 0.00805698
I1028 18:40:41.483363 12309 solver.cpp:222] Iteration 2200 (1.28694 iter/s, 31.0815s/40 iters), loss = 1.9569
I1028 18:40:41.483553 12309 solver.cpp:241]     Train net output #0: loss = 1.9569 (* 1 = 1.9569 loss)
I1028 18:40:41.483570 12309 sgd_solver.cpp:105] Iteration 2200, lr = 0.00802481
I1028 18:41:12.644938 12309 solver.cpp:222] Iteration 2240 (1.28367 iter/s, 31.1606s/40 iters), loss = 1.7638
I1028 18:41:12.645146 12309 solver.cpp:241]     Train net output #0: loss = 1.7638 (* 1 = 1.7638 loss)
I1028 18:41:12.645164 12309 sgd_solver.cpp:105] Iteration 2240, lr = 0.00799276
I1028 18:41:44.043499 12309 solver.cpp:222] Iteration 2280 (1.27398 iter/s, 31.3976s/40 iters), loss = 1.47028
I1028 18:41:44.043718 12309 solver.cpp:241]     Train net output #0: loss = 1.47028 (* 1 = 1.47028 loss)
I1028 18:41:44.043735 12309 sgd_solver.cpp:105] Iteration 2280, lr = 0.00796085
I1028 18:42:15.662070 12309 solver.cpp:222] Iteration 2320 (1.26512 iter/s, 31.6176s/40 iters), loss = 1.72465
I1028 18:42:15.662292 12309 solver.cpp:241]     Train net output #0: loss = 1.72465 (* 1 = 1.72465 loss)
I1028 18:42:15.662307 12309 sgd_solver.cpp:105] Iteration 2320, lr = 0.00792906
I1028 18:42:47.010879 12309 solver.cpp:222] Iteration 2360 (1.27601 iter/s, 31.3478s/40 iters), loss = 1.63681
I1028 18:42:47.011082 12309 solver.cpp:241]     Train net output #0: loss = 1.63681 (* 1 = 1.63681 loss)
I1028 18:42:47.011099 12309 sgd_solver.cpp:105] Iteration 2360, lr = 0.0078974
I1028 18:43:18.378226 12309 solver.cpp:222] Iteration 2400 (1.27525 iter/s, 31.3664s/40 iters), loss = 1.56474
I1028 18:43:18.378417 12309 solver.cpp:241]     Train net output #0: loss = 1.56474 (* 1 = 1.56474 loss)
I1028 18:43:18.378435 12309 sgd_solver.cpp:105] Iteration 2400, lr = 0.00786587
I1028 18:43:49.436499 12309 solver.cpp:222] Iteration 2440 (1.28794 iter/s, 31.0573s/40 iters), loss = 2.11034
I1028 18:43:49.436687 12309 solver.cpp:241]     Train net output #0: loss = 2.11034 (* 1 = 2.11034 loss)
I1028 18:43:49.436704 12309 sgd_solver.cpp:105] Iteration 2440, lr = 0.00783446
I1028 18:44:20.604327 12309 solver.cpp:222] Iteration 2480 (1.28342 iter/s, 31.1668s/40 iters), loss = 1.85761
I1028 18:44:20.604509 12309 solver.cpp:241]     Train net output #0: loss = 1.85761 (* 1 = 1.85761 loss)
I1028 18:44:20.604526 12309 sgd_solver.cpp:105] Iteration 2480, lr = 0.00780318
I1028 18:44:34.792132 12360 data_layer.cpp:73] Restarting data prefetching from start.
I1028 18:44:35.418782 12309 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_2500.caffemodel
I1028 18:44:35.544528 12309 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_2500.solverstate
I1028 18:44:35.659427 12309 solver.cpp:334] Iteration 2500, Testing net (#0)
I1028 18:45:06.802327 12361 data_layer.cpp:73] Restarting data prefetching from start.
I1028 18:45:07.016764 12309 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5404
I1028 18:45:07.016816 12309 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78308
I1028 18:45:07.016829 12309 solver.cpp:401]     Test net output #2: loss = 2.02934 (* 1 = 2.02934 loss)
I1028 18:45:23.127210 12309 solver.cpp:222] Iteration 2520 (0.639783 iter/s, 62.5212s/40 iters), loss = 1.93934
I1028 18:45:23.127285 12309 solver.cpp:241]     Train net output #0: loss = 1.93934 (* 1 = 1.93934 loss)
I1028 18:45:23.127300 12309 sgd_solver.cpp:105] Iteration 2520, lr = 0.00777202
I1028 18:45:53.816319 12309 solver.cpp:222] Iteration 2560 (1.30343 iter/s, 30.6882s/40 iters), loss = 1.49905
I1028 18:45:53.816509 12309 solver.cpp:241]     Train net output #0: loss = 1.49905 (* 1 = 1.49905 loss)
I1028 18:45:53.816526 12309 sgd_solver.cpp:105] Iteration 2560, lr = 0.00774099
I1028 18:46:24.419104 12309 solver.cpp:222] Iteration 2600 (1.30711 iter/s, 30.6018s/40 iters), loss = 1.816
I1028 18:46:24.419301 12309 solver.cpp:241]     Train net output #0: loss = 1.816 (* 1 = 1.816 loss)
I1028 18:46:24.419317 12309 sgd_solver.cpp:105] Iteration 2600, lr = 0.00771008
I1028 18:46:54.969384 12309 solver.cpp:222] Iteration 2640 (1.30936 iter/s, 30.5493s/40 iters), loss = 1.91966
I1028 18:46:54.969557 12309 solver.cpp:241]     Train net output #0: loss = 1.91966 (* 1 = 1.91966 loss)
I1028 18:46:54.969573 12309 sgd_solver.cpp:105] Iteration 2640, lr = 0.0076793
I1028 18:47:25.474107 12309 solver.cpp:222] Iteration 2680 (1.31131 iter/s, 30.5038s/40 iters), loss = 1.48837
I1028 18:47:25.474310 12309 solver.cpp:241]     Train net output #0: loss = 1.48837 (* 1 = 1.48837 loss)
I1028 18:47:25.474328 12309 sgd_solver.cpp:105] Iteration 2680, lr = 0.00764863
I1028 18:47:55.468641 12309 solver.cpp:222] Iteration 2720 (1.33362 iter/s, 29.9936s/40 iters), loss = 1.55576
I1028 18:47:55.468698 12309 solver.cpp:241]     Train net output #0: loss = 1.55576 (* 1 = 1.55576 loss)
I1028 18:47:55.468711 12309 sgd_solver.cpp:105] Iteration 2720, lr = 0.00761809
I1028 18:48:25.231472 12309 solver.cpp:222] Iteration 2760 (1.34399 iter/s, 29.7621s/40 iters), loss = 1.88731
I1028 18:48:25.231734 12309 solver.cpp:241]     Train net output #0: loss = 1.88731 (* 1 = 1.88731 loss)
I1028 18:48:25.231750 12309 sgd_solver.cpp:105] Iteration 2760, lr = 0.00758768
I1028 18:48:55.640360 12309 solver.cpp:222] Iteration 2800 (1.31545 iter/s, 30.4079s/40 iters), loss = 1.61905
I1028 18:48:55.640581 12309 solver.cpp:241]     Train net output #0: loss = 1.61905 (* 1 = 1.61905 loss)
I1028 18:48:55.640597 12309 sgd_solver.cpp:105] Iteration 2800, lr = 0.00755738
I1028 18:49:26.002061 12309 solver.cpp:222] Iteration 2840 (1.31749 iter/s, 30.3608s/40 iters), loss = 1.59074
I1028 18:49:26.002266 12309 solver.cpp:241]     Train net output #0: loss = 1.59074 (* 1 = 1.59074 loss)
I1028 18:49:26.002281 12309 sgd_solver.cpp:105] Iteration 2840, lr = 0.0075272
I1028 18:49:56.048661 12309 solver.cpp:222] Iteration 2880 (1.33131 iter/s, 30.0456s/40 iters), loss = 1.61536
I1028 18:49:56.048841 12309 solver.cpp:241]     Train net output #0: loss = 1.61536 (* 1 = 1.61536 loss)
I1028 18:49:56.048856 12309 sgd_solver.cpp:105] Iteration 2880, lr = 0.00749715
I1028 18:50:26.136674 12309 solver.cpp:222] Iteration 2920 (1.32947 iter/s, 30.0871s/40 iters), loss = 1.72736
I1028 18:50:26.136883 12309 solver.cpp:241]     Train net output #0: loss = 1.72736 (* 1 = 1.72736 loss)
I1028 18:50:26.136898 12309 sgd_solver.cpp:105] Iteration 2920, lr = 0.00746721
I1028 18:50:55.899646 12309 solver.cpp:222] Iteration 2960 (1.34399 iter/s, 29.7621s/40 iters), loss = 1.78404
I1028 18:50:55.899708 12309 solver.cpp:241]     Train net output #0: loss = 1.78404 (* 1 = 1.78404 loss)
I1028 18:50:55.899721 12309 sgd_solver.cpp:105] Iteration 2960, lr = 0.0074374
I1028 18:51:25.155697 12309 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_3000.caffemodel
I1028 18:51:25.307127 12309 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_3000.solverstate
I1028 18:51:25.413152 12309 solver.cpp:334] Iteration 3000, Testing net (#0)
I1028 18:51:56.711644 12309 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53532
I1028 18:51:56.711813 12309 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77692
I1028 18:51:56.711828 12309 solver.cpp:401]     Test net output #2: loss = 2.11136 (* 1 = 2.11136 loss)
I1028 18:51:57.476042 12309 solver.cpp:222] Iteration 3000 (0.649616 iter/s, 61.5748s/40 iters), loss = 2.17788
I1028 18:51:57.476100 12309 solver.cpp:241]     Train net output #0: loss = 2.17788 (* 1 = 2.17788 loss)
I1028 18:51:57.476114 12309 sgd_solver.cpp:105] Iteration 3000, lr = 0.0074077
I1028 18:52:28.321807 12309 solver.cpp:222] Iteration 3040 (1.29681 iter/s, 30.845s/40 iters), loss = 1.58952
I1028 18:52:28.322000 12309 solver.cpp:241]     Train net output #0: loss = 1.58952 (* 1 = 1.58952 loss)
I1028 18:52:28.322016 12309 sgd_solver.cpp:105] Iteration 3040, lr = 0.00737812
I1028 18:52:58.241307 12309 solver.cpp:222] Iteration 3080 (1.33696 iter/s, 29.9185s/40 iters), loss = 1.57581
I1028 18:52:58.241365 12309 solver.cpp:241]     Train net output #0: loss = 1.57581 (* 1 = 1.57581 loss)
I1028 18:52:58.241379 12309 sgd_solver.cpp:105] Iteration 3080, lr = 0.00734866
I1028 18:53:21.399863 12309 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_3112.caffemodel
I1028 18:53:21.553198 12309 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_3112.solverstate
I1028 18:53:21.685508 12309 solver.cpp:298] Optimization stopped early.
*** Aborted at 1509231319 (unix time) try "date -d @1509231319" if you are using GNU date ***
PC: @     0x7f5f40f90705 __pthread_cond_wait
*** SIGTERM (@0x3ed00003107) received by PID 12309 (TID 0x7f5f54005740) from PID 12551; stack trace: ***
    @     0x7f5f40f94130 (unknown)
    @     0x7f5f40f90705 __pthread_cond_wait
    @     0x7f5f532ea804 boost::condition_variable::wait()
    @     0x7f5f4985a8d4 boost::thread::join_noexcept()
    @     0x7f5f532d5b8a caffe::InternalThread::StopInternalThread()
    @     0x7f5f532ee302 caffe::NCCL<>::Run()
    @           0x40adef train()
    @           0x4082ec main
    @     0x7f5f40be5af5 __libc_start_main
    @           0x408bf5 (unknown)
nohup: ignoring input
I1028 19:00:28.030648 12690 caffe.cpp:218] Using GPUs 0, 1, 2, 3
I1028 19:00:28.031518 12690 caffe.cpp:223] GPU 0: Tesla P40
I1028 19:00:28.031915 12690 caffe.cpp:223] GPU 1: Tesla P40
I1028 19:00:28.032304 12690 caffe.cpp:223] GPU 2: Tesla P40
I1028 19:00:28.032685 12690 caffe.cpp:223] GPU 3: Tesla P40
I1028 19:00:28.839892 12690 solver.cpp:44] Initializing solver from parameters: 
test_iter: 500
test_interval: 500
base_lr: 0.01
display: 40
max_iter: 100000
lr_policy: "exp"
gamma: 0.9999
momentum: 0.9
weight_decay: 0.0002
snapshot: 500
snapshot_prefix: "SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp"
solver_mode: GPU
device_id: 0
random_seed: 42
net: "SqueezeNet/SqueezeNet_v1.1/train_val_inq_40.prototxt"
train_state {
  level: 0
  stage: ""
}
I1028 19:00:28.841514 12690 solver.cpp:87] Creating training net from net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_40.prototxt
I1028 19:00:28.844854 12690 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1028 19:00:28.844970 12690 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top1
I1028 19:00:28.844980 12690 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top5
I1028 19:00:28.846053 12690 net.cpp:51] Initializing net from parameters: 
name: "SqueezeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/data/caffe-imagenet/ilsvrc12_train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "INQConvolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "fire3/concat"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire4/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool3"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "fire5/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire4/concat"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "fire5/concat"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire6/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool5"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "fire9/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire8/concat"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "INQConvolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "pool10"
  bottom: "label"
  top: "loss"
}
I1028 19:00:28.846668 12690 layer_factory.hpp:77] Creating layer data
I1028 19:00:28.847453 12690 db_lmdb.cpp:35] Opened lmdb /home/data/caffe-imagenet/ilsvrc12_train_lmdb
I1028 19:00:28.847532 12690 net.cpp:84] Creating Layer data
I1028 19:00:28.847551 12690 net.cpp:387] data -> data
I1028 19:00:28.847591 12690 net.cpp:387] data -> label
I1028 19:00:28.850411 12690 data_layer.cpp:45] output data size: 128,3,227,227
I1028 19:00:29.077793 12690 net.cpp:127] Setting up data
I1028 19:00:29.077838 12690 net.cpp:136] Top shape: 128 3 227 227 (19787136)
I1028 19:00:29.077846 12690 net.cpp:136] Top shape: 128 (128)
I1028 19:00:29.077849 12690 net.cpp:144] Memory required for data: 79149056
I1028 19:00:29.077862 12690 layer_factory.hpp:77] Creating layer conv1
I1028 19:00:29.077888 12690 net.cpp:84] Creating Layer conv1
I1028 19:00:29.077896 12690 net.cpp:413] conv1 <- data
I1028 19:00:29.077915 12690 net.cpp:387] conv1 -> conv1
I1028 19:00:29.081184 12690 net.cpp:127] Setting up conv1
I1028 19:00:29.081202 12690 net.cpp:136] Top shape: 128 64 113 113 (104603648)
I1028 19:00:29.081207 12690 net.cpp:144] Memory required for data: 497563648
I1028 19:00:29.081226 12690 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1028 19:00:29.081238 12690 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1028 19:00:29.081246 12690 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1028 19:00:29.081252 12690 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1028 19:00:29.081257 12690 layer_factory.hpp:77] Creating layer relu_conv1
I1028 19:00:29.081270 12690 net.cpp:84] Creating Layer relu_conv1
I1028 19:00:29.081275 12690 net.cpp:413] relu_conv1 <- conv1
I1028 19:00:29.081281 12690 net.cpp:374] relu_conv1 -> conv1 (in-place)
I1028 19:00:29.591327 12690 net.cpp:127] Setting up relu_conv1
I1028 19:00:29.591372 12690 net.cpp:136] Top shape: 128 64 113 113 (104603648)
I1028 19:00:29.591377 12690 net.cpp:144] Memory required for data: 915978240
I1028 19:00:29.591387 12690 layer_factory.hpp:77] Creating layer pool1
I1028 19:00:29.591410 12690 net.cpp:84] Creating Layer pool1
I1028 19:00:29.591416 12690 net.cpp:413] pool1 <- conv1
I1028 19:00:29.591428 12690 net.cpp:387] pool1 -> pool1
I1028 19:00:29.591506 12690 net.cpp:127] Setting up pool1
I1028 19:00:29.591516 12690 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 19:00:29.591552 12690 net.cpp:144] Memory required for data: 1018738688
I1028 19:00:29.591557 12690 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I1028 19:00:29.591572 12690 net.cpp:84] Creating Layer fire2/squeeze1x1
I1028 19:00:29.591578 12690 net.cpp:413] fire2/squeeze1x1 <- pool1
I1028 19:00:29.591584 12690 net.cpp:387] fire2/squeeze1x1 -> fire2/squeeze1x1
I1028 19:00:29.593395 12690 net.cpp:127] Setting up fire2/squeeze1x1
I1028 19:00:29.593412 12690 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 19:00:29.593417 12690 net.cpp:144] Memory required for data: 1044428800
I1028 19:00:29.593428 12690 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1028 19:00:29.593437 12690 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1028 19:00:29.593442 12690 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1028 19:00:29.593447 12690 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1028 19:00:29.593451 12690 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I1028 19:00:29.593461 12690 net.cpp:84] Creating Layer fire2/relu_squeeze1x1
I1028 19:00:29.593464 12690 net.cpp:413] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I1028 19:00:29.593471 12690 net.cpp:374] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I1028 19:00:29.594861 12690 net.cpp:127] Setting up fire2/relu_squeeze1x1
I1028 19:00:29.594877 12690 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 19:00:29.594882 12690 net.cpp:144] Memory required for data: 1070118912
I1028 19:00:29.594887 12690 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1028 19:00:29.594898 12690 net.cpp:84] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1028 19:00:29.594902 12690 net.cpp:413] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I1028 19:00:29.594909 12690 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1028 19:00:29.594924 12690 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1028 19:00:29.594974 12690 net.cpp:127] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1028 19:00:29.594992 12690 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 19:00:29.594997 12690 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 19:00:29.595000 12690 net.cpp:144] Memory required for data: 1121499136
I1028 19:00:29.595005 12690 layer_factory.hpp:77] Creating layer fire2/expand1x1
I1028 19:00:29.595015 12690 net.cpp:84] Creating Layer fire2/expand1x1
I1028 19:00:29.595018 12690 net.cpp:413] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1028 19:00:29.595024 12690 net.cpp:387] fire2/expand1x1 -> fire2/expand1x1
I1028 19:00:29.595346 12690 net.cpp:127] Setting up fire2/expand1x1
I1028 19:00:29.595355 12690 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 19:00:29.595360 12690 net.cpp:144] Memory required for data: 1224259584
I1028 19:00:29.595368 12690 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1028 19:00:29.595377 12690 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1028 19:00:29.595382 12690 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1028 19:00:29.595387 12690 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1028 19:00:29.595392 12690 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I1028 19:00:29.595401 12690 net.cpp:84] Creating Layer fire2/relu_expand1x1
I1028 19:00:29.595405 12690 net.cpp:413] fire2/relu_expand1x1 <- fire2/expand1x1
I1028 19:00:29.595415 12690 net.cpp:374] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I1028 19:00:29.595613 12690 net.cpp:127] Setting up fire2/relu_expand1x1
I1028 19:00:29.595621 12690 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 19:00:29.595626 12690 net.cpp:144] Memory required for data: 1327020032
I1028 19:00:29.595649 12690 layer_factory.hpp:77] Creating layer fire2/expand3x3
I1028 19:00:29.595659 12690 net.cpp:84] Creating Layer fire2/expand3x3
I1028 19:00:29.595662 12690 net.cpp:413] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1028 19:00:29.595669 12690 net.cpp:387] fire2/expand3x3 -> fire2/expand3x3
I1028 19:00:29.596086 12690 net.cpp:127] Setting up fire2/expand3x3
I1028 19:00:29.596096 12690 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 19:00:29.596099 12690 net.cpp:144] Memory required for data: 1429780480
I1028 19:00:29.596107 12690 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1028 19:00:29.596112 12690 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1028 19:00:29.596117 12690 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1028 19:00:29.596122 12690 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1028 19:00:29.596127 12690 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I1028 19:00:29.596132 12690 net.cpp:84] Creating Layer fire2/relu_expand3x3
I1028 19:00:29.596138 12690 net.cpp:413] fire2/relu_expand3x3 <- fire2/expand3x3
I1028 19:00:29.596143 12690 net.cpp:374] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I1028 19:00:29.596338 12690 net.cpp:127] Setting up fire2/relu_expand3x3
I1028 19:00:29.596346 12690 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 19:00:29.596350 12690 net.cpp:144] Memory required for data: 1532540928
I1028 19:00:29.596354 12690 layer_factory.hpp:77] Creating layer fire2/concat
I1028 19:00:29.596364 12690 net.cpp:84] Creating Layer fire2/concat
I1028 19:00:29.596369 12690 net.cpp:413] fire2/concat <- fire2/expand1x1
I1028 19:00:29.596374 12690 net.cpp:413] fire2/concat <- fire2/expand3x3
I1028 19:00:29.596379 12690 net.cpp:387] fire2/concat -> fire2/concat
I1028 19:00:29.596411 12690 net.cpp:127] Setting up fire2/concat
I1028 19:00:29.596418 12690 net.cpp:136] Top shape: 128 128 56 56 (51380224)
I1028 19:00:29.596421 12690 net.cpp:144] Memory required for data: 1738061824
I1028 19:00:29.596426 12690 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I1028 19:00:29.596434 12690 net.cpp:84] Creating Layer fire3/squeeze1x1
I1028 19:00:29.596438 12690 net.cpp:413] fire3/squeeze1x1 <- fire2/concat
I1028 19:00:29.596444 12690 net.cpp:387] fire3/squeeze1x1 -> fire3/squeeze1x1
I1028 19:00:29.596762 12690 net.cpp:127] Setting up fire3/squeeze1x1
I1028 19:00:29.596771 12690 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 19:00:29.596776 12690 net.cpp:144] Memory required for data: 1763751936
I1028 19:00:29.596783 12690 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1028 19:00:29.596791 12690 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1028 19:00:29.596796 12690 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1028 19:00:29.596801 12690 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1028 19:00:29.596806 12690 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I1028 19:00:29.596812 12690 net.cpp:84] Creating Layer fire3/relu_squeeze1x1
I1028 19:00:29.596817 12690 net.cpp:413] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I1028 19:00:29.596822 12690 net.cpp:374] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I1028 19:00:29.598215 12690 net.cpp:127] Setting up fire3/relu_squeeze1x1
I1028 19:00:29.598230 12690 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 19:00:29.598235 12690 net.cpp:144] Memory required for data: 1789442048
I1028 19:00:29.598240 12690 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1028 19:00:29.598251 12690 net.cpp:84] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1028 19:00:29.598255 12690 net.cpp:413] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I1028 19:00:29.598263 12690 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1028 19:00:29.598284 12690 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1028 19:00:29.598330 12690 net.cpp:127] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1028 19:00:29.598336 12690 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 19:00:29.598341 12690 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 19:00:29.598345 12690 net.cpp:144] Memory required for data: 1840822272
I1028 19:00:29.598348 12690 layer_factory.hpp:77] Creating layer fire3/expand1x1
I1028 19:00:29.598357 12690 net.cpp:84] Creating Layer fire3/expand1x1
I1028 19:00:29.598361 12690 net.cpp:413] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1028 19:00:29.598368 12690 net.cpp:387] fire3/expand1x1 -> fire3/expand1x1
I1028 19:00:29.598680 12690 net.cpp:127] Setting up fire3/expand1x1
I1028 19:00:29.598687 12690 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 19:00:29.598691 12690 net.cpp:144] Memory required for data: 1943582720
I1028 19:00:29.598698 12690 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1028 19:00:29.598704 12690 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1028 19:00:29.598709 12690 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1028 19:00:29.598714 12690 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1028 19:00:29.598717 12690 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I1028 19:00:29.598726 12690 net.cpp:84] Creating Layer fire3/relu_expand1x1
I1028 19:00:29.598731 12690 net.cpp:413] fire3/relu_expand1x1 <- fire3/expand1x1
I1028 19:00:29.598737 12690 net.cpp:374] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I1028 19:00:29.598937 12690 net.cpp:127] Setting up fire3/relu_expand1x1
I1028 19:00:29.598945 12690 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 19:00:29.598949 12690 net.cpp:144] Memory required for data: 2046343168
I1028 19:00:29.598953 12690 layer_factory.hpp:77] Creating layer fire3/expand3x3
I1028 19:00:29.598963 12690 net.cpp:84] Creating Layer fire3/expand3x3
I1028 19:00:29.598968 12690 net.cpp:413] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1028 19:00:29.598974 12690 net.cpp:387] fire3/expand3x3 -> fire3/expand3x3
I1028 19:00:29.599364 12690 net.cpp:127] Setting up fire3/expand3x3
I1028 19:00:29.599373 12690 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 19:00:29.599377 12690 net.cpp:144] Memory required for data: 2149103616
I1028 19:00:29.599383 12690 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1028 19:00:29.599390 12690 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1028 19:00:29.599395 12690 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1028 19:00:29.599400 12690 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1028 19:00:29.599403 12690 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I1028 19:00:29.599409 12690 net.cpp:84] Creating Layer fire3/relu_expand3x3
I1028 19:00:29.599414 12690 net.cpp:413] fire3/relu_expand3x3 <- fire3/expand3x3
I1028 19:00:29.599419 12690 net.cpp:374] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I1028 19:00:29.599611 12690 net.cpp:127] Setting up fire3/relu_expand3x3
I1028 19:00:29.599620 12690 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 19:00:29.599624 12690 net.cpp:144] Memory required for data: 2251864064
I1028 19:00:29.599628 12690 layer_factory.hpp:77] Creating layer fire3/concat
I1028 19:00:29.599635 12690 net.cpp:84] Creating Layer fire3/concat
I1028 19:00:29.599644 12690 net.cpp:413] fire3/concat <- fire3/expand1x1
I1028 19:00:29.599649 12690 net.cpp:413] fire3/concat <- fire3/expand3x3
I1028 19:00:29.599655 12690 net.cpp:387] fire3/concat -> fire3/concat
I1028 19:00:29.599684 12690 net.cpp:127] Setting up fire3/concat
I1028 19:00:29.599689 12690 net.cpp:136] Top shape: 128 128 56 56 (51380224)
I1028 19:00:29.599704 12690 net.cpp:144] Memory required for data: 2457384960
I1028 19:00:29.599709 12690 layer_factory.hpp:77] Creating layer pool3
I1028 19:00:29.599716 12690 net.cpp:84] Creating Layer pool3
I1028 19:00:29.599720 12690 net.cpp:413] pool3 <- fire3/concat
I1028 19:00:29.599726 12690 net.cpp:387] pool3 -> pool3
I1028 19:00:29.599768 12690 net.cpp:127] Setting up pool3
I1028 19:00:29.599774 12690 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 19:00:29.599778 12690 net.cpp:144] Memory required for data: 2508765184
I1028 19:00:29.599782 12690 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I1028 19:00:29.599792 12690 net.cpp:84] Creating Layer fire4/squeeze1x1
I1028 19:00:29.599795 12690 net.cpp:413] fire4/squeeze1x1 <- pool3
I1028 19:00:29.599802 12690 net.cpp:387] fire4/squeeze1x1 -> fire4/squeeze1x1
I1028 19:00:29.600147 12690 net.cpp:127] Setting up fire4/squeeze1x1
I1028 19:00:29.600155 12690 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 19:00:29.600159 12690 net.cpp:144] Memory required for data: 2521610240
I1028 19:00:29.600167 12690 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1028 19:00:29.600172 12690 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1028 19:00:29.600178 12690 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1028 19:00:29.600181 12690 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1028 19:00:29.600185 12690 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I1028 19:00:29.600193 12690 net.cpp:84] Creating Layer fire4/relu_squeeze1x1
I1028 19:00:29.600196 12690 net.cpp:413] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I1028 19:00:29.600203 12690 net.cpp:374] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I1028 19:00:29.600399 12690 net.cpp:127] Setting up fire4/relu_squeeze1x1
I1028 19:00:29.600406 12690 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 19:00:29.600410 12690 net.cpp:144] Memory required for data: 2534455296
I1028 19:00:29.600415 12690 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1028 19:00:29.600421 12690 net.cpp:84] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1028 19:00:29.600425 12690 net.cpp:413] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I1028 19:00:29.600431 12690 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1028 19:00:29.600438 12690 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1028 19:00:29.600481 12690 net.cpp:127] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1028 19:00:29.600486 12690 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 19:00:29.600492 12690 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 19:00:29.600495 12690 net.cpp:144] Memory required for data: 2560145408
I1028 19:00:29.600499 12690 layer_factory.hpp:77] Creating layer fire4/expand1x1
I1028 19:00:29.600507 12690 net.cpp:84] Creating Layer fire4/expand1x1
I1028 19:00:29.600512 12690 net.cpp:413] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1028 19:00:29.600518 12690 net.cpp:387] fire4/expand1x1 -> fire4/expand1x1
I1028 19:00:29.600850 12690 net.cpp:127] Setting up fire4/expand1x1
I1028 19:00:29.600859 12690 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 19:00:29.600863 12690 net.cpp:144] Memory required for data: 2611525632
I1028 19:00:29.600872 12690 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1028 19:00:29.600880 12690 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1028 19:00:29.600890 12690 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1028 19:00:29.600895 12690 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1028 19:00:29.600899 12690 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I1028 19:00:29.600916 12690 net.cpp:84] Creating Layer fire4/relu_expand1x1
I1028 19:00:29.600929 12690 net.cpp:413] fire4/relu_expand1x1 <- fire4/expand1x1
I1028 19:00:29.600934 12690 net.cpp:374] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I1028 19:00:29.602291 12690 net.cpp:127] Setting up fire4/relu_expand1x1
I1028 19:00:29.602305 12690 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 19:00:29.602309 12690 net.cpp:144] Memory required for data: 2662905856
I1028 19:00:29.602314 12690 layer_factory.hpp:77] Creating layer fire4/expand3x3
I1028 19:00:29.602324 12690 net.cpp:84] Creating Layer fire4/expand3x3
I1028 19:00:29.602329 12690 net.cpp:413] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1028 19:00:29.602337 12690 net.cpp:387] fire4/expand3x3 -> fire4/expand3x3
I1028 19:00:29.604235 12690 net.cpp:127] Setting up fire4/expand3x3
I1028 19:00:29.604250 12690 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 19:00:29.604255 12690 net.cpp:144] Memory required for data: 2714286080
I1028 19:00:29.604261 12690 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1028 19:00:29.604267 12690 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1028 19:00:29.604272 12690 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1028 19:00:29.604277 12690 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1028 19:00:29.604280 12690 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I1028 19:00:29.604288 12690 net.cpp:84] Creating Layer fire4/relu_expand3x3
I1028 19:00:29.604292 12690 net.cpp:413] fire4/relu_expand3x3 <- fire4/expand3x3
I1028 19:00:29.604298 12690 net.cpp:374] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I1028 19:00:29.604498 12690 net.cpp:127] Setting up fire4/relu_expand3x3
I1028 19:00:29.604508 12690 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 19:00:29.604512 12690 net.cpp:144] Memory required for data: 2765666304
I1028 19:00:29.604516 12690 layer_factory.hpp:77] Creating layer fire4/concat
I1028 19:00:29.604523 12690 net.cpp:84] Creating Layer fire4/concat
I1028 19:00:29.604527 12690 net.cpp:413] fire4/concat <- fire4/expand1x1
I1028 19:00:29.604532 12690 net.cpp:413] fire4/concat <- fire4/expand3x3
I1028 19:00:29.604537 12690 net.cpp:387] fire4/concat -> fire4/concat
I1028 19:00:29.604566 12690 net.cpp:127] Setting up fire4/concat
I1028 19:00:29.604573 12690 net.cpp:136] Top shape: 128 256 28 28 (25690112)
I1028 19:00:29.604576 12690 net.cpp:144] Memory required for data: 2868426752
I1028 19:00:29.604580 12690 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I1028 19:00:29.604589 12690 net.cpp:84] Creating Layer fire5/squeeze1x1
I1028 19:00:29.604593 12690 net.cpp:413] fire5/squeeze1x1 <- fire4/concat
I1028 19:00:29.604604 12690 net.cpp:387] fire5/squeeze1x1 -> fire5/squeeze1x1
I1028 19:00:29.604992 12690 net.cpp:127] Setting up fire5/squeeze1x1
I1028 19:00:29.605001 12690 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 19:00:29.605005 12690 net.cpp:144] Memory required for data: 2881271808
I1028 19:00:29.605011 12690 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1028 19:00:29.605017 12690 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1028 19:00:29.605021 12690 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1028 19:00:29.605026 12690 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1028 19:00:29.605031 12690 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I1028 19:00:29.605038 12690 net.cpp:84] Creating Layer fire5/relu_squeeze1x1
I1028 19:00:29.605042 12690 net.cpp:413] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I1028 19:00:29.605051 12690 net.cpp:374] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I1028 19:00:29.605265 12690 net.cpp:127] Setting up fire5/relu_squeeze1x1
I1028 19:00:29.605274 12690 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 19:00:29.605290 12690 net.cpp:144] Memory required for data: 2894116864
I1028 19:00:29.605295 12690 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1028 19:00:29.605304 12690 net.cpp:84] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1028 19:00:29.605307 12690 net.cpp:413] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I1028 19:00:29.605315 12690 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1028 19:00:29.605322 12690 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1028 19:00:29.605367 12690 net.cpp:127] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1028 19:00:29.605374 12690 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 19:00:29.605378 12690 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 19:00:29.605382 12690 net.cpp:144] Memory required for data: 2919806976
I1028 19:00:29.605386 12690 layer_factory.hpp:77] Creating layer fire5/expand1x1
I1028 19:00:29.605401 12690 net.cpp:84] Creating Layer fire5/expand1x1
I1028 19:00:29.605404 12690 net.cpp:413] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1028 19:00:29.605413 12690 net.cpp:387] fire5/expand1x1 -> fire5/expand1x1
I1028 19:00:29.605756 12690 net.cpp:127] Setting up fire5/expand1x1
I1028 19:00:29.605763 12690 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 19:00:29.605767 12690 net.cpp:144] Memory required for data: 2971187200
I1028 19:00:29.605773 12690 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1028 19:00:29.605779 12690 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1028 19:00:29.605783 12690 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1028 19:00:29.605788 12690 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1028 19:00:29.605792 12690 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I1028 19:00:29.605798 12690 net.cpp:84] Creating Layer fire5/relu_expand1x1
I1028 19:00:29.605803 12690 net.cpp:413] fire5/relu_expand1x1 <- fire5/expand1x1
I1028 19:00:29.605810 12690 net.cpp:374] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I1028 19:00:29.606017 12690 net.cpp:127] Setting up fire5/relu_expand1x1
I1028 19:00:29.606026 12690 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 19:00:29.606030 12690 net.cpp:144] Memory required for data: 3022567424
I1028 19:00:29.606034 12690 layer_factory.hpp:77] Creating layer fire5/expand3x3
I1028 19:00:29.606045 12690 net.cpp:84] Creating Layer fire5/expand3x3
I1028 19:00:29.606050 12690 net.cpp:413] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1028 19:00:29.606060 12690 net.cpp:387] fire5/expand3x3 -> fire5/expand3x3
I1028 19:00:29.606665 12690 net.cpp:127] Setting up fire5/expand3x3
I1028 19:00:29.606673 12690 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 19:00:29.606678 12690 net.cpp:144] Memory required for data: 3073947648
I1028 19:00:29.606683 12690 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1028 19:00:29.606688 12690 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1028 19:00:29.606693 12690 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1028 19:00:29.606698 12690 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1028 19:00:29.606700 12690 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I1028 19:00:29.606706 12690 net.cpp:84] Creating Layer fire5/relu_expand3x3
I1028 19:00:29.606710 12690 net.cpp:413] fire5/relu_expand3x3 <- fire5/expand3x3
I1028 19:00:29.606721 12690 net.cpp:374] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I1028 19:00:29.608079 12690 net.cpp:127] Setting up fire5/relu_expand3x3
I1028 19:00:29.608093 12690 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 19:00:29.608098 12690 net.cpp:144] Memory required for data: 3125327872
I1028 19:00:29.608114 12690 layer_factory.hpp:77] Creating layer fire5/concat
I1028 19:00:29.608124 12690 net.cpp:84] Creating Layer fire5/concat
I1028 19:00:29.608129 12690 net.cpp:413] fire5/concat <- fire5/expand1x1
I1028 19:00:29.608134 12690 net.cpp:413] fire5/concat <- fire5/expand3x3
I1028 19:00:29.608140 12690 net.cpp:387] fire5/concat -> fire5/concat
I1028 19:00:29.608175 12690 net.cpp:127] Setting up fire5/concat
I1028 19:00:29.608181 12690 net.cpp:136] Top shape: 128 256 28 28 (25690112)
I1028 19:00:29.608186 12690 net.cpp:144] Memory required for data: 3228088320
I1028 19:00:29.608189 12690 layer_factory.hpp:77] Creating layer pool5
I1028 19:00:29.608196 12690 net.cpp:84] Creating Layer pool5
I1028 19:00:29.608199 12690 net.cpp:413] pool5 <- fire5/concat
I1028 19:00:29.608207 12690 net.cpp:387] pool5 -> pool5
I1028 19:00:29.608248 12690 net.cpp:127] Setting up pool5
I1028 19:00:29.608254 12690 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 19:00:29.608258 12690 net.cpp:144] Memory required for data: 3253778432
I1028 19:00:29.608261 12690 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I1028 19:00:29.608271 12690 net.cpp:84] Creating Layer fire6/squeeze1x1
I1028 19:00:29.608276 12690 net.cpp:413] fire6/squeeze1x1 <- pool5
I1028 19:00:29.608283 12690 net.cpp:387] fire6/squeeze1x1 -> fire6/squeeze1x1
I1028 19:00:29.608711 12690 net.cpp:127] Setting up fire6/squeeze1x1
I1028 19:00:29.608719 12690 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 19:00:29.608722 12690 net.cpp:144] Memory required for data: 3258595328
I1028 19:00:29.608728 12690 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1028 19:00:29.608734 12690 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1028 19:00:29.608739 12690 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1028 19:00:29.608744 12690 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1028 19:00:29.608748 12690 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I1028 19:00:29.608757 12690 net.cpp:84] Creating Layer fire6/relu_squeeze1x1
I1028 19:00:29.608762 12690 net.cpp:413] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I1028 19:00:29.608767 12690 net.cpp:374] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I1028 19:00:29.608983 12690 net.cpp:127] Setting up fire6/relu_squeeze1x1
I1028 19:00:29.608992 12690 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 19:00:29.608996 12690 net.cpp:144] Memory required for data: 3263412224
I1028 19:00:29.609000 12690 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1028 19:00:29.609009 12690 net.cpp:84] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1028 19:00:29.609014 12690 net.cpp:413] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I1028 19:00:29.609019 12690 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1028 19:00:29.609026 12690 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1028 19:00:29.609077 12690 net.cpp:127] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1028 19:00:29.609083 12690 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 19:00:29.609089 12690 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 19:00:29.609092 12690 net.cpp:144] Memory required for data: 3273046016
I1028 19:00:29.609097 12690 layer_factory.hpp:77] Creating layer fire6/expand1x1
I1028 19:00:29.609107 12690 net.cpp:84] Creating Layer fire6/expand1x1
I1028 19:00:29.609110 12690 net.cpp:413] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1028 19:00:29.609118 12690 net.cpp:387] fire6/expand1x1 -> fire6/expand1x1
I1028 19:00:29.609508 12690 net.cpp:127] Setting up fire6/expand1x1
I1028 19:00:29.609515 12690 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 19:00:29.609519 12690 net.cpp:144] Memory required for data: 3292313600
I1028 19:00:29.609525 12690 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1028 19:00:29.609541 12690 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1028 19:00:29.609546 12690 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1028 19:00:29.609551 12690 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1028 19:00:29.609555 12690 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I1028 19:00:29.609560 12690 net.cpp:84] Creating Layer fire6/relu_expand1x1
I1028 19:00:29.609565 12690 net.cpp:413] fire6/relu_expand1x1 <- fire6/expand1x1
I1028 19:00:29.609573 12690 net.cpp:374] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I1028 19:00:29.609778 12690 net.cpp:127] Setting up fire6/relu_expand1x1
I1028 19:00:29.609787 12690 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 19:00:29.609791 12690 net.cpp:144] Memory required for data: 3311581184
I1028 19:00:29.609794 12690 layer_factory.hpp:77] Creating layer fire6/expand3x3
I1028 19:00:29.609805 12690 net.cpp:84] Creating Layer fire6/expand3x3
I1028 19:00:29.609809 12690 net.cpp:413] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1028 19:00:29.609818 12690 net.cpp:387] fire6/expand3x3 -> fire6/expand3x3
I1028 19:00:29.612155 12690 net.cpp:127] Setting up fire6/expand3x3
I1028 19:00:29.612170 12690 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 19:00:29.612174 12690 net.cpp:144] Memory required for data: 3330848768
I1028 19:00:29.612181 12690 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1028 19:00:29.612187 12690 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1028 19:00:29.612192 12690 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1028 19:00:29.612196 12690 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1028 19:00:29.612200 12690 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I1028 19:00:29.612207 12690 net.cpp:84] Creating Layer fire6/relu_expand3x3
I1028 19:00:29.612212 12690 net.cpp:413] fire6/relu_expand3x3 <- fire6/expand3x3
I1028 19:00:29.612222 12690 net.cpp:374] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I1028 19:00:29.612449 12690 net.cpp:127] Setting up fire6/relu_expand3x3
I1028 19:00:29.612458 12690 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 19:00:29.612462 12690 net.cpp:144] Memory required for data: 3350116352
I1028 19:00:29.612467 12690 layer_factory.hpp:77] Creating layer fire6/concat
I1028 19:00:29.612475 12690 net.cpp:84] Creating Layer fire6/concat
I1028 19:00:29.612479 12690 net.cpp:413] fire6/concat <- fire6/expand1x1
I1028 19:00:29.612484 12690 net.cpp:413] fire6/concat <- fire6/expand3x3
I1028 19:00:29.612490 12690 net.cpp:387] fire6/concat -> fire6/concat
I1028 19:00:29.612520 12690 net.cpp:127] Setting up fire6/concat
I1028 19:00:29.612526 12690 net.cpp:136] Top shape: 128 384 14 14 (9633792)
I1028 19:00:29.612530 12690 net.cpp:144] Memory required for data: 3388651520
I1028 19:00:29.612534 12690 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I1028 19:00:29.612545 12690 net.cpp:84] Creating Layer fire7/squeeze1x1
I1028 19:00:29.612550 12690 net.cpp:413] fire7/squeeze1x1 <- fire6/concat
I1028 19:00:29.612555 12690 net.cpp:387] fire7/squeeze1x1 -> fire7/squeeze1x1
I1028 19:00:29.613029 12690 net.cpp:127] Setting up fire7/squeeze1x1
I1028 19:00:29.613037 12690 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 19:00:29.613041 12690 net.cpp:144] Memory required for data: 3393468416
I1028 19:00:29.613056 12690 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1028 19:00:29.613065 12690 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1028 19:00:29.613073 12690 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1028 19:00:29.613078 12690 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1028 19:00:29.613082 12690 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I1028 19:00:29.613106 12690 net.cpp:84] Creating Layer fire7/relu_squeeze1x1
I1028 19:00:29.613111 12690 net.cpp:413] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I1028 19:00:29.613116 12690 net.cpp:374] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I1028 19:00:29.614481 12690 net.cpp:127] Setting up fire7/relu_squeeze1x1
I1028 19:00:29.614497 12690 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 19:00:29.614501 12690 net.cpp:144] Memory required for data: 3398285312
I1028 19:00:29.614506 12690 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1028 19:00:29.614513 12690 net.cpp:84] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1028 19:00:29.614518 12690 net.cpp:413] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I1028 19:00:29.614524 12690 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1028 19:00:29.614532 12690 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1028 19:00:29.614583 12690 net.cpp:127] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1028 19:00:29.614590 12690 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 19:00:29.614595 12690 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 19:00:29.614598 12690 net.cpp:144] Memory required for data: 3407919104
I1028 19:00:29.614603 12690 layer_factory.hpp:77] Creating layer fire7/expand1x1
I1028 19:00:29.614612 12690 net.cpp:84] Creating Layer fire7/expand1x1
I1028 19:00:29.614616 12690 net.cpp:413] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1028 19:00:29.614624 12690 net.cpp:387] fire7/expand1x1 -> fire7/expand1x1
I1028 19:00:29.615031 12690 net.cpp:127] Setting up fire7/expand1x1
I1028 19:00:29.615041 12690 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 19:00:29.615043 12690 net.cpp:144] Memory required for data: 3427186688
I1028 19:00:29.615049 12690 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1028 19:00:29.615056 12690 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1028 19:00:29.615059 12690 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1028 19:00:29.615064 12690 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1028 19:00:29.615067 12690 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I1028 19:00:29.615074 12690 net.cpp:84] Creating Layer fire7/relu_expand1x1
I1028 19:00:29.615078 12690 net.cpp:413] fire7/relu_expand1x1 <- fire7/expand1x1
I1028 19:00:29.615083 12690 net.cpp:374] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I1028 19:00:29.615289 12690 net.cpp:127] Setting up fire7/relu_expand1x1
I1028 19:00:29.615298 12690 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 19:00:29.615301 12690 net.cpp:144] Memory required for data: 3446454272
I1028 19:00:29.615305 12690 layer_factory.hpp:77] Creating layer fire7/expand3x3
I1028 19:00:29.615316 12690 net.cpp:84] Creating Layer fire7/expand3x3
I1028 19:00:29.615321 12690 net.cpp:413] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1028 19:00:29.615330 12690 net.cpp:387] fire7/expand3x3 -> fire7/expand3x3
I1028 19:00:29.616317 12690 net.cpp:127] Setting up fire7/expand3x3
I1028 19:00:29.616327 12690 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 19:00:29.616330 12690 net.cpp:144] Memory required for data: 3465721856
I1028 19:00:29.616336 12690 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1028 19:00:29.616343 12690 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1028 19:00:29.616349 12690 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1028 19:00:29.616354 12690 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1028 19:00:29.616358 12690 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I1028 19:00:29.616376 12690 net.cpp:84] Creating Layer fire7/relu_expand3x3
I1028 19:00:29.616380 12690 net.cpp:413] fire7/relu_expand3x3 <- fire7/expand3x3
I1028 19:00:29.616386 12690 net.cpp:374] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I1028 19:00:29.616600 12690 net.cpp:127] Setting up fire7/relu_expand3x3
I1028 19:00:29.616610 12690 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 19:00:29.616613 12690 net.cpp:144] Memory required for data: 3484989440
I1028 19:00:29.616617 12690 layer_factory.hpp:77] Creating layer fire7/concat
I1028 19:00:29.616624 12690 net.cpp:84] Creating Layer fire7/concat
I1028 19:00:29.616628 12690 net.cpp:413] fire7/concat <- fire7/expand1x1
I1028 19:00:29.616633 12690 net.cpp:413] fire7/concat <- fire7/expand3x3
I1028 19:00:29.616638 12690 net.cpp:387] fire7/concat -> fire7/concat
I1028 19:00:29.616669 12690 net.cpp:127] Setting up fire7/concat
I1028 19:00:29.616675 12690 net.cpp:136] Top shape: 128 384 14 14 (9633792)
I1028 19:00:29.616679 12690 net.cpp:144] Memory required for data: 3523524608
I1028 19:00:29.616683 12690 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I1028 19:00:29.616693 12690 net.cpp:84] Creating Layer fire8/squeeze1x1
I1028 19:00:29.616696 12690 net.cpp:413] fire8/squeeze1x1 <- fire7/concat
I1028 19:00:29.616703 12690 net.cpp:387] fire8/squeeze1x1 -> fire8/squeeze1x1
I1028 19:00:29.617220 12690 net.cpp:127] Setting up fire8/squeeze1x1
I1028 19:00:29.617228 12690 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 19:00:29.617233 12690 net.cpp:144] Memory required for data: 3529947136
I1028 19:00:29.617238 12690 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1028 19:00:29.617244 12690 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1028 19:00:29.617249 12690 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1028 19:00:29.617252 12690 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1028 19:00:29.617256 12690 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I1028 19:00:29.617262 12690 net.cpp:84] Creating Layer fire8/relu_squeeze1x1
I1028 19:00:29.617266 12690 net.cpp:413] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I1028 19:00:29.617274 12690 net.cpp:374] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I1028 19:00:29.618639 12690 net.cpp:127] Setting up fire8/relu_squeeze1x1
I1028 19:00:29.618654 12690 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 19:00:29.618659 12690 net.cpp:144] Memory required for data: 3536369664
I1028 19:00:29.618662 12690 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1028 19:00:29.618670 12690 net.cpp:84] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1028 19:00:29.618674 12690 net.cpp:413] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I1028 19:00:29.618682 12690 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1028 19:00:29.618690 12690 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1028 19:00:29.618738 12690 net.cpp:127] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1028 19:00:29.618746 12690 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 19:00:29.618751 12690 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 19:00:29.618753 12690 net.cpp:144] Memory required for data: 3549214720
I1028 19:00:29.618757 12690 layer_factory.hpp:77] Creating layer fire8/expand1x1
I1028 19:00:29.618769 12690 net.cpp:84] Creating Layer fire8/expand1x1
I1028 19:00:29.618773 12690 net.cpp:413] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1028 19:00:29.618783 12690 net.cpp:387] fire8/expand1x1 -> fire8/expand1x1
I1028 19:00:29.619244 12690 net.cpp:127] Setting up fire8/expand1x1
I1028 19:00:29.619253 12690 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 19:00:29.619257 12690 net.cpp:144] Memory required for data: 3574904832
I1028 19:00:29.619276 12690 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1028 19:00:29.619282 12690 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1028 19:00:29.619287 12690 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1028 19:00:29.619290 12690 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1028 19:00:29.619294 12690 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I1028 19:00:29.619300 12690 net.cpp:84] Creating Layer fire8/relu_expand1x1
I1028 19:00:29.619305 12690 net.cpp:413] fire8/relu_expand1x1 <- fire8/expand1x1
I1028 19:00:29.619310 12690 net.cpp:374] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I1028 19:00:29.619518 12690 net.cpp:127] Setting up fire8/relu_expand1x1
I1028 19:00:29.619525 12690 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 19:00:29.619529 12690 net.cpp:144] Memory required for data: 3600594944
I1028 19:00:29.619534 12690 layer_factory.hpp:77] Creating layer fire8/expand3x3
I1028 19:00:29.619544 12690 net.cpp:84] Creating Layer fire8/expand3x3
I1028 19:00:29.619549 12690 net.cpp:413] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1028 19:00:29.619559 12690 net.cpp:387] fire8/expand3x3 -> fire8/expand3x3
I1028 19:00:29.622360 12690 net.cpp:127] Setting up fire8/expand3x3
I1028 19:00:29.622375 12690 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 19:00:29.622380 12690 net.cpp:144] Memory required for data: 3626285056
I1028 19:00:29.622385 12690 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1028 19:00:29.622391 12690 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1028 19:00:29.622396 12690 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1028 19:00:29.622400 12690 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1028 19:00:29.622404 12690 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I1028 19:00:29.622413 12690 net.cpp:84] Creating Layer fire8/relu_expand3x3
I1028 19:00:29.622418 12690 net.cpp:413] fire8/relu_expand3x3 <- fire8/expand3x3
I1028 19:00:29.622424 12690 net.cpp:374] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I1028 19:00:29.622644 12690 net.cpp:127] Setting up fire8/relu_expand3x3
I1028 19:00:29.622653 12690 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 19:00:29.622658 12690 net.cpp:144] Memory required for data: 3651975168
I1028 19:00:29.622661 12690 layer_factory.hpp:77] Creating layer fire8/concat
I1028 19:00:29.622669 12690 net.cpp:84] Creating Layer fire8/concat
I1028 19:00:29.622674 12690 net.cpp:413] fire8/concat <- fire8/expand1x1
I1028 19:00:29.622679 12690 net.cpp:413] fire8/concat <- fire8/expand3x3
I1028 19:00:29.622685 12690 net.cpp:387] fire8/concat -> fire8/concat
I1028 19:00:29.622717 12690 net.cpp:127] Setting up fire8/concat
I1028 19:00:29.622723 12690 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1028 19:00:29.622727 12690 net.cpp:144] Memory required for data: 3703355392
I1028 19:00:29.622731 12690 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I1028 19:00:29.622742 12690 net.cpp:84] Creating Layer fire9/squeeze1x1
I1028 19:00:29.622746 12690 net.cpp:413] fire9/squeeze1x1 <- fire8/concat
I1028 19:00:29.622755 12690 net.cpp:387] fire9/squeeze1x1 -> fire9/squeeze1x1
I1028 19:00:29.623349 12690 net.cpp:127] Setting up fire9/squeeze1x1
I1028 19:00:29.623358 12690 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 19:00:29.623363 12690 net.cpp:144] Memory required for data: 3709777920
I1028 19:00:29.623368 12690 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1028 19:00:29.623373 12690 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1028 19:00:29.623381 12690 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1028 19:00:29.623385 12690 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1028 19:00:29.623404 12690 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I1028 19:00:29.623411 12690 net.cpp:84] Creating Layer fire9/relu_squeeze1x1
I1028 19:00:29.623415 12690 net.cpp:413] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I1028 19:00:29.623420 12690 net.cpp:374] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I1028 19:00:29.623631 12690 net.cpp:127] Setting up fire9/relu_squeeze1x1
I1028 19:00:29.623641 12690 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 19:00:29.623644 12690 net.cpp:144] Memory required for data: 3716200448
I1028 19:00:29.623648 12690 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1028 19:00:29.623663 12690 net.cpp:84] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1028 19:00:29.623667 12690 net.cpp:413] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I1028 19:00:29.623673 12690 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1028 19:00:29.623682 12690 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1028 19:00:29.623730 12690 net.cpp:127] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1028 19:00:29.623736 12690 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 19:00:29.623741 12690 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 19:00:29.623744 12690 net.cpp:144] Memory required for data: 3729045504
I1028 19:00:29.623749 12690 layer_factory.hpp:77] Creating layer fire9/expand1x1
I1028 19:00:29.623759 12690 net.cpp:84] Creating Layer fire9/expand1x1
I1028 19:00:29.623764 12690 net.cpp:413] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1028 19:00:29.623770 12690 net.cpp:387] fire9/expand1x1 -> fire9/expand1x1
I1028 19:00:29.624228 12690 net.cpp:127] Setting up fire9/expand1x1
I1028 19:00:29.624235 12690 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 19:00:29.624239 12690 net.cpp:144] Memory required for data: 3754735616
I1028 19:00:29.624245 12690 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1028 19:00:29.624250 12690 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1028 19:00:29.624255 12690 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1028 19:00:29.624259 12690 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1028 19:00:29.624264 12690 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I1028 19:00:29.624271 12690 net.cpp:84] Creating Layer fire9/relu_expand1x1
I1028 19:00:29.624276 12690 net.cpp:413] fire9/relu_expand1x1 <- fire9/expand1x1
I1028 19:00:29.624281 12690 net.cpp:374] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I1028 19:00:29.625661 12690 net.cpp:127] Setting up fire9/relu_expand1x1
I1028 19:00:29.625677 12690 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 19:00:29.625682 12690 net.cpp:144] Memory required for data: 3780425728
I1028 19:00:29.625687 12690 layer_factory.hpp:77] Creating layer fire9/expand3x3
I1028 19:00:29.625696 12690 net.cpp:84] Creating Layer fire9/expand3x3
I1028 19:00:29.625701 12690 net.cpp:413] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1028 19:00:29.625710 12690 net.cpp:387] fire9/expand3x3 -> fire9/expand3x3
I1028 19:00:29.627212 12690 net.cpp:127] Setting up fire9/expand3x3
I1028 19:00:29.627220 12690 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 19:00:29.627224 12690 net.cpp:144] Memory required for data: 3806115840
I1028 19:00:29.627230 12690 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1028 19:00:29.627236 12690 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1028 19:00:29.627245 12690 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1028 19:00:29.627250 12690 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1028 19:00:29.627254 12690 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I1028 19:00:29.627274 12690 net.cpp:84] Creating Layer fire9/relu_expand3x3
I1028 19:00:29.627279 12690 net.cpp:413] fire9/relu_expand3x3 <- fire9/expand3x3
I1028 19:00:29.627285 12690 net.cpp:374] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I1028 19:00:29.627488 12690 net.cpp:127] Setting up fire9/relu_expand3x3
I1028 19:00:29.627497 12690 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 19:00:29.627501 12690 net.cpp:144] Memory required for data: 3831805952
I1028 19:00:29.627504 12690 layer_factory.hpp:77] Creating layer fire9/concat
I1028 19:00:29.627512 12690 net.cpp:84] Creating Layer fire9/concat
I1028 19:00:29.627516 12690 net.cpp:413] fire9/concat <- fire9/expand1x1
I1028 19:00:29.627521 12690 net.cpp:413] fire9/concat <- fire9/expand3x3
I1028 19:00:29.627529 12690 net.cpp:387] fire9/concat -> fire9/concat
I1028 19:00:29.627559 12690 net.cpp:127] Setting up fire9/concat
I1028 19:00:29.627565 12690 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1028 19:00:29.627569 12690 net.cpp:144] Memory required for data: 3883186176
I1028 19:00:29.627573 12690 layer_factory.hpp:77] Creating layer drop9
I1028 19:00:29.627583 12690 net.cpp:84] Creating Layer drop9
I1028 19:00:29.627588 12690 net.cpp:413] drop9 <- fire9/concat
I1028 19:00:29.627593 12690 net.cpp:374] drop9 -> fire9/concat (in-place)
I1028 19:00:29.627627 12690 net.cpp:127] Setting up drop9
I1028 19:00:29.627634 12690 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1028 19:00:29.627636 12690 net.cpp:144] Memory required for data: 3934566400
I1028 19:00:29.627640 12690 layer_factory.hpp:77] Creating layer conv10
I1028 19:00:29.627650 12690 net.cpp:84] Creating Layer conv10
I1028 19:00:29.627653 12690 net.cpp:413] conv10 <- fire9/concat
I1028 19:00:29.627661 12690 net.cpp:387] conv10 -> conv10
I1028 19:00:29.637112 12690 net.cpp:127] Setting up conv10
I1028 19:00:29.637128 12690 net.cpp:136] Top shape: 128 1000 14 14 (25088000)
I1028 19:00:29.637132 12690 net.cpp:144] Memory required for data: 4034918400
I1028 19:00:29.637140 12690 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1028 19:00:29.637145 12690 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1028 19:00:29.637150 12690 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1028 19:00:29.637154 12690 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1028 19:00:29.637157 12690 layer_factory.hpp:77] Creating layer relu_conv10
I1028 19:00:29.637166 12690 net.cpp:84] Creating Layer relu_conv10
I1028 19:00:29.637169 12690 net.cpp:413] relu_conv10 <- conv10
I1028 19:00:29.637178 12690 net.cpp:374] relu_conv10 -> conv10 (in-place)
I1028 19:00:29.637405 12690 net.cpp:127] Setting up relu_conv10
I1028 19:00:29.637415 12690 net.cpp:136] Top shape: 128 1000 14 14 (25088000)
I1028 19:00:29.637419 12690 net.cpp:144] Memory required for data: 4135270400
I1028 19:00:29.637423 12690 layer_factory.hpp:77] Creating layer pool10
I1028 19:00:29.637432 12690 net.cpp:84] Creating Layer pool10
I1028 19:00:29.637436 12690 net.cpp:413] pool10 <- conv10
I1028 19:00:29.637442 12690 net.cpp:387] pool10 -> pool10
I1028 19:00:29.637681 12690 net.cpp:127] Setting up pool10
I1028 19:00:29.637693 12690 net.cpp:136] Top shape: 128 1000 1 1 (128000)
I1028 19:00:29.637697 12690 net.cpp:144] Memory required for data: 4135782400
I1028 19:00:29.637701 12690 layer_factory.hpp:77] Creating layer loss
I1028 19:00:29.637709 12690 net.cpp:84] Creating Layer loss
I1028 19:00:29.637713 12690 net.cpp:413] loss <- pool10
I1028 19:00:29.637719 12690 net.cpp:413] loss <- label
I1028 19:00:29.637725 12690 net.cpp:387] loss -> loss
I1028 19:00:29.637737 12690 layer_factory.hpp:77] Creating layer loss
I1028 19:00:29.640651 12690 net.cpp:127] Setting up loss
I1028 19:00:29.640671 12690 net.cpp:136] Top shape: (1)
I1028 19:00:29.640676 12690 net.cpp:139]     with loss weight 1
I1028 19:00:29.640702 12690 net.cpp:144] Memory required for data: 4135782404
I1028 19:00:29.640707 12690 net.cpp:205] loss needs backward computation.
I1028 19:00:29.640722 12690 net.cpp:205] pool10 needs backward computation.
I1028 19:00:29.640727 12690 net.cpp:205] relu_conv10 needs backward computation.
I1028 19:00:29.640730 12690 net.cpp:205] conv10 needs backward computation.
I1028 19:00:29.640734 12690 net.cpp:205] drop9 needs backward computation.
I1028 19:00:29.640738 12690 net.cpp:205] fire9/concat needs backward computation.
I1028 19:00:29.640743 12690 net.cpp:205] fire9/relu_expand3x3 needs backward computation.
I1028 19:00:29.640745 12690 net.cpp:205] fire9/expand3x3 needs backward computation.
I1028 19:00:29.640749 12690 net.cpp:205] fire9/relu_expand1x1 needs backward computation.
I1028 19:00:29.640753 12690 net.cpp:205] fire9/expand1x1 needs backward computation.
I1028 19:00:29.640756 12690 net.cpp:205] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I1028 19:00:29.640760 12690 net.cpp:205] fire9/relu_squeeze1x1 needs backward computation.
I1028 19:00:29.640764 12690 net.cpp:205] fire9/squeeze1x1 needs backward computation.
I1028 19:00:29.640769 12690 net.cpp:205] fire8/concat needs backward computation.
I1028 19:00:29.640772 12690 net.cpp:205] fire8/relu_expand3x3 needs backward computation.
I1028 19:00:29.640776 12690 net.cpp:205] fire8/expand3x3 needs backward computation.
I1028 19:00:29.640779 12690 net.cpp:205] fire8/relu_expand1x1 needs backward computation.
I1028 19:00:29.640784 12690 net.cpp:205] fire8/expand1x1 needs backward computation.
I1028 19:00:29.640786 12690 net.cpp:205] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I1028 19:00:29.640790 12690 net.cpp:205] fire8/relu_squeeze1x1 needs backward computation.
I1028 19:00:29.640794 12690 net.cpp:205] fire8/squeeze1x1 needs backward computation.
I1028 19:00:29.640797 12690 net.cpp:205] fire7/concat needs backward computation.
I1028 19:00:29.640801 12690 net.cpp:205] fire7/relu_expand3x3 needs backward computation.
I1028 19:00:29.640805 12690 net.cpp:205] fire7/expand3x3 needs backward computation.
I1028 19:00:29.640808 12690 net.cpp:205] fire7/relu_expand1x1 needs backward computation.
I1028 19:00:29.640811 12690 net.cpp:205] fire7/expand1x1 needs backward computation.
I1028 19:00:29.640815 12690 net.cpp:205] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I1028 19:00:29.640820 12690 net.cpp:205] fire7/relu_squeeze1x1 needs backward computation.
I1028 19:00:29.640822 12690 net.cpp:205] fire7/squeeze1x1 needs backward computation.
I1028 19:00:29.640826 12690 net.cpp:205] fire6/concat needs backward computation.
I1028 19:00:29.640830 12690 net.cpp:205] fire6/relu_expand3x3 needs backward computation.
I1028 19:00:29.640833 12690 net.cpp:205] fire6/expand3x3 needs backward computation.
I1028 19:00:29.640837 12690 net.cpp:205] fire6/relu_expand1x1 needs backward computation.
I1028 19:00:29.640841 12690 net.cpp:205] fire6/expand1x1 needs backward computation.
I1028 19:00:29.640844 12690 net.cpp:205] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I1028 19:00:29.640848 12690 net.cpp:205] fire6/relu_squeeze1x1 needs backward computation.
I1028 19:00:29.640851 12690 net.cpp:205] fire6/squeeze1x1 needs backward computation.
I1028 19:00:29.640856 12690 net.cpp:205] pool5 needs backward computation.
I1028 19:00:29.640858 12690 net.cpp:205] fire5/concat needs backward computation.
I1028 19:00:29.640862 12690 net.cpp:205] fire5/relu_expand3x3 needs backward computation.
I1028 19:00:29.640866 12690 net.cpp:205] fire5/expand3x3 needs backward computation.
I1028 19:00:29.640869 12690 net.cpp:205] fire5/relu_expand1x1 needs backward computation.
I1028 19:00:29.640872 12690 net.cpp:205] fire5/expand1x1 needs backward computation.
I1028 19:00:29.640877 12690 net.cpp:205] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I1028 19:00:29.640882 12690 net.cpp:205] fire5/relu_squeeze1x1 needs backward computation.
I1028 19:00:29.640887 12690 net.cpp:205] fire5/squeeze1x1 needs backward computation.
I1028 19:00:29.640890 12690 net.cpp:205] fire4/concat needs backward computation.
I1028 19:00:29.640894 12690 net.cpp:205] fire4/relu_expand3x3 needs backward computation.
I1028 19:00:29.640903 12690 net.cpp:205] fire4/expand3x3 needs backward computation.
I1028 19:00:29.640907 12690 net.cpp:205] fire4/relu_expand1x1 needs backward computation.
I1028 19:00:29.640910 12690 net.cpp:205] fire4/expand1x1 needs backward computation.
I1028 19:00:29.640913 12690 net.cpp:205] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I1028 19:00:29.640918 12690 net.cpp:205] fire4/relu_squeeze1x1 needs backward computation.
I1028 19:00:29.640928 12690 net.cpp:205] fire4/squeeze1x1 needs backward computation.
I1028 19:00:29.640931 12690 net.cpp:205] pool3 needs backward computation.
I1028 19:00:29.640935 12690 net.cpp:205] fire3/concat needs backward computation.
I1028 19:00:29.640939 12690 net.cpp:205] fire3/relu_expand3x3 needs backward computation.
I1028 19:00:29.640944 12690 net.cpp:205] fire3/expand3x3 needs backward computation.
I1028 19:00:29.640946 12690 net.cpp:205] fire3/relu_expand1x1 needs backward computation.
I1028 19:00:29.640950 12690 net.cpp:205] fire3/expand1x1 needs backward computation.
I1028 19:00:29.640954 12690 net.cpp:205] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I1028 19:00:29.640957 12690 net.cpp:205] fire3/relu_squeeze1x1 needs backward computation.
I1028 19:00:29.640961 12690 net.cpp:205] fire3/squeeze1x1 needs backward computation.
I1028 19:00:29.640964 12690 net.cpp:205] fire2/concat needs backward computation.
I1028 19:00:29.640969 12690 net.cpp:205] fire2/relu_expand3x3 needs backward computation.
I1028 19:00:29.640972 12690 net.cpp:205] fire2/expand3x3 needs backward computation.
I1028 19:00:29.640975 12690 net.cpp:205] fire2/relu_expand1x1 needs backward computation.
I1028 19:00:29.640978 12690 net.cpp:205] fire2/expand1x1 needs backward computation.
I1028 19:00:29.640982 12690 net.cpp:205] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I1028 19:00:29.640986 12690 net.cpp:205] fire2/relu_squeeze1x1 needs backward computation.
I1028 19:00:29.640990 12690 net.cpp:205] fire2/squeeze1x1 needs backward computation.
I1028 19:00:29.640996 12690 net.cpp:205] pool1 needs backward computation.
I1028 19:00:29.641002 12690 net.cpp:205] relu_conv1 needs backward computation.
I1028 19:00:29.641006 12690 net.cpp:205] conv1 needs backward computation.
I1028 19:00:29.641010 12690 net.cpp:207] data does not need backward computation.
I1028 19:00:29.641014 12690 net.cpp:249] This network produces output loss
I1028 19:00:29.641067 12690 net.cpp:262] Network initialization done.
I1028 19:00:29.643949 12690 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_40.prototxt
I1028 19:00:29.644136 12690 net.cpp:301] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1028 19:00:29.645506 12690 net.cpp:51] Initializing net from parameters: 
name: "SqueezeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/data/caffe-imagenet/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "INQConvolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "fire3/concat"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire4/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool3"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "fire5/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire4/concat"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "fire5/concat"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire6/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool5"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "fire9/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire8/concat"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "INQConvolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "pool10"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy_top1"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy_top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy_top5"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy_top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I1028 19:00:29.646173 12690 layer_factory.hpp:77] Creating layer data
I1028 19:00:29.646301 12690 db_lmdb.cpp:35] Opened lmdb /home/data/caffe-imagenet/ilsvrc12_val_lmdb
I1028 19:00:29.646334 12690 net.cpp:84] Creating Layer data
I1028 19:00:29.646345 12690 net.cpp:387] data -> data
I1028 19:00:29.646366 12690 net.cpp:387] data -> label
I1028 19:00:29.647042 12690 data_layer.cpp:45] output data size: 50,3,227,227
I1028 19:00:29.745870 12690 net.cpp:127] Setting up data
I1028 19:00:29.745911 12690 net.cpp:136] Top shape: 50 3 227 227 (7729350)
I1028 19:00:29.745924 12690 net.cpp:136] Top shape: 50 (50)
I1028 19:00:29.745929 12690 net.cpp:144] Memory required for data: 30917600
I1028 19:00:29.745937 12690 layer_factory.hpp:77] Creating layer label_data_1_split
I1028 19:00:29.745954 12690 net.cpp:84] Creating Layer label_data_1_split
I1028 19:00:29.745959 12690 net.cpp:413] label_data_1_split <- label
I1028 19:00:29.745968 12690 net.cpp:387] label_data_1_split -> label_data_1_split_0
I1028 19:00:29.745981 12690 net.cpp:387] label_data_1_split -> label_data_1_split_1
I1028 19:00:29.745990 12690 net.cpp:387] label_data_1_split -> label_data_1_split_2
I1028 19:00:29.746153 12690 net.cpp:127] Setting up label_data_1_split
I1028 19:00:29.746162 12690 net.cpp:136] Top shape: 50 (50)
I1028 19:00:29.746167 12690 net.cpp:136] Top shape: 50 (50)
I1028 19:00:29.746172 12690 net.cpp:136] Top shape: 50 (50)
I1028 19:00:29.746176 12690 net.cpp:144] Memory required for data: 30918200
I1028 19:00:29.746181 12690 layer_factory.hpp:77] Creating layer conv1
I1028 19:00:29.746196 12690 net.cpp:84] Creating Layer conv1
I1028 19:00:29.746201 12690 net.cpp:413] conv1 <- data
I1028 19:00:29.746208 12690 net.cpp:387] conv1 -> conv1
I1028 19:00:29.746747 12690 net.cpp:127] Setting up conv1
I1028 19:00:29.746757 12690 net.cpp:136] Top shape: 50 64 113 113 (40860800)
I1028 19:00:29.746760 12690 net.cpp:144] Memory required for data: 194361400
I1028 19:00:29.746769 12690 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1028 19:00:29.746779 12690 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1028 19:00:29.746788 12690 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1028 19:00:29.746793 12690 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1028 19:00:29.746798 12690 layer_factory.hpp:77] Creating layer relu_conv1
I1028 19:00:29.746806 12690 net.cpp:84] Creating Layer relu_conv1
I1028 19:00:29.746810 12690 net.cpp:413] relu_conv1 <- conv1
I1028 19:00:29.746817 12690 net.cpp:374] relu_conv1 -> conv1 (in-place)
I1028 19:00:29.747089 12690 net.cpp:127] Setting up relu_conv1
I1028 19:00:29.747100 12690 net.cpp:136] Top shape: 50 64 113 113 (40860800)
I1028 19:00:29.747104 12690 net.cpp:144] Memory required for data: 357804600
I1028 19:00:29.747108 12690 layer_factory.hpp:77] Creating layer pool1
I1028 19:00:29.747119 12690 net.cpp:84] Creating Layer pool1
I1028 19:00:29.747123 12690 net.cpp:413] pool1 <- conv1
I1028 19:00:29.747130 12690 net.cpp:387] pool1 -> pool1
I1028 19:00:29.747181 12690 net.cpp:127] Setting up pool1
I1028 19:00:29.747187 12690 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 19:00:29.747191 12690 net.cpp:144] Memory required for data: 397945400
I1028 19:00:29.747195 12690 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I1028 19:00:29.747205 12690 net.cpp:84] Creating Layer fire2/squeeze1x1
I1028 19:00:29.747210 12690 net.cpp:413] fire2/squeeze1x1 <- pool1
I1028 19:00:29.747216 12690 net.cpp:387] fire2/squeeze1x1 -> fire2/squeeze1x1
I1028 19:00:29.747579 12690 net.cpp:127] Setting up fire2/squeeze1x1
I1028 19:00:29.747587 12690 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 19:00:29.747591 12690 net.cpp:144] Memory required for data: 407980600
I1028 19:00:29.747598 12690 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1028 19:00:29.747606 12690 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1028 19:00:29.747611 12690 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1028 19:00:29.747617 12690 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1028 19:00:29.747627 12690 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I1028 19:00:29.747634 12690 net.cpp:84] Creating Layer fire2/relu_squeeze1x1
I1028 19:00:29.747638 12690 net.cpp:413] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I1028 19:00:29.747671 12690 net.cpp:374] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I1028 19:00:29.747895 12690 net.cpp:127] Setting up fire2/relu_squeeze1x1
I1028 19:00:29.747905 12690 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 19:00:29.747908 12690 net.cpp:144] Memory required for data: 418015800
I1028 19:00:29.747912 12690 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1028 19:00:29.747925 12690 net.cpp:84] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1028 19:00:29.747930 12690 net.cpp:413] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I1028 19:00:29.747937 12690 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1028 19:00:29.747946 12690 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1028 19:00:29.747995 12690 net.cpp:127] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1028 19:00:29.748003 12690 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 19:00:29.748008 12690 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 19:00:29.748010 12690 net.cpp:144] Memory required for data: 438086200
I1028 19:00:29.748014 12690 layer_factory.hpp:77] Creating layer fire2/expand1x1
I1028 19:00:29.748025 12690 net.cpp:84] Creating Layer fire2/expand1x1
I1028 19:00:29.748029 12690 net.cpp:413] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1028 19:00:29.748036 12690 net.cpp:387] fire2/expand1x1 -> fire2/expand1x1
I1028 19:00:29.748536 12690 net.cpp:127] Setting up fire2/expand1x1
I1028 19:00:29.748546 12690 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 19:00:29.748550 12690 net.cpp:144] Memory required for data: 478227000
I1028 19:00:29.748558 12690 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1028 19:00:29.748566 12690 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1028 19:00:29.748571 12690 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1028 19:00:29.748576 12690 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1028 19:00:29.748580 12690 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I1028 19:00:29.748587 12690 net.cpp:84] Creating Layer fire2/relu_expand1x1
I1028 19:00:29.748591 12690 net.cpp:413] fire2/relu_expand1x1 <- fire2/expand1x1
I1028 19:00:29.748598 12690 net.cpp:374] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I1028 19:00:29.752566 12690 net.cpp:127] Setting up fire2/relu_expand1x1
I1028 19:00:29.752598 12690 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 19:00:29.752606 12690 net.cpp:144] Memory required for data: 518367800
I1028 19:00:29.752614 12690 layer_factory.hpp:77] Creating layer fire2/expand3x3
I1028 19:00:29.752634 12690 net.cpp:84] Creating Layer fire2/expand3x3
I1028 19:00:29.752641 12690 net.cpp:413] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1028 19:00:29.752656 12690 net.cpp:387] fire2/expand3x3 -> fire2/expand3x3
I1028 19:00:29.753223 12690 net.cpp:127] Setting up fire2/expand3x3
I1028 19:00:29.753232 12690 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 19:00:29.753237 12690 net.cpp:144] Memory required for data: 558508600
I1028 19:00:29.753242 12690 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1028 19:00:29.753248 12690 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1028 19:00:29.753253 12690 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1028 19:00:29.753257 12690 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1028 19:00:29.753262 12690 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I1028 19:00:29.753273 12690 net.cpp:84] Creating Layer fire2/relu_expand3x3
I1028 19:00:29.753278 12690 net.cpp:413] fire2/relu_expand3x3 <- fire2/expand3x3
I1028 19:00:29.753283 12690 net.cpp:374] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I1028 19:00:29.753525 12690 net.cpp:127] Setting up fire2/relu_expand3x3
I1028 19:00:29.753535 12690 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 19:00:29.753538 12690 net.cpp:144] Memory required for data: 598649400
I1028 19:00:29.753542 12690 layer_factory.hpp:77] Creating layer fire2/concat
I1028 19:00:29.753551 12690 net.cpp:84] Creating Layer fire2/concat
I1028 19:00:29.753556 12690 net.cpp:413] fire2/concat <- fire2/expand1x1
I1028 19:00:29.753561 12690 net.cpp:413] fire2/concat <- fire2/expand3x3
I1028 19:00:29.753567 12690 net.cpp:387] fire2/concat -> fire2/concat
I1028 19:00:29.753626 12690 net.cpp:127] Setting up fire2/concat
I1028 19:00:29.753634 12690 net.cpp:136] Top shape: 50 128 56 56 (20070400)
I1028 19:00:29.753638 12690 net.cpp:144] Memory required for data: 678931000
I1028 19:00:29.753643 12690 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I1028 19:00:29.753654 12690 net.cpp:84] Creating Layer fire3/squeeze1x1
I1028 19:00:29.753657 12690 net.cpp:413] fire3/squeeze1x1 <- fire2/concat
I1028 19:00:29.753666 12690 net.cpp:387] fire3/squeeze1x1 -> fire3/squeeze1x1
I1028 19:00:29.754040 12690 net.cpp:127] Setting up fire3/squeeze1x1
I1028 19:00:29.754050 12690 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 19:00:29.754053 12690 net.cpp:144] Memory required for data: 688966200
I1028 19:00:29.754061 12690 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1028 19:00:29.754068 12690 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1028 19:00:29.754073 12690 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1028 19:00:29.754078 12690 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1028 19:00:29.754082 12690 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I1028 19:00:29.754092 12690 net.cpp:84] Creating Layer fire3/relu_squeeze1x1
I1028 19:00:29.754096 12690 net.cpp:413] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I1028 19:00:29.754102 12690 net.cpp:374] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I1028 19:00:29.754323 12690 net.cpp:127] Setting up fire3/relu_squeeze1x1
I1028 19:00:29.754330 12690 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 19:00:29.754334 12690 net.cpp:144] Memory required for data: 699001400
I1028 19:00:29.754338 12690 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1028 19:00:29.754344 12690 net.cpp:84] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1028 19:00:29.754348 12690 net.cpp:413] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I1028 19:00:29.754356 12690 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1028 19:00:29.754364 12690 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1028 19:00:29.754412 12690 net.cpp:127] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1028 19:00:29.754418 12690 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 19:00:29.754423 12690 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 19:00:29.754426 12690 net.cpp:144] Memory required for data: 719071800
I1028 19:00:29.754431 12690 layer_factory.hpp:77] Creating layer fire3/expand1x1
I1028 19:00:29.754442 12690 net.cpp:84] Creating Layer fire3/expand1x1
I1028 19:00:29.754446 12690 net.cpp:413] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1028 19:00:29.754454 12690 net.cpp:387] fire3/expand1x1 -> fire3/expand1x1
I1028 19:00:29.754804 12690 net.cpp:127] Setting up fire3/expand1x1
I1028 19:00:29.754813 12690 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 19:00:29.754817 12690 net.cpp:144] Memory required for data: 759212600
I1028 19:00:29.754825 12690 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1028 19:00:29.754832 12690 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1028 19:00:29.754837 12690 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1028 19:00:29.754851 12690 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1028 19:00:29.754855 12690 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I1028 19:00:29.754861 12690 net.cpp:84] Creating Layer fire3/relu_expand1x1
I1028 19:00:29.754865 12690 net.cpp:413] fire3/relu_expand1x1 <- fire3/expand1x1
I1028 19:00:29.754873 12690 net.cpp:374] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I1028 19:00:29.755095 12690 net.cpp:127] Setting up fire3/relu_expand1x1
I1028 19:00:29.755105 12690 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 19:00:29.755110 12690 net.cpp:144] Memory required for data: 799353400
I1028 19:00:29.755113 12690 layer_factory.hpp:77] Creating layer fire3/expand3x3
I1028 19:00:29.755125 12690 net.cpp:84] Creating Layer fire3/expand3x3
I1028 19:00:29.755128 12690 net.cpp:413] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1028 19:00:29.755136 12690 net.cpp:387] fire3/expand3x3 -> fire3/expand3x3
I1028 19:00:29.755574 12690 net.cpp:127] Setting up fire3/expand3x3
I1028 19:00:29.755583 12690 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 19:00:29.755586 12690 net.cpp:144] Memory required for data: 839494200
I1028 19:00:29.755591 12690 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1028 19:00:29.755597 12690 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1028 19:00:29.755602 12690 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1028 19:00:29.755606 12690 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1028 19:00:29.755609 12690 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I1028 19:00:29.755615 12690 net.cpp:84] Creating Layer fire3/relu_expand3x3
I1028 19:00:29.755620 12690 net.cpp:413] fire3/relu_expand3x3 <- fire3/expand3x3
I1028 19:00:29.755628 12690 net.cpp:374] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I1028 19:00:29.757056 12690 net.cpp:127] Setting up fire3/relu_expand3x3
I1028 19:00:29.757071 12690 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 19:00:29.757076 12690 net.cpp:144] Memory required for data: 879635000
I1028 19:00:29.757081 12690 layer_factory.hpp:77] Creating layer fire3/concat
I1028 19:00:29.757087 12690 net.cpp:84] Creating Layer fire3/concat
I1028 19:00:29.757092 12690 net.cpp:413] fire3/concat <- fire3/expand1x1
I1028 19:00:29.757098 12690 net.cpp:413] fire3/concat <- fire3/expand3x3
I1028 19:00:29.757107 12690 net.cpp:387] fire3/concat -> fire3/concat
I1028 19:00:29.757140 12690 net.cpp:127] Setting up fire3/concat
I1028 19:00:29.757148 12690 net.cpp:136] Top shape: 50 128 56 56 (20070400)
I1028 19:00:29.757153 12690 net.cpp:144] Memory required for data: 959916600
I1028 19:00:29.757156 12690 layer_factory.hpp:77] Creating layer pool3
I1028 19:00:29.757163 12690 net.cpp:84] Creating Layer pool3
I1028 19:00:29.757166 12690 net.cpp:413] pool3 <- fire3/concat
I1028 19:00:29.757172 12690 net.cpp:387] pool3 -> pool3
I1028 19:00:29.757220 12690 net.cpp:127] Setting up pool3
I1028 19:00:29.757225 12690 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 19:00:29.757230 12690 net.cpp:144] Memory required for data: 979987000
I1028 19:00:29.757232 12690 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I1028 19:00:29.757243 12690 net.cpp:84] Creating Layer fire4/squeeze1x1
I1028 19:00:29.757247 12690 net.cpp:413] fire4/squeeze1x1 <- pool3
I1028 19:00:29.757254 12690 net.cpp:387] fire4/squeeze1x1 -> fire4/squeeze1x1
I1028 19:00:29.757652 12690 net.cpp:127] Setting up fire4/squeeze1x1
I1028 19:00:29.757660 12690 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 19:00:29.757663 12690 net.cpp:144] Memory required for data: 985004600
I1028 19:00:29.757673 12690 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1028 19:00:29.757680 12690 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1028 19:00:29.757684 12690 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1028 19:00:29.757700 12690 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1028 19:00:29.757704 12690 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I1028 19:00:29.757710 12690 net.cpp:84] Creating Layer fire4/relu_squeeze1x1
I1028 19:00:29.757715 12690 net.cpp:413] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I1028 19:00:29.757720 12690 net.cpp:374] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I1028 19:00:29.757944 12690 net.cpp:127] Setting up fire4/relu_squeeze1x1
I1028 19:00:29.757953 12690 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 19:00:29.757957 12690 net.cpp:144] Memory required for data: 990022200
I1028 19:00:29.757961 12690 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1028 19:00:29.757968 12690 net.cpp:84] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1028 19:00:29.757972 12690 net.cpp:413] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I1028 19:00:29.757979 12690 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1028 19:00:29.757987 12690 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1028 19:00:29.758035 12690 net.cpp:127] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1028 19:00:29.758043 12690 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 19:00:29.758047 12690 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 19:00:29.758050 12690 net.cpp:144] Memory required for data: 1000057400
I1028 19:00:29.758054 12690 layer_factory.hpp:77] Creating layer fire4/expand1x1
I1028 19:00:29.758066 12690 net.cpp:84] Creating Layer fire4/expand1x1
I1028 19:00:29.758070 12690 net.cpp:413] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1028 19:00:29.758076 12690 net.cpp:387] fire4/expand1x1 -> fire4/expand1x1
I1028 19:00:29.758442 12690 net.cpp:127] Setting up fire4/expand1x1
I1028 19:00:29.758450 12690 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 19:00:29.758455 12690 net.cpp:144] Memory required for data: 1020127800
I1028 19:00:29.758463 12690 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1028 19:00:29.758473 12690 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1028 19:00:29.758478 12690 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1028 19:00:29.758483 12690 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1028 19:00:29.758487 12690 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I1028 19:00:29.758493 12690 net.cpp:84] Creating Layer fire4/relu_expand1x1
I1028 19:00:29.758497 12690 net.cpp:413] fire4/relu_expand1x1 <- fire4/expand1x1
I1028 19:00:29.758503 12690 net.cpp:374] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I1028 19:00:29.758716 12690 net.cpp:127] Setting up fire4/relu_expand1x1
I1028 19:00:29.758725 12690 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 19:00:29.758729 12690 net.cpp:144] Memory required for data: 1040198200
I1028 19:00:29.758733 12690 layer_factory.hpp:77] Creating layer fire4/expand3x3
I1028 19:00:29.758745 12690 net.cpp:84] Creating Layer fire4/expand3x3
I1028 19:00:29.758749 12690 net.cpp:413] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1028 19:00:29.758756 12690 net.cpp:387] fire4/expand3x3 -> fire4/expand3x3
I1028 19:00:29.759420 12690 net.cpp:127] Setting up fire4/expand3x3
I1028 19:00:29.759430 12690 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 19:00:29.759433 12690 net.cpp:144] Memory required for data: 1060268600
I1028 19:00:29.759439 12690 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1028 19:00:29.759449 12690 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1028 19:00:29.759454 12690 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1028 19:00:29.759467 12690 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1028 19:00:29.759471 12690 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I1028 19:00:29.759477 12690 net.cpp:84] Creating Layer fire4/relu_expand3x3
I1028 19:00:29.759482 12690 net.cpp:413] fire4/relu_expand3x3 <- fire4/expand3x3
I1028 19:00:29.759490 12690 net.cpp:374] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I1028 19:00:29.759699 12690 net.cpp:127] Setting up fire4/relu_expand3x3
I1028 19:00:29.759708 12690 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 19:00:29.759712 12690 net.cpp:144] Memory required for data: 1080339000
I1028 19:00:29.759716 12690 layer_factory.hpp:77] Creating layer fire4/concat
I1028 19:00:29.759723 12690 net.cpp:84] Creating Layer fire4/concat
I1028 19:00:29.759727 12690 net.cpp:413] fire4/concat <- fire4/expand1x1
I1028 19:00:29.759732 12690 net.cpp:413] fire4/concat <- fire4/expand3x3
I1028 19:00:29.759739 12690 net.cpp:387] fire4/concat -> fire4/concat
I1028 19:00:29.759768 12690 net.cpp:127] Setting up fire4/concat
I1028 19:00:29.759776 12690 net.cpp:136] Top shape: 50 256 28 28 (10035200)
I1028 19:00:29.759779 12690 net.cpp:144] Memory required for data: 1120479800
I1028 19:00:29.759783 12690 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I1028 19:00:29.759791 12690 net.cpp:84] Creating Layer fire5/squeeze1x1
I1028 19:00:29.759795 12690 net.cpp:413] fire5/squeeze1x1 <- fire4/concat
I1028 19:00:29.759804 12690 net.cpp:387] fire5/squeeze1x1 -> fire5/squeeze1x1
I1028 19:00:29.760227 12690 net.cpp:127] Setting up fire5/squeeze1x1
I1028 19:00:29.760236 12690 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 19:00:29.760239 12690 net.cpp:144] Memory required for data: 1125497400
I1028 19:00:29.760246 12690 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1028 19:00:29.760251 12690 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1028 19:00:29.760255 12690 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1028 19:00:29.760259 12690 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1028 19:00:29.760263 12690 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I1028 19:00:29.760270 12690 net.cpp:84] Creating Layer fire5/relu_squeeze1x1
I1028 19:00:29.760275 12690 net.cpp:413] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I1028 19:00:29.760280 12690 net.cpp:374] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I1028 19:00:29.761694 12690 net.cpp:127] Setting up fire5/relu_squeeze1x1
I1028 19:00:29.761708 12690 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 19:00:29.761713 12690 net.cpp:144] Memory required for data: 1130515000
I1028 19:00:29.761718 12690 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1028 19:00:29.761729 12690 net.cpp:84] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1028 19:00:29.761734 12690 net.cpp:413] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I1028 19:00:29.761744 12690 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1028 19:00:29.761751 12690 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1028 19:00:29.761803 12690 net.cpp:127] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1028 19:00:29.761809 12690 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 19:00:29.761814 12690 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 19:00:29.761818 12690 net.cpp:144] Memory required for data: 1140550200
I1028 19:00:29.761821 12690 layer_factory.hpp:77] Creating layer fire5/expand1x1
I1028 19:00:29.761835 12690 net.cpp:84] Creating Layer fire5/expand1x1
I1028 19:00:29.761839 12690 net.cpp:413] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1028 19:00:29.761847 12690 net.cpp:387] fire5/expand1x1 -> fire5/expand1x1
I1028 19:00:29.764890 12690 net.cpp:127] Setting up fire5/expand1x1
I1028 19:00:29.764914 12690 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 19:00:29.764922 12690 net.cpp:144] Memory required for data: 1160620600
I1028 19:00:29.764930 12690 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1028 19:00:29.764936 12690 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1028 19:00:29.764941 12690 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1028 19:00:29.764945 12690 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1028 19:00:29.764950 12690 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I1028 19:00:29.764963 12690 net.cpp:84] Creating Layer fire5/relu_expand1x1
I1028 19:00:29.764969 12690 net.cpp:413] fire5/relu_expand1x1 <- fire5/expand1x1
I1028 19:00:29.764976 12690 net.cpp:374] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I1028 19:00:29.765278 12690 net.cpp:127] Setting up fire5/relu_expand1x1
I1028 19:00:29.765288 12690 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 19:00:29.765292 12690 net.cpp:144] Memory required for data: 1180691000
I1028 19:00:29.765296 12690 layer_factory.hpp:77] Creating layer fire5/expand3x3
I1028 19:00:29.765311 12690 net.cpp:84] Creating Layer fire5/expand3x3
I1028 19:00:29.765314 12690 net.cpp:413] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1028 19:00:29.765321 12690 net.cpp:387] fire5/expand3x3 -> fire5/expand3x3
I1028 19:00:29.765985 12690 net.cpp:127] Setting up fire5/expand3x3
I1028 19:00:29.765993 12690 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 19:00:29.765997 12690 net.cpp:144] Memory required for data: 1200761400
I1028 19:00:29.766002 12690 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1028 19:00:29.766008 12690 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1028 19:00:29.766013 12690 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1028 19:00:29.766017 12690 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1028 19:00:29.766021 12690 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I1028 19:00:29.766029 12690 net.cpp:84] Creating Layer fire5/relu_expand3x3
I1028 19:00:29.766034 12690 net.cpp:413] fire5/relu_expand3x3 <- fire5/expand3x3
I1028 19:00:29.766039 12690 net.cpp:374] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I1028 19:00:29.766255 12690 net.cpp:127] Setting up fire5/relu_expand3x3
I1028 19:00:29.766263 12690 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 19:00:29.766268 12690 net.cpp:144] Memory required for data: 1220831800
I1028 19:00:29.766273 12690 layer_factory.hpp:77] Creating layer fire5/concat
I1028 19:00:29.766281 12690 net.cpp:84] Creating Layer fire5/concat
I1028 19:00:29.766285 12690 net.cpp:413] fire5/concat <- fire5/expand1x1
I1028 19:00:29.766290 12690 net.cpp:413] fire5/concat <- fire5/expand3x3
I1028 19:00:29.766296 12690 net.cpp:387] fire5/concat -> fire5/concat
I1028 19:00:29.766330 12690 net.cpp:127] Setting up fire5/concat
I1028 19:00:29.766335 12690 net.cpp:136] Top shape: 50 256 28 28 (10035200)
I1028 19:00:29.766340 12690 net.cpp:144] Memory required for data: 1260972600
I1028 19:00:29.766342 12690 layer_factory.hpp:77] Creating layer pool5
I1028 19:00:29.766352 12690 net.cpp:84] Creating Layer pool5
I1028 19:00:29.766356 12690 net.cpp:413] pool5 <- fire5/concat
I1028 19:00:29.766362 12690 net.cpp:387] pool5 -> pool5
I1028 19:00:29.766414 12690 net.cpp:127] Setting up pool5
I1028 19:00:29.766422 12690 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 19:00:29.766424 12690 net.cpp:144] Memory required for data: 1271007800
I1028 19:00:29.766428 12690 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I1028 19:00:29.766448 12690 net.cpp:84] Creating Layer fire6/squeeze1x1
I1028 19:00:29.766453 12690 net.cpp:413] fire6/squeeze1x1 <- pool5
I1028 19:00:29.766460 12690 net.cpp:387] fire6/squeeze1x1 -> fire6/squeeze1x1
I1028 19:00:29.766932 12690 net.cpp:127] Setting up fire6/squeeze1x1
I1028 19:00:29.766952 12690 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 19:00:29.766957 12690 net.cpp:144] Memory required for data: 1272889400
I1028 19:00:29.766963 12690 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1028 19:00:29.766968 12690 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1028 19:00:29.766973 12690 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1028 19:00:29.766976 12690 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1028 19:00:29.766981 12690 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I1028 19:00:29.766989 12690 net.cpp:84] Creating Layer fire6/relu_squeeze1x1
I1028 19:00:29.766993 12690 net.cpp:413] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I1028 19:00:29.767001 12690 net.cpp:374] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I1028 19:00:29.767213 12690 net.cpp:127] Setting up fire6/relu_squeeze1x1
I1028 19:00:29.767222 12690 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 19:00:29.767226 12690 net.cpp:144] Memory required for data: 1274771000
I1028 19:00:29.767230 12690 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1028 19:00:29.767237 12690 net.cpp:84] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1028 19:00:29.767242 12690 net.cpp:413] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I1028 19:00:29.767249 12690 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1028 19:00:29.767256 12690 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1028 19:00:29.767319 12690 net.cpp:127] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1028 19:00:29.767328 12690 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 19:00:29.767333 12690 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 19:00:29.767338 12690 net.cpp:144] Memory required for data: 1278534200
I1028 19:00:29.767340 12690 layer_factory.hpp:77] Creating layer fire6/expand1x1
I1028 19:00:29.767350 12690 net.cpp:84] Creating Layer fire6/expand1x1
I1028 19:00:29.767354 12690 net.cpp:413] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1028 19:00:29.767360 12690 net.cpp:387] fire6/expand1x1 -> fire6/expand1x1
I1028 19:00:29.767779 12690 net.cpp:127] Setting up fire6/expand1x1
I1028 19:00:29.767787 12690 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 19:00:29.767791 12690 net.cpp:144] Memory required for data: 1286060600
I1028 19:00:29.767796 12690 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1028 19:00:29.767802 12690 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1028 19:00:29.767807 12690 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1028 19:00:29.767812 12690 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1028 19:00:29.767815 12690 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I1028 19:00:29.767827 12690 net.cpp:84] Creating Layer fire6/relu_expand1x1
I1028 19:00:29.767830 12690 net.cpp:413] fire6/relu_expand1x1 <- fire6/expand1x1
I1028 19:00:29.767837 12690 net.cpp:374] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I1028 19:00:29.769294 12690 net.cpp:127] Setting up fire6/relu_expand1x1
I1028 19:00:29.769310 12690 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 19:00:29.769315 12690 net.cpp:144] Memory required for data: 1293587000
I1028 19:00:29.769320 12690 layer_factory.hpp:77] Creating layer fire6/expand3x3
I1028 19:00:29.769333 12690 net.cpp:84] Creating Layer fire6/expand3x3
I1028 19:00:29.769341 12690 net.cpp:413] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1028 19:00:29.769348 12690 net.cpp:387] fire6/expand3x3 -> fire6/expand3x3
I1028 19:00:29.770417 12690 net.cpp:127] Setting up fire6/expand3x3
I1028 19:00:29.770427 12690 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 19:00:29.770447 12690 net.cpp:144] Memory required for data: 1301113400
I1028 19:00:29.770453 12690 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1028 19:00:29.770459 12690 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1028 19:00:29.770464 12690 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1028 19:00:29.770469 12690 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1028 19:00:29.770473 12690 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I1028 19:00:29.770483 12690 net.cpp:84] Creating Layer fire6/relu_expand3x3
I1028 19:00:29.770488 12690 net.cpp:413] fire6/relu_expand3x3 <- fire6/expand3x3
I1028 19:00:29.770493 12690 net.cpp:374] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I1028 19:00:29.770705 12690 net.cpp:127] Setting up fire6/relu_expand3x3
I1028 19:00:29.770716 12690 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 19:00:29.770720 12690 net.cpp:144] Memory required for data: 1308639800
I1028 19:00:29.770725 12690 layer_factory.hpp:77] Creating layer fire6/concat
I1028 19:00:29.770730 12690 net.cpp:84] Creating Layer fire6/concat
I1028 19:00:29.770735 12690 net.cpp:413] fire6/concat <- fire6/expand1x1
I1028 19:00:29.770740 12690 net.cpp:413] fire6/concat <- fire6/expand3x3
I1028 19:00:29.770745 12690 net.cpp:387] fire6/concat -> fire6/concat
I1028 19:00:29.770784 12690 net.cpp:127] Setting up fire6/concat
I1028 19:00:29.770790 12690 net.cpp:136] Top shape: 50 384 14 14 (3763200)
I1028 19:00:29.770794 12690 net.cpp:144] Memory required for data: 1323692600
I1028 19:00:29.770797 12690 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I1028 19:00:29.770809 12690 net.cpp:84] Creating Layer fire7/squeeze1x1
I1028 19:00:29.770813 12690 net.cpp:413] fire7/squeeze1x1 <- fire6/concat
I1028 19:00:29.770822 12690 net.cpp:387] fire7/squeeze1x1 -> fire7/squeeze1x1
I1028 19:00:29.771332 12690 net.cpp:127] Setting up fire7/squeeze1x1
I1028 19:00:29.771342 12690 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 19:00:29.771344 12690 net.cpp:144] Memory required for data: 1325574200
I1028 19:00:29.771359 12690 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1028 19:00:29.771370 12690 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1028 19:00:29.771375 12690 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1028 19:00:29.771380 12690 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1028 19:00:29.771384 12690 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I1028 19:00:29.771392 12690 net.cpp:84] Creating Layer fire7/relu_squeeze1x1
I1028 19:00:29.771396 12690 net.cpp:413] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I1028 19:00:29.771404 12690 net.cpp:374] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I1028 19:00:29.771616 12690 net.cpp:127] Setting up fire7/relu_squeeze1x1
I1028 19:00:29.771625 12690 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 19:00:29.771630 12690 net.cpp:144] Memory required for data: 1327455800
I1028 19:00:29.771633 12690 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1028 19:00:29.771641 12690 net.cpp:84] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1028 19:00:29.771646 12690 net.cpp:413] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I1028 19:00:29.771652 12690 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1028 19:00:29.771659 12690 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1028 19:00:29.771711 12690 net.cpp:127] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1028 19:00:29.771718 12690 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 19:00:29.771723 12690 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 19:00:29.771726 12690 net.cpp:144] Memory required for data: 1331219000
I1028 19:00:29.771739 12690 layer_factory.hpp:77] Creating layer fire7/expand1x1
I1028 19:00:29.771750 12690 net.cpp:84] Creating Layer fire7/expand1x1
I1028 19:00:29.771754 12690 net.cpp:413] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1028 19:00:29.771762 12690 net.cpp:387] fire7/expand1x1 -> fire7/expand1x1
I1028 19:00:29.772186 12690 net.cpp:127] Setting up fire7/expand1x1
I1028 19:00:29.772195 12690 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 19:00:29.772199 12690 net.cpp:144] Memory required for data: 1338745400
I1028 19:00:29.772204 12690 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1028 19:00:29.772210 12690 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1028 19:00:29.772215 12690 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1028 19:00:29.772219 12690 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1028 19:00:29.772223 12690 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I1028 19:00:29.772230 12690 net.cpp:84] Creating Layer fire7/relu_expand1x1
I1028 19:00:29.772234 12690 net.cpp:413] fire7/relu_expand1x1 <- fire7/expand1x1
I1028 19:00:29.772241 12690 net.cpp:374] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I1028 19:00:29.773648 12690 net.cpp:127] Setting up fire7/relu_expand1x1
I1028 19:00:29.773661 12690 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 19:00:29.773665 12690 net.cpp:144] Memory required for data: 1346271800
I1028 19:00:29.773670 12690 layer_factory.hpp:77] Creating layer fire7/expand3x3
I1028 19:00:29.773682 12690 net.cpp:84] Creating Layer fire7/expand3x3
I1028 19:00:29.773687 12690 net.cpp:413] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1028 19:00:29.773696 12690 net.cpp:387] fire7/expand3x3 -> fire7/expand3x3
I1028 19:00:29.774758 12690 net.cpp:127] Setting up fire7/expand3x3
I1028 19:00:29.774768 12690 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 19:00:29.774771 12690 net.cpp:144] Memory required for data: 1353798200
I1028 19:00:29.774777 12690 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1028 19:00:29.774783 12690 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1028 19:00:29.774788 12690 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1028 19:00:29.774793 12690 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1028 19:00:29.774797 12690 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I1028 19:00:29.774803 12690 net.cpp:84] Creating Layer fire7/relu_expand3x3
I1028 19:00:29.774808 12690 net.cpp:413] fire7/relu_expand3x3 <- fire7/expand3x3
I1028 19:00:29.774817 12690 net.cpp:374] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I1028 19:00:29.775035 12690 net.cpp:127] Setting up fire7/relu_expand3x3
I1028 19:00:29.775044 12690 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 19:00:29.775048 12690 net.cpp:144] Memory required for data: 1361324600
I1028 19:00:29.775053 12690 layer_factory.hpp:77] Creating layer fire7/concat
I1028 19:00:29.775059 12690 net.cpp:84] Creating Layer fire7/concat
I1028 19:00:29.775064 12690 net.cpp:413] fire7/concat <- fire7/expand1x1
I1028 19:00:29.775069 12690 net.cpp:413] fire7/concat <- fire7/expand3x3
I1028 19:00:29.775080 12690 net.cpp:387] fire7/concat -> fire7/concat
I1028 19:00:29.775112 12690 net.cpp:127] Setting up fire7/concat
I1028 19:00:29.775121 12690 net.cpp:136] Top shape: 50 384 14 14 (3763200)
I1028 19:00:29.775125 12690 net.cpp:144] Memory required for data: 1376377400
I1028 19:00:29.775130 12690 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I1028 19:00:29.775141 12690 net.cpp:84] Creating Layer fire8/squeeze1x1
I1028 19:00:29.775146 12690 net.cpp:413] fire8/squeeze1x1 <- fire7/concat
I1028 19:00:29.775153 12690 net.cpp:387] fire8/squeeze1x1 -> fire8/squeeze1x1
I1028 19:00:29.777102 12690 net.cpp:127] Setting up fire8/squeeze1x1
I1028 19:00:29.777129 12690 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 19:00:29.777133 12690 net.cpp:144] Memory required for data: 1378886200
I1028 19:00:29.777140 12690 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1028 19:00:29.777146 12690 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1028 19:00:29.777151 12690 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1028 19:00:29.777155 12690 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1028 19:00:29.777158 12690 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I1028 19:00:29.777169 12690 net.cpp:84] Creating Layer fire8/relu_squeeze1x1
I1028 19:00:29.777174 12690 net.cpp:413] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I1028 19:00:29.777180 12690 net.cpp:374] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I1028 19:00:29.777415 12690 net.cpp:127] Setting up fire8/relu_squeeze1x1
I1028 19:00:29.777425 12690 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 19:00:29.777428 12690 net.cpp:144] Memory required for data: 1381395000
I1028 19:00:29.777432 12690 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1028 19:00:29.777441 12690 net.cpp:84] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1028 19:00:29.777446 12690 net.cpp:413] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I1028 19:00:29.777451 12690 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1028 19:00:29.777460 12690 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1028 19:00:29.777511 12690 net.cpp:127] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1028 19:00:29.777518 12690 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 19:00:29.777523 12690 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 19:00:29.777525 12690 net.cpp:144] Memory required for data: 1386412600
I1028 19:00:29.777530 12690 layer_factory.hpp:77] Creating layer fire8/expand1x1
I1028 19:00:29.777541 12690 net.cpp:84] Creating Layer fire8/expand1x1
I1028 19:00:29.777546 12690 net.cpp:413] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1028 19:00:29.777554 12690 net.cpp:387] fire8/expand1x1 -> fire8/expand1x1
I1028 19:00:29.778033 12690 net.cpp:127] Setting up fire8/expand1x1
I1028 19:00:29.778041 12690 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 19:00:29.778044 12690 net.cpp:144] Memory required for data: 1396447800
I1028 19:00:29.778050 12690 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1028 19:00:29.778056 12690 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1028 19:00:29.778061 12690 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1028 19:00:29.778065 12690 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1028 19:00:29.778069 12690 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I1028 19:00:29.778077 12690 net.cpp:84] Creating Layer fire8/relu_expand1x1
I1028 19:00:29.778082 12690 net.cpp:413] fire8/relu_expand1x1 <- fire8/expand1x1
I1028 19:00:29.778087 12690 net.cpp:374] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I1028 19:00:29.778306 12690 net.cpp:127] Setting up fire8/relu_expand1x1
I1028 19:00:29.778316 12690 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 19:00:29.778319 12690 net.cpp:144] Memory required for data: 1406483000
I1028 19:00:29.778323 12690 layer_factory.hpp:77] Creating layer fire8/expand3x3
I1028 19:00:29.778337 12690 net.cpp:84] Creating Layer fire8/expand3x3
I1028 19:00:29.778343 12690 net.cpp:413] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1028 19:00:29.778352 12690 net.cpp:387] fire8/expand3x3 -> fire8/expand3x3
I1028 19:00:29.781216 12690 net.cpp:127] Setting up fire8/expand3x3
I1028 19:00:29.781230 12690 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 19:00:29.781246 12690 net.cpp:144] Memory required for data: 1416518200
I1028 19:00:29.781253 12690 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1028 19:00:29.781260 12690 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1028 19:00:29.781263 12690 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1028 19:00:29.781268 12690 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1028 19:00:29.781271 12690 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I1028 19:00:29.781280 12690 net.cpp:84] Creating Layer fire8/relu_expand3x3
I1028 19:00:29.781283 12690 net.cpp:413] fire8/relu_expand3x3 <- fire8/expand3x3
I1028 19:00:29.781293 12690 net.cpp:374] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I1028 19:00:29.782713 12690 net.cpp:127] Setting up fire8/relu_expand3x3
I1028 19:00:29.782728 12690 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 19:00:29.782732 12690 net.cpp:144] Memory required for data: 1426553400
I1028 19:00:29.782738 12690 layer_factory.hpp:77] Creating layer fire8/concat
I1028 19:00:29.782747 12690 net.cpp:84] Creating Layer fire8/concat
I1028 19:00:29.782750 12690 net.cpp:413] fire8/concat <- fire8/expand1x1
I1028 19:00:29.782757 12690 net.cpp:413] fire8/concat <- fire8/expand3x3
I1028 19:00:29.782764 12690 net.cpp:387] fire8/concat -> fire8/concat
I1028 19:00:29.782800 12690 net.cpp:127] Setting up fire8/concat
I1028 19:00:29.782809 12690 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1028 19:00:29.782814 12690 net.cpp:144] Memory required for data: 1446623800
I1028 19:00:29.782816 12690 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I1028 19:00:29.782825 12690 net.cpp:84] Creating Layer fire9/squeeze1x1
I1028 19:00:29.782829 12690 net.cpp:413] fire9/squeeze1x1 <- fire8/concat
I1028 19:00:29.782837 12690 net.cpp:387] fire9/squeeze1x1 -> fire9/squeeze1x1
I1028 19:00:29.783453 12690 net.cpp:127] Setting up fire9/squeeze1x1
I1028 19:00:29.783463 12690 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 19:00:29.783466 12690 net.cpp:144] Memory required for data: 1449132600
I1028 19:00:29.783473 12690 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1028 19:00:29.783478 12690 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1028 19:00:29.783483 12690 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1028 19:00:29.783488 12690 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1028 19:00:29.783490 12690 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I1028 19:00:29.783507 12690 net.cpp:84] Creating Layer fire9/relu_squeeze1x1
I1028 19:00:29.783512 12690 net.cpp:413] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I1028 19:00:29.783519 12690 net.cpp:374] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I1028 19:00:29.783731 12690 net.cpp:127] Setting up fire9/relu_squeeze1x1
I1028 19:00:29.783740 12690 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 19:00:29.783745 12690 net.cpp:144] Memory required for data: 1451641400
I1028 19:00:29.783748 12690 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1028 19:00:29.783756 12690 net.cpp:84] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1028 19:00:29.783759 12690 net.cpp:413] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I1028 19:00:29.783766 12690 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1028 19:00:29.783774 12690 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1028 19:00:29.783828 12690 net.cpp:127] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1028 19:00:29.783834 12690 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 19:00:29.783839 12690 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 19:00:29.783843 12690 net.cpp:144] Memory required for data: 1456659000
I1028 19:00:29.783859 12690 layer_factory.hpp:77] Creating layer fire9/expand1x1
I1028 19:00:29.783872 12690 net.cpp:84] Creating Layer fire9/expand1x1
I1028 19:00:29.783876 12690 net.cpp:413] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1028 19:00:29.783882 12690 net.cpp:387] fire9/expand1x1 -> fire9/expand1x1
I1028 19:00:29.784369 12690 net.cpp:127] Setting up fire9/expand1x1
I1028 19:00:29.784379 12690 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 19:00:29.784382 12690 net.cpp:144] Memory required for data: 1466694200
I1028 19:00:29.784389 12690 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1028 19:00:29.784394 12690 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1028 19:00:29.784399 12690 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1028 19:00:29.784402 12690 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1028 19:00:29.784406 12690 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I1028 19:00:29.784412 12690 net.cpp:84] Creating Layer fire9/relu_expand1x1
I1028 19:00:29.784417 12690 net.cpp:413] fire9/relu_expand1x1 <- fire9/expand1x1
I1028 19:00:29.784422 12690 net.cpp:374] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I1028 19:00:29.784636 12690 net.cpp:127] Setting up fire9/relu_expand1x1
I1028 19:00:29.784644 12690 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 19:00:29.784648 12690 net.cpp:144] Memory required for data: 1476729400
I1028 19:00:29.784651 12690 layer_factory.hpp:77] Creating layer fire9/expand3x3
I1028 19:00:29.784662 12690 net.cpp:84] Creating Layer fire9/expand3x3
I1028 19:00:29.784667 12690 net.cpp:413] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1028 19:00:29.784674 12690 net.cpp:387] fire9/expand3x3 -> fire9/expand3x3
I1028 19:00:29.787544 12690 net.cpp:127] Setting up fire9/expand3x3
I1028 19:00:29.787559 12690 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 19:00:29.787562 12690 net.cpp:144] Memory required for data: 1486764600
I1028 19:00:29.787569 12690 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1028 19:00:29.787575 12690 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1028 19:00:29.787580 12690 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1028 19:00:29.787585 12690 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1028 19:00:29.787587 12690 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I1028 19:00:29.787596 12690 net.cpp:84] Creating Layer fire9/relu_expand3x3
I1028 19:00:29.787601 12690 net.cpp:413] fire9/relu_expand3x3 <- fire9/expand3x3
I1028 19:00:29.787607 12690 net.cpp:374] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I1028 19:00:29.787832 12690 net.cpp:127] Setting up fire9/relu_expand3x3
I1028 19:00:29.787842 12690 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 19:00:29.787845 12690 net.cpp:144] Memory required for data: 1496799800
I1028 19:00:29.787849 12690 layer_factory.hpp:77] Creating layer fire9/concat
I1028 19:00:29.787858 12690 net.cpp:84] Creating Layer fire9/concat
I1028 19:00:29.787861 12690 net.cpp:413] fire9/concat <- fire9/expand1x1
I1028 19:00:29.787868 12690 net.cpp:413] fire9/concat <- fire9/expand3x3
I1028 19:00:29.787873 12690 net.cpp:387] fire9/concat -> fire9/concat
I1028 19:00:29.787907 12690 net.cpp:127] Setting up fire9/concat
I1028 19:00:29.787914 12690 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1028 19:00:29.787917 12690 net.cpp:144] Memory required for data: 1516870200
I1028 19:00:29.787927 12690 layer_factory.hpp:77] Creating layer drop9
I1028 19:00:29.787938 12690 net.cpp:84] Creating Layer drop9
I1028 19:00:29.787942 12690 net.cpp:413] drop9 <- fire9/concat
I1028 19:00:29.787950 12690 net.cpp:374] drop9 -> fire9/concat (in-place)
I1028 19:00:29.787979 12690 net.cpp:127] Setting up drop9
I1028 19:00:29.787987 12690 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1028 19:00:29.788002 12690 net.cpp:144] Memory required for data: 1536940600
I1028 19:00:29.788005 12690 layer_factory.hpp:77] Creating layer conv10
I1028 19:00:29.788014 12690 net.cpp:84] Creating Layer conv10
I1028 19:00:29.788019 12690 net.cpp:413] conv10 <- fire9/concat
I1028 19:00:29.788028 12690 net.cpp:387] conv10 -> conv10
I1028 19:00:29.797611 12690 net.cpp:127] Setting up conv10
I1028 19:00:29.797629 12690 net.cpp:136] Top shape: 50 1000 14 14 (9800000)
I1028 19:00:29.797634 12690 net.cpp:144] Memory required for data: 1576140600
I1028 19:00:29.797641 12690 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1028 19:00:29.797646 12690 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1028 19:00:29.797652 12690 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1028 19:00:29.797657 12690 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1028 19:00:29.797660 12690 layer_factory.hpp:77] Creating layer relu_conv10
I1028 19:00:29.797668 12690 net.cpp:84] Creating Layer relu_conv10
I1028 19:00:29.797673 12690 net.cpp:413] relu_conv10 <- conv10
I1028 19:00:29.797679 12690 net.cpp:374] relu_conv10 -> conv10 (in-place)
I1028 19:00:29.799103 12690 net.cpp:127] Setting up relu_conv10
I1028 19:00:29.799118 12690 net.cpp:136] Top shape: 50 1000 14 14 (9800000)
I1028 19:00:29.799123 12690 net.cpp:144] Memory required for data: 1615340600
I1028 19:00:29.799127 12690 layer_factory.hpp:77] Creating layer pool10
I1028 19:00:29.799137 12690 net.cpp:84] Creating Layer pool10
I1028 19:00:29.799141 12690 net.cpp:413] pool10 <- conv10
I1028 19:00:29.799150 12690 net.cpp:387] pool10 -> pool10
I1028 19:00:29.799381 12690 net.cpp:127] Setting up pool10
I1028 19:00:29.799391 12690 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1028 19:00:29.799394 12690 net.cpp:144] Memory required for data: 1615540600
I1028 19:00:29.799398 12690 layer_factory.hpp:77] Creating layer pool10_pool10_0_split
I1028 19:00:29.799404 12690 net.cpp:84] Creating Layer pool10_pool10_0_split
I1028 19:00:29.799408 12690 net.cpp:413] pool10_pool10_0_split <- pool10
I1028 19:00:29.799417 12690 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_0
I1028 19:00:29.799424 12690 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_1
I1028 19:00:29.799430 12690 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_2
I1028 19:00:29.799496 12690 net.cpp:127] Setting up pool10_pool10_0_split
I1028 19:00:29.799502 12690 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1028 19:00:29.799507 12690 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1028 19:00:29.799512 12690 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1028 19:00:29.799515 12690 net.cpp:144] Memory required for data: 1616140600
I1028 19:00:29.799520 12690 layer_factory.hpp:77] Creating layer loss
I1028 19:00:29.799526 12690 net.cpp:84] Creating Layer loss
I1028 19:00:29.799530 12690 net.cpp:413] loss <- pool10_pool10_0_split_0
I1028 19:00:29.799535 12690 net.cpp:413] loss <- label_data_1_split_0
I1028 19:00:29.799542 12690 net.cpp:387] loss -> loss
I1028 19:00:29.799551 12690 layer_factory.hpp:77] Creating layer loss
I1028 19:00:29.799911 12690 net.cpp:127] Setting up loss
I1028 19:00:29.799927 12690 net.cpp:136] Top shape: (1)
I1028 19:00:29.799932 12690 net.cpp:139]     with loss weight 1
I1028 19:00:29.799943 12690 net.cpp:144] Memory required for data: 1616140604
I1028 19:00:29.799947 12690 layer_factory.hpp:77] Creating layer accuracy_top1
I1028 19:00:29.799958 12690 net.cpp:84] Creating Layer accuracy_top1
I1028 19:00:29.799963 12690 net.cpp:413] accuracy_top1 <- pool10_pool10_0_split_1
I1028 19:00:29.799969 12690 net.cpp:413] accuracy_top1 <- label_data_1_split_1
I1028 19:00:29.799975 12690 net.cpp:387] accuracy_top1 -> accuracy_top1
I1028 19:00:29.799991 12690 net.cpp:127] Setting up accuracy_top1
I1028 19:00:29.799996 12690 net.cpp:136] Top shape: (1)
I1028 19:00:29.800000 12690 net.cpp:144] Memory required for data: 1616140608
I1028 19:00:29.800004 12690 layer_factory.hpp:77] Creating layer accuracy_top5
I1028 19:00:29.800024 12690 net.cpp:84] Creating Layer accuracy_top5
I1028 19:00:29.800029 12690 net.cpp:413] accuracy_top5 <- pool10_pool10_0_split_2
I1028 19:00:29.800034 12690 net.cpp:413] accuracy_top5 <- label_data_1_split_2
I1028 19:00:29.800041 12690 net.cpp:387] accuracy_top5 -> accuracy_top5
I1028 19:00:29.800055 12690 net.cpp:127] Setting up accuracy_top5
I1028 19:00:29.800061 12690 net.cpp:136] Top shape: (1)
I1028 19:00:29.800065 12690 net.cpp:144] Memory required for data: 1616140612
I1028 19:00:29.800068 12690 net.cpp:207] accuracy_top5 does not need backward computation.
I1028 19:00:29.800073 12690 net.cpp:207] accuracy_top1 does not need backward computation.
I1028 19:00:29.800077 12690 net.cpp:205] loss needs backward computation.
I1028 19:00:29.800081 12690 net.cpp:205] pool10_pool10_0_split needs backward computation.
I1028 19:00:29.800086 12690 net.cpp:205] pool10 needs backward computation.
I1028 19:00:29.800089 12690 net.cpp:205] relu_conv10 needs backward computation.
I1028 19:00:29.800093 12690 net.cpp:205] conv10 needs backward computation.
I1028 19:00:29.800096 12690 net.cpp:205] drop9 needs backward computation.
I1028 19:00:29.800101 12690 net.cpp:205] fire9/concat needs backward computation.
I1028 19:00:29.800104 12690 net.cpp:205] fire9/relu_expand3x3 needs backward computation.
I1028 19:00:29.800108 12690 net.cpp:205] fire9/expand3x3 needs backward computation.
I1028 19:00:29.800112 12690 net.cpp:205] fire9/relu_expand1x1 needs backward computation.
I1028 19:00:29.800117 12690 net.cpp:205] fire9/expand1x1 needs backward computation.
I1028 19:00:29.800120 12690 net.cpp:205] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I1028 19:00:29.800124 12690 net.cpp:205] fire9/relu_squeeze1x1 needs backward computation.
I1028 19:00:29.800128 12690 net.cpp:205] fire9/squeeze1x1 needs backward computation.
I1028 19:00:29.800132 12690 net.cpp:205] fire8/concat needs backward computation.
I1028 19:00:29.800137 12690 net.cpp:205] fire8/relu_expand3x3 needs backward computation.
I1028 19:00:29.800140 12690 net.cpp:205] fire8/expand3x3 needs backward computation.
I1028 19:00:29.800144 12690 net.cpp:205] fire8/relu_expand1x1 needs backward computation.
I1028 19:00:29.800148 12690 net.cpp:205] fire8/expand1x1 needs backward computation.
I1028 19:00:29.800151 12690 net.cpp:205] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I1028 19:00:29.800155 12690 net.cpp:205] fire8/relu_squeeze1x1 needs backward computation.
I1028 19:00:29.800159 12690 net.cpp:205] fire8/squeeze1x1 needs backward computation.
I1028 19:00:29.800164 12690 net.cpp:205] fire7/concat needs backward computation.
I1028 19:00:29.800169 12690 net.cpp:205] fire7/relu_expand3x3 needs backward computation.
I1028 19:00:29.800173 12690 net.cpp:205] fire7/expand3x3 needs backward computation.
I1028 19:00:29.800176 12690 net.cpp:205] fire7/relu_expand1x1 needs backward computation.
I1028 19:00:29.800179 12690 net.cpp:205] fire7/expand1x1 needs backward computation.
I1028 19:00:29.800184 12690 net.cpp:205] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I1028 19:00:29.800187 12690 net.cpp:205] fire7/relu_squeeze1x1 needs backward computation.
I1028 19:00:29.800191 12690 net.cpp:205] fire7/squeeze1x1 needs backward computation.
I1028 19:00:29.800194 12690 net.cpp:205] fire6/concat needs backward computation.
I1028 19:00:29.800199 12690 net.cpp:205] fire6/relu_expand3x3 needs backward computation.
I1028 19:00:29.800202 12690 net.cpp:205] fire6/expand3x3 needs backward computation.
I1028 19:00:29.800205 12690 net.cpp:205] fire6/relu_expand1x1 needs backward computation.
I1028 19:00:29.800209 12690 net.cpp:205] fire6/expand1x1 needs backward computation.
I1028 19:00:29.800215 12690 net.cpp:205] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I1028 19:00:29.800220 12690 net.cpp:205] fire6/relu_squeeze1x1 needs backward computation.
I1028 19:00:29.800223 12690 net.cpp:205] fire6/squeeze1x1 needs backward computation.
I1028 19:00:29.800227 12690 net.cpp:205] pool5 needs backward computation.
I1028 19:00:29.800235 12690 net.cpp:205] fire5/concat needs backward computation.
I1028 19:00:29.800240 12690 net.cpp:205] fire5/relu_expand3x3 needs backward computation.
I1028 19:00:29.800243 12690 net.cpp:205] fire5/expand3x3 needs backward computation.
I1028 19:00:29.800247 12690 net.cpp:205] fire5/relu_expand1x1 needs backward computation.
I1028 19:00:29.800251 12690 net.cpp:205] fire5/expand1x1 needs backward computation.
I1028 19:00:29.800254 12690 net.cpp:205] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I1028 19:00:29.800257 12690 net.cpp:205] fire5/relu_squeeze1x1 needs backward computation.
I1028 19:00:29.800261 12690 net.cpp:205] fire5/squeeze1x1 needs backward computation.
I1028 19:00:29.800266 12690 net.cpp:205] fire4/concat needs backward computation.
I1028 19:00:29.800269 12690 net.cpp:205] fire4/relu_expand3x3 needs backward computation.
I1028 19:00:29.800272 12690 net.cpp:205] fire4/expand3x3 needs backward computation.
I1028 19:00:29.800276 12690 net.cpp:205] fire4/relu_expand1x1 needs backward computation.
I1028 19:00:29.800279 12690 net.cpp:205] fire4/expand1x1 needs backward computation.
I1028 19:00:29.800283 12690 net.cpp:205] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I1028 19:00:29.800287 12690 net.cpp:205] fire4/relu_squeeze1x1 needs backward computation.
I1028 19:00:29.800290 12690 net.cpp:205] fire4/squeeze1x1 needs backward computation.
I1028 19:00:29.800294 12690 net.cpp:205] pool3 needs backward computation.
I1028 19:00:29.800297 12690 net.cpp:205] fire3/concat needs backward computation.
I1028 19:00:29.800302 12690 net.cpp:205] fire3/relu_expand3x3 needs backward computation.
I1028 19:00:29.800305 12690 net.cpp:205] fire3/expand3x3 needs backward computation.
I1028 19:00:29.800308 12690 net.cpp:205] fire3/relu_expand1x1 needs backward computation.
I1028 19:00:29.800312 12690 net.cpp:205] fire3/expand1x1 needs backward computation.
I1028 19:00:29.800317 12690 net.cpp:205] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I1028 19:00:29.800319 12690 net.cpp:205] fire3/relu_squeeze1x1 needs backward computation.
I1028 19:00:29.800323 12690 net.cpp:205] fire3/squeeze1x1 needs backward computation.
I1028 19:00:29.800326 12690 net.cpp:205] fire2/concat needs backward computation.
I1028 19:00:29.800330 12690 net.cpp:205] fire2/relu_expand3x3 needs backward computation.
I1028 19:00:29.800336 12690 net.cpp:205] fire2/expand3x3 needs backward computation.
I1028 19:00:29.800340 12690 net.cpp:205] fire2/relu_expand1x1 needs backward computation.
I1028 19:00:29.800343 12690 net.cpp:205] fire2/expand1x1 needs backward computation.
I1028 19:00:29.800348 12690 net.cpp:205] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I1028 19:00:29.800350 12690 net.cpp:205] fire2/relu_squeeze1x1 needs backward computation.
I1028 19:00:29.800354 12690 net.cpp:205] fire2/squeeze1x1 needs backward computation.
I1028 19:00:29.800359 12690 net.cpp:205] pool1 needs backward computation.
I1028 19:00:29.800362 12690 net.cpp:205] relu_conv1 needs backward computation.
I1028 19:00:29.800365 12690 net.cpp:205] conv1 needs backward computation.
I1028 19:00:29.800370 12690 net.cpp:207] label_data_1_split does not need backward computation.
I1028 19:00:29.800375 12690 net.cpp:207] data does not need backward computation.
I1028 19:00:29.800379 12690 net.cpp:249] This network produces output accuracy_top1
I1028 19:00:29.800384 12690 net.cpp:249] This network produces output accuracy_top5
I1028 19:00:29.800387 12690 net.cpp:249] This network produces output loss
I1028 19:00:29.800442 12690 net.cpp:262] Network initialization done.
I1028 19:00:29.800741 12690 solver.cpp:56] Solver scaffolding done.
I1028 19:00:29.805312 12690 caffe.cpp:242] Resuming from SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_3112.solverstate
I1028 19:00:29.836195 12690 sgd_solver.cpp:372] SGDSolver: restoring history
I1028 19:00:29.851326 12690 caffe.cpp:248] Starting Optimization
I1028 19:00:33.616075 12740 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_40.prototxt
I1028 19:00:33.619540 12741 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_40.prototxt
I1028 19:00:33.627221 12739 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_40.prototxt
I1028 19:00:34.337651 12740 sgd_solver.cpp:372] SGDSolver: restoring history
I1028 19:00:34.341724 12741 sgd_solver.cpp:372] SGDSolver: restoring history
I1028 19:00:34.345095 12739 sgd_solver.cpp:372] SGDSolver: restoring history
I1028 19:00:34.645829 12690 solver.cpp:276] Solving SqueezeNet
I1028 19:00:34.645877 12690 solver.cpp:277] Learning Rate Policy: exp
I1028 19:00:41.993432 12690 solver.cpp:222] Iteration 3120 (424.71 iter/s, 7.34619s/40 iters), loss = 1.64745
I1028 19:00:41.993500 12690 solver.cpp:241]     Train net output #0: loss = 1.64745 (* 1 = 1.64745 loss)
I1028 19:00:41.993522 12690 sgd_solver.cpp:105] Iteration 3120, lr = 0.00731932
I1028 19:01:12.306514 12690 solver.cpp:222] Iteration 3160 (1.31959 iter/s, 30.3124s/40 iters), loss = 1.35546
I1028 19:01:12.306690 12690 solver.cpp:241]     Train net output #0: loss = 1.35546 (* 1 = 1.35546 loss)
I1028 19:01:12.306705 12690 sgd_solver.cpp:105] Iteration 3160, lr = 0.0072901
I1028 19:01:41.721051 12690 solver.cpp:222] Iteration 3200 (1.35991 iter/s, 29.4137s/40 iters), loss = 1.4688
I1028 19:01:41.721130 12690 solver.cpp:241]     Train net output #0: loss = 1.4688 (* 1 = 1.4688 loss)
I1028 19:01:41.721143 12690 sgd_solver.cpp:105] Iteration 3200, lr = 0.00726099
I1028 19:02:11.142320 12690 solver.cpp:222] Iteration 3240 (1.3596 iter/s, 29.4205s/40 iters), loss = 1.56677
I1028 19:02:11.142535 12690 solver.cpp:241]     Train net output #0: loss = 1.56677 (* 1 = 1.56677 loss)
I1028 19:02:11.142549 12690 sgd_solver.cpp:105] Iteration 3240, lr = 0.007232
I1028 19:02:40.527812 12690 solver.cpp:222] Iteration 3280 (1.36126 iter/s, 29.3846s/40 iters), loss = 1.63069
I1028 19:02:40.527871 12690 solver.cpp:241]     Train net output #0: loss = 1.63069 (* 1 = 1.63069 loss)
I1028 19:02:40.527884 12690 sgd_solver.cpp:105] Iteration 3280, lr = 0.00720312
I1028 19:03:10.026388 12690 solver.cpp:222] Iteration 3320 (1.35603 iter/s, 29.4978s/40 iters), loss = 1.54172
I1028 19:03:10.026536 12690 solver.cpp:241]     Train net output #0: loss = 1.54172 (* 1 = 1.54172 loss)
I1028 19:03:10.026551 12690 sgd_solver.cpp:105] Iteration 3320, lr = 0.00717436
I1028 19:03:39.441840 12690 solver.cpp:222] Iteration 3360 (1.35987 iter/s, 29.4146s/40 iters), loss = 1.60275
I1028 19:03:39.441898 12690 solver.cpp:241]     Train net output #0: loss = 1.60275 (* 1 = 1.60275 loss)
I1028 19:03:39.441910 12690 sgd_solver.cpp:105] Iteration 3360, lr = 0.00714571
I1028 19:04:08.818665 12690 solver.cpp:222] Iteration 3400 (1.36165 iter/s, 29.3761s/40 iters), loss = 1.69448
I1028 19:04:08.818807 12690 solver.cpp:241]     Train net output #0: loss = 1.69448 (* 1 = 1.69448 loss)
I1028 19:04:08.818821 12690 sgd_solver.cpp:105] Iteration 3400, lr = 0.00711718
I1028 19:04:38.158573 12690 solver.cpp:222] Iteration 3440 (1.36337 iter/s, 29.3391s/40 iters), loss = 1.70422
I1028 19:04:38.158629 12690 solver.cpp:241]     Train net output #0: loss = 1.70422 (* 1 = 1.70422 loss)
I1028 19:04:38.158641 12690 sgd_solver.cpp:105] Iteration 3440, lr = 0.00708876
I1028 19:05:07.464484 12690 solver.cpp:222] Iteration 3480 (1.36495 iter/s, 29.3052s/40 iters), loss = 1.82954
I1028 19:05:07.464574 12690 solver.cpp:241]     Train net output #0: loss = 1.82954 (* 1 = 1.82954 loss)
I1028 19:05:07.464587 12690 sgd_solver.cpp:105] Iteration 3480, lr = 0.00706046
I1028 19:05:21.399049 12690 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_3500.caffemodel
I1028 19:05:21.557448 12690 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_3500.solverstate
I1028 19:05:21.671263 12690 solver.cpp:334] Iteration 3500, Testing net (#0)
I1028 19:05:52.882510 12690 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54156
I1028 19:05:52.882721 12690 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.782
I1028 19:05:52.882736 12690 solver.cpp:401]     Test net output #2: loss = 2.10879 (* 1 = 2.10879 loss)
I1028 19:06:09.056354 12690 solver.cpp:222] Iteration 3520 (0.649453 iter/s, 61.5903s/40 iters), loss = 1.38277
I1028 19:06:09.056413 12690 solver.cpp:241]     Train net output #0: loss = 1.38277 (* 1 = 1.38277 loss)
I1028 19:06:09.056427 12690 sgd_solver.cpp:105] Iteration 3520, lr = 0.00703227
I1028 19:06:39.332000 12690 solver.cpp:222] Iteration 3560 (1.32123 iter/s, 30.2749s/40 iters), loss = 1.64755
I1028 19:06:39.332175 12690 solver.cpp:241]     Train net output #0: loss = 1.64755 (* 1 = 1.64755 loss)
I1028 19:06:39.332190 12690 sgd_solver.cpp:105] Iteration 3560, lr = 0.00700419
I1028 19:07:00.236119 12690 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_3589.caffemodel
I1028 19:07:00.377539 12690 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_3589.solverstate
I1028 19:07:00.488436 12690 solver.cpp:298] Optimization stopped early.
*** Aborted at 1509232036 (unix time) try "date -d @1509232036" if you are using GNU date ***
PC: @     0x7ff90b2dc705 __pthread_cond_wait
*** SIGTERM (@0x3ed00003107) received by PID 12690 (TID 0x7ff91e351740) from PID 12551; stack trace: ***
    @     0x7ff90b2e0130 (unknown)
    @     0x7ff90b2dc705 __pthread_cond_wait
    @     0x7ff91d636804 boost::condition_variable::wait()
    @     0x7ff913ba68d4 boost::thread::join_noexcept()
    @     0x7ff91d621b8a caffe::InternalThread::StopInternalThread()
    @     0x7ff91d63a302 caffe::NCCL<>::Run()
    @           0x40adef train()
    @           0x4082ec main
    @     0x7ff90af31af5 __libc_start_main
    @           0x408bf5 (unknown)
nohup: ignoring input
I1028 19:08:04.339294 12802 caffe.cpp:218] Using GPUs 0, 1, 2, 3
I1028 19:08:04.340041 12802 caffe.cpp:223] GPU 0: Tesla P40
I1028 19:08:04.340438 12802 caffe.cpp:223] GPU 1: Tesla P40
I1028 19:08:04.340832 12802 caffe.cpp:223] GPU 2: Tesla P40
I1028 19:08:04.341228 12802 caffe.cpp:223] GPU 3: Tesla P40
I1028 19:08:05.070983 12802 solver.cpp:44] Initializing solver from parameters: 
test_iter: 500
test_interval: 500
base_lr: 0.01
display: 40
max_iter: 100000
lr_policy: "exp"
gamma: 0.99991
momentum: 0.9
weight_decay: 0.0002
snapshot: 500
snapshot_prefix: "SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp"
solver_mode: GPU
device_id: 0
random_seed: 42
net: "SqueezeNet/SqueezeNet_v1.1/train_val_inq_40.prototxt"
train_state {
  level: 0
  stage: ""
}
I1028 19:08:05.072515 12802 solver.cpp:87] Creating training net from net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_40.prototxt
I1028 19:08:05.076167 12802 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1028 19:08:05.076277 12802 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top1
I1028 19:08:05.076287 12802 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top5
I1028 19:08:05.077452 12802 net.cpp:51] Initializing net from parameters: 
name: "SqueezeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/data/caffe-imagenet/ilsvrc12_train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "INQConvolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "fire3/concat"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire4/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool3"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "fire5/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire4/concat"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "fire5/concat"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire6/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool5"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "fire9/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire8/concat"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "INQConvolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "pool10"
  bottom: "label"
  top: "loss"
}
I1028 19:08:05.078090 12802 layer_factory.hpp:77] Creating layer data
I1028 19:08:05.078301 12802 db_lmdb.cpp:35] Opened lmdb /home/data/caffe-imagenet/ilsvrc12_train_lmdb
I1028 19:08:05.078367 12802 net.cpp:84] Creating Layer data
I1028 19:08:05.078383 12802 net.cpp:387] data -> data
I1028 19:08:05.078421 12802 net.cpp:387] data -> label
I1028 19:08:05.080914 12802 data_layer.cpp:45] output data size: 128,3,227,227
I1028 19:08:05.304942 12802 net.cpp:127] Setting up data
I1028 19:08:05.304988 12802 net.cpp:136] Top shape: 128 3 227 227 (19787136)
I1028 19:08:05.304996 12802 net.cpp:136] Top shape: 128 (128)
I1028 19:08:05.304999 12802 net.cpp:144] Memory required for data: 79149056
I1028 19:08:05.305012 12802 layer_factory.hpp:77] Creating layer conv1
I1028 19:08:05.305037 12802 net.cpp:84] Creating Layer conv1
I1028 19:08:05.305044 12802 net.cpp:413] conv1 <- data
I1028 19:08:05.305063 12802 net.cpp:387] conv1 -> conv1
I1028 19:08:05.308329 12802 net.cpp:127] Setting up conv1
I1028 19:08:05.308346 12802 net.cpp:136] Top shape: 128 64 113 113 (104603648)
I1028 19:08:05.308351 12802 net.cpp:144] Memory required for data: 497563648
I1028 19:08:05.308370 12802 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1028 19:08:05.308380 12802 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1028 19:08:05.308388 12802 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1028 19:08:05.308394 12802 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1028 19:08:05.308399 12802 layer_factory.hpp:77] Creating layer relu_conv1
I1028 19:08:05.308413 12802 net.cpp:84] Creating Layer relu_conv1
I1028 19:08:05.308418 12802 net.cpp:413] relu_conv1 <- conv1
I1028 19:08:05.308424 12802 net.cpp:374] relu_conv1 -> conv1 (in-place)
I1028 19:08:05.760257 12802 net.cpp:127] Setting up relu_conv1
I1028 19:08:05.760306 12802 net.cpp:136] Top shape: 128 64 113 113 (104603648)
I1028 19:08:05.760316 12802 net.cpp:144] Memory required for data: 915978240
I1028 19:08:05.760329 12802 layer_factory.hpp:77] Creating layer pool1
I1028 19:08:05.760352 12802 net.cpp:84] Creating Layer pool1
I1028 19:08:05.760361 12802 net.cpp:413] pool1 <- conv1
I1028 19:08:05.760378 12802 net.cpp:387] pool1 -> pool1
I1028 19:08:05.760502 12802 net.cpp:127] Setting up pool1
I1028 19:08:05.760515 12802 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 19:08:05.760562 12802 net.cpp:144] Memory required for data: 1018738688
I1028 19:08:05.760571 12802 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I1028 19:08:05.760593 12802 net.cpp:84] Creating Layer fire2/squeeze1x1
I1028 19:08:05.760601 12802 net.cpp:413] fire2/squeeze1x1 <- pool1
I1028 19:08:05.760613 12802 net.cpp:387] fire2/squeeze1x1 -> fire2/squeeze1x1
I1028 19:08:05.763232 12802 net.cpp:127] Setting up fire2/squeeze1x1
I1028 19:08:05.763259 12802 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 19:08:05.763267 12802 net.cpp:144] Memory required for data: 1044428800
I1028 19:08:05.763285 12802 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1028 19:08:05.763300 12802 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1028 19:08:05.763310 12802 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1028 19:08:05.763319 12802 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1028 19:08:05.763325 12802 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I1028 19:08:05.763339 12802 net.cpp:84] Creating Layer fire2/relu_squeeze1x1
I1028 19:08:05.763347 12802 net.cpp:413] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I1028 19:08:05.763358 12802 net.cpp:374] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I1028 19:08:05.765727 12802 net.cpp:127] Setting up fire2/relu_squeeze1x1
I1028 19:08:05.765751 12802 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 19:08:05.765759 12802 net.cpp:144] Memory required for data: 1070118912
I1028 19:08:05.765769 12802 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1028 19:08:05.765791 12802 net.cpp:84] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1028 19:08:05.765799 12802 net.cpp:413] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I1028 19:08:05.765811 12802 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1028 19:08:05.765826 12802 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1028 19:08:05.765907 12802 net.cpp:127] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1028 19:08:05.765934 12802 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 19:08:05.765944 12802 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 19:08:05.765951 12802 net.cpp:144] Memory required for data: 1121499136
I1028 19:08:05.765959 12802 layer_factory.hpp:77] Creating layer fire2/expand1x1
I1028 19:08:05.765974 12802 net.cpp:84] Creating Layer fire2/expand1x1
I1028 19:08:05.765981 12802 net.cpp:413] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1028 19:08:05.765993 12802 net.cpp:387] fire2/expand1x1 -> fire2/expand1x1
I1028 19:08:05.766536 12802 net.cpp:127] Setting up fire2/expand1x1
I1028 19:08:05.766549 12802 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 19:08:05.766556 12802 net.cpp:144] Memory required for data: 1224259584
I1028 19:08:05.766569 12802 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1028 19:08:05.766582 12802 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1028 19:08:05.766592 12802 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1028 19:08:05.766599 12802 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1028 19:08:05.766605 12802 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I1028 19:08:05.766618 12802 net.cpp:84] Creating Layer fire2/relu_expand1x1
I1028 19:08:05.766625 12802 net.cpp:413] fire2/relu_expand1x1 <- fire2/expand1x1
I1028 19:08:05.766634 12802 net.cpp:374] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I1028 19:08:05.766952 12802 net.cpp:127] Setting up fire2/relu_expand1x1
I1028 19:08:05.766966 12802 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 19:08:05.766973 12802 net.cpp:144] Memory required for data: 1327020032
I1028 19:08:05.767000 12802 layer_factory.hpp:77] Creating layer fire2/expand3x3
I1028 19:08:05.767014 12802 net.cpp:84] Creating Layer fire2/expand3x3
I1028 19:08:05.767021 12802 net.cpp:413] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1028 19:08:05.767033 12802 net.cpp:387] fire2/expand3x3 -> fire2/expand3x3
I1028 19:08:05.767684 12802 net.cpp:127] Setting up fire2/expand3x3
I1028 19:08:05.767699 12802 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 19:08:05.767705 12802 net.cpp:144] Memory required for data: 1429780480
I1028 19:08:05.767715 12802 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1028 19:08:05.767724 12802 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1028 19:08:05.767734 12802 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1028 19:08:05.767740 12802 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1028 19:08:05.767746 12802 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I1028 19:08:05.767756 12802 net.cpp:84] Creating Layer fire2/relu_expand3x3
I1028 19:08:05.767763 12802 net.cpp:413] fire2/relu_expand3x3 <- fire2/expand3x3
I1028 19:08:05.767773 12802 net.cpp:374] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I1028 19:08:05.768090 12802 net.cpp:127] Setting up fire2/relu_expand3x3
I1028 19:08:05.768105 12802 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 19:08:05.768111 12802 net.cpp:144] Memory required for data: 1532540928
I1028 19:08:05.768118 12802 layer_factory.hpp:77] Creating layer fire2/concat
I1028 19:08:05.768133 12802 net.cpp:84] Creating Layer fire2/concat
I1028 19:08:05.768146 12802 net.cpp:413] fire2/concat <- fire2/expand1x1
I1028 19:08:05.768154 12802 net.cpp:413] fire2/concat <- fire2/expand3x3
I1028 19:08:05.768164 12802 net.cpp:387] fire2/concat -> fire2/concat
I1028 19:08:05.768213 12802 net.cpp:127] Setting up fire2/concat
I1028 19:08:05.768224 12802 net.cpp:136] Top shape: 128 128 56 56 (51380224)
I1028 19:08:05.768230 12802 net.cpp:144] Memory required for data: 1738061824
I1028 19:08:05.768236 12802 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I1028 19:08:05.768249 12802 net.cpp:84] Creating Layer fire3/squeeze1x1
I1028 19:08:05.768255 12802 net.cpp:413] fire3/squeeze1x1 <- fire2/concat
I1028 19:08:05.768270 12802 net.cpp:387] fire3/squeeze1x1 -> fire3/squeeze1x1
I1028 19:08:05.768777 12802 net.cpp:127] Setting up fire3/squeeze1x1
I1028 19:08:05.768790 12802 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 19:08:05.768797 12802 net.cpp:144] Memory required for data: 1763751936
I1028 19:08:05.768810 12802 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1028 19:08:05.768822 12802 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1028 19:08:05.768831 12802 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1028 19:08:05.768838 12802 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1028 19:08:05.768844 12802 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I1028 19:08:05.768854 12802 net.cpp:84] Creating Layer fire3/relu_squeeze1x1
I1028 19:08:05.768862 12802 net.cpp:413] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I1028 19:08:05.768870 12802 net.cpp:374] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I1028 19:08:05.771073 12802 net.cpp:127] Setting up fire3/relu_squeeze1x1
I1028 19:08:05.771096 12802 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 19:08:05.771103 12802 net.cpp:144] Memory required for data: 1789442048
I1028 19:08:05.771111 12802 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1028 19:08:05.771122 12802 net.cpp:84] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1028 19:08:05.771131 12802 net.cpp:413] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I1028 19:08:05.771142 12802 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1028 19:08:05.771176 12802 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1028 19:08:05.771250 12802 net.cpp:127] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1028 19:08:05.771260 12802 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 19:08:05.771268 12802 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 19:08:05.771275 12802 net.cpp:144] Memory required for data: 1840822272
I1028 19:08:05.771281 12802 layer_factory.hpp:77] Creating layer fire3/expand1x1
I1028 19:08:05.771294 12802 net.cpp:84] Creating Layer fire3/expand1x1
I1028 19:08:05.771301 12802 net.cpp:413] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1028 19:08:05.771312 12802 net.cpp:387] fire3/expand1x1 -> fire3/expand1x1
I1028 19:08:05.771811 12802 net.cpp:127] Setting up fire3/expand1x1
I1028 19:08:05.771824 12802 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 19:08:05.771831 12802 net.cpp:144] Memory required for data: 1943582720
I1028 19:08:05.771842 12802 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1028 19:08:05.771852 12802 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1028 19:08:05.771859 12802 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1028 19:08:05.771867 12802 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1028 19:08:05.771873 12802 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I1028 19:08:05.771885 12802 net.cpp:84] Creating Layer fire3/relu_expand1x1
I1028 19:08:05.771893 12802 net.cpp:413] fire3/relu_expand1x1 <- fire3/expand1x1
I1028 19:08:05.771908 12802 net.cpp:374] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I1028 19:08:05.772224 12802 net.cpp:127] Setting up fire3/relu_expand1x1
I1028 19:08:05.772239 12802 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 19:08:05.772246 12802 net.cpp:144] Memory required for data: 2046343168
I1028 19:08:05.772253 12802 layer_factory.hpp:77] Creating layer fire3/expand3x3
I1028 19:08:05.772266 12802 net.cpp:84] Creating Layer fire3/expand3x3
I1028 19:08:05.772274 12802 net.cpp:413] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1028 19:08:05.772284 12802 net.cpp:387] fire3/expand3x3 -> fire3/expand3x3
I1028 19:08:05.772949 12802 net.cpp:127] Setting up fire3/expand3x3
I1028 19:08:05.772966 12802 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 19:08:05.772974 12802 net.cpp:144] Memory required for data: 2149103616
I1028 19:08:05.772982 12802 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1028 19:08:05.772992 12802 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1028 19:08:05.773000 12802 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1028 19:08:05.773007 12802 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1028 19:08:05.773013 12802 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I1028 19:08:05.773023 12802 net.cpp:84] Creating Layer fire3/relu_expand3x3
I1028 19:08:05.773030 12802 net.cpp:413] fire3/relu_expand3x3 <- fire3/expand3x3
I1028 19:08:05.773039 12802 net.cpp:374] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I1028 19:08:05.773368 12802 net.cpp:127] Setting up fire3/relu_expand3x3
I1028 19:08:05.773385 12802 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 19:08:05.773391 12802 net.cpp:144] Memory required for data: 2251864064
I1028 19:08:05.773397 12802 layer_factory.hpp:77] Creating layer fire3/concat
I1028 19:08:05.773406 12802 net.cpp:84] Creating Layer fire3/concat
I1028 19:08:05.773413 12802 net.cpp:413] fire3/concat <- fire3/expand1x1
I1028 19:08:05.773422 12802 net.cpp:413] fire3/concat <- fire3/expand3x3
I1028 19:08:05.773432 12802 net.cpp:387] fire3/concat -> fire3/concat
I1028 19:08:05.773478 12802 net.cpp:127] Setting up fire3/concat
I1028 19:08:05.773488 12802 net.cpp:136] Top shape: 128 128 56 56 (51380224)
I1028 19:08:05.773511 12802 net.cpp:144] Memory required for data: 2457384960
I1028 19:08:05.773519 12802 layer_factory.hpp:77] Creating layer pool3
I1028 19:08:05.773531 12802 net.cpp:84] Creating Layer pool3
I1028 19:08:05.773538 12802 net.cpp:413] pool3 <- fire3/concat
I1028 19:08:05.773547 12802 net.cpp:387] pool3 -> pool3
I1028 19:08:05.773619 12802 net.cpp:127] Setting up pool3
I1028 19:08:05.773630 12802 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 19:08:05.773636 12802 net.cpp:144] Memory required for data: 2508765184
I1028 19:08:05.773643 12802 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I1028 19:08:05.773658 12802 net.cpp:84] Creating Layer fire4/squeeze1x1
I1028 19:08:05.773664 12802 net.cpp:413] fire4/squeeze1x1 <- pool3
I1028 19:08:05.773676 12802 net.cpp:387] fire4/squeeze1x1 -> fire4/squeeze1x1
I1028 19:08:05.774252 12802 net.cpp:127] Setting up fire4/squeeze1x1
I1028 19:08:05.774266 12802 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 19:08:05.774272 12802 net.cpp:144] Memory required for data: 2521610240
I1028 19:08:05.774281 12802 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1028 19:08:05.774291 12802 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1028 19:08:05.774298 12802 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1028 19:08:05.774307 12802 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1028 19:08:05.774312 12802 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I1028 19:08:05.774322 12802 net.cpp:84] Creating Layer fire4/relu_squeeze1x1
I1028 19:08:05.774333 12802 net.cpp:413] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I1028 19:08:05.774343 12802 net.cpp:374] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I1028 19:08:05.774689 12802 net.cpp:127] Setting up fire4/relu_squeeze1x1
I1028 19:08:05.774703 12802 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 19:08:05.774709 12802 net.cpp:144] Memory required for data: 2534455296
I1028 19:08:05.774715 12802 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1028 19:08:05.774727 12802 net.cpp:84] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1028 19:08:05.774734 12802 net.cpp:413] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I1028 19:08:05.774746 12802 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1028 19:08:05.774757 12802 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1028 19:08:05.774826 12802 net.cpp:127] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1028 19:08:05.774835 12802 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 19:08:05.774843 12802 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 19:08:05.774848 12802 net.cpp:144] Memory required for data: 2560145408
I1028 19:08:05.774854 12802 layer_factory.hpp:77] Creating layer fire4/expand1x1
I1028 19:08:05.774869 12802 net.cpp:84] Creating Layer fire4/expand1x1
I1028 19:08:05.774875 12802 net.cpp:413] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1028 19:08:05.774893 12802 net.cpp:387] fire4/expand1x1 -> fire4/expand1x1
I1028 19:08:05.775449 12802 net.cpp:127] Setting up fire4/expand1x1
I1028 19:08:05.775462 12802 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 19:08:05.775468 12802 net.cpp:144] Memory required for data: 2611525632
I1028 19:08:05.775485 12802 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1028 19:08:05.775501 12802 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1028 19:08:05.775508 12802 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1028 19:08:05.775516 12802 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1028 19:08:05.775522 12802 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I1028 19:08:05.775552 12802 net.cpp:84] Creating Layer fire4/relu_expand1x1
I1028 19:08:05.775559 12802 net.cpp:413] fire4/relu_expand1x1 <- fire4/expand1x1
I1028 19:08:05.775569 12802 net.cpp:374] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I1028 19:08:05.777719 12802 net.cpp:127] Setting up fire4/relu_expand1x1
I1028 19:08:05.777741 12802 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 19:08:05.777748 12802 net.cpp:144] Memory required for data: 2662905856
I1028 19:08:05.777755 12802 layer_factory.hpp:77] Creating layer fire4/expand3x3
I1028 19:08:05.777773 12802 net.cpp:84] Creating Layer fire4/expand3x3
I1028 19:08:05.777781 12802 net.cpp:413] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1028 19:08:05.777792 12802 net.cpp:387] fire4/expand3x3 -> fire4/expand3x3
I1028 19:08:05.780517 12802 net.cpp:127] Setting up fire4/expand3x3
I1028 19:08:05.780539 12802 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 19:08:05.780545 12802 net.cpp:144] Memory required for data: 2714286080
I1028 19:08:05.780555 12802 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1028 19:08:05.780565 12802 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1028 19:08:05.780571 12802 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1028 19:08:05.780578 12802 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1028 19:08:05.780583 12802 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I1028 19:08:05.780594 12802 net.cpp:84] Creating Layer fire4/relu_expand3x3
I1028 19:08:05.780601 12802 net.cpp:413] fire4/relu_expand3x3 <- fire4/expand3x3
I1028 19:08:05.780618 12802 net.cpp:374] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I1028 19:08:05.780980 12802 net.cpp:127] Setting up fire4/relu_expand3x3
I1028 19:08:05.780997 12802 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 19:08:05.781004 12802 net.cpp:144] Memory required for data: 2765666304
I1028 19:08:05.781010 12802 layer_factory.hpp:77] Creating layer fire4/concat
I1028 19:08:05.781023 12802 net.cpp:84] Creating Layer fire4/concat
I1028 19:08:05.781030 12802 net.cpp:413] fire4/concat <- fire4/expand1x1
I1028 19:08:05.781038 12802 net.cpp:413] fire4/concat <- fire4/expand3x3
I1028 19:08:05.781047 12802 net.cpp:387] fire4/concat -> fire4/concat
I1028 19:08:05.781092 12802 net.cpp:127] Setting up fire4/concat
I1028 19:08:05.781102 12802 net.cpp:136] Top shape: 128 256 28 28 (25690112)
I1028 19:08:05.781107 12802 net.cpp:144] Memory required for data: 2868426752
I1028 19:08:05.781113 12802 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I1028 19:08:05.781131 12802 net.cpp:84] Creating Layer fire5/squeeze1x1
I1028 19:08:05.781137 12802 net.cpp:413] fire5/squeeze1x1 <- fire4/concat
I1028 19:08:05.781147 12802 net.cpp:387] fire5/squeeze1x1 -> fire5/squeeze1x1
I1028 19:08:05.781741 12802 net.cpp:127] Setting up fire5/squeeze1x1
I1028 19:08:05.781754 12802 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 19:08:05.781759 12802 net.cpp:144] Memory required for data: 2881271808
I1028 19:08:05.781769 12802 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1028 19:08:05.781777 12802 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1028 19:08:05.781785 12802 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1028 19:08:05.781791 12802 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1028 19:08:05.781796 12802 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I1028 19:08:05.781807 12802 net.cpp:84] Creating Layer fire5/relu_squeeze1x1
I1028 19:08:05.781814 12802 net.cpp:413] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I1028 19:08:05.781826 12802 net.cpp:374] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I1028 19:08:05.782152 12802 net.cpp:127] Setting up fire5/relu_squeeze1x1
I1028 19:08:05.782166 12802 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 19:08:05.782191 12802 net.cpp:144] Memory required for data: 2894116864
I1028 19:08:05.782198 12802 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1028 19:08:05.782210 12802 net.cpp:84] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1028 19:08:05.782217 12802 net.cpp:413] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I1028 19:08:05.782227 12802 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1028 19:08:05.782236 12802 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1028 19:08:05.782308 12802 net.cpp:127] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1028 19:08:05.782318 12802 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 19:08:05.782326 12802 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 19:08:05.782331 12802 net.cpp:144] Memory required for data: 2919806976
I1028 19:08:05.782337 12802 layer_factory.hpp:77] Creating layer fire5/expand1x1
I1028 19:08:05.782356 12802 net.cpp:84] Creating Layer fire5/expand1x1
I1028 19:08:05.782362 12802 net.cpp:413] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1028 19:08:05.782375 12802 net.cpp:387] fire5/expand1x1 -> fire5/expand1x1
I1028 19:08:05.782902 12802 net.cpp:127] Setting up fire5/expand1x1
I1028 19:08:05.782914 12802 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 19:08:05.782927 12802 net.cpp:144] Memory required for data: 2971187200
I1028 19:08:05.782937 12802 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1028 19:08:05.782945 12802 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1028 19:08:05.782958 12802 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1028 19:08:05.782964 12802 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1028 19:08:05.782969 12802 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I1028 19:08:05.782981 12802 net.cpp:84] Creating Layer fire5/relu_expand1x1
I1028 19:08:05.782989 12802 net.cpp:413] fire5/relu_expand1x1 <- fire5/expand1x1
I1028 19:08:05.782996 12802 net.cpp:374] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I1028 19:08:05.783310 12802 net.cpp:127] Setting up fire5/relu_expand1x1
I1028 19:08:05.783324 12802 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 19:08:05.783330 12802 net.cpp:144] Memory required for data: 3022567424
I1028 19:08:05.783336 12802 layer_factory.hpp:77] Creating layer fire5/expand3x3
I1028 19:08:05.783352 12802 net.cpp:84] Creating Layer fire5/expand3x3
I1028 19:08:05.783360 12802 net.cpp:413] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1028 19:08:05.783370 12802 net.cpp:387] fire5/expand3x3 -> fire5/expand3x3
I1028 19:08:05.784314 12802 net.cpp:127] Setting up fire5/expand3x3
I1028 19:08:05.784327 12802 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 19:08:05.784333 12802 net.cpp:144] Memory required for data: 3073947648
I1028 19:08:05.784343 12802 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1028 19:08:05.784350 12802 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1028 19:08:05.784358 12802 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1028 19:08:05.784364 12802 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1028 19:08:05.784370 12802 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I1028 19:08:05.784379 12802 net.cpp:84] Creating Layer fire5/relu_expand3x3
I1028 19:08:05.784385 12802 net.cpp:413] fire5/relu_expand3x3 <- fire5/expand3x3
I1028 19:08:05.784396 12802 net.cpp:374] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I1028 19:08:05.786517 12802 net.cpp:127] Setting up fire5/relu_expand3x3
I1028 19:08:05.786538 12802 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 19:08:05.786545 12802 net.cpp:144] Memory required for data: 3125327872
I1028 19:08:05.786574 12802 layer_factory.hpp:77] Creating layer fire5/concat
I1028 19:08:05.786584 12802 net.cpp:84] Creating Layer fire5/concat
I1028 19:08:05.786592 12802 net.cpp:413] fire5/concat <- fire5/expand1x1
I1028 19:08:05.786599 12802 net.cpp:413] fire5/concat <- fire5/expand3x3
I1028 19:08:05.786610 12802 net.cpp:387] fire5/concat -> fire5/concat
I1028 19:08:05.786658 12802 net.cpp:127] Setting up fire5/concat
I1028 19:08:05.786667 12802 net.cpp:136] Top shape: 128 256 28 28 (25690112)
I1028 19:08:05.786672 12802 net.cpp:144] Memory required for data: 3228088320
I1028 19:08:05.786677 12802 layer_factory.hpp:77] Creating layer pool5
I1028 19:08:05.786689 12802 net.cpp:84] Creating Layer pool5
I1028 19:08:05.786695 12802 net.cpp:413] pool5 <- fire5/concat
I1028 19:08:05.786705 12802 net.cpp:387] pool5 -> pool5
I1028 19:08:05.786763 12802 net.cpp:127] Setting up pool5
I1028 19:08:05.786772 12802 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 19:08:05.786777 12802 net.cpp:144] Memory required for data: 3253778432
I1028 19:08:05.786782 12802 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I1028 19:08:05.786795 12802 net.cpp:84] Creating Layer fire6/squeeze1x1
I1028 19:08:05.786801 12802 net.cpp:413] fire6/squeeze1x1 <- pool5
I1028 19:08:05.786813 12802 net.cpp:387] fire6/squeeze1x1 -> fire6/squeeze1x1
I1028 19:08:05.787432 12802 net.cpp:127] Setting up fire6/squeeze1x1
I1028 19:08:05.787446 12802 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 19:08:05.787451 12802 net.cpp:144] Memory required for data: 3258595328
I1028 19:08:05.787459 12802 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1028 19:08:05.787467 12802 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1028 19:08:05.787478 12802 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1028 19:08:05.787485 12802 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1028 19:08:05.787490 12802 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I1028 19:08:05.787498 12802 net.cpp:84] Creating Layer fire6/relu_squeeze1x1
I1028 19:08:05.787505 12802 net.cpp:413] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I1028 19:08:05.787514 12802 net.cpp:374] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I1028 19:08:05.787811 12802 net.cpp:127] Setting up fire6/relu_squeeze1x1
I1028 19:08:05.787824 12802 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 19:08:05.787829 12802 net.cpp:144] Memory required for data: 3263412224
I1028 19:08:05.787835 12802 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1028 19:08:05.787844 12802 net.cpp:84] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1028 19:08:05.787850 12802 net.cpp:413] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I1028 19:08:05.787861 12802 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1028 19:08:05.787871 12802 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1028 19:08:05.787953 12802 net.cpp:127] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1028 19:08:05.787963 12802 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 19:08:05.787971 12802 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 19:08:05.787976 12802 net.cpp:144] Memory required for data: 3273046016
I1028 19:08:05.787981 12802 layer_factory.hpp:77] Creating layer fire6/expand1x1
I1028 19:08:05.787994 12802 net.cpp:84] Creating Layer fire6/expand1x1
I1028 19:08:05.788002 12802 net.cpp:413] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1028 19:08:05.788012 12802 net.cpp:387] fire6/expand1x1 -> fire6/expand1x1
I1028 19:08:05.788565 12802 net.cpp:127] Setting up fire6/expand1x1
I1028 19:08:05.788578 12802 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 19:08:05.788583 12802 net.cpp:144] Memory required for data: 3292313600
I1028 19:08:05.788590 12802 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1028 19:08:05.788614 12802 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1028 19:08:05.788621 12802 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1028 19:08:05.788627 12802 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1028 19:08:05.788632 12802 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I1028 19:08:05.788641 12802 net.cpp:84] Creating Layer fire6/relu_expand1x1
I1028 19:08:05.788647 12802 net.cpp:413] fire6/relu_expand1x1 <- fire6/expand1x1
I1028 19:08:05.788655 12802 net.cpp:374] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I1028 19:08:05.788954 12802 net.cpp:127] Setting up fire6/relu_expand1x1
I1028 19:08:05.788966 12802 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 19:08:05.788972 12802 net.cpp:144] Memory required for data: 3311581184
I1028 19:08:05.788977 12802 layer_factory.hpp:77] Creating layer fire6/expand3x3
I1028 19:08:05.788991 12802 net.cpp:84] Creating Layer fire6/expand3x3
I1028 19:08:05.788997 12802 net.cpp:413] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1028 19:08:05.789010 12802 net.cpp:387] fire6/expand3x3 -> fire6/expand3x3
I1028 19:08:05.792173 12802 net.cpp:127] Setting up fire6/expand3x3
I1028 19:08:05.792193 12802 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 19:08:05.792199 12802 net.cpp:144] Memory required for data: 3330848768
I1028 19:08:05.792208 12802 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1028 19:08:05.792217 12802 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1028 19:08:05.792232 12802 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1028 19:08:05.792238 12802 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1028 19:08:05.792244 12802 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I1028 19:08:05.792254 12802 net.cpp:84] Creating Layer fire6/relu_expand3x3
I1028 19:08:05.792260 12802 net.cpp:413] fire6/relu_expand3x3 <- fire6/expand3x3
I1028 19:08:05.792271 12802 net.cpp:374] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I1028 19:08:05.792587 12802 net.cpp:127] Setting up fire6/relu_expand3x3
I1028 19:08:05.792599 12802 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 19:08:05.792605 12802 net.cpp:144] Memory required for data: 3350116352
I1028 19:08:05.792611 12802 layer_factory.hpp:77] Creating layer fire6/concat
I1028 19:08:05.792619 12802 net.cpp:84] Creating Layer fire6/concat
I1028 19:08:05.792626 12802 net.cpp:413] fire6/concat <- fire6/expand1x1
I1028 19:08:05.792634 12802 net.cpp:413] fire6/concat <- fire6/expand3x3
I1028 19:08:05.792644 12802 net.cpp:387] fire6/concat -> fire6/concat
I1028 19:08:05.792686 12802 net.cpp:127] Setting up fire6/concat
I1028 19:08:05.792695 12802 net.cpp:136] Top shape: 128 384 14 14 (9633792)
I1028 19:08:05.792701 12802 net.cpp:144] Memory required for data: 3388651520
I1028 19:08:05.792706 12802 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I1028 19:08:05.792721 12802 net.cpp:84] Creating Layer fire7/squeeze1x1
I1028 19:08:05.792726 12802 net.cpp:413] fire7/squeeze1x1 <- fire6/concat
I1028 19:08:05.792735 12802 net.cpp:387] fire7/squeeze1x1 -> fire7/squeeze1x1
I1028 19:08:05.793417 12802 net.cpp:127] Setting up fire7/squeeze1x1
I1028 19:08:05.793429 12802 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 19:08:05.793436 12802 net.cpp:144] Memory required for data: 3393468416
I1028 19:08:05.793460 12802 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1028 19:08:05.793473 12802 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1028 19:08:05.793480 12802 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1028 19:08:05.793488 12802 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1028 19:08:05.793493 12802 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I1028 19:08:05.793522 12802 net.cpp:84] Creating Layer fire7/relu_squeeze1x1
I1028 19:08:05.793529 12802 net.cpp:413] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I1028 19:08:05.793537 12802 net.cpp:374] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I1028 19:08:05.795517 12802 net.cpp:127] Setting up fire7/relu_squeeze1x1
I1028 19:08:05.795537 12802 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 19:08:05.795544 12802 net.cpp:144] Memory required for data: 3398285312
I1028 19:08:05.795550 12802 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1028 19:08:05.795562 12802 net.cpp:84] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1028 19:08:05.795568 12802 net.cpp:413] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I1028 19:08:05.795578 12802 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1028 19:08:05.795589 12802 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1028 19:08:05.795665 12802 net.cpp:127] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1028 19:08:05.795675 12802 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 19:08:05.795682 12802 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 19:08:05.795687 12802 net.cpp:144] Memory required for data: 3407919104
I1028 19:08:05.795692 12802 layer_factory.hpp:77] Creating layer fire7/expand1x1
I1028 19:08:05.795706 12802 net.cpp:84] Creating Layer fire7/expand1x1
I1028 19:08:05.795712 12802 net.cpp:413] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1028 19:08:05.795727 12802 net.cpp:387] fire7/expand1x1 -> fire7/expand1x1
I1028 19:08:05.796301 12802 net.cpp:127] Setting up fire7/expand1x1
I1028 19:08:05.796316 12802 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 19:08:05.796321 12802 net.cpp:144] Memory required for data: 3427186688
I1028 19:08:05.796329 12802 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1028 19:08:05.796337 12802 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1028 19:08:05.796344 12802 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1028 19:08:05.796350 12802 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1028 19:08:05.796355 12802 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I1028 19:08:05.796362 12802 net.cpp:84] Creating Layer fire7/relu_expand1x1
I1028 19:08:05.796368 12802 net.cpp:413] fire7/relu_expand1x1 <- fire7/expand1x1
I1028 19:08:05.796376 12802 net.cpp:374] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I1028 19:08:05.796653 12802 net.cpp:127] Setting up fire7/relu_expand1x1
I1028 19:08:05.796669 12802 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 19:08:05.796674 12802 net.cpp:144] Memory required for data: 3446454272
I1028 19:08:05.796679 12802 layer_factory.hpp:77] Creating layer fire7/expand3x3
I1028 19:08:05.796691 12802 net.cpp:84] Creating Layer fire7/expand3x3
I1028 19:08:05.796697 12802 net.cpp:413] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1028 19:08:05.796706 12802 net.cpp:387] fire7/expand3x3 -> fire7/expand3x3
I1028 19:08:05.798048 12802 net.cpp:127] Setting up fire7/expand3x3
I1028 19:08:05.798060 12802 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 19:08:05.798065 12802 net.cpp:144] Memory required for data: 3465721856
I1028 19:08:05.798074 12802 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1028 19:08:05.798080 12802 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1028 19:08:05.798086 12802 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1028 19:08:05.798092 12802 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1028 19:08:05.798097 12802 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I1028 19:08:05.798123 12802 net.cpp:84] Creating Layer fire7/relu_expand3x3
I1028 19:08:05.798130 12802 net.cpp:413] fire7/relu_expand3x3 <- fire7/expand3x3
I1028 19:08:05.798137 12802 net.cpp:374] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I1028 19:08:05.798413 12802 net.cpp:127] Setting up fire7/relu_expand3x3
I1028 19:08:05.798427 12802 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 19:08:05.798434 12802 net.cpp:144] Memory required for data: 3484989440
I1028 19:08:05.798439 12802 layer_factory.hpp:77] Creating layer fire7/concat
I1028 19:08:05.798446 12802 net.cpp:84] Creating Layer fire7/concat
I1028 19:08:05.798452 12802 net.cpp:413] fire7/concat <- fire7/expand1x1
I1028 19:08:05.798460 12802 net.cpp:413] fire7/concat <- fire7/expand3x3
I1028 19:08:05.798466 12802 net.cpp:387] fire7/concat -> fire7/concat
I1028 19:08:05.798507 12802 net.cpp:127] Setting up fire7/concat
I1028 19:08:05.798516 12802 net.cpp:136] Top shape: 128 384 14 14 (9633792)
I1028 19:08:05.798521 12802 net.cpp:144] Memory required for data: 3523524608
I1028 19:08:05.798526 12802 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I1028 19:08:05.798538 12802 net.cpp:84] Creating Layer fire8/squeeze1x1
I1028 19:08:05.798543 12802 net.cpp:413] fire8/squeeze1x1 <- fire7/concat
I1028 19:08:05.798553 12802 net.cpp:387] fire8/squeeze1x1 -> fire8/squeeze1x1
I1028 19:08:05.799260 12802 net.cpp:127] Setting up fire8/squeeze1x1
I1028 19:08:05.799271 12802 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 19:08:05.799278 12802 net.cpp:144] Memory required for data: 3529947136
I1028 19:08:05.799284 12802 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1028 19:08:05.799291 12802 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1028 19:08:05.799302 12802 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1028 19:08:05.799309 12802 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1028 19:08:05.799314 12802 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I1028 19:08:05.799321 12802 net.cpp:84] Creating Layer fire8/relu_squeeze1x1
I1028 19:08:05.799326 12802 net.cpp:413] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I1028 19:08:05.799336 12802 net.cpp:374] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I1028 19:08:05.801187 12802 net.cpp:127] Setting up fire8/relu_squeeze1x1
I1028 19:08:05.801208 12802 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 19:08:05.801213 12802 net.cpp:144] Memory required for data: 3536369664
I1028 19:08:05.801218 12802 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1028 19:08:05.801229 12802 net.cpp:84] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1028 19:08:05.801234 12802 net.cpp:413] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I1028 19:08:05.801245 12802 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1028 19:08:05.801256 12802 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1028 19:08:05.801321 12802 net.cpp:127] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1028 19:08:05.801329 12802 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 19:08:05.801336 12802 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 19:08:05.801340 12802 net.cpp:144] Memory required for data: 3549214720
I1028 19:08:05.801345 12802 layer_factory.hpp:77] Creating layer fire8/expand1x1
I1028 19:08:05.801360 12802 net.cpp:84] Creating Layer fire8/expand1x1
I1028 19:08:05.801368 12802 net.cpp:413] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1028 19:08:05.801376 12802 net.cpp:387] fire8/expand1x1 -> fire8/expand1x1
I1028 19:08:05.801990 12802 net.cpp:127] Setting up fire8/expand1x1
I1028 19:08:05.802002 12802 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 19:08:05.802007 12802 net.cpp:144] Memory required for data: 3574904832
I1028 19:08:05.802031 12802 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1028 19:08:05.802039 12802 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1028 19:08:05.802047 12802 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1028 19:08:05.802052 12802 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1028 19:08:05.802057 12802 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I1028 19:08:05.802065 12802 net.cpp:84] Creating Layer fire8/relu_expand1x1
I1028 19:08:05.802072 12802 net.cpp:413] fire8/relu_expand1x1 <- fire8/expand1x1
I1028 19:08:05.802078 12802 net.cpp:374] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I1028 19:08:05.802362 12802 net.cpp:127] Setting up fire8/relu_expand1x1
I1028 19:08:05.802374 12802 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 19:08:05.802381 12802 net.cpp:144] Memory required for data: 3600594944
I1028 19:08:05.802386 12802 layer_factory.hpp:77] Creating layer fire8/expand3x3
I1028 19:08:05.802397 12802 net.cpp:84] Creating Layer fire8/expand3x3
I1028 19:08:05.802404 12802 net.cpp:413] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1028 19:08:05.802415 12802 net.cpp:387] fire8/expand3x3 -> fire8/expand3x3
I1028 19:08:05.806149 12802 net.cpp:127] Setting up fire8/expand3x3
I1028 19:08:05.806169 12802 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 19:08:05.806174 12802 net.cpp:144] Memory required for data: 3626285056
I1028 19:08:05.806182 12802 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1028 19:08:05.806190 12802 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1028 19:08:05.806201 12802 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1028 19:08:05.806208 12802 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1028 19:08:05.806212 12802 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I1028 19:08:05.806222 12802 net.cpp:84] Creating Layer fire8/relu_expand3x3
I1028 19:08:05.806228 12802 net.cpp:413] fire8/relu_expand3x3 <- fire8/expand3x3
I1028 19:08:05.806239 12802 net.cpp:374] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I1028 19:08:05.806545 12802 net.cpp:127] Setting up fire8/relu_expand3x3
I1028 19:08:05.806557 12802 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 19:08:05.806563 12802 net.cpp:144] Memory required for data: 3651975168
I1028 19:08:05.806568 12802 layer_factory.hpp:77] Creating layer fire8/concat
I1028 19:08:05.806576 12802 net.cpp:84] Creating Layer fire8/concat
I1028 19:08:05.806581 12802 net.cpp:413] fire8/concat <- fire8/expand1x1
I1028 19:08:05.806587 12802 net.cpp:413] fire8/concat <- fire8/expand3x3
I1028 19:08:05.806596 12802 net.cpp:387] fire8/concat -> fire8/concat
I1028 19:08:05.806638 12802 net.cpp:127] Setting up fire8/concat
I1028 19:08:05.806646 12802 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1028 19:08:05.806650 12802 net.cpp:144] Memory required for data: 3703355392
I1028 19:08:05.806655 12802 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I1028 19:08:05.806668 12802 net.cpp:84] Creating Layer fire9/squeeze1x1
I1028 19:08:05.806673 12802 net.cpp:413] fire9/squeeze1x1 <- fire8/concat
I1028 19:08:05.806682 12802 net.cpp:387] fire9/squeeze1x1 -> fire9/squeeze1x1
I1028 19:08:05.807435 12802 net.cpp:127] Setting up fire9/squeeze1x1
I1028 19:08:05.807447 12802 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 19:08:05.807452 12802 net.cpp:144] Memory required for data: 3709777920
I1028 19:08:05.807461 12802 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1028 19:08:05.807466 12802 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1028 19:08:05.807472 12802 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1028 19:08:05.807478 12802 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1028 19:08:05.807502 12802 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I1028 19:08:05.807509 12802 net.cpp:84] Creating Layer fire9/relu_squeeze1x1
I1028 19:08:05.807515 12802 net.cpp:413] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I1028 19:08:05.807523 12802 net.cpp:374] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I1028 19:08:05.807790 12802 net.cpp:127] Setting up fire9/relu_squeeze1x1
I1028 19:08:05.807802 12802 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 19:08:05.807807 12802 net.cpp:144] Memory required for data: 3716200448
I1028 19:08:05.807812 12802 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1028 19:08:05.807831 12802 net.cpp:84] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1028 19:08:05.807835 12802 net.cpp:413] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I1028 19:08:05.807843 12802 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1028 19:08:05.807852 12802 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1028 19:08:05.807914 12802 net.cpp:127] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1028 19:08:05.807929 12802 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 19:08:05.807934 12802 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 19:08:05.807940 12802 net.cpp:144] Memory required for data: 3729045504
I1028 19:08:05.807945 12802 layer_factory.hpp:77] Creating layer fire9/expand1x1
I1028 19:08:05.807962 12802 net.cpp:84] Creating Layer fire9/expand1x1
I1028 19:08:05.807967 12802 net.cpp:413] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1028 19:08:05.807981 12802 net.cpp:387] fire9/expand1x1 -> fire9/expand1x1
I1028 19:08:05.808552 12802 net.cpp:127] Setting up fire9/expand1x1
I1028 19:08:05.808563 12802 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 19:08:05.808568 12802 net.cpp:144] Memory required for data: 3754735616
I1028 19:08:05.808575 12802 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1028 19:08:05.808581 12802 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1028 19:08:05.808588 12802 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1028 19:08:05.808593 12802 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1028 19:08:05.808598 12802 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I1028 19:08:05.808605 12802 net.cpp:84] Creating Layer fire9/relu_expand1x1
I1028 19:08:05.808611 12802 net.cpp:413] fire9/relu_expand1x1 <- fire9/expand1x1
I1028 19:08:05.808619 12802 net.cpp:374] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I1028 19:08:05.811612 12802 net.cpp:127] Setting up fire9/relu_expand1x1
I1028 19:08:05.811630 12802 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 19:08:05.811636 12802 net.cpp:144] Memory required for data: 3780425728
I1028 19:08:05.811642 12802 layer_factory.hpp:77] Creating layer fire9/expand3x3
I1028 19:08:05.811656 12802 net.cpp:84] Creating Layer fire9/expand3x3
I1028 19:08:05.811662 12802 net.cpp:413] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1028 19:08:05.811674 12802 net.cpp:387] fire9/expand3x3 -> fire9/expand3x3
I1028 19:08:05.813604 12802 net.cpp:127] Setting up fire9/expand3x3
I1028 19:08:05.813616 12802 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 19:08:05.813621 12802 net.cpp:144] Memory required for data: 3806115840
I1028 19:08:05.813628 12802 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1028 19:08:05.813637 12802 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1028 19:08:05.813642 12802 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1028 19:08:05.813648 12802 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1028 19:08:05.813652 12802 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I1028 19:08:05.813679 12802 net.cpp:84] Creating Layer fire9/relu_expand3x3
I1028 19:08:05.813686 12802 net.cpp:413] fire9/relu_expand3x3 <- fire9/expand3x3
I1028 19:08:05.813694 12802 net.cpp:374] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I1028 19:08:05.813966 12802 net.cpp:127] Setting up fire9/relu_expand3x3
I1028 19:08:05.813978 12802 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 19:08:05.813983 12802 net.cpp:144] Memory required for data: 3831805952
I1028 19:08:05.813988 12802 layer_factory.hpp:77] Creating layer fire9/concat
I1028 19:08:05.813999 12802 net.cpp:84] Creating Layer fire9/concat
I1028 19:08:05.814004 12802 net.cpp:413] fire9/concat <- fire9/expand1x1
I1028 19:08:05.814010 12802 net.cpp:413] fire9/concat <- fire9/expand3x3
I1028 19:08:05.814018 12802 net.cpp:387] fire9/concat -> fire9/concat
I1028 19:08:05.814059 12802 net.cpp:127] Setting up fire9/concat
I1028 19:08:05.814066 12802 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1028 19:08:05.814071 12802 net.cpp:144] Memory required for data: 3883186176
I1028 19:08:05.814075 12802 layer_factory.hpp:77] Creating layer drop9
I1028 19:08:05.814087 12802 net.cpp:84] Creating Layer drop9
I1028 19:08:05.814092 12802 net.cpp:413] drop9 <- fire9/concat
I1028 19:08:05.814101 12802 net.cpp:374] drop9 -> fire9/concat (in-place)
I1028 19:08:05.814139 12802 net.cpp:127] Setting up drop9
I1028 19:08:05.814149 12802 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1028 19:08:05.814153 12802 net.cpp:144] Memory required for data: 3934566400
I1028 19:08:05.814158 12802 layer_factory.hpp:77] Creating layer conv10
I1028 19:08:05.814168 12802 net.cpp:84] Creating Layer conv10
I1028 19:08:05.814173 12802 net.cpp:413] conv10 <- fire9/concat
I1028 19:08:05.814188 12802 net.cpp:387] conv10 -> conv10
I1028 19:08:05.825552 12802 net.cpp:127] Setting up conv10
I1028 19:08:05.825570 12802 net.cpp:136] Top shape: 128 1000 14 14 (25088000)
I1028 19:08:05.825575 12802 net.cpp:144] Memory required for data: 4034918400
I1028 19:08:05.825583 12802 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1028 19:08:05.825590 12802 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1028 19:08:05.825597 12802 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1028 19:08:05.825601 12802 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1028 19:08:05.825605 12802 layer_factory.hpp:77] Creating layer relu_conv10
I1028 19:08:05.825614 12802 net.cpp:84] Creating Layer relu_conv10
I1028 19:08:05.825619 12802 net.cpp:413] relu_conv10 <- conv10
I1028 19:08:05.825628 12802 net.cpp:374] relu_conv10 -> conv10 (in-place)
I1028 19:08:05.825901 12802 net.cpp:127] Setting up relu_conv10
I1028 19:08:05.825912 12802 net.cpp:136] Top shape: 128 1000 14 14 (25088000)
I1028 19:08:05.825917 12802 net.cpp:144] Memory required for data: 4135270400
I1028 19:08:05.825930 12802 layer_factory.hpp:77] Creating layer pool10
I1028 19:08:05.825938 12802 net.cpp:84] Creating Layer pool10
I1028 19:08:05.825943 12802 net.cpp:413] pool10 <- conv10
I1028 19:08:05.825958 12802 net.cpp:387] pool10 -> pool10
I1028 19:08:05.826249 12802 net.cpp:127] Setting up pool10
I1028 19:08:05.826261 12802 net.cpp:136] Top shape: 128 1000 1 1 (128000)
I1028 19:08:05.826266 12802 net.cpp:144] Memory required for data: 4135782400
I1028 19:08:05.826269 12802 layer_factory.hpp:77] Creating layer loss
I1028 19:08:05.826282 12802 net.cpp:84] Creating Layer loss
I1028 19:08:05.826287 12802 net.cpp:413] loss <- pool10
I1028 19:08:05.826292 12802 net.cpp:413] loss <- label
I1028 19:08:05.826300 12802 net.cpp:387] loss -> loss
I1028 19:08:05.826313 12802 layer_factory.hpp:77] Creating layer loss
I1028 19:08:05.829586 12802 net.cpp:127] Setting up loss
I1028 19:08:05.829602 12802 net.cpp:136] Top shape: (1)
I1028 19:08:05.829607 12802 net.cpp:139]     with loss weight 1
I1028 19:08:05.829635 12802 net.cpp:144] Memory required for data: 4135782404
I1028 19:08:05.829640 12802 net.cpp:205] loss needs backward computation.
I1028 19:08:05.829660 12802 net.cpp:205] pool10 needs backward computation.
I1028 19:08:05.829665 12802 net.cpp:205] relu_conv10 needs backward computation.
I1028 19:08:05.829669 12802 net.cpp:205] conv10 needs backward computation.
I1028 19:08:05.829674 12802 net.cpp:205] drop9 needs backward computation.
I1028 19:08:05.829677 12802 net.cpp:205] fire9/concat needs backward computation.
I1028 19:08:05.829682 12802 net.cpp:205] fire9/relu_expand3x3 needs backward computation.
I1028 19:08:05.829686 12802 net.cpp:205] fire9/expand3x3 needs backward computation.
I1028 19:08:05.829691 12802 net.cpp:205] fire9/relu_expand1x1 needs backward computation.
I1028 19:08:05.829695 12802 net.cpp:205] fire9/expand1x1 needs backward computation.
I1028 19:08:05.829700 12802 net.cpp:205] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I1028 19:08:05.829705 12802 net.cpp:205] fire9/relu_squeeze1x1 needs backward computation.
I1028 19:08:05.829710 12802 net.cpp:205] fire9/squeeze1x1 needs backward computation.
I1028 19:08:05.829713 12802 net.cpp:205] fire8/concat needs backward computation.
I1028 19:08:05.829718 12802 net.cpp:205] fire8/relu_expand3x3 needs backward computation.
I1028 19:08:05.829722 12802 net.cpp:205] fire8/expand3x3 needs backward computation.
I1028 19:08:05.829726 12802 net.cpp:205] fire8/relu_expand1x1 needs backward computation.
I1028 19:08:05.829730 12802 net.cpp:205] fire8/expand1x1 needs backward computation.
I1028 19:08:05.829735 12802 net.cpp:205] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I1028 19:08:05.829742 12802 net.cpp:205] fire8/relu_squeeze1x1 needs backward computation.
I1028 19:08:05.829746 12802 net.cpp:205] fire8/squeeze1x1 needs backward computation.
I1028 19:08:05.829753 12802 net.cpp:205] fire7/concat needs backward computation.
I1028 19:08:05.829758 12802 net.cpp:205] fire7/relu_expand3x3 needs backward computation.
I1028 19:08:05.829762 12802 net.cpp:205] fire7/expand3x3 needs backward computation.
I1028 19:08:05.829766 12802 net.cpp:205] fire7/relu_expand1x1 needs backward computation.
I1028 19:08:05.829771 12802 net.cpp:205] fire7/expand1x1 needs backward computation.
I1028 19:08:05.829776 12802 net.cpp:205] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I1028 19:08:05.829779 12802 net.cpp:205] fire7/relu_squeeze1x1 needs backward computation.
I1028 19:08:05.829783 12802 net.cpp:205] fire7/squeeze1x1 needs backward computation.
I1028 19:08:05.829787 12802 net.cpp:205] fire6/concat needs backward computation.
I1028 19:08:05.829792 12802 net.cpp:205] fire6/relu_expand3x3 needs backward computation.
I1028 19:08:05.829797 12802 net.cpp:205] fire6/expand3x3 needs backward computation.
I1028 19:08:05.829800 12802 net.cpp:205] fire6/relu_expand1x1 needs backward computation.
I1028 19:08:05.829804 12802 net.cpp:205] fire6/expand1x1 needs backward computation.
I1028 19:08:05.829808 12802 net.cpp:205] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I1028 19:08:05.829813 12802 net.cpp:205] fire6/relu_squeeze1x1 needs backward computation.
I1028 19:08:05.829816 12802 net.cpp:205] fire6/squeeze1x1 needs backward computation.
I1028 19:08:05.829821 12802 net.cpp:205] pool5 needs backward computation.
I1028 19:08:05.829825 12802 net.cpp:205] fire5/concat needs backward computation.
I1028 19:08:05.829829 12802 net.cpp:205] fire5/relu_expand3x3 needs backward computation.
I1028 19:08:05.829833 12802 net.cpp:205] fire5/expand3x3 needs backward computation.
I1028 19:08:05.829838 12802 net.cpp:205] fire5/relu_expand1x1 needs backward computation.
I1028 19:08:05.829843 12802 net.cpp:205] fire5/expand1x1 needs backward computation.
I1028 19:08:05.829846 12802 net.cpp:205] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I1028 19:08:05.829850 12802 net.cpp:205] fire5/relu_squeeze1x1 needs backward computation.
I1028 19:08:05.829854 12802 net.cpp:205] fire5/squeeze1x1 needs backward computation.
I1028 19:08:05.829859 12802 net.cpp:205] fire4/concat needs backward computation.
I1028 19:08:05.829864 12802 net.cpp:205] fire4/relu_expand3x3 needs backward computation.
I1028 19:08:05.829874 12802 net.cpp:205] fire4/expand3x3 needs backward computation.
I1028 19:08:05.829877 12802 net.cpp:205] fire4/relu_expand1x1 needs backward computation.
I1028 19:08:05.829881 12802 net.cpp:205] fire4/expand1x1 needs backward computation.
I1028 19:08:05.829885 12802 net.cpp:205] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I1028 19:08:05.829890 12802 net.cpp:205] fire4/relu_squeeze1x1 needs backward computation.
I1028 19:08:05.829893 12802 net.cpp:205] fire4/squeeze1x1 needs backward computation.
I1028 19:08:05.829898 12802 net.cpp:205] pool3 needs backward computation.
I1028 19:08:05.829902 12802 net.cpp:205] fire3/concat needs backward computation.
I1028 19:08:05.829907 12802 net.cpp:205] fire3/relu_expand3x3 needs backward computation.
I1028 19:08:05.829911 12802 net.cpp:205] fire3/expand3x3 needs backward computation.
I1028 19:08:05.829916 12802 net.cpp:205] fire3/relu_expand1x1 needs backward computation.
I1028 19:08:05.829926 12802 net.cpp:205] fire3/expand1x1 needs backward computation.
I1028 19:08:05.829931 12802 net.cpp:205] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I1028 19:08:05.829936 12802 net.cpp:205] fire3/relu_squeeze1x1 needs backward computation.
I1028 19:08:05.829939 12802 net.cpp:205] fire3/squeeze1x1 needs backward computation.
I1028 19:08:05.829943 12802 net.cpp:205] fire2/concat needs backward computation.
I1028 19:08:05.829948 12802 net.cpp:205] fire2/relu_expand3x3 needs backward computation.
I1028 19:08:05.829952 12802 net.cpp:205] fire2/expand3x3 needs backward computation.
I1028 19:08:05.829957 12802 net.cpp:205] fire2/relu_expand1x1 needs backward computation.
I1028 19:08:05.829964 12802 net.cpp:205] fire2/expand1x1 needs backward computation.
I1028 19:08:05.829969 12802 net.cpp:205] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I1028 19:08:05.829973 12802 net.cpp:205] fire2/relu_squeeze1x1 needs backward computation.
I1028 19:08:05.829977 12802 net.cpp:205] fire2/squeeze1x1 needs backward computation.
I1028 19:08:05.829982 12802 net.cpp:205] pool1 needs backward computation.
I1028 19:08:05.829987 12802 net.cpp:205] relu_conv1 needs backward computation.
I1028 19:08:05.829990 12802 net.cpp:205] conv1 needs backward computation.
I1028 19:08:05.829996 12802 net.cpp:207] data does not need backward computation.
I1028 19:08:05.830000 12802 net.cpp:249] This network produces output loss
I1028 19:08:05.830061 12802 net.cpp:262] Network initialization done.
I1028 19:08:05.831943 12802 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_40.prototxt
I1028 19:08:05.832052 12802 net.cpp:301] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1028 19:08:05.832788 12802 net.cpp:51] Initializing net from parameters: 
name: "SqueezeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/data/caffe-imagenet/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "INQConvolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "fire3/concat"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire4/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool3"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "fire5/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire4/concat"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "fire5/concat"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire6/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool5"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "fire9/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire8/concat"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "INQConvolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "pool10"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy_top1"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy_top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy_top5"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy_top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I1028 19:08:05.833174 12802 layer_factory.hpp:77] Creating layer data
I1028 19:08:05.833248 12802 db_lmdb.cpp:35] Opened lmdb /home/data/caffe-imagenet/ilsvrc12_val_lmdb
I1028 19:08:05.833272 12802 net.cpp:84] Creating Layer data
I1028 19:08:05.833279 12802 net.cpp:387] data -> data
I1028 19:08:05.833290 12802 net.cpp:387] data -> label
I1028 19:08:05.833709 12802 data_layer.cpp:45] output data size: 50,3,227,227
I1028 19:08:05.918797 12802 net.cpp:127] Setting up data
I1028 19:08:05.918838 12802 net.cpp:136] Top shape: 50 3 227 227 (7729350)
I1028 19:08:05.918845 12802 net.cpp:136] Top shape: 50 (50)
I1028 19:08:05.918849 12802 net.cpp:144] Memory required for data: 30917600
I1028 19:08:05.918857 12802 layer_factory.hpp:77] Creating layer label_data_1_split
I1028 19:08:05.918874 12802 net.cpp:84] Creating Layer label_data_1_split
I1028 19:08:05.918879 12802 net.cpp:413] label_data_1_split <- label
I1028 19:08:05.918889 12802 net.cpp:387] label_data_1_split -> label_data_1_split_0
I1028 19:08:05.918901 12802 net.cpp:387] label_data_1_split -> label_data_1_split_1
I1028 19:08:05.918907 12802 net.cpp:387] label_data_1_split -> label_data_1_split_2
I1028 19:08:05.919037 12802 net.cpp:127] Setting up label_data_1_split
I1028 19:08:05.919046 12802 net.cpp:136] Top shape: 50 (50)
I1028 19:08:05.919051 12802 net.cpp:136] Top shape: 50 (50)
I1028 19:08:05.919055 12802 net.cpp:136] Top shape: 50 (50)
I1028 19:08:05.919059 12802 net.cpp:144] Memory required for data: 30918200
I1028 19:08:05.919064 12802 layer_factory.hpp:77] Creating layer conv1
I1028 19:08:05.919078 12802 net.cpp:84] Creating Layer conv1
I1028 19:08:05.919082 12802 net.cpp:413] conv1 <- data
I1028 19:08:05.919090 12802 net.cpp:387] conv1 -> conv1
I1028 19:08:05.919612 12802 net.cpp:127] Setting up conv1
I1028 19:08:05.919623 12802 net.cpp:136] Top shape: 50 64 113 113 (40860800)
I1028 19:08:05.919627 12802 net.cpp:144] Memory required for data: 194361400
I1028 19:08:05.919636 12802 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1028 19:08:05.919644 12802 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1028 19:08:05.919656 12802 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1028 19:08:05.919663 12802 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1028 19:08:05.919667 12802 layer_factory.hpp:77] Creating layer relu_conv1
I1028 19:08:05.919677 12802 net.cpp:84] Creating Layer relu_conv1
I1028 19:08:05.919680 12802 net.cpp:413] relu_conv1 <- conv1
I1028 19:08:05.919687 12802 net.cpp:374] relu_conv1 -> conv1 (in-place)
I1028 19:08:05.919958 12802 net.cpp:127] Setting up relu_conv1
I1028 19:08:05.919968 12802 net.cpp:136] Top shape: 50 64 113 113 (40860800)
I1028 19:08:05.919972 12802 net.cpp:144] Memory required for data: 357804600
I1028 19:08:05.919976 12802 layer_factory.hpp:77] Creating layer pool1
I1028 19:08:05.919987 12802 net.cpp:84] Creating Layer pool1
I1028 19:08:05.919991 12802 net.cpp:413] pool1 <- conv1
I1028 19:08:05.919998 12802 net.cpp:387] pool1 -> pool1
I1028 19:08:05.920048 12802 net.cpp:127] Setting up pool1
I1028 19:08:05.920054 12802 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 19:08:05.920058 12802 net.cpp:144] Memory required for data: 397945400
I1028 19:08:05.920063 12802 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I1028 19:08:05.920071 12802 net.cpp:84] Creating Layer fire2/squeeze1x1
I1028 19:08:05.920075 12802 net.cpp:413] fire2/squeeze1x1 <- pool1
I1028 19:08:05.920083 12802 net.cpp:387] fire2/squeeze1x1 -> fire2/squeeze1x1
I1028 19:08:05.920437 12802 net.cpp:127] Setting up fire2/squeeze1x1
I1028 19:08:05.920445 12802 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 19:08:05.920449 12802 net.cpp:144] Memory required for data: 407980600
I1028 19:08:05.920456 12802 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1028 19:08:05.920464 12802 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1028 19:08:05.920469 12802 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1028 19:08:05.920475 12802 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1028 19:08:05.920480 12802 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I1028 19:08:05.920486 12802 net.cpp:84] Creating Layer fire2/relu_squeeze1x1
I1028 19:08:05.920490 12802 net.cpp:413] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I1028 19:08:05.920526 12802 net.cpp:374] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I1028 19:08:05.920886 12802 net.cpp:127] Setting up fire2/relu_squeeze1x1
I1028 19:08:05.920897 12802 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 19:08:05.920900 12802 net.cpp:144] Memory required for data: 418015800
I1028 19:08:05.920905 12802 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1028 19:08:05.920912 12802 net.cpp:84] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1028 19:08:05.920917 12802 net.cpp:413] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I1028 19:08:05.920931 12802 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1028 19:08:05.920940 12802 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1028 19:08:05.920991 12802 net.cpp:127] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1028 19:08:05.920999 12802 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 19:08:05.921003 12802 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 19:08:05.921006 12802 net.cpp:144] Memory required for data: 438086200
I1028 19:08:05.921010 12802 layer_factory.hpp:77] Creating layer fire2/expand1x1
I1028 19:08:05.921021 12802 net.cpp:84] Creating Layer fire2/expand1x1
I1028 19:08:05.921025 12802 net.cpp:413] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1028 19:08:05.921032 12802 net.cpp:387] fire2/expand1x1 -> fire2/expand1x1
I1028 19:08:05.924013 12802 net.cpp:127] Setting up fire2/expand1x1
I1028 19:08:05.924032 12802 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 19:08:05.924046 12802 net.cpp:144] Memory required for data: 478227000
I1028 19:08:05.924055 12802 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1028 19:08:05.924064 12802 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1028 19:08:05.924070 12802 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1028 19:08:05.924074 12802 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1028 19:08:05.924078 12802 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I1028 19:08:05.924087 12802 net.cpp:84] Creating Layer fire2/relu_expand1x1
I1028 19:08:05.924091 12802 net.cpp:413] fire2/relu_expand1x1 <- fire2/expand1x1
I1028 19:08:05.924098 12802 net.cpp:374] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I1028 19:08:05.925581 12802 net.cpp:127] Setting up fire2/relu_expand1x1
I1028 19:08:05.925598 12802 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 19:08:05.925602 12802 net.cpp:144] Memory required for data: 518367800
I1028 19:08:05.925607 12802 layer_factory.hpp:77] Creating layer fire2/expand3x3
I1028 19:08:05.925618 12802 net.cpp:84] Creating Layer fire2/expand3x3
I1028 19:08:05.925623 12802 net.cpp:413] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1028 19:08:05.925632 12802 net.cpp:387] fire2/expand3x3 -> fire2/expand3x3
I1028 19:08:05.926089 12802 net.cpp:127] Setting up fire2/expand3x3
I1028 19:08:05.926098 12802 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 19:08:05.926102 12802 net.cpp:144] Memory required for data: 558508600
I1028 19:08:05.926108 12802 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1028 19:08:05.926113 12802 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1028 19:08:05.926118 12802 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1028 19:08:05.926122 12802 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1028 19:08:05.926126 12802 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I1028 19:08:05.926133 12802 net.cpp:84] Creating Layer fire2/relu_expand3x3
I1028 19:08:05.926138 12802 net.cpp:413] fire2/relu_expand3x3 <- fire2/expand3x3
I1028 19:08:05.926144 12802 net.cpp:374] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I1028 19:08:05.926376 12802 net.cpp:127] Setting up fire2/relu_expand3x3
I1028 19:08:05.926385 12802 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 19:08:05.926389 12802 net.cpp:144] Memory required for data: 598649400
I1028 19:08:05.926393 12802 layer_factory.hpp:77] Creating layer fire2/concat
I1028 19:08:05.926400 12802 net.cpp:84] Creating Layer fire2/concat
I1028 19:08:05.926405 12802 net.cpp:413] fire2/concat <- fire2/expand1x1
I1028 19:08:05.926410 12802 net.cpp:413] fire2/concat <- fire2/expand3x3
I1028 19:08:05.926417 12802 net.cpp:387] fire2/concat -> fire2/concat
I1028 19:08:05.926450 12802 net.cpp:127] Setting up fire2/concat
I1028 19:08:05.926457 12802 net.cpp:136] Top shape: 50 128 56 56 (20070400)
I1028 19:08:05.926461 12802 net.cpp:144] Memory required for data: 678931000
I1028 19:08:05.926465 12802 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I1028 19:08:05.926472 12802 net.cpp:84] Creating Layer fire3/squeeze1x1
I1028 19:08:05.926476 12802 net.cpp:413] fire3/squeeze1x1 <- fire2/concat
I1028 19:08:05.926484 12802 net.cpp:387] fire3/squeeze1x1 -> fire3/squeeze1x1
I1028 19:08:05.926848 12802 net.cpp:127] Setting up fire3/squeeze1x1
I1028 19:08:05.926856 12802 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 19:08:05.926859 12802 net.cpp:144] Memory required for data: 688966200
I1028 19:08:05.926869 12802 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1028 19:08:05.926877 12802 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1028 19:08:05.926882 12802 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1028 19:08:05.926887 12802 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1028 19:08:05.926892 12802 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I1028 19:08:05.926898 12802 net.cpp:84] Creating Layer fire3/relu_squeeze1x1
I1028 19:08:05.926903 12802 net.cpp:413] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I1028 19:08:05.926908 12802 net.cpp:374] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I1028 19:08:05.927124 12802 net.cpp:127] Setting up fire3/relu_squeeze1x1
I1028 19:08:05.927134 12802 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 19:08:05.927137 12802 net.cpp:144] Memory required for data: 699001400
I1028 19:08:05.927141 12802 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1028 19:08:05.927147 12802 net.cpp:84] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1028 19:08:05.927151 12802 net.cpp:413] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I1028 19:08:05.927158 12802 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1028 19:08:05.927165 12802 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1028 19:08:05.927213 12802 net.cpp:127] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1028 19:08:05.927219 12802 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 19:08:05.927224 12802 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 19:08:05.927228 12802 net.cpp:144] Memory required for data: 719071800
I1028 19:08:05.927232 12802 layer_factory.hpp:77] Creating layer fire3/expand1x1
I1028 19:08:05.927244 12802 net.cpp:84] Creating Layer fire3/expand1x1
I1028 19:08:05.927249 12802 net.cpp:413] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1028 19:08:05.927255 12802 net.cpp:387] fire3/expand1x1 -> fire3/expand1x1
I1028 19:08:05.927615 12802 net.cpp:127] Setting up fire3/expand1x1
I1028 19:08:05.927623 12802 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 19:08:05.927628 12802 net.cpp:144] Memory required for data: 759212600
I1028 19:08:05.927634 12802 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1028 19:08:05.927639 12802 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1028 19:08:05.927644 12802 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1028 19:08:05.927659 12802 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1028 19:08:05.927662 12802 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I1028 19:08:05.927670 12802 net.cpp:84] Creating Layer fire3/relu_expand1x1
I1028 19:08:05.927675 12802 net.cpp:413] fire3/relu_expand1x1 <- fire3/expand1x1
I1028 19:08:05.927680 12802 net.cpp:374] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I1028 19:08:05.927891 12802 net.cpp:127] Setting up fire3/relu_expand1x1
I1028 19:08:05.927901 12802 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 19:08:05.927904 12802 net.cpp:144] Memory required for data: 799353400
I1028 19:08:05.927907 12802 layer_factory.hpp:77] Creating layer fire3/expand3x3
I1028 19:08:05.927927 12802 net.cpp:84] Creating Layer fire3/expand3x3
I1028 19:08:05.927932 12802 net.cpp:413] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1028 19:08:05.927939 12802 net.cpp:387] fire3/expand3x3 -> fire3/expand3x3
I1028 19:08:05.928369 12802 net.cpp:127] Setting up fire3/expand3x3
I1028 19:08:05.928378 12802 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 19:08:05.928382 12802 net.cpp:144] Memory required for data: 839494200
I1028 19:08:05.928387 12802 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1028 19:08:05.928393 12802 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1028 19:08:05.928398 12802 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1028 19:08:05.928402 12802 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1028 19:08:05.928408 12802 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I1028 19:08:05.928416 12802 net.cpp:84] Creating Layer fire3/relu_expand3x3
I1028 19:08:05.928421 12802 net.cpp:413] fire3/relu_expand3x3 <- fire3/expand3x3
I1028 19:08:05.928426 12802 net.cpp:374] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I1028 19:08:05.929837 12802 net.cpp:127] Setting up fire3/relu_expand3x3
I1028 19:08:05.929853 12802 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 19:08:05.929858 12802 net.cpp:144] Memory required for data: 879635000
I1028 19:08:05.929862 12802 layer_factory.hpp:77] Creating layer fire3/concat
I1028 19:08:05.929870 12802 net.cpp:84] Creating Layer fire3/concat
I1028 19:08:05.929874 12802 net.cpp:413] fire3/concat <- fire3/expand1x1
I1028 19:08:05.929880 12802 net.cpp:413] fire3/concat <- fire3/expand3x3
I1028 19:08:05.929885 12802 net.cpp:387] fire3/concat -> fire3/concat
I1028 19:08:05.929929 12802 net.cpp:127] Setting up fire3/concat
I1028 19:08:05.929936 12802 net.cpp:136] Top shape: 50 128 56 56 (20070400)
I1028 19:08:05.929939 12802 net.cpp:144] Memory required for data: 959916600
I1028 19:08:05.929944 12802 layer_factory.hpp:77] Creating layer pool3
I1028 19:08:05.929951 12802 net.cpp:84] Creating Layer pool3
I1028 19:08:05.929955 12802 net.cpp:413] pool3 <- fire3/concat
I1028 19:08:05.929961 12802 net.cpp:387] pool3 -> pool3
I1028 19:08:05.930009 12802 net.cpp:127] Setting up pool3
I1028 19:08:05.930016 12802 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 19:08:05.930018 12802 net.cpp:144] Memory required for data: 979987000
I1028 19:08:05.930022 12802 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I1028 19:08:05.930032 12802 net.cpp:84] Creating Layer fire4/squeeze1x1
I1028 19:08:05.930037 12802 net.cpp:413] fire4/squeeze1x1 <- pool3
I1028 19:08:05.930042 12802 net.cpp:387] fire4/squeeze1x1 -> fire4/squeeze1x1
I1028 19:08:05.930433 12802 net.cpp:127] Setting up fire4/squeeze1x1
I1028 19:08:05.930441 12802 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 19:08:05.930445 12802 net.cpp:144] Memory required for data: 985004600
I1028 19:08:05.930451 12802 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1028 19:08:05.930457 12802 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1028 19:08:05.930462 12802 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1028 19:08:05.930480 12802 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1028 19:08:05.930483 12802 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I1028 19:08:05.930492 12802 net.cpp:84] Creating Layer fire4/relu_squeeze1x1
I1028 19:08:05.930496 12802 net.cpp:413] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I1028 19:08:05.930502 12802 net.cpp:374] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I1028 19:08:05.930711 12802 net.cpp:127] Setting up fire4/relu_squeeze1x1
I1028 19:08:05.930721 12802 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 19:08:05.930725 12802 net.cpp:144] Memory required for data: 990022200
I1028 19:08:05.930729 12802 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1028 19:08:05.930735 12802 net.cpp:84] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1028 19:08:05.930739 12802 net.cpp:413] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I1028 19:08:05.930745 12802 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1028 19:08:05.930752 12802 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1028 19:08:05.930802 12802 net.cpp:127] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1028 19:08:05.930809 12802 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 19:08:05.930814 12802 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 19:08:05.930816 12802 net.cpp:144] Memory required for data: 1000057400
I1028 19:08:05.930820 12802 layer_factory.hpp:77] Creating layer fire4/expand1x1
I1028 19:08:05.930832 12802 net.cpp:84] Creating Layer fire4/expand1x1
I1028 19:08:05.930837 12802 net.cpp:413] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1028 19:08:05.930845 12802 net.cpp:387] fire4/expand1x1 -> fire4/expand1x1
I1028 19:08:05.931226 12802 net.cpp:127] Setting up fire4/expand1x1
I1028 19:08:05.931234 12802 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 19:08:05.931238 12802 net.cpp:144] Memory required for data: 1020127800
I1028 19:08:05.931249 12802 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1028 19:08:05.931257 12802 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1028 19:08:05.931262 12802 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1028 19:08:05.931267 12802 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1028 19:08:05.931272 12802 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I1028 19:08:05.931279 12802 net.cpp:84] Creating Layer fire4/relu_expand1x1
I1028 19:08:05.931283 12802 net.cpp:413] fire4/relu_expand1x1 <- fire4/expand1x1
I1028 19:08:05.931289 12802 net.cpp:374] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I1028 19:08:05.931499 12802 net.cpp:127] Setting up fire4/relu_expand1x1
I1028 19:08:05.931507 12802 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 19:08:05.931510 12802 net.cpp:144] Memory required for data: 1040198200
I1028 19:08:05.931514 12802 layer_factory.hpp:77] Creating layer fire4/expand3x3
I1028 19:08:05.931524 12802 net.cpp:84] Creating Layer fire4/expand3x3
I1028 19:08:05.931529 12802 net.cpp:413] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1028 19:08:05.931537 12802 net.cpp:387] fire4/expand3x3 -> fire4/expand3x3
I1028 19:08:05.932199 12802 net.cpp:127] Setting up fire4/expand3x3
I1028 19:08:05.932209 12802 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 19:08:05.932214 12802 net.cpp:144] Memory required for data: 1060268600
I1028 19:08:05.932219 12802 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1028 19:08:05.932224 12802 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1028 19:08:05.932229 12802 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1028 19:08:05.932243 12802 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1028 19:08:05.932247 12802 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I1028 19:08:05.932255 12802 net.cpp:84] Creating Layer fire4/relu_expand3x3
I1028 19:08:05.932260 12802 net.cpp:413] fire4/relu_expand3x3 <- fire4/expand3x3
I1028 19:08:05.932265 12802 net.cpp:374] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I1028 19:08:05.932477 12802 net.cpp:127] Setting up fire4/relu_expand3x3
I1028 19:08:05.932487 12802 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 19:08:05.932492 12802 net.cpp:144] Memory required for data: 1080339000
I1028 19:08:05.932495 12802 layer_factory.hpp:77] Creating layer fire4/concat
I1028 19:08:05.932502 12802 net.cpp:84] Creating Layer fire4/concat
I1028 19:08:05.932504 12802 net.cpp:413] fire4/concat <- fire4/expand1x1
I1028 19:08:05.932509 12802 net.cpp:413] fire4/concat <- fire4/expand3x3
I1028 19:08:05.932515 12802 net.cpp:387] fire4/concat -> fire4/concat
I1028 19:08:05.932545 12802 net.cpp:127] Setting up fire4/concat
I1028 19:08:05.932551 12802 net.cpp:136] Top shape: 50 256 28 28 (10035200)
I1028 19:08:05.932555 12802 net.cpp:144] Memory required for data: 1120479800
I1028 19:08:05.932559 12802 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I1028 19:08:05.932569 12802 net.cpp:84] Creating Layer fire5/squeeze1x1
I1028 19:08:05.932572 12802 net.cpp:413] fire5/squeeze1x1 <- fire4/concat
I1028 19:08:05.932580 12802 net.cpp:387] fire5/squeeze1x1 -> fire5/squeeze1x1
I1028 19:08:05.933001 12802 net.cpp:127] Setting up fire5/squeeze1x1
I1028 19:08:05.933009 12802 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 19:08:05.933015 12802 net.cpp:144] Memory required for data: 1125497400
I1028 19:08:05.933022 12802 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1028 19:08:05.933027 12802 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1028 19:08:05.933032 12802 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1028 19:08:05.933037 12802 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1028 19:08:05.933039 12802 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I1028 19:08:05.933045 12802 net.cpp:84] Creating Layer fire5/relu_squeeze1x1
I1028 19:08:05.933049 12802 net.cpp:413] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I1028 19:08:05.933058 12802 net.cpp:374] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I1028 19:08:05.934547 12802 net.cpp:127] Setting up fire5/relu_squeeze1x1
I1028 19:08:05.934562 12802 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 19:08:05.934566 12802 net.cpp:144] Memory required for data: 1130515000
I1028 19:08:05.934571 12802 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1028 19:08:05.934583 12802 net.cpp:84] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1028 19:08:05.934587 12802 net.cpp:413] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I1028 19:08:05.934594 12802 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1028 19:08:05.934602 12802 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1028 19:08:05.934656 12802 net.cpp:127] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1028 19:08:05.934664 12802 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 19:08:05.934667 12802 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 19:08:05.934671 12802 net.cpp:144] Memory required for data: 1140550200
I1028 19:08:05.934674 12802 layer_factory.hpp:77] Creating layer fire5/expand1x1
I1028 19:08:05.934685 12802 net.cpp:84] Creating Layer fire5/expand1x1
I1028 19:08:05.934689 12802 net.cpp:413] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1028 19:08:05.934697 12802 net.cpp:387] fire5/expand1x1 -> fire5/expand1x1
I1028 19:08:05.935083 12802 net.cpp:127] Setting up fire5/expand1x1
I1028 19:08:05.935104 12802 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 19:08:05.935107 12802 net.cpp:144] Memory required for data: 1160620600
I1028 19:08:05.935114 12802 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1028 19:08:05.935119 12802 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1028 19:08:05.935124 12802 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1028 19:08:05.935128 12802 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1028 19:08:05.935132 12802 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I1028 19:08:05.935139 12802 net.cpp:84] Creating Layer fire5/relu_expand1x1
I1028 19:08:05.935143 12802 net.cpp:413] fire5/relu_expand1x1 <- fire5/expand1x1
I1028 19:08:05.935151 12802 net.cpp:374] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I1028 19:08:05.935361 12802 net.cpp:127] Setting up fire5/relu_expand1x1
I1028 19:08:05.935370 12802 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 19:08:05.935374 12802 net.cpp:144] Memory required for data: 1180691000
I1028 19:08:05.935379 12802 layer_factory.hpp:77] Creating layer fire5/expand3x3
I1028 19:08:05.935389 12802 net.cpp:84] Creating Layer fire5/expand3x3
I1028 19:08:05.935392 12802 net.cpp:413] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1028 19:08:05.935402 12802 net.cpp:387] fire5/expand3x3 -> fire5/expand3x3
I1028 19:08:05.936061 12802 net.cpp:127] Setting up fire5/expand3x3
I1028 19:08:05.936070 12802 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 19:08:05.936074 12802 net.cpp:144] Memory required for data: 1200761400
I1028 19:08:05.936082 12802 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1028 19:08:05.936089 12802 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1028 19:08:05.936094 12802 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1028 19:08:05.936097 12802 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1028 19:08:05.936101 12802 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I1028 19:08:05.936110 12802 net.cpp:84] Creating Layer fire5/relu_expand3x3
I1028 19:08:05.936113 12802 net.cpp:413] fire5/relu_expand3x3 <- fire5/expand3x3
I1028 19:08:05.936120 12802 net.cpp:374] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I1028 19:08:05.936331 12802 net.cpp:127] Setting up fire5/relu_expand3x3
I1028 19:08:05.936339 12802 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 19:08:05.936344 12802 net.cpp:144] Memory required for data: 1220831800
I1028 19:08:05.936349 12802 layer_factory.hpp:77] Creating layer fire5/concat
I1028 19:08:05.936355 12802 net.cpp:84] Creating Layer fire5/concat
I1028 19:08:05.936359 12802 net.cpp:413] fire5/concat <- fire5/expand1x1
I1028 19:08:05.936364 12802 net.cpp:413] fire5/concat <- fire5/expand3x3
I1028 19:08:05.936370 12802 net.cpp:387] fire5/concat -> fire5/concat
I1028 19:08:05.936401 12802 net.cpp:127] Setting up fire5/concat
I1028 19:08:05.936408 12802 net.cpp:136] Top shape: 50 256 28 28 (10035200)
I1028 19:08:05.936411 12802 net.cpp:144] Memory required for data: 1260972600
I1028 19:08:05.936414 12802 layer_factory.hpp:77] Creating layer pool5
I1028 19:08:05.936421 12802 net.cpp:84] Creating Layer pool5
I1028 19:08:05.936425 12802 net.cpp:413] pool5 <- fire5/concat
I1028 19:08:05.936432 12802 net.cpp:387] pool5 -> pool5
I1028 19:08:05.936481 12802 net.cpp:127] Setting up pool5
I1028 19:08:05.936487 12802 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 19:08:05.936491 12802 net.cpp:144] Memory required for data: 1271007800
I1028 19:08:05.936494 12802 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I1028 19:08:05.936504 12802 net.cpp:84] Creating Layer fire6/squeeze1x1
I1028 19:08:05.936508 12802 net.cpp:413] fire6/squeeze1x1 <- pool5
I1028 19:08:05.936517 12802 net.cpp:387] fire6/squeeze1x1 -> fire6/squeeze1x1
I1028 19:08:05.936972 12802 net.cpp:127] Setting up fire6/squeeze1x1
I1028 19:08:05.936991 12802 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 19:08:05.936995 12802 net.cpp:144] Memory required for data: 1272889400
I1028 19:08:05.937001 12802 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1028 19:08:05.937006 12802 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1028 19:08:05.937011 12802 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1028 19:08:05.937016 12802 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1028 19:08:05.937019 12802 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I1028 19:08:05.937026 12802 net.cpp:84] Creating Layer fire6/relu_squeeze1x1
I1028 19:08:05.937031 12802 net.cpp:413] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I1028 19:08:05.937036 12802 net.cpp:374] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I1028 19:08:05.937247 12802 net.cpp:127] Setting up fire6/relu_squeeze1x1
I1028 19:08:05.937254 12802 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 19:08:05.937258 12802 net.cpp:144] Memory required for data: 1274771000
I1028 19:08:05.937263 12802 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1028 19:08:05.937268 12802 net.cpp:84] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1028 19:08:05.937273 12802 net.cpp:413] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I1028 19:08:05.937278 12802 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1028 19:08:05.937288 12802 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1028 19:08:05.937346 12802 net.cpp:127] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1028 19:08:05.937352 12802 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 19:08:05.937357 12802 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 19:08:05.937361 12802 net.cpp:144] Memory required for data: 1278534200
I1028 19:08:05.937364 12802 layer_factory.hpp:77] Creating layer fire6/expand1x1
I1028 19:08:05.937373 12802 net.cpp:84] Creating Layer fire6/expand1x1
I1028 19:08:05.937384 12802 net.cpp:413] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1028 19:08:05.937391 12802 net.cpp:387] fire6/expand1x1 -> fire6/expand1x1
I1028 19:08:05.937805 12802 net.cpp:127] Setting up fire6/expand1x1
I1028 19:08:05.937813 12802 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 19:08:05.937816 12802 net.cpp:144] Memory required for data: 1286060600
I1028 19:08:05.937821 12802 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1028 19:08:05.937827 12802 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1028 19:08:05.937831 12802 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1028 19:08:05.937836 12802 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1028 19:08:05.937839 12802 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I1028 19:08:05.937845 12802 net.cpp:84] Creating Layer fire6/relu_expand1x1
I1028 19:08:05.937849 12802 net.cpp:413] fire6/relu_expand1x1 <- fire6/expand1x1
I1028 19:08:05.937860 12802 net.cpp:374] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I1028 19:08:05.939266 12802 net.cpp:127] Setting up fire6/relu_expand1x1
I1028 19:08:05.939280 12802 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 19:08:05.939285 12802 net.cpp:144] Memory required for data: 1293587000
I1028 19:08:05.939290 12802 layer_factory.hpp:77] Creating layer fire6/expand3x3
I1028 19:08:05.939301 12802 net.cpp:84] Creating Layer fire6/expand3x3
I1028 19:08:05.939306 12802 net.cpp:413] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1028 19:08:05.939314 12802 net.cpp:387] fire6/expand3x3 -> fire6/expand3x3
I1028 19:08:05.940377 12802 net.cpp:127] Setting up fire6/expand3x3
I1028 19:08:05.940387 12802 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 19:08:05.940407 12802 net.cpp:144] Memory required for data: 1301113400
I1028 19:08:05.940412 12802 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1028 19:08:05.940418 12802 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1028 19:08:05.940423 12802 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1028 19:08:05.940428 12802 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1028 19:08:05.940431 12802 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I1028 19:08:05.940438 12802 net.cpp:84] Creating Layer fire6/relu_expand3x3
I1028 19:08:05.940443 12802 net.cpp:413] fire6/relu_expand3x3 <- fire6/expand3x3
I1028 19:08:05.940450 12802 net.cpp:374] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I1028 19:08:05.940665 12802 net.cpp:127] Setting up fire6/relu_expand3x3
I1028 19:08:05.940673 12802 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 19:08:05.940677 12802 net.cpp:144] Memory required for data: 1308639800
I1028 19:08:05.940681 12802 layer_factory.hpp:77] Creating layer fire6/concat
I1028 19:08:05.940687 12802 net.cpp:84] Creating Layer fire6/concat
I1028 19:08:05.940691 12802 net.cpp:413] fire6/concat <- fire6/expand1x1
I1028 19:08:05.940696 12802 net.cpp:413] fire6/concat <- fire6/expand3x3
I1028 19:08:05.940704 12802 net.cpp:387] fire6/concat -> fire6/concat
I1028 19:08:05.940735 12802 net.cpp:127] Setting up fire6/concat
I1028 19:08:05.940742 12802 net.cpp:136] Top shape: 50 384 14 14 (3763200)
I1028 19:08:05.940745 12802 net.cpp:144] Memory required for data: 1323692600
I1028 19:08:05.940748 12802 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I1028 19:08:05.940764 12802 net.cpp:84] Creating Layer fire7/squeeze1x1
I1028 19:08:05.940769 12802 net.cpp:413] fire7/squeeze1x1 <- fire6/concat
I1028 19:08:05.940775 12802 net.cpp:387] fire7/squeeze1x1 -> fire7/squeeze1x1
I1028 19:08:05.941292 12802 net.cpp:127] Setting up fire7/squeeze1x1
I1028 19:08:05.941300 12802 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 19:08:05.941304 12802 net.cpp:144] Memory required for data: 1325574200
I1028 19:08:05.941318 12802 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1028 19:08:05.941328 12802 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1028 19:08:05.941332 12802 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1028 19:08:05.941337 12802 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1028 19:08:05.941341 12802 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I1028 19:08:05.941350 12802 net.cpp:84] Creating Layer fire7/relu_squeeze1x1
I1028 19:08:05.941354 12802 net.cpp:413] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I1028 19:08:05.941360 12802 net.cpp:374] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I1028 19:08:05.941571 12802 net.cpp:127] Setting up fire7/relu_squeeze1x1
I1028 19:08:05.941581 12802 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 19:08:05.941584 12802 net.cpp:144] Memory required for data: 1327455800
I1028 19:08:05.941588 12802 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1028 19:08:05.941596 12802 net.cpp:84] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1028 19:08:05.941601 12802 net.cpp:413] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I1028 19:08:05.941606 12802 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1028 19:08:05.941613 12802 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1028 19:08:05.941663 12802 net.cpp:127] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1028 19:08:05.941669 12802 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 19:08:05.941674 12802 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 19:08:05.941679 12802 net.cpp:144] Memory required for data: 1331219000
I1028 19:08:05.941697 12802 layer_factory.hpp:77] Creating layer fire7/expand1x1
I1028 19:08:05.941709 12802 net.cpp:84] Creating Layer fire7/expand1x1
I1028 19:08:05.941712 12802 net.cpp:413] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1028 19:08:05.941720 12802 net.cpp:387] fire7/expand1x1 -> fire7/expand1x1
I1028 19:08:05.942147 12802 net.cpp:127] Setting up fire7/expand1x1
I1028 19:08:05.942157 12802 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 19:08:05.942160 12802 net.cpp:144] Memory required for data: 1338745400
I1028 19:08:05.942165 12802 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1028 19:08:05.942172 12802 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1028 19:08:05.942176 12802 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1028 19:08:05.942180 12802 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1028 19:08:05.942183 12802 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I1028 19:08:05.942191 12802 net.cpp:84] Creating Layer fire7/relu_expand1x1
I1028 19:08:05.942195 12802 net.cpp:413] fire7/relu_expand1x1 <- fire7/expand1x1
I1028 19:08:05.942201 12802 net.cpp:374] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I1028 19:08:05.943583 12802 net.cpp:127] Setting up fire7/relu_expand1x1
I1028 19:08:05.943598 12802 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 19:08:05.943601 12802 net.cpp:144] Memory required for data: 1346271800
I1028 19:08:05.943605 12802 layer_factory.hpp:77] Creating layer fire7/expand3x3
I1028 19:08:05.943617 12802 net.cpp:84] Creating Layer fire7/expand3x3
I1028 19:08:05.943625 12802 net.cpp:413] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1028 19:08:05.943634 12802 net.cpp:387] fire7/expand3x3 -> fire7/expand3x3
I1028 19:08:05.944697 12802 net.cpp:127] Setting up fire7/expand3x3
I1028 19:08:05.944707 12802 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 19:08:05.944713 12802 net.cpp:144] Memory required for data: 1353798200
I1028 19:08:05.944720 12802 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1028 19:08:05.944725 12802 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1028 19:08:05.944730 12802 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1028 19:08:05.944736 12802 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1028 19:08:05.944738 12802 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I1028 19:08:05.944746 12802 net.cpp:84] Creating Layer fire7/relu_expand3x3
I1028 19:08:05.944749 12802 net.cpp:413] fire7/relu_expand3x3 <- fire7/expand3x3
I1028 19:08:05.944756 12802 net.cpp:374] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I1028 19:08:05.944980 12802 net.cpp:127] Setting up fire7/relu_expand3x3
I1028 19:08:05.944993 12802 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 19:08:05.944996 12802 net.cpp:144] Memory required for data: 1361324600
I1028 19:08:05.945000 12802 layer_factory.hpp:77] Creating layer fire7/concat
I1028 19:08:05.945006 12802 net.cpp:84] Creating Layer fire7/concat
I1028 19:08:05.945010 12802 net.cpp:413] fire7/concat <- fire7/expand1x1
I1028 19:08:05.945015 12802 net.cpp:413] fire7/concat <- fire7/expand3x3
I1028 19:08:05.945021 12802 net.cpp:387] fire7/concat -> fire7/concat
I1028 19:08:05.945055 12802 net.cpp:127] Setting up fire7/concat
I1028 19:08:05.945060 12802 net.cpp:136] Top shape: 50 384 14 14 (3763200)
I1028 19:08:05.945065 12802 net.cpp:144] Memory required for data: 1376377400
I1028 19:08:05.945067 12802 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I1028 19:08:05.945077 12802 net.cpp:84] Creating Layer fire8/squeeze1x1
I1028 19:08:05.945081 12802 net.cpp:413] fire8/squeeze1x1 <- fire7/concat
I1028 19:08:05.945089 12802 net.cpp:387] fire8/squeeze1x1 -> fire8/squeeze1x1
I1028 19:08:05.947031 12802 net.cpp:127] Setting up fire8/squeeze1x1
I1028 19:08:05.947058 12802 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 19:08:05.947062 12802 net.cpp:144] Memory required for data: 1378886200
I1028 19:08:05.947069 12802 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1028 19:08:05.947075 12802 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1028 19:08:05.947080 12802 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1028 19:08:05.947084 12802 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1028 19:08:05.947088 12802 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I1028 19:08:05.947095 12802 net.cpp:84] Creating Layer fire8/relu_squeeze1x1
I1028 19:08:05.947099 12802 net.cpp:413] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I1028 19:08:05.947108 12802 net.cpp:374] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I1028 19:08:05.947333 12802 net.cpp:127] Setting up fire8/relu_squeeze1x1
I1028 19:08:05.947342 12802 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 19:08:05.947346 12802 net.cpp:144] Memory required for data: 1381395000
I1028 19:08:05.947350 12802 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1028 19:08:05.947357 12802 net.cpp:84] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1028 19:08:05.947361 12802 net.cpp:413] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I1028 19:08:05.947368 12802 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1028 19:08:05.947376 12802 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1028 19:08:05.947432 12802 net.cpp:127] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1028 19:08:05.947439 12802 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 19:08:05.947444 12802 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 19:08:05.947448 12802 net.cpp:144] Memory required for data: 1386412600
I1028 19:08:05.947451 12802 layer_factory.hpp:77] Creating layer fire8/expand1x1
I1028 19:08:05.947461 12802 net.cpp:84] Creating Layer fire8/expand1x1
I1028 19:08:05.947466 12802 net.cpp:413] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1028 19:08:05.947473 12802 net.cpp:387] fire8/expand1x1 -> fire8/expand1x1
I1028 19:08:05.947959 12802 net.cpp:127] Setting up fire8/expand1x1
I1028 19:08:05.947968 12802 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 19:08:05.947971 12802 net.cpp:144] Memory required for data: 1396447800
I1028 19:08:05.947978 12802 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1028 19:08:05.947983 12802 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1028 19:08:05.947988 12802 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1028 19:08:05.947993 12802 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1028 19:08:05.947995 12802 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I1028 19:08:05.948001 12802 net.cpp:84] Creating Layer fire8/relu_expand1x1
I1028 19:08:05.948009 12802 net.cpp:413] fire8/relu_expand1x1 <- fire8/expand1x1
I1028 19:08:05.948016 12802 net.cpp:374] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I1028 19:08:05.948235 12802 net.cpp:127] Setting up fire8/relu_expand1x1
I1028 19:08:05.948242 12802 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 19:08:05.948246 12802 net.cpp:144] Memory required for data: 1406483000
I1028 19:08:05.948251 12802 layer_factory.hpp:77] Creating layer fire8/expand3x3
I1028 19:08:05.948262 12802 net.cpp:84] Creating Layer fire8/expand3x3
I1028 19:08:05.948266 12802 net.cpp:413] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1028 19:08:05.948276 12802 net.cpp:387] fire8/expand3x3 -> fire8/expand3x3
I1028 19:08:05.951140 12802 net.cpp:127] Setting up fire8/expand3x3
I1028 19:08:05.951154 12802 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 19:08:05.951170 12802 net.cpp:144] Memory required for data: 1416518200
I1028 19:08:05.951177 12802 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1028 19:08:05.951184 12802 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1028 19:08:05.951189 12802 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1028 19:08:05.951192 12802 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1028 19:08:05.951196 12802 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I1028 19:08:05.951210 12802 net.cpp:84] Creating Layer fire8/relu_expand3x3
I1028 19:08:05.951215 12802 net.cpp:413] fire8/relu_expand3x3 <- fire8/expand3x3
I1028 19:08:05.951221 12802 net.cpp:374] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I1028 19:08:05.952644 12802 net.cpp:127] Setting up fire8/relu_expand3x3
I1028 19:08:05.952661 12802 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 19:08:05.952666 12802 net.cpp:144] Memory required for data: 1426553400
I1028 19:08:05.952670 12802 layer_factory.hpp:77] Creating layer fire8/concat
I1028 19:08:05.952677 12802 net.cpp:84] Creating Layer fire8/concat
I1028 19:08:05.952682 12802 net.cpp:413] fire8/concat <- fire8/expand1x1
I1028 19:08:05.952687 12802 net.cpp:413] fire8/concat <- fire8/expand3x3
I1028 19:08:05.952693 12802 net.cpp:387] fire8/concat -> fire8/concat
I1028 19:08:05.952731 12802 net.cpp:127] Setting up fire8/concat
I1028 19:08:05.952738 12802 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1028 19:08:05.952741 12802 net.cpp:144] Memory required for data: 1446623800
I1028 19:08:05.952745 12802 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I1028 19:08:05.952759 12802 net.cpp:84] Creating Layer fire9/squeeze1x1
I1028 19:08:05.952764 12802 net.cpp:413] fire9/squeeze1x1 <- fire8/concat
I1028 19:08:05.952771 12802 net.cpp:387] fire9/squeeze1x1 -> fire9/squeeze1x1
I1028 19:08:05.953394 12802 net.cpp:127] Setting up fire9/squeeze1x1
I1028 19:08:05.953403 12802 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 19:08:05.953408 12802 net.cpp:144] Memory required for data: 1449132600
I1028 19:08:05.953413 12802 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1028 19:08:05.953419 12802 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1028 19:08:05.953423 12802 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1028 19:08:05.953428 12802 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1028 19:08:05.953431 12802 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I1028 19:08:05.953444 12802 net.cpp:84] Creating Layer fire9/relu_squeeze1x1
I1028 19:08:05.953449 12802 net.cpp:413] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I1028 19:08:05.953455 12802 net.cpp:374] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I1028 19:08:05.953666 12802 net.cpp:127] Setting up fire9/relu_squeeze1x1
I1028 19:08:05.953675 12802 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 19:08:05.953680 12802 net.cpp:144] Memory required for data: 1451641400
I1028 19:08:05.953683 12802 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1028 19:08:05.953691 12802 net.cpp:84] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1028 19:08:05.953694 12802 net.cpp:413] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I1028 19:08:05.953702 12802 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1028 19:08:05.953716 12802 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1028 19:08:05.953766 12802 net.cpp:127] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1028 19:08:05.953773 12802 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 19:08:05.953778 12802 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 19:08:05.953780 12802 net.cpp:144] Memory required for data: 1456659000
I1028 19:08:05.953797 12802 layer_factory.hpp:77] Creating layer fire9/expand1x1
I1028 19:08:05.953807 12802 net.cpp:84] Creating Layer fire9/expand1x1
I1028 19:08:05.953812 12802 net.cpp:413] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1028 19:08:05.953820 12802 net.cpp:387] fire9/expand1x1 -> fire9/expand1x1
I1028 19:08:05.954305 12802 net.cpp:127] Setting up fire9/expand1x1
I1028 19:08:05.954318 12802 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 19:08:05.954321 12802 net.cpp:144] Memory required for data: 1466694200
I1028 19:08:05.954326 12802 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1028 19:08:05.954332 12802 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1028 19:08:05.954336 12802 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1028 19:08:05.954340 12802 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1028 19:08:05.954344 12802 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I1028 19:08:05.954350 12802 net.cpp:84] Creating Layer fire9/relu_expand1x1
I1028 19:08:05.954355 12802 net.cpp:413] fire9/relu_expand1x1 <- fire9/expand1x1
I1028 19:08:05.954360 12802 net.cpp:374] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I1028 19:08:05.954573 12802 net.cpp:127] Setting up fire9/relu_expand1x1
I1028 19:08:05.954583 12802 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 19:08:05.954587 12802 net.cpp:144] Memory required for data: 1476729400
I1028 19:08:05.954591 12802 layer_factory.hpp:77] Creating layer fire9/expand3x3
I1028 19:08:05.954601 12802 net.cpp:84] Creating Layer fire9/expand3x3
I1028 19:08:05.954607 12802 net.cpp:413] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1028 19:08:05.954617 12802 net.cpp:387] fire9/expand3x3 -> fire9/expand3x3
I1028 19:08:05.957499 12802 net.cpp:127] Setting up fire9/expand3x3
I1028 19:08:05.957514 12802 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 19:08:05.957517 12802 net.cpp:144] Memory required for data: 1486764600
I1028 19:08:05.957525 12802 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1028 19:08:05.957530 12802 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1028 19:08:05.957535 12802 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1028 19:08:05.957540 12802 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1028 19:08:05.957543 12802 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I1028 19:08:05.957551 12802 net.cpp:84] Creating Layer fire9/relu_expand3x3
I1028 19:08:05.957556 12802 net.cpp:413] fire9/relu_expand3x3 <- fire9/expand3x3
I1028 19:08:05.957563 12802 net.cpp:374] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I1028 19:08:05.957787 12802 net.cpp:127] Setting up fire9/relu_expand3x3
I1028 19:08:05.957797 12802 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 19:08:05.957800 12802 net.cpp:144] Memory required for data: 1496799800
I1028 19:08:05.957804 12802 layer_factory.hpp:77] Creating layer fire9/concat
I1028 19:08:05.957810 12802 net.cpp:84] Creating Layer fire9/concat
I1028 19:08:05.957814 12802 net.cpp:413] fire9/concat <- fire9/expand1x1
I1028 19:08:05.957820 12802 net.cpp:413] fire9/concat <- fire9/expand3x3
I1028 19:08:05.957828 12802 net.cpp:387] fire9/concat -> fire9/concat
I1028 19:08:05.957862 12802 net.cpp:127] Setting up fire9/concat
I1028 19:08:05.957868 12802 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1028 19:08:05.957871 12802 net.cpp:144] Memory required for data: 1516870200
I1028 19:08:05.957875 12802 layer_factory.hpp:77] Creating layer drop9
I1028 19:08:05.957882 12802 net.cpp:84] Creating Layer drop9
I1028 19:08:05.957886 12802 net.cpp:413] drop9 <- fire9/concat
I1028 19:08:05.957891 12802 net.cpp:374] drop9 -> fire9/concat (in-place)
I1028 19:08:05.957926 12802 net.cpp:127] Setting up drop9
I1028 19:08:05.957932 12802 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1028 19:08:05.957948 12802 net.cpp:144] Memory required for data: 1536940600
I1028 19:08:05.957952 12802 layer_factory.hpp:77] Creating layer conv10
I1028 19:08:05.957962 12802 net.cpp:84] Creating Layer conv10
I1028 19:08:05.957967 12802 net.cpp:413] conv10 <- fire9/concat
I1028 19:08:05.957979 12802 net.cpp:387] conv10 -> conv10
I1028 19:08:05.967545 12802 net.cpp:127] Setting up conv10
I1028 19:08:05.967561 12802 net.cpp:136] Top shape: 50 1000 14 14 (9800000)
I1028 19:08:05.967564 12802 net.cpp:144] Memory required for data: 1576140600
I1028 19:08:05.967571 12802 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1028 19:08:05.967577 12802 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1028 19:08:05.967582 12802 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1028 19:08:05.967586 12802 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1028 19:08:05.967591 12802 layer_factory.hpp:77] Creating layer relu_conv10
I1028 19:08:05.967600 12802 net.cpp:84] Creating Layer relu_conv10
I1028 19:08:05.967605 12802 net.cpp:413] relu_conv10 <- conv10
I1028 19:08:05.967612 12802 net.cpp:374] relu_conv10 -> conv10 (in-place)
I1028 19:08:05.969034 12802 net.cpp:127] Setting up relu_conv10
I1028 19:08:05.969048 12802 net.cpp:136] Top shape: 50 1000 14 14 (9800000)
I1028 19:08:05.969053 12802 net.cpp:144] Memory required for data: 1615340600
I1028 19:08:05.969058 12802 layer_factory.hpp:77] Creating layer pool10
I1028 19:08:05.969068 12802 net.cpp:84] Creating Layer pool10
I1028 19:08:05.969071 12802 net.cpp:413] pool10 <- conv10
I1028 19:08:05.969079 12802 net.cpp:387] pool10 -> pool10
I1028 19:08:05.969313 12802 net.cpp:127] Setting up pool10
I1028 19:08:05.969323 12802 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1028 19:08:05.969327 12802 net.cpp:144] Memory required for data: 1615540600
I1028 19:08:05.969331 12802 layer_factory.hpp:77] Creating layer pool10_pool10_0_split
I1028 19:08:05.969338 12802 net.cpp:84] Creating Layer pool10_pool10_0_split
I1028 19:08:05.969342 12802 net.cpp:413] pool10_pool10_0_split <- pool10
I1028 19:08:05.969348 12802 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_0
I1028 19:08:05.969357 12802 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_1
I1028 19:08:05.969364 12802 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_2
I1028 19:08:05.969434 12802 net.cpp:127] Setting up pool10_pool10_0_split
I1028 19:08:05.969439 12802 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1028 19:08:05.969444 12802 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1028 19:08:05.969449 12802 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1028 19:08:05.969452 12802 net.cpp:144] Memory required for data: 1616140600
I1028 19:08:05.969455 12802 layer_factory.hpp:77] Creating layer loss
I1028 19:08:05.969463 12802 net.cpp:84] Creating Layer loss
I1028 19:08:05.969468 12802 net.cpp:413] loss <- pool10_pool10_0_split_0
I1028 19:08:05.969473 12802 net.cpp:413] loss <- label_data_1_split_0
I1028 19:08:05.969478 12802 net.cpp:387] loss -> loss
I1028 19:08:05.969486 12802 layer_factory.hpp:77] Creating layer loss
I1028 19:08:05.969838 12802 net.cpp:127] Setting up loss
I1028 19:08:05.969848 12802 net.cpp:136] Top shape: (1)
I1028 19:08:05.969851 12802 net.cpp:139]     with loss weight 1
I1028 19:08:05.969864 12802 net.cpp:144] Memory required for data: 1616140604
I1028 19:08:05.969868 12802 layer_factory.hpp:77] Creating layer accuracy_top1
I1028 19:08:05.969880 12802 net.cpp:84] Creating Layer accuracy_top1
I1028 19:08:05.969885 12802 net.cpp:413] accuracy_top1 <- pool10_pool10_0_split_1
I1028 19:08:05.969892 12802 net.cpp:413] accuracy_top1 <- label_data_1_split_1
I1028 19:08:05.969897 12802 net.cpp:387] accuracy_top1 -> accuracy_top1
I1028 19:08:05.969909 12802 net.cpp:127] Setting up accuracy_top1
I1028 19:08:05.969914 12802 net.cpp:136] Top shape: (1)
I1028 19:08:05.969924 12802 net.cpp:144] Memory required for data: 1616140608
I1028 19:08:05.969928 12802 layer_factory.hpp:77] Creating layer accuracy_top5
I1028 19:08:05.969951 12802 net.cpp:84] Creating Layer accuracy_top5
I1028 19:08:05.969956 12802 net.cpp:413] accuracy_top5 <- pool10_pool10_0_split_2
I1028 19:08:05.969962 12802 net.cpp:413] accuracy_top5 <- label_data_1_split_2
I1028 19:08:05.969969 12802 net.cpp:387] accuracy_top5 -> accuracy_top5
I1028 19:08:05.969985 12802 net.cpp:127] Setting up accuracy_top5
I1028 19:08:05.969990 12802 net.cpp:136] Top shape: (1)
I1028 19:08:05.969995 12802 net.cpp:144] Memory required for data: 1616140612
I1028 19:08:05.969997 12802 net.cpp:207] accuracy_top5 does not need backward computation.
I1028 19:08:05.970002 12802 net.cpp:207] accuracy_top1 does not need backward computation.
I1028 19:08:05.970006 12802 net.cpp:205] loss needs backward computation.
I1028 19:08:05.970010 12802 net.cpp:205] pool10_pool10_0_split needs backward computation.
I1028 19:08:05.970015 12802 net.cpp:205] pool10 needs backward computation.
I1028 19:08:05.970018 12802 net.cpp:205] relu_conv10 needs backward computation.
I1028 19:08:05.970022 12802 net.cpp:205] conv10 needs backward computation.
I1028 19:08:05.970026 12802 net.cpp:205] drop9 needs backward computation.
I1028 19:08:05.970029 12802 net.cpp:205] fire9/concat needs backward computation.
I1028 19:08:05.970034 12802 net.cpp:205] fire9/relu_expand3x3 needs backward computation.
I1028 19:08:05.970037 12802 net.cpp:205] fire9/expand3x3 needs backward computation.
I1028 19:08:05.970041 12802 net.cpp:205] fire9/relu_expand1x1 needs backward computation.
I1028 19:08:05.970046 12802 net.cpp:205] fire9/expand1x1 needs backward computation.
I1028 19:08:05.970049 12802 net.cpp:205] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I1028 19:08:05.970057 12802 net.cpp:205] fire9/relu_squeeze1x1 needs backward computation.
I1028 19:08:05.970060 12802 net.cpp:205] fire9/squeeze1x1 needs backward computation.
I1028 19:08:05.970064 12802 net.cpp:205] fire8/concat needs backward computation.
I1028 19:08:05.970069 12802 net.cpp:205] fire8/relu_expand3x3 needs backward computation.
I1028 19:08:05.970072 12802 net.cpp:205] fire8/expand3x3 needs backward computation.
I1028 19:08:05.970077 12802 net.cpp:205] fire8/relu_expand1x1 needs backward computation.
I1028 19:08:05.970080 12802 net.cpp:205] fire8/expand1x1 needs backward computation.
I1028 19:08:05.970084 12802 net.cpp:205] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I1028 19:08:05.970088 12802 net.cpp:205] fire8/relu_squeeze1x1 needs backward computation.
I1028 19:08:05.970091 12802 net.cpp:205] fire8/squeeze1x1 needs backward computation.
I1028 19:08:05.970095 12802 net.cpp:205] fire7/concat needs backward computation.
I1028 19:08:05.970099 12802 net.cpp:205] fire7/relu_expand3x3 needs backward computation.
I1028 19:08:05.970103 12802 net.cpp:205] fire7/expand3x3 needs backward computation.
I1028 19:08:05.970106 12802 net.cpp:205] fire7/relu_expand1x1 needs backward computation.
I1028 19:08:05.970110 12802 net.cpp:205] fire7/expand1x1 needs backward computation.
I1028 19:08:05.970113 12802 net.cpp:205] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I1028 19:08:05.970118 12802 net.cpp:205] fire7/relu_squeeze1x1 needs backward computation.
I1028 19:08:05.970121 12802 net.cpp:205] fire7/squeeze1x1 needs backward computation.
I1028 19:08:05.970125 12802 net.cpp:205] fire6/concat needs backward computation.
I1028 19:08:05.970129 12802 net.cpp:205] fire6/relu_expand3x3 needs backward computation.
I1028 19:08:05.970132 12802 net.cpp:205] fire6/expand3x3 needs backward computation.
I1028 19:08:05.970136 12802 net.cpp:205] fire6/relu_expand1x1 needs backward computation.
I1028 19:08:05.970139 12802 net.cpp:205] fire6/expand1x1 needs backward computation.
I1028 19:08:05.970144 12802 net.cpp:205] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I1028 19:08:05.970147 12802 net.cpp:205] fire6/relu_squeeze1x1 needs backward computation.
I1028 19:08:05.970150 12802 net.cpp:205] fire6/squeeze1x1 needs backward computation.
I1028 19:08:05.970155 12802 net.cpp:205] pool5 needs backward computation.
I1028 19:08:05.970163 12802 net.cpp:205] fire5/concat needs backward computation.
I1028 19:08:05.970167 12802 net.cpp:205] fire5/relu_expand3x3 needs backward computation.
I1028 19:08:05.970171 12802 net.cpp:205] fire5/expand3x3 needs backward computation.
I1028 19:08:05.970175 12802 net.cpp:205] fire5/relu_expand1x1 needs backward computation.
I1028 19:08:05.970178 12802 net.cpp:205] fire5/expand1x1 needs backward computation.
I1028 19:08:05.970183 12802 net.cpp:205] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I1028 19:08:05.970187 12802 net.cpp:205] fire5/relu_squeeze1x1 needs backward computation.
I1028 19:08:05.970191 12802 net.cpp:205] fire5/squeeze1x1 needs backward computation.
I1028 19:08:05.970194 12802 net.cpp:205] fire4/concat needs backward computation.
I1028 19:08:05.970199 12802 net.cpp:205] fire4/relu_expand3x3 needs backward computation.
I1028 19:08:05.970202 12802 net.cpp:205] fire4/expand3x3 needs backward computation.
I1028 19:08:05.970206 12802 net.cpp:205] fire4/relu_expand1x1 needs backward computation.
I1028 19:08:05.970209 12802 net.cpp:205] fire4/expand1x1 needs backward computation.
I1028 19:08:05.970213 12802 net.cpp:205] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I1028 19:08:05.970216 12802 net.cpp:205] fire4/relu_squeeze1x1 needs backward computation.
I1028 19:08:05.970221 12802 net.cpp:205] fire4/squeeze1x1 needs backward computation.
I1028 19:08:05.970224 12802 net.cpp:205] pool3 needs backward computation.
I1028 19:08:05.970228 12802 net.cpp:205] fire3/concat needs backward computation.
I1028 19:08:05.970232 12802 net.cpp:205] fire3/relu_expand3x3 needs backward computation.
I1028 19:08:05.970237 12802 net.cpp:205] fire3/expand3x3 needs backward computation.
I1028 19:08:05.970242 12802 net.cpp:205] fire3/relu_expand1x1 needs backward computation.
I1028 19:08:05.970245 12802 net.cpp:205] fire3/expand1x1 needs backward computation.
I1028 19:08:05.970248 12802 net.cpp:205] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I1028 19:08:05.970252 12802 net.cpp:205] fire3/relu_squeeze1x1 needs backward computation.
I1028 19:08:05.970257 12802 net.cpp:205] fire3/squeeze1x1 needs backward computation.
I1028 19:08:05.970259 12802 net.cpp:205] fire2/concat needs backward computation.
I1028 19:08:05.970264 12802 net.cpp:205] fire2/relu_expand3x3 needs backward computation.
I1028 19:08:05.970268 12802 net.cpp:205] fire2/expand3x3 needs backward computation.
I1028 19:08:05.970271 12802 net.cpp:205] fire2/relu_expand1x1 needs backward computation.
I1028 19:08:05.970274 12802 net.cpp:205] fire2/expand1x1 needs backward computation.
I1028 19:08:05.970278 12802 net.cpp:205] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I1028 19:08:05.970281 12802 net.cpp:205] fire2/relu_squeeze1x1 needs backward computation.
I1028 19:08:05.970285 12802 net.cpp:205] fire2/squeeze1x1 needs backward computation.
I1028 19:08:05.970289 12802 net.cpp:205] pool1 needs backward computation.
I1028 19:08:05.970293 12802 net.cpp:205] relu_conv1 needs backward computation.
I1028 19:08:05.970296 12802 net.cpp:205] conv1 needs backward computation.
I1028 19:08:05.970301 12802 net.cpp:207] label_data_1_split does not need backward computation.
I1028 19:08:05.970306 12802 net.cpp:207] data does not need backward computation.
I1028 19:08:05.970309 12802 net.cpp:249] This network produces output accuracy_top1
I1028 19:08:05.970314 12802 net.cpp:249] This network produces output accuracy_top5
I1028 19:08:05.970319 12802 net.cpp:249] This network produces output loss
I1028 19:08:05.970374 12802 net.cpp:262] Network initialization done.
I1028 19:08:05.970644 12802 solver.cpp:56] Solver scaffolding done.
I1028 19:08:05.975430 12802 caffe.cpp:242] Resuming from SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_3589.solverstate
I1028 19:08:06.008463 12802 sgd_solver.cpp:372] SGDSolver: restoring history
I1028 19:08:06.025955 12802 caffe.cpp:248] Starting Optimization
I1028 19:08:09.738246 12852 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_40.prototxt
I1028 19:08:09.742390 12854 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_40.prototxt
I1028 19:08:09.745225 12853 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_40.prototxt
I1028 19:08:10.497870 12853 sgd_solver.cpp:372] SGDSolver: restoring history
I1028 19:08:10.499611 12852 sgd_solver.cpp:372] SGDSolver: restoring history
I1028 19:08:10.505476 12854 sgd_solver.cpp:372] SGDSolver: restoring history
I1028 19:08:10.788415 12802 solver.cpp:276] Solving SqueezeNet
I1028 19:08:10.788463 12802 solver.cpp:277] Learning Rate Policy: exp
I1028 19:08:20.271499 12802 solver.cpp:222] Iteration 3600 (379.679 iter/s, 9.4817s/40 iters), loss = 1.41329
I1028 19:08:20.271558 12802 solver.cpp:241]     Train net output #0: loss = 1.41329 (* 1 = 1.41329 loss)
I1028 19:08:20.271571 12802 sgd_solver.cpp:105] Iteration 3600, lr = 0.00723232
I1028 19:08:50.350255 12802 solver.cpp:222] Iteration 3640 (1.32988 iter/s, 30.078s/40 iters), loss = 1.53537
I1028 19:08:50.350406 12802 solver.cpp:241]     Train net output #0: loss = 1.53537 (* 1 = 1.53537 loss)
I1028 19:08:50.350419 12802 sgd_solver.cpp:105] Iteration 3640, lr = 0.00720633
I1028 19:09:21.375655 12802 solver.cpp:222] Iteration 3680 (1.2893 iter/s, 31.0245s/40 iters), loss = 1.42932
I1028 19:09:21.375828 12802 solver.cpp:241]     Train net output #0: loss = 1.42932 (* 1 = 1.42932 loss)
I1028 19:09:21.375843 12802 sgd_solver.cpp:105] Iteration 3680, lr = 0.00718043
I1028 19:09:52.088201 12802 solver.cpp:222] Iteration 3720 (1.30244 iter/s, 30.7117s/40 iters), loss = 1.33094
I1028 19:09:52.088304 12802 solver.cpp:241]     Train net output #0: loss = 1.33094 (* 1 = 1.33094 loss)
I1028 19:09:52.088318 12802 sgd_solver.cpp:105] Iteration 3720, lr = 0.00715462
I1028 19:10:22.727825 12802 solver.cpp:222] Iteration 3760 (1.30553 iter/s, 30.6388s/40 iters), loss = 1.47208
I1028 19:10:22.728057 12802 solver.cpp:241]     Train net output #0: loss = 1.47208 (* 1 = 1.47208 loss)
I1028 19:10:22.728073 12802 sgd_solver.cpp:105] Iteration 3760, lr = 0.00712891
I1028 19:10:53.322765 12802 solver.cpp:222] Iteration 3800 (1.30745 iter/s, 30.594s/40 iters), loss = 1.29791
I1028 19:10:53.322944 12802 solver.cpp:241]     Train net output #0: loss = 1.29791 (* 1 = 1.29791 loss)
I1028 19:10:53.322962 12802 sgd_solver.cpp:105] Iteration 3800, lr = 0.00710329
I1028 19:11:23.897893 12802 solver.cpp:222] Iteration 3840 (1.30829 iter/s, 30.5742s/40 iters), loss = 1.50453
I1028 19:11:23.898071 12802 solver.cpp:241]     Train net output #0: loss = 1.50453 (* 1 = 1.50453 loss)
I1028 19:11:23.898085 12802 sgd_solver.cpp:105] Iteration 3840, lr = 0.00707776
I1028 19:11:54.830354 12802 solver.cpp:222] Iteration 3880 (1.29318 iter/s, 30.9316s/40 iters), loss = 1.4836
I1028 19:11:54.830499 12802 solver.cpp:241]     Train net output #0: loss = 1.4836 (* 1 = 1.4836 loss)
I1028 19:11:54.830516 12802 sgd_solver.cpp:105] Iteration 3880, lr = 0.00705233
I1028 19:12:25.904445 12802 solver.cpp:222] Iteration 3920 (1.28728 iter/s, 31.0732s/40 iters), loss = 1.77281
I1028 19:12:25.904603 12802 solver.cpp:241]     Train net output #0: loss = 1.77281 (* 1 = 1.77281 loss)
I1028 19:12:25.904624 12802 sgd_solver.cpp:105] Iteration 3920, lr = 0.00702698
I1028 19:12:56.843724 12802 solver.cpp:222] Iteration 3960 (1.29289 iter/s, 30.9384s/40 iters), loss = 1.31897
I1028 19:12:56.843816 12802 solver.cpp:241]     Train net output #0: loss = 1.31897 (* 1 = 1.31897 loss)
I1028 19:12:56.843829 12802 sgd_solver.cpp:105] Iteration 3960, lr = 0.00700173
I1028 19:13:26.501353 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_4000.caffemodel
I1028 19:13:26.641973 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_4000.solverstate
I1028 19:13:26.755617 12802 solver.cpp:334] Iteration 4000, Testing net (#0)
I1028 19:13:57.930763 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53264
I1028 19:13:57.931040 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7742
I1028 19:13:57.931053 12802 solver.cpp:401]     Test net output #2: loss = 2.10515 (* 1 = 2.10515 loss)
I1028 19:13:58.695498 12802 solver.cpp:222] Iteration 4000 (0.646723 iter/s, 61.8502s/40 iters), loss = 1.32882
I1028 19:13:58.695531 12802 solver.cpp:241]     Train net output #0: loss = 1.32882 (* 1 = 1.32882 loss)
I1028 19:13:58.695549 12802 sgd_solver.cpp:105] Iteration 4000, lr = 0.00697657
I1028 19:14:29.368759 12802 solver.cpp:222] Iteration 4040 (1.3041 iter/s, 30.6725s/40 iters), loss = 1.22546
I1028 19:14:29.368945 12802 solver.cpp:241]     Train net output #0: loss = 1.22546 (* 1 = 1.22546 loss)
I1028 19:14:29.368963 12802 sgd_solver.cpp:105] Iteration 4040, lr = 0.00695149
I1028 19:15:00.114732 12802 solver.cpp:222] Iteration 4080 (1.30102 iter/s, 30.7451s/40 iters), loss = 1.74033
I1028 19:15:00.114868 12802 solver.cpp:241]     Train net output #0: loss = 1.74033 (* 1 = 1.74033 loss)
I1028 19:15:00.114890 12802 sgd_solver.cpp:105] Iteration 4080, lr = 0.00692651
I1028 19:15:30.640372 12802 solver.cpp:222] Iteration 4120 (1.31041 iter/s, 30.5248s/40 iters), loss = 1.76295
I1028 19:15:30.640512 12802 solver.cpp:241]     Train net output #0: loss = 1.76295 (* 1 = 1.76295 loss)
I1028 19:15:30.640529 12802 sgd_solver.cpp:105] Iteration 4120, lr = 0.00690162
I1028 19:16:01.127068 12802 solver.cpp:222] Iteration 4160 (1.31209 iter/s, 30.4858s/40 iters), loss = 1.73771
I1028 19:16:01.127195 12802 solver.cpp:241]     Train net output #0: loss = 1.73771 (* 1 = 1.73771 loss)
I1028 19:16:01.127221 12802 sgd_solver.cpp:105] Iteration 4160, lr = 0.00687682
I1028 19:16:32.038132 12802 solver.cpp:222] Iteration 4200 (1.29407 iter/s, 30.9102s/40 iters), loss = 1.48379
I1028 19:16:32.038285 12802 solver.cpp:241]     Train net output #0: loss = 1.48379 (* 1 = 1.48379 loss)
I1028 19:16:32.038300 12802 sgd_solver.cpp:105] Iteration 4200, lr = 0.0068521
I1028 19:17:02.974128 12802 solver.cpp:222] Iteration 4240 (1.29303 iter/s, 30.9351s/40 iters), loss = 1.64162
I1028 19:17:02.974292 12802 solver.cpp:241]     Train net output #0: loss = 1.64162 (* 1 = 1.64162 loss)
I1028 19:17:02.974308 12802 sgd_solver.cpp:105] Iteration 4240, lr = 0.00682748
I1028 19:17:34.228068 12802 solver.cpp:222] Iteration 4280 (1.27988 iter/s, 31.253s/40 iters), loss = 1.67384
I1028 19:17:34.228240 12802 solver.cpp:241]     Train net output #0: loss = 1.67384 (* 1 = 1.67384 loss)
I1028 19:17:34.228258 12802 sgd_solver.cpp:105] Iteration 4280, lr = 0.00680294
I1028 19:18:04.949004 12802 solver.cpp:222] Iteration 4320 (1.30208 iter/s, 30.72s/40 iters), loss = 1.43386
I1028 19:18:04.949159 12802 solver.cpp:241]     Train net output #0: loss = 1.43386 (* 1 = 1.43386 loss)
I1028 19:18:04.949173 12802 sgd_solver.cpp:105] Iteration 4320, lr = 0.00677849
I1028 19:18:35.689819 12802 solver.cpp:222] Iteration 4360 (1.30124 iter/s, 30.7399s/40 iters), loss = 1.67475
I1028 19:18:35.689995 12802 solver.cpp:241]     Train net output #0: loss = 1.67475 (* 1 = 1.67475 loss)
I1028 19:18:35.690013 12802 sgd_solver.cpp:105] Iteration 4360, lr = 0.00675413
I1028 19:19:07.028048 12802 solver.cpp:222] Iteration 4400 (1.27643 iter/s, 31.3373s/40 iters), loss = 1.71904
I1028 19:19:07.028208 12802 solver.cpp:241]     Train net output #0: loss = 1.71904 (* 1 = 1.71904 loss)
I1028 19:19:07.028223 12802 sgd_solver.cpp:105] Iteration 4400, lr = 0.00672986
I1028 19:19:37.811722 12802 solver.cpp:222] Iteration 4440 (1.29943 iter/s, 30.7828s/40 iters), loss = 1.64862
I1028 19:19:37.811894 12802 solver.cpp:241]     Train net output #0: loss = 1.64862 (* 1 = 1.64862 loss)
I1028 19:19:37.811909 12802 sgd_solver.cpp:105] Iteration 4440, lr = 0.00670567
I1028 19:20:08.552788 12802 solver.cpp:222] Iteration 4480 (1.30123 iter/s, 30.7402s/40 iters), loss = 1.93538
I1028 19:20:08.553012 12802 solver.cpp:241]     Train net output #0: loss = 1.93538 (* 1 = 1.93538 loss)
I1028 19:20:08.553030 12802 sgd_solver.cpp:105] Iteration 4480, lr = 0.00668157
I1028 19:20:23.248576 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_4500.caffemodel
I1028 19:20:23.389482 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_4500.solverstate
I1028 19:20:23.506544 12802 solver.cpp:334] Iteration 4500, Testing net (#0)
I1028 19:20:54.480867 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1028 19:20:54.693816 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53772
I1028 19:20:54.693869 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.778
I1028 19:20:54.693879 12802 solver.cpp:401]     Test net output #2: loss = 2.07773 (* 1 = 2.07773 loss)
I1028 19:21:10.388208 12802 solver.cpp:222] Iteration 4520 (0.646896 iter/s, 61.8337s/40 iters), loss = 1.69628
I1028 19:21:10.388296 12802 solver.cpp:241]     Train net output #0: loss = 1.69628 (* 1 = 1.69628 loss)
I1028 19:21:10.388309 12802 sgd_solver.cpp:105] Iteration 4520, lr = 0.00665756
I1028 19:21:40.097231 12802 solver.cpp:222] Iteration 4560 (1.34643 iter/s, 29.7082s/40 iters), loss = 1.533
I1028 19:21:40.097414 12802 solver.cpp:241]     Train net output #0: loss = 1.533 (* 1 = 1.533 loss)
I1028 19:21:40.097429 12802 sgd_solver.cpp:105] Iteration 4560, lr = 0.00663363
I1028 19:22:10.566622 12802 solver.cpp:222] Iteration 4600 (1.31283 iter/s, 30.4685s/40 iters), loss = 1.56031
I1028 19:22:10.566784 12802 solver.cpp:241]     Train net output #0: loss = 1.56031 (* 1 = 1.56031 loss)
I1028 19:22:10.566799 12802 sgd_solver.cpp:105] Iteration 4600, lr = 0.00660979
I1028 19:22:41.245359 12802 solver.cpp:222] Iteration 4640 (1.30387 iter/s, 30.6779s/40 iters), loss = 1.88693
I1028 19:22:41.245512 12802 solver.cpp:241]     Train net output #0: loss = 1.88693 (* 1 = 1.88693 loss)
I1028 19:22:41.245530 12802 sgd_solver.cpp:105] Iteration 4640, lr = 0.00658604
I1028 19:23:12.156930 12802 solver.cpp:222] Iteration 4680 (1.29405 iter/s, 30.9107s/40 iters), loss = 2.03062
I1028 19:23:12.157101 12802 solver.cpp:241]     Train net output #0: loss = 2.03062 (* 1 = 2.03062 loss)
I1028 19:23:12.157119 12802 sgd_solver.cpp:105] Iteration 4680, lr = 0.00656237
I1028 19:23:42.399554 12802 solver.cpp:222] Iteration 4720 (1.32268 iter/s, 30.2417s/40 iters), loss = 1.96661
I1028 19:23:42.399710 12802 solver.cpp:241]     Train net output #0: loss = 1.96661 (* 1 = 1.96661 loss)
I1028 19:23:42.399727 12802 sgd_solver.cpp:105] Iteration 4720, lr = 0.00653879
I1028 19:24:12.164703 12802 solver.cpp:222] Iteration 4760 (1.34389 iter/s, 29.7643s/40 iters), loss = 1.94549
I1028 19:24:12.164765 12802 solver.cpp:241]     Train net output #0: loss = 1.94549 (* 1 = 1.94549 loss)
I1028 19:24:12.164778 12802 sgd_solver.cpp:105] Iteration 4760, lr = 0.00651529
I1028 19:24:41.758174 12802 solver.cpp:222] Iteration 4800 (1.35168 iter/s, 29.5927s/40 iters), loss = 1.52325
I1028 19:24:41.758312 12802 solver.cpp:241]     Train net output #0: loss = 1.52325 (* 1 = 1.52325 loss)
I1028 19:24:41.758329 12802 sgd_solver.cpp:105] Iteration 4800, lr = 0.00649187
I1028 19:25:11.442785 12802 solver.cpp:222] Iteration 4840 (1.34754 iter/s, 29.6838s/40 iters), loss = 1.67159
I1028 19:25:11.442848 12802 solver.cpp:241]     Train net output #0: loss = 1.67159 (* 1 = 1.67159 loss)
I1028 19:25:11.442865 12802 sgd_solver.cpp:105] Iteration 4840, lr = 0.00646854
I1028 19:25:41.338233 12802 solver.cpp:222] Iteration 4880 (1.33803 iter/s, 29.8947s/40 iters), loss = 1.75457
I1028 19:25:41.338418 12802 solver.cpp:241]     Train net output #0: loss = 1.75457 (* 1 = 1.75457 loss)
I1028 19:25:41.338434 12802 sgd_solver.cpp:105] Iteration 4880, lr = 0.0064453
I1028 19:26:10.943209 12802 solver.cpp:222] Iteration 4920 (1.35116 iter/s, 29.6041s/40 iters), loss = 1.86982
I1028 19:26:10.943274 12802 solver.cpp:241]     Train net output #0: loss = 1.86982 (* 1 = 1.86982 loss)
I1028 19:26:10.943289 12802 sgd_solver.cpp:105] Iteration 4920, lr = 0.00642213
I1028 19:26:41.072605 12802 solver.cpp:222] Iteration 4960 (1.32764 iter/s, 30.1286s/40 iters), loss = 1.86657
I1028 19:26:41.072842 12802 solver.cpp:241]     Train net output #0: loss = 1.86657 (* 1 = 1.86657 loss)
I1028 19:26:41.072860 12802 sgd_solver.cpp:105] Iteration 4960, lr = 0.00639905
I1028 19:27:10.410749 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_5000.caffemodel
I1028 19:27:10.553519 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_5000.solverstate
I1028 19:27:10.675575 12802 solver.cpp:334] Iteration 5000, Testing net (#0)
I1028 19:27:42.165786 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53844
I1028 19:27:42.165942 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77784
I1028 19:27:42.165956 12802 solver.cpp:401]     Test net output #2: loss = 2.03961 (* 1 = 2.03961 loss)
I1028 19:27:42.922593 12802 solver.cpp:222] Iteration 5000 (0.646744 iter/s, 61.8483s/40 iters), loss = 1.97169
I1028 19:27:42.922652 12802 solver.cpp:241]     Train net output #0: loss = 1.97169 (* 1 = 1.97169 loss)
I1028 19:27:42.922667 12802 sgd_solver.cpp:105] Iteration 5000, lr = 0.00637606
I1028 19:28:12.812881 12802 solver.cpp:222] Iteration 5040 (1.33826 iter/s, 29.8895s/40 iters), loss = 1.72551
I1028 19:28:12.813024 12802 solver.cpp:241]     Train net output #0: loss = 1.72551 (* 1 = 1.72551 loss)
I1028 19:28:12.813040 12802 sgd_solver.cpp:105] Iteration 5040, lr = 0.00635314
I1028 19:28:42.778544 12802 solver.cpp:222] Iteration 5080 (1.3349 iter/s, 29.9648s/40 iters), loss = 1.44218
I1028 19:28:42.778614 12802 solver.cpp:241]     Train net output #0: loss = 1.44218 (* 1 = 1.44218 loss)
I1028 19:28:42.778637 12802 sgd_solver.cpp:105] Iteration 5080, lr = 0.00633031
I1028 19:29:12.698523 12802 solver.cpp:222] Iteration 5120 (1.33693 iter/s, 29.9192s/40 iters), loss = 1.498
I1028 19:29:12.698719 12802 solver.cpp:241]     Train net output #0: loss = 1.498 (* 1 = 1.498 loss)
I1028 19:29:12.698735 12802 sgd_solver.cpp:105] Iteration 5120, lr = 0.00630756
I1028 19:29:42.514001 12802 solver.cpp:222] Iteration 5160 (1.34163 iter/s, 29.8146s/40 iters), loss = 1.38432
I1028 19:29:42.514066 12802 solver.cpp:241]     Train net output #0: loss = 1.38432 (* 1 = 1.38432 loss)
I1028 19:29:42.514082 12802 sgd_solver.cpp:105] Iteration 5160, lr = 0.00628489
I1028 19:30:12.342540 12802 solver.cpp:222] Iteration 5200 (1.34103 iter/s, 29.8278s/40 iters), loss = 1.75909
I1028 19:30:12.342767 12802 solver.cpp:241]     Train net output #0: loss = 1.75909 (* 1 = 1.75909 loss)
I1028 19:30:12.342782 12802 sgd_solver.cpp:105] Iteration 5200, lr = 0.00626231
I1028 19:30:42.318729 12802 solver.cpp:222] Iteration 5240 (1.33443 iter/s, 29.9753s/40 iters), loss = 1.48158
I1028 19:30:42.318794 12802 solver.cpp:241]     Train net output #0: loss = 1.48158 (* 1 = 1.48158 loss)
I1028 19:30:42.318807 12802 sgd_solver.cpp:105] Iteration 5240, lr = 0.0062398
I1028 19:31:12.587795 12802 solver.cpp:222] Iteration 5280 (1.32152 iter/s, 30.2683s/40 iters), loss = 1.73566
I1028 19:31:12.588018 12802 solver.cpp:241]     Train net output #0: loss = 1.73566 (* 1 = 1.73566 loss)
I1028 19:31:12.588035 12802 sgd_solver.cpp:105] Iteration 5280, lr = 0.00621737
I1028 19:31:42.910848 12802 solver.cpp:222] Iteration 5320 (1.31917 iter/s, 30.3221s/40 iters), loss = 1.84637
I1028 19:31:42.911020 12802 solver.cpp:241]     Train net output #0: loss = 1.84637 (* 1 = 1.84637 loss)
I1028 19:31:42.911037 12802 sgd_solver.cpp:105] Iteration 5320, lr = 0.00619503
I1028 19:32:13.004039 12802 solver.cpp:222] Iteration 5360 (1.32924 iter/s, 30.0923s/40 iters), loss = 1.63783
I1028 19:32:13.004226 12802 solver.cpp:241]     Train net output #0: loss = 1.63783 (* 1 = 1.63783 loss)
I1028 19:32:13.004245 12802 sgd_solver.cpp:105] Iteration 5360, lr = 0.00617277
I1028 19:32:43.148046 12802 solver.cpp:222] Iteration 5400 (1.327 iter/s, 30.1431s/40 iters), loss = 1.9768
I1028 19:32:43.148274 12802 solver.cpp:241]     Train net output #0: loss = 1.9768 (* 1 = 1.9768 loss)
I1028 19:32:43.148291 12802 sgd_solver.cpp:105] Iteration 5400, lr = 0.00615058
I1028 19:33:13.412618 12802 solver.cpp:222] Iteration 5440 (1.32172 iter/s, 30.2636s/40 iters), loss = 1.59063
I1028 19:33:13.412825 12802 solver.cpp:241]     Train net output #0: loss = 1.59063 (* 1 = 1.59063 loss)
I1028 19:33:13.412842 12802 sgd_solver.cpp:105] Iteration 5440, lr = 0.00612848
I1028 19:33:43.855618 12802 solver.cpp:222] Iteration 5480 (1.31397 iter/s, 30.4421s/40 iters), loss = 1.40776
I1028 19:33:43.855818 12802 solver.cpp:241]     Train net output #0: loss = 1.40776 (* 1 = 1.40776 loss)
I1028 19:33:43.855835 12802 sgd_solver.cpp:105] Iteration 5480, lr = 0.00610645
I1028 19:33:58.084717 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_5500.caffemodel
I1028 19:33:58.249861 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_5500.solverstate
I1028 19:33:58.370080 12802 solver.cpp:334] Iteration 5500, Testing net (#0)
I1028 19:34:29.477587 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1028 19:34:29.687140 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54644
I1028 19:34:29.687191 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78548
I1028 19:34:29.687202 12802 solver.cpp:401]     Test net output #2: loss = 2.01616 (* 1 = 2.01616 loss)
I1028 19:34:45.896296 12802 solver.cpp:222] Iteration 5520 (0.644755 iter/s, 62.039s/40 iters), loss = 1.98618
I1028 19:34:45.896361 12802 solver.cpp:241]     Train net output #0: loss = 1.98618 (* 1 = 1.98618 loss)
I1028 19:34:45.896378 12802 sgd_solver.cpp:105] Iteration 5520, lr = 0.00608451
I1028 19:35:16.813160 12802 solver.cpp:222] Iteration 5560 (1.29383 iter/s, 30.9161s/40 iters), loss = 1.67269
I1028 19:35:16.813349 12802 solver.cpp:241]     Train net output #0: loss = 1.67269 (* 1 = 1.67269 loss)
I1028 19:35:16.813365 12802 sgd_solver.cpp:105] Iteration 5560, lr = 0.00606264
I1028 19:35:46.848337 12802 solver.cpp:222] Iteration 5600 (1.33181 iter/s, 30.0343s/40 iters), loss = 1.66288
I1028 19:35:46.848543 12802 solver.cpp:241]     Train net output #0: loss = 1.66288 (* 1 = 1.66288 loss)
I1028 19:35:46.848558 12802 sgd_solver.cpp:105] Iteration 5600, lr = 0.00604085
I1028 19:36:16.503717 12802 solver.cpp:222] Iteration 5640 (1.34887 iter/s, 29.6545s/40 iters), loss = 1.69258
I1028 19:36:16.503787 12802 solver.cpp:241]     Train net output #0: loss = 1.69258 (* 1 = 1.69258 loss)
I1028 19:36:16.503801 12802 sgd_solver.cpp:105] Iteration 5640, lr = 0.00601915
I1028 19:36:46.325935 12802 solver.cpp:222] Iteration 5680 (1.34132 iter/s, 29.8214s/40 iters), loss = 1.88475
I1028 19:36:46.326143 12802 solver.cpp:241]     Train net output #0: loss = 1.88475 (* 1 = 1.88475 loss)
I1028 19:36:46.326160 12802 sgd_solver.cpp:105] Iteration 5680, lr = 0.00599751
I1028 19:37:16.307296 12802 solver.cpp:222] Iteration 5720 (1.3342 iter/s, 29.9804s/40 iters), loss = 1.77096
I1028 19:37:16.307358 12802 solver.cpp:241]     Train net output #0: loss = 1.77096 (* 1 = 1.77096 loss)
I1028 19:37:16.307371 12802 sgd_solver.cpp:105] Iteration 5720, lr = 0.00597596
I1028 19:37:46.187856 12802 solver.cpp:222] Iteration 5760 (1.3387 iter/s, 29.8798s/40 iters), loss = 1.56027
I1028 19:37:46.188060 12802 solver.cpp:241]     Train net output #0: loss = 1.56027 (* 1 = 1.56027 loss)
I1028 19:37:46.188077 12802 sgd_solver.cpp:105] Iteration 5760, lr = 0.00595448
I1028 19:38:16.086755 12802 solver.cpp:222] Iteration 5800 (1.33788 iter/s, 29.898s/40 iters), loss = 2.07599
I1028 19:38:16.086822 12802 solver.cpp:241]     Train net output #0: loss = 2.07599 (* 1 = 2.07599 loss)
I1028 19:38:16.086838 12802 sgd_solver.cpp:105] Iteration 5800, lr = 0.00593308
I1028 19:38:45.800684 12802 solver.cpp:222] Iteration 5840 (1.3462 iter/s, 29.7132s/40 iters), loss = 1.27255
I1028 19:38:45.800942 12802 solver.cpp:241]     Train net output #0: loss = 1.27255 (* 1 = 1.27255 loss)
I1028 19:38:45.800961 12802 sgd_solver.cpp:105] Iteration 5840, lr = 0.00591176
I1028 19:39:15.520133 12802 solver.cpp:222] Iteration 5880 (1.34596 iter/s, 29.7185s/40 iters), loss = 1.42239
I1028 19:39:15.520196 12802 solver.cpp:241]     Train net output #0: loss = 1.42239 (* 1 = 1.42239 loss)
I1028 19:39:15.520211 12802 sgd_solver.cpp:105] Iteration 5880, lr = 0.00589052
I1028 19:39:45.507226 12802 solver.cpp:222] Iteration 5920 (1.33394 iter/s, 29.9863s/40 iters), loss = 1.86475
I1028 19:39:45.507444 12802 solver.cpp:241]     Train net output #0: loss = 1.86475 (* 1 = 1.86475 loss)
I1028 19:39:45.507460 12802 sgd_solver.cpp:105] Iteration 5920, lr = 0.00586935
I1028 19:40:15.771340 12802 solver.cpp:222] Iteration 5960 (1.32174 iter/s, 30.2632s/40 iters), loss = 1.53492
I1028 19:40:15.771529 12802 solver.cpp:241]     Train net output #0: loss = 1.53492 (* 1 = 1.53492 loss)
I1028 19:40:15.771546 12802 sgd_solver.cpp:105] Iteration 5960, lr = 0.00584825
I1028 19:40:45.651082 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_6000.caffemodel
I1028 19:40:45.792824 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_6000.solverstate
I1028 19:40:45.918602 12802 solver.cpp:334] Iteration 6000, Testing net (#0)
I1028 19:41:17.182361 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55136
I1028 19:41:17.182448 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78812
I1028 19:41:17.182461 12802 solver.cpp:401]     Test net output #2: loss = 1.99686 (* 1 = 1.99686 loss)
I1028 19:41:17.950191 12802 solver.cpp:222] Iteration 6000 (0.643323 iter/s, 62.1772s/40 iters), loss = 1.75311
I1028 19:41:17.950259 12802 solver.cpp:241]     Train net output #0: loss = 1.75311 (* 1 = 1.75311 loss)
I1028 19:41:17.950283 12802 sgd_solver.cpp:105] Iteration 6000, lr = 0.00582724
I1028 19:41:47.877617 12802 solver.cpp:222] Iteration 6040 (1.3366 iter/s, 29.9266s/40 iters), loss = 1.50463
I1028 19:41:47.877794 12802 solver.cpp:241]     Train net output #0: loss = 1.50463 (* 1 = 1.50463 loss)
I1028 19:41:47.877809 12802 sgd_solver.cpp:105] Iteration 6040, lr = 0.00580629
I1028 19:42:17.883479 12802 solver.cpp:222] Iteration 6080 (1.33311 iter/s, 30.005s/40 iters), loss = 1.87848
I1028 19:42:17.883628 12802 solver.cpp:241]     Train net output #0: loss = 1.87848 (* 1 = 1.87848 loss)
I1028 19:42:17.883646 12802 sgd_solver.cpp:105] Iteration 6080, lr = 0.00578543
I1028 19:42:23.217622 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1028 19:42:47.556507 12802 solver.cpp:222] Iteration 6120 (1.34806 iter/s, 29.6722s/40 iters), loss = 1.59679
I1028 19:42:47.556571 12802 solver.cpp:241]     Train net output #0: loss = 1.59679 (* 1 = 1.59679 loss)
I1028 19:42:47.556588 12802 sgd_solver.cpp:105] Iteration 6120, lr = 0.00576463
I1028 19:43:17.125744 12802 solver.cpp:222] Iteration 6160 (1.35279 iter/s, 29.5685s/40 iters), loss = 1.95398
I1028 19:43:17.125928 12802 solver.cpp:241]     Train net output #0: loss = 1.95398 (* 1 = 1.95398 loss)
I1028 19:43:17.125944 12802 sgd_solver.cpp:105] Iteration 6160, lr = 0.00574392
I1028 19:43:46.668026 12802 solver.cpp:222] Iteration 6200 (1.35403 iter/s, 29.5414s/40 iters), loss = 1.72147
I1028 19:43:46.668093 12802 solver.cpp:241]     Train net output #0: loss = 1.72147 (* 1 = 1.72147 loss)
I1028 19:43:46.668107 12802 sgd_solver.cpp:105] Iteration 6200, lr = 0.00572328
I1028 19:44:16.440565 12802 solver.cpp:222] Iteration 6240 (1.34355 iter/s, 29.7718s/40 iters), loss = 1.08665
I1028 19:44:16.440734 12802 solver.cpp:241]     Train net output #0: loss = 1.08665 (* 1 = 1.08665 loss)
I1028 19:44:16.440750 12802 sgd_solver.cpp:105] Iteration 6240, lr = 0.00570271
I1028 19:44:46.654856 12802 solver.cpp:222] Iteration 6280 (1.32392 iter/s, 30.2134s/40 iters), loss = 1.6611
I1028 19:44:46.655062 12802 solver.cpp:241]     Train net output #0: loss = 1.6611 (* 1 = 1.6611 loss)
I1028 19:44:46.655086 12802 sgd_solver.cpp:105] Iteration 6280, lr = 0.00568221
I1028 19:45:17.666568 12802 solver.cpp:222] Iteration 6320 (1.28987 iter/s, 31.0108s/40 iters), loss = 1.39444
I1028 19:45:17.666852 12802 solver.cpp:241]     Train net output #0: loss = 1.39444 (* 1 = 1.39444 loss)
I1028 19:45:17.666890 12802 sgd_solver.cpp:105] Iteration 6320, lr = 0.00566179
I1028 19:45:48.296288 12802 solver.cpp:222] Iteration 6360 (1.30596 iter/s, 30.6287s/40 iters), loss = 1.54963
I1028 19:45:48.296514 12802 solver.cpp:241]     Train net output #0: loss = 1.54963 (* 1 = 1.54963 loss)
I1028 19:45:48.296531 12802 sgd_solver.cpp:105] Iteration 6360, lr = 0.00564144
I1028 19:46:18.186403 12802 solver.cpp:222] Iteration 6400 (1.33828 iter/s, 29.8892s/40 iters), loss = 1.61361
I1028 19:46:18.186465 12802 solver.cpp:241]     Train net output #0: loss = 1.61361 (* 1 = 1.61361 loss)
I1028 19:46:18.186478 12802 sgd_solver.cpp:105] Iteration 6400, lr = 0.00562117
I1028 19:46:48.355602 12802 solver.cpp:222] Iteration 6440 (1.32589 iter/s, 30.1684s/40 iters), loss = 1.66107
I1028 19:46:48.355793 12802 solver.cpp:241]     Train net output #0: loss = 1.66107 (* 1 = 1.66107 loss)
I1028 19:46:48.355810 12802 sgd_solver.cpp:105] Iteration 6440, lr = 0.00560097
I1028 19:47:18.275240 12802 solver.cpp:222] Iteration 6480 (1.33695 iter/s, 29.9187s/40 iters), loss = 1.62518
I1028 19:47:18.275300 12802 solver.cpp:241]     Train net output #0: loss = 1.62518 (* 1 = 1.62518 loss)
I1028 19:47:18.275316 12802 sgd_solver.cpp:105] Iteration 6480, lr = 0.00558084
I1028 19:47:32.510133 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_6500.caffemodel
I1028 19:47:32.665287 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_6500.solverstate
I1028 19:47:32.788357 12802 solver.cpp:334] Iteration 6500, Testing net (#0)
I1028 19:48:03.833518 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1028 19:48:04.044131 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54628
I1028 19:48:04.044183 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78796
I1028 19:48:04.044193 12802 solver.cpp:401]     Test net output #2: loss = 2.00513 (* 1 = 2.00513 loss)
I1028 19:48:19.805454 12802 solver.cpp:222] Iteration 6520 (0.650103 iter/s, 61.5287s/40 iters), loss = 1.70019
I1028 19:48:19.805512 12802 solver.cpp:241]     Train net output #0: loss = 1.70019 (* 1 = 1.70019 loss)
I1028 19:48:19.805526 12802 sgd_solver.cpp:105] Iteration 6520, lr = 0.00556078
I1028 19:48:49.649396 12802 solver.cpp:222] Iteration 6560 (1.34034 iter/s, 29.8432s/40 iters), loss = 1.70249
I1028 19:48:49.649590 12802 solver.cpp:241]     Train net output #0: loss = 1.70249 (* 1 = 1.70249 loss)
I1028 19:48:49.649607 12802 sgd_solver.cpp:105] Iteration 6560, lr = 0.0055408
I1028 19:49:19.488972 12802 solver.cpp:222] Iteration 6600 (1.34054 iter/s, 29.8387s/40 iters), loss = 1.52562
I1028 19:49:19.489039 12802 solver.cpp:241]     Train net output #0: loss = 1.52562 (* 1 = 1.52562 loss)
I1028 19:49:19.489055 12802 sgd_solver.cpp:105] Iteration 6600, lr = 0.00552089
I1028 19:49:49.780978 12802 solver.cpp:222] Iteration 6640 (1.32052 iter/s, 30.2912s/40 iters), loss = 1.47565
I1028 19:49:49.781188 12802 solver.cpp:241]     Train net output #0: loss = 1.47565 (* 1 = 1.47565 loss)
I1028 19:49:49.781203 12802 sgd_solver.cpp:105] Iteration 6640, lr = 0.00550105
I1028 19:50:19.624116 12802 solver.cpp:222] Iteration 6680 (1.34038 iter/s, 29.8422s/40 iters), loss = 1.81181
I1028 19:50:19.624176 12802 solver.cpp:241]     Train net output #0: loss = 1.81181 (* 1 = 1.81181 loss)
I1028 19:50:19.624188 12802 sgd_solver.cpp:105] Iteration 6680, lr = 0.00548128
I1028 19:50:49.643328 12802 solver.cpp:222] Iteration 6720 (1.33251 iter/s, 30.0184s/40 iters), loss = 1.51817
I1028 19:50:49.643534 12802 solver.cpp:241]     Train net output #0: loss = 1.51817 (* 1 = 1.51817 loss)
I1028 19:50:49.643550 12802 sgd_solver.cpp:105] Iteration 6720, lr = 0.00546158
I1028 19:51:19.889828 12802 solver.cpp:222] Iteration 6760 (1.32251 iter/s, 30.2456s/40 iters), loss = 1.64101
I1028 19:51:19.890125 12802 solver.cpp:241]     Train net output #0: loss = 1.64101 (* 1 = 1.64101 loss)
I1028 19:51:19.890159 12802 sgd_solver.cpp:105] Iteration 6760, lr = 0.00544195
I1028 19:51:50.947613 12802 solver.cpp:222] Iteration 6800 (1.28796 iter/s, 31.0568s/40 iters), loss = 1.53666
I1028 19:51:50.947814 12802 solver.cpp:241]     Train net output #0: loss = 1.53666 (* 1 = 1.53666 loss)
I1028 19:51:50.947831 12802 sgd_solver.cpp:105] Iteration 6800, lr = 0.00542239
I1028 19:52:21.796175 12802 solver.cpp:222] Iteration 6840 (1.2967 iter/s, 30.8476s/40 iters), loss = 1.85888
I1028 19:52:21.796351 12802 solver.cpp:241]     Train net output #0: loss = 1.85888 (* 1 = 1.85888 loss)
I1028 19:52:21.796366 12802 sgd_solver.cpp:105] Iteration 6840, lr = 0.0054029
I1028 19:52:52.096756 12802 solver.cpp:222] Iteration 6880 (1.32015 iter/s, 30.2997s/40 iters), loss = 1.55771
I1028 19:52:52.096961 12802 solver.cpp:241]     Train net output #0: loss = 1.55771 (* 1 = 1.55771 loss)
I1028 19:52:52.096979 12802 sgd_solver.cpp:105] Iteration 6880, lr = 0.00538349
I1028 19:53:22.134222 12802 solver.cpp:222] Iteration 6920 (1.33171 iter/s, 30.0365s/40 iters), loss = 1.76954
I1028 19:53:22.134428 12802 solver.cpp:241]     Train net output #0: loss = 1.76954 (* 1 = 1.76954 loss)
I1028 19:53:22.134444 12802 sgd_solver.cpp:105] Iteration 6920, lr = 0.00536414
I1028 19:53:51.583005 12854 blocking_queue.cpp:49] Waiting for data
I1028 19:53:53.460573 12802 solver.cpp:222] Iteration 6960 (1.27692 iter/s, 31.3254s/40 iters), loss = 1.31147
I1028 19:53:53.460786 12802 solver.cpp:241]     Train net output #0: loss = 1.31147 (* 1 = 1.31147 loss)
I1028 19:53:53.460810 12802 sgd_solver.cpp:105] Iteration 6960, lr = 0.00534486
I1028 19:54:32.829867 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_7000.caffemodel
I1028 19:54:32.959117 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_7000.solverstate
I1028 19:54:33.075393 12802 solver.cpp:334] Iteration 7000, Testing net (#0)
I1028 19:55:05.082823 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55136
I1028 19:55:05.082998 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.787
I1028 19:55:05.083010 12802 solver.cpp:401]     Test net output #2: loss = 1.98359 (* 1 = 1.98359 loss)
I1028 19:55:05.830039 12802 solver.cpp:222] Iteration 7000 (0.552734 iter/s, 72.3676s/40 iters), loss = 1.56331
I1028 19:55:05.830088 12802 solver.cpp:241]     Train net output #0: loss = 1.56331 (* 1 = 1.56331 loss)
I1028 19:55:05.830103 12802 sgd_solver.cpp:105] Iteration 7000, lr = 0.00532565
I1028 19:55:35.851455 12802 solver.cpp:222] Iteration 7040 (1.33242 iter/s, 30.0206s/40 iters), loss = 1.46682
I1028 19:55:35.851655 12802 solver.cpp:241]     Train net output #0: loss = 1.46682 (* 1 = 1.46682 loss)
I1028 19:55:35.851672 12802 sgd_solver.cpp:105] Iteration 7040, lr = 0.00530652
I1028 19:56:06.166164 12802 solver.cpp:222] Iteration 7080 (1.31953 iter/s, 30.3138s/40 iters), loss = 1.55857
I1028 19:56:06.166342 12802 solver.cpp:241]     Train net output #0: loss = 1.55857 (* 1 = 1.55857 loss)
I1028 19:56:06.166358 12802 sgd_solver.cpp:105] Iteration 7080, lr = 0.00528744
I1028 19:56:36.416345 12802 solver.cpp:222] Iteration 7120 (1.32235 iter/s, 30.2493s/40 iters), loss = 1.58587
I1028 19:56:36.416496 12802 solver.cpp:241]     Train net output #0: loss = 1.58587 (* 1 = 1.58587 loss)
I1028 19:56:36.416514 12802 sgd_solver.cpp:105] Iteration 7120, lr = 0.00526844
I1028 19:57:06.225695 12802 solver.cpp:222] Iteration 7160 (1.3419 iter/s, 29.8084s/40 iters), loss = 1.7758
I1028 19:57:06.225757 12802 solver.cpp:241]     Train net output #0: loss = 1.7758 (* 1 = 1.7758 loss)
I1028 19:57:06.225775 12802 sgd_solver.cpp:105] Iteration 7160, lr = 0.00524951
I1028 19:57:35.974040 12802 solver.cpp:222] Iteration 7200 (1.34465 iter/s, 29.7476s/40 iters), loss = 1.88784
I1028 19:57:35.974263 12802 solver.cpp:241]     Train net output #0: loss = 1.88784 (* 1 = 1.88784 loss)
I1028 19:57:35.974282 12802 sgd_solver.cpp:105] Iteration 7200, lr = 0.00523064
I1028 19:58:05.693228 12802 solver.cpp:222] Iteration 7240 (1.34598 iter/s, 29.7182s/40 iters), loss = 1.85181
I1028 19:58:05.693285 12802 solver.cpp:241]     Train net output #0: loss = 1.85181 (* 1 = 1.85181 loss)
I1028 19:58:05.693298 12802 sgd_solver.cpp:105] Iteration 7240, lr = 0.00521185
I1028 19:58:35.522853 12802 solver.cpp:222] Iteration 7280 (1.34099 iter/s, 29.8288s/40 iters), loss = 1.58384
I1028 19:58:35.523061 12802 solver.cpp:241]     Train net output #0: loss = 1.58384 (* 1 = 1.58384 loss)
I1028 19:58:35.523077 12802 sgd_solver.cpp:105] Iteration 7280, lr = 0.00519311
I1028 19:59:05.394985 12802 solver.cpp:222] Iteration 7320 (1.33908 iter/s, 29.8712s/40 iters), loss = 1.46229
I1028 19:59:05.395051 12802 solver.cpp:241]     Train net output #0: loss = 1.46229 (* 1 = 1.46229 loss)
I1028 19:59:05.395067 12802 sgd_solver.cpp:105] Iteration 7320, lr = 0.00517445
I1028 19:59:35.723956 12802 solver.cpp:222] Iteration 7360 (1.31891 iter/s, 30.3281s/40 iters), loss = 1.60789
I1028 19:59:35.724171 12802 solver.cpp:241]     Train net output #0: loss = 1.60789 (* 1 = 1.60789 loss)
I1028 19:59:35.724192 12802 sgd_solver.cpp:105] Iteration 7360, lr = 0.00515586
I1028 20:00:05.977629 12802 solver.cpp:222] Iteration 7400 (1.32219 iter/s, 30.2527s/40 iters), loss = 1.55377
I1028 20:00:05.977835 12802 solver.cpp:241]     Train net output #0: loss = 1.55377 (* 1 = 1.55377 loss)
I1028 20:00:05.977860 12802 sgd_solver.cpp:105] Iteration 7400, lr = 0.00513733
I1028 20:00:35.892984 12802 solver.cpp:222] Iteration 7440 (1.33715 iter/s, 29.9144s/40 iters), loss = 1.99434
I1028 20:00:35.893046 12802 solver.cpp:241]     Train net output #0: loss = 1.99434 (* 1 = 1.99434 loss)
I1028 20:00:35.893067 12802 sgd_solver.cpp:105] Iteration 7440, lr = 0.00511886
I1028 20:01:05.803866 12802 solver.cpp:222] Iteration 7480 (1.33734 iter/s, 29.91s/40 iters), loss = 1.56773
I1028 20:01:05.804056 12802 solver.cpp:241]     Train net output #0: loss = 1.56773 (* 1 = 1.56773 loss)
I1028 20:01:05.804071 12802 sgd_solver.cpp:105] Iteration 7480, lr = 0.00510047
I1028 20:01:19.993417 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_7500.caffemodel
I1028 20:01:20.134753 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_7500.solverstate
I1028 20:01:20.245874 12802 solver.cpp:334] Iteration 7500, Testing net (#0)
I1028 20:01:51.372151 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1028 20:01:51.579119 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5486
I1028 20:01:51.579172 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78716
I1028 20:01:51.579183 12802 solver.cpp:401]     Test net output #2: loss = 2.04165 (* 1 = 2.04165 loss)
I1028 20:02:07.408766 12802 solver.cpp:222] Iteration 7520 (0.649316 iter/s, 61.6032s/40 iters), loss = 1.89901
I1028 20:02:07.408828 12802 solver.cpp:241]     Train net output #0: loss = 1.89901 (* 1 = 1.89901 loss)
I1028 20:02:07.408844 12802 sgd_solver.cpp:105] Iteration 7520, lr = 0.00508214
I1028 20:02:38.564693 12802 solver.cpp:222] Iteration 7560 (1.2839 iter/s, 31.155s/40 iters), loss = 1.39562
I1028 20:02:38.564899 12802 solver.cpp:241]     Train net output #0: loss = 1.39562 (* 1 = 1.39562 loss)
I1028 20:02:38.564915 12802 sgd_solver.cpp:105] Iteration 7560, lr = 0.00506387
I1028 20:03:09.078320 12802 solver.cpp:222] Iteration 7600 (1.31093 iter/s, 30.5126s/40 iters), loss = 1.62004
I1028 20:03:09.078553 12802 solver.cpp:241]     Train net output #0: loss = 1.62004 (* 1 = 1.62004 loss)
I1028 20:03:09.078570 12802 sgd_solver.cpp:105] Iteration 7600, lr = 0.00504567
I1028 20:03:39.594544 12802 solver.cpp:222] Iteration 7640 (1.31082 iter/s, 30.5152s/40 iters), loss = 1.31829
I1028 20:03:39.594751 12802 solver.cpp:241]     Train net output #0: loss = 1.31829 (* 1 = 1.31829 loss)
I1028 20:03:39.594771 12802 sgd_solver.cpp:105] Iteration 7640, lr = 0.00502754
I1028 20:04:10.333218 12802 solver.cpp:222] Iteration 7680 (1.30133 iter/s, 30.7377s/40 iters), loss = 1.61853
I1028 20:04:10.333500 12802 solver.cpp:241]     Train net output #0: loss = 1.61853 (* 1 = 1.61853 loss)
I1028 20:04:10.333536 12802 sgd_solver.cpp:105] Iteration 7680, lr = 0.00500947
I1028 20:04:40.110354 12802 solver.cpp:222] Iteration 7720 (1.34336 iter/s, 29.7762s/40 iters), loss = 1.65158
I1028 20:04:40.110420 12802 solver.cpp:241]     Train net output #0: loss = 1.65158 (* 1 = 1.65158 loss)
I1028 20:04:40.110435 12802 sgd_solver.cpp:105] Iteration 7720, lr = 0.00499147
I1028 20:05:10.128950 12802 solver.cpp:222] Iteration 7760 (1.33255 iter/s, 30.0177s/40 iters), loss = 2.04176
I1028 20:05:10.129176 12802 solver.cpp:241]     Train net output #0: loss = 2.04176 (* 1 = 2.04176 loss)
I1028 20:05:10.129192 12802 sgd_solver.cpp:105] Iteration 7760, lr = 0.00497353
I1028 20:05:40.118396 12802 solver.cpp:222] Iteration 7800 (1.33385 iter/s, 29.9884s/40 iters), loss = 1.72807
I1028 20:05:40.118458 12802 solver.cpp:241]     Train net output #0: loss = 1.72807 (* 1 = 1.72807 loss)
I1028 20:05:40.118474 12802 sgd_solver.cpp:105] Iteration 7800, lr = 0.00495566
I1028 20:06:10.010529 12802 solver.cpp:222] Iteration 7840 (1.33818 iter/s, 29.8913s/40 iters), loss = 1.7591
I1028 20:06:10.010699 12802 solver.cpp:241]     Train net output #0: loss = 1.7591 (* 1 = 1.7591 loss)
I1028 20:06:10.010717 12802 sgd_solver.cpp:105] Iteration 7840, lr = 0.00493785
I1028 20:06:39.938118 12802 solver.cpp:222] Iteration 7880 (1.3366 iter/s, 29.9267s/40 iters), loss = 1.56673
I1028 20:06:39.938182 12802 solver.cpp:241]     Train net output #0: loss = 1.56673 (* 1 = 1.56673 loss)
I1028 20:06:39.938197 12802 sgd_solver.cpp:105] Iteration 7880, lr = 0.0049201
I1028 20:07:09.873241 12802 solver.cpp:222] Iteration 7920 (1.33626 iter/s, 29.9343s/40 iters), loss = 1.41896
I1028 20:07:09.873435 12802 solver.cpp:241]     Train net output #0: loss = 1.41896 (* 1 = 1.41896 loss)
I1028 20:07:09.873450 12802 sgd_solver.cpp:105] Iteration 7920, lr = 0.00490242
I1028 20:07:39.881023 12802 solver.cpp:222] Iteration 7960 (1.33303 iter/s, 30.0068s/40 iters), loss = 1.90827
I1028 20:07:39.881207 12802 solver.cpp:241]     Train net output #0: loss = 1.90827 (* 1 = 1.90827 loss)
I1028 20:07:39.881222 12802 sgd_solver.cpp:105] Iteration 7960, lr = 0.0048848
I1028 20:08:08.987692 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_8000.caffemodel
I1028 20:08:09.130194 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_8000.solverstate
I1028 20:08:09.247172 12802 solver.cpp:334] Iteration 8000, Testing net (#0)
I1028 20:08:40.646553 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55924
I1028 20:08:40.646741 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.791639
I1028 20:08:40.646754 12802 solver.cpp:401]     Test net output #2: loss = 1.96912 (* 1 = 1.96912 loss)
I1028 20:08:41.397754 12802 solver.cpp:222] Iteration 8000 (0.650247 iter/s, 61.5151s/40 iters), loss = 1.46358
I1028 20:08:41.397814 12802 solver.cpp:241]     Train net output #0: loss = 1.46358 (* 1 = 1.46358 loss)
I1028 20:08:41.397831 12802 sgd_solver.cpp:105] Iteration 8000, lr = 0.00486725
I1028 20:09:11.316550 12802 solver.cpp:222] Iteration 8040 (1.33699 iter/s, 29.918s/40 iters), loss = 1.74055
I1028 20:09:11.316758 12802 solver.cpp:241]     Train net output #0: loss = 1.74055 (* 1 = 1.74055 loss)
I1028 20:09:11.316774 12802 sgd_solver.cpp:105] Iteration 8040, lr = 0.00484976
I1028 20:09:41.238255 12802 solver.cpp:222] Iteration 8080 (1.33687 iter/s, 29.9207s/40 iters), loss = 1.23472
I1028 20:09:41.238312 12802 solver.cpp:241]     Train net output #0: loss = 1.23472 (* 1 = 1.23472 loss)
I1028 20:09:41.238327 12802 sgd_solver.cpp:105] Iteration 8080, lr = 0.00483233
I1028 20:10:11.237000 12802 solver.cpp:222] Iteration 8120 (1.33343 iter/s, 29.9979s/40 iters), loss = 1.91962
I1028 20:10:11.237274 12802 solver.cpp:241]     Train net output #0: loss = 1.91962 (* 1 = 1.91962 loss)
I1028 20:10:11.237293 12802 sgd_solver.cpp:105] Iteration 8120, lr = 0.00481496
I1028 20:10:40.913970 12802 solver.cpp:222] Iteration 8160 (1.34789 iter/s, 29.6759s/40 iters), loss = 1.89496
I1028 20:10:40.914029 12802 solver.cpp:241]     Train net output #0: loss = 1.89496 (* 1 = 1.89496 loss)
I1028 20:10:40.914046 12802 sgd_solver.cpp:105] Iteration 8160, lr = 0.00479766
I1028 20:11:10.741510 12802 solver.cpp:222] Iteration 8200 (1.34108 iter/s, 29.8268s/40 iters), loss = 1.36449
I1028 20:11:10.741700 12802 solver.cpp:241]     Train net output #0: loss = 1.36449 (* 1 = 1.36449 loss)
I1028 20:11:10.741717 12802 sgd_solver.cpp:105] Iteration 8200, lr = 0.00478041
I1028 20:11:40.728888 12802 solver.cpp:222] Iteration 8240 (1.33394 iter/s, 29.9864s/40 iters), loss = 1.44529
I1028 20:11:40.728950 12802 solver.cpp:241]     Train net output #0: loss = 1.44529 (* 1 = 1.44529 loss)
I1028 20:11:40.728965 12802 sgd_solver.cpp:105] Iteration 8240, lr = 0.00476323
I1028 20:12:10.939121 12802 solver.cpp:222] Iteration 8280 (1.32409 iter/s, 30.2094s/40 iters), loss = 1.37351
I1028 20:12:10.939335 12802 solver.cpp:241]     Train net output #0: loss = 1.37351 (* 1 = 1.37351 loss)
I1028 20:12:10.939353 12802 sgd_solver.cpp:105] Iteration 8280, lr = 0.00474612
I1028 20:12:40.665449 12802 solver.cpp:222] Iteration 8320 (1.34565 iter/s, 29.7253s/40 iters), loss = 1.53334
I1028 20:12:40.665506 12802 solver.cpp:241]     Train net output #0: loss = 1.53334 (* 1 = 1.53334 loss)
I1028 20:12:40.665522 12802 sgd_solver.cpp:105] Iteration 8320, lr = 0.00472906
I1028 20:13:10.277631 12802 solver.cpp:222] Iteration 8360 (1.35083 iter/s, 29.6114s/40 iters), loss = 1.52947
I1028 20:13:10.277807 12802 solver.cpp:241]     Train net output #0: loss = 1.52947 (* 1 = 1.52947 loss)
I1028 20:13:10.277832 12802 sgd_solver.cpp:105] Iteration 8360, lr = 0.00471206
I1028 20:13:40.003680 12802 solver.cpp:222] Iteration 8400 (1.34566 iter/s, 29.7251s/40 iters), loss = 1.81167
I1028 20:13:40.003741 12802 solver.cpp:241]     Train net output #0: loss = 1.81167 (* 1 = 1.81167 loss)
I1028 20:13:40.003758 12802 sgd_solver.cpp:105] Iteration 8400, lr = 0.00469513
I1028 20:14:09.791074 12802 solver.cpp:222] Iteration 8440 (1.34289 iter/s, 29.7866s/40 iters), loss = 1.60809
I1028 20:14:09.791241 12802 solver.cpp:241]     Train net output #0: loss = 1.60809 (* 1 = 1.60809 loss)
I1028 20:14:09.791259 12802 sgd_solver.cpp:105] Iteration 8440, lr = 0.00467826
I1028 20:14:39.587824 12802 solver.cpp:222] Iteration 8480 (1.34247 iter/s, 29.7958s/40 iters), loss = 1.48792
I1028 20:14:39.587888 12802 solver.cpp:241]     Train net output #0: loss = 1.48792 (* 1 = 1.48792 loss)
I1028 20:14:39.587905 12802 sgd_solver.cpp:105] Iteration 8480, lr = 0.00466144
I1028 20:14:53.695976 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_8500.caffemodel
I1028 20:14:53.841379 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_8500.solverstate
I1028 20:14:53.964103 12802 solver.cpp:334] Iteration 8500, Testing net (#0)
I1028 20:15:24.993324 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1028 20:15:25.201897 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55696
I1028 20:15:25.201951 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7926
I1028 20:15:25.201963 12802 solver.cpp:401]     Test net output #2: loss = 1.98557 (* 1 = 1.98557 loss)
I1028 20:15:40.742446 12802 solver.cpp:222] Iteration 8520 (0.654096 iter/s, 61.1531s/40 iters), loss = 1.57084
I1028 20:15:40.742507 12802 solver.cpp:241]     Train net output #0: loss = 1.57084 (* 1 = 1.57084 loss)
I1028 20:15:40.742523 12802 sgd_solver.cpp:105] Iteration 8520, lr = 0.00464469
I1028 20:16:10.334321 12802 solver.cpp:222] Iteration 8560 (1.35176 iter/s, 29.591s/40 iters), loss = 1.59572
I1028 20:16:10.334553 12802 solver.cpp:241]     Train net output #0: loss = 1.59572 (* 1 = 1.59572 loss)
I1028 20:16:10.334573 12802 sgd_solver.cpp:105] Iteration 8560, lr = 0.004628
I1028 20:16:31.838515 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1028 20:16:39.870024 12802 solver.cpp:222] Iteration 8600 (1.35434 iter/s, 29.5347s/40 iters), loss = 1.36638
I1028 20:16:39.870082 12802 solver.cpp:241]     Train net output #0: loss = 1.36638 (* 1 = 1.36638 loss)
I1028 20:16:39.870098 12802 sgd_solver.cpp:105] Iteration 8600, lr = 0.00461137
I1028 20:17:09.384668 12802 solver.cpp:222] Iteration 8640 (1.3553 iter/s, 29.5138s/40 iters), loss = 1.46931
I1028 20:17:09.384824 12802 solver.cpp:241]     Train net output #0: loss = 1.46931 (* 1 = 1.46931 loss)
I1028 20:17:09.384845 12802 sgd_solver.cpp:105] Iteration 8640, lr = 0.00459479
I1028 20:17:38.983731 12802 solver.cpp:222] Iteration 8680 (1.35143 iter/s, 29.5982s/40 iters), loss = 1.51407
I1028 20:17:38.983788 12802 solver.cpp:241]     Train net output #0: loss = 1.51407 (* 1 = 1.51407 loss)
I1028 20:17:38.983801 12802 sgd_solver.cpp:105] Iteration 8680, lr = 0.00457828
I1028 20:18:08.604370 12802 solver.cpp:222] Iteration 8720 (1.35045 iter/s, 29.6198s/40 iters), loss = 1.87296
I1028 20:18:08.604516 12802 solver.cpp:241]     Train net output #0: loss = 1.87296 (* 1 = 1.87296 loss)
I1028 20:18:08.604531 12802 sgd_solver.cpp:105] Iteration 8720, lr = 0.00456183
I1028 20:18:38.423447 12802 solver.cpp:222] Iteration 8760 (1.34147 iter/s, 29.8181s/40 iters), loss = 1.2793
I1028 20:18:38.423514 12802 solver.cpp:241]     Train net output #0: loss = 1.2793 (* 1 = 1.2793 loss)
I1028 20:18:38.423537 12802 sgd_solver.cpp:105] Iteration 8760, lr = 0.00454543
I1028 20:19:08.509388 12802 solver.cpp:222] Iteration 8800 (1.32956 iter/s, 30.0851s/40 iters), loss = 1.63495
I1028 20:19:08.509582 12802 solver.cpp:241]     Train net output #0: loss = 1.63495 (* 1 = 1.63495 loss)
I1028 20:19:08.509603 12802 sgd_solver.cpp:105] Iteration 8800, lr = 0.0045291
I1028 20:19:38.399487 12802 solver.cpp:222] Iteration 8840 (1.33828 iter/s, 29.8891s/40 iters), loss = 1.57014
I1028 20:19:38.399547 12802 solver.cpp:241]     Train net output #0: loss = 1.57014 (* 1 = 1.57014 loss)
I1028 20:19:38.399562 12802 sgd_solver.cpp:105] Iteration 8840, lr = 0.00451282
I1028 20:20:08.178979 12802 solver.cpp:222] Iteration 8880 (1.34324 iter/s, 29.7787s/40 iters), loss = 1.52089
I1028 20:20:08.179167 12802 solver.cpp:241]     Train net output #0: loss = 1.52089 (* 1 = 1.52089 loss)
I1028 20:20:08.179185 12802 sgd_solver.cpp:105] Iteration 8880, lr = 0.0044966
I1028 20:20:38.099004 12802 solver.cpp:222] Iteration 8920 (1.33694 iter/s, 29.9191s/40 iters), loss = 1.50033
I1028 20:20:38.099069 12802 solver.cpp:241]     Train net output #0: loss = 1.50033 (* 1 = 1.50033 loss)
I1028 20:20:38.099082 12802 sgd_solver.cpp:105] Iteration 8920, lr = 0.00448044
I1028 20:21:07.947654 12802 solver.cpp:222] Iteration 8960 (1.34013 iter/s, 29.8479s/40 iters), loss = 1.54672
I1028 20:21:07.947865 12802 solver.cpp:241]     Train net output #0: loss = 1.54672 (* 1 = 1.54672 loss)
I1028 20:21:07.947882 12802 sgd_solver.cpp:105] Iteration 8960, lr = 0.00446434
I1028 20:21:36.976986 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_9000.caffemodel
I1028 20:21:37.128195 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_9000.solverstate
I1028 20:21:37.241421 12802 solver.cpp:334] Iteration 9000, Testing net (#0)
I1028 20:22:08.632712 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55764
I1028 20:22:08.632928 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79144
I1028 20:22:08.632941 12802 solver.cpp:401]     Test net output #2: loss = 1.9737 (* 1 = 1.9737 loss)
I1028 20:22:09.385452 12802 solver.cpp:222] Iteration 9000 (0.651083 iter/s, 61.4361s/40 iters), loss = 1.94481
I1028 20:22:09.385504 12802 solver.cpp:241]     Train net output #0: loss = 1.94481 (* 1 = 1.94481 loss)
I1028 20:22:09.385521 12802 sgd_solver.cpp:105] Iteration 9000, lr = 0.0044483
I1028 20:22:39.277978 12802 solver.cpp:222] Iteration 9040 (1.33816 iter/s, 29.8918s/40 iters), loss = 1.78905
I1028 20:22:39.278301 12802 solver.cpp:241]     Train net output #0: loss = 1.78905 (* 1 = 1.78905 loss)
I1028 20:22:39.278334 12802 sgd_solver.cpp:105] Iteration 9040, lr = 0.00443231
I1028 20:23:09.347985 12802 solver.cpp:222] Iteration 9080 (1.33027 iter/s, 30.069s/40 iters), loss = 1.68994
I1028 20:23:09.348135 12802 solver.cpp:241]     Train net output #0: loss = 1.68994 (* 1 = 1.68994 loss)
I1028 20:23:09.348150 12802 sgd_solver.cpp:105] Iteration 9080, lr = 0.00441638
I1028 20:23:39.357354 12802 solver.cpp:222] Iteration 9120 (1.33296 iter/s, 30.0085s/40 iters), loss = 1.63594
I1028 20:23:39.357504 12802 solver.cpp:241]     Train net output #0: loss = 1.63594 (* 1 = 1.63594 loss)
I1028 20:23:39.357522 12802 sgd_solver.cpp:105] Iteration 9120, lr = 0.00440051
I1028 20:24:09.665170 12802 solver.cpp:222] Iteration 9160 (1.31983 iter/s, 30.3069s/40 iters), loss = 1.54118
I1028 20:24:09.665367 12802 solver.cpp:241]     Train net output #0: loss = 1.54118 (* 1 = 1.54118 loss)
I1028 20:24:09.665382 12802 sgd_solver.cpp:105] Iteration 9160, lr = 0.0043847
I1028 20:24:39.679253 12802 solver.cpp:222] Iteration 9200 (1.33275 iter/s, 30.0131s/40 iters), loss = 1.46407
I1028 20:24:39.679450 12802 solver.cpp:241]     Train net output #0: loss = 1.46407 (* 1 = 1.46407 loss)
I1028 20:24:39.679467 12802 sgd_solver.cpp:105] Iteration 9200, lr = 0.00436894
I1028 20:25:18.241734 12802 solver.cpp:222] Iteration 9240 (1.03731 iter/s, 38.5614s/40 iters), loss = 1.91169
I1028 20:25:18.241935 12802 solver.cpp:241]     Train net output #0: loss = 1.91169 (* 1 = 1.91169 loss)
I1028 20:25:18.241957 12802 sgd_solver.cpp:105] Iteration 9240, lr = 0.00435324
I1028 20:25:55.521644 12802 solver.cpp:222] Iteration 9280 (1.07299 iter/s, 37.2789s/40 iters), loss = 1.67192
I1028 20:25:55.521858 12802 solver.cpp:241]     Train net output #0: loss = 1.67192 (* 1 = 1.67192 loss)
I1028 20:25:55.521875 12802 sgd_solver.cpp:105] Iteration 9280, lr = 0.00433759
I1028 20:26:25.874362 12802 solver.cpp:222] Iteration 9320 (1.31788 iter/s, 30.3518s/40 iters), loss = 1.76997
I1028 20:26:25.874553 12802 solver.cpp:241]     Train net output #0: loss = 1.76997 (* 1 = 1.76997 loss)
I1028 20:26:25.874567 12802 sgd_solver.cpp:105] Iteration 9320, lr = 0.004322
I1028 20:26:57.542457 12802 solver.cpp:222] Iteration 9360 (1.26314 iter/s, 31.6672s/40 iters), loss = 1.46312
I1028 20:26:57.542634 12802 solver.cpp:241]     Train net output #0: loss = 1.46312 (* 1 = 1.46312 loss)
I1028 20:26:57.542652 12802 sgd_solver.cpp:105] Iteration 9360, lr = 0.00430647
I1028 20:27:33.289283 12802 solver.cpp:222] Iteration 9400 (1.11901 iter/s, 35.7458s/40 iters), loss = 1.81423
I1028 20:27:33.289464 12802 solver.cpp:241]     Train net output #0: loss = 1.81423 (* 1 = 1.81423 loss)
I1028 20:27:33.289482 12802 sgd_solver.cpp:105] Iteration 9400, lr = 0.004291
I1028 20:28:03.733959 12802 solver.cpp:222] Iteration 9440 (1.3139 iter/s, 30.4438s/40 iters), loss = 1.69335
I1028 20:28:03.734154 12802 solver.cpp:241]     Train net output #0: loss = 1.69335 (* 1 = 1.69335 loss)
I1028 20:28:03.734172 12802 sgd_solver.cpp:105] Iteration 9440, lr = 0.00427557
I1028 20:28:34.231978 12802 solver.cpp:222] Iteration 9480 (1.3116 iter/s, 30.4971s/40 iters), loss = 1.49947
I1028 20:28:34.232204 12802 solver.cpp:241]     Train net output #0: loss = 1.49947 (* 1 = 1.49947 loss)
I1028 20:28:34.232229 12802 sgd_solver.cpp:105] Iteration 9480, lr = 0.00426021
I1028 20:28:48.345660 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_9500.caffemodel
I1028 20:28:48.490360 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_9500.solverstate
I1028 20:28:48.615813 12802 solver.cpp:334] Iteration 9500, Testing net (#0)
I1028 20:29:19.738746 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1028 20:29:19.951894 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55664
I1028 20:29:19.951954 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79164
I1028 20:29:19.951966 12802 solver.cpp:401]     Test net output #2: loss = 1.97601 (* 1 = 1.97601 loss)
I1028 20:29:35.913079 12802 solver.cpp:222] Iteration 9520 (0.648515 iter/s, 61.6794s/40 iters), loss = 1.60883
I1028 20:29:35.913141 12802 solver.cpp:241]     Train net output #0: loss = 1.60883 (* 1 = 1.60883 loss)
I1028 20:29:35.913156 12802 sgd_solver.cpp:105] Iteration 9520, lr = 0.0042449
I1028 20:30:05.806715 12802 solver.cpp:222] Iteration 9560 (1.33811 iter/s, 29.8928s/40 iters), loss = 1.42987
I1028 20:30:05.806942 12802 solver.cpp:241]     Train net output #0: loss = 1.42987 (* 1 = 1.42987 loss)
I1028 20:30:05.806958 12802 sgd_solver.cpp:105] Iteration 9560, lr = 0.00422964
I1028 20:30:35.422854 12802 solver.cpp:222] Iteration 9600 (1.35066 iter/s, 29.6151s/40 iters), loss = 2.12469
I1028 20:30:35.422914 12802 solver.cpp:241]     Train net output #0: loss = 2.12469 (* 1 = 2.12469 loss)
I1028 20:30:35.422935 12802 sgd_solver.cpp:105] Iteration 9600, lr = 0.00421444
I1028 20:31:05.072746 12802 solver.cpp:222] Iteration 9640 (1.34911 iter/s, 29.6491s/40 iters), loss = 1.79718
I1028 20:31:05.072950 12802 solver.cpp:241]     Train net output #0: loss = 1.79718 (* 1 = 1.79718 loss)
I1028 20:31:05.072968 12802 sgd_solver.cpp:105] Iteration 9640, lr = 0.0041993
I1028 20:31:34.592161 12802 solver.cpp:222] Iteration 9680 (1.35508 iter/s, 29.5184s/40 iters), loss = 1.55832
I1028 20:31:34.592216 12802 solver.cpp:241]     Train net output #0: loss = 1.55832 (* 1 = 1.55832 loss)
I1028 20:31:34.592231 12802 sgd_solver.cpp:105] Iteration 9680, lr = 0.00418421
I1028 20:32:04.101543 12802 solver.cpp:222] Iteration 9720 (1.35554 iter/s, 29.5086s/40 iters), loss = 1.31893
I1028 20:32:04.101752 12802 solver.cpp:241]     Train net output #0: loss = 1.31893 (* 1 = 1.31893 loss)
I1028 20:32:04.101778 12802 sgd_solver.cpp:105] Iteration 9720, lr = 0.00416917
I1028 20:32:33.666460 12802 solver.cpp:222] Iteration 9760 (1.353 iter/s, 29.5639s/40 iters), loss = 1.54705
I1028 20:32:33.666518 12802 solver.cpp:241]     Train net output #0: loss = 1.54705 (* 1 = 1.54705 loss)
I1028 20:32:33.666535 12802 sgd_solver.cpp:105] Iteration 9760, lr = 0.00415418
I1028 20:33:03.257522 12802 solver.cpp:222] Iteration 9800 (1.3518 iter/s, 29.5902s/40 iters), loss = 1.74543
I1028 20:33:03.257728 12802 solver.cpp:241]     Train net output #0: loss = 1.74543 (* 1 = 1.74543 loss)
I1028 20:33:03.257745 12802 sgd_solver.cpp:105] Iteration 9800, lr = 0.00413926
I1028 20:33:32.861567 12802 solver.cpp:222] Iteration 9840 (1.35121 iter/s, 29.6031s/40 iters), loss = 1.6733
I1028 20:33:32.861625 12802 solver.cpp:241]     Train net output #0: loss = 1.6733 (* 1 = 1.6733 loss)
I1028 20:33:32.861641 12802 sgd_solver.cpp:105] Iteration 9840, lr = 0.00412438
I1028 20:34:02.478173 12802 solver.cpp:222] Iteration 9880 (1.35063 iter/s, 29.6158s/40 iters), loss = 1.63086
I1028 20:34:02.478309 12802 solver.cpp:241]     Train net output #0: loss = 1.63086 (* 1 = 1.63086 loss)
I1028 20:34:02.478325 12802 sgd_solver.cpp:105] Iteration 9880, lr = 0.00410956
I1028 20:34:32.047432 12802 solver.cpp:222] Iteration 9920 (1.3528 iter/s, 29.5684s/40 iters), loss = 1.78505
I1028 20:34:32.047489 12802 solver.cpp:241]     Train net output #0: loss = 1.78505 (* 1 = 1.78505 loss)
I1028 20:34:32.047507 12802 sgd_solver.cpp:105] Iteration 9920, lr = 0.00409479
I1028 20:35:01.661222 12802 solver.cpp:222] Iteration 9960 (1.35076 iter/s, 29.613s/40 iters), loss = 1.78897
I1028 20:35:01.661379 12802 solver.cpp:241]     Train net output #0: loss = 1.78897 (* 1 = 1.78897 loss)
I1028 20:35:01.661398 12802 sgd_solver.cpp:105] Iteration 9960, lr = 0.00408007
I1028 20:35:30.547344 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_10000.caffemodel
I1028 20:35:30.703804 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_10000.solverstate
I1028 20:35:30.812047 12802 solver.cpp:334] Iteration 10000, Testing net (#0)
I1028 20:36:05.230309 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5554
I1028 20:36:05.230541 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78732
I1028 20:36:05.230557 12802 solver.cpp:401]     Test net output #2: loss = 1.98265 (* 1 = 1.98265 loss)
I1028 20:36:05.979861 12802 solver.cpp:222] Iteration 10000 (0.62192 iter/s, 64.317s/40 iters), loss = 1.47304
I1028 20:36:05.979924 12802 solver.cpp:241]     Train net output #0: loss = 1.47304 (* 1 = 1.47304 loss)
I1028 20:36:05.979943 12802 sgd_solver.cpp:105] Iteration 10000, lr = 0.00406541
I1028 20:36:35.619957 12802 solver.cpp:222] Iteration 10040 (1.34956 iter/s, 29.6393s/40 iters), loss = 1.65173
I1028 20:36:35.620142 12802 solver.cpp:241]     Train net output #0: loss = 1.65173 (* 1 = 1.65173 loss)
I1028 20:36:35.620159 12802 sgd_solver.cpp:105] Iteration 10040, lr = 0.0040508
I1028 20:37:05.299242 12802 solver.cpp:222] Iteration 10080 (1.34778 iter/s, 29.6783s/40 iters), loss = 1.45637
I1028 20:37:05.299302 12802 solver.cpp:241]     Train net output #0: loss = 1.45637 (* 1 = 1.45637 loss)
I1028 20:37:05.299319 12802 sgd_solver.cpp:105] Iteration 10080, lr = 0.00403624
I1028 20:37:34.971915 12802 solver.cpp:222] Iteration 10120 (1.34808 iter/s, 29.6718s/40 iters), loss = 1.97656
I1028 20:37:34.972120 12802 solver.cpp:241]     Train net output #0: loss = 1.97656 (* 1 = 1.97656 loss)
I1028 20:37:34.972136 12802 sgd_solver.cpp:105] Iteration 10120, lr = 0.00402174
I1028 20:38:04.649963 12802 solver.cpp:222] Iteration 10160 (1.34784 iter/s, 29.6771s/40 iters), loss = 1.97405
I1028 20:38:04.650019 12802 solver.cpp:241]     Train net output #0: loss = 1.97405 (* 1 = 1.97405 loss)
I1028 20:38:04.650034 12802 sgd_solver.cpp:105] Iteration 10160, lr = 0.00400728
I1028 20:38:34.395036 12802 solver.cpp:222] Iteration 10200 (1.3448 iter/s, 29.7442s/40 iters), loss = 1.55686
I1028 20:38:34.395228 12802 solver.cpp:241]     Train net output #0: loss = 1.55686 (* 1 = 1.55686 loss)
I1028 20:38:34.395246 12802 sgd_solver.cpp:105] Iteration 10200, lr = 0.00399288
I1028 20:39:04.116081 12802 solver.cpp:222] Iteration 10240 (1.34589 iter/s, 29.7201s/40 iters), loss = 1.61527
I1028 20:39:04.116138 12802 solver.cpp:241]     Train net output #0: loss = 1.61527 (* 1 = 1.61527 loss)
I1028 20:39:04.116153 12802 sgd_solver.cpp:105] Iteration 10240, lr = 0.00397853
I1028 20:39:33.953258 12802 solver.cpp:222] Iteration 10280 (1.34064 iter/s, 29.8364s/40 iters), loss = 1.43257
I1028 20:39:33.953449 12802 solver.cpp:241]     Train net output #0: loss = 1.43257 (* 1 = 1.43257 loss)
I1028 20:39:33.953465 12802 sgd_solver.cpp:105] Iteration 10280, lr = 0.00396423
I1028 20:40:04.288345 12802 solver.cpp:222] Iteration 10320 (1.31865 iter/s, 30.3341s/40 iters), loss = 1.55491
I1028 20:40:04.288533 12802 solver.cpp:241]     Train net output #0: loss = 1.55491 (* 1 = 1.55491 loss)
I1028 20:40:04.288550 12802 sgd_solver.cpp:105] Iteration 10320, lr = 0.00394999
I1028 20:40:34.048712 12802 solver.cpp:222] Iteration 10360 (1.34411 iter/s, 29.7594s/40 iters), loss = 1.49985
I1028 20:40:34.048769 12802 solver.cpp:241]     Train net output #0: loss = 1.49985 (* 1 = 1.49985 loss)
I1028 20:40:34.048782 12802 sgd_solver.cpp:105] Iteration 10360, lr = 0.00393579
I1028 20:41:03.887857 12802 solver.cpp:222] Iteration 10400 (1.34056 iter/s, 29.8383s/40 iters), loss = 1.61374
I1028 20:41:03.888044 12802 solver.cpp:241]     Train net output #0: loss = 1.61374 (* 1 = 1.61374 loss)
I1028 20:41:03.888061 12802 sgd_solver.cpp:105] Iteration 10400, lr = 0.00392165
I1028 20:41:33.765257 12802 solver.cpp:222] Iteration 10440 (1.33885 iter/s, 29.8764s/40 iters), loss = 1.65669
I1028 20:41:33.765316 12802 solver.cpp:241]     Train net output #0: loss = 1.65669 (* 1 = 1.65669 loss)
I1028 20:41:33.765334 12802 sgd_solver.cpp:105] Iteration 10440, lr = 0.00390755
I1028 20:42:03.720281 12802 solver.cpp:222] Iteration 10480 (1.33537 iter/s, 29.9542s/40 iters), loss = 1.86266
I1028 20:42:03.720631 12802 solver.cpp:241]     Train net output #0: loss = 1.86266 (* 1 = 1.86266 loss)
I1028 20:42:03.720676 12802 sgd_solver.cpp:105] Iteration 10480, lr = 0.00389351
I1028 20:42:18.395732 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_10500.caffemodel
I1028 20:42:18.538233 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_10500.solverstate
I1028 20:42:18.650730 12802 solver.cpp:334] Iteration 10500, Testing net (#0)
I1028 20:42:49.741729 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1028 20:42:49.952127 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5572
I1028 20:42:49.952180 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79428
I1028 20:42:49.952193 12802 solver.cpp:401]     Test net output #2: loss = 1.98252 (* 1 = 1.98252 loss)
I1028 20:43:06.069829 12802 solver.cpp:222] Iteration 10520 (0.641563 iter/s, 62.3478s/40 iters), loss = 1.44613
I1028 20:43:06.069897 12802 solver.cpp:241]     Train net output #0: loss = 1.44613 (* 1 = 1.44613 loss)
I1028 20:43:06.069913 12802 sgd_solver.cpp:105] Iteration 10520, lr = 0.00387952
I1028 20:43:35.718071 12802 solver.cpp:222] Iteration 10560 (1.34919 iter/s, 29.6474s/40 iters), loss = 1.68214
I1028 20:43:35.718282 12802 solver.cpp:241]     Train net output #0: loss = 1.68214 (* 1 = 1.68214 loss)
I1028 20:43:35.718298 12802 sgd_solver.cpp:105] Iteration 10560, lr = 0.00386558
I1028 20:44:05.359573 12802 solver.cpp:222] Iteration 10600 (1.3495 iter/s, 29.6406s/40 iters), loss = 1.82178
I1028 20:44:05.359642 12802 solver.cpp:241]     Train net output #0: loss = 1.82178 (* 1 = 1.82178 loss)
I1028 20:44:05.359658 12802 sgd_solver.cpp:105] Iteration 10600, lr = 0.00385168
I1028 20:44:35.025167 12802 solver.cpp:222] Iteration 10640 (1.3484 iter/s, 29.6648s/40 iters), loss = 1.73006
I1028 20:44:35.025327 12802 solver.cpp:241]     Train net output #0: loss = 1.73006 (* 1 = 1.73006 loss)
I1028 20:44:35.025346 12802 sgd_solver.cpp:105] Iteration 10640, lr = 0.00383784
I1028 20:45:04.652825 12802 solver.cpp:222] Iteration 10680 (1.35013 iter/s, 29.6267s/40 iters), loss = 1.22634
I1028 20:45:04.652886 12802 solver.cpp:241]     Train net output #0: loss = 1.22634 (* 1 = 1.22634 loss)
I1028 20:45:04.652902 12802 sgd_solver.cpp:105] Iteration 10680, lr = 0.00382405
I1028 20:45:34.281441 12802 solver.cpp:222] Iteration 10720 (1.35008 iter/s, 29.6278s/40 iters), loss = 1.57689
I1028 20:45:34.281616 12802 solver.cpp:241]     Train net output #0: loss = 1.57689 (* 1 = 1.57689 loss)
I1028 20:45:34.281633 12802 sgd_solver.cpp:105] Iteration 10720, lr = 0.00381031
I1028 20:46:04.076820 12802 solver.cpp:222] Iteration 10760 (1.34253 iter/s, 29.7944s/40 iters), loss = 1.72727
I1028 20:46:04.076882 12802 solver.cpp:241]     Train net output #0: loss = 1.72727 (* 1 = 1.72727 loss)
I1028 20:46:04.076898 12802 sgd_solver.cpp:105] Iteration 10760, lr = 0.00379661
I1028 20:46:34.072234 12802 solver.cpp:222] Iteration 10800 (1.33357 iter/s, 29.9946s/40 iters), loss = 1.49004
I1028 20:46:34.072408 12802 solver.cpp:241]     Train net output #0: loss = 1.49004 (* 1 = 1.49004 loss)
I1028 20:46:34.072423 12802 sgd_solver.cpp:105] Iteration 10800, lr = 0.00378297
I1028 20:47:04.107417 12802 solver.cpp:222] Iteration 10840 (1.33181 iter/s, 30.0342s/40 iters), loss = 1.51215
I1028 20:47:04.107584 12802 solver.cpp:241]     Train net output #0: loss = 1.51215 (* 1 = 1.51215 loss)
I1028 20:47:04.107601 12802 sgd_solver.cpp:105] Iteration 10840, lr = 0.00376937
I1028 20:47:34.099596 12802 solver.cpp:222] Iteration 10880 (1.33372 iter/s, 29.9912s/40 iters), loss = 1.53498
I1028 20:47:34.099656 12802 solver.cpp:241]     Train net output #0: loss = 1.53498 (* 1 = 1.53498 loss)
I1028 20:47:34.099673 12802 sgd_solver.cpp:105] Iteration 10880, lr = 0.00375583
I1028 20:48:04.000401 12802 solver.cpp:222] Iteration 10920 (1.33779 iter/s, 29.9s/40 iters), loss = 1.65011
I1028 20:48:04.000625 12802 solver.cpp:241]     Train net output #0: loss = 1.65011 (* 1 = 1.65011 loss)
I1028 20:48:04.000643 12802 sgd_solver.cpp:105] Iteration 10920, lr = 0.00374233
I1028 20:48:33.714077 12802 solver.cpp:222] Iteration 10960 (1.34623 iter/s, 29.7127s/40 iters), loss = 1.44555
I1028 20:48:33.714140 12802 solver.cpp:241]     Train net output #0: loss = 1.44555 (* 1 = 1.44555 loss)
I1028 20:48:33.714155 12802 sgd_solver.cpp:105] Iteration 10960, lr = 0.00372888
I1028 20:49:02.953104 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_11000.caffemodel
I1028 20:49:03.092931 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_11000.solverstate
I1028 20:49:03.218051 12802 solver.cpp:334] Iteration 11000, Testing net (#0)
I1028 20:49:34.589326 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56232
I1028 20:49:34.589484 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.795
I1028 20:49:34.589498 12802 solver.cpp:401]     Test net output #2: loss = 1.93371 (* 1 = 1.93371 loss)
I1028 20:49:35.356562 12802 solver.cpp:222] Iteration 11000 (0.648919 iter/s, 61.641s/40 iters), loss = 1.59835
I1028 20:49:35.356609 12802 solver.cpp:241]     Train net output #0: loss = 1.59835 (* 1 = 1.59835 loss)
I1028 20:49:35.356626 12802 sgd_solver.cpp:105] Iteration 11000, lr = 0.00371548
I1028 20:50:06.536217 12802 solver.cpp:222] Iteration 11040 (1.28292 iter/s, 31.1788s/40 iters), loss = 1.67894
I1028 20:50:06.536415 12802 solver.cpp:241]     Train net output #0: loss = 1.67894 (* 1 = 1.67894 loss)
I1028 20:50:06.536437 12802 sgd_solver.cpp:105] Iteration 11040, lr = 0.00370213
I1028 20:50:45.083400 12802 solver.cpp:222] Iteration 11080 (1.03772 iter/s, 38.546s/40 iters), loss = 1.32801
I1028 20:50:45.083603 12802 solver.cpp:241]     Train net output #0: loss = 1.32801 (* 1 = 1.32801 loss)
I1028 20:50:45.083621 12802 sgd_solver.cpp:105] Iteration 11080, lr = 0.00368882
I1028 20:50:53.621421 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1028 20:51:16.474401 12802 solver.cpp:222] Iteration 11120 (1.27429 iter/s, 31.39s/40 iters), loss = 1.47146
I1028 20:51:16.474553 12802 solver.cpp:241]     Train net output #0: loss = 1.47146 (* 1 = 1.47146 loss)
I1028 20:51:16.474572 12802 sgd_solver.cpp:105] Iteration 11120, lr = 0.00367556
I1028 20:51:46.688712 12802 solver.cpp:222] Iteration 11160 (1.32392 iter/s, 30.2134s/40 iters), loss = 1.61839
I1028 20:51:46.688858 12802 solver.cpp:241]     Train net output #0: loss = 1.61839 (* 1 = 1.61839 loss)
I1028 20:51:46.688874 12802 sgd_solver.cpp:105] Iteration 11160, lr = 0.00366235
I1028 20:52:17.030735 12802 solver.cpp:222] Iteration 11200 (1.31834 iter/s, 30.3411s/40 iters), loss = 1.59249
I1028 20:52:17.030908 12802 solver.cpp:241]     Train net output #0: loss = 1.59249 (* 1 = 1.59249 loss)
I1028 20:52:17.030930 12802 sgd_solver.cpp:105] Iteration 11200, lr = 0.00364919
I1028 20:52:47.190598 12802 solver.cpp:222] Iteration 11240 (1.3263 iter/s, 30.159s/40 iters), loss = 1.47196
I1028 20:52:47.190739 12802 solver.cpp:241]     Train net output #0: loss = 1.47196 (* 1 = 1.47196 loss)
I1028 20:52:47.190754 12802 sgd_solver.cpp:105] Iteration 11240, lr = 0.00363608
I1028 20:53:17.291034 12802 solver.cpp:222] Iteration 11280 (1.32892 iter/s, 30.0995s/40 iters), loss = 1.74535
I1028 20:53:17.291213 12802 solver.cpp:241]     Train net output #0: loss = 1.74535 (* 1 = 1.74535 loss)
I1028 20:53:17.291231 12802 sgd_solver.cpp:105] Iteration 11280, lr = 0.00362301
I1028 20:53:47.382678 12802 solver.cpp:222] Iteration 11320 (1.32932 iter/s, 30.0907s/40 iters), loss = 1.46042
I1028 20:53:47.382817 12802 solver.cpp:241]     Train net output #0: loss = 1.46042 (* 1 = 1.46042 loss)
I1028 20:53:47.382834 12802 sgd_solver.cpp:105] Iteration 11320, lr = 0.00360999
I1028 20:54:17.200582 12802 solver.cpp:222] Iteration 11360 (1.34151 iter/s, 29.8171s/40 iters), loss = 1.70438
I1028 20:54:17.200639 12802 solver.cpp:241]     Train net output #0: loss = 1.70438 (* 1 = 1.70438 loss)
I1028 20:54:17.200652 12802 sgd_solver.cpp:105] Iteration 11360, lr = 0.00359702
I1028 20:54:47.090567 12802 solver.cpp:222] Iteration 11400 (1.33828 iter/s, 29.8892s/40 iters), loss = 1.47062
I1028 20:54:47.090775 12802 solver.cpp:241]     Train net output #0: loss = 1.47062 (* 1 = 1.47062 loss)
I1028 20:54:47.090792 12802 sgd_solver.cpp:105] Iteration 11400, lr = 0.00358409
I1028 20:55:16.974792 12802 solver.cpp:222] Iteration 11440 (1.33854 iter/s, 29.8833s/40 iters), loss = 1.88329
I1028 20:55:16.974853 12802 solver.cpp:241]     Train net output #0: loss = 1.88329 (* 1 = 1.88329 loss)
I1028 20:55:16.974869 12802 sgd_solver.cpp:105] Iteration 11440, lr = 0.00357121
I1028 20:55:46.802916 12802 solver.cpp:222] Iteration 11480 (1.34105 iter/s, 29.8274s/40 iters), loss = 1.59114
I1028 20:55:46.803146 12802 solver.cpp:241]     Train net output #0: loss = 1.59114 (* 1 = 1.59114 loss)
I1028 20:55:46.803164 12802 sgd_solver.cpp:105] Iteration 11480, lr = 0.00355837
I1028 20:56:01.139128 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_11500.caffemodel
I1028 20:56:01.280885 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_11500.solverstate
I1028 20:56:01.393882 12802 solver.cpp:334] Iteration 11500, Testing net (#0)
I1028 20:56:32.439309 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1028 20:56:32.648746 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5596
I1028 20:56:32.648798 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79904
I1028 20:56:32.648809 12802 solver.cpp:401]     Test net output #2: loss = 1.9491 (* 1 = 1.9491 loss)
I1028 20:56:48.379631 12802 solver.cpp:222] Iteration 11520 (0.649614 iter/s, 61.575s/40 iters), loss = 1.32697
I1028 20:56:48.379688 12802 solver.cpp:241]     Train net output #0: loss = 1.32697 (* 1 = 1.32697 loss)
I1028 20:56:48.379705 12802 sgd_solver.cpp:105] Iteration 11520, lr = 0.00354559
I1028 20:57:18.839458 12802 solver.cpp:222] Iteration 11560 (1.31324 iter/s, 30.459s/40 iters), loss = 1.56967
I1028 20:57:18.839637 12802 solver.cpp:241]     Train net output #0: loss = 1.56967 (* 1 = 1.56967 loss)
I1028 20:57:18.839653 12802 sgd_solver.cpp:105] Iteration 11560, lr = 0.00353284
I1028 20:57:48.883946 12802 solver.cpp:222] Iteration 11600 (1.3314 iter/s, 30.0436s/40 iters), loss = 1.6036
I1028 20:57:48.884114 12802 solver.cpp:241]     Train net output #0: loss = 1.6036 (* 1 = 1.6036 loss)
I1028 20:57:48.884131 12802 sgd_solver.cpp:105] Iteration 11600, lr = 0.00352015
I1028 20:58:18.736086 12802 solver.cpp:222] Iteration 11640 (1.33998 iter/s, 29.8513s/40 iters), loss = 1.4302
I1028 20:58:18.736150 12802 solver.cpp:241]     Train net output #0: loss = 1.4302 (* 1 = 1.4302 loss)
I1028 20:58:18.736166 12802 sgd_solver.cpp:105] Iteration 11640, lr = 0.0035075
I1028 20:58:48.776037 12802 solver.cpp:222] Iteration 11680 (1.33159 iter/s, 30.0392s/40 iters), loss = 1.66856
I1028 20:58:48.776211 12802 solver.cpp:241]     Train net output #0: loss = 1.66856 (* 1 = 1.66856 loss)
I1028 20:58:48.776227 12802 sgd_solver.cpp:105] Iteration 11680, lr = 0.00349489
I1028 20:59:18.962695 12802 solver.cpp:222] Iteration 11720 (1.32513 iter/s, 30.1858s/40 iters), loss = 1.8482
I1028 20:59:18.962875 12802 solver.cpp:241]     Train net output #0: loss = 1.8482 (* 1 = 1.8482 loss)
I1028 20:59:18.962893 12802 sgd_solver.cpp:105] Iteration 11720, lr = 0.00348233
I1028 20:59:48.970456 12802 solver.cpp:222] Iteration 11760 (1.33303 iter/s, 30.0069s/40 iters), loss = 1.63388
I1028 20:59:48.970656 12802 solver.cpp:241]     Train net output #0: loss = 1.63388 (* 1 = 1.63388 loss)
I1028 20:59:48.970674 12802 sgd_solver.cpp:105] Iteration 11760, lr = 0.00346982
I1028 21:00:18.586812 12802 solver.cpp:222] Iteration 11800 (1.35065 iter/s, 29.6154s/40 iters), loss = 1.65229
I1028 21:00:18.586876 12802 solver.cpp:241]     Train net output #0: loss = 1.65229 (* 1 = 1.65229 loss)
I1028 21:00:18.586892 12802 sgd_solver.cpp:105] Iteration 11800, lr = 0.00345735
I1028 21:00:48.221829 12802 solver.cpp:222] Iteration 11840 (1.34979 iter/s, 29.6342s/40 iters), loss = 1.38608
I1028 21:00:48.222116 12802 solver.cpp:241]     Train net output #0: loss = 1.38608 (* 1 = 1.38608 loss)
I1028 21:00:48.222154 12802 sgd_solver.cpp:105] Iteration 11840, lr = 0.00344492
I1028 21:01:18.110093 12802 solver.cpp:222] Iteration 11880 (1.33836 iter/s, 29.8873s/40 iters), loss = 1.93452
I1028 21:01:18.110155 12802 solver.cpp:241]     Train net output #0: loss = 1.93452 (* 1 = 1.93452 loss)
I1028 21:01:18.110170 12802 sgd_solver.cpp:105] Iteration 11880, lr = 0.00343254
I1028 21:01:47.706688 12802 solver.cpp:222] Iteration 11920 (1.35154 iter/s, 29.5958s/40 iters), loss = 1.17497
I1028 21:01:47.706899 12802 solver.cpp:241]     Train net output #0: loss = 1.17497 (* 1 = 1.17497 loss)
I1028 21:01:47.706917 12802 sgd_solver.cpp:105] Iteration 11920, lr = 0.00342021
I1028 21:02:17.488153 12802 solver.cpp:222] Iteration 11960 (1.34316 iter/s, 29.7805s/40 iters), loss = 1.35255
I1028 21:02:17.488216 12802 solver.cpp:241]     Train net output #0: loss = 1.35255 (* 1 = 1.35255 loss)
I1028 21:02:17.488232 12802 sgd_solver.cpp:105] Iteration 11960, lr = 0.00340791
I1028 21:02:47.784294 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_12000.caffemodel
I1028 21:02:47.932577 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_12000.solverstate
I1028 21:02:48.046233 12802 solver.cpp:334] Iteration 12000, Testing net (#0)
I1028 21:03:19.374872 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56016
I1028 21:03:19.375020 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79168
I1028 21:03:19.375035 12802 solver.cpp:401]     Test net output #2: loss = 1.94832 (* 1 = 1.94832 loss)
I1028 21:03:20.143635 12802 solver.cpp:222] Iteration 12000 (0.638427 iter/s, 62.654s/40 iters), loss = 1.57013
I1028 21:03:20.143688 12802 solver.cpp:241]     Train net output #0: loss = 1.57013 (* 1 = 1.57013 loss)
I1028 21:03:20.143708 12802 sgd_solver.cpp:105] Iteration 12000, lr = 0.00339567
I1028 21:03:50.046041 12802 solver.cpp:222] Iteration 12040 (1.33772 iter/s, 29.9016s/40 iters), loss = 1.52304
I1028 21:03:50.046254 12802 solver.cpp:241]     Train net output #0: loss = 1.52304 (* 1 = 1.52304 loss)
I1028 21:03:50.046272 12802 sgd_solver.cpp:105] Iteration 12040, lr = 0.00338346
I1028 21:04:20.018054 12802 solver.cpp:222] Iteration 12080 (1.33462 iter/s, 29.9711s/40 iters), loss = 1.88844
I1028 21:04:20.018116 12802 solver.cpp:241]     Train net output #0: loss = 1.88844 (* 1 = 1.88844 loss)
I1028 21:04:20.018131 12802 sgd_solver.cpp:105] Iteration 12080, lr = 0.0033713
I1028 21:04:51.320870 12802 solver.cpp:222] Iteration 12120 (1.27787 iter/s, 31.302s/40 iters), loss = 1.36372
I1028 21:04:51.321092 12802 solver.cpp:241]     Train net output #0: loss = 1.36372 (* 1 = 1.36372 loss)
I1028 21:04:51.321113 12802 sgd_solver.cpp:105] Iteration 12120, lr = 0.00335919
I1028 21:05:24.334360 12802 solver.cpp:222] Iteration 12160 (1.21166 iter/s, 33.0125s/40 iters), loss = 1.36378
I1028 21:05:24.334549 12802 solver.cpp:241]     Train net output #0: loss = 1.36378 (* 1 = 1.36378 loss)
I1028 21:05:24.334570 12802 sgd_solver.cpp:105] Iteration 12160, lr = 0.00334712
I1028 21:05:55.464948 12802 solver.cpp:222] Iteration 12200 (1.28495 iter/s, 31.1297s/40 iters), loss = 1.53005
I1028 21:05:55.465124 12802 solver.cpp:241]     Train net output #0: loss = 1.53005 (* 1 = 1.53005 loss)
I1028 21:05:55.465142 12802 sgd_solver.cpp:105] Iteration 12200, lr = 0.00333509
I1028 21:06:26.564229 12802 solver.cpp:222] Iteration 12240 (1.28624 iter/s, 31.0984s/40 iters), loss = 1.50046
I1028 21:06:26.564396 12802 solver.cpp:241]     Train net output #0: loss = 1.50046 (* 1 = 1.50046 loss)
I1028 21:06:26.564414 12802 sgd_solver.cpp:105] Iteration 12240, lr = 0.0033231
I1028 21:06:57.531010 12802 solver.cpp:222] Iteration 12280 (1.29174 iter/s, 30.9659s/40 iters), loss = 1.71312
I1028 21:06:57.531196 12802 solver.cpp:241]     Train net output #0: loss = 1.71312 (* 1 = 1.71312 loss)
I1028 21:06:57.531213 12802 sgd_solver.cpp:105] Iteration 12280, lr = 0.00331116
I1028 21:07:28.236752 12802 solver.cpp:222] Iteration 12320 (1.30273 iter/s, 30.7048s/40 iters), loss = 1.72666
I1028 21:07:28.237108 12802 solver.cpp:241]     Train net output #0: loss = 1.72666 (* 1 = 1.72666 loss)
I1028 21:07:28.237146 12802 sgd_solver.cpp:105] Iteration 12320, lr = 0.00329926
I1028 21:07:59.386489 12802 solver.cpp:222] Iteration 12360 (1.28416 iter/s, 31.1487s/40 iters), loss = 1.48443
I1028 21:07:59.386673 12802 solver.cpp:241]     Train net output #0: loss = 1.48443 (* 1 = 1.48443 loss)
I1028 21:07:59.386689 12802 sgd_solver.cpp:105] Iteration 12360, lr = 0.0032874
I1028 21:08:29.633651 12802 solver.cpp:222] Iteration 12400 (1.32248 iter/s, 30.2463s/40 iters), loss = 1.48808
I1028 21:08:29.633859 12802 solver.cpp:241]     Train net output #0: loss = 1.48808 (* 1 = 1.48808 loss)
I1028 21:08:29.633877 12802 sgd_solver.cpp:105] Iteration 12400, lr = 0.00327559
I1028 21:08:59.710070 12802 solver.cpp:222] Iteration 12440 (1.32999 iter/s, 30.0755s/40 iters), loss = 1.58288
I1028 21:08:59.710265 12802 solver.cpp:241]     Train net output #0: loss = 1.58288 (* 1 = 1.58288 loss)
I1028 21:08:59.710283 12802 sgd_solver.cpp:105] Iteration 12440, lr = 0.00326382
I1028 21:09:29.864488 12802 solver.cpp:222] Iteration 12480 (1.32655 iter/s, 30.1535s/40 iters), loss = 1.5653
I1028 21:09:29.864662 12802 solver.cpp:241]     Train net output #0: loss = 1.5653 (* 1 = 1.5653 loss)
I1028 21:09:29.864676 12802 sgd_solver.cpp:105] Iteration 12480, lr = 0.00325209
I1028 21:09:44.166618 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_12500.caffemodel
I1028 21:09:44.310117 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_12500.solverstate
I1028 21:09:44.441948 12802 solver.cpp:334] Iteration 12500, Testing net (#0)
I1028 21:10:15.632526 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1028 21:10:15.842900 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56732
I1028 21:10:15.842954 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79888
I1028 21:10:15.842965 12802 solver.cpp:401]     Test net output #2: loss = 1.92917 (* 1 = 1.92917 loss)
I1028 21:10:31.540186 12802 solver.cpp:222] Iteration 12520 (0.648571 iter/s, 61.6741s/40 iters), loss = 1.36106
I1028 21:10:31.540262 12802 solver.cpp:241]     Train net output #0: loss = 1.36106 (* 1 = 1.36106 loss)
I1028 21:10:31.540282 12802 sgd_solver.cpp:105] Iteration 12520, lr = 0.0032404
I1028 21:11:02.406307 12802 solver.cpp:222] Iteration 12560 (1.29595 iter/s, 30.8653s/40 iters), loss = 1.69539
I1028 21:11:02.406503 12802 solver.cpp:241]     Train net output #0: loss = 1.69539 (* 1 = 1.69539 loss)
I1028 21:11:02.406523 12802 sgd_solver.cpp:105] Iteration 12560, lr = 0.00322875
I1028 21:11:33.309799 12802 solver.cpp:222] Iteration 12600 (1.29439 iter/s, 30.9026s/40 iters), loss = 1.40686
I1028 21:11:33.310000 12802 solver.cpp:241]     Train net output #0: loss = 1.40686 (* 1 = 1.40686 loss)
I1028 21:11:33.310017 12802 sgd_solver.cpp:105] Iteration 12600, lr = 0.00321715
I1028 21:12:03.426049 12802 solver.cpp:222] Iteration 12640 (1.32823 iter/s, 30.1153s/40 iters), loss = 1.45331
I1028 21:12:03.426211 12802 solver.cpp:241]     Train net output #0: loss = 1.45331 (* 1 = 1.45331 loss)
I1028 21:12:03.426229 12802 sgd_solver.cpp:105] Iteration 12640, lr = 0.00320559
I1028 21:12:33.649674 12802 solver.cpp:222] Iteration 12680 (1.32351 iter/s, 30.2227s/40 iters), loss = 1.75123
I1028 21:12:33.649837 12802 solver.cpp:241]     Train net output #0: loss = 1.75123 (* 1 = 1.75123 loss)
I1028 21:12:33.649855 12802 sgd_solver.cpp:105] Iteration 12680, lr = 0.00319407
I1028 21:13:04.145967 12802 solver.cpp:222] Iteration 12720 (1.31167 iter/s, 30.4954s/40 iters), loss = 1.81447
I1028 21:13:04.146181 12802 solver.cpp:241]     Train net output #0: loss = 1.81447 (* 1 = 1.81447 loss)
I1028 21:13:04.146198 12802 sgd_solver.cpp:105] Iteration 12720, lr = 0.00318259
I1028 21:13:34.727607 12802 solver.cpp:222] Iteration 12760 (1.30801 iter/s, 30.5807s/40 iters), loss = 1.62639
I1028 21:13:34.727869 12802 solver.cpp:241]     Train net output #0: loss = 1.62639 (* 1 = 1.62639 loss)
I1028 21:13:34.727907 12802 sgd_solver.cpp:105] Iteration 12760, lr = 0.00317115
I1028 21:14:05.037827 12802 solver.cpp:222] Iteration 12800 (1.31973 iter/s, 30.3092s/40 iters), loss = 1.63217
I1028 21:14:05.038014 12802 solver.cpp:241]     Train net output #0: loss = 1.63217 (* 1 = 1.63217 loss)
I1028 21:14:05.038033 12802 sgd_solver.cpp:105] Iteration 12800, lr = 0.00315976
I1028 21:14:35.507412 12802 solver.cpp:222] Iteration 12840 (1.31282 iter/s, 30.4687s/40 iters), loss = 1.44637
I1028 21:14:35.507593 12802 solver.cpp:241]     Train net output #0: loss = 1.44637 (* 1 = 1.44637 loss)
I1028 21:14:35.507609 12802 sgd_solver.cpp:105] Iteration 12840, lr = 0.0031484
I1028 21:15:05.826625 12802 solver.cpp:222] Iteration 12880 (1.31933 iter/s, 30.3183s/40 iters), loss = 1.64776
I1028 21:15:05.826804 12802 solver.cpp:241]     Train net output #0: loss = 1.64776 (* 1 = 1.64776 loss)
I1028 21:15:05.826822 12802 sgd_solver.cpp:105] Iteration 12880, lr = 0.00313709
I1028 21:15:36.217222 12802 solver.cpp:222] Iteration 12920 (1.31624 iter/s, 30.3897s/40 iters), loss = 1.71578
I1028 21:15:36.217403 12802 solver.cpp:241]     Train net output #0: loss = 1.71578 (* 1 = 1.71578 loss)
I1028 21:15:36.217420 12802 sgd_solver.cpp:105] Iteration 12920, lr = 0.00312581
I1028 21:16:06.576876 12802 solver.cpp:222] Iteration 12960 (1.31758 iter/s, 30.3587s/40 iters), loss = 1.37139
I1028 21:16:06.577047 12802 solver.cpp:241]     Train net output #0: loss = 1.37139 (* 1 = 1.37139 loss)
I1028 21:16:06.577062 12802 sgd_solver.cpp:105] Iteration 12960, lr = 0.00311458
I1028 21:16:36.289660 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_13000.caffemodel
I1028 21:16:36.430733 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_13000.solverstate
I1028 21:16:36.547827 12802 solver.cpp:334] Iteration 13000, Testing net (#0)
I1028 21:17:07.836282 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56116
I1028 21:17:07.836488 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79356
I1028 21:17:07.836501 12802 solver.cpp:401]     Test net output #2: loss = 1.93386 (* 1 = 1.93386 loss)
I1028 21:17:08.588944 12802 solver.cpp:222] Iteration 13000 (0.645053 iter/s, 62.0104s/40 iters), loss = 1.5729
I1028 21:17:08.588995 12802 solver.cpp:241]     Train net output #0: loss = 1.5729 (* 1 = 1.5729 loss)
I1028 21:17:08.589012 12802 sgd_solver.cpp:105] Iteration 13000, lr = 0.00310338
I1028 21:17:39.622611 12802 solver.cpp:222] Iteration 13040 (1.28896 iter/s, 31.0329s/40 iters), loss = 1.54076
I1028 21:17:39.622805 12802 solver.cpp:241]     Train net output #0: loss = 1.54076 (* 1 = 1.54076 loss)
I1028 21:17:39.622822 12802 sgd_solver.cpp:105] Iteration 13040, lr = 0.00309223
I1028 21:18:09.927280 12802 solver.cpp:222] Iteration 13080 (1.31997 iter/s, 30.3037s/40 iters), loss = 1.44576
I1028 21:18:09.927453 12802 solver.cpp:241]     Train net output #0: loss = 1.44576 (* 1 = 1.44576 loss)
I1028 21:18:09.927469 12802 sgd_solver.cpp:105] Iteration 13080, lr = 0.00308112
I1028 21:18:40.110265 12802 solver.cpp:222] Iteration 13120 (1.32529 iter/s, 30.1821s/40 iters), loss = 1.5488
I1028 21:18:40.110436 12802 solver.cpp:241]     Train net output #0: loss = 1.5488 (* 1 = 1.5488 loss)
I1028 21:18:40.110453 12802 sgd_solver.cpp:105] Iteration 13120, lr = 0.00307005
I1028 21:19:10.127297 12802 solver.cpp:222] Iteration 13160 (1.33262 iter/s, 30.0161s/40 iters), loss = 1.38229
I1028 21:19:10.127496 12802 solver.cpp:241]     Train net output #0: loss = 1.38229 (* 1 = 1.38229 loss)
I1028 21:19:10.127513 12802 sgd_solver.cpp:105] Iteration 13160, lr = 0.00305901
I1028 21:19:40.274078 12802 solver.cpp:222] Iteration 13200 (1.32688 iter/s, 30.1459s/40 iters), loss = 1.8661
I1028 21:19:40.274328 12802 solver.cpp:241]     Train net output #0: loss = 1.8661 (* 1 = 1.8661 loss)
I1028 21:19:40.274345 12802 sgd_solver.cpp:105] Iteration 13200, lr = 0.00304802
I1028 21:20:10.205899 12802 solver.cpp:222] Iteration 13240 (1.33641 iter/s, 29.9308s/40 iters), loss = 1.97083
I1028 21:20:10.208693 12802 solver.cpp:241]     Train net output #0: loss = 1.97083 (* 1 = 1.97083 loss)
I1028 21:20:10.211896 12802 sgd_solver.cpp:105] Iteration 13240, lr = 0.00303706
I1028 21:20:52.452904 12802 solver.cpp:222] Iteration 13280 (0.946898 iter/s, 42.2432s/40 iters), loss = 1.78652
I1028 21:20:52.453143 12802 solver.cpp:241]     Train net output #0: loss = 1.78652 (* 1 = 1.78652 loss)
I1028 21:20:52.453161 12802 sgd_solver.cpp:105] Iteration 13280, lr = 0.00302615
I1028 21:21:23.711518 12802 solver.cpp:222] Iteration 13320 (1.27969 iter/s, 31.2576s/40 iters), loss = 1.37625
I1028 21:21:23.711709 12802 solver.cpp:241]     Train net output #0: loss = 1.37625 (* 1 = 1.37625 loss)
I1028 21:21:23.711725 12802 sgd_solver.cpp:105] Iteration 13320, lr = 0.00301527
I1028 21:21:54.565074 12802 solver.cpp:222] Iteration 13360 (1.29649 iter/s, 30.8526s/40 iters), loss = 1.64433
I1028 21:21:54.565291 12802 solver.cpp:241]     Train net output #0: loss = 1.64433 (* 1 = 1.64433 loss)
I1028 21:21:54.565309 12802 sgd_solver.cpp:105] Iteration 13360, lr = 0.00300444
I1028 21:22:25.457900 12802 solver.cpp:222] Iteration 13400 (1.29484 iter/s, 30.8919s/40 iters), loss = 1.80603
I1028 21:22:25.458089 12802 solver.cpp:241]     Train net output #0: loss = 1.80603 (* 1 = 1.80603 loss)
I1028 21:22:25.458107 12802 sgd_solver.cpp:105] Iteration 13400, lr = 0.00299364
I1028 21:22:56.667577 12802 solver.cpp:222] Iteration 13440 (1.28169 iter/s, 31.2087s/40 iters), loss = 1.72443
I1028 21:22:56.667762 12802 solver.cpp:241]     Train net output #0: loss = 1.72443 (* 1 = 1.72443 loss)
I1028 21:22:56.667789 12802 sgd_solver.cpp:105] Iteration 13440, lr = 0.00298288
I1028 21:23:27.377336 12802 solver.cpp:222] Iteration 13480 (1.30256 iter/s, 30.7088s/40 iters), loss = 1.36649
I1028 21:23:27.377529 12802 solver.cpp:241]     Train net output #0: loss = 1.36649 (* 1 = 1.36649 loss)
I1028 21:23:27.377547 12802 sgd_solver.cpp:105] Iteration 13480, lr = 0.00297216
I1028 21:23:41.886857 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_13500.caffemodel
I1028 21:23:42.023792 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_13500.solverstate
I1028 21:23:42.137840 12802 solver.cpp:334] Iteration 13500, Testing net (#0)
I1028 21:24:13.185154 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1028 21:24:13.392386 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56688
I1028 21:24:13.392431 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80032
I1028 21:24:13.392443 12802 solver.cpp:401]     Test net output #2: loss = 1.91722 (* 1 = 1.91722 loss)
I1028 21:24:29.814842 12802 solver.cpp:222] Iteration 13520 (0.640658 iter/s, 62.4358s/40 iters), loss = 1.66668
I1028 21:24:29.814913 12802 solver.cpp:241]     Train net output #0: loss = 1.66668 (* 1 = 1.66668 loss)
I1028 21:24:29.814939 12802 sgd_solver.cpp:105] Iteration 13520, lr = 0.00296148
I1028 21:25:00.805480 12802 solver.cpp:222] Iteration 13560 (1.29075 iter/s, 30.9898s/40 iters), loss = 1.45542
I1028 21:25:00.805691 12802 solver.cpp:241]     Train net output #0: loss = 1.45542 (* 1 = 1.45542 loss)
I1028 21:25:00.805709 12802 sgd_solver.cpp:105] Iteration 13560, lr = 0.00295084
I1028 21:25:26.745175 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1028 21:25:31.149514 12802 solver.cpp:222] Iteration 13600 (1.31826 iter/s, 30.3431s/40 iters), loss = 1.74684
I1028 21:25:31.149705 12802 solver.cpp:241]     Train net output #0: loss = 1.74684 (* 1 = 1.74684 loss)
I1028 21:25:31.149721 12802 sgd_solver.cpp:105] Iteration 13600, lr = 0.00294023
I1028 21:26:01.186230 12802 solver.cpp:222] Iteration 13640 (1.33174 iter/s, 30.0358s/40 iters), loss = 1.73181
I1028 21:26:01.186478 12802 solver.cpp:241]     Train net output #0: loss = 1.73181 (* 1 = 1.73181 loss)
I1028 21:26:01.186494 12802 sgd_solver.cpp:105] Iteration 13640, lr = 0.00292967
I1028 21:26:31.177073 12802 solver.cpp:222] Iteration 13680 (1.33378 iter/s, 29.9899s/40 iters), loss = 1.44219
I1028 21:26:31.177129 12802 solver.cpp:241]     Train net output #0: loss = 1.44219 (* 1 = 1.44219 loss)
I1028 21:26:31.177145 12802 sgd_solver.cpp:105] Iteration 13680, lr = 0.00291914
I1028 21:27:01.210793 12802 solver.cpp:222] Iteration 13720 (1.33187 iter/s, 30.0329s/40 iters), loss = 1.30539
I1028 21:27:01.211375 12802 solver.cpp:241]     Train net output #0: loss = 1.30539 (* 1 = 1.30539 loss)
I1028 21:27:01.211393 12802 sgd_solver.cpp:105] Iteration 13720, lr = 0.00290865
I1028 21:27:31.356972 12802 solver.cpp:222] Iteration 13760 (1.32693 iter/s, 30.1449s/40 iters), loss = 1.56078
I1028 21:27:31.357153 12802 solver.cpp:241]     Train net output #0: loss = 1.56078 (* 1 = 1.56078 loss)
I1028 21:27:31.357170 12802 sgd_solver.cpp:105] Iteration 13760, lr = 0.00289819
I1028 21:28:01.644224 12802 solver.cpp:222] Iteration 13800 (1.32073 iter/s, 30.2863s/40 iters), loss = 1.45458
I1028 21:28:01.644403 12802 solver.cpp:241]     Train net output #0: loss = 1.45458 (* 1 = 1.45458 loss)
I1028 21:28:01.644420 12802 sgd_solver.cpp:105] Iteration 13800, lr = 0.00288778
I1028 21:28:32.008711 12802 solver.cpp:222] Iteration 13840 (1.31737 iter/s, 30.3636s/40 iters), loss = 1.57447
I1028 21:28:32.008900 12802 solver.cpp:241]     Train net output #0: loss = 1.57447 (* 1 = 1.57447 loss)
I1028 21:28:32.008918 12802 sgd_solver.cpp:105] Iteration 13840, lr = 0.0028774
I1028 21:29:02.092795 12802 solver.cpp:222] Iteration 13880 (1.32965 iter/s, 30.0832s/40 iters), loss = 1.45088
I1028 21:29:02.093039 12802 solver.cpp:241]     Train net output #0: loss = 1.45088 (* 1 = 1.45088 loss)
I1028 21:29:02.093063 12802 sgd_solver.cpp:105] Iteration 13880, lr = 0.00286706
I1028 21:29:39.491000 12802 solver.cpp:222] Iteration 13920 (1.0696 iter/s, 37.3971s/40 iters), loss = 1.68078
I1028 21:29:39.491230 12802 solver.cpp:241]     Train net output #0: loss = 1.68078 (* 1 = 1.68078 loss)
I1028 21:29:39.491247 12802 sgd_solver.cpp:105] Iteration 13920, lr = 0.00285676
I1028 21:30:21.555896 12802 solver.cpp:222] Iteration 13960 (0.950939 iter/s, 42.0637s/40 iters), loss = 1.28816
I1028 21:30:21.556105 12802 solver.cpp:241]     Train net output #0: loss = 1.28816 (* 1 = 1.28816 loss)
I1028 21:30:21.556123 12802 sgd_solver.cpp:105] Iteration 13960, lr = 0.00284649
I1028 21:30:52.240685 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_14000.caffemodel
I1028 21:30:52.384549 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_14000.solverstate
I1028 21:30:52.513738 12802 solver.cpp:334] Iteration 14000, Testing net (#0)
I1028 21:31:23.926832 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56964
I1028 21:31:23.926980 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.798199
I1028 21:31:23.926995 12802 solver.cpp:401]     Test net output #2: loss = 1.92492 (* 1 = 1.92492 loss)
I1028 21:31:24.676501 12802 solver.cpp:222] Iteration 14000 (0.633724 iter/s, 63.1189s/40 iters), loss = 1.21293
I1028 21:31:24.676560 12802 solver.cpp:241]     Train net output #0: loss = 1.21293 (* 1 = 1.21293 loss)
I1028 21:31:24.676576 12802 sgd_solver.cpp:105] Iteration 14000, lr = 0.00283626
I1028 21:31:55.749948 12802 solver.cpp:222] Iteration 14040 (1.28731 iter/s, 31.0726s/40 iters), loss = 1.84209
I1028 21:31:55.750170 12802 solver.cpp:241]     Train net output #0: loss = 1.84209 (* 1 = 1.84209 loss)
I1028 21:31:55.750188 12802 sgd_solver.cpp:105] Iteration 14040, lr = 0.00282607
I1028 21:32:26.416889 12802 solver.cpp:222] Iteration 14080 (1.30438 iter/s, 30.666s/40 iters), loss = 1.21902
I1028 21:32:26.417098 12802 solver.cpp:241]     Train net output #0: loss = 1.21902 (* 1 = 1.21902 loss)
I1028 21:32:26.417115 12802 sgd_solver.cpp:105] Iteration 14080, lr = 0.00281591
I1028 21:32:57.749632 12802 solver.cpp:222] Iteration 14120 (1.27666 iter/s, 31.3318s/40 iters), loss = 1.63276
I1028 21:32:57.749833 12802 solver.cpp:241]     Train net output #0: loss = 1.63276 (* 1 = 1.63276 loss)
I1028 21:32:57.749848 12802 sgd_solver.cpp:105] Iteration 14120, lr = 0.00280579
I1028 21:33:31.826136 12802 solver.cpp:222] Iteration 14160 (1.17386 iter/s, 34.0755s/40 iters), loss = 1.54016
I1028 21:33:31.826318 12802 solver.cpp:241]     Train net output #0: loss = 1.54016 (* 1 = 1.54016 loss)
I1028 21:33:31.826331 12802 sgd_solver.cpp:105] Iteration 14160, lr = 0.00279571
I1028 21:34:02.504199 12802 solver.cpp:222] Iteration 14200 (1.3039 iter/s, 30.6771s/40 iters), loss = 1.70167
I1028 21:34:02.504391 12802 solver.cpp:241]     Train net output #0: loss = 1.70167 (* 1 = 1.70167 loss)
I1028 21:34:02.504408 12802 sgd_solver.cpp:105] Iteration 14200, lr = 0.00278566
I1028 21:34:33.431654 12802 solver.cpp:222] Iteration 14240 (1.29339 iter/s, 30.9265s/40 iters), loss = 1.24064
I1028 21:34:33.431852 12802 solver.cpp:241]     Train net output #0: loss = 1.24064 (* 1 = 1.24064 loss)
I1028 21:34:33.431870 12802 sgd_solver.cpp:105] Iteration 14240, lr = 0.00277565
I1028 21:35:03.200378 12802 solver.cpp:222] Iteration 14280 (1.34373 iter/s, 29.7678s/40 iters), loss = 1.75922
I1028 21:35:03.200436 12802 solver.cpp:241]     Train net output #0: loss = 1.75922 (* 1 = 1.75922 loss)
I1028 21:35:03.200453 12802 sgd_solver.cpp:105] Iteration 14280, lr = 0.00276567
I1028 21:35:32.797041 12802 solver.cpp:222] Iteration 14320 (1.35154 iter/s, 29.5959s/40 iters), loss = 1.97006
I1028 21:35:32.797215 12802 solver.cpp:241]     Train net output #0: loss = 1.97006 (* 1 = 1.97006 loss)
I1028 21:35:32.797232 12802 sgd_solver.cpp:105] Iteration 14320, lr = 0.00275573
I1028 21:36:02.873443 12802 solver.cpp:222] Iteration 14360 (1.32999 iter/s, 30.0755s/40 iters), loss = 1.30047
I1028 21:36:02.873601 12802 solver.cpp:241]     Train net output #0: loss = 1.30047 (* 1 = 1.30047 loss)
I1028 21:36:02.873618 12802 sgd_solver.cpp:105] Iteration 14360, lr = 0.00274583
I1028 21:36:47.121567 12802 solver.cpp:222] Iteration 14400 (0.904018 iter/s, 44.2469s/40 iters), loss = 1.46392
I1028 21:36:47.121732 12802 solver.cpp:241]     Train net output #0: loss = 1.46392 (* 1 = 1.46392 loss)
I1028 21:36:47.121750 12802 sgd_solver.cpp:105] Iteration 14400, lr = 0.00273596
I1028 21:37:18.852924 12802 solver.cpp:222] Iteration 14440 (1.26062 iter/s, 31.7304s/40 iters), loss = 1.69078
I1028 21:37:18.853075 12802 solver.cpp:241]     Train net output #0: loss = 1.69078 (* 1 = 1.69078 loss)
I1028 21:37:18.853091 12802 sgd_solver.cpp:105] Iteration 14440, lr = 0.00272613
I1028 21:37:49.604306 12802 solver.cpp:222] Iteration 14480 (1.30079 iter/s, 30.7505s/40 iters), loss = 1.52913
I1028 21:37:49.604455 12802 solver.cpp:241]     Train net output #0: loss = 1.52913 (* 1 = 1.52913 loss)
I1028 21:37:49.604472 12802 sgd_solver.cpp:105] Iteration 14480, lr = 0.00271633
I1028 21:38:04.065376 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_14500.caffemodel
I1028 21:38:04.212880 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_14500.solverstate
I1028 21:38:04.338912 12802 solver.cpp:334] Iteration 14500, Testing net (#0)
I1028 21:38:35.558008 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1028 21:38:35.769146 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56224
I1028 21:38:35.769198 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79728
I1028 21:38:35.769208 12802 solver.cpp:401]     Test net output #2: loss = 1.95703 (* 1 = 1.95703 loss)
I1028 21:38:52.217947 12802 solver.cpp:222] Iteration 14520 (0.638855 iter/s, 62.612s/40 iters), loss = 1.71856
I1028 21:38:52.218014 12802 solver.cpp:241]     Train net output #0: loss = 1.71856 (* 1 = 1.71856 loss)
I1028 21:38:52.218035 12802 sgd_solver.cpp:105] Iteration 14520, lr = 0.00270657
I1028 21:39:23.290554 12802 solver.cpp:222] Iteration 14560 (1.28734 iter/s, 31.0718s/40 iters), loss = 1.38934
I1028 21:39:23.290874 12802 solver.cpp:241]     Train net output #0: loss = 1.38934 (* 1 = 1.38934 loss)
I1028 21:39:23.290941 12802 sgd_solver.cpp:105] Iteration 14560, lr = 0.00269684
I1028 21:39:54.272267 12802 solver.cpp:222] Iteration 14600 (1.29113 iter/s, 30.9807s/40 iters), loss = 1.68405
I1028 21:39:54.272455 12802 solver.cpp:241]     Train net output #0: loss = 1.68405 (* 1 = 1.68405 loss)
I1028 21:39:54.272472 12802 sgd_solver.cpp:105] Iteration 14600, lr = 0.00268715
I1028 21:40:24.581218 12802 solver.cpp:222] Iteration 14640 (1.31978 iter/s, 30.308s/40 iters), loss = 1.43357
I1028 21:40:24.581399 12802 solver.cpp:241]     Train net output #0: loss = 1.43357 (* 1 = 1.43357 loss)
I1028 21:40:24.581414 12802 sgd_solver.cpp:105] Iteration 14640, lr = 0.00267749
I1028 21:40:54.414613 12802 solver.cpp:222] Iteration 14680 (1.34082 iter/s, 29.8325s/40 iters), loss = 1.55978
I1028 21:40:54.414674 12802 solver.cpp:241]     Train net output #0: loss = 1.55978 (* 1 = 1.55978 loss)
I1028 21:40:54.414687 12802 sgd_solver.cpp:105] Iteration 14680, lr = 0.00266787
I1028 21:41:24.369681 12802 solver.cpp:222] Iteration 14720 (1.33537 iter/s, 29.9543s/40 iters), loss = 1.65573
I1028 21:41:24.369901 12802 solver.cpp:241]     Train net output #0: loss = 1.65573 (* 1 = 1.65573 loss)
I1028 21:41:24.369915 12802 sgd_solver.cpp:105] Iteration 14720, lr = 0.00265828
I1028 21:43:02.395045 12802 solver.cpp:222] Iteration 14760 (0.408068 iter/s, 98.0229s/40 iters), loss = 1.59918
I1028 21:43:02.395216 12802 solver.cpp:241]     Train net output #0: loss = 1.59918 (* 1 = 1.59918 loss)
I1028 21:43:02.395234 12802 sgd_solver.cpp:105] Iteration 14760, lr = 0.00264873
I1028 21:43:41.226688 12802 solver.cpp:222] Iteration 14800 (1.03012 iter/s, 38.8306s/40 iters), loss = 1.42674
I1028 21:43:41.226897 12802 solver.cpp:241]     Train net output #0: loss = 1.42674 (* 1 = 1.42674 loss)
I1028 21:43:41.226914 12802 sgd_solver.cpp:105] Iteration 14800, lr = 0.00263921
I1028 21:44:12.445181 12802 solver.cpp:222] Iteration 14840 (1.28133 iter/s, 31.2175s/40 iters), loss = 1.17205
I1028 21:44:12.445411 12802 solver.cpp:241]     Train net output #0: loss = 1.17205 (* 1 = 1.17205 loss)
I1028 21:44:12.445436 12802 sgd_solver.cpp:105] Iteration 14840, lr = 0.00262973
I1028 21:44:43.675571 12802 solver.cpp:222] Iteration 14880 (1.28084 iter/s, 31.2294s/40 iters), loss = 1.77892
I1028 21:44:43.675771 12802 solver.cpp:241]     Train net output #0: loss = 1.77892 (* 1 = 1.77892 loss)
I1028 21:44:43.675786 12802 sgd_solver.cpp:105] Iteration 14880, lr = 0.00262028
I1028 21:45:14.912741 12802 solver.cpp:222] Iteration 14920 (1.28056 iter/s, 31.2362s/40 iters), loss = 1.35925
I1028 21:45:14.912951 12802 solver.cpp:241]     Train net output #0: loss = 1.35925 (* 1 = 1.35925 loss)
I1028 21:45:14.912973 12802 sgd_solver.cpp:105] Iteration 14920, lr = 0.00261086
I1028 21:45:45.053592 12802 solver.cpp:222] Iteration 14960 (1.32714 iter/s, 30.1399s/40 iters), loss = 1.51078
I1028 21:45:45.053782 12802 solver.cpp:241]     Train net output #0: loss = 1.51078 (* 1 = 1.51078 loss)
I1028 21:45:45.053799 12802 sgd_solver.cpp:105] Iteration 14960, lr = 0.00260148
I1028 21:46:15.138797 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_15000.caffemodel
I1028 21:46:15.284616 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_15000.solverstate
I1028 21:46:15.416297 12802 solver.cpp:334] Iteration 15000, Testing net (#0)
I1028 21:46:46.687155 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5672
I1028 21:46:46.687304 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.798279
I1028 21:46:46.687317 12802 solver.cpp:401]     Test net output #2: loss = 1.90798 (* 1 = 1.90798 loss)
I1028 21:46:47.451441 12802 solver.cpp:222] Iteration 15000 (0.641065 iter/s, 62.3962s/40 iters), loss = 1.53881
I1028 21:46:47.451498 12802 solver.cpp:241]     Train net output #0: loss = 1.53881 (* 1 = 1.53881 loss)
I1028 21:46:47.451514 12802 sgd_solver.cpp:105] Iteration 15000, lr = 0.00259213
I1028 21:47:18.070128 12802 solver.cpp:222] Iteration 15040 (1.30643 iter/s, 30.6179s/40 iters), loss = 1.53747
I1028 21:47:18.070381 12802 solver.cpp:241]     Train net output #0: loss = 1.53747 (* 1 = 1.53747 loss)
I1028 21:47:18.070399 12802 sgd_solver.cpp:105] Iteration 15040, lr = 0.00258281
I1028 21:48:12.459767 12802 solver.cpp:222] Iteration 15080 (0.735455 iter/s, 54.3881s/40 iters), loss = 1.23594
I1028 21:48:12.460177 12802 solver.cpp:241]     Train net output #0: loss = 1.23594 (* 1 = 1.23594 loss)
I1028 21:48:12.460194 12802 sgd_solver.cpp:105] Iteration 15080, lr = 0.00257353
I1028 21:48:42.614576 12802 solver.cpp:222] Iteration 15120 (1.32654 iter/s, 30.1537s/40 iters), loss = 1.3795
I1028 21:48:42.614753 12802 solver.cpp:241]     Train net output #0: loss = 1.3795 (* 1 = 1.3795 loss)
I1028 21:48:42.614769 12802 sgd_solver.cpp:105] Iteration 15120, lr = 0.00256428
I1028 21:49:12.542136 12802 solver.cpp:222] Iteration 15160 (1.3366 iter/s, 29.9267s/40 iters), loss = 1.5477
I1028 21:49:12.542194 12802 solver.cpp:241]     Train net output #0: loss = 1.5477 (* 1 = 1.5477 loss)
I1028 21:49:12.542209 12802 sgd_solver.cpp:105] Iteration 15160, lr = 0.00255507
I1028 21:49:42.723736 12802 solver.cpp:222] Iteration 15200 (1.32535 iter/s, 30.1808s/40 iters), loss = 1.51222
I1028 21:49:42.723944 12802 solver.cpp:241]     Train net output #0: loss = 1.51222 (* 1 = 1.51222 loss)
I1028 21:49:42.723963 12802 sgd_solver.cpp:105] Iteration 15200, lr = 0.00254588
I1028 21:50:12.748994 12802 solver.cpp:222] Iteration 15240 (1.33225 iter/s, 30.0243s/40 iters), loss = 1.66068
I1028 21:50:12.749204 12802 solver.cpp:241]     Train net output #0: loss = 1.66068 (* 1 = 1.66068 loss)
I1028 21:50:12.749225 12802 sgd_solver.cpp:105] Iteration 15240, lr = 0.00253673
I1028 21:50:42.942791 12802 solver.cpp:222] Iteration 15280 (1.32482 iter/s, 30.1929s/40 iters), loss = 1.48272
I1028 21:50:42.943132 12802 solver.cpp:241]     Train net output #0: loss = 1.48272 (* 1 = 1.48272 loss)
I1028 21:50:42.943148 12802 sgd_solver.cpp:105] Iteration 15280, lr = 0.00252762
I1028 21:51:13.182639 12802 solver.cpp:222] Iteration 15320 (1.3228 iter/s, 30.2388s/40 iters), loss = 1.54683
I1028 21:51:13.182837 12802 solver.cpp:241]     Train net output #0: loss = 1.54683 (* 1 = 1.54683 loss)
I1028 21:51:13.182854 12802 sgd_solver.cpp:105] Iteration 15320, lr = 0.00251853
I1028 21:51:43.403100 12802 solver.cpp:222] Iteration 15360 (1.32365 iter/s, 30.2195s/40 iters), loss = 1.87657
I1028 21:51:43.403270 12802 solver.cpp:241]     Train net output #0: loss = 1.87657 (* 1 = 1.87657 loss)
I1028 21:51:43.403286 12802 sgd_solver.cpp:105] Iteration 15360, lr = 0.00250948
I1028 21:52:13.842308 12802 solver.cpp:222] Iteration 15400 (1.31413 iter/s, 30.4383s/40 iters), loss = 1.55424
I1028 21:52:13.842504 12802 solver.cpp:241]     Train net output #0: loss = 1.55424 (* 1 = 1.55424 loss)
I1028 21:52:13.842521 12802 sgd_solver.cpp:105] Iteration 15400, lr = 0.00250046
I1028 21:52:44.957396 12802 solver.cpp:222] Iteration 15440 (1.28559 iter/s, 31.1141s/40 iters), loss = 1.6029
I1028 21:52:44.957592 12802 solver.cpp:241]     Train net output #0: loss = 1.6029 (* 1 = 1.6029 loss)
I1028 21:52:44.957614 12802 sgd_solver.cpp:105] Iteration 15440, lr = 0.00249148
I1028 21:53:16.095170 12802 solver.cpp:222] Iteration 15480 (1.28465 iter/s, 31.1368s/40 iters), loss = 1.37369
I1028 21:53:16.095386 12802 solver.cpp:241]     Train net output #0: loss = 1.37369 (* 1 = 1.37369 loss)
I1028 21:53:16.095402 12802 sgd_solver.cpp:105] Iteration 15480, lr = 0.00248252
I1028 21:53:30.970443 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_15500.caffemodel
I1028 21:53:31.106401 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_15500.solverstate
I1028 21:53:31.222712 12802 solver.cpp:334] Iteration 15500, Testing net (#0)
I1028 21:54:02.279711 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1028 21:54:02.489084 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56816
I1028 21:54:02.489137 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80224
I1028 21:54:02.489147 12802 solver.cpp:401]     Test net output #2: loss = 1.91127 (* 1 = 1.91127 loss)
I1028 21:54:18.722944 12802 solver.cpp:222] Iteration 15520 (0.638712 iter/s, 62.6261s/40 iters), loss = 1.22971
I1028 21:54:18.723001 12802 solver.cpp:241]     Train net output #0: loss = 1.22971 (* 1 = 1.22971 loss)
I1028 21:54:18.723016 12802 sgd_solver.cpp:105] Iteration 15520, lr = 0.0024736
I1028 21:54:48.560904 12802 solver.cpp:222] Iteration 15560 (1.34061 iter/s, 29.8372s/40 iters), loss = 1.51804
I1028 21:54:48.561112 12802 solver.cpp:241]     Train net output #0: loss = 1.51804 (* 1 = 1.51804 loss)
I1028 21:54:48.561131 12802 sgd_solver.cpp:105] Iteration 15560, lr = 0.00246471
I1028 21:55:18.540076 12802 solver.cpp:222] Iteration 15600 (1.3343 iter/s, 29.9782s/40 iters), loss = 1.67369
I1028 21:55:18.540132 12802 solver.cpp:241]     Train net output #0: loss = 1.67369 (* 1 = 1.67369 loss)
I1028 21:55:18.540148 12802 sgd_solver.cpp:105] Iteration 15600, lr = 0.00245585
I1028 21:55:49.184757 12802 solver.cpp:222] Iteration 15640 (1.30532 iter/s, 30.6439s/40 iters), loss = 1.56025
I1028 21:55:49.184960 12802 solver.cpp:241]     Train net output #0: loss = 1.56025 (* 1 = 1.56025 loss)
I1028 21:55:49.184978 12802 sgd_solver.cpp:105] Iteration 15640, lr = 0.00244703
I1028 21:56:19.081840 12802 solver.cpp:222] Iteration 15680 (1.33796 iter/s, 29.8962s/40 iters), loss = 1.55433
I1028 21:56:19.081900 12802 solver.cpp:241]     Train net output #0: loss = 1.55433 (* 1 = 1.55433 loss)
I1028 21:56:19.081915 12802 sgd_solver.cpp:105] Iteration 15680, lr = 0.00243823
I1028 21:56:49.450702 12802 solver.cpp:222] Iteration 15720 (1.31717 iter/s, 30.3681s/40 iters), loss = 1.78207
I1028 21:56:49.450908 12802 solver.cpp:241]     Train net output #0: loss = 1.78207 (* 1 = 1.78207 loss)
I1028 21:56:49.450930 12802 sgd_solver.cpp:105] Iteration 15720, lr = 0.00242947
I1028 21:57:19.797611 12802 solver.cpp:222] Iteration 15760 (1.31813 iter/s, 30.346s/40 iters), loss = 1.33529
I1028 21:57:19.797808 12802 solver.cpp:241]     Train net output #0: loss = 1.33529 (* 1 = 1.33529 loss)
I1028 21:57:19.797824 12802 sgd_solver.cpp:105] Iteration 15760, lr = 0.00242074
I1028 21:57:49.592854 12802 solver.cpp:222] Iteration 15800 (1.34254 iter/s, 29.7943s/40 iters), loss = 1.40221
I1028 21:57:49.592911 12802 solver.cpp:241]     Train net output #0: loss = 1.40221 (* 1 = 1.40221 loss)
I1028 21:57:49.592931 12802 sgd_solver.cpp:105] Iteration 15800, lr = 0.00241204
I1028 21:58:19.911206 12802 solver.cpp:222] Iteration 15840 (1.31937 iter/s, 30.3176s/40 iters), loss = 1.50221
I1028 21:58:19.911420 12802 solver.cpp:241]     Train net output #0: loss = 1.50221 (* 1 = 1.50221 loss)
I1028 21:58:19.911437 12802 sgd_solver.cpp:105] Iteration 15840, lr = 0.00240337
I1028 21:58:49.557992 12802 solver.cpp:222] Iteration 15880 (1.34926 iter/s, 29.6459s/40 iters), loss = 1.52752
I1028 21:58:49.558055 12802 solver.cpp:241]     Train net output #0: loss = 1.52752 (* 1 = 1.52752 loss)
I1028 21:58:49.558071 12802 sgd_solver.cpp:105] Iteration 15880, lr = 0.00239474
I1028 21:59:19.792495 12802 solver.cpp:222] Iteration 15920 (1.32303 iter/s, 30.2337s/40 iters), loss = 1.55739
I1028 21:59:19.792703 12802 solver.cpp:241]     Train net output #0: loss = 1.55739 (* 1 = 1.55739 loss)
I1028 21:59:19.792717 12802 sgd_solver.cpp:105] Iteration 15920, lr = 0.00238613
I1028 21:59:49.448312 12802 solver.cpp:222] Iteration 15960 (1.34885 iter/s, 29.6549s/40 iters), loss = 1.55005
I1028 21:59:49.448375 12802 solver.cpp:241]     Train net output #0: loss = 1.55005 (* 1 = 1.55005 loss)
I1028 21:59:49.448388 12802 sgd_solver.cpp:105] Iteration 15960, lr = 0.00237755
I1028 22:00:18.355216 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_16000.caffemodel
I1028 22:00:18.497349 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_16000.solverstate
I1028 22:00:18.611627 12802 solver.cpp:334] Iteration 16000, Testing net (#0)
I1028 22:00:49.875586 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57
I1028 22:00:49.875756 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.801
I1028 22:00:49.875769 12802 solver.cpp:401]     Test net output #2: loss = 1.89302 (* 1 = 1.89302 loss)
I1028 22:00:50.643147 12802 solver.cpp:222] Iteration 16000 (0.653666 iter/s, 61.1934s/40 iters), loss = 1.30703
I1028 22:00:50.643198 12802 solver.cpp:241]     Train net output #0: loss = 1.30703 (* 1 = 1.30703 loss)
I1028 22:00:50.643213 12802 sgd_solver.cpp:105] Iteration 16000, lr = 0.00236901
I1028 22:01:20.746733 12802 solver.cpp:222] Iteration 16040 (1.32878 iter/s, 30.1028s/40 iters), loss = 1.3549
I1028 22:01:20.746951 12802 solver.cpp:241]     Train net output #0: loss = 1.3549 (* 1 = 1.3549 loss)
I1028 22:01:20.746968 12802 sgd_solver.cpp:105] Iteration 16040, lr = 0.0023605
I1028 22:01:50.932229 12802 solver.cpp:222] Iteration 16080 (1.32518 iter/s, 30.1846s/40 iters), loss = 1.87672
I1028 22:01:50.932426 12802 solver.cpp:241]     Train net output #0: loss = 1.87672 (* 1 = 1.87672 loss)
I1028 22:01:50.932443 12802 sgd_solver.cpp:105] Iteration 16080, lr = 0.00235201
I1028 22:02:03.047787 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1028 22:02:21.065435 12802 solver.cpp:222] Iteration 16120 (1.32748 iter/s, 30.1323s/40 iters), loss = 1.47156
I1028 22:02:21.065637 12802 solver.cpp:241]     Train net output #0: loss = 1.47156 (* 1 = 1.47156 loss)
I1028 22:02:21.065656 12802 sgd_solver.cpp:105] Iteration 16120, lr = 0.00234356
I1028 22:02:51.328472 12802 solver.cpp:222] Iteration 16160 (1.32178 iter/s, 30.2621s/40 iters), loss = 1.35497
I1028 22:02:51.328680 12802 solver.cpp:241]     Train net output #0: loss = 1.35497 (* 1 = 1.35497 loss)
I1028 22:02:51.328697 12802 sgd_solver.cpp:105] Iteration 16160, lr = 0.00233514
I1028 22:03:21.309525 12802 solver.cpp:222] Iteration 16200 (1.33422 iter/s, 29.9801s/40 iters), loss = 1.5447
I1028 22:03:21.309589 12802 solver.cpp:241]     Train net output #0: loss = 1.5447 (* 1 = 1.5447 loss)
I1028 22:03:21.309602 12802 sgd_solver.cpp:105] Iteration 16200, lr = 0.00232675
I1028 22:03:51.681380 12802 solver.cpp:222] Iteration 16240 (1.31704 iter/s, 30.3711s/40 iters), loss = 1.42753
I1028 22:03:51.681588 12802 solver.cpp:241]     Train net output #0: loss = 1.42753 (* 1 = 1.42753 loss)
I1028 22:03:51.681605 12802 sgd_solver.cpp:105] Iteration 16240, lr = 0.00231838
I1028 22:04:21.645434 12802 solver.cpp:222] Iteration 16280 (1.33497 iter/s, 29.9631s/40 iters), loss = 1.45557
I1028 22:04:21.645498 12802 solver.cpp:241]     Train net output #0: loss = 1.45557 (* 1 = 1.45557 loss)
I1028 22:04:21.645512 12802 sgd_solver.cpp:105] Iteration 16280, lr = 0.00231005
I1028 22:04:51.728468 12802 solver.cpp:222] Iteration 16320 (1.32969 iter/s, 30.0823s/40 iters), loss = 1.40868
I1028 22:04:51.728677 12802 solver.cpp:241]     Train net output #0: loss = 1.40868 (* 1 = 1.40868 loss)
I1028 22:04:51.728693 12802 sgd_solver.cpp:105] Iteration 16320, lr = 0.00230175
I1028 22:05:21.701473 12802 solver.cpp:222] Iteration 16360 (1.33458 iter/s, 29.9721s/40 iters), loss = 1.60324
I1028 22:05:21.701539 12802 solver.cpp:241]     Train net output #0: loss = 1.60324 (* 1 = 1.60324 loss)
I1028 22:05:21.701555 12802 sgd_solver.cpp:105] Iteration 16360, lr = 0.00229348
I1028 22:05:51.452757 12802 solver.cpp:222] Iteration 16400 (1.34452 iter/s, 29.7505s/40 iters), loss = 1.30375
I1028 22:05:51.453104 12802 solver.cpp:241]     Train net output #0: loss = 1.30375 (* 1 = 1.30375 loss)
I1028 22:05:51.453121 12802 sgd_solver.cpp:105] Iteration 16400, lr = 0.00228524
I1028 22:06:21.485812 12802 solver.cpp:222] Iteration 16440 (1.33191 iter/s, 30.032s/40 iters), loss = 1.30575
I1028 22:06:21.486002 12802 solver.cpp:241]     Train net output #0: loss = 1.30575 (* 1 = 1.30575 loss)
I1028 22:06:21.486016 12802 sgd_solver.cpp:105] Iteration 16440, lr = 0.00227702
I1028 22:06:51.329957 12802 solver.cpp:222] Iteration 16480 (1.34034 iter/s, 29.8432s/40 iters), loss = 1.44649
I1028 22:06:51.330014 12802 solver.cpp:241]     Train net output #0: loss = 1.44649 (* 1 = 1.44649 loss)
I1028 22:06:51.330029 12802 sgd_solver.cpp:105] Iteration 16480, lr = 0.00226884
I1028 22:07:05.492434 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_16500.caffemodel
I1028 22:07:05.644788 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_16500.solverstate
I1028 22:07:05.764071 12802 solver.cpp:334] Iteration 16500, Testing net (#0)
I1028 22:07:36.818274 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1028 22:07:37.025796 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56736
I1028 22:07:37.025849 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8004
I1028 22:07:37.025861 12802 solver.cpp:401]     Test net output #2: loss = 1.93245 (* 1 = 1.93245 loss)
I1028 22:07:52.924393 12802 solver.cpp:222] Iteration 16520 (0.649425 iter/s, 61.5929s/40 iters), loss = 1.57016
I1028 22:07:52.924453 12802 solver.cpp:241]     Train net output #0: loss = 1.57016 (* 1 = 1.57016 loss)
I1028 22:07:52.924469 12802 sgd_solver.cpp:105] Iteration 16520, lr = 0.00226069
I1028 22:08:22.651398 12802 solver.cpp:222] Iteration 16560 (1.34561 iter/s, 29.7262s/40 iters), loss = 1.57518
I1028 22:08:22.651582 12802 solver.cpp:241]     Train net output #0: loss = 1.57518 (* 1 = 1.57518 loss)
I1028 22:08:22.651600 12802 sgd_solver.cpp:105] Iteration 16560, lr = 0.00225256
I1028 22:08:52.396332 12802 solver.cpp:222] Iteration 16600 (1.34481 iter/s, 29.744s/40 iters), loss = 1.56891
I1028 22:08:52.396395 12802 solver.cpp:241]     Train net output #0: loss = 1.56891 (* 1 = 1.56891 loss)
I1028 22:08:52.396411 12802 sgd_solver.cpp:105] Iteration 16600, lr = 0.00224447
I1028 22:09:22.455454 12802 solver.cpp:222] Iteration 16640 (1.33075 iter/s, 30.0583s/40 iters), loss = 1.5652
I1028 22:09:22.455601 12802 solver.cpp:241]     Train net output #0: loss = 1.5652 (* 1 = 1.5652 loss)
I1028 22:09:22.455618 12802 sgd_solver.cpp:105] Iteration 16640, lr = 0.0022364
I1028 22:09:52.367180 12802 solver.cpp:222] Iteration 16680 (1.33731 iter/s, 29.9109s/40 iters), loss = 1.51187
I1028 22:09:52.367242 12802 solver.cpp:241]     Train net output #0: loss = 1.51187 (* 1 = 1.51187 loss)
I1028 22:09:52.367257 12802 sgd_solver.cpp:105] Iteration 16680, lr = 0.00222836
I1028 22:10:22.500819 12802 solver.cpp:222] Iteration 16720 (1.32746 iter/s, 30.1328s/40 iters), loss = 1.72715
I1028 22:10:22.501026 12802 solver.cpp:241]     Train net output #0: loss = 1.72715 (* 1 = 1.72715 loss)
I1028 22:10:22.501044 12802 sgd_solver.cpp:105] Iteration 16720, lr = 0.00222035
I1028 22:10:52.710748 12802 solver.cpp:222] Iteration 16760 (1.32411 iter/s, 30.209s/40 iters), loss = 1.2068
I1028 22:10:52.710958 12802 solver.cpp:241]     Train net output #0: loss = 1.2068 (* 1 = 1.2068 loss)
I1028 22:10:52.710975 12802 sgd_solver.cpp:105] Iteration 16760, lr = 0.00221238
I1028 22:11:22.303418 12802 solver.cpp:222] Iteration 16800 (1.35173 iter/s, 29.5917s/40 iters), loss = 1.56778
I1028 22:11:22.303483 12802 solver.cpp:241]     Train net output #0: loss = 1.56778 (* 1 = 1.56778 loss)
I1028 22:11:22.303495 12802 sgd_solver.cpp:105] Iteration 16800, lr = 0.00220442
I1028 22:11:51.922853 12802 solver.cpp:222] Iteration 16840 (1.3505 iter/s, 29.6187s/40 iters), loss = 1.25682
I1028 22:11:51.923041 12802 solver.cpp:241]     Train net output #0: loss = 1.25682 (* 1 = 1.25682 loss)
I1028 22:11:51.923058 12802 sgd_solver.cpp:105] Iteration 16840, lr = 0.0021965
I1028 22:12:21.517650 12802 solver.cpp:222] Iteration 16880 (1.35163 iter/s, 29.5939s/40 iters), loss = 1.55584
I1028 22:12:21.517709 12802 solver.cpp:241]     Train net output #0: loss = 1.55584 (* 1 = 1.55584 loss)
I1028 22:12:21.517725 12802 sgd_solver.cpp:105] Iteration 16880, lr = 0.00218861
I1028 22:12:51.200595 12802 solver.cpp:222] Iteration 16920 (1.34761 iter/s, 29.6822s/40 iters), loss = 1.11818
I1028 22:12:51.200880 12802 solver.cpp:241]     Train net output #0: loss = 1.11818 (* 1 = 1.11818 loss)
I1028 22:12:51.200914 12802 sgd_solver.cpp:105] Iteration 16920, lr = 0.00218074
I1028 22:13:20.986730 12802 solver.cpp:222] Iteration 16960 (1.34295 iter/s, 29.7852s/40 iters), loss = 1.60402
I1028 22:13:20.986788 12802 solver.cpp:241]     Train net output #0: loss = 1.60402 (* 1 = 1.60402 loss)
I1028 22:13:20.986800 12802 sgd_solver.cpp:105] Iteration 16960, lr = 0.00217291
I1028 22:13:50.450903 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_17000.caffemodel
I1028 22:13:50.593478 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_17000.solverstate
I1028 22:13:50.707819 12802 solver.cpp:334] Iteration 17000, Testing net (#0)
I1028 22:14:22.212270 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57144
I1028 22:14:22.212361 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79936
I1028 22:14:22.212375 12802 solver.cpp:401]     Test net output #2: loss = 1.91416 (* 1 = 1.91416 loss)
I1028 22:14:22.989588 12802 solver.cpp:222] Iteration 17000 (0.645147 iter/s, 62.0013s/40 iters), loss = 1.38455
I1028 22:14:22.989645 12802 solver.cpp:241]     Train net output #0: loss = 1.38455 (* 1 = 1.38455 loss)
I1028 22:14:22.989661 12802 sgd_solver.cpp:105] Iteration 17000, lr = 0.0021651
I1028 22:17:15.452616 12802 solver.cpp:222] Iteration 17040 (0.231939 iter/s, 172.459s/40 iters), loss = 1.56068
I1028 22:17:15.452810 12802 solver.cpp:241]     Train net output #0: loss = 1.56068 (* 1 = 1.56068 loss)
I1028 22:17:15.452826 12802 sgd_solver.cpp:105] Iteration 17040, lr = 0.00215732
I1028 22:17:45.665834 12802 solver.cpp:222] Iteration 17080 (1.32396 iter/s, 30.2123s/40 iters), loss = 1.37599
I1028 22:17:45.665987 12802 solver.cpp:241]     Train net output #0: loss = 1.37599 (* 1 = 1.37599 loss)
I1028 22:17:45.666005 12802 sgd_solver.cpp:105] Iteration 17080, lr = 0.00214956
I1028 22:18:16.828356 12802 solver.cpp:222] Iteration 17120 (1.28363 iter/s, 31.1616s/40 iters), loss = 1.41154
I1028 22:18:16.828502 12802 solver.cpp:241]     Train net output #0: loss = 1.41154 (* 1 = 1.41154 loss)
I1028 22:18:16.828519 12802 sgd_solver.cpp:105] Iteration 17120, lr = 0.00214184
I1028 22:18:47.499683 12802 solver.cpp:222] Iteration 17160 (1.30419 iter/s, 30.6705s/40 iters), loss = 1.44133
I1028 22:18:47.499830 12802 solver.cpp:241]     Train net output #0: loss = 1.44133 (* 1 = 1.44133 loss)
I1028 22:18:47.499847 12802 sgd_solver.cpp:105] Iteration 17160, lr = 0.00213414
I1028 22:19:18.032418 12802 solver.cpp:222] Iteration 17200 (1.31011 iter/s, 30.5319s/40 iters), loss = 1.51424
I1028 22:19:18.032565 12802 solver.cpp:241]     Train net output #0: loss = 1.51424 (* 1 = 1.51424 loss)
I1028 22:19:18.032583 12802 sgd_solver.cpp:105] Iteration 17200, lr = 0.00212647
I1028 22:19:48.566728 12802 solver.cpp:222] Iteration 17240 (1.31004 iter/s, 30.5334s/40 iters), loss = 1.39047
I1028 22:19:48.566901 12802 solver.cpp:241]     Train net output #0: loss = 1.39047 (* 1 = 1.39047 loss)
I1028 22:19:48.566922 12802 sgd_solver.cpp:105] Iteration 17240, lr = 0.00211883
I1028 22:20:18.966373 12802 solver.cpp:222] Iteration 17280 (1.31584 iter/s, 30.3988s/40 iters), loss = 1.43416
I1028 22:20:18.966573 12802 solver.cpp:241]     Train net output #0: loss = 1.43416 (* 1 = 1.43416 loss)
I1028 22:20:18.966590 12802 sgd_solver.cpp:105] Iteration 17280, lr = 0.00211121
I1028 22:20:48.768685 12802 solver.cpp:222] Iteration 17320 (1.34222 iter/s, 29.8014s/40 iters), loss = 1.66982
I1028 22:20:48.768744 12802 solver.cpp:241]     Train net output #0: loss = 1.66982 (* 1 = 1.66982 loss)
I1028 22:20:48.768760 12802 sgd_solver.cpp:105] Iteration 17320, lr = 0.00210363
I1028 22:21:18.234848 12802 solver.cpp:222] Iteration 17360 (1.35752 iter/s, 29.4654s/40 iters), loss = 1.66686
I1028 22:21:18.235092 12802 solver.cpp:241]     Train net output #0: loss = 1.66686 (* 1 = 1.66686 loss)
I1028 22:21:18.235107 12802 sgd_solver.cpp:105] Iteration 17360, lr = 0.00209607
I1028 22:21:47.715056 12802 solver.cpp:222] Iteration 17400 (1.35689 iter/s, 29.4793s/40 iters), loss = 1.33337
I1028 22:21:47.715119 12802 solver.cpp:241]     Train net output #0: loss = 1.33337 (* 1 = 1.33337 loss)
I1028 22:21:47.715135 12802 sgd_solver.cpp:105] Iteration 17400, lr = 0.00208853
I1028 22:22:17.192006 12802 solver.cpp:222] Iteration 17440 (1.35703 iter/s, 29.4762s/40 iters), loss = 1.84993
I1028 22:22:17.192162 12802 solver.cpp:241]     Train net output #0: loss = 1.84993 (* 1 = 1.84993 loss)
I1028 22:22:17.192178 12802 sgd_solver.cpp:105] Iteration 17440, lr = 0.00208103
I1028 22:22:46.701294 12802 solver.cpp:222] Iteration 17480 (1.35554 iter/s, 29.5084s/40 iters), loss = 1.4475
I1028 22:22:46.701359 12802 solver.cpp:241]     Train net output #0: loss = 1.4475 (* 1 = 1.4475 loss)
I1028 22:22:46.701375 12802 sgd_solver.cpp:105] Iteration 17480, lr = 0.00207355
I1028 22:23:00.750464 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_17500.caffemodel
I1028 22:23:00.907125 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_17500.solverstate
I1028 22:23:01.019178 12802 solver.cpp:334] Iteration 17500, Testing net (#0)
I1028 22:23:33.017151 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1028 22:23:33.223785 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57036
I1028 22:23:33.223835 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.803279
I1028 22:23:33.223847 12802 solver.cpp:401]     Test net output #2: loss = 1.91624 (* 1 = 1.91624 loss)
I1028 22:23:48.794291 12802 solver.cpp:222] Iteration 17520 (0.644211 iter/s, 62.0915s/40 iters), loss = 1.83966
I1028 22:23:48.794355 12802 solver.cpp:241]     Train net output #0: loss = 1.83966 (* 1 = 1.83966 loss)
I1028 22:23:48.794370 12802 sgd_solver.cpp:105] Iteration 17520, lr = 0.0020661
I1028 22:24:18.450196 12802 solver.cpp:222] Iteration 17560 (1.34884 iter/s, 29.6551s/40 iters), loss = 1.68018
I1028 22:24:18.450284 12802 solver.cpp:241]     Train net output #0: loss = 1.68018 (* 1 = 1.68018 loss)
I1028 22:24:18.450301 12802 sgd_solver.cpp:105] Iteration 17560, lr = 0.00205867
I1028 22:24:48.089990 12802 solver.cpp:222] Iteration 17600 (1.34957 iter/s, 29.639s/40 iters), loss = 1.55114
I1028 22:24:48.090050 12802 solver.cpp:241]     Train net output #0: loss = 1.55114 (* 1 = 1.55114 loss)
I1028 22:24:48.090065 12802 sgd_solver.cpp:105] Iteration 17600, lr = 0.00205127
I1028 22:25:17.677394 12802 solver.cpp:222] Iteration 17640 (1.35196 iter/s, 29.5866s/40 iters), loss = 1.42426
I1028 22:25:17.677491 12802 solver.cpp:241]     Train net output #0: loss = 1.42426 (* 1 = 1.42426 loss)
I1028 22:25:17.677505 12802 sgd_solver.cpp:105] Iteration 17640, lr = 0.0020439
I1028 22:25:47.280364 12802 solver.cpp:222] Iteration 17680 (1.35125 iter/s, 29.6021s/40 iters), loss = 1.3107
I1028 22:25:47.280428 12802 solver.cpp:241]     Train net output #0: loss = 1.3107 (* 1 = 1.3107 loss)
I1028 22:25:47.280444 12802 sgd_solver.cpp:105] Iteration 17680, lr = 0.00203656
I1028 22:26:16.894387 12802 solver.cpp:222] Iteration 17720 (1.35075 iter/s, 29.6133s/40 iters), loss = 1.64995
I1028 22:26:16.894533 12802 solver.cpp:241]     Train net output #0: loss = 1.64995 (* 1 = 1.64995 loss)
I1028 22:26:16.894551 12802 sgd_solver.cpp:105] Iteration 17720, lr = 0.00202924
I1028 22:26:46.468807 12802 solver.cpp:222] Iteration 17760 (1.35256 iter/s, 29.5736s/40 iters), loss = 1.41709
I1028 22:26:46.468871 12802 solver.cpp:241]     Train net output #0: loss = 1.41709 (* 1 = 1.41709 loss)
I1028 22:26:46.468885 12802 sgd_solver.cpp:105] Iteration 17760, lr = 0.00202194
I1028 22:27:15.950698 12802 solver.cpp:222] Iteration 17800 (1.3568 iter/s, 29.4811s/40 iters), loss = 1.2978
I1028 22:27:15.950806 12802 solver.cpp:241]     Train net output #0: loss = 1.2978 (* 1 = 1.2978 loss)
I1028 22:27:15.950824 12802 sgd_solver.cpp:105] Iteration 17800, lr = 0.00201468
I1028 22:27:45.443750 12802 solver.cpp:222] Iteration 17840 (1.35629 iter/s, 29.4922s/40 iters), loss = 1.26732
I1028 22:27:45.443815 12802 solver.cpp:241]     Train net output #0: loss = 1.26732 (* 1 = 1.26732 loss)
I1028 22:27:45.443828 12802 sgd_solver.cpp:105] Iteration 17840, lr = 0.00200744
I1028 22:28:14.979403 12802 solver.cpp:222] Iteration 17880 (1.35433 iter/s, 29.5349s/40 iters), loss = 1.5154
I1028 22:28:14.979642 12802 solver.cpp:241]     Train net output #0: loss = 1.5154 (* 1 = 1.5154 loss)
I1028 22:28:14.979660 12802 sgd_solver.cpp:105] Iteration 17880, lr = 0.00200022
I1028 22:28:44.615149 12802 solver.cpp:222] Iteration 17920 (1.34976 iter/s, 29.6348s/40 iters), loss = 1.3294
I1028 22:28:44.615207 12802 solver.cpp:241]     Train net output #0: loss = 1.3294 (* 1 = 1.3294 loss)
I1028 22:28:44.615224 12802 sgd_solver.cpp:105] Iteration 17920, lr = 0.00199303
I1028 22:29:14.173599 12802 solver.cpp:222] Iteration 17960 (1.35329 iter/s, 29.5577s/40 iters), loss = 1.77128
I1028 22:29:14.173750 12802 solver.cpp:241]     Train net output #0: loss = 1.77128 (* 1 = 1.77128 loss)
I1028 22:29:14.173764 12802 sgd_solver.cpp:105] Iteration 17960, lr = 0.00198587
I1028 22:29:43.048869 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_18000.caffemodel
I1028 22:29:43.191745 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_18000.solverstate
I1028 22:29:43.305111 12802 solver.cpp:334] Iteration 18000, Testing net (#0)
I1028 22:30:14.569141 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57248
I1028 22:30:14.569314 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79792
I1028 22:30:14.569334 12802 solver.cpp:401]     Test net output #2: loss = 1.91626 (* 1 = 1.91626 loss)
I1028 22:30:15.326172 12802 solver.cpp:222] Iteration 18000 (0.654119 iter/s, 61.151s/40 iters), loss = 1.64544
I1028 22:30:15.326236 12802 solver.cpp:241]     Train net output #0: loss = 1.64544 (* 1 = 1.64544 loss)
I1028 22:30:15.326251 12802 sgd_solver.cpp:105] Iteration 18000, lr = 0.00197874
I1028 22:30:44.896036 12802 solver.cpp:222] Iteration 18040 (1.35276 iter/s, 29.5691s/40 iters), loss = 1.40056
I1028 22:30:44.896163 12802 solver.cpp:241]     Train net output #0: loss = 1.40056 (* 1 = 1.40056 loss)
I1028 22:30:44.896180 12802 sgd_solver.cpp:105] Iteration 18040, lr = 0.00197162
I1028 22:31:14.528401 12802 solver.cpp:222] Iteration 18080 (1.34991 iter/s, 29.6315s/40 iters), loss = 1.89722
I1028 22:31:14.528457 12802 solver.cpp:241]     Train net output #0: loss = 1.89722 (* 1 = 1.89722 loss)
I1028 22:31:14.528472 12802 sgd_solver.cpp:105] Iteration 18080, lr = 0.00196454
I1028 22:31:44.324846 12802 solver.cpp:222] Iteration 18120 (1.34248 iter/s, 29.7957s/40 iters), loss = 1.53798
I1028 22:31:44.325008 12802 solver.cpp:241]     Train net output #0: loss = 1.53798 (* 1 = 1.53798 loss)
I1028 22:31:44.325026 12802 sgd_solver.cpp:105] Iteration 18120, lr = 0.00195748
I1028 22:32:13.917453 12802 solver.cpp:222] Iteration 18160 (1.35173 iter/s, 29.5917s/40 iters), loss = 1.57135
I1028 22:32:13.917507 12802 solver.cpp:241]     Train net output #0: loss = 1.57135 (* 1 = 1.57135 loss)
I1028 22:32:13.917522 12802 sgd_solver.cpp:105] Iteration 18160, lr = 0.00195044
I1028 22:32:43.602772 12802 solver.cpp:222] Iteration 18200 (1.3475 iter/s, 29.6845s/40 iters), loss = 1.64373
I1028 22:32:43.602936 12802 solver.cpp:241]     Train net output #0: loss = 1.64373 (* 1 = 1.64373 loss)
I1028 22:32:43.602951 12802 sgd_solver.cpp:105] Iteration 18200, lr = 0.00194343
I1028 22:33:13.146031 12802 solver.cpp:222] Iteration 18240 (1.35399 iter/s, 29.5424s/40 iters), loss = 1.47222
I1028 22:33:13.146088 12802 solver.cpp:241]     Train net output #0: loss = 1.47222 (* 1 = 1.47222 loss)
I1028 22:33:13.146104 12802 sgd_solver.cpp:105] Iteration 18240, lr = 0.00193645
I1028 22:33:43.442698 12802 solver.cpp:222] Iteration 18280 (1.32031 iter/s, 30.2959s/40 iters), loss = 1.43956
I1028 22:33:43.443053 12802 solver.cpp:241]     Train net output #0: loss = 1.43956 (* 1 = 1.43956 loss)
I1028 22:33:43.443097 12802 sgd_solver.cpp:105] Iteration 18280, lr = 0.00192949
I1028 22:34:14.135315 12802 solver.cpp:222] Iteration 18320 (1.30329 iter/s, 30.6916s/40 iters), loss = 1.86297
I1028 22:34:14.135524 12802 solver.cpp:241]     Train net output #0: loss = 1.86297 (* 1 = 1.86297 loss)
I1028 22:34:14.135537 12802 sgd_solver.cpp:105] Iteration 18320, lr = 0.00192256
I1028 22:34:44.685282 12802 solver.cpp:222] Iteration 18360 (1.30937 iter/s, 30.549s/40 iters), loss = 1.49519
I1028 22:34:44.685492 12802 solver.cpp:241]     Train net output #0: loss = 1.49519 (* 1 = 1.49519 loss)
I1028 22:34:44.685509 12802 sgd_solver.cpp:105] Iteration 18360, lr = 0.00191565
I1028 22:35:15.075551 12802 solver.cpp:222] Iteration 18400 (1.31625 iter/s, 30.3893s/40 iters), loss = 1.62453
I1028 22:35:15.075744 12802 solver.cpp:241]     Train net output #0: loss = 1.62453 (* 1 = 1.62453 loss)
I1028 22:35:15.075762 12802 sgd_solver.cpp:105] Iteration 18400, lr = 0.00190876
I1028 22:35:45.551798 12802 solver.cpp:222] Iteration 18440 (1.31254 iter/s, 30.4753s/40 iters), loss = 1.44393
I1028 22:35:45.552003 12802 solver.cpp:241]     Train net output #0: loss = 1.44393 (* 1 = 1.44393 loss)
I1028 22:35:45.552019 12802 sgd_solver.cpp:105] Iteration 18440, lr = 0.0019019
I1028 22:36:16.073498 12802 solver.cpp:222] Iteration 18480 (1.31058 iter/s, 30.5208s/40 iters), loss = 1.69402
I1028 22:36:16.073683 12802 solver.cpp:241]     Train net output #0: loss = 1.69402 (* 1 = 1.69402 loss)
I1028 22:36:16.073696 12802 sgd_solver.cpp:105] Iteration 18480, lr = 0.00189507
I1028 22:36:30.527727 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_18500.caffemodel
I1028 22:36:30.671705 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_18500.solverstate
I1028 22:36:30.784306 12802 solver.cpp:334] Iteration 18500, Testing net (#0)
I1028 22:37:01.912359 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1028 22:37:02.126956 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5728
I1028 22:37:02.127005 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.805359
I1028 22:37:02.127017 12802 solver.cpp:401]     Test net output #2: loss = 1.90025 (* 1 = 1.90025 loss)
I1028 22:37:18.317905 12802 solver.cpp:222] Iteration 18520 (0.642645 iter/s, 62.2428s/40 iters), loss = 1.65821
I1028 22:37:18.317982 12802 solver.cpp:241]     Train net output #0: loss = 1.65821 (* 1 = 1.65821 loss)
I1028 22:37:18.317999 12802 sgd_solver.cpp:105] Iteration 18520, lr = 0.00188826
I1028 22:37:48.778554 12802 solver.cpp:222] Iteration 18560 (1.3132 iter/s, 30.4598s/40 iters), loss = 1.57895
I1028 22:37:48.778758 12802 solver.cpp:241]     Train net output #0: loss = 1.57895 (* 1 = 1.57895 loss)
I1028 22:37:48.778774 12802 sgd_solver.cpp:105] Iteration 18560, lr = 0.00188147
I1028 22:38:17.900990 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1028 22:38:19.117494 12802 solver.cpp:222] Iteration 18600 (1.31848 iter/s, 30.338s/40 iters), loss = 1.82744
I1028 22:38:19.117676 12802 solver.cpp:241]     Train net output #0: loss = 1.82744 (* 1 = 1.82744 loss)
I1028 22:38:19.117692 12802 sgd_solver.cpp:105] Iteration 18600, lr = 0.00187471
I1028 22:38:49.754602 12802 solver.cpp:222] Iteration 18640 (1.30564 iter/s, 30.6362s/40 iters), loss = 1.79801
I1028 22:38:49.754797 12802 solver.cpp:241]     Train net output #0: loss = 1.79801 (* 1 = 1.79801 loss)
I1028 22:38:49.754814 12802 sgd_solver.cpp:105] Iteration 18640, lr = 0.00186797
I1028 22:39:20.213137 12802 solver.cpp:222] Iteration 18680 (1.3133 iter/s, 30.4576s/40 iters), loss = 1.31884
I1028 22:39:20.213342 12802 solver.cpp:241]     Train net output #0: loss = 1.31884 (* 1 = 1.31884 loss)
I1028 22:39:20.213356 12802 sgd_solver.cpp:105] Iteration 18680, lr = 0.00186126
I1028 22:39:50.492244 12802 solver.cpp:222] Iteration 18720 (1.32108 iter/s, 30.2782s/40 iters), loss = 1.45167
I1028 22:39:50.492563 12802 solver.cpp:241]     Train net output #0: loss = 1.45167 (* 1 = 1.45167 loss)
I1028 22:39:50.492616 12802 sgd_solver.cpp:105] Iteration 18720, lr = 0.00185457
I1028 22:40:20.634290 12802 solver.cpp:222] Iteration 18760 (1.32709 iter/s, 30.141s/40 iters), loss = 1.23568
I1028 22:40:20.634501 12802 solver.cpp:241]     Train net output #0: loss = 1.23568 (* 1 = 1.23568 loss)
I1028 22:40:20.634518 12802 sgd_solver.cpp:105] Iteration 18760, lr = 0.0018479
I1028 22:40:50.734378 12802 solver.cpp:222] Iteration 18800 (1.32894 iter/s, 30.0992s/40 iters), loss = 1.05431
I1028 22:40:50.734578 12802 solver.cpp:241]     Train net output #0: loss = 1.05431 (* 1 = 1.05431 loss)
I1028 22:40:50.734592 12802 sgd_solver.cpp:105] Iteration 18800, lr = 0.00184126
I1028 22:41:21.114929 12802 solver.cpp:222] Iteration 18840 (1.31667 iter/s, 30.3796s/40 iters), loss = 1.29208
I1028 22:41:21.115124 12802 solver.cpp:241]     Train net output #0: loss = 1.29208 (* 1 = 1.29208 loss)
I1028 22:41:21.115141 12802 sgd_solver.cpp:105] Iteration 18840, lr = 0.00183465
I1028 22:41:51.395655 12802 solver.cpp:222] Iteration 18880 (1.32101 iter/s, 30.2798s/40 iters), loss = 1.67695
I1028 22:41:51.395839 12802 solver.cpp:241]     Train net output #0: loss = 1.67695 (* 1 = 1.67695 loss)
I1028 22:41:51.395860 12802 sgd_solver.cpp:105] Iteration 18880, lr = 0.00182805
I1028 22:42:21.595849 12802 solver.cpp:222] Iteration 18920 (1.32453 iter/s, 30.1993s/40 iters), loss = 1.44138
I1028 22:42:21.596016 12802 solver.cpp:241]     Train net output #0: loss = 1.44138 (* 1 = 1.44138 loss)
I1028 22:42:21.596034 12802 sgd_solver.cpp:105] Iteration 18920, lr = 0.00182148
I1028 22:42:52.052337 12802 solver.cpp:222] Iteration 18960 (1.31339 iter/s, 30.4556s/40 iters), loss = 1.75677
I1028 22:42:52.052541 12802 solver.cpp:241]     Train net output #0: loss = 1.75677 (* 1 = 1.75677 loss)
I1028 22:42:52.052557 12802 sgd_solver.cpp:105] Iteration 18960, lr = 0.00181494
I1028 22:43:21.826218 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_19000.caffemodel
I1028 22:43:21.972491 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_19000.solverstate
I1028 22:43:22.542220 12802 solver.cpp:334] Iteration 19000, Testing net (#0)
I1028 22:43:53.898525 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57592
I1028 22:43:53.898676 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.800679
I1028 22:43:53.898689 12802 solver.cpp:401]     Test net output #2: loss = 1.88766 (* 1 = 1.88766 loss)
I1028 22:43:54.648895 12802 solver.cpp:222] Iteration 19000 (0.63903 iter/s, 62.5949s/40 iters), loss = 1.55086
I1028 22:43:54.648957 12802 solver.cpp:241]     Train net output #0: loss = 1.55086 (* 1 = 1.55086 loss)
I1028 22:43:54.648972 12802 sgd_solver.cpp:105] Iteration 19000, lr = 0.00180842
I1028 22:44:24.796334 12802 solver.cpp:222] Iteration 19040 (1.32685 iter/s, 30.1466s/40 iters), loss = 1.49845
I1028 22:44:24.796528 12802 solver.cpp:241]     Train net output #0: loss = 1.49845 (* 1 = 1.49845 loss)
I1028 22:44:24.796543 12802 sgd_solver.cpp:105] Iteration 19040, lr = 0.00180192
I1028 22:44:54.868472 12802 solver.cpp:222] Iteration 19080 (1.33018 iter/s, 30.0712s/40 iters), loss = 1.50275
I1028 22:44:54.868643 12802 solver.cpp:241]     Train net output #0: loss = 1.50275 (* 1 = 1.50275 loss)
I1028 22:44:54.868659 12802 sgd_solver.cpp:105] Iteration 19080, lr = 0.00179544
I1028 22:45:25.074820 12802 solver.cpp:222] Iteration 19120 (1.32426 iter/s, 30.2055s/40 iters), loss = 1.40956
I1028 22:45:25.075234 12802 solver.cpp:241]     Train net output #0: loss = 1.40956 (* 1 = 1.40956 loss)
I1028 22:45:25.075251 12802 sgd_solver.cpp:105] Iteration 19120, lr = 0.00178899
I1028 22:45:55.350662 12802 solver.cpp:222] Iteration 19160 (1.32123 iter/s, 30.2747s/40 iters), loss = 1.29439
I1028 22:45:55.350884 12802 solver.cpp:241]     Train net output #0: loss = 1.29439 (* 1 = 1.29439 loss)
I1028 22:45:55.350903 12802 sgd_solver.cpp:105] Iteration 19160, lr = 0.00178256
I1028 22:46:25.812085 12802 solver.cpp:222] Iteration 19200 (1.31318 iter/s, 30.4605s/40 iters), loss = 1.50959
I1028 22:46:25.812305 12802 solver.cpp:241]     Train net output #0: loss = 1.50959 (* 1 = 1.50959 loss)
I1028 22:46:25.812324 12802 sgd_solver.cpp:105] Iteration 19200, lr = 0.00177615
I1028 22:46:55.695129 12802 solver.cpp:222] Iteration 19240 (1.33859 iter/s, 29.8821s/40 iters), loss = 1.4706
I1028 22:46:55.695192 12802 solver.cpp:241]     Train net output #0: loss = 1.4706 (* 1 = 1.4706 loss)
I1028 22:46:55.695209 12802 sgd_solver.cpp:105] Iteration 19240, lr = 0.00176977
I1028 22:47:25.427295 12802 solver.cpp:222] Iteration 19280 (1.34538 iter/s, 29.7314s/40 iters), loss = 1.61764
I1028 22:47:25.427491 12802 solver.cpp:241]     Train net output #0: loss = 1.61764 (* 1 = 1.61764 loss)
I1028 22:47:25.427508 12802 sgd_solver.cpp:105] Iteration 19280, lr = 0.00176341
I1028 22:47:55.315554 12802 solver.cpp:222] Iteration 19320 (1.33836 iter/s, 29.8873s/40 iters), loss = 1.34381
I1028 22:47:55.315614 12802 solver.cpp:241]     Train net output #0: loss = 1.34381 (* 1 = 1.34381 loss)
I1028 22:47:55.315629 12802 sgd_solver.cpp:105] Iteration 19320, lr = 0.00175707
I1028 22:49:25.431807 12802 solver.cpp:222] Iteration 19360 (0.443882 iter/s, 90.1141s/40 iters), loss = 1.57806
I1028 22:49:25.432018 12802 solver.cpp:241]     Train net output #0: loss = 1.57806 (* 1 = 1.57806 loss)
I1028 22:49:25.432041 12802 sgd_solver.cpp:105] Iteration 19360, lr = 0.00175076
I1028 22:50:02.425566 12802 solver.cpp:222] Iteration 19400 (1.08129 iter/s, 36.9927s/40 iters), loss = 1.36561
I1028 22:50:02.425758 12802 solver.cpp:241]     Train net output #0: loss = 1.36561 (* 1 = 1.36561 loss)
I1028 22:50:02.425776 12802 sgd_solver.cpp:105] Iteration 19400, lr = 0.00174447
I1028 22:50:32.612351 12802 solver.cpp:222] Iteration 19440 (1.32512 iter/s, 30.1859s/40 iters), loss = 1.54631
I1028 22:50:32.612534 12802 solver.cpp:241]     Train net output #0: loss = 1.54631 (* 1 = 1.54631 loss)
I1028 22:50:32.612550 12802 sgd_solver.cpp:105] Iteration 19440, lr = 0.0017382
I1028 22:51:03.242007 12802 solver.cpp:222] Iteration 19480 (1.30596 iter/s, 30.6288s/40 iters), loss = 1.43296
I1028 22:51:03.242200 12802 solver.cpp:241]     Train net output #0: loss = 1.43296 (* 1 = 1.43296 loss)
I1028 22:51:03.242214 12802 sgd_solver.cpp:105] Iteration 19480, lr = 0.00173195
I1028 22:51:17.559257 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_19500.caffemodel
I1028 22:51:17.867658 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_19500.solverstate
I1028 22:51:17.982111 12802 solver.cpp:334] Iteration 19500, Testing net (#0)
I1028 22:51:49.144966 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1028 22:51:49.355499 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57164
I1028 22:51:49.355551 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.806599
I1028 22:51:49.355562 12802 solver.cpp:401]     Test net output #2: loss = 1.88805 (* 1 = 1.88805 loss)
I1028 22:52:05.201177 12802 solver.cpp:222] Iteration 19520 (0.645603 iter/s, 61.9575s/40 iters), loss = 1.33427
I1028 22:52:05.201237 12802 solver.cpp:241]     Train net output #0: loss = 1.33427 (* 1 = 1.33427 loss)
I1028 22:52:05.201252 12802 sgd_solver.cpp:105] Iteration 19520, lr = 0.00172572
I1028 22:52:35.029445 12802 solver.cpp:222] Iteration 19560 (1.34104 iter/s, 29.8275s/40 iters), loss = 1.42032
I1028 22:52:35.029652 12802 solver.cpp:241]     Train net output #0: loss = 1.42032 (* 1 = 1.42032 loss)
I1028 22:52:35.029670 12802 sgd_solver.cpp:105] Iteration 19560, lr = 0.00171952
I1028 22:53:05.283792 12802 solver.cpp:222] Iteration 19600 (1.32216 iter/s, 30.2534s/40 iters), loss = 1.30944
I1028 22:53:05.283948 12802 solver.cpp:241]     Train net output #0: loss = 1.30944 (* 1 = 1.30944 loss)
I1028 22:53:05.283965 12802 sgd_solver.cpp:105] Iteration 19600, lr = 0.00171334
I1028 22:53:35.588315 12802 solver.cpp:222] Iteration 19640 (1.31997 iter/s, 30.3036s/40 iters), loss = 1.48061
I1028 22:53:35.588436 12802 solver.cpp:241]     Train net output #0: loss = 1.48061 (* 1 = 1.48061 loss)
I1028 22:53:35.588470 12802 sgd_solver.cpp:105] Iteration 19640, lr = 0.00170719
I1028 22:54:05.070103 12802 solver.cpp:222] Iteration 19680 (1.35681 iter/s, 29.481s/40 iters), loss = 1.4621
I1028 22:54:05.070161 12802 solver.cpp:241]     Train net output #0: loss = 1.4621 (* 1 = 1.4621 loss)
I1028 22:54:05.070176 12802 sgd_solver.cpp:105] Iteration 19680, lr = 0.00170105
I1028 22:54:34.600047 12802 solver.cpp:222] Iteration 19720 (1.35459 iter/s, 29.5292s/40 iters), loss = 1.59439
I1028 22:54:34.600188 12802 solver.cpp:241]     Train net output #0: loss = 1.59439 (* 1 = 1.59439 loss)
I1028 22:54:34.600204 12802 sgd_solver.cpp:105] Iteration 19720, lr = 0.00169494
I1028 22:55:04.285382 12802 solver.cpp:222] Iteration 19760 (1.34751 iter/s, 29.6845s/40 iters), loss = 1.3971
I1028 22:55:04.285444 12802 solver.cpp:241]     Train net output #0: loss = 1.3971 (* 1 = 1.3971 loss)
I1028 22:55:04.285456 12802 sgd_solver.cpp:105] Iteration 19760, lr = 0.00168885
I1028 22:55:34.228639 12802 solver.cpp:222] Iteration 19800 (1.33589 iter/s, 29.9425s/40 iters), loss = 1.53622
I1028 22:55:34.228842 12802 solver.cpp:241]     Train net output #0: loss = 1.53622 (* 1 = 1.53622 loss)
I1028 22:55:34.228859 12802 sgd_solver.cpp:105] Iteration 19800, lr = 0.00168278
I1028 22:56:03.868131 12802 solver.cpp:222] Iteration 19840 (1.34959 iter/s, 29.6386s/40 iters), loss = 1.59649
I1028 22:56:03.868196 12802 solver.cpp:241]     Train net output #0: loss = 1.59649 (* 1 = 1.59649 loss)
I1028 22:56:03.868209 12802 sgd_solver.cpp:105] Iteration 19840, lr = 0.00167673
I1028 22:56:33.485944 12802 solver.cpp:222] Iteration 19880 (1.35057 iter/s, 29.617s/40 iters), loss = 1.35344
I1028 22:56:33.486114 12802 solver.cpp:241]     Train net output #0: loss = 1.35344 (* 1 = 1.35344 loss)
I1028 22:56:33.486132 12802 sgd_solver.cpp:105] Iteration 19880, lr = 0.0016707
I1028 22:57:03.127981 12802 solver.cpp:222] Iteration 19920 (1.34948 iter/s, 29.6411s/40 iters), loss = 1.3852
I1028 22:57:03.128043 12802 solver.cpp:241]     Train net output #0: loss = 1.3852 (* 1 = 1.3852 loss)
I1028 22:57:03.128059 12802 sgd_solver.cpp:105] Iteration 19920, lr = 0.0016647
I1028 22:57:32.809620 12802 solver.cpp:222] Iteration 19960 (1.34767 iter/s, 29.6809s/40 iters), loss = 1.67473
I1028 22:57:32.809777 12802 solver.cpp:241]     Train net output #0: loss = 1.67473 (* 1 = 1.67473 loss)
I1028 22:57:32.809794 12802 sgd_solver.cpp:105] Iteration 19960, lr = 0.00165872
I1028 22:58:01.717396 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_20000.caffemodel
I1028 22:58:01.863116 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_20000.solverstate
I1028 22:58:01.978395 12802 solver.cpp:334] Iteration 20000, Testing net (#0)
I1028 22:58:33.226840 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57364
I1028 22:58:33.226999 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80096
I1028 22:58:33.227011 12802 solver.cpp:401]     Test net output #2: loss = 1.89585 (* 1 = 1.89585 loss)
I1028 22:58:34.003823 12802 solver.cpp:222] Iteration 20000 (0.653674 iter/s, 61.1926s/40 iters), loss = 2.04757
I1028 22:58:34.003890 12802 solver.cpp:241]     Train net output #0: loss = 2.04757 (* 1 = 2.04757 loss)
I1028 22:58:34.003907 12802 sgd_solver.cpp:105] Iteration 20000, lr = 0.00165276
I1028 22:59:04.784423 12802 solver.cpp:222] Iteration 20040 (1.29955 iter/s, 30.7798s/40 iters), loss = 1.51382
I1028 22:59:04.784605 12802 solver.cpp:241]     Train net output #0: loss = 1.51382 (* 1 = 1.51382 loss)
I1028 22:59:04.784621 12802 sgd_solver.cpp:105] Iteration 20040, lr = 0.00164682
I1028 22:59:34.296979 12802 solver.cpp:222] Iteration 20080 (1.3554 iter/s, 29.5117s/40 iters), loss = 1.65675
I1028 22:59:34.297037 12802 solver.cpp:241]     Train net output #0: loss = 1.65675 (* 1 = 1.65675 loss)
I1028 22:59:34.297053 12802 sgd_solver.cpp:105] Iteration 20080, lr = 0.0016409
I1028 23:00:03.818428 12802 solver.cpp:222] Iteration 20120 (1.35498 iter/s, 29.5207s/40 iters), loss = 1.84163
I1028 23:00:03.818735 12802 solver.cpp:241]     Train net output #0: loss = 1.84163 (* 1 = 1.84163 loss)
I1028 23:00:03.818773 12802 sgd_solver.cpp:105] Iteration 20120, lr = 0.001635
I1028 23:00:33.374910 12802 solver.cpp:222] Iteration 20160 (1.35339 iter/s, 29.5555s/40 iters), loss = 1.33391
I1028 23:00:33.374970 12802 solver.cpp:241]     Train net output #0: loss = 1.33391 (* 1 = 1.33391 loss)
I1028 23:00:33.374986 12802 sgd_solver.cpp:105] Iteration 20160, lr = 0.00162912
I1028 23:01:03.401782 12802 solver.cpp:222] Iteration 20200 (1.33217 iter/s, 30.0261s/40 iters), loss = 1.84426
I1028 23:01:03.402055 12802 solver.cpp:241]     Train net output #0: loss = 1.84426 (* 1 = 1.84426 loss)
I1028 23:01:03.402071 12802 sgd_solver.cpp:105] Iteration 20200, lr = 0.00162327
I1028 23:01:33.055621 12802 solver.cpp:222] Iteration 20240 (1.34894 iter/s, 29.6529s/40 iters), loss = 1.55271
I1028 23:01:33.055680 12802 solver.cpp:241]     Train net output #0: loss = 1.55271 (* 1 = 1.55271 loss)
I1028 23:01:33.055694 12802 sgd_solver.cpp:105] Iteration 20240, lr = 0.00161744
I1028 23:02:03.185108 12802 solver.cpp:222] Iteration 20280 (1.32764 iter/s, 30.1287s/40 iters), loss = 1.25961
I1028 23:02:03.185279 12802 solver.cpp:241]     Train net output #0: loss = 1.25961 (* 1 = 1.25961 loss)
I1028 23:02:03.185297 12802 sgd_solver.cpp:105] Iteration 20280, lr = 0.00161162
I1028 23:02:33.655740 12802 solver.cpp:222] Iteration 20320 (1.31278 iter/s, 30.4697s/40 iters), loss = 1.72215
I1028 23:02:33.655959 12802 solver.cpp:241]     Train net output #0: loss = 1.72215 (* 1 = 1.72215 loss)
I1028 23:02:33.655982 12802 sgd_solver.cpp:105] Iteration 20320, lr = 0.00160583
I1028 23:03:04.365329 12802 solver.cpp:222] Iteration 20360 (1.30256 iter/s, 30.7086s/40 iters), loss = 1.39037
I1028 23:03:04.365530 12802 solver.cpp:241]     Train net output #0: loss = 1.39037 (* 1 = 1.39037 loss)
I1028 23:03:04.365543 12802 sgd_solver.cpp:105] Iteration 20360, lr = 0.00160006
I1028 23:03:34.987742 12802 solver.cpp:222] Iteration 20400 (1.30627 iter/s, 30.6215s/40 iters), loss = 1.3593
I1028 23:03:34.987933 12802 solver.cpp:241]     Train net output #0: loss = 1.3593 (* 1 = 1.3593 loss)
I1028 23:03:34.987951 12802 sgd_solver.cpp:105] Iteration 20400, lr = 0.00159431
I1028 23:04:13.302300 12802 solver.cpp:222] Iteration 20440 (1.04402 iter/s, 38.3134s/40 iters), loss = 1.53995
I1028 23:04:13.302520 12802 solver.cpp:241]     Train net output #0: loss = 1.53995 (* 1 = 1.53995 loss)
I1028 23:04:13.302543 12802 sgd_solver.cpp:105] Iteration 20440, lr = 0.00158858
I1028 23:04:47.090600 12802 solver.cpp:222] Iteration 20480 (1.18388 iter/s, 33.7873s/40 iters), loss = 1.43413
I1028 23:04:47.090803 12802 solver.cpp:241]     Train net output #0: loss = 1.43413 (* 1 = 1.43413 loss)
I1028 23:04:47.090821 12802 sgd_solver.cpp:105] Iteration 20480, lr = 0.00158287
I1028 23:05:02.082635 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_20500.caffemodel
I1028 23:05:02.230594 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_20500.solverstate
I1028 23:05:02.358541 12802 solver.cpp:334] Iteration 20500, Testing net (#0)
I1028 23:05:33.394604 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1028 23:05:33.602645 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57336
I1028 23:05:33.602696 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.807759
I1028 23:05:33.602707 12802 solver.cpp:401]     Test net output #2: loss = 1.90142 (* 1 = 1.90142 loss)
I1028 23:05:49.771317 12802 solver.cpp:222] Iteration 20520 (0.638172 iter/s, 62.6791s/40 iters), loss = 1.60571
I1028 23:05:49.771383 12802 solver.cpp:241]     Train net output #0: loss = 1.60571 (* 1 = 1.60571 loss)
I1028 23:05:49.771399 12802 sgd_solver.cpp:105] Iteration 20520, lr = 0.00157718
I1028 23:06:21.375425 12802 solver.cpp:222] Iteration 20560 (1.26569 iter/s, 31.6033s/40 iters), loss = 1.58382
I1028 23:06:21.375658 12802 solver.cpp:241]     Train net output #0: loss = 1.58382 (* 1 = 1.58382 loss)
I1028 23:06:21.375677 12802 sgd_solver.cpp:105] Iteration 20560, lr = 0.00157151
I1028 23:06:51.887203 12802 solver.cpp:222] Iteration 20600 (1.31101 iter/s, 30.5108s/40 iters), loss = 1.50128
I1028 23:06:51.887347 12802 solver.cpp:241]     Train net output #0: loss = 1.50128 (* 1 = 1.50128 loss)
I1028 23:06:51.887365 12802 sgd_solver.cpp:105] Iteration 20600, lr = 0.00156587
I1028 23:07:22.048995 12802 solver.cpp:222] Iteration 20640 (1.32622 iter/s, 30.1609s/40 iters), loss = 1.57527
I1028 23:07:22.049183 12802 solver.cpp:241]     Train net output #0: loss = 1.57527 (* 1 = 1.57527 loss)
I1028 23:07:22.049201 12802 sgd_solver.cpp:105] Iteration 20640, lr = 0.00156024
I1028 23:07:51.826815 12802 solver.cpp:222] Iteration 20680 (1.34332 iter/s, 29.7769s/40 iters), loss = 1.47051
I1028 23:07:51.826879 12802 solver.cpp:241]     Train net output #0: loss = 1.47051 (* 1 = 1.47051 loss)
I1028 23:07:51.826894 12802 sgd_solver.cpp:105] Iteration 20680, lr = 0.00155463
I1028 23:08:22.512044 12802 solver.cpp:222] Iteration 20720 (1.30359 iter/s, 30.6844s/40 iters), loss = 1.78385
I1028 23:08:22.512260 12802 solver.cpp:241]     Train net output #0: loss = 1.78385 (* 1 = 1.78385 loss)
I1028 23:08:22.512279 12802 sgd_solver.cpp:105] Iteration 20720, lr = 0.00154905
I1028 23:08:52.395026 12802 solver.cpp:222] Iteration 20760 (1.3386 iter/s, 29.8821s/40 iters), loss = 1.86383
I1028 23:08:52.395087 12802 solver.cpp:241]     Train net output #0: loss = 1.86383 (* 1 = 1.86383 loss)
I1028 23:08:52.395107 12802 sgd_solver.cpp:105] Iteration 20760, lr = 0.00154348
I1028 23:09:22.102339 12802 solver.cpp:222] Iteration 20800 (1.3465 iter/s, 29.7065s/40 iters), loss = 1.4959
I1028 23:09:22.102568 12802 solver.cpp:241]     Train net output #0: loss = 1.4959 (* 1 = 1.4959 loss)
I1028 23:09:22.102586 12802 sgd_solver.cpp:105] Iteration 20800, lr = 0.00153793
I1028 23:09:51.843299 12802 solver.cpp:222] Iteration 20840 (1.34499 iter/s, 29.74s/40 iters), loss = 1.42609
I1028 23:09:51.843359 12802 solver.cpp:241]     Train net output #0: loss = 1.42609 (* 1 = 1.42609 loss)
I1028 23:09:51.843375 12802 sgd_solver.cpp:105] Iteration 20840, lr = 0.0015324
I1028 23:10:21.676671 12802 solver.cpp:222] Iteration 20880 (1.34081 iter/s, 29.8326s/40 iters), loss = 1.42328
I1028 23:10:21.676889 12802 solver.cpp:241]     Train net output #0: loss = 1.42328 (* 1 = 1.42328 loss)
I1028 23:10:21.676906 12802 sgd_solver.cpp:105] Iteration 20880, lr = 0.0015269
I1028 23:10:51.446425 12802 solver.cpp:222] Iteration 20920 (1.34369 iter/s, 29.7688s/40 iters), loss = 1.61667
I1028 23:10:51.446487 12802 solver.cpp:241]     Train net output #0: loss = 1.61667 (* 1 = 1.61667 loss)
I1028 23:10:51.446502 12802 sgd_solver.cpp:105] Iteration 20920, lr = 0.00152141
I1028 23:11:21.103808 12802 solver.cpp:222] Iteration 20960 (1.34877 iter/s, 29.6566s/40 iters), loss = 1.58345
I1028 23:11:21.104183 12802 solver.cpp:241]     Train net output #0: loss = 1.58345 (* 1 = 1.58345 loss)
I1028 23:11:21.104200 12802 sgd_solver.cpp:105] Iteration 20960, lr = 0.00151594
I1028 23:11:50.230856 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_21000.caffemodel
I1028 23:11:50.383188 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_21000.solverstate
I1028 23:11:50.499091 12802 solver.cpp:334] Iteration 21000, Testing net (#0)
I1028 23:12:21.886168 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57696
I1028 23:12:21.886327 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80264
I1028 23:12:21.886342 12802 solver.cpp:401]     Test net output #2: loss = 1.87188 (* 1 = 1.87188 loss)
I1028 23:12:22.645272 12802 solver.cpp:222] Iteration 21000 (0.649988 iter/s, 61.5396s/40 iters), loss = 1.87349
I1028 23:12:22.645329 12802 solver.cpp:241]     Train net output #0: loss = 1.87349 (* 1 = 1.87349 loss)
I1028 23:12:22.645345 12802 sgd_solver.cpp:105] Iteration 21000, lr = 0.00151049
I1028 23:12:52.514240 12802 solver.cpp:222] Iteration 21040 (1.33922 iter/s, 29.8682s/40 iters), loss = 1.51554
I1028 23:12:52.514432 12802 solver.cpp:241]     Train net output #0: loss = 1.51554 (* 1 = 1.51554 loss)
I1028 23:12:52.514451 12802 sgd_solver.cpp:105] Iteration 21040, lr = 0.00150507
I1028 23:13:22.074421 12802 solver.cpp:222] Iteration 21080 (1.35321 iter/s, 29.5593s/40 iters), loss = 1.42894
I1028 23:13:22.074481 12802 solver.cpp:241]     Train net output #0: loss = 1.42894 (* 1 = 1.42894 loss)
I1028 23:13:22.074493 12802 sgd_solver.cpp:105] Iteration 21080, lr = 0.00149966
I1028 23:15:05.450172 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1028 23:15:27.426103 12802 solver.cpp:222] Iteration 21120 (0.31911 iter/s, 125.349s/40 iters), loss = 1.25429
I1028 23:15:27.426165 12802 solver.cpp:241]     Train net output #0: loss = 1.25429 (* 1 = 1.25429 loss)
I1028 23:15:27.426182 12802 sgd_solver.cpp:105] Iteration 21120, lr = 0.00149427
I1028 23:16:55.320395 12802 solver.cpp:222] Iteration 21160 (0.455103 iter/s, 87.8923s/40 iters), loss = 1.65561
I1028 23:16:55.320569 12802 solver.cpp:241]     Train net output #0: loss = 1.65561 (* 1 = 1.65561 loss)
I1028 23:16:55.320587 12802 sgd_solver.cpp:105] Iteration 21160, lr = 0.0014889
I1028 23:17:29.092831 12802 solver.cpp:222] Iteration 21200 (1.18443 iter/s, 33.7715s/40 iters), loss = 1.62576
I1028 23:17:29.092989 12802 solver.cpp:241]     Train net output #0: loss = 1.62576 (* 1 = 1.62576 loss)
I1028 23:17:29.093006 12802 sgd_solver.cpp:105] Iteration 21200, lr = 0.00148355
I1028 23:17:59.811949 12802 solver.cpp:222] Iteration 21240 (1.30216 iter/s, 30.7183s/40 iters), loss = 1.28983
I1028 23:17:59.812116 12802 solver.cpp:241]     Train net output #0: loss = 1.28983 (* 1 = 1.28983 loss)
I1028 23:17:59.812134 12802 sgd_solver.cpp:105] Iteration 21240, lr = 0.00147821
I1028 23:18:30.094866 12802 solver.cpp:222] Iteration 21280 (1.32091 iter/s, 30.282s/40 iters), loss = 1.48487
I1028 23:18:30.095062 12802 solver.cpp:241]     Train net output #0: loss = 1.48487 (* 1 = 1.48487 loss)
I1028 23:18:30.095079 12802 sgd_solver.cpp:105] Iteration 21280, lr = 0.0014729
I1028 23:19:01.318063 12802 solver.cpp:222] Iteration 21320 (1.28114 iter/s, 31.2223s/40 iters), loss = 1.45541
I1028 23:19:01.318272 12802 solver.cpp:241]     Train net output #0: loss = 1.45541 (* 1 = 1.45541 loss)
I1028 23:19:01.318298 12802 sgd_solver.cpp:105] Iteration 21320, lr = 0.00146761
I1028 23:19:31.711295 12802 solver.cpp:222] Iteration 21360 (1.31612 iter/s, 30.3923s/40 iters), loss = 1.28126
I1028 23:19:31.711489 12802 solver.cpp:241]     Train net output #0: loss = 1.28126 (* 1 = 1.28126 loss)
I1028 23:19:31.711506 12802 sgd_solver.cpp:105] Iteration 21360, lr = 0.00146233
I1028 23:20:02.058589 12802 solver.cpp:222] Iteration 21400 (1.31811 iter/s, 30.3464s/40 iters), loss = 1.24498
I1028 23:20:02.058770 12802 solver.cpp:241]     Train net output #0: loss = 1.24498 (* 1 = 1.24498 loss)
I1028 23:20:02.058786 12802 sgd_solver.cpp:105] Iteration 21400, lr = 0.00145708
I1028 23:20:31.931820 12802 solver.cpp:222] Iteration 21440 (1.33903 iter/s, 29.8723s/40 iters), loss = 1.44298
I1028 23:20:31.931882 12802 solver.cpp:241]     Train net output #0: loss = 1.44298 (* 1 = 1.44298 loss)
I1028 23:20:31.931897 12802 sgd_solver.cpp:105] Iteration 21440, lr = 0.00145184
I1028 23:21:01.814404 12802 solver.cpp:222] Iteration 21480 (1.33861 iter/s, 29.8818s/40 iters), loss = 1.69133
I1028 23:21:01.814609 12802 solver.cpp:241]     Train net output #0: loss = 1.69133 (* 1 = 1.69133 loss)
I1028 23:21:01.814626 12802 sgd_solver.cpp:105] Iteration 21480, lr = 0.00144663
I1028 23:21:15.995090 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_21500.caffemodel
I1028 23:21:16.148213 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_21500.solverstate
I1028 23:21:16.261868 12802 solver.cpp:334] Iteration 21500, Testing net (#0)
I1028 23:21:47.368332 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1028 23:21:47.576112 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.570599
I1028 23:21:47.576156 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.805679
I1028 23:21:47.576167 12802 solver.cpp:401]     Test net output #2: loss = 1.90604 (* 1 = 1.90604 loss)
I1028 23:22:03.272878 12802 solver.cpp:222] Iteration 21520 (0.650863 iter/s, 61.4568s/40 iters), loss = 1.49571
I1028 23:22:03.272944 12802 solver.cpp:241]     Train net output #0: loss = 1.49571 (* 1 = 1.49571 loss)
I1028 23:22:03.272961 12802 sgd_solver.cpp:105] Iteration 21520, lr = 0.00144143
I1028 23:22:32.928124 12802 solver.cpp:222] Iteration 21560 (1.34887 iter/s, 29.6545s/40 iters), loss = 1.3615
I1028 23:22:32.928321 12802 solver.cpp:241]     Train net output #0: loss = 1.3615 (* 1 = 1.3615 loss)
I1028 23:22:32.928339 12802 sgd_solver.cpp:105] Iteration 21560, lr = 0.00143625
I1028 23:23:02.605265 12802 solver.cpp:222] Iteration 21600 (1.34788 iter/s, 29.6762s/40 iters), loss = 1.45045
I1028 23:23:02.605322 12802 solver.cpp:241]     Train net output #0: loss = 1.45045 (* 1 = 1.45045 loss)
I1028 23:23:02.605337 12802 sgd_solver.cpp:105] Iteration 21600, lr = 0.00143108
I1028 23:23:32.241014 12802 solver.cpp:222] Iteration 21640 (1.34976 iter/s, 29.635s/40 iters), loss = 1.37211
I1028 23:23:32.241225 12802 solver.cpp:241]     Train net output #0: loss = 1.37211 (* 1 = 1.37211 loss)
I1028 23:23:32.241241 12802 sgd_solver.cpp:105] Iteration 21640, lr = 0.00142594
I1028 23:24:01.978219 12802 solver.cpp:222] Iteration 21680 (1.34516 iter/s, 29.7363s/40 iters), loss = 1.3088
I1028 23:24:01.978283 12802 solver.cpp:241]     Train net output #0: loss = 1.3088 (* 1 = 1.3088 loss)
I1028 23:24:01.978299 12802 sgd_solver.cpp:105] Iteration 21680, lr = 0.00142082
I1028 23:24:31.717881 12802 solver.cpp:222] Iteration 21720 (1.34504 iter/s, 29.7389s/40 iters), loss = 1.49312
I1028 23:24:31.718070 12802 solver.cpp:241]     Train net output #0: loss = 1.49312 (* 1 = 1.49312 loss)
I1028 23:24:31.718086 12802 sgd_solver.cpp:105] Iteration 21720, lr = 0.00141571
I1028 23:25:01.550174 12802 solver.cpp:222] Iteration 21760 (1.34087 iter/s, 29.8314s/40 iters), loss = 1.24099
I1028 23:25:01.550227 12802 solver.cpp:241]     Train net output #0: loss = 1.24099 (* 1 = 1.24099 loss)
I1028 23:25:01.550242 12802 sgd_solver.cpp:105] Iteration 21760, lr = 0.00141062
I1028 23:25:32.516404 12802 solver.cpp:222] Iteration 21800 (1.29176 iter/s, 30.9654s/40 iters), loss = 1.16095
I1028 23:25:32.516600 12802 solver.cpp:241]     Train net output #0: loss = 1.16095 (* 1 = 1.16095 loss)
I1028 23:25:32.516618 12802 sgd_solver.cpp:105] Iteration 21800, lr = 0.00140555
I1028 23:26:02.223809 12802 solver.cpp:222] Iteration 21840 (1.34651 iter/s, 29.7065s/40 iters), loss = 1.28837
I1028 23:26:02.223870 12802 solver.cpp:241]     Train net output #0: loss = 1.28837 (* 1 = 1.28837 loss)
I1028 23:26:02.223886 12802 sgd_solver.cpp:105] Iteration 21840, lr = 0.0014005
I1028 23:26:31.639127 12802 solver.cpp:222] Iteration 21880 (1.35987 iter/s, 29.4146s/40 iters), loss = 1.4262
I1028 23:26:31.639309 12802 solver.cpp:241]     Train net output #0: loss = 1.4262 (* 1 = 1.4262 loss)
I1028 23:26:31.639323 12802 sgd_solver.cpp:105] Iteration 21880, lr = 0.00139547
I1028 23:27:01.059087 12802 solver.cpp:222] Iteration 21920 (1.35966 iter/s, 29.4191s/40 iters), loss = 1.57162
I1028 23:27:01.059144 12802 solver.cpp:241]     Train net output #0: loss = 1.57162 (* 1 = 1.57162 loss)
I1028 23:27:01.059161 12802 sgd_solver.cpp:105] Iteration 21920, lr = 0.00139045
I1028 23:27:30.435248 12802 solver.cpp:222] Iteration 21960 (1.36168 iter/s, 29.3754s/40 iters), loss = 1.41992
I1028 23:27:30.435396 12802 solver.cpp:241]     Train net output #0: loss = 1.41992 (* 1 = 1.41992 loss)
I1028 23:27:30.435413 12802 sgd_solver.cpp:105] Iteration 21960, lr = 0.00138546
I1028 23:27:59.103201 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_22000.caffemodel
I1028 23:27:59.243430 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_22000.solverstate
I1028 23:27:59.357100 12802 solver.cpp:334] Iteration 22000, Testing net (#0)
I1028 23:28:30.577250 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57756
I1028 23:28:30.577383 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80232
I1028 23:28:30.577426 12802 solver.cpp:401]     Test net output #2: loss = 1.88528 (* 1 = 1.88528 loss)
I1028 23:28:31.329843 12802 solver.cpp:222] Iteration 22000 (0.65689 iter/s, 60.893s/40 iters), loss = 1.22862
I1028 23:28:31.329898 12802 solver.cpp:241]     Train net output #0: loss = 1.22862 (* 1 = 1.22862 loss)
I1028 23:28:31.329913 12802 sgd_solver.cpp:105] Iteration 22000, lr = 0.00138048
I1028 23:29:00.851307 12802 solver.cpp:222] Iteration 22040 (1.35498 iter/s, 29.5207s/40 iters), loss = 1.76315
I1028 23:29:00.851478 12802 solver.cpp:241]     Train net output #0: loss = 1.76315 (* 1 = 1.76315 loss)
I1028 23:29:00.851493 12802 sgd_solver.cpp:105] Iteration 22040, lr = 0.00137552
I1028 23:29:30.362766 12802 solver.cpp:222] Iteration 22080 (1.35545 iter/s, 29.5106s/40 iters), loss = 1.47841
I1028 23:29:30.362823 12802 solver.cpp:241]     Train net output #0: loss = 1.47841 (* 1 = 1.47841 loss)
I1028 23:29:30.362840 12802 sgd_solver.cpp:105] Iteration 22080, lr = 0.00137057
I1028 23:30:00.131793 12802 solver.cpp:222] Iteration 22120 (1.34371 iter/s, 29.7683s/40 iters), loss = 1.52034
I1028 23:30:00.132009 12802 solver.cpp:241]     Train net output #0: loss = 1.52034 (* 1 = 1.52034 loss)
I1028 23:30:00.132030 12802 sgd_solver.cpp:105] Iteration 22120, lr = 0.00136565
I1028 23:31:27.101861 12802 solver.cpp:222] Iteration 22160 (0.45994 iter/s, 86.9678s/40 iters), loss = 1.35109
I1028 23:31:27.102089 12802 solver.cpp:241]     Train net output #0: loss = 1.35109 (* 1 = 1.35109 loss)
I1028 23:31:27.102108 12802 sgd_solver.cpp:105] Iteration 22160, lr = 0.00136074
I1028 23:31:59.188340 12802 solver.cpp:222] Iteration 22200 (1.24667 iter/s, 32.0855s/40 iters), loss = 1.43366
I1028 23:31:59.188508 12802 solver.cpp:241]     Train net output #0: loss = 1.43366 (* 1 = 1.43366 loss)
I1028 23:31:59.188527 12802 sgd_solver.cpp:105] Iteration 22200, lr = 0.00135585
I1028 23:32:46.550257 12802 solver.cpp:222] Iteration 22240 (0.844583 iter/s, 47.3607s/40 iters), loss = 1.51061
I1028 23:32:46.550477 12802 solver.cpp:241]     Train net output #0: loss = 1.51061 (* 1 = 1.51061 loss)
I1028 23:32:46.550493 12802 sgd_solver.cpp:105] Iteration 22240, lr = 0.00135098
I1028 23:33:16.747776 12802 solver.cpp:222] Iteration 22280 (1.32465 iter/s, 30.1966s/40 iters), loss = 1.62044
I1028 23:33:16.747970 12802 solver.cpp:241]     Train net output #0: loss = 1.62044 (* 1 = 1.62044 loss)
I1028 23:33:16.747988 12802 sgd_solver.cpp:105] Iteration 22280, lr = 0.00134612
I1028 23:33:46.617285 12802 solver.cpp:222] Iteration 22320 (1.3392 iter/s, 29.8686s/40 iters), loss = 1.83352
I1028 23:33:46.617342 12802 solver.cpp:241]     Train net output #0: loss = 1.83352 (* 1 = 1.83352 loss)
I1028 23:33:46.617359 12802 sgd_solver.cpp:105] Iteration 22320, lr = 0.00134128
I1028 23:34:16.297864 12802 solver.cpp:222] Iteration 22360 (1.34772 iter/s, 29.6798s/40 iters), loss = 1.25154
I1028 23:34:16.298043 12802 solver.cpp:241]     Train net output #0: loss = 1.25154 (* 1 = 1.25154 loss)
I1028 23:34:16.298056 12802 sgd_solver.cpp:105] Iteration 22360, lr = 0.00133646
I1028 23:34:45.914922 12802 solver.cpp:222] Iteration 22400 (1.35061 iter/s, 29.6162s/40 iters), loss = 1.38396
I1028 23:34:45.914988 12802 solver.cpp:241]     Train net output #0: loss = 1.38396 (* 1 = 1.38396 loss)
I1028 23:34:45.915001 12802 sgd_solver.cpp:105] Iteration 22400, lr = 0.00133166
I1028 23:35:15.628325 12802 solver.cpp:222] Iteration 22440 (1.34623 iter/s, 29.7126s/40 iters), loss = 1.30481
I1028 23:35:15.628569 12802 solver.cpp:241]     Train net output #0: loss = 1.30481 (* 1 = 1.30481 loss)
I1028 23:35:15.628588 12802 sgd_solver.cpp:105] Iteration 22440, lr = 0.00132687
I1028 23:35:45.413506 12802 solver.cpp:222] Iteration 22480 (1.34299 iter/s, 29.7842s/40 iters), loss = 1.39933
I1028 23:35:45.413570 12802 solver.cpp:241]     Train net output #0: loss = 1.39933 (* 1 = 1.39933 loss)
I1028 23:35:45.413586 12802 sgd_solver.cpp:105] Iteration 22480, lr = 0.00132211
I1028 23:35:59.435072 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_22500.caffemodel
I1028 23:35:59.574975 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_22500.solverstate
I1028 23:35:59.686182 12802 solver.cpp:334] Iteration 22500, Testing net (#0)
I1028 23:36:31.196085 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1028 23:36:31.401635 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57544
I1028 23:36:31.401688 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8096
I1028 23:36:31.401700 12802 solver.cpp:401]     Test net output #2: loss = 1.88673 (* 1 = 1.88673 loss)
I1028 23:36:46.922128 12802 solver.cpp:222] Iteration 22520 (0.650331 iter/s, 61.5071s/40 iters), loss = 1.56566
I1028 23:36:46.922189 12802 solver.cpp:241]     Train net output #0: loss = 1.56566 (* 1 = 1.56566 loss)
I1028 23:36:46.922205 12802 sgd_solver.cpp:105] Iteration 22520, lr = 0.00131736
I1028 23:37:16.549448 12802 solver.cpp:222] Iteration 22560 (1.35014 iter/s, 29.6265s/40 iters), loss = 1.4826
I1028 23:37:16.549614 12802 solver.cpp:241]     Train net output #0: loss = 1.4826 (* 1 = 1.4826 loss)
I1028 23:37:16.549631 12802 sgd_solver.cpp:105] Iteration 22560, lr = 0.00131262
I1028 23:37:47.210168 12802 solver.cpp:222] Iteration 22600 (1.30464 iter/s, 30.6598s/40 iters), loss = 1.41283
I1028 23:37:47.210340 12802 solver.cpp:241]     Train net output #0: loss = 1.41283 (* 1 = 1.41283 loss)
I1028 23:37:47.210364 12802 sgd_solver.cpp:105] Iteration 22600, lr = 0.0013079
I1028 23:38:17.000439 12802 solver.cpp:222] Iteration 22640 (1.34276 iter/s, 29.7894s/40 iters), loss = 1.38233
I1028 23:38:17.000495 12802 solver.cpp:241]     Train net output #0: loss = 1.38233 (* 1 = 1.38233 loss)
I1028 23:38:17.000510 12802 sgd_solver.cpp:105] Iteration 22640, lr = 0.0013032
I1028 23:38:47.187314 12802 solver.cpp:222] Iteration 22680 (1.32511 iter/s, 30.1861s/40 iters), loss = 1.25473
I1028 23:38:47.187484 12802 solver.cpp:241]     Train net output #0: loss = 1.25473 (* 1 = 1.25473 loss)
I1028 23:38:47.187502 12802 sgd_solver.cpp:105] Iteration 22680, lr = 0.00129852
I1028 23:39:17.057492 12802 solver.cpp:222] Iteration 22720 (1.33917 iter/s, 29.8693s/40 iters), loss = 1.28884
I1028 23:39:17.057559 12802 solver.cpp:241]     Train net output #0: loss = 1.28884 (* 1 = 1.28884 loss)
I1028 23:39:17.057572 12802 sgd_solver.cpp:105] Iteration 22720, lr = 0.00129385
I1028 23:39:46.627781 12802 solver.cpp:222] Iteration 22760 (1.35274 iter/s, 29.5695s/40 iters), loss = 1.64374
I1028 23:39:46.628271 12802 solver.cpp:241]     Train net output #0: loss = 1.64374 (* 1 = 1.64374 loss)
I1028 23:39:46.628288 12802 sgd_solver.cpp:105] Iteration 22760, lr = 0.0012892
I1028 23:40:16.881866 12802 solver.cpp:222] Iteration 22800 (1.32219 iter/s, 30.2529s/40 iters), loss = 1.55778
I1028 23:40:16.882052 12802 solver.cpp:241]     Train net output #0: loss = 1.55778 (* 1 = 1.55778 loss)
I1028 23:40:16.882069 12802 sgd_solver.cpp:105] Iteration 22800, lr = 0.00128457
I1028 23:40:47.802577 12802 solver.cpp:222] Iteration 22840 (1.29367 iter/s, 30.9198s/40 iters), loss = 1.36782
I1028 23:40:47.802764 12802 solver.cpp:241]     Train net output #0: loss = 1.36782 (* 1 = 1.36782 loss)
I1028 23:40:47.802781 12802 sgd_solver.cpp:105] Iteration 22840, lr = 0.00127995
I1028 23:41:17.493017 12802 solver.cpp:222] Iteration 22880 (1.34728 iter/s, 29.6895s/40 iters), loss = 1.20954
I1028 23:41:17.493073 12802 solver.cpp:241]     Train net output #0: loss = 1.20954 (* 1 = 1.20954 loss)
I1028 23:41:17.493088 12802 sgd_solver.cpp:105] Iteration 22880, lr = 0.00127535
I1028 23:41:47.418334 12802 solver.cpp:222] Iteration 22920 (1.3367 iter/s, 29.9245s/40 iters), loss = 1.51516
I1028 23:41:47.418591 12802 solver.cpp:241]     Train net output #0: loss = 1.51516 (* 1 = 1.51516 loss)
I1028 23:41:47.418609 12802 sgd_solver.cpp:105] Iteration 22920, lr = 0.00127077
I1028 23:42:17.101806 12802 solver.cpp:222] Iteration 22960 (1.34759 iter/s, 29.6825s/40 iters), loss = 1.49079
I1028 23:42:17.101866 12802 solver.cpp:241]     Train net output #0: loss = 1.49079 (* 1 = 1.49079 loss)
I1028 23:42:17.101881 12802 sgd_solver.cpp:105] Iteration 22960, lr = 0.0012662
I1028 23:42:46.091105 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_23000.caffemodel
I1028 23:42:46.233114 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_23000.solverstate
I1028 23:42:46.355223 12802 solver.cpp:334] Iteration 23000, Testing net (#0)
I1028 23:43:17.617091 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57764
I1028 23:43:17.617233 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8046
I1028 23:43:17.617246 12802 solver.cpp:401]     Test net output #2: loss = 1.87901 (* 1 = 1.87901 loss)
I1028 23:43:18.378180 12802 solver.cpp:222] Iteration 23000 (0.652796 iter/s, 61.2749s/40 iters), loss = 1.75736
I1028 23:43:18.378242 12802 solver.cpp:241]     Train net output #0: loss = 1.75736 (* 1 = 1.75736 loss)
I1028 23:43:18.378257 12802 sgd_solver.cpp:105] Iteration 23000, lr = 0.00126165
I1028 23:43:48.039724 12802 solver.cpp:222] Iteration 23040 (1.34858 iter/s, 29.6608s/40 iters), loss = 1.49308
I1028 23:43:48.039863 12802 solver.cpp:241]     Train net output #0: loss = 1.49308 (* 1 = 1.49308 loss)
I1028 23:43:48.039880 12802 sgd_solver.cpp:105] Iteration 23040, lr = 0.00125712
I1028 23:44:17.709466 12802 solver.cpp:222] Iteration 23080 (1.34821 iter/s, 29.6689s/40 iters), loss = 1.4725
I1028 23:44:17.709528 12802 solver.cpp:241]     Train net output #0: loss = 1.4725 (* 1 = 1.4725 loss)
I1028 23:44:17.709544 12802 sgd_solver.cpp:105] Iteration 23080, lr = 0.0012526
I1028 23:44:47.356729 12802 solver.cpp:222] Iteration 23120 (1.34923 iter/s, 29.6465s/40 iters), loss = 1.3759
I1028 23:44:47.356884 12802 solver.cpp:241]     Train net output #0: loss = 1.3759 (* 1 = 1.3759 loss)
I1028 23:44:47.356902 12802 sgd_solver.cpp:105] Iteration 23120, lr = 0.0012481
I1028 23:45:17.085942 12802 solver.cpp:222] Iteration 23160 (1.34552 iter/s, 29.7283s/40 iters), loss = 1.46128
I1028 23:45:17.086004 12802 solver.cpp:241]     Train net output #0: loss = 1.46128 (* 1 = 1.46128 loss)
I1028 23:45:17.086020 12802 sgd_solver.cpp:105] Iteration 23160, lr = 0.00124361
I1028 23:45:46.844952 12802 solver.cpp:222] Iteration 23200 (1.34417 iter/s, 29.7582s/40 iters), loss = 1.56171
I1028 23:45:46.845094 12802 solver.cpp:241]     Train net output #0: loss = 1.56171 (* 1 = 1.56171 loss)
I1028 23:45:46.845110 12802 sgd_solver.cpp:105] Iteration 23200, lr = 0.00123914
I1028 23:46:16.627804 12802 solver.cpp:222] Iteration 23240 (1.34309 iter/s, 29.782s/40 iters), loss = 1.7165
I1028 23:46:16.627869 12802 solver.cpp:241]     Train net output #0: loss = 1.7165 (* 1 = 1.7165 loss)
I1028 23:46:16.627885 12802 sgd_solver.cpp:105] Iteration 23240, lr = 0.00123469
I1028 23:46:46.958849 12802 solver.cpp:222] Iteration 23280 (1.31881 iter/s, 30.3303s/40 iters), loss = 1.59346
I1028 23:46:46.959062 12802 solver.cpp:241]     Train net output #0: loss = 1.59346 (* 1 = 1.59346 loss)
I1028 23:46:46.959080 12802 sgd_solver.cpp:105] Iteration 23280, lr = 0.00123025
I1028 23:47:17.288202 12802 solver.cpp:222] Iteration 23320 (1.3189 iter/s, 30.3284s/40 iters), loss = 1.32232
I1028 23:47:17.288393 12802 solver.cpp:241]     Train net output #0: loss = 1.32232 (* 1 = 1.32232 loss)
I1028 23:47:17.288410 12802 sgd_solver.cpp:105] Iteration 23320, lr = 0.00122583
I1028 23:47:47.544342 12802 solver.cpp:222] Iteration 23360 (1.32209 iter/s, 30.2552s/40 iters), loss = 1.51117
I1028 23:47:47.544553 12802 solver.cpp:241]     Train net output #0: loss = 1.51117 (* 1 = 1.51117 loss)
I1028 23:47:47.544571 12802 sgd_solver.cpp:105] Iteration 23360, lr = 0.00122143
I1028 23:48:18.547988 12802 solver.cpp:222] Iteration 23400 (1.29021 iter/s, 31.0027s/40 iters), loss = 1.41596
I1028 23:48:18.548172 12802 solver.cpp:241]     Train net output #0: loss = 1.41596 (* 1 = 1.41596 loss)
I1028 23:48:18.548189 12802 sgd_solver.cpp:105] Iteration 23400, lr = 0.00121704
I1028 23:49:02.437561 12802 solver.cpp:222] Iteration 23440 (0.911404 iter/s, 43.8883s/40 iters), loss = 1.78573
I1028 23:49:02.437783 12802 solver.cpp:241]     Train net output #0: loss = 1.78573 (* 1 = 1.78573 loss)
I1028 23:49:02.437804 12802 sgd_solver.cpp:105] Iteration 23440, lr = 0.00121266
I1028 23:49:33.031206 12802 solver.cpp:222] Iteration 23480 (1.3075 iter/s, 30.5927s/40 iters), loss = 1.16923
I1028 23:49:33.031371 12802 solver.cpp:241]     Train net output #0: loss = 1.16923 (* 1 = 1.16923 loss)
I1028 23:49:33.031388 12802 sgd_solver.cpp:105] Iteration 23480, lr = 0.00120831
I1028 23:49:47.559974 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_23500.caffemodel
I1028 23:49:47.704471 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_23500.solverstate
I1028 23:49:47.828660 12802 solver.cpp:334] Iteration 23500, Testing net (#0)
I1028 23:50:18.943562 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1028 23:50:19.152484 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57904
I1028 23:50:19.152532 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80948
I1028 23:50:19.152559 12802 solver.cpp:401]     Test net output #2: loss = 1.8672 (* 1 = 1.8672 loss)
I1028 23:50:35.146786 12802 solver.cpp:222] Iteration 23520 (0.643978 iter/s, 62.114s/40 iters), loss = 1.53511
I1028 23:50:35.146844 12802 solver.cpp:241]     Train net output #0: loss = 1.53511 (* 1 = 1.53511 loss)
I1028 23:50:35.146859 12802 sgd_solver.cpp:105] Iteration 23520, lr = 0.00120396
I1028 23:51:05.617334 12802 solver.cpp:222] Iteration 23560 (1.31278 iter/s, 30.4698s/40 iters), loss = 1.59625
I1028 23:51:05.617558 12802 solver.cpp:241]     Train net output #0: loss = 1.59625 (* 1 = 1.59625 loss)
I1028 23:51:05.617580 12802 sgd_solver.cpp:105] Iteration 23560, lr = 0.00119964
I1028 23:51:35.861135 12802 solver.cpp:222] Iteration 23600 (1.32263 iter/s, 30.2429s/40 iters), loss = 1.50929
I1028 23:51:35.861344 12802 solver.cpp:241]     Train net output #0: loss = 1.50929 (* 1 = 1.50929 loss)
I1028 23:51:35.861359 12802 sgd_solver.cpp:105] Iteration 23600, lr = 0.00119533
I1028 23:51:38.231787 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1028 23:52:05.668773 12802 solver.cpp:222] Iteration 23640 (1.34198 iter/s, 29.8067s/40 iters), loss = 1.51988
I1028 23:52:05.668839 12802 solver.cpp:241]     Train net output #0: loss = 1.51988 (* 1 = 1.51988 loss)
I1028 23:52:05.668855 12802 sgd_solver.cpp:105] Iteration 23640, lr = 0.00119103
I1028 23:52:35.647104 12802 solver.cpp:222] Iteration 23680 (1.33433 iter/s, 29.9775s/40 iters), loss = 1.66321
I1028 23:52:35.647300 12802 solver.cpp:241]     Train net output #0: loss = 1.66321 (* 1 = 1.66321 loss)
I1028 23:52:35.647315 12802 sgd_solver.cpp:105] Iteration 23680, lr = 0.00118675
I1028 23:53:05.600049 12802 solver.cpp:222] Iteration 23720 (1.33547 iter/s, 29.952s/40 iters), loss = 1.45805
I1028 23:53:05.600102 12802 solver.cpp:241]     Train net output #0: loss = 1.45805 (* 1 = 1.45805 loss)
I1028 23:53:05.600118 12802 sgd_solver.cpp:105] Iteration 23720, lr = 0.00118248
I1028 23:53:35.715639 12802 solver.cpp:222] Iteration 23760 (1.32825 iter/s, 30.1148s/40 iters), loss = 1.38479
I1028 23:53:35.715875 12802 solver.cpp:241]     Train net output #0: loss = 1.38479 (* 1 = 1.38479 loss)
I1028 23:53:35.715893 12802 sgd_solver.cpp:105] Iteration 23760, lr = 0.00117823
I1028 23:54:05.683053 12802 solver.cpp:222] Iteration 23800 (1.33483 iter/s, 29.9665s/40 iters), loss = 1.56412
I1028 23:54:05.683112 12802 solver.cpp:241]     Train net output #0: loss = 1.56412 (* 1 = 1.56412 loss)
I1028 23:54:05.683127 12802 sgd_solver.cpp:105] Iteration 23800, lr = 0.001174
I1028 23:54:35.966629 12802 solver.cpp:222] Iteration 23840 (1.32088 iter/s, 30.2828s/40 iters), loss = 1.60414
I1028 23:54:35.966840 12802 solver.cpp:241]     Train net output #0: loss = 1.60414 (* 1 = 1.60414 loss)
I1028 23:54:35.966859 12802 sgd_solver.cpp:105] Iteration 23840, lr = 0.00116978
I1028 23:55:06.347060 12802 solver.cpp:222] Iteration 23880 (1.31668 iter/s, 30.3795s/40 iters), loss = 1.28923
I1028 23:55:06.347232 12802 solver.cpp:241]     Train net output #0: loss = 1.28923 (* 1 = 1.28923 loss)
I1028 23:55:06.347251 12802 sgd_solver.cpp:105] Iteration 23880, lr = 0.00116558
I1028 23:55:37.163558 12802 solver.cpp:222] Iteration 23920 (1.29805 iter/s, 30.8156s/40 iters), loss = 1.19278
I1028 23:55:37.163771 12802 solver.cpp:241]     Train net output #0: loss = 1.19278 (* 1 = 1.19278 loss)
I1028 23:55:37.163799 12802 sgd_solver.cpp:105] Iteration 23920, lr = 0.00116139
I1028 23:56:08.645125 12802 solver.cpp:222] Iteration 23960 (1.27062 iter/s, 31.4806s/40 iters), loss = 1.61569
I1028 23:56:08.645335 12802 solver.cpp:241]     Train net output #0: loss = 1.61569 (* 1 = 1.61569 loss)
I1028 23:56:08.645349 12802 sgd_solver.cpp:105] Iteration 23960, lr = 0.00115721
I1028 23:56:38.691864 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_24000.caffemodel
I1028 23:56:38.833778 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_24000.solverstate
I1028 23:56:38.945785 12802 solver.cpp:334] Iteration 24000, Testing net (#0)
I1028 23:57:10.197093 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57892
I1028 23:57:10.197257 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8038
I1028 23:57:10.197269 12802 solver.cpp:401]     Test net output #2: loss = 1.88945 (* 1 = 1.88945 loss)
I1028 23:57:10.966512 12802 solver.cpp:222] Iteration 24000 (0.641851 iter/s, 62.3197s/40 iters), loss = 1.76289
I1028 23:57:10.966562 12802 solver.cpp:241]     Train net output #0: loss = 1.76289 (* 1 = 1.76289 loss)
I1028 23:57:10.966578 12802 sgd_solver.cpp:105] Iteration 24000, lr = 0.00115306
I1028 23:57:41.990285 12802 solver.cpp:222] Iteration 24040 (1.28937 iter/s, 31.023s/40 iters), loss = 1.54017
I1028 23:57:41.990481 12802 solver.cpp:241]     Train net output #0: loss = 1.54017 (* 1 = 1.54017 loss)
I1028 23:57:41.990504 12802 sgd_solver.cpp:105] Iteration 24040, lr = 0.00114891
I1028 23:58:30.040735 12802 solver.cpp:222] Iteration 24080 (0.832482 iter/s, 48.0491s/40 iters), loss = 1.27641
I1028 23:58:30.040940 12802 solver.cpp:241]     Train net output #0: loss = 1.27641 (* 1 = 1.27641 loss)
I1028 23:58:30.040958 12802 sgd_solver.cpp:105] Iteration 24080, lr = 0.00114478
I1028 23:59:00.764369 12802 solver.cpp:222] Iteration 24120 (1.30197 iter/s, 30.7227s/40 iters), loss = 1.07134
I1028 23:59:00.764578 12802 solver.cpp:241]     Train net output #0: loss = 1.07134 (* 1 = 1.07134 loss)
I1028 23:59:00.764595 12802 sgd_solver.cpp:105] Iteration 24120, lr = 0.00114067
I1028 23:59:31.613049 12802 solver.cpp:222] Iteration 24160 (1.29669 iter/s, 30.8477s/40 iters), loss = 1.48701
I1028 23:59:31.613237 12802 solver.cpp:241]     Train net output #0: loss = 1.48701 (* 1 = 1.48701 loss)
I1028 23:59:31.613253 12802 sgd_solver.cpp:105] Iteration 24160, lr = 0.00113657
I1029 00:00:01.842552 12802 solver.cpp:222] Iteration 24200 (1.32325 iter/s, 30.2286s/40 iters), loss = 1.23903
I1029 00:00:01.842739 12802 solver.cpp:241]     Train net output #0: loss = 1.23903 (* 1 = 1.23903 loss)
I1029 00:00:01.842764 12802 sgd_solver.cpp:105] Iteration 24200, lr = 0.00113248
I1029 00:00:31.789531 12802 solver.cpp:222] Iteration 24240 (1.33573 iter/s, 29.9461s/40 iters), loss = 1.78756
I1029 00:00:31.789594 12802 solver.cpp:241]     Train net output #0: loss = 1.78756 (* 1 = 1.78756 loss)
I1029 00:00:31.789608 12802 sgd_solver.cpp:105] Iteration 24240, lr = 0.00112841
I1029 00:01:01.562434 12802 solver.cpp:222] Iteration 24280 (1.34354 iter/s, 29.7721s/40 iters), loss = 1.56311
I1029 00:01:01.562723 12802 solver.cpp:241]     Train net output #0: loss = 1.56311 (* 1 = 1.56311 loss)
I1029 00:01:01.562764 12802 sgd_solver.cpp:105] Iteration 24280, lr = 0.00112436
I1029 00:01:32.042120 12802 solver.cpp:222] Iteration 24320 (1.31239 iter/s, 30.4787s/40 iters), loss = 1.27627
I1029 00:01:32.042346 12802 solver.cpp:241]     Train net output #0: loss = 1.27627 (* 1 = 1.27627 loss)
I1029 00:01:32.042362 12802 sgd_solver.cpp:105] Iteration 24320, lr = 0.00112032
I1029 00:02:01.978868 12802 solver.cpp:222] Iteration 24360 (1.33619 iter/s, 29.9358s/40 iters), loss = 1.44857
I1029 00:02:01.978934 12802 solver.cpp:241]     Train net output #0: loss = 1.44857 (* 1 = 1.44857 loss)
I1029 00:02:01.978950 12802 sgd_solver.cpp:105] Iteration 24360, lr = 0.00111629
I1029 00:02:46.365332 12802 solver.cpp:222] Iteration 24400 (0.901198 iter/s, 44.3854s/40 iters), loss = 1.71607
I1029 00:02:46.365550 12802 solver.cpp:241]     Train net output #0: loss = 1.71607 (* 1 = 1.71607 loss)
I1029 00:02:46.365567 12802 sgd_solver.cpp:105] Iteration 24400, lr = 0.00111228
I1029 00:03:16.912844 12802 solver.cpp:222] Iteration 24440 (1.30948 iter/s, 30.5466s/40 iters), loss = 1.33473
I1029 00:03:16.913017 12802 solver.cpp:241]     Train net output #0: loss = 1.33473 (* 1 = 1.33473 loss)
I1029 00:03:16.913034 12802 sgd_solver.cpp:105] Iteration 24440, lr = 0.00110828
I1029 00:03:47.584358 12802 solver.cpp:222] Iteration 24480 (1.30418 iter/s, 30.6706s/40 iters), loss = 1.4912
I1029 00:03:47.584568 12802 solver.cpp:241]     Train net output #0: loss = 1.4912 (* 1 = 1.4912 loss)
I1029 00:03:47.584590 12802 sgd_solver.cpp:105] Iteration 24480, lr = 0.0011043
I1029 00:04:01.911087 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_24500.caffemodel
I1029 00:04:02.052834 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_24500.solverstate
I1029 00:04:02.158946 12802 solver.cpp:334] Iteration 24500, Testing net (#0)
I1029 00:04:33.186539 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 00:04:33.395576 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57696
I1029 00:04:33.395627 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.808879
I1029 00:04:33.395637 12802 solver.cpp:401]     Test net output #2: loss = 1.87641 (* 1 = 1.87641 loss)
I1029 00:04:49.862047 12802 solver.cpp:222] Iteration 24520 (0.642302 iter/s, 62.276s/40 iters), loss = 1.8522
I1029 00:04:49.862110 12802 solver.cpp:241]     Train net output #0: loss = 1.8522 (* 1 = 1.8522 loss)
I1029 00:04:49.862125 12802 sgd_solver.cpp:105] Iteration 24520, lr = 0.00110033
I1029 00:05:20.728440 12802 solver.cpp:222] Iteration 24560 (1.29594 iter/s, 30.8656s/40 iters), loss = 1.6699
I1029 00:05:20.728636 12802 solver.cpp:241]     Train net output #0: loss = 1.6699 (* 1 = 1.6699 loss)
I1029 00:05:20.728653 12802 sgd_solver.cpp:105] Iteration 24560, lr = 0.00109638
I1029 00:05:50.200769 12802 solver.cpp:222] Iteration 24600 (1.35725 iter/s, 29.4714s/40 iters), loss = 1.13348
I1029 00:05:50.200829 12802 solver.cpp:241]     Train net output #0: loss = 1.13348 (* 1 = 1.13348 loss)
I1029 00:05:50.200844 12802 sgd_solver.cpp:105] Iteration 24600, lr = 0.00109244
I1029 00:06:19.811267 12802 solver.cpp:222] Iteration 24640 (1.35091 iter/s, 29.6097s/40 iters), loss = 1.51893
I1029 00:06:19.811449 12802 solver.cpp:241]     Train net output #0: loss = 1.51893 (* 1 = 1.51893 loss)
I1029 00:06:19.811465 12802 sgd_solver.cpp:105] Iteration 24640, lr = 0.00108851
I1029 00:06:49.465847 12802 solver.cpp:222] Iteration 24680 (1.3489 iter/s, 29.6537s/40 iters), loss = 1.41453
I1029 00:06:49.465903 12802 solver.cpp:241]     Train net output #0: loss = 1.41453 (* 1 = 1.41453 loss)
I1029 00:06:49.465924 12802 sgd_solver.cpp:105] Iteration 24680, lr = 0.0010846
I1029 00:07:19.130482 12802 solver.cpp:222] Iteration 24720 (1.34844 iter/s, 29.6639s/40 iters), loss = 1.23758
I1029 00:07:19.130623 12802 solver.cpp:241]     Train net output #0: loss = 1.23758 (* 1 = 1.23758 loss)
I1029 00:07:19.130640 12802 sgd_solver.cpp:105] Iteration 24720, lr = 0.0010807
I1029 00:07:48.751907 12802 solver.cpp:222] Iteration 24760 (1.35041 iter/s, 29.6206s/40 iters), loss = 1.59156
I1029 00:07:48.751971 12802 solver.cpp:241]     Train net output #0: loss = 1.59156 (* 1 = 1.59156 loss)
I1029 00:07:48.751986 12802 sgd_solver.cpp:105] Iteration 24760, lr = 0.00107682
I1029 00:08:18.421685 12802 solver.cpp:222] Iteration 24800 (1.34821 iter/s, 29.669s/40 iters), loss = 1.48504
I1029 00:08:18.421785 12802 solver.cpp:241]     Train net output #0: loss = 1.48504 (* 1 = 1.48504 loss)
I1029 00:08:18.421803 12802 sgd_solver.cpp:105] Iteration 24800, lr = 0.00107295
I1029 00:08:48.089818 12802 solver.cpp:222] Iteration 24840 (1.34828 iter/s, 29.6673s/40 iters), loss = 1.75868
I1029 00:08:48.089879 12802 solver.cpp:241]     Train net output #0: loss = 1.75868 (* 1 = 1.75868 loss)
I1029 00:08:48.089895 12802 sgd_solver.cpp:105] Iteration 24840, lr = 0.00106909
I1029 00:09:17.693553 12802 solver.cpp:222] Iteration 24880 (1.35122 iter/s, 29.603s/40 iters), loss = 1.18639
I1029 00:09:17.693717 12802 solver.cpp:241]     Train net output #0: loss = 1.18639 (* 1 = 1.18639 loss)
I1029 00:09:17.693734 12802 sgd_solver.cpp:105] Iteration 24880, lr = 0.00106525
I1029 00:09:47.331861 12802 solver.cpp:222] Iteration 24920 (1.34964 iter/s, 29.6374s/40 iters), loss = 1.24201
I1029 00:09:47.331925 12802 solver.cpp:241]     Train net output #0: loss = 1.24201 (* 1 = 1.24201 loss)
I1029 00:09:47.331941 12802 sgd_solver.cpp:105] Iteration 24920, lr = 0.00106142
I1029 00:10:16.905210 12802 solver.cpp:222] Iteration 24960 (1.3526 iter/s, 29.5726s/40 iters), loss = 1.65494
I1029 00:10:16.905406 12802 solver.cpp:241]     Train net output #0: loss = 1.65494 (* 1 = 1.65494 loss)
I1029 00:10:16.905429 12802 sgd_solver.cpp:105] Iteration 24960, lr = 0.00105761
I1029 00:10:48.348357 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_25000.caffemodel
I1029 00:10:48.488253 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_25000.solverstate
I1029 00:10:48.612830 12802 solver.cpp:334] Iteration 25000, Testing net (#0)
I1029 00:11:19.882992 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57912
I1029 00:11:19.883168 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80512
I1029 00:11:19.883182 12802 solver.cpp:401]     Test net output #2: loss = 1.85794 (* 1 = 1.85794 loss)
I1029 00:11:20.654420 12802 solver.cpp:222] Iteration 25000 (0.627475 iter/s, 63.7475s/40 iters), loss = 1.30994
I1029 00:11:20.654479 12802 solver.cpp:241]     Train net output #0: loss = 1.30994 (* 1 = 1.30994 loss)
I1029 00:11:20.654502 12802 sgd_solver.cpp:105] Iteration 25000, lr = 0.00105381
I1029 00:11:52.023380 12802 solver.cpp:222] Iteration 25040 (1.27518 iter/s, 31.3682s/40 iters), loss = 1.51103
I1029 00:11:52.023586 12802 solver.cpp:241]     Train net output #0: loss = 1.51103 (* 1 = 1.51103 loss)
I1029 00:11:52.023604 12802 sgd_solver.cpp:105] Iteration 25040, lr = 0.00105002
I1029 00:12:22.671871 12802 solver.cpp:222] Iteration 25080 (1.30516 iter/s, 30.6476s/40 iters), loss = 1.52066
I1029 00:12:22.672025 12802 solver.cpp:241]     Train net output #0: loss = 1.52066 (* 1 = 1.52066 loss)
I1029 00:12:22.672042 12802 sgd_solver.cpp:105] Iteration 25080, lr = 0.00104625
I1029 00:12:53.529939 12802 solver.cpp:222] Iteration 25120 (1.2963 iter/s, 30.8572s/40 iters), loss = 1.78324
I1029 00:12:53.530084 12802 solver.cpp:241]     Train net output #0: loss = 1.78324 (* 1 = 1.78324 loss)
I1029 00:12:53.530102 12802 sgd_solver.cpp:105] Iteration 25120, lr = 0.00104249
I1029 00:13:23.987670 12802 solver.cpp:222] Iteration 25160 (1.31333 iter/s, 30.4569s/40 iters), loss = 1.48041
I1029 00:13:23.987932 12802 solver.cpp:241]     Train net output #0: loss = 1.48041 (* 1 = 1.48041 loss)
I1029 00:13:23.987951 12802 sgd_solver.cpp:105] Iteration 25160, lr = 0.00103874
I1029 00:13:54.130287 12802 solver.cpp:222] Iteration 25200 (1.32707 iter/s, 30.1416s/40 iters), loss = 1.43099
I1029 00:13:54.130511 12802 solver.cpp:241]     Train net output #0: loss = 1.43099 (* 1 = 1.43099 loss)
I1029 00:13:54.130527 12802 sgd_solver.cpp:105] Iteration 25200, lr = 0.00103501
I1029 00:14:23.782269 12802 solver.cpp:222] Iteration 25240 (1.34902 iter/s, 29.6511s/40 iters), loss = 1.32717
I1029 00:14:23.782330 12802 solver.cpp:241]     Train net output #0: loss = 1.32717 (* 1 = 1.32717 loss)
I1029 00:14:23.782344 12802 sgd_solver.cpp:105] Iteration 25240, lr = 0.00103129
I1029 00:14:53.341130 12802 solver.cpp:222] Iteration 25280 (1.35327 iter/s, 29.5581s/40 iters), loss = 1.69527
I1029 00:14:53.341289 12802 solver.cpp:241]     Train net output #0: loss = 1.69527 (* 1 = 1.69527 loss)
I1029 00:14:53.341305 12802 sgd_solver.cpp:105] Iteration 25280, lr = 0.00102758
I1029 00:15:22.887141 12802 solver.cpp:222] Iteration 25320 (1.35386 iter/s, 29.5452s/40 iters), loss = 1.55922
I1029 00:15:22.887200 12802 solver.cpp:241]     Train net output #0: loss = 1.55922 (* 1 = 1.55922 loss)
I1029 00:15:22.887217 12802 sgd_solver.cpp:105] Iteration 25320, lr = 0.00102389
I1029 00:15:55.164217 12802 solver.cpp:222] Iteration 25360 (1.2393 iter/s, 32.2763s/40 iters), loss = 1.56585
I1029 00:15:55.164362 12802 solver.cpp:241]     Train net output #0: loss = 1.56585 (* 1 = 1.56585 loss)
I1029 00:15:55.164379 12802 sgd_solver.cpp:105] Iteration 25360, lr = 0.00102021
I1029 00:16:26.013403 12802 solver.cpp:222] Iteration 25400 (1.29667 iter/s, 30.8483s/40 iters), loss = 1.19252
I1029 00:16:26.013568 12802 solver.cpp:241]     Train net output #0: loss = 1.19252 (* 1 = 1.19252 loss)
I1029 00:16:26.013586 12802 sgd_solver.cpp:105] Iteration 25400, lr = 0.00101654
I1029 00:16:56.461784 12802 solver.cpp:222] Iteration 25440 (1.31374 iter/s, 30.4475s/40 iters), loss = 1.59036
I1029 00:16:56.461922 12802 solver.cpp:241]     Train net output #0: loss = 1.59036 (* 1 = 1.59036 loss)
I1029 00:16:56.461941 12802 sgd_solver.cpp:105] Iteration 25440, lr = 0.00101289
I1029 00:17:27.093808 12802 solver.cpp:222] Iteration 25480 (1.30586 iter/s, 30.6312s/40 iters), loss = 1.4474
I1029 00:17:27.094015 12802 solver.cpp:241]     Train net output #0: loss = 1.4474 (* 1 = 1.4474 loss)
I1029 00:17:27.094029 12802 sgd_solver.cpp:105] Iteration 25480, lr = 0.00100925
I1029 00:17:41.551587 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_25500.caffemodel
I1029 00:17:41.707875 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_25500.solverstate
I1029 00:17:41.853991 12802 solver.cpp:334] Iteration 25500, Testing net (#0)
I1029 00:18:12.895685 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 00:18:13.102847 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57956
I1029 00:18:13.102897 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8102
I1029 00:18:13.102908 12802 solver.cpp:401]     Test net output #2: loss = 1.86678 (* 1 = 1.86678 loss)
I1029 00:18:28.992067 12802 solver.cpp:222] Iteration 25520 (0.646239 iter/s, 61.8966s/40 iters), loss = 1.37449
I1029 00:18:28.992123 12802 solver.cpp:241]     Train net output #0: loss = 1.37449 (* 1 = 1.37449 loss)
I1029 00:18:28.992138 12802 sgd_solver.cpp:105] Iteration 25520, lr = 0.00100562
I1029 00:18:58.817256 12802 solver.cpp:222] Iteration 25560 (1.34118 iter/s, 29.8244s/40 iters), loss = 1.39937
I1029 00:18:58.817433 12802 solver.cpp:241]     Train net output #0: loss = 1.39937 (* 1 = 1.39937 loss)
I1029 00:18:58.817451 12802 sgd_solver.cpp:105] Iteration 25560, lr = 0.00100201
I1029 00:19:28.597868 12802 solver.cpp:222] Iteration 25600 (1.3432 iter/s, 29.7797s/40 iters), loss = 1.57086
I1029 00:19:28.597932 12802 solver.cpp:241]     Train net output #0: loss = 1.57086 (* 1 = 1.57086 loss)
I1029 00:19:28.597949 12802 sgd_solver.cpp:105] Iteration 25600, lr = 0.000998406
I1029 00:19:58.345959 12802 solver.cpp:222] Iteration 25640 (1.34466 iter/s, 29.7473s/40 iters), loss = 1.25968
I1029 00:19:58.346174 12802 solver.cpp:241]     Train net output #0: loss = 1.25968 (* 1 = 1.25968 loss)
I1029 00:19:58.346202 12802 sgd_solver.cpp:105] Iteration 25640, lr = 0.000994817
I1029 00:20:28.456320 12802 solver.cpp:222] Iteration 25680 (1.32849 iter/s, 30.1094s/40 iters), loss = 1.53451
I1029 00:20:28.456526 12802 solver.cpp:241]     Train net output #0: loss = 1.53451 (* 1 = 1.53451 loss)
I1029 00:20:28.456543 12802 sgd_solver.cpp:105] Iteration 25680, lr = 0.000991242
I1029 00:20:58.325793 12802 solver.cpp:222] Iteration 25720 (1.3392 iter/s, 29.8686s/40 iters), loss = 1.04386
I1029 00:20:58.325851 12802 solver.cpp:241]     Train net output #0: loss = 1.04386 (* 1 = 1.04386 loss)
I1029 00:20:58.325865 12802 sgd_solver.cpp:105] Iteration 25720, lr = 0.00098768
I1029 00:21:27.991719 12802 solver.cpp:222] Iteration 25760 (1.34838 iter/s, 29.6652s/40 iters), loss = 1.13074
I1029 00:21:27.991901 12802 solver.cpp:241]     Train net output #0: loss = 1.13074 (* 1 = 1.13074 loss)
I1029 00:21:27.991915 12802 sgd_solver.cpp:105] Iteration 25760, lr = 0.00098413
I1029 00:21:57.669790 12802 solver.cpp:222] Iteration 25800 (1.34784 iter/s, 29.6772s/40 iters), loss = 1.279
I1029 00:21:57.669849 12802 solver.cpp:241]     Train net output #0: loss = 1.279 (* 1 = 1.279 loss)
I1029 00:21:57.669864 12802 sgd_solver.cpp:105] Iteration 25800, lr = 0.000980594
I1029 00:22:28.458088 12802 solver.cpp:222] Iteration 25840 (1.29923 iter/s, 30.7875s/40 iters), loss = 1.32901
I1029 00:22:28.458287 12802 solver.cpp:241]     Train net output #0: loss = 1.32901 (* 1 = 1.32901 loss)
I1029 00:22:28.458320 12802 sgd_solver.cpp:105] Iteration 25840, lr = 0.000977069
I1029 00:22:58.784278 12802 solver.cpp:222] Iteration 25880 (1.31903 iter/s, 30.3253s/40 iters), loss = 1.44077
I1029 00:22:58.784458 12802 solver.cpp:241]     Train net output #0: loss = 1.44077 (* 1 = 1.44077 loss)
I1029 00:22:58.784476 12802 sgd_solver.cpp:105] Iteration 25880, lr = 0.000973558
I1029 00:23:28.385673 12802 solver.cpp:222] Iteration 25920 (1.35133 iter/s, 29.6005s/40 iters), loss = 1.30432
I1029 00:23:28.385736 12802 solver.cpp:241]     Train net output #0: loss = 1.30432 (* 1 = 1.30432 loss)
I1029 00:23:28.385749 12802 sgd_solver.cpp:105] Iteration 25920, lr = 0.000970059
I1029 00:23:58.192925 12802 solver.cpp:222] Iteration 25960 (1.34199 iter/s, 29.8065s/40 iters), loss = 1.39111
I1029 00:23:58.193156 12802 solver.cpp:241]     Train net output #0: loss = 1.39111 (* 1 = 1.39111 loss)
I1029 00:23:58.193171 12802 sgd_solver.cpp:105] Iteration 25960, lr = 0.000966573
I1029 00:24:27.297682 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_26000.caffemodel
I1029 00:24:27.440255 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_26000.solverstate
I1029 00:24:27.558125 12802 solver.cpp:334] Iteration 26000, Testing net (#0)
I1029 00:24:58.893201 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57984
I1029 00:24:58.893385 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80716
I1029 00:24:58.893401 12802 solver.cpp:401]     Test net output #2: loss = 1.85909 (* 1 = 1.85909 loss)
I1029 00:24:59.674163 12802 solver.cpp:222] Iteration 26000 (0.650623 iter/s, 61.4796s/40 iters), loss = 1.1282
I1029 00:24:59.674226 12802 solver.cpp:241]     Train net output #0: loss = 1.1282 (* 1 = 1.1282 loss)
I1029 00:24:59.674243 12802 sgd_solver.cpp:105] Iteration 26000, lr = 0.000963099
I1029 00:25:29.656430 12802 solver.cpp:222] Iteration 26040 (1.33416 iter/s, 29.9815s/40 iters), loss = 1.48217
I1029 00:25:29.656625 12802 solver.cpp:241]     Train net output #0: loss = 1.48217 (* 1 = 1.48217 loss)
I1029 00:25:29.656642 12802 sgd_solver.cpp:105] Iteration 26040, lr = 0.000959638
I1029 00:25:59.298516 12802 solver.cpp:222] Iteration 26080 (1.34947 iter/s, 29.6412s/40 iters), loss = 1.41195
I1029 00:25:59.298576 12802 solver.cpp:241]     Train net output #0: loss = 1.41195 (* 1 = 1.41195 loss)
I1029 00:25:59.298591 12802 sgd_solver.cpp:105] Iteration 26080, lr = 0.00095619
I1029 00:26:17.889027 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 00:26:28.946112 12802 solver.cpp:222] Iteration 26120 (1.34922 iter/s, 29.6468s/40 iters), loss = 1.30911
I1029 00:26:28.946171 12802 solver.cpp:241]     Train net output #0: loss = 1.30911 (* 1 = 1.30911 loss)
I1029 00:26:28.946185 12802 sgd_solver.cpp:105] Iteration 26120, lr = 0.000952753
I1029 00:26:58.938047 12802 solver.cpp:222] Iteration 26160 (1.33373 iter/s, 29.9912s/40 iters), loss = 1.47085
I1029 00:26:58.938225 12802 solver.cpp:241]     Train net output #0: loss = 1.47085 (* 1 = 1.47085 loss)
I1029 00:26:58.938239 12802 sgd_solver.cpp:105] Iteration 26160, lr = 0.000949329
I1029 00:27:34.704102 12802 solver.cpp:222] Iteration 26200 (1.11841 iter/s, 35.765s/40 iters), loss = 1.75884
I1029 00:27:34.704249 12802 solver.cpp:241]     Train net output #0: loss = 1.75884 (* 1 = 1.75884 loss)
I1029 00:27:34.704264 12802 sgd_solver.cpp:105] Iteration 26200, lr = 0.000945917
I1029 00:28:32.770067 12802 solver.cpp:222] Iteration 26240 (0.68889 iter/s, 58.0645s/40 iters), loss = 1.25161
I1029 00:28:32.770246 12802 solver.cpp:241]     Train net output #0: loss = 1.25161 (* 1 = 1.25161 loss)
I1029 00:28:32.770264 12802 sgd_solver.cpp:105] Iteration 26240, lr = 0.000942518
I1029 00:29:59.726840 12802 solver.cpp:222] Iteration 26280 (0.46001 iter/s, 86.9546s/40 iters), loss = 1.18871
I1029 00:29:59.727051 12802 solver.cpp:241]     Train net output #0: loss = 1.18871 (* 1 = 1.18871 loss)
I1029 00:29:59.727072 12802 sgd_solver.cpp:105] Iteration 26280, lr = 0.000939131
I1029 00:30:29.752450 12802 solver.cpp:222] Iteration 26320 (1.33224 iter/s, 30.0247s/40 iters), loss = 1.5906
I1029 00:30:29.752622 12802 solver.cpp:241]     Train net output #0: loss = 1.5906 (* 1 = 1.5906 loss)
I1029 00:30:29.752638 12802 sgd_solver.cpp:105] Iteration 26320, lr = 0.000935756
I1029 00:30:59.900027 12802 solver.cpp:222] Iteration 26360 (1.32684 iter/s, 30.1467s/40 iters), loss = 1.64455
I1029 00:30:59.900212 12802 solver.cpp:241]     Train net output #0: loss = 1.64455 (* 1 = 1.64455 loss)
I1029 00:30:59.900228 12802 sgd_solver.cpp:105] Iteration 26360, lr = 0.000932393
I1029 00:31:29.701369 12802 solver.cpp:222] Iteration 26400 (1.34226 iter/s, 29.8004s/40 iters), loss = 1.41674
I1029 00:31:29.701433 12802 solver.cpp:241]     Train net output #0: loss = 1.41674 (* 1 = 1.41674 loss)
I1029 00:31:29.701447 12802 sgd_solver.cpp:105] Iteration 26400, lr = 0.000929042
I1029 00:31:59.486656 12802 solver.cpp:222] Iteration 26440 (1.34298 iter/s, 29.7845s/40 iters), loss = 1.49358
I1029 00:31:59.486861 12802 solver.cpp:241]     Train net output #0: loss = 1.49358 (* 1 = 1.49358 loss)
I1029 00:31:59.486878 12802 sgd_solver.cpp:105] Iteration 26440, lr = 0.000925703
I1029 00:32:29.408084 12802 solver.cpp:222] Iteration 26480 (1.33688 iter/s, 29.9205s/40 iters), loss = 1.63791
I1029 00:32:29.408144 12802 solver.cpp:241]     Train net output #0: loss = 1.63791 (* 1 = 1.63791 loss)
I1029 00:32:29.408160 12802 sgd_solver.cpp:105] Iteration 26480, lr = 0.000922376
I1029 00:32:43.528368 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_26500.caffemodel
I1029 00:32:43.670220 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_26500.solverstate
I1029 00:32:43.793880 12802 solver.cpp:334] Iteration 26500, Testing net (#0)
I1029 00:33:14.930416 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 00:33:15.142094 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57872
I1029 00:33:15.142141 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80988
I1029 00:33:15.142153 12802 solver.cpp:401]     Test net output #2: loss = 1.8903 (* 1 = 1.8903 loss)
I1029 00:33:30.858986 12802 solver.cpp:222] Iteration 26520 (0.650942 iter/s, 61.4494s/40 iters), loss = 1.66251
I1029 00:33:30.859045 12802 solver.cpp:241]     Train net output #0: loss = 1.66251 (* 1 = 1.66251 loss)
I1029 00:33:30.859062 12802 sgd_solver.cpp:105] Iteration 26520, lr = 0.000919061
I1029 00:34:00.992996 12802 solver.cpp:222] Iteration 26560 (1.32744 iter/s, 30.1332s/40 iters), loss = 1.47208
I1029 00:34:00.993263 12802 solver.cpp:241]     Train net output #0: loss = 1.47208 (* 1 = 1.47208 loss)
I1029 00:34:00.993280 12802 sgd_solver.cpp:105] Iteration 26560, lr = 0.000915759
I1029 00:34:30.720780 12802 solver.cpp:222] Iteration 26600 (1.34559 iter/s, 29.7268s/40 iters), loss = 1.36429
I1029 00:34:30.720840 12802 solver.cpp:241]     Train net output #0: loss = 1.36429 (* 1 = 1.36429 loss)
I1029 00:34:30.720856 12802 sgd_solver.cpp:105] Iteration 26600, lr = 0.000912467
I1029 00:35:08.580687 12802 solver.cpp:222] Iteration 26640 (1.05655 iter/s, 37.8589s/40 iters), loss = 1.63337
I1029 00:35:08.580896 12802 solver.cpp:241]     Train net output #0: loss = 1.63337 (* 1 = 1.63337 loss)
I1029 00:35:08.580914 12802 sgd_solver.cpp:105] Iteration 26640, lr = 0.000909188
I1029 00:35:59.783668 12802 solver.cpp:222] Iteration 26680 (0.781227 iter/s, 51.2015s/40 iters), loss = 1.43576
I1029 00:35:59.783855 12802 solver.cpp:241]     Train net output #0: loss = 1.43576 (* 1 = 1.43576 loss)
I1029 00:35:59.783876 12802 sgd_solver.cpp:105] Iteration 26680, lr = 0.000905921
I1029 00:36:30.821970 12802 solver.cpp:222] Iteration 26720 (1.28877 iter/s, 31.0374s/40 iters), loss = 1.50521
I1029 00:36:30.822187 12802 solver.cpp:241]     Train net output #0: loss = 1.50521 (* 1 = 1.50521 loss)
I1029 00:36:30.822206 12802 sgd_solver.cpp:105] Iteration 26720, lr = 0.000902665
I1029 00:37:00.802110 12802 solver.cpp:222] Iteration 26760 (1.33426 iter/s, 29.9792s/40 iters), loss = 1.58273
I1029 00:37:00.802168 12802 solver.cpp:241]     Train net output #0: loss = 1.58273 (* 1 = 1.58273 loss)
I1029 00:37:00.802186 12802 sgd_solver.cpp:105] Iteration 26760, lr = 0.000899421
I1029 00:37:30.431774 12802 solver.cpp:222] Iteration 26800 (1.35003 iter/s, 29.6289s/40 iters), loss = 1.28789
I1029 00:37:30.432340 12802 solver.cpp:241]     Train net output #0: loss = 1.28789 (* 1 = 1.28789 loss)
I1029 00:37:30.432358 12802 sgd_solver.cpp:105] Iteration 26800, lr = 0.000896189
I1029 00:38:00.562338 12802 solver.cpp:222] Iteration 26840 (1.32761 iter/s, 30.1293s/40 iters), loss = 1.35223
I1029 00:38:00.562531 12802 solver.cpp:241]     Train net output #0: loss = 1.35223 (* 1 = 1.35223 loss)
I1029 00:38:00.562548 12802 sgd_solver.cpp:105] Iteration 26840, lr = 0.000892968
I1029 00:38:30.722048 12802 solver.cpp:222] Iteration 26880 (1.32631 iter/s, 30.1588s/40 iters), loss = 1.66852
I1029 00:38:30.722177 12802 solver.cpp:241]     Train net output #0: loss = 1.66852 (* 1 = 1.66852 loss)
I1029 00:38:30.722193 12802 sgd_solver.cpp:105] Iteration 26880, lr = 0.000889759
I1029 00:39:00.260545 12802 solver.cpp:222] Iteration 26920 (1.3542 iter/s, 29.5377s/40 iters), loss = 1.35244
I1029 00:39:00.260610 12802 solver.cpp:241]     Train net output #0: loss = 1.35244 (* 1 = 1.35244 loss)
I1029 00:39:00.260627 12802 sgd_solver.cpp:105] Iteration 26920, lr = 0.000886561
I1029 00:39:30.190016 12802 solver.cpp:222] Iteration 26960 (1.33651 iter/s, 29.9287s/40 iters), loss = 1.5629
I1029 00:39:30.190120 12802 solver.cpp:241]     Train net output #0: loss = 1.5629 (* 1 = 1.5629 loss)
I1029 00:39:30.190137 12802 sgd_solver.cpp:105] Iteration 26960, lr = 0.000883375
I1029 00:39:59.066610 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_27000.caffemodel
I1029 00:39:59.216230 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_27000.solverstate
I1029 00:39:59.340342 12802 solver.cpp:334] Iteration 27000, Testing net (#0)
I1029 00:40:30.599009 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5802
I1029 00:40:30.599241 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8058
I1029 00:40:30.599257 12802 solver.cpp:401]     Test net output #2: loss = 1.86537 (* 1 = 1.86537 loss)
I1029 00:40:31.351953 12802 solver.cpp:222] Iteration 27000 (0.654018 iter/s, 61.1604s/40 iters), loss = 1.85553
I1029 00:40:31.352016 12802 solver.cpp:241]     Train net output #0: loss = 1.85553 (* 1 = 1.85553 loss)
I1029 00:40:31.352032 12802 sgd_solver.cpp:105] Iteration 27000, lr = 0.0008802
I1029 00:41:00.899518 12802 solver.cpp:222] Iteration 27040 (1.35379 iter/s, 29.5468s/40 iters), loss = 1.03105
I1029 00:41:00.899612 12802 solver.cpp:241]     Train net output #0: loss = 1.03105 (* 1 = 1.03105 loss)
I1029 00:41:00.899628 12802 sgd_solver.cpp:105] Iteration 27040, lr = 0.000877037
I1029 00:41:30.413846 12802 solver.cpp:222] Iteration 27080 (1.35531 iter/s, 29.5135s/40 iters), loss = 1.53575
I1029 00:41:30.413906 12802 solver.cpp:241]     Train net output #0: loss = 1.53575 (* 1 = 1.53575 loss)
I1029 00:41:30.413923 12802 sgd_solver.cpp:105] Iteration 27080, lr = 0.000873885
I1029 00:41:59.938148 12802 solver.cpp:222] Iteration 27120 (1.35485 iter/s, 29.5235s/40 iters), loss = 1.27339
I1029 00:41:59.938239 12802 solver.cpp:241]     Train net output #0: loss = 1.27339 (* 1 = 1.27339 loss)
I1029 00:41:59.938256 12802 sgd_solver.cpp:105] Iteration 27120, lr = 0.000870745
I1029 00:42:29.548770 12802 solver.cpp:222] Iteration 27160 (1.3509 iter/s, 29.6098s/40 iters), loss = 1.22092
I1029 00:42:29.548830 12802 solver.cpp:241]     Train net output #0: loss = 1.22092 (* 1 = 1.22092 loss)
I1029 00:42:29.548844 12802 sgd_solver.cpp:105] Iteration 27160, lr = 0.000867615
I1029 00:42:59.386170 12802 solver.cpp:222] Iteration 27200 (1.34063 iter/s, 29.8366s/40 iters), loss = 1.20688
I1029 00:42:59.386400 12802 solver.cpp:241]     Train net output #0: loss = 1.20688 (* 1 = 1.20688 loss)
I1029 00:42:59.386418 12802 sgd_solver.cpp:105] Iteration 27200, lr = 0.000864497
I1029 00:43:29.383229 12802 solver.cpp:222] Iteration 27240 (1.33351 iter/s, 29.9961s/40 iters), loss = 1.40353
I1029 00:43:29.383291 12802 solver.cpp:241]     Train net output #0: loss = 1.40353 (* 1 = 1.40353 loss)
I1029 00:43:29.383304 12802 sgd_solver.cpp:105] Iteration 27240, lr = 0.00086139
I1029 00:44:03.892241 12802 solver.cpp:222] Iteration 27280 (1.15915 iter/s, 34.5081s/40 iters), loss = 1.61436
I1029 00:44:03.892412 12802 solver.cpp:241]     Train net output #0: loss = 1.61436 (* 1 = 1.61436 loss)
I1029 00:44:03.892426 12802 sgd_solver.cpp:105] Iteration 27280, lr = 0.000858295
I1029 00:44:34.531540 12802 solver.cpp:222] Iteration 27320 (1.30555 iter/s, 30.6384s/40 iters), loss = 1.54665
I1029 00:44:34.531743 12802 solver.cpp:241]     Train net output #0: loss = 1.54665 (* 1 = 1.54665 loss)
I1029 00:44:34.531759 12802 sgd_solver.cpp:105] Iteration 27320, lr = 0.00085521
I1029 00:45:59.673111 12802 solver.cpp:222] Iteration 27360 (0.469818 iter/s, 85.1394s/40 iters), loss = 1.44127
I1029 00:45:59.673315 12802 solver.cpp:241]     Train net output #0: loss = 1.44127 (* 1 = 1.44127 loss)
I1029 00:45:59.673331 12802 sgd_solver.cpp:105] Iteration 27360, lr = 0.000852137
I1029 00:46:56.026779 12802 solver.cpp:222] Iteration 27400 (0.709822 iter/s, 56.3522s/40 iters), loss = 1.28467
I1029 00:46:56.027184 12802 solver.cpp:241]     Train net output #0: loss = 1.28467 (* 1 = 1.28467 loss)
I1029 00:46:56.027201 12802 sgd_solver.cpp:105] Iteration 27400, lr = 0.000849074
I1029 00:47:27.839035 12802 solver.cpp:222] Iteration 27440 (1.25742 iter/s, 31.8111s/40 iters), loss = 1.28435
I1029 00:47:27.839188 12802 solver.cpp:241]     Train net output #0: loss = 1.28435 (* 1 = 1.28435 loss)
I1029 00:47:27.839206 12802 sgd_solver.cpp:105] Iteration 27440, lr = 0.000846023
I1029 00:48:09.315148 12802 solver.cpp:222] Iteration 27480 (0.964436 iter/s, 41.475s/40 iters), loss = 1.76811
I1029 00:48:09.315338 12802 solver.cpp:241]     Train net output #0: loss = 1.76811 (* 1 = 1.76811 loss)
I1029 00:48:09.315352 12802 sgd_solver.cpp:105] Iteration 27480, lr = 0.000842982
I1029 00:48:23.441184 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_27500.caffemodel
I1029 00:48:23.589731 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_27500.solverstate
I1029 00:48:23.707262 12802 solver.cpp:334] Iteration 27500, Testing net (#0)
I1029 00:48:55.172803 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 00:48:55.378945 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58032
I1029 00:48:55.378995 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81072
I1029 00:48:55.379005 12802 solver.cpp:401]     Test net output #2: loss = 1.85466 (* 1 = 1.85466 loss)
I1029 00:49:10.985502 12802 solver.cpp:222] Iteration 27520 (0.648627 iter/s, 61.6687s/40 iters), loss = 1.27506
I1029 00:49:10.985561 12802 solver.cpp:241]     Train net output #0: loss = 1.27506 (* 1 = 1.27506 loss)
I1029 00:49:10.985577 12802 sgd_solver.cpp:105] Iteration 27520, lr = 0.000839953
I1029 00:49:40.676559 12802 solver.cpp:222] Iteration 27560 (1.34724 iter/s, 29.6903s/40 iters), loss = 1.3631
I1029 00:49:40.676748 12802 solver.cpp:241]     Train net output #0: loss = 1.3631 (* 1 = 1.3631 loss)
I1029 00:49:40.676765 12802 sgd_solver.cpp:105] Iteration 27560, lr = 0.000836934
I1029 00:50:10.678385 12802 solver.cpp:222] Iteration 27600 (1.33329 iter/s, 30.0009s/40 iters), loss = 1.40478
I1029 00:50:10.678578 12802 solver.cpp:241]     Train net output #0: loss = 1.40478 (* 1 = 1.40478 loss)
I1029 00:50:10.678596 12802 sgd_solver.cpp:105] Iteration 27600, lr = 0.000833927
I1029 00:50:40.428930 12802 solver.cpp:222] Iteration 27640 (1.34455 iter/s, 29.7496s/40 iters), loss = 1.55924
I1029 00:50:40.428990 12802 solver.cpp:241]     Train net output #0: loss = 1.55924 (* 1 = 1.55924 loss)
I1029 00:50:40.429011 12802 sgd_solver.cpp:105] Iteration 27640, lr = 0.00083093
I1029 00:51:10.020936 12802 solver.cpp:222] Iteration 27680 (1.35175 iter/s, 29.5912s/40 iters), loss = 1.55501
I1029 00:51:10.021122 12802 solver.cpp:241]     Train net output #0: loss = 1.55501 (* 1 = 1.55501 loss)
I1029 00:51:10.021140 12802 sgd_solver.cpp:105] Iteration 27680, lr = 0.000827943
I1029 00:51:39.542925 12802 solver.cpp:222] Iteration 27720 (1.35496 iter/s, 29.5211s/40 iters), loss = 1.31582
I1029 00:51:39.542986 12802 solver.cpp:241]     Train net output #0: loss = 1.31582 (* 1 = 1.31582 loss)
I1029 00:51:39.542999 12802 sgd_solver.cpp:105] Iteration 27720, lr = 0.000824968
I1029 00:52:09.129575 12802 solver.cpp:222] Iteration 27760 (1.352 iter/s, 29.5859s/40 iters), loss = 1.26361
I1029 00:52:09.129766 12802 solver.cpp:241]     Train net output #0: loss = 1.26361 (* 1 = 1.26361 loss)
I1029 00:52:09.129783 12802 sgd_solver.cpp:105] Iteration 27760, lr = 0.000822003
I1029 00:52:39.595976 12802 solver.cpp:222] Iteration 27800 (1.31296 iter/s, 30.4655s/40 iters), loss = 1.29166
I1029 00:52:39.596150 12802 solver.cpp:241]     Train net output #0: loss = 1.29166 (* 1 = 1.29166 loss)
I1029 00:52:39.596168 12802 sgd_solver.cpp:105] Iteration 27800, lr = 0.000819049
I1029 00:53:11.849534 12802 solver.cpp:222] Iteration 27840 (1.24021 iter/s, 32.2526s/40 iters), loss = 1.54766
I1029 00:53:11.849701 12802 solver.cpp:241]     Train net output #0: loss = 1.54766 (* 1 = 1.54766 loss)
I1029 00:53:11.849719 12802 sgd_solver.cpp:105] Iteration 27840, lr = 0.000816106
I1029 00:53:41.921583 12802 solver.cpp:222] Iteration 27880 (1.33018 iter/s, 30.0712s/40 iters), loss = 1.53179
I1029 00:53:41.921759 12802 solver.cpp:241]     Train net output #0: loss = 1.53179 (* 1 = 1.53179 loss)
I1029 00:53:41.921777 12802 sgd_solver.cpp:105] Iteration 27880, lr = 0.000813173
I1029 00:54:12.476099 12802 solver.cpp:222] Iteration 27920 (1.30917 iter/s, 30.5536s/40 iters), loss = 1.52861
I1029 00:54:12.476297 12802 solver.cpp:241]     Train net output #0: loss = 1.52861 (* 1 = 1.52861 loss)
I1029 00:54:12.476315 12802 sgd_solver.cpp:105] Iteration 27920, lr = 0.00081025
I1029 00:54:42.079828 12802 solver.cpp:222] Iteration 27960 (1.35122 iter/s, 29.6028s/40 iters), loss = 1.13595
I1029 00:54:42.079886 12802 solver.cpp:241]     Train net output #0: loss = 1.13595 (* 1 = 1.13595 loss)
I1029 00:54:42.079900 12802 sgd_solver.cpp:105] Iteration 27960, lr = 0.000807338
I1029 00:55:10.976541 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_28000.caffemodel
I1029 00:55:11.477677 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_28000.solverstate
I1029 00:55:12.140606 12802 solver.cpp:334] Iteration 28000, Testing net (#0)
I1029 00:55:43.443853 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58268
I1029 00:55:43.443950 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8066
I1029 00:55:43.443964 12802 solver.cpp:401]     Test net output #2: loss = 1.86162 (* 1 = 1.86162 loss)
I1029 00:55:44.200217 12802 solver.cpp:222] Iteration 28000 (0.643927 iter/s, 62.1189s/40 iters), loss = 1.56572
I1029 00:55:44.200275 12802 solver.cpp:241]     Train net output #0: loss = 1.56572 (* 1 = 1.56572 loss)
I1029 00:55:44.200291 12802 sgd_solver.cpp:105] Iteration 28000, lr = 0.000804437
I1029 00:56:13.815945 12802 solver.cpp:222] Iteration 28040 (1.35067 iter/s, 29.615s/40 iters), loss = 1.7436
I1029 00:56:13.816082 12802 solver.cpp:241]     Train net output #0: loss = 1.7436 (* 1 = 1.7436 loss)
I1029 00:56:13.816098 12802 sgd_solver.cpp:105] Iteration 28040, lr = 0.000801546
I1029 00:56:43.855883 12802 solver.cpp:222] Iteration 28080 (1.3316 iter/s, 30.0391s/40 iters), loss = 1.83967
I1029 00:56:43.856065 12802 solver.cpp:241]     Train net output #0: loss = 1.83967 (* 1 = 1.83967 loss)
I1029 00:56:43.856082 12802 sgd_solver.cpp:105] Iteration 28080, lr = 0.000798665
I1029 00:57:13.488595 12802 solver.cpp:222] Iteration 28120 (1.3499 iter/s, 29.6318s/40 iters), loss = 1.79547
I1029 00:57:13.488654 12802 solver.cpp:241]     Train net output #0: loss = 1.79547 (* 1 = 1.79547 loss)
I1029 00:57:13.488667 12802 sgd_solver.cpp:105] Iteration 28120, lr = 0.000795795
I1029 00:57:43.066921 12802 solver.cpp:222] Iteration 28160 (1.35238 iter/s, 29.5776s/40 iters), loss = 1.5377
I1029 00:57:43.067162 12802 solver.cpp:241]     Train net output #0: loss = 1.5377 (* 1 = 1.5377 loss)
I1029 00:57:43.067178 12802 sgd_solver.cpp:105] Iteration 28160, lr = 0.000792935
I1029 00:58:12.734033 12802 solver.cpp:222] Iteration 28200 (1.34834 iter/s, 29.6662s/40 iters), loss = 1.58957
I1029 00:58:12.734098 12802 solver.cpp:241]     Train net output #0: loss = 1.58957 (* 1 = 1.58957 loss)
I1029 00:58:12.734113 12802 sgd_solver.cpp:105] Iteration 28200, lr = 0.000790085
I1029 00:58:42.683625 12802 solver.cpp:222] Iteration 28240 (1.33561 iter/s, 29.9488s/40 iters), loss = 1.46276
I1029 00:58:42.683814 12802 solver.cpp:241]     Train net output #0: loss = 1.46276 (* 1 = 1.46276 loss)
I1029 00:58:42.683831 12802 sgd_solver.cpp:105] Iteration 28240, lr = 0.000787246
I1029 00:59:13.221357 12802 solver.cpp:222] Iteration 28280 (1.30989 iter/s, 30.5368s/40 iters), loss = 1.43857
I1029 00:59:13.221545 12802 solver.cpp:241]     Train net output #0: loss = 1.43857 (* 1 = 1.43857 loss)
I1029 00:59:13.221565 12802 sgd_solver.cpp:105] Iteration 28280, lr = 0.000784417
I1029 00:59:43.614578 12802 solver.cpp:222] Iteration 28320 (1.31612 iter/s, 30.3923s/40 iters), loss = 1.87552
I1029 00:59:43.614755 12802 solver.cpp:241]     Train net output #0: loss = 1.87552 (* 1 = 1.87552 loss)
I1029 00:59:43.614773 12802 sgd_solver.cpp:105] Iteration 28320, lr = 0.000781598
I1029 01:00:14.701239 12802 solver.cpp:222] Iteration 28360 (1.28676 iter/s, 31.0857s/40 iters), loss = 1.71721
I1029 01:00:14.701459 12802 solver.cpp:241]     Train net output #0: loss = 1.71721 (* 1 = 1.71721 loss)
I1029 01:00:14.701483 12802 sgd_solver.cpp:105] Iteration 28360, lr = 0.000778789
I1029 01:00:46.127171 12802 solver.cpp:222] Iteration 28400 (1.27287 iter/s, 31.425s/40 iters), loss = 1.18577
I1029 01:00:46.127401 12802 solver.cpp:241]     Train net output #0: loss = 1.18577 (* 1 = 1.18577 loss)
I1029 01:00:46.127418 12802 sgd_solver.cpp:105] Iteration 28400, lr = 0.00077599
I1029 01:01:16.926503 12802 solver.cpp:222] Iteration 28440 (1.29877 iter/s, 30.7984s/40 iters), loss = 1.72056
I1029 01:01:16.926723 12802 solver.cpp:241]     Train net output #0: loss = 1.72056 (* 1 = 1.72056 loss)
I1029 01:01:16.926738 12802 sgd_solver.cpp:105] Iteration 28440, lr = 0.000773201
I1029 01:01:47.677814 12802 solver.cpp:222] Iteration 28480 (1.3008 iter/s, 30.7504s/40 iters), loss = 1.51003
I1029 01:01:47.678014 12802 solver.cpp:241]     Train net output #0: loss = 1.51003 (* 1 = 1.51003 loss)
I1029 01:01:47.678030 12802 sgd_solver.cpp:105] Iteration 28480, lr = 0.000770423
I1029 01:02:17.946382 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_28500.caffemodel
I1029 01:02:18.093969 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_28500.solverstate
I1029 01:02:18.221563 12802 solver.cpp:334] Iteration 28500, Testing net (#0)
I1029 01:02:49.346772 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 01:02:49.560952 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58236
I1029 01:02:49.561004 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.811519
I1029 01:02:49.561014 12802 solver.cpp:401]     Test net output #2: loss = 1.8548 (* 1 = 1.8548 loss)
I1029 01:03:09.531172 12802 solver.cpp:222] Iteration 28520 (0.488691 iter/s, 81.8513s/40 iters), loss = 1.03021
I1029 01:03:09.531231 12802 solver.cpp:241]     Train net output #0: loss = 1.03021 (* 1 = 1.03021 loss)
I1029 01:03:09.531249 12802 sgd_solver.cpp:105] Iteration 28520, lr = 0.000767654
I1029 01:03:40.815691 12802 solver.cpp:222] Iteration 28560 (1.27862 iter/s, 31.2837s/40 iters), loss = 1.39047
I1029 01:03:40.815913 12802 solver.cpp:241]     Train net output #0: loss = 1.39047 (* 1 = 1.39047 loss)
I1029 01:03:40.815944 12802 sgd_solver.cpp:105] Iteration 28560, lr = 0.000764895
I1029 01:04:11.500583 12802 solver.cpp:222] Iteration 28600 (1.30361 iter/s, 30.684s/40 iters), loss = 1.53004
I1029 01:04:11.500771 12802 solver.cpp:241]     Train net output #0: loss = 1.53004 (* 1 = 1.53004 loss)
I1029 01:04:11.500787 12802 sgd_solver.cpp:105] Iteration 28600, lr = 0.000762146
I1029 01:04:17.125571 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 01:04:41.461969 12802 solver.cpp:222] Iteration 28640 (1.33509 iter/s, 29.9605s/40 iters), loss = 1.45354
I1029 01:04:41.462031 12802 solver.cpp:241]     Train net output #0: loss = 1.45354 (* 1 = 1.45354 loss)
I1029 01:04:41.462045 12802 sgd_solver.cpp:105] Iteration 28640, lr = 0.000759407
I1029 01:05:11.483142 12802 solver.cpp:222] Iteration 28680 (1.33243 iter/s, 30.0204s/40 iters), loss = 1.29909
I1029 01:05:11.483314 12802 solver.cpp:241]     Train net output #0: loss = 1.29909 (* 1 = 1.29909 loss)
I1029 01:05:11.483330 12802 sgd_solver.cpp:105] Iteration 28680, lr = 0.000756678
I1029 01:05:42.396894 12802 solver.cpp:222] Iteration 28720 (1.29396 iter/s, 30.9128s/40 iters), loss = 1.3616
I1029 01:05:42.397078 12802 solver.cpp:241]     Train net output #0: loss = 1.3616 (* 1 = 1.3616 loss)
I1029 01:05:42.397092 12802 sgd_solver.cpp:105] Iteration 28720, lr = 0.000753959
I1029 01:06:13.551975 12802 solver.cpp:222] Iteration 28760 (1.28394 iter/s, 31.1542s/40 iters), loss = 1.20683
I1029 01:06:13.552158 12802 solver.cpp:241]     Train net output #0: loss = 1.20683 (* 1 = 1.20683 loss)
I1029 01:06:13.552176 12802 sgd_solver.cpp:105] Iteration 28760, lr = 0.000751249
I1029 01:06:44.072698 12802 solver.cpp:222] Iteration 28800 (1.31062 iter/s, 30.5198s/40 iters), loss = 1.46399
I1029 01:06:44.072906 12802 solver.cpp:241]     Train net output #0: loss = 1.46399 (* 1 = 1.46399 loss)
I1029 01:06:44.072927 12802 sgd_solver.cpp:105] Iteration 28800, lr = 0.000748549
I1029 01:07:16.873965 12802 solver.cpp:222] Iteration 28840 (1.2195 iter/s, 32.8003s/40 iters), loss = 1.20916
I1029 01:07:16.874213 12802 solver.cpp:241]     Train net output #0: loss = 1.20916 (* 1 = 1.20916 loss)
I1029 01:07:16.874231 12802 sgd_solver.cpp:105] Iteration 28840, lr = 0.000745859
I1029 01:07:47.028321 12802 solver.cpp:222] Iteration 28880 (1.32655 iter/s, 30.1534s/40 iters), loss = 1.24171
I1029 01:07:47.028537 12802 solver.cpp:241]     Train net output #0: loss = 1.24171 (* 1 = 1.24171 loss)
I1029 01:07:47.028553 12802 sgd_solver.cpp:105] Iteration 28880, lr = 0.000743179
I1029 01:08:17.012455 12802 solver.cpp:222] Iteration 28920 (1.33408 iter/s, 29.9832s/40 iters), loss = 1.25192
I1029 01:08:17.012516 12802 solver.cpp:241]     Train net output #0: loss = 1.25192 (* 1 = 1.25192 loss)
I1029 01:08:17.012531 12802 sgd_solver.cpp:105] Iteration 28920, lr = 0.000740508
I1029 01:08:52.995331 12802 solver.cpp:222] Iteration 28960 (1.11167 iter/s, 35.982s/40 iters), loss = 1.67524
I1029 01:08:52.995532 12802 solver.cpp:241]     Train net output #0: loss = 1.67524 (* 1 = 1.67524 loss)
I1029 01:08:52.995549 12802 sgd_solver.cpp:105] Iteration 28960, lr = 0.000737846
I1029 01:09:22.437441 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_29000.caffemodel
I1029 01:09:22.605141 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_29000.solverstate
I1029 01:09:22.718731 12802 solver.cpp:334] Iteration 29000, Testing net (#0)
I1029 01:09:54.006960 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58336
I1029 01:09:54.007169 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80512
I1029 01:09:54.007182 12802 solver.cpp:401]     Test net output #2: loss = 1.88155 (* 1 = 1.88155 loss)
I1029 01:09:54.762140 12802 solver.cpp:222] Iteration 29000 (0.647614 iter/s, 61.7652s/40 iters), loss = 1.48782
I1029 01:09:54.762197 12802 solver.cpp:241]     Train net output #0: loss = 1.48782 (* 1 = 1.48782 loss)
I1029 01:09:54.762212 12802 sgd_solver.cpp:105] Iteration 29000, lr = 0.000735195
I1029 01:10:24.993989 12802 solver.cpp:222] Iteration 29040 (1.32314 iter/s, 30.2311s/40 iters), loss = 1.46877
I1029 01:10:24.994206 12802 solver.cpp:241]     Train net output #0: loss = 1.46877 (* 1 = 1.46877 loss)
I1029 01:10:24.994225 12802 sgd_solver.cpp:105] Iteration 29040, lr = 0.000732553
I1029 01:10:55.241914 12802 solver.cpp:222] Iteration 29080 (1.32245 iter/s, 30.247s/40 iters), loss = 1.37386
I1029 01:10:55.242101 12802 solver.cpp:241]     Train net output #0: loss = 1.37386 (* 1 = 1.37386 loss)
I1029 01:10:55.242118 12802 sgd_solver.cpp:105] Iteration 29080, lr = 0.00072992
I1029 01:11:27.660830 12802 solver.cpp:222] Iteration 29120 (1.23388 iter/s, 32.418s/40 iters), loss = 1.2341
I1029 01:11:27.661043 12802 solver.cpp:241]     Train net output #0: loss = 1.2341 (* 1 = 1.2341 loss)
I1029 01:11:27.661061 12802 sgd_solver.cpp:105] Iteration 29120, lr = 0.000727297
I1029 01:11:57.759443 12802 solver.cpp:222] Iteration 29160 (1.32901 iter/s, 30.0977s/40 iters), loss = 1.39513
I1029 01:11:57.759654 12802 solver.cpp:241]     Train net output #0: loss = 1.39513 (* 1 = 1.39513 loss)
I1029 01:11:57.759670 12802 sgd_solver.cpp:105] Iteration 29160, lr = 0.000724683
I1029 01:12:28.003070 12802 solver.cpp:222] Iteration 29200 (1.32263 iter/s, 30.2427s/40 iters), loss = 1.37145
I1029 01:12:28.003211 12802 solver.cpp:241]     Train net output #0: loss = 1.37145 (* 1 = 1.37145 loss)
I1029 01:12:28.003228 12802 sgd_solver.cpp:105] Iteration 29200, lr = 0.000722079
I1029 01:13:05.242715 12802 solver.cpp:222] Iteration 29240 (1.07415 iter/s, 37.2386s/40 iters), loss = 1.29339
I1029 01:13:05.242888 12802 solver.cpp:241]     Train net output #0: loss = 1.29339 (* 1 = 1.29339 loss)
I1029 01:13:05.242913 12802 sgd_solver.cpp:105] Iteration 29240, lr = 0.000719484
I1029 01:13:37.333407 12802 solver.cpp:222] Iteration 29280 (1.2465 iter/s, 32.0898s/40 iters), loss = 1.23489
I1029 01:13:37.333570 12802 solver.cpp:241]     Train net output #0: loss = 1.23489 (* 1 = 1.23489 loss)
I1029 01:13:37.333587 12802 sgd_solver.cpp:105] Iteration 29280, lr = 0.000716898
I1029 01:14:06.976130 12802 solver.cpp:222] Iteration 29320 (1.34944 iter/s, 29.6419s/40 iters), loss = 1.58199
I1029 01:14:06.976188 12802 solver.cpp:241]     Train net output #0: loss = 1.58199 (* 1 = 1.58199 loss)
I1029 01:14:06.976204 12802 sgd_solver.cpp:105] Iteration 29320, lr = 0.000714322
I1029 01:14:37.041330 12802 solver.cpp:222] Iteration 29360 (1.33048 iter/s, 30.0644s/40 iters), loss = 1.20605
I1029 01:14:37.041540 12802 solver.cpp:241]     Train net output #0: loss = 1.20605 (* 1 = 1.20605 loss)
I1029 01:14:37.041559 12802 sgd_solver.cpp:105] Iteration 29360, lr = 0.000711754
I1029 01:15:07.718106 12802 solver.cpp:222] Iteration 29400 (1.30396 iter/s, 30.6758s/40 iters), loss = 1.4683
I1029 01:15:07.718302 12802 solver.cpp:241]     Train net output #0: loss = 1.4683 (* 1 = 1.4683 loss)
I1029 01:15:07.718318 12802 sgd_solver.cpp:105] Iteration 29400, lr = 0.000709196
I1029 01:15:38.120749 12802 solver.cpp:222] Iteration 29440 (1.31571 iter/s, 30.4017s/40 iters), loss = 1.30579
I1029 01:15:38.120967 12802 solver.cpp:241]     Train net output #0: loss = 1.30579 (* 1 = 1.30579 loss)
I1029 01:15:38.120985 12802 sgd_solver.cpp:105] Iteration 29440, lr = 0.000706648
I1029 01:16:15.713928 12802 solver.cpp:222] Iteration 29480 (1.06405 iter/s, 37.5921s/40 iters), loss = 1.65972
I1029 01:16:15.714119 12802 solver.cpp:241]     Train net output #0: loss = 1.65972 (* 1 = 1.65972 loss)
I1029 01:16:15.714136 12802 sgd_solver.cpp:105] Iteration 29480, lr = 0.000704108
I1029 01:16:30.404860 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_29500.caffemodel
I1029 01:16:30.549566 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_29500.solverstate
I1029 01:16:30.659600 12802 solver.cpp:334] Iteration 29500, Testing net (#0)
I1029 01:17:01.789304 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 01:17:01.999568 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58112
I1029 01:17:01.999621 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.810759
I1029 01:17:01.999632 12802 solver.cpp:401]     Test net output #2: loss = 1.84902 (* 1 = 1.84902 loss)
I1029 01:17:17.989964 12802 solver.cpp:222] Iteration 29520 (0.642319 iter/s, 62.2744s/40 iters), loss = 1.42439
I1029 01:17:17.990027 12802 solver.cpp:241]     Train net output #0: loss = 1.42439 (* 1 = 1.42439 loss)
I1029 01:17:17.990044 12802 sgd_solver.cpp:105] Iteration 29520, lr = 0.000701578
I1029 01:17:47.836935 12802 solver.cpp:222] Iteration 29560 (1.3402 iter/s, 29.8462s/40 iters), loss = 1.2611
I1029 01:17:47.837134 12802 solver.cpp:241]     Train net output #0: loss = 1.2611 (* 1 = 1.2611 loss)
I1029 01:17:47.837152 12802 sgd_solver.cpp:105] Iteration 29560, lr = 0.000699056
I1029 01:18:17.383718 12802 solver.cpp:222] Iteration 29600 (1.35383 iter/s, 29.5459s/40 iters), loss = 1.52591
I1029 01:18:17.383774 12802 solver.cpp:241]     Train net output #0: loss = 1.52591 (* 1 = 1.52591 loss)
I1029 01:18:17.383790 12802 sgd_solver.cpp:105] Iteration 29600, lr = 0.000696544
I1029 01:18:46.949458 12802 solver.cpp:222] Iteration 29640 (1.35295 iter/s, 29.565s/40 iters), loss = 1.35448
I1029 01:18:46.949610 12802 solver.cpp:241]     Train net output #0: loss = 1.35448 (* 1 = 1.35448 loss)
I1029 01:18:46.949627 12802 sgd_solver.cpp:105] Iteration 29640, lr = 0.000694041
I1029 01:19:16.547976 12802 solver.cpp:222] Iteration 29680 (1.35146 iter/s, 29.5977s/40 iters), loss = 1.35565
I1029 01:19:16.548033 12802 solver.cpp:241]     Train net output #0: loss = 1.35565 (* 1 = 1.35565 loss)
I1029 01:19:16.548046 12802 sgd_solver.cpp:105] Iteration 29680, lr = 0.000691547
I1029 01:19:46.159888 12802 solver.cpp:222] Iteration 29720 (1.35084 iter/s, 29.6111s/40 iters), loss = 1.34074
I1029 01:19:46.160051 12802 solver.cpp:241]     Train net output #0: loss = 1.34074 (* 1 = 1.34074 loss)
I1029 01:19:46.160068 12802 sgd_solver.cpp:105] Iteration 29720, lr = 0.000689061
I1029 01:20:15.964205 12802 solver.cpp:222] Iteration 29760 (1.34213 iter/s, 29.8034s/40 iters), loss = 1.3189
I1029 01:20:15.964269 12802 solver.cpp:241]     Train net output #0: loss = 1.3189 (* 1 = 1.3189 loss)
I1029 01:20:15.964285 12802 sgd_solver.cpp:105] Iteration 29760, lr = 0.000686585
I1029 01:20:45.581099 12802 solver.cpp:222] Iteration 29800 (1.35062 iter/s, 29.6161s/40 iters), loss = 1.64987
I1029 01:20:45.581339 12802 solver.cpp:241]     Train net output #0: loss = 1.64987 (* 1 = 1.64987 loss)
I1029 01:20:45.581357 12802 sgd_solver.cpp:105] Iteration 29800, lr = 0.000684118
I1029 01:21:15.261390 12802 solver.cpp:222] Iteration 29840 (1.34774 iter/s, 29.6793s/40 iters), loss = 1.36879
I1029 01:21:15.261448 12802 solver.cpp:241]     Train net output #0: loss = 1.36879 (* 1 = 1.36879 loss)
I1029 01:21:15.261464 12802 sgd_solver.cpp:105] Iteration 29840, lr = 0.000681659
I1029 01:21:44.833237 12802 solver.cpp:222] Iteration 29880 (1.35267 iter/s, 29.5711s/40 iters), loss = 1.32459
I1029 01:21:44.833420 12802 solver.cpp:241]     Train net output #0: loss = 1.32459 (* 1 = 1.32459 loss)
I1029 01:21:44.833434 12802 sgd_solver.cpp:105] Iteration 29880, lr = 0.000679209
I1029 01:22:14.455668 12802 solver.cpp:222] Iteration 29920 (1.35037 iter/s, 29.6215s/40 iters), loss = 1.47753
I1029 01:22:14.455730 12802 solver.cpp:241]     Train net output #0: loss = 1.47753 (* 1 = 1.47753 loss)
I1029 01:22:14.455746 12802 sgd_solver.cpp:105] Iteration 29920, lr = 0.000676768
I1029 01:22:44.060169 12802 solver.cpp:222] Iteration 29960 (1.35118 iter/s, 29.6037s/40 iters), loss = 1.20928
I1029 01:22:44.060277 12802 solver.cpp:241]     Train net output #0: loss = 1.20928 (* 1 = 1.20928 loss)
I1029 01:22:44.060293 12802 sgd_solver.cpp:105] Iteration 29960, lr = 0.000674336
I1029 01:23:13.759589 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_30000.caffemodel
I1029 01:23:13.906038 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_30000.solverstate
I1029 01:23:14.030195 12802 solver.cpp:334] Iteration 30000, Testing net (#0)
I1029 01:23:45.407475 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58132
I1029 01:23:45.407650 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80744
I1029 01:23:45.407665 12802 solver.cpp:401]     Test net output #2: loss = 1.85821 (* 1 = 1.85821 loss)
I1029 01:23:46.157675 12802 solver.cpp:222] Iteration 30000 (0.644165 iter/s, 62.0959s/40 iters), loss = 1.52115
I1029 01:23:46.157734 12802 solver.cpp:241]     Train net output #0: loss = 1.52115 (* 1 = 1.52115 loss)
I1029 01:23:46.157750 12802 sgd_solver.cpp:105] Iteration 30000, lr = 0.000671913
I1029 01:24:16.837335 12802 solver.cpp:222] Iteration 30040 (1.30383 iter/s, 30.6789s/40 iters), loss = 1.59653
I1029 01:24:16.837489 12802 solver.cpp:241]     Train net output #0: loss = 1.59653 (* 1 = 1.59653 loss)
I1029 01:24:16.837507 12802 sgd_solver.cpp:105] Iteration 30040, lr = 0.000669498
I1029 01:24:47.393510 12802 solver.cpp:222] Iteration 30080 (1.3091 iter/s, 30.5553s/40 iters), loss = 1.54942
I1029 01:24:47.393662 12802 solver.cpp:241]     Train net output #0: loss = 1.54942 (* 1 = 1.54942 loss)
I1029 01:24:47.393678 12802 sgd_solver.cpp:105] Iteration 30080, lr = 0.000667092
I1029 01:25:17.899574 12802 solver.cpp:222] Iteration 30120 (1.31125 iter/s, 30.5052s/40 iters), loss = 1.32414
I1029 01:25:17.899713 12802 solver.cpp:241]     Train net output #0: loss = 1.32414 (* 1 = 1.32414 loss)
I1029 01:25:17.899730 12802 sgd_solver.cpp:105] Iteration 30120, lr = 0.000664695
I1029 01:25:48.518241 12802 solver.cpp:222] Iteration 30160 (1.30643 iter/s, 30.6178s/40 iters), loss = 1.50606
I1029 01:25:48.518426 12802 solver.cpp:241]     Train net output #0: loss = 1.50606 (* 1 = 1.50606 loss)
I1029 01:25:48.518443 12802 sgd_solver.cpp:105] Iteration 30160, lr = 0.000662306
I1029 01:26:18.448407 12802 solver.cpp:222] Iteration 30200 (1.33648 iter/s, 29.9293s/40 iters), loss = 1.45918
I1029 01:26:18.448468 12802 solver.cpp:241]     Train net output #0: loss = 1.45918 (* 1 = 1.45918 loss)
I1029 01:26:18.448483 12802 sgd_solver.cpp:105] Iteration 30200, lr = 0.000659926
I1029 01:26:48.025966 12802 solver.cpp:222] Iteration 30240 (1.35241 iter/s, 29.5768s/40 iters), loss = 1.47827
I1029 01:26:48.026197 12802 solver.cpp:241]     Train net output #0: loss = 1.47827 (* 1 = 1.47827 loss)
I1029 01:26:48.026216 12802 sgd_solver.cpp:105] Iteration 30240, lr = 0.000657554
I1029 01:27:17.726003 12802 solver.cpp:222] Iteration 30280 (1.34684 iter/s, 29.6991s/40 iters), loss = 1.44844
I1029 01:27:17.726059 12802 solver.cpp:241]     Train net output #0: loss = 1.44844 (* 1 = 1.44844 loss)
I1029 01:27:17.726075 12802 sgd_solver.cpp:105] Iteration 30280, lr = 0.000655191
I1029 01:27:47.999245 12802 solver.cpp:222] Iteration 30320 (1.32133 iter/s, 30.2725s/40 iters), loss = 1.68299
I1029 01:27:47.999356 12802 solver.cpp:241]     Train net output #0: loss = 1.68299 (* 1 = 1.68299 loss)
I1029 01:27:47.999374 12802 sgd_solver.cpp:105] Iteration 30320, lr = 0.000652836
I1029 01:28:18.144701 12802 solver.cpp:222] Iteration 30360 (1.32694 iter/s, 30.1446s/40 iters), loss = 1.49198
I1029 01:28:18.144829 12802 solver.cpp:241]     Train net output #0: loss = 1.49198 (* 1 = 1.49198 loss)
I1029 01:28:18.144847 12802 sgd_solver.cpp:105] Iteration 30360, lr = 0.00065049
I1029 01:28:47.788094 12802 solver.cpp:222] Iteration 30400 (1.34941 iter/s, 29.6426s/40 iters), loss = 1.45061
I1029 01:28:47.788161 12802 solver.cpp:241]     Train net output #0: loss = 1.45061 (* 1 = 1.45061 loss)
I1029 01:28:47.788172 12802 sgd_solver.cpp:105] Iteration 30400, lr = 0.000648152
I1029 01:29:17.383718 12802 solver.cpp:222] Iteration 30440 (1.35159 iter/s, 29.5949s/40 iters), loss = 1.26957
I1029 01:29:17.383872 12802 solver.cpp:241]     Train net output #0: loss = 1.26957 (* 1 = 1.26957 loss)
I1029 01:29:17.383894 12802 sgd_solver.cpp:105] Iteration 30440, lr = 0.000645823
I1029 01:29:46.999672 12802 solver.cpp:222] Iteration 30480 (1.35066 iter/s, 29.6151s/40 iters), loss = 1.41314
I1029 01:29:46.999730 12802 solver.cpp:241]     Train net output #0: loss = 1.41314 (* 1 = 1.41314 loss)
I1029 01:29:46.999747 12802 sgd_solver.cpp:105] Iteration 30480, lr = 0.000643502
I1029 01:30:01.735230 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_30500.caffemodel
I1029 01:30:01.876538 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_30500.solverstate
I1029 01:30:02.018038 12802 solver.cpp:334] Iteration 30500, Testing net (#0)
I1029 01:30:33.128413 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 01:30:33.339457 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57984
I1029 01:30:33.339506 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81196
I1029 01:30:33.339519 12802 solver.cpp:401]     Test net output #2: loss = 1.85963 (* 1 = 1.85963 loss)
I1029 01:30:49.605872 12802 solver.cpp:222] Iteration 30520 (0.63893 iter/s, 62.6047s/40 iters), loss = 1.5121
I1029 01:30:49.605936 12802 solver.cpp:241]     Train net output #0: loss = 1.5121 (* 1 = 1.5121 loss)
I1029 01:30:49.605952 12802 sgd_solver.cpp:105] Iteration 30520, lr = 0.000641189
I1029 01:31:20.574970 12802 solver.cpp:222] Iteration 30560 (1.29164 iter/s, 30.9683s/40 iters), loss = 1.14814
I1029 01:31:20.575186 12802 solver.cpp:241]     Train net output #0: loss = 1.14814 (* 1 = 1.14814 loss)
I1029 01:31:20.575204 12802 sgd_solver.cpp:105] Iteration 30560, lr = 0.000638885
I1029 01:32:07.091135 12802 solver.cpp:222] Iteration 30600 (0.859941 iter/s, 46.5148s/40 iters), loss = 1.23754
I1029 01:32:07.091344 12802 solver.cpp:241]     Train net output #0: loss = 1.23754 (* 1 = 1.23754 loss)
I1029 01:32:07.091367 12802 sgd_solver.cpp:105] Iteration 30600, lr = 0.000636589
I1029 01:32:38.239414 12802 solver.cpp:222] Iteration 30640 (1.28422 iter/s, 31.1473s/40 iters), loss = 1.45591
I1029 01:32:38.239653 12802 solver.cpp:241]     Train net output #0: loss = 1.45591 (* 1 = 1.45591 loss)
I1029 01:32:38.239668 12802 sgd_solver.cpp:105] Iteration 30640, lr = 0.000634301
I1029 01:33:08.046804 12802 solver.cpp:222] Iteration 30680 (1.34199 iter/s, 29.8064s/40 iters), loss = 1.6655
I1029 01:33:08.046864 12802 solver.cpp:241]     Train net output #0: loss = 1.6655 (* 1 = 1.6655 loss)
I1029 01:33:08.046876 12802 sgd_solver.cpp:105] Iteration 30680, lr = 0.000632022
I1029 01:33:38.141711 12802 solver.cpp:222] Iteration 30720 (1.32916 iter/s, 30.0941s/40 iters), loss = 1.34716
I1029 01:33:38.141906 12802 solver.cpp:241]     Train net output #0: loss = 1.34716 (* 1 = 1.34716 loss)
I1029 01:33:38.141928 12802 sgd_solver.cpp:105] Iteration 30720, lr = 0.00062975
I1029 01:34:08.078244 12802 solver.cpp:222] Iteration 30760 (1.3362 iter/s, 29.9356s/40 iters), loss = 1.50264
I1029 01:34:08.078306 12802 solver.cpp:241]     Train net output #0: loss = 1.50264 (* 1 = 1.50264 loss)
I1029 01:34:08.078322 12802 sgd_solver.cpp:105] Iteration 30760, lr = 0.000627487
I1029 01:34:37.800967 12802 solver.cpp:222] Iteration 30800 (1.34581 iter/s, 29.722s/40 iters), loss = 1.40744
I1029 01:34:37.801151 12802 solver.cpp:241]     Train net output #0: loss = 1.40744 (* 1 = 1.40744 loss)
I1029 01:34:37.801167 12802 sgd_solver.cpp:105] Iteration 30800, lr = 0.000625232
I1029 01:35:07.828426 12802 solver.cpp:222] Iteration 30840 (1.33215 iter/s, 30.0266s/40 iters), loss = 1.47057
I1029 01:35:07.828620 12802 solver.cpp:241]     Train net output #0: loss = 1.47057 (* 1 = 1.47057 loss)
I1029 01:35:07.828639 12802 sgd_solver.cpp:105] Iteration 30840, lr = 0.000622985
I1029 01:35:38.524950 12802 solver.cpp:222] Iteration 30880 (1.30312 iter/s, 30.6956s/40 iters), loss = 1.4668
I1029 01:35:38.525141 12802 solver.cpp:241]     Train net output #0: loss = 1.4668 (* 1 = 1.4668 loss)
I1029 01:35:38.525161 12802 sgd_solver.cpp:105] Iteration 30880, lr = 0.000620746
I1029 01:36:09.379171 12802 solver.cpp:222] Iteration 30920 (1.29646 iter/s, 30.8533s/40 iters), loss = 1.34546
I1029 01:36:09.379387 12802 solver.cpp:241]     Train net output #0: loss = 1.34546 (* 1 = 1.34546 loss)
I1029 01:36:09.379412 12802 sgd_solver.cpp:105] Iteration 30920, lr = 0.000618515
I1029 01:36:42.861652 12802 solver.cpp:222] Iteration 30960 (1.19469 iter/s, 33.4815s/40 iters), loss = 1.25208
I1029 01:36:42.861846 12802 solver.cpp:241]     Train net output #0: loss = 1.25208 (* 1 = 1.25208 loss)
I1029 01:36:42.861860 12802 sgd_solver.cpp:105] Iteration 30960, lr = 0.000616292
I1029 01:37:11.883003 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_31000.caffemodel
I1029 01:37:12.024600 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_31000.solverstate
I1029 01:37:12.139608 12802 solver.cpp:334] Iteration 31000, Testing net (#0)
I1029 01:37:43.351406 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58516
I1029 01:37:43.351603 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.808279
I1029 01:37:43.351616 12802 solver.cpp:401]     Test net output #2: loss = 1.83916 (* 1 = 1.83916 loss)
I1029 01:37:44.101644 12802 solver.cpp:222] Iteration 31000 (0.653185 iter/s, 61.2384s/40 iters), loss = 1.23482
I1029 01:37:44.101692 12802 solver.cpp:241]     Train net output #0: loss = 1.23482 (* 1 = 1.23482 loss)
I1029 01:37:44.101708 12802 sgd_solver.cpp:105] Iteration 31000, lr = 0.000614078
I1029 01:38:35.291026 12802 solver.cpp:222] Iteration 31040 (0.781431 iter/s, 51.1881s/40 iters), loss = 1.45512
I1029 01:38:35.291203 12802 solver.cpp:241]     Train net output #0: loss = 1.45512 (* 1 = 1.45512 loss)
I1029 01:38:35.291221 12802 sgd_solver.cpp:105] Iteration 31040, lr = 0.000611871
I1029 01:39:14.512269 12802 solver.cpp:222] Iteration 31080 (1.01988 iter/s, 39.2202s/40 iters), loss = 1.26502
I1029 01:39:14.512459 12802 solver.cpp:241]     Train net output #0: loss = 1.26502 (* 1 = 1.26502 loss)
I1029 01:39:14.512476 12802 sgd_solver.cpp:105] Iteration 31080, lr = 0.000609672
I1029 01:39:36.975260 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 01:39:44.529500 12802 solver.cpp:222] Iteration 31120 (1.33261 iter/s, 30.0163s/40 iters), loss = 1.34454
I1029 01:39:44.529747 12802 solver.cpp:241]     Train net output #0: loss = 1.34454 (* 1 = 1.34454 loss)
I1029 01:39:44.529767 12802 sgd_solver.cpp:105] Iteration 31120, lr = 0.000607481
I1029 01:40:15.123322 12802 solver.cpp:222] Iteration 31160 (1.30749 iter/s, 30.5929s/40 iters), loss = 1.36468
I1029 01:40:15.123529 12802 solver.cpp:241]     Train net output #0: loss = 1.36468 (* 1 = 1.36468 loss)
I1029 01:40:15.123549 12802 sgd_solver.cpp:105] Iteration 31160, lr = 0.000605298
I1029 01:40:45.255817 12802 solver.cpp:222] Iteration 31200 (1.32751 iter/s, 30.1316s/40 iters), loss = 1.80857
I1029 01:40:45.256055 12802 solver.cpp:241]     Train net output #0: loss = 1.80857 (* 1 = 1.80857 loss)
I1029 01:40:45.256072 12802 sgd_solver.cpp:105] Iteration 31200, lr = 0.000603122
I1029 01:41:15.003880 12802 solver.cpp:222] Iteration 31240 (1.34467 iter/s, 29.7471s/40 iters), loss = 0.924247
I1029 01:41:15.003947 12802 solver.cpp:241]     Train net output #0: loss = 0.924247 (* 1 = 0.924247 loss)
I1029 01:41:15.003962 12802 sgd_solver.cpp:105] Iteration 31240, lr = 0.000600955
I1029 01:41:45.433147 12802 solver.cpp:222] Iteration 31280 (1.31456 iter/s, 30.4285s/40 iters), loss = 1.12138
I1029 01:41:45.433327 12802 solver.cpp:241]     Train net output #0: loss = 1.12138 (* 1 = 1.12138 loss)
I1029 01:41:45.433346 12802 sgd_solver.cpp:105] Iteration 31280, lr = 0.000598795
I1029 01:42:41.380455 12802 solver.cpp:222] Iteration 31320 (0.714977 iter/s, 55.9458s/40 iters), loss = 1.50174
I1029 01:42:41.380645 12802 solver.cpp:241]     Train net output #0: loss = 1.50174 (* 1 = 1.50174 loss)
I1029 01:42:41.380661 12802 sgd_solver.cpp:105] Iteration 31320, lr = 0.000596643
I1029 01:43:11.419055 12802 solver.cpp:222] Iteration 31360 (1.33166 iter/s, 30.0377s/40 iters), loss = 1.49261
I1029 01:43:11.419245 12802 solver.cpp:241]     Train net output #0: loss = 1.49261 (* 1 = 1.49261 loss)
I1029 01:43:11.419263 12802 sgd_solver.cpp:105] Iteration 31360, lr = 0.000594499
I1029 01:43:41.389528 12802 solver.cpp:222] Iteration 31400 (1.33469 iter/s, 29.9696s/40 iters), loss = 1.59376
I1029 01:43:41.389586 12802 solver.cpp:241]     Train net output #0: loss = 1.59376 (* 1 = 1.59376 loss)
I1029 01:43:41.389602 12802 sgd_solver.cpp:105] Iteration 31400, lr = 0.000592362
I1029 01:44:11.058231 12802 solver.cpp:222] Iteration 31440 (1.34826 iter/s, 29.6679s/40 iters), loss = 1.59895
I1029 01:44:11.058403 12802 solver.cpp:241]     Train net output #0: loss = 1.59895 (* 1 = 1.59895 loss)
I1029 01:44:11.058419 12802 sgd_solver.cpp:105] Iteration 31440, lr = 0.000590234
I1029 01:44:41.356029 12802 solver.cpp:222] Iteration 31480 (1.32027 iter/s, 30.2969s/40 iters), loss = 1.22695
I1029 01:44:41.356215 12802 solver.cpp:241]     Train net output #0: loss = 1.22695 (* 1 = 1.22695 loss)
I1029 01:44:41.356232 12802 sgd_solver.cpp:105] Iteration 31480, lr = 0.000588112
I1029 01:44:55.683982 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_31500.caffemodel
I1029 01:44:55.817451 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_31500.solverstate
I1029 01:44:55.933625 12802 solver.cpp:334] Iteration 31500, Testing net (#0)
I1029 01:45:27.192198 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 01:45:27.404036 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58096
I1029 01:45:27.404088 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813599
I1029 01:45:27.404099 12802 solver.cpp:401]     Test net output #2: loss = 1.87139 (* 1 = 1.87139 loss)
I1029 01:45:43.644850 12802 solver.cpp:222] Iteration 31520 (0.642187 iter/s, 62.2872s/40 iters), loss = 1.39784
I1029 01:45:43.644917 12802 solver.cpp:241]     Train net output #0: loss = 1.39784 (* 1 = 1.39784 loss)
I1029 01:45:43.644942 12802 sgd_solver.cpp:105] Iteration 31520, lr = 0.000585999
I1029 01:46:26.080246 12802 solver.cpp:222] Iteration 31560 (0.942633 iter/s, 42.4343s/40 iters), loss = 1.45839
I1029 01:46:26.080534 12802 solver.cpp:241]     Train net output #0: loss = 1.45839 (* 1 = 1.45839 loss)
I1029 01:46:26.080556 12802 sgd_solver.cpp:105] Iteration 31560, lr = 0.000583893
I1029 01:46:55.775276 12802 solver.cpp:222] Iteration 31600 (1.34707 iter/s, 29.694s/40 iters), loss = 1.87934
I1029 01:46:55.775332 12802 solver.cpp:241]     Train net output #0: loss = 1.87934 (* 1 = 1.87934 loss)
I1029 01:46:55.775347 12802 sgd_solver.cpp:105] Iteration 31600, lr = 0.000581794
I1029 01:47:25.364298 12802 solver.cpp:222] Iteration 31640 (1.35189 iter/s, 29.5883s/40 iters), loss = 1.67907
I1029 01:47:25.364509 12802 solver.cpp:241]     Train net output #0: loss = 1.67907 (* 1 = 1.67907 loss)
I1029 01:47:25.364527 12802 sgd_solver.cpp:105] Iteration 31640, lr = 0.000579704
I1029 01:47:54.948788 12802 solver.cpp:222] Iteration 31680 (1.3521 iter/s, 29.5836s/40 iters), loss = 1.70516
I1029 01:47:54.948854 12802 solver.cpp:241]     Train net output #0: loss = 1.70516 (* 1 = 1.70516 loss)
I1029 01:47:54.948868 12802 sgd_solver.cpp:105] Iteration 31680, lr = 0.00057762
I1029 01:48:24.526885 12802 solver.cpp:222] Iteration 31720 (1.35239 iter/s, 29.5773s/40 iters), loss = 1.30596
I1029 01:48:24.527079 12802 solver.cpp:241]     Train net output #0: loss = 1.30596 (* 1 = 1.30596 loss)
I1029 01:48:24.527096 12802 sgd_solver.cpp:105] Iteration 31720, lr = 0.000575544
I1029 01:48:54.020622 12802 solver.cpp:222] Iteration 31760 (1.35626 iter/s, 29.4928s/40 iters), loss = 1.27266
I1029 01:48:54.020678 12802 solver.cpp:241]     Train net output #0: loss = 1.27266 (* 1 = 1.27266 loss)
I1029 01:48:54.020694 12802 sgd_solver.cpp:105] Iteration 31760, lr = 0.000573476
I1029 01:50:11.883463 12802 solver.cpp:222] Iteration 31800 (0.513736 iter/s, 77.861s/40 iters), loss = 1.2138
I1029 01:50:11.883664 12802 solver.cpp:241]     Train net output #0: loss = 1.2138 (* 1 = 1.2138 loss)
I1029 01:50:11.883682 12802 sgd_solver.cpp:105] Iteration 31800, lr = 0.000571415
I1029 01:50:42.633957 12802 solver.cpp:222] Iteration 31840 (1.30083 iter/s, 30.7496s/40 iters), loss = 1.60441
I1029 01:50:42.634158 12802 solver.cpp:241]     Train net output #0: loss = 1.60441 (* 1 = 1.60441 loss)
I1029 01:50:42.634176 12802 sgd_solver.cpp:105] Iteration 31840, lr = 0.000569361
I1029 01:51:12.366020 12802 solver.cpp:222] Iteration 31880 (1.34539 iter/s, 29.7312s/40 iters), loss = 1.56252
I1029 01:51:12.366080 12802 solver.cpp:241]     Train net output #0: loss = 1.56252 (* 1 = 1.56252 loss)
I1029 01:51:12.366096 12802 sgd_solver.cpp:105] Iteration 31880, lr = 0.000567315
I1029 01:51:41.754943 12802 solver.cpp:222] Iteration 31920 (1.36109 iter/s, 29.3882s/40 iters), loss = 1.48366
I1029 01:51:41.755121 12802 solver.cpp:241]     Train net output #0: loss = 1.48366 (* 1 = 1.48366 loss)
I1029 01:51:41.755138 12802 sgd_solver.cpp:105] Iteration 31920, lr = 0.000565276
I1029 01:52:11.235791 12802 solver.cpp:222] Iteration 31960 (1.35685 iter/s, 29.48s/40 iters), loss = 1.52785
I1029 01:52:11.235851 12802 solver.cpp:241]     Train net output #0: loss = 1.52785 (* 1 = 1.52785 loss)
I1029 01:52:11.235865 12802 sgd_solver.cpp:105] Iteration 31960, lr = 0.000563245
I1029 01:52:40.083554 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_32000.caffemodel
I1029 01:52:40.239677 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_32000.solverstate
I1029 01:52:40.355799 12802 solver.cpp:334] Iteration 32000, Testing net (#0)
I1029 01:53:13.426419 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5848
I1029 01:53:13.426570 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80632
I1029 01:53:13.426584 12802 solver.cpp:401]     Test net output #2: loss = 1.84569 (* 1 = 1.84569 loss)
I1029 01:53:14.185344 12802 solver.cpp:222] Iteration 32000 (0.635445 iter/s, 62.948s/40 iters), loss = 1.20867
I1029 01:53:14.185402 12802 solver.cpp:241]     Train net output #0: loss = 1.20867 (* 1 = 1.20867 loss)
I1029 01:53:14.185418 12802 sgd_solver.cpp:105] Iteration 32000, lr = 0.000561221
I1029 01:53:43.804285 12802 solver.cpp:222] Iteration 32040 (1.35052 iter/s, 29.6182s/40 iters), loss = 1.79465
I1029 01:53:43.804471 12802 solver.cpp:241]     Train net output #0: loss = 1.79465 (* 1 = 1.79465 loss)
I1029 01:53:43.804489 12802 sgd_solver.cpp:105] Iteration 32040, lr = 0.000559204
I1029 01:54:13.429738 12802 solver.cpp:222] Iteration 32080 (1.35023 iter/s, 29.6246s/40 iters), loss = 1.54801
I1029 01:54:13.429793 12802 solver.cpp:241]     Train net output #0: loss = 1.54801 (* 1 = 1.54801 loss)
I1029 01:54:13.429808 12802 sgd_solver.cpp:105] Iteration 32080, lr = 0.000557194
I1029 01:54:43.112267 12802 solver.cpp:222] Iteration 32120 (1.34763 iter/s, 29.6818s/40 iters), loss = 1.53176
I1029 01:54:43.112439 12802 solver.cpp:241]     Train net output #0: loss = 1.53176 (* 1 = 1.53176 loss)
I1029 01:54:43.112457 12802 sgd_solver.cpp:105] Iteration 32120, lr = 0.000555192
I1029 01:55:12.805173 12802 solver.cpp:222] Iteration 32160 (1.34716 iter/s, 29.692s/40 iters), loss = 1.61012
I1029 01:55:12.805240 12802 solver.cpp:241]     Train net output #0: loss = 1.61012 (* 1 = 1.61012 loss)
I1029 01:55:12.805256 12802 sgd_solver.cpp:105] Iteration 32160, lr = 0.000553196
I1029 01:55:42.803406 12802 solver.cpp:222] Iteration 32200 (1.33345 iter/s, 29.9974s/40 iters), loss = 1.32657
I1029 01:55:42.803584 12802 solver.cpp:241]     Train net output #0: loss = 1.32657 (* 1 = 1.32657 loss)
I1029 01:55:42.803602 12802 sgd_solver.cpp:105] Iteration 32200, lr = 0.000551208
I1029 01:56:13.303287 12802 solver.cpp:222] Iteration 32240 (1.31152 iter/s, 30.499s/40 iters), loss = 1.38449
I1029 01:56:13.303479 12802 solver.cpp:241]     Train net output #0: loss = 1.38449 (* 1 = 1.38449 loss)
I1029 01:56:13.303503 12802 sgd_solver.cpp:105] Iteration 32240, lr = 0.000549227
I1029 01:56:43.857828 12802 solver.cpp:222] Iteration 32280 (1.30917 iter/s, 30.5536s/40 iters), loss = 1.81921
I1029 01:56:43.858022 12802 solver.cpp:241]     Train net output #0: loss = 1.81921 (* 1 = 1.81921 loss)
I1029 01:56:43.858039 12802 sgd_solver.cpp:105] Iteration 32280, lr = 0.000547254
I1029 01:57:18.292779 12802 solver.cpp:222] Iteration 32320 (1.16164 iter/s, 34.4339s/40 iters), loss = 1.1482
I1029 01:57:18.293053 12802 solver.cpp:241]     Train net output #0: loss = 1.1482 (* 1 = 1.1482 loss)
I1029 01:57:18.293071 12802 sgd_solver.cpp:105] Iteration 32320, lr = 0.000545287
I1029 01:57:48.119226 12802 solver.cpp:222] Iteration 32360 (1.34114 iter/s, 29.8255s/40 iters), loss = 1.44773
I1029 01:57:48.119284 12802 solver.cpp:241]     Train net output #0: loss = 1.44773 (* 1 = 1.44773 loss)
I1029 01:57:48.119299 12802 sgd_solver.cpp:105] Iteration 32360, lr = 0.000543327
I1029 01:58:17.892063 12802 solver.cpp:222] Iteration 32400 (1.34354 iter/s, 29.7721s/40 iters), loss = 1.37685
I1029 01:58:17.892208 12802 solver.cpp:241]     Train net output #0: loss = 1.37685 (* 1 = 1.37685 loss)
I1029 01:58:17.892225 12802 sgd_solver.cpp:105] Iteration 32400, lr = 0.000541375
I1029 01:59:05.752935 12802 solver.cpp:222] Iteration 32440 (0.835778 iter/s, 47.8596s/40 iters), loss = 1.77658
I1029 01:59:05.753151 12802 solver.cpp:241]     Train net output #0: loss = 1.77658 (* 1 = 1.77658 loss)
I1029 01:59:05.753170 12802 sgd_solver.cpp:105] Iteration 32440, lr = 0.000539429
I1029 02:00:06.631775 12802 solver.cpp:222] Iteration 32480 (0.65706 iter/s, 60.8772s/40 iters), loss = 1.56866
I1029 02:00:06.632041 12802 solver.cpp:241]     Train net output #0: loss = 1.56866 (* 1 = 1.56866 loss)
I1029 02:00:06.632058 12802 sgd_solver.cpp:105] Iteration 32480, lr = 0.00053749
I1029 02:00:20.728524 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_32500.caffemodel
I1029 02:00:20.870203 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_32500.solverstate
I1029 02:00:20.995261 12802 solver.cpp:334] Iteration 32500, Testing net (#0)
I1029 02:00:52.523469 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 02:00:52.729486 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58256
I1029 02:00:52.729532 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81376
I1029 02:00:52.729542 12802 solver.cpp:401]     Test net output #2: loss = 1.86516 (* 1 = 1.86516 loss)
I1029 02:01:08.948262 12802 solver.cpp:222] Iteration 32520 (0.641902 iter/s, 62.3148s/40 iters), loss = 1.35101
I1029 02:01:08.948320 12802 solver.cpp:241]     Train net output #0: loss = 1.35101 (* 1 = 1.35101 loss)
I1029 02:01:08.948336 12802 sgd_solver.cpp:105] Iteration 32520, lr = 0.000535559
I1029 02:01:40.064944 12802 solver.cpp:222] Iteration 32560 (1.28552 iter/s, 31.1159s/40 iters), loss = 1.47156
I1029 02:01:40.065145 12802 solver.cpp:241]     Train net output #0: loss = 1.47156 (* 1 = 1.47156 loss)
I1029 02:01:40.065163 12802 sgd_solver.cpp:105] Iteration 32560, lr = 0.000533634
I1029 02:02:09.595644 12802 solver.cpp:222] Iteration 32600 (1.35456 iter/s, 29.5298s/40 iters), loss = 1.34323
I1029 02:02:09.595706 12802 solver.cpp:241]     Train net output #0: loss = 1.34323 (* 1 = 1.34323 loss)
I1029 02:02:09.595721 12802 sgd_solver.cpp:105] Iteration 32600, lr = 0.000531716
I1029 02:02:39.248482 12802 solver.cpp:222] Iteration 32640 (1.34898 iter/s, 29.6521s/40 iters), loss = 1.38662
I1029 02:02:39.248687 12802 solver.cpp:241]     Train net output #0: loss = 1.38662 (* 1 = 1.38662 loss)
I1029 02:02:39.248703 12802 sgd_solver.cpp:105] Iteration 32640, lr = 0.000529805
I1029 02:03:08.924283 12802 solver.cpp:222] Iteration 32680 (1.34794 iter/s, 29.6749s/40 iters), loss = 1.23467
I1029 02:03:08.924340 12802 solver.cpp:241]     Train net output #0: loss = 1.23467 (* 1 = 1.23467 loss)
I1029 02:03:08.924360 12802 sgd_solver.cpp:105] Iteration 32680, lr = 0.000527901
I1029 02:03:39.509171 12802 solver.cpp:222] Iteration 32720 (1.30787 iter/s, 30.5841s/40 iters), loss = 1.34015
I1029 02:03:39.509377 12802 solver.cpp:241]     Train net output #0: loss = 1.34015 (* 1 = 1.34015 loss)
I1029 02:03:39.509395 12802 sgd_solver.cpp:105] Iteration 32720, lr = 0.000526004
I1029 02:04:12.978912 12802 solver.cpp:222] Iteration 32760 (1.19515 iter/s, 33.4687s/40 iters), loss = 1.72556
I1029 02:04:12.979105 12802 solver.cpp:241]     Train net output #0: loss = 1.72556 (* 1 = 1.72556 loss)
I1029 02:04:12.979122 12802 sgd_solver.cpp:105] Iteration 32760, lr = 0.000524114
I1029 02:04:43.413323 12802 solver.cpp:222] Iteration 32800 (1.31434 iter/s, 30.4335s/40 iters), loss = 1.36859
I1029 02:04:43.413513 12802 solver.cpp:241]     Train net output #0: loss = 1.36859 (* 1 = 1.36859 loss)
I1029 02:04:43.413530 12802 sgd_solver.cpp:105] Iteration 32800, lr = 0.00052223
I1029 02:05:13.859735 12802 solver.cpp:222] Iteration 32840 (1.31382 iter/s, 30.4455s/40 iters), loss = 1.44382
I1029 02:05:13.859941 12802 solver.cpp:241]     Train net output #0: loss = 1.44382 (* 1 = 1.44382 loss)
I1029 02:05:13.859956 12802 sgd_solver.cpp:105] Iteration 32840, lr = 0.000520353
I1029 02:05:43.623046 12802 solver.cpp:222] Iteration 32880 (1.34398 iter/s, 29.7624s/40 iters), loss = 1.60105
I1029 02:05:43.623109 12802 solver.cpp:241]     Train net output #0: loss = 1.60105 (* 1 = 1.60105 loss)
I1029 02:05:43.623124 12802 sgd_solver.cpp:105] Iteration 32880, lr = 0.000518483
I1029 02:06:13.391711 12802 solver.cpp:222] Iteration 32920 (1.34373 iter/s, 29.7679s/40 iters), loss = 1.47406
I1029 02:06:13.391929 12802 solver.cpp:241]     Train net output #0: loss = 1.47406 (* 1 = 1.47406 loss)
I1029 02:06:13.391947 12802 sgd_solver.cpp:105] Iteration 32920, lr = 0.00051662
I1029 02:06:43.129914 12802 solver.cpp:222] Iteration 32960 (1.34511 iter/s, 29.7373s/40 iters), loss = 1.57364
I1029 02:06:43.129977 12802 solver.cpp:241]     Train net output #0: loss = 1.57364 (* 1 = 1.57364 loss)
I1029 02:06:43.129994 12802 sgd_solver.cpp:105] Iteration 32960, lr = 0.000514763
I1029 02:07:12.134043 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_33000.caffemodel
I1029 02:07:12.274323 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_33000.solverstate
I1029 02:07:12.386591 12802 solver.cpp:334] Iteration 33000, Testing net (#0)
I1029 02:07:43.643182 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58552
I1029 02:07:43.643276 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.806
I1029 02:07:43.643288 12802 solver.cpp:401]     Test net output #2: loss = 1.84522 (* 1 = 1.84522 loss)
I1029 02:07:44.411689 12802 solver.cpp:222] Iteration 33000 (0.652739 iter/s, 61.2803s/40 iters), loss = 1.33354
I1029 02:07:44.411751 12802 solver.cpp:241]     Train net output #0: loss = 1.33354 (* 1 = 1.33354 loss)
I1029 02:07:44.411765 12802 sgd_solver.cpp:105] Iteration 33000, lr = 0.000512914
I1029 02:08:14.340399 12802 solver.cpp:222] Iteration 33040 (1.33654 iter/s, 29.9279s/40 iters), loss = 1.30619
I1029 02:08:14.340538 12802 solver.cpp:241]     Train net output #0: loss = 1.30619 (* 1 = 1.30619 loss)
I1029 02:08:14.340555 12802 sgd_solver.cpp:105] Iteration 33040, lr = 0.00051107
I1029 02:08:44.123831 12802 solver.cpp:222] Iteration 33080 (1.34307 iter/s, 29.7826s/40 iters), loss = 1.45096
I1029 02:08:44.123889 12802 solver.cpp:241]     Train net output #0: loss = 1.45096 (* 1 = 1.45096 loss)
I1029 02:08:44.123904 12802 sgd_solver.cpp:105] Iteration 33080, lr = 0.000509234
I1029 02:09:13.895746 12802 solver.cpp:222] Iteration 33120 (1.34358 iter/s, 29.7711s/40 iters), loss = 1.33806
I1029 02:09:13.895879 12802 solver.cpp:241]     Train net output #0: loss = 1.33806 (* 1 = 1.33806 loss)
I1029 02:09:13.895896 12802 sgd_solver.cpp:105] Iteration 33120, lr = 0.000507403
I1029 02:09:43.700770 12802 solver.cpp:222] Iteration 33160 (1.34209 iter/s, 29.8042s/40 iters), loss = 1.53978
I1029 02:09:43.700836 12802 solver.cpp:241]     Train net output #0: loss = 1.53978 (* 1 = 1.53978 loss)
I1029 02:09:43.700852 12802 sgd_solver.cpp:105] Iteration 33160, lr = 0.00050558
I1029 02:10:13.544978 12802 solver.cpp:222] Iteration 33200 (1.34033 iter/s, 29.8434s/40 iters), loss = 1.46709
I1029 02:10:13.545151 12802 solver.cpp:241]     Train net output #0: loss = 1.46709 (* 1 = 1.46709 loss)
I1029 02:10:13.545168 12802 sgd_solver.cpp:105] Iteration 33200, lr = 0.000503763
I1029 02:10:43.384229 12802 solver.cpp:222] Iteration 33240 (1.34056 iter/s, 29.8384s/40 iters), loss = 1.57861
I1029 02:10:43.384292 12802 solver.cpp:241]     Train net output #0: loss = 1.57861 (* 1 = 1.57861 loss)
I1029 02:10:43.384308 12802 sgd_solver.cpp:105] Iteration 33240, lr = 0.000501953
I1029 02:11:14.014832 12802 solver.cpp:222] Iteration 33280 (1.30592 iter/s, 30.6298s/40 iters), loss = 1.69386
I1029 02:11:14.015020 12802 solver.cpp:241]     Train net output #0: loss = 1.69386 (* 1 = 1.69386 loss)
I1029 02:11:14.015041 12802 sgd_solver.cpp:105] Iteration 33280, lr = 0.000500149
I1029 02:11:44.448207 12802 solver.cpp:222] Iteration 33320 (1.31439 iter/s, 30.4325s/40 iters), loss = 1.51181
I1029 02:11:44.448374 12802 solver.cpp:241]     Train net output #0: loss = 1.51181 (* 1 = 1.51181 loss)
I1029 02:11:44.448391 12802 sgd_solver.cpp:105] Iteration 33320, lr = 0.000498351
I1029 02:12:14.861327 12802 solver.cpp:222] Iteration 33360 (1.31526 iter/s, 30.4122s/40 iters), loss = 1.36715
I1029 02:12:14.861479 12802 solver.cpp:241]     Train net output #0: loss = 1.36715 (* 1 = 1.36715 loss)
I1029 02:12:14.861495 12802 sgd_solver.cpp:105] Iteration 33360, lr = 0.00049656
I1029 02:12:45.183614 12802 solver.cpp:222] Iteration 33400 (1.3192 iter/s, 30.3214s/40 iters), loss = 1.60731
I1029 02:12:45.183755 12802 solver.cpp:241]     Train net output #0: loss = 1.60731 (* 1 = 1.60731 loss)
I1029 02:12:45.183769 12802 sgd_solver.cpp:105] Iteration 33400, lr = 0.000494776
I1029 02:13:16.053692 12802 solver.cpp:222] Iteration 33440 (1.29579 iter/s, 30.8692s/40 iters), loss = 1.6202
I1029 02:13:16.053885 12802 solver.cpp:241]     Train net output #0: loss = 1.6202 (* 1 = 1.6202 loss)
I1029 02:13:16.053905 12802 sgd_solver.cpp:105] Iteration 33440, lr = 0.000492998
I1029 02:13:46.943313 12802 solver.cpp:222] Iteration 33480 (1.29497 iter/s, 30.8887s/40 iters), loss = 1.03292
I1029 02:13:46.943555 12802 solver.cpp:241]     Train net output #0: loss = 1.03292 (* 1 = 1.03292 loss)
I1029 02:13:46.943574 12802 sgd_solver.cpp:105] Iteration 33480, lr = 0.000491226
I1029 02:14:01.315129 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_33500.caffemodel
I1029 02:14:01.447559 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_33500.solverstate
I1029 02:14:01.576712 12802 solver.cpp:334] Iteration 33500, Testing net (#0)
I1029 02:14:32.673465 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 02:14:32.880692 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5834
I1029 02:14:32.880736 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.811679
I1029 02:14:32.880748 12802 solver.cpp:401]     Test net output #2: loss = 1.83606 (* 1 = 1.83606 loss)
I1029 02:14:49.310498 12802 solver.cpp:222] Iteration 33520 (0.64138 iter/s, 62.3655s/40 iters), loss = 1.44741
I1029 02:14:49.310557 12802 solver.cpp:241]     Train net output #0: loss = 1.44741 (* 1 = 1.44741 loss)
I1029 02:14:49.310572 12802 sgd_solver.cpp:105] Iteration 33520, lr = 0.00048946
I1029 02:15:20.235122 12802 solver.cpp:222] Iteration 33560 (1.2935 iter/s, 30.9238s/40 iters), loss = 1.3154
I1029 02:15:20.235321 12802 solver.cpp:241]     Train net output #0: loss = 1.3154 (* 1 = 1.3154 loss)
I1029 02:15:20.235334 12802 sgd_solver.cpp:105] Iteration 33560, lr = 0.000487701
I1029 02:15:50.440790 12802 solver.cpp:222] Iteration 33600 (1.3243 iter/s, 30.2048s/40 iters), loss = 1.28977
I1029 02:15:50.441064 12802 solver.cpp:241]     Train net output #0: loss = 1.28977 (* 1 = 1.28977 loss)
I1029 02:15:50.441082 12802 sgd_solver.cpp:105] Iteration 33600, lr = 0.000485949
I1029 02:15:59.697058 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 02:16:20.405730 12802 solver.cpp:222] Iteration 33640 (1.33494 iter/s, 29.964s/40 iters), loss = 1.32332
I1029 02:16:20.405794 12802 solver.cpp:241]     Train net output #0: loss = 1.32332 (* 1 = 1.32332 loss)
I1029 02:16:20.405809 12802 sgd_solver.cpp:105] Iteration 33640, lr = 0.000484202
I1029 02:16:50.377326 12802 solver.cpp:222] Iteration 33680 (1.33463 iter/s, 29.9708s/40 iters), loss = 1.53307
I1029 02:16:50.377472 12802 solver.cpp:241]     Train net output #0: loss = 1.53307 (* 1 = 1.53307 loss)
I1029 02:16:50.377488 12802 sgd_solver.cpp:105] Iteration 33680, lr = 0.000482462
I1029 02:17:20.457077 12802 solver.cpp:222] Iteration 33720 (1.32984 iter/s, 30.0789s/40 iters), loss = 1.11685
I1029 02:17:20.457240 12802 solver.cpp:241]     Train net output #0: loss = 1.11685 (* 1 = 1.11685 loss)
I1029 02:17:20.457257 12802 sgd_solver.cpp:105] Iteration 33720, lr = 0.000480728
I1029 02:17:50.484876 12802 solver.cpp:222] Iteration 33760 (1.33214 iter/s, 30.0269s/40 iters), loss = 1.40939
I1029 02:17:50.485036 12802 solver.cpp:241]     Train net output #0: loss = 1.40939 (* 1 = 1.40939 loss)
I1029 02:17:50.485054 12802 sgd_solver.cpp:105] Iteration 33760, lr = 0.000479001
I1029 02:18:20.402616 12802 solver.cpp:222] Iteration 33800 (1.33704 iter/s, 29.9169s/40 iters), loss = 1.86129
I1029 02:18:20.402671 12802 solver.cpp:241]     Train net output #0: loss = 1.86129 (* 1 = 1.86129 loss)
I1029 02:18:20.402688 12802 sgd_solver.cpp:105] Iteration 33800, lr = 0.000477279
I1029 02:18:51.265015 12802 solver.cpp:222] Iteration 33840 (1.29611 iter/s, 30.8616s/40 iters), loss = 1.40793
I1029 02:18:51.265198 12802 solver.cpp:241]     Train net output #0: loss = 1.40793 (* 1 = 1.40793 loss)
I1029 02:18:51.265215 12802 sgd_solver.cpp:105] Iteration 33840, lr = 0.000475564
I1029 02:19:21.334887 12802 solver.cpp:222] Iteration 33880 (1.33027 iter/s, 30.069s/40 iters), loss = 1.40997
I1029 02:19:21.335160 12802 solver.cpp:241]     Train net output #0: loss = 1.40997 (* 1 = 1.40997 loss)
I1029 02:19:21.335178 12802 sgd_solver.cpp:105] Iteration 33880, lr = 0.000473855
I1029 02:19:51.348258 12802 solver.cpp:222] Iteration 33920 (1.33278 iter/s, 30.0124s/40 iters), loss = 1.44865
I1029 02:19:51.348449 12802 solver.cpp:241]     Train net output #0: loss = 1.44865 (* 1 = 1.44865 loss)
I1029 02:19:51.348466 12802 sgd_solver.cpp:105] Iteration 33920, lr = 0.000472152
I1029 02:20:21.649740 12802 solver.cpp:222] Iteration 33960 (1.32011 iter/s, 30.3006s/40 iters), loss = 1.46794
I1029 02:20:21.649943 12802 solver.cpp:241]     Train net output #0: loss = 1.46794 (* 1 = 1.46794 loss)
I1029 02:20:21.649960 12802 sgd_solver.cpp:105] Iteration 33960, lr = 0.000470455
I1029 02:20:51.223078 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_34000.caffemodel
I1029 02:20:51.363289 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_34000.solverstate
I1029 02:20:51.478623 12802 solver.cpp:334] Iteration 34000, Testing net (#0)
I1029 02:21:22.765357 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58612
I1029 02:21:22.765549 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80852
I1029 02:21:22.765563 12802 solver.cpp:401]     Test net output #2: loss = 1.84823 (* 1 = 1.84823 loss)
I1029 02:21:23.519337 12802 solver.cpp:222] Iteration 34000 (0.646538 iter/s, 61.868s/40 iters), loss = 1.5767
I1029 02:21:23.519395 12802 solver.cpp:241]     Train net output #0: loss = 1.5767 (* 1 = 1.5767 loss)
I1029 02:21:23.519410 12802 sgd_solver.cpp:105] Iteration 34000, lr = 0.000468764
I1029 02:21:53.734226 12802 solver.cpp:222] Iteration 34040 (1.32388 iter/s, 30.2141s/40 iters), loss = 1.47434
I1029 02:21:53.734390 12802 solver.cpp:241]     Train net output #0: loss = 1.47434 (* 1 = 1.47434 loss)
I1029 02:21:53.734414 12802 sgd_solver.cpp:105] Iteration 34040, lr = 0.00046708
I1029 02:22:25.140784 12802 solver.cpp:222] Iteration 34080 (1.27366 iter/s, 31.4056s/40 iters), loss = 1.59203
I1029 02:22:25.140960 12802 solver.cpp:241]     Train net output #0: loss = 1.59203 (* 1 = 1.59203 loss)
I1029 02:22:25.140977 12802 sgd_solver.cpp:105] Iteration 34080, lr = 0.000465401
I1029 02:22:59.013599 12802 solver.cpp:222] Iteration 34120 (1.18092 iter/s, 33.8718s/40 iters), loss = 1.43043
I1029 02:22:59.013743 12802 solver.cpp:241]     Train net output #0: loss = 1.43043 (* 1 = 1.43043 loss)
I1029 02:22:59.013761 12802 sgd_solver.cpp:105] Iteration 34120, lr = 0.000463729
I1029 02:23:29.037729 12802 solver.cpp:222] Iteration 34160 (1.3323 iter/s, 30.0233s/40 iters), loss = 1.43634
I1029 02:23:29.037879 12802 solver.cpp:241]     Train net output #0: loss = 1.43634 (* 1 = 1.43634 loss)
I1029 02:23:29.037897 12802 sgd_solver.cpp:105] Iteration 34160, lr = 0.000462062
I1029 02:24:04.821346 12802 solver.cpp:222] Iteration 34200 (1.11786 iter/s, 35.7826s/40 iters), loss = 1.72499
I1029 02:24:04.821487 12802 solver.cpp:241]     Train net output #0: loss = 1.72499 (* 1 = 1.72499 loss)
I1029 02:24:04.821504 12802 sgd_solver.cpp:105] Iteration 34200, lr = 0.000460401
I1029 02:24:35.292415 12802 solver.cpp:222] Iteration 34240 (1.31276 iter/s, 30.4702s/40 iters), loss = 1.67378
I1029 02:24:35.292567 12802 solver.cpp:241]     Train net output #0: loss = 1.67378 (* 1 = 1.67378 loss)
I1029 02:24:35.292584 12802 sgd_solver.cpp:105] Iteration 34240, lr = 0.000458747
I1029 02:25:05.524744 12802 solver.cpp:222] Iteration 34280 (1.32312 iter/s, 30.2315s/40 iters), loss = 1.60088
I1029 02:25:05.524891 12802 solver.cpp:241]     Train net output #0: loss = 1.60088 (* 1 = 1.60088 loss)
I1029 02:25:05.524909 12802 sgd_solver.cpp:105] Iteration 34280, lr = 0.000457098
I1029 02:25:35.381276 12802 solver.cpp:222] Iteration 34320 (1.33978 iter/s, 29.8557s/40 iters), loss = 1.52983
I1029 02:25:35.381340 12802 solver.cpp:241]     Train net output #0: loss = 1.52983 (* 1 = 1.52983 loss)
I1029 02:25:35.381356 12802 sgd_solver.cpp:105] Iteration 34320, lr = 0.000455455
I1029 02:26:05.443145 12802 solver.cpp:222] Iteration 34360 (1.33062 iter/s, 30.0611s/40 iters), loss = 1.33504
I1029 02:26:05.443363 12802 solver.cpp:241]     Train net output #0: loss = 1.33504 (* 1 = 1.33504 loss)
I1029 02:26:05.443382 12802 sgd_solver.cpp:105] Iteration 34360, lr = 0.000453819
I1029 02:26:42.020689 12802 solver.cpp:222] Iteration 34400 (1.0936 iter/s, 36.5765s/40 iters), loss = 1.37513
I1029 02:26:42.020830 12802 solver.cpp:241]     Train net output #0: loss = 1.37513 (* 1 = 1.37513 loss)
I1029 02:26:42.020848 12802 sgd_solver.cpp:105] Iteration 34400, lr = 0.000452188
I1029 02:27:13.350805 12802 solver.cpp:222] Iteration 34440 (1.27676 iter/s, 31.3292s/40 iters), loss = 1.80817
I1029 02:27:13.350956 12802 solver.cpp:241]     Train net output #0: loss = 1.80817 (* 1 = 1.80817 loss)
I1029 02:27:13.350973 12802 sgd_solver.cpp:105] Iteration 34440, lr = 0.000450563
I1029 02:27:43.334244 12802 solver.cpp:222] Iteration 34480 (1.33411 iter/s, 29.9826s/40 iters), loss = 1.74917
I1029 02:27:43.334306 12802 solver.cpp:241]     Train net output #0: loss = 1.74917 (* 1 = 1.74917 loss)
I1029 02:27:43.334321 12802 sgd_solver.cpp:105] Iteration 34480, lr = 0.000448943
I1029 02:27:57.665684 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_34500.caffemodel
I1029 02:27:57.806556 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_34500.solverstate
I1029 02:27:57.930060 12802 solver.cpp:334] Iteration 34500, Testing net (#0)
I1029 02:28:29.113250 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 02:28:29.320807 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58192
I1029 02:28:29.320860 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81224
I1029 02:28:29.320871 12802 solver.cpp:401]     Test net output #2: loss = 1.84327 (* 1 = 1.84327 loss)
I1029 02:28:46.014031 12802 solver.cpp:222] Iteration 34520 (0.63818 iter/s, 62.6783s/40 iters), loss = 1.28481
I1029 02:28:46.014107 12802 solver.cpp:241]     Train net output #0: loss = 1.28481 (* 1 = 1.28481 loss)
I1029 02:28:46.014129 12802 sgd_solver.cpp:105] Iteration 34520, lr = 0.00044733
I1029 02:29:16.320231 12802 solver.cpp:222] Iteration 34560 (1.3199 iter/s, 30.3054s/40 iters), loss = 1.70526
I1029 02:29:16.320443 12802 solver.cpp:241]     Train net output #0: loss = 1.70526 (* 1 = 1.70526 loss)
I1029 02:29:16.320458 12802 sgd_solver.cpp:105] Iteration 34560, lr = 0.000445722
I1029 02:29:46.568747 12802 solver.cpp:222] Iteration 34600 (1.32242 iter/s, 30.2476s/40 iters), loss = 1.35674
I1029 02:29:46.568938 12802 solver.cpp:241]     Train net output #0: loss = 1.35674 (* 1 = 1.35674 loss)
I1029 02:29:46.568954 12802 sgd_solver.cpp:105] Iteration 34600, lr = 0.00044412
I1029 02:30:16.933712 12802 solver.cpp:222] Iteration 34640 (1.31735 iter/s, 30.3641s/40 iters), loss = 1.34742
I1029 02:30:16.933909 12802 solver.cpp:241]     Train net output #0: loss = 1.34742 (* 1 = 1.34742 loss)
I1029 02:30:16.933933 12802 sgd_solver.cpp:105] Iteration 34640, lr = 0.000442524
I1029 02:30:46.520566 12802 solver.cpp:222] Iteration 34680 (1.35199 iter/s, 29.5859s/40 iters), loss = 1.35204
I1029 02:30:46.520627 12802 solver.cpp:241]     Train net output #0: loss = 1.35204 (* 1 = 1.35204 loss)
I1029 02:30:46.520642 12802 sgd_solver.cpp:105] Iteration 34680, lr = 0.000440934
I1029 02:31:16.158373 12802 solver.cpp:222] Iteration 34720 (1.34966 iter/s, 29.637s/40 iters), loss = 1.27652
I1029 02:31:16.158535 12802 solver.cpp:241]     Train net output #0: loss = 1.27652 (* 1 = 1.27652 loss)
I1029 02:31:16.158551 12802 sgd_solver.cpp:105] Iteration 34720, lr = 0.000439349
I1029 02:31:46.041748 12802 solver.cpp:222] Iteration 34760 (1.33858 iter/s, 29.8825s/40 iters), loss = 1.45194
I1029 02:31:46.041805 12802 solver.cpp:241]     Train net output #0: loss = 1.45194 (* 1 = 1.45194 loss)
I1029 02:31:46.041821 12802 sgd_solver.cpp:105] Iteration 34760, lr = 0.000437771
I1029 02:32:16.652103 12802 solver.cpp:222] Iteration 34800 (1.30678 iter/s, 30.6096s/40 iters), loss = 1.2973
I1029 02:32:16.652359 12802 solver.cpp:241]     Train net output #0: loss = 1.2973 (* 1 = 1.2973 loss)
I1029 02:32:16.652375 12802 sgd_solver.cpp:105] Iteration 34800, lr = 0.000436197
I1029 02:32:46.843302 12802 solver.cpp:222] Iteration 34840 (1.32493 iter/s, 30.1902s/40 iters), loss = 1.27948
I1029 02:32:46.843458 12802 solver.cpp:241]     Train net output #0: loss = 1.27948 (* 1 = 1.27948 loss)
I1029 02:32:46.843475 12802 sgd_solver.cpp:105] Iteration 34840, lr = 0.00043463
I1029 02:33:16.501397 12802 solver.cpp:222] Iteration 34880 (1.34874 iter/s, 29.6572s/40 iters), loss = 1.39658
I1029 02:33:16.501458 12802 solver.cpp:241]     Train net output #0: loss = 1.39658 (* 1 = 1.39658 loss)
I1029 02:33:16.501474 12802 sgd_solver.cpp:105] Iteration 34880, lr = 0.000433068
I1029 02:33:46.162849 12802 solver.cpp:222] Iteration 34920 (1.34859 iter/s, 29.6607s/40 iters), loss = 1.72189
I1029 02:33:46.163050 12802 solver.cpp:241]     Train net output #0: loss = 1.72189 (* 1 = 1.72189 loss)
I1029 02:33:46.163067 12802 sgd_solver.cpp:105] Iteration 34920, lr = 0.000431511
I1029 02:34:15.797147 12802 solver.cpp:222] Iteration 34960 (1.34983 iter/s, 29.6334s/40 iters), loss = 1.43211
I1029 02:34:15.797205 12802 solver.cpp:241]     Train net output #0: loss = 1.43211 (* 1 = 1.43211 loss)
I1029 02:34:15.797220 12802 sgd_solver.cpp:105] Iteration 34960, lr = 0.000429961
I1029 02:34:44.620679 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_35000.caffemodel
I1029 02:34:44.760975 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_35000.solverstate
I1029 02:34:44.874563 12802 solver.cpp:334] Iteration 35000, Testing net (#0)
I1029 02:35:16.107769 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58524
I1029 02:35:16.107933 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80752
I1029 02:35:16.107947 12802 solver.cpp:401]     Test net output #2: loss = 1.84704 (* 1 = 1.84704 loss)
I1029 02:35:16.854110 12802 solver.cpp:222] Iteration 35000 (0.655142 iter/s, 61.0555s/40 iters), loss = 1.24757
I1029 02:35:16.854174 12802 solver.cpp:241]     Train net output #0: loss = 1.24757 (* 1 = 1.24757 loss)
I1029 02:35:16.854190 12802 sgd_solver.cpp:105] Iteration 35000, lr = 0.000428415
I1029 02:35:46.342007 12802 solver.cpp:222] Iteration 35040 (1.35652 iter/s, 29.4871s/40 iters), loss = 1.30472
I1029 02:35:46.342084 12802 solver.cpp:241]     Train net output #0: loss = 1.30472 (* 1 = 1.30472 loss)
I1029 02:35:46.342102 12802 sgd_solver.cpp:105] Iteration 35040, lr = 0.000426876
I1029 02:36:15.823573 12802 solver.cpp:222] Iteration 35080 (1.35682 iter/s, 29.4808s/40 iters), loss = 1.42
I1029 02:36:15.823635 12802 solver.cpp:241]     Train net output #0: loss = 1.42 (* 1 = 1.42 loss)
I1029 02:36:15.823650 12802 sgd_solver.cpp:105] Iteration 35080, lr = 0.000425342
I1029 02:36:45.296172 12802 solver.cpp:222] Iteration 35120 (1.35723 iter/s, 29.4718s/40 iters), loss = 1.48551
I1029 02:36:45.296319 12802 solver.cpp:241]     Train net output #0: loss = 1.48551 (* 1 = 1.48551 loss)
I1029 02:36:45.296336 12802 sgd_solver.cpp:105] Iteration 35120, lr = 0.000423813
I1029 02:37:14.752490 12802 solver.cpp:222] Iteration 35160 (1.35798 iter/s, 29.4555s/40 iters), loss = 1.36271
I1029 02:37:14.752552 12802 solver.cpp:241]     Train net output #0: loss = 1.36271 (* 1 = 1.36271 loss)
I1029 02:37:14.752568 12802 sgd_solver.cpp:105] Iteration 35160, lr = 0.00042229
I1029 02:37:44.282232 12802 solver.cpp:222] Iteration 35200 (1.3546 iter/s, 29.529s/40 iters), loss = 1.34585
I1029 02:37:44.282407 12802 solver.cpp:241]     Train net output #0: loss = 1.34585 (* 1 = 1.34585 loss)
I1029 02:37:44.282423 12802 sgd_solver.cpp:105] Iteration 35200, lr = 0.000420772
I1029 02:38:13.659394 12802 solver.cpp:222] Iteration 35240 (1.36164 iter/s, 29.3763s/40 iters), loss = 1.44864
I1029 02:38:13.659456 12802 solver.cpp:241]     Train net output #0: loss = 1.44864 (* 1 = 1.44864 loss)
I1029 02:38:13.659471 12802 sgd_solver.cpp:105] Iteration 35240, lr = 0.00041926
I1029 02:38:43.122300 12802 solver.cpp:222] Iteration 35280 (1.35767 iter/s, 29.4621s/40 iters), loss = 1.50328
I1029 02:38:43.122432 12802 solver.cpp:241]     Train net output #0: loss = 1.50328 (* 1 = 1.50328 loss)
I1029 02:38:43.122449 12802 sgd_solver.cpp:105] Iteration 35280, lr = 0.000417753
I1029 02:39:12.706573 12802 solver.cpp:222] Iteration 35320 (1.35211 iter/s, 29.5834s/40 iters), loss = 1.34213
I1029 02:39:12.706634 12802 solver.cpp:241]     Train net output #0: loss = 1.34213 (* 1 = 1.34213 loss)
I1029 02:39:12.706648 12802 sgd_solver.cpp:105] Iteration 35320, lr = 0.000416252
I1029 02:39:42.307062 12802 solver.cpp:222] Iteration 35360 (1.35136 iter/s, 29.5997s/40 iters), loss = 1.32624
I1029 02:39:42.307229 12802 solver.cpp:241]     Train net output #0: loss = 1.32624 (* 1 = 1.32624 loss)
I1029 02:39:42.307246 12802 sgd_solver.cpp:105] Iteration 35360, lr = 0.000414756
I1029 02:40:12.623390 12802 solver.cpp:222] Iteration 35400 (1.31946 iter/s, 30.3154s/40 iters), loss = 1.5429
I1029 02:40:12.623601 12802 solver.cpp:241]     Train net output #0: loss = 1.5429 (* 1 = 1.5429 loss)
I1029 02:40:12.623618 12802 sgd_solver.cpp:105] Iteration 35400, lr = 0.000413266
I1029 02:40:43.518200 12802 solver.cpp:222] Iteration 35440 (1.29476 iter/s, 30.8939s/40 iters), loss = 1.23059
I1029 02:40:43.518411 12802 solver.cpp:241]     Train net output #0: loss = 1.23059 (* 1 = 1.23059 loss)
I1029 02:40:43.518425 12802 sgd_solver.cpp:105] Iteration 35440, lr = 0.00041178
I1029 02:40:45.825649 12853 blocking_queue.cpp:49] Waiting for data
I1029 02:42:04.601938 12802 solver.cpp:222] Iteration 35480 (0.49333 iter/s, 81.0817s/40 iters), loss = 1.58371
I1029 02:42:04.602110 12802 solver.cpp:241]     Train net output #0: loss = 1.58371 (* 1 = 1.58371 loss)
I1029 02:42:04.602133 12802 sgd_solver.cpp:105] Iteration 35480, lr = 0.0004103
I1029 02:42:18.704430 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_35500.caffemodel
I1029 02:42:18.900133 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_35500.solverstate
I1029 02:42:19.016391 12802 solver.cpp:334] Iteration 35500, Testing net (#0)
I1029 02:42:50.034173 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 02:42:50.242868 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5832
I1029 02:42:50.242918 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813679
I1029 02:42:50.242933 12802 solver.cpp:401]     Test net output #2: loss = 1.84141 (* 1 = 1.84141 loss)
I1029 02:43:06.243336 12802 solver.cpp:222] Iteration 35520 (0.648931 iter/s, 61.6398s/40 iters), loss = 1.60534
I1029 02:43:06.243394 12802 solver.cpp:241]     Train net output #0: loss = 1.60534 (* 1 = 1.60534 loss)
I1029 02:43:06.243409 12802 sgd_solver.cpp:105] Iteration 35520, lr = 0.000408826
I1029 02:43:35.897281 12802 solver.cpp:222] Iteration 35560 (1.34893 iter/s, 29.6532s/40 iters), loss = 1.64866
I1029 02:43:35.897495 12802 solver.cpp:241]     Train net output #0: loss = 1.64866 (* 1 = 1.64866 loss)
I1029 02:43:35.897508 12802 sgd_solver.cpp:105] Iteration 35560, lr = 0.000407357
I1029 02:44:05.737126 12802 solver.cpp:222] Iteration 35600 (1.34053 iter/s, 29.8389s/40 iters), loss = 1.18051
I1029 02:44:05.737185 12802 solver.cpp:241]     Train net output #0: loss = 1.18051 (* 1 = 1.18051 loss)
I1029 02:44:05.737198 12802 sgd_solver.cpp:105] Iteration 35600, lr = 0.000405893
I1029 02:44:35.467283 12802 solver.cpp:222] Iteration 35640 (1.34547 iter/s, 29.7294s/40 iters), loss = 1.59609
I1029 02:44:35.467430 12802 solver.cpp:241]     Train net output #0: loss = 1.59609 (* 1 = 1.59609 loss)
I1029 02:44:35.467447 12802 sgd_solver.cpp:105] Iteration 35640, lr = 0.000404434
I1029 02:45:05.328774 12802 solver.cpp:222] Iteration 35680 (1.33956 iter/s, 29.8606s/40 iters), loss = 1.70257
I1029 02:45:05.328832 12802 solver.cpp:241]     Train net output #0: loss = 1.70257 (* 1 = 1.70257 loss)
I1029 02:45:05.328850 12802 sgd_solver.cpp:105] Iteration 35680, lr = 0.000402981
I1029 02:45:35.141077 12802 solver.cpp:222] Iteration 35720 (1.34176 iter/s, 29.8115s/40 iters), loss = 1.46139
I1029 02:45:35.141276 12802 solver.cpp:241]     Train net output #0: loss = 1.46139 (* 1 = 1.46139 loss)
I1029 02:45:35.141295 12802 sgd_solver.cpp:105] Iteration 35720, lr = 0.000401532
I1029 02:46:05.225114 12802 solver.cpp:222] Iteration 35760 (1.32965 iter/s, 30.0831s/40 iters), loss = 1.51049
I1029 02:46:05.225322 12802 solver.cpp:241]     Train net output #0: loss = 1.51049 (* 1 = 1.51049 loss)
I1029 02:46:05.225339 12802 sgd_solver.cpp:105] Iteration 35760, lr = 0.000400089
I1029 02:46:34.994868 12802 solver.cpp:222] Iteration 35800 (1.34369 iter/s, 29.7688s/40 iters), loss = 1.45245
I1029 02:46:34.994931 12802 solver.cpp:241]     Train net output #0: loss = 1.45245 (* 1 = 1.45245 loss)
I1029 02:46:34.994947 12802 sgd_solver.cpp:105] Iteration 35800, lr = 0.000398651
I1029 02:47:05.173552 12802 solver.cpp:222] Iteration 35840 (1.32547 iter/s, 30.1779s/40 iters), loss = 1.4952
I1029 02:47:05.173754 12802 solver.cpp:241]     Train net output #0: loss = 1.4952 (* 1 = 1.4952 loss)
I1029 02:47:05.173771 12802 sgd_solver.cpp:105] Iteration 35840, lr = 0.000397219
I1029 02:47:34.922030 12802 solver.cpp:222] Iteration 35880 (1.34465 iter/s, 29.7476s/40 iters), loss = 1.18975
I1029 02:47:34.922089 12802 solver.cpp:241]     Train net output #0: loss = 1.18975 (* 1 = 1.18975 loss)
I1029 02:47:34.922103 12802 sgd_solver.cpp:105] Iteration 35880, lr = 0.000395791
I1029 02:48:05.010327 12802 solver.cpp:222] Iteration 35920 (1.32946 iter/s, 30.0875s/40 iters), loss = 1.42072
I1029 02:48:05.010545 12802 solver.cpp:241]     Train net output #0: loss = 1.42072 (* 1 = 1.42072 loss)
I1029 02:48:05.010561 12802 sgd_solver.cpp:105] Iteration 35920, lr = 0.000394369
I1029 02:48:35.674204 12802 solver.cpp:222] Iteration 35960 (1.30451 iter/s, 30.6629s/40 iters), loss = 1.37016
I1029 02:48:35.674386 12802 solver.cpp:241]     Train net output #0: loss = 1.37016 (* 1 = 1.37016 loss)
I1029 02:48:35.674403 12802 sgd_solver.cpp:105] Iteration 35960, lr = 0.000392952
I1029 02:49:05.057271 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_36000.caffemodel
I1029 02:49:05.202715 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_36000.solverstate
I1029 02:49:05.320608 12802 solver.cpp:334] Iteration 36000, Testing net (#0)
I1029 02:49:36.635757 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58596
I1029 02:49:36.635931 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.808719
I1029 02:49:36.635943 12802 solver.cpp:401]     Test net output #2: loss = 1.83242 (* 1 = 1.83242 loss)
I1029 02:49:37.403488 12802 solver.cpp:222] Iteration 36000 (0.648008 iter/s, 61.7277s/40 iters), loss = 1.61373
I1029 02:49:37.403547 12802 solver.cpp:241]     Train net output #0: loss = 1.61373 (* 1 = 1.61373 loss)
I1029 02:49:37.403569 12802 sgd_solver.cpp:105] Iteration 36000, lr = 0.000391539
I1029 02:50:07.224750 12802 solver.cpp:222] Iteration 36040 (1.34136 iter/s, 29.8205s/40 iters), loss = 1.56156
I1029 02:50:07.224956 12802 solver.cpp:241]     Train net output #0: loss = 1.56156 (* 1 = 1.56156 loss)
I1029 02:50:07.224973 12802 sgd_solver.cpp:105] Iteration 36040, lr = 0.000390132
I1029 02:50:43.056453 12802 solver.cpp:222] Iteration 36080 (1.11636 iter/s, 35.8306s/40 iters), loss = 1.48109
I1029 02:50:43.056674 12802 solver.cpp:241]     Train net output #0: loss = 1.48109 (* 1 = 1.48109 loss)
I1029 02:50:43.056691 12802 sgd_solver.cpp:105] Iteration 36080, lr = 0.00038873
I1029 02:51:08.402789 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 02:51:12.735519 12802 solver.cpp:222] Iteration 36120 (1.34779 iter/s, 29.6781s/40 iters), loss = 1.55097
I1029 02:51:12.735581 12802 solver.cpp:241]     Train net output #0: loss = 1.55097 (* 1 = 1.55097 loss)
I1029 02:51:12.735595 12802 sgd_solver.cpp:105] Iteration 36120, lr = 0.000387333
I1029 02:51:42.254571 12802 solver.cpp:222] Iteration 36160 (1.35509 iter/s, 29.5183s/40 iters), loss = 1.50864
I1029 02:51:42.254817 12802 solver.cpp:241]     Train net output #0: loss = 1.50864 (* 1 = 1.50864 loss)
I1029 02:51:42.254834 12802 sgd_solver.cpp:105] Iteration 36160, lr = 0.000385941
I1029 02:52:12.065003 12802 solver.cpp:222] Iteration 36200 (1.34185 iter/s, 29.8095s/40 iters), loss = 1.37982
I1029 02:52:12.065065 12802 solver.cpp:241]     Train net output #0: loss = 1.37982 (* 1 = 1.37982 loss)
I1029 02:52:12.065080 12802 sgd_solver.cpp:105] Iteration 36200, lr = 0.000384554
I1029 02:53:50.661299 12802 solver.cpp:222] Iteration 36240 (0.405704 iter/s, 98.594s/40 iters), loss = 1.51991
I1029 02:53:50.661500 12802 solver.cpp:241]     Train net output #0: loss = 1.51991 (* 1 = 1.51991 loss)
I1029 02:53:50.661516 12802 sgd_solver.cpp:105] Iteration 36240, lr = 0.000383172
I1029 02:54:20.608300 12802 solver.cpp:222] Iteration 36280 (1.33573 iter/s, 29.9461s/40 iters), loss = 1.81343
I1029 02:54:20.608361 12802 solver.cpp:241]     Train net output #0: loss = 1.81343 (* 1 = 1.81343 loss)
I1029 02:54:20.608374 12802 sgd_solver.cpp:105] Iteration 36280, lr = 0.000381795
I1029 02:54:51.930847 12802 solver.cpp:222] Iteration 36320 (1.27707 iter/s, 31.3218s/40 iters), loss = 1.43869
I1029 02:54:51.931025 12802 solver.cpp:241]     Train net output #0: loss = 1.43869 (* 1 = 1.43869 loss)
I1029 02:54:51.931041 12802 sgd_solver.cpp:105] Iteration 36320, lr = 0.000380423
I1029 02:55:22.613422 12802 solver.cpp:222] Iteration 36360 (1.30371 iter/s, 30.6817s/40 iters), loss = 1.47498
I1029 02:55:22.613632 12802 solver.cpp:241]     Train net output #0: loss = 1.47498 (* 1 = 1.47498 loss)
I1029 02:55:22.613651 12802 sgd_solver.cpp:105] Iteration 36360, lr = 0.000379056
I1029 02:55:57.092824 12802 solver.cpp:222] Iteration 36400 (1.16015 iter/s, 34.4784s/40 iters), loss = 1.48759
I1029 02:55:57.093016 12802 solver.cpp:241]     Train net output #0: loss = 1.48759 (* 1 = 1.48759 loss)
I1029 02:55:57.093034 12802 sgd_solver.cpp:105] Iteration 36400, lr = 0.000377694
I1029 02:56:26.991654 12802 solver.cpp:222] Iteration 36440 (1.33788 iter/s, 29.8979s/40 iters), loss = 1.48674
I1029 02:56:26.991713 12802 solver.cpp:241]     Train net output #0: loss = 1.48674 (* 1 = 1.48674 loss)
I1029 02:56:26.991727 12802 sgd_solver.cpp:105] Iteration 36440, lr = 0.000376336
I1029 02:56:56.690588 12802 solver.cpp:222] Iteration 36480 (1.34688 iter/s, 29.6982s/40 iters), loss = 1.54701
I1029 02:56:56.690814 12802 solver.cpp:241]     Train net output #0: loss = 1.54701 (* 1 = 1.54701 loss)
I1029 02:56:56.690831 12802 sgd_solver.cpp:105] Iteration 36480, lr = 0.000374984
I1029 02:57:10.870352 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_36500.caffemodel
I1029 02:57:11.057296 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_36500.solverstate
I1029 02:57:11.187438 12802 solver.cpp:334] Iteration 36500, Testing net (#0)
I1029 02:57:42.183082 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 02:57:42.392043 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58248
I1029 02:57:42.392096 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81364
I1029 02:57:42.392107 12802 solver.cpp:401]     Test net output #2: loss = 1.84962 (* 1 = 1.84962 loss)
I1029 02:57:58.525342 12802 solver.cpp:222] Iteration 36520 (0.646903 iter/s, 61.8331s/40 iters), loss = 1.23771
I1029 02:57:58.525398 12802 solver.cpp:241]     Train net output #0: loss = 1.23771 (* 1 = 1.23771 loss)
I1029 02:57:58.525413 12802 sgd_solver.cpp:105] Iteration 36520, lr = 0.000373636
I1029 02:58:28.312836 12802 solver.cpp:222] Iteration 36560 (1.34288 iter/s, 29.7867s/40 iters), loss = 1.38825
I1029 02:58:28.313011 12802 solver.cpp:241]     Train net output #0: loss = 1.38825 (* 1 = 1.38825 loss)
I1029 02:58:28.313030 12802 sgd_solver.cpp:105] Iteration 36560, lr = 0.000372293
I1029 02:58:58.373929 12802 solver.cpp:222] Iteration 36600 (1.33066 iter/s, 30.0602s/40 iters), loss = 1.35336
I1029 02:58:58.374204 12802 solver.cpp:241]     Train net output #0: loss = 1.35336 (* 1 = 1.35336 loss)
I1029 02:58:58.374253 12802 sgd_solver.cpp:105] Iteration 36600, lr = 0.000370955
I1029 02:59:28.221608 12802 solver.cpp:222] Iteration 36640 (1.34018 iter/s, 29.8467s/40 iters), loss = 1.20748
I1029 02:59:28.221674 12802 solver.cpp:241]     Train net output #0: loss = 1.20748 (* 1 = 1.20748 loss)
I1029 02:59:28.221690 12802 sgd_solver.cpp:105] Iteration 36640, lr = 0.000369622
I1029 02:59:58.164353 12802 solver.cpp:222] Iteration 36680 (1.33592 iter/s, 29.942s/40 iters), loss = 1.34334
I1029 02:59:58.164521 12802 solver.cpp:241]     Train net output #0: loss = 1.34334 (* 1 = 1.34334 loss)
I1029 02:59:58.164539 12802 sgd_solver.cpp:105] Iteration 36680, lr = 0.000368294
I1029 03:00:27.706974 12802 solver.cpp:222] Iteration 36720 (1.35402 iter/s, 29.5417s/40 iters), loss = 1.41232
I1029 03:00:27.707039 12802 solver.cpp:241]     Train net output #0: loss = 1.41232 (* 1 = 1.41232 loss)
I1029 03:00:27.707054 12802 sgd_solver.cpp:105] Iteration 36720, lr = 0.00036697
I1029 03:00:57.218703 12802 solver.cpp:222] Iteration 36760 (1.35543 iter/s, 29.511s/40 iters), loss = 1.54665
I1029 03:00:57.218878 12802 solver.cpp:241]     Train net output #0: loss = 1.54665 (* 1 = 1.54665 loss)
I1029 03:00:57.218894 12802 sgd_solver.cpp:105] Iteration 36760, lr = 0.000365652
I1029 03:01:26.814785 12802 solver.cpp:222] Iteration 36800 (1.35157 iter/s, 29.5952s/40 iters), loss = 1.38761
I1029 03:01:26.814851 12802 solver.cpp:241]     Train net output #0: loss = 1.38761 (* 1 = 1.38761 loss)
I1029 03:01:26.814867 12802 sgd_solver.cpp:105] Iteration 36800, lr = 0.000364337
I1029 03:01:56.846086 12802 solver.cpp:222] Iteration 36840 (1.33198 iter/s, 30.0305s/40 iters), loss = 1.74182
I1029 03:01:56.846292 12802 solver.cpp:241]     Train net output #0: loss = 1.74182 (* 1 = 1.74182 loss)
I1029 03:01:56.846309 12802 sgd_solver.cpp:105] Iteration 36840, lr = 0.000363028
I1029 03:02:26.349489 12802 solver.cpp:222] Iteration 36880 (1.35582 iter/s, 29.5025s/40 iters), loss = 1.34878
I1029 03:02:26.349545 12802 solver.cpp:241]     Train net output #0: loss = 1.34878 (* 1 = 1.34878 loss)
I1029 03:02:26.349560 12802 sgd_solver.cpp:105] Iteration 36880, lr = 0.000361723
I1029 03:02:55.875895 12802 solver.cpp:222] Iteration 36920 (1.35475 iter/s, 29.5256s/40 iters), loss = 1.7259
I1029 03:02:55.876044 12802 solver.cpp:241]     Train net output #0: loss = 1.7259 (* 1 = 1.7259 loss)
I1029 03:02:55.876061 12802 sgd_solver.cpp:105] Iteration 36920, lr = 0.000360423
I1029 03:03:25.381836 12802 solver.cpp:222] Iteration 36960 (1.3557 iter/s, 29.5051s/40 iters), loss = 1.58917
I1029 03:03:25.381898 12802 solver.cpp:241]     Train net output #0: loss = 1.58917 (* 1 = 1.58917 loss)
I1029 03:03:25.381913 12802 sgd_solver.cpp:105] Iteration 36960, lr = 0.000359128
I1029 03:03:54.192265 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_37000.caffemodel
I1029 03:03:54.333595 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_37000.solverstate
I1029 03:03:54.455328 12802 solver.cpp:334] Iteration 37000, Testing net (#0)
I1029 03:04:25.709878 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5852
I1029 03:04:25.709967 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80788
I1029 03:04:25.709980 12802 solver.cpp:401]     Test net output #2: loss = 1.83935 (* 1 = 1.83935 loss)
I1029 03:04:26.468380 12802 solver.cpp:222] Iteration 37000 (0.654825 iter/s, 61.085s/40 iters), loss = 1.77296
I1029 03:04:26.468447 12802 solver.cpp:241]     Train net output #0: loss = 1.77296 (* 1 = 1.77296 loss)
I1029 03:04:26.468463 12802 sgd_solver.cpp:105] Iteration 37000, lr = 0.000357838
I1029 03:04:56.053241 12802 solver.cpp:222] Iteration 37040 (1.35208 iter/s, 29.5841s/40 iters), loss = 1.48656
I1029 03:04:56.053362 12802 solver.cpp:241]     Train net output #0: loss = 1.48656 (* 1 = 1.48656 loss)
I1029 03:04:56.053398 12802 sgd_solver.cpp:105] Iteration 37040, lr = 0.000356551
I1029 03:05:25.725800 12802 solver.cpp:222] Iteration 37080 (1.34808 iter/s, 29.6717s/40 iters), loss = 1.37947
I1029 03:05:25.725859 12802 solver.cpp:241]     Train net output #0: loss = 1.37947 (* 1 = 1.37947 loss)
I1029 03:05:25.725875 12802 sgd_solver.cpp:105] Iteration 37080, lr = 0.00035527
I1029 03:05:55.371558 12802 solver.cpp:222] Iteration 37120 (1.3493 iter/s, 29.645s/40 iters), loss = 1.27096
I1029 03:05:55.371667 12802 solver.cpp:241]     Train net output #0: loss = 1.27096 (* 1 = 1.27096 loss)
I1029 03:05:55.371685 12802 sgd_solver.cpp:105] Iteration 37120, lr = 0.000353993
I1029 03:06:25.033162 12802 solver.cpp:222] Iteration 37160 (1.34858 iter/s, 29.6608s/40 iters), loss = 1.30256
I1029 03:06:25.033228 12802 solver.cpp:241]     Train net output #0: loss = 1.30256 (* 1 = 1.30256 loss)
I1029 03:06:25.033242 12802 sgd_solver.cpp:105] Iteration 37160, lr = 0.000352721
I1029 03:06:54.593327 12802 solver.cpp:222] Iteration 37200 (1.35321 iter/s, 29.5594s/40 iters), loss = 1.68928
I1029 03:06:54.593468 12802 solver.cpp:241]     Train net output #0: loss = 1.68928 (* 1 = 1.68928 loss)
I1029 03:06:54.593485 12802 sgd_solver.cpp:105] Iteration 37200, lr = 0.000351454
I1029 03:07:24.123165 12802 solver.cpp:222] Iteration 37240 (1.3546 iter/s, 29.529s/40 iters), loss = 1.36229
I1029 03:07:24.123230 12802 solver.cpp:241]     Train net output #0: loss = 1.36229 (* 1 = 1.36229 loss)
I1029 03:07:24.123246 12802 sgd_solver.cpp:105] Iteration 37240, lr = 0.000350191
I1029 03:07:53.721145 12802 solver.cpp:222] Iteration 37280 (1.35148 iter/s, 29.5972s/40 iters), loss = 1.27469
I1029 03:07:53.721304 12802 solver.cpp:241]     Train net output #0: loss = 1.27469 (* 1 = 1.27469 loss)
I1029 03:07:53.721328 12802 sgd_solver.cpp:105] Iteration 37280, lr = 0.000348932
I1029 03:08:23.318644 12802 solver.cpp:222] Iteration 37320 (1.3515 iter/s, 29.5966s/40 iters), loss = 1.44241
I1029 03:08:23.318701 12802 solver.cpp:241]     Train net output #0: loss = 1.44241 (* 1 = 1.44241 loss)
I1029 03:08:23.318717 12802 sgd_solver.cpp:105] Iteration 37320, lr = 0.000347678
I1029 03:08:52.999888 12802 solver.cpp:222] Iteration 37360 (1.34769 iter/s, 29.6805s/40 iters), loss = 1.28985
I1029 03:08:52.999996 12802 solver.cpp:241]     Train net output #0: loss = 1.28985 (* 1 = 1.28985 loss)
I1029 03:08:53.000012 12802 sgd_solver.cpp:105] Iteration 37360, lr = 0.000346428
I1029 03:09:22.513727 12802 solver.cpp:222] Iteration 37400 (1.35533 iter/s, 29.513s/40 iters), loss = 1.32917
I1029 03:09:22.513790 12802 solver.cpp:241]     Train net output #0: loss = 1.32917 (* 1 = 1.32917 loss)
I1029 03:09:22.513805 12802 sgd_solver.cpp:105] Iteration 37400, lr = 0.000345184
I1029 03:09:52.034209 12802 solver.cpp:222] Iteration 37440 (1.35503 iter/s, 29.5197s/40 iters), loss = 1.57045
I1029 03:09:52.034354 12802 solver.cpp:241]     Train net output #0: loss = 1.57045 (* 1 = 1.57045 loss)
I1029 03:09:52.034371 12802 sgd_solver.cpp:105] Iteration 37440, lr = 0.000343943
I1029 03:10:21.556867 12802 solver.cpp:222] Iteration 37480 (1.35493 iter/s, 29.5218s/40 iters), loss = 1.23314
I1029 03:10:21.556931 12802 solver.cpp:241]     Train net output #0: loss = 1.23314 (* 1 = 1.23314 loss)
I1029 03:10:21.556947 12802 sgd_solver.cpp:105] Iteration 37480, lr = 0.000342707
I1029 03:10:35.579988 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_37500.caffemodel
I1029 03:10:35.733361 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_37500.solverstate
I1029 03:10:35.853313 12802 solver.cpp:334] Iteration 37500, Testing net (#0)
I1029 03:11:07.022428 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 03:11:07.234422 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58296
I1029 03:11:07.234477 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81304
I1029 03:11:07.234488 12802 solver.cpp:401]     Test net output #2: loss = 1.84173 (* 1 = 1.84173 loss)
I1029 03:11:22.773036 12802 solver.cpp:222] Iteration 37520 (0.653438 iter/s, 61.2147s/40 iters), loss = 1.53628
I1029 03:11:22.773095 12802 solver.cpp:241]     Train net output #0: loss = 1.53628 (* 1 = 1.53628 loss)
I1029 03:11:22.773111 12802 sgd_solver.cpp:105] Iteration 37520, lr = 0.000341475
I1029 03:11:52.349570 12802 solver.cpp:222] Iteration 37560 (1.35246 iter/s, 29.5758s/40 iters), loss = 1.28322
I1029 03:11:52.349807 12802 solver.cpp:241]     Train net output #0: loss = 1.28322 (* 1 = 1.28322 loss)
I1029 03:11:52.349825 12802 sgd_solver.cpp:105] Iteration 37560, lr = 0.000340248
I1029 03:12:22.037304 12802 solver.cpp:222] Iteration 37600 (1.3474 iter/s, 29.6868s/40 iters), loss = 1.55773
I1029 03:12:22.037359 12802 solver.cpp:241]     Train net output #0: loss = 1.55773 (* 1 = 1.55773 loss)
I1029 03:12:22.037374 12802 sgd_solver.cpp:105] Iteration 37600, lr = 0.000339025
I1029 03:12:51.748131 12802 solver.cpp:222] Iteration 37640 (1.34635 iter/s, 29.7101s/40 iters), loss = 1.44121
I1029 03:12:51.748298 12802 solver.cpp:241]     Train net output #0: loss = 1.44121 (* 1 = 1.44121 loss)
I1029 03:12:51.748316 12802 sgd_solver.cpp:105] Iteration 37640, lr = 0.000337807
I1029 03:13:21.476850 12802 solver.cpp:222] Iteration 37680 (1.34554 iter/s, 29.7278s/40 iters), loss = 1.57326
I1029 03:13:21.476907 12802 solver.cpp:241]     Train net output #0: loss = 1.57326 (* 1 = 1.57326 loss)
I1029 03:13:21.476925 12802 sgd_solver.cpp:105] Iteration 37680, lr = 0.000336593
I1029 03:13:51.995661 12802 solver.cpp:222] Iteration 37720 (1.3107 iter/s, 30.518s/40 iters), loss = 1.54316
I1029 03:13:51.995817 12802 solver.cpp:241]     Train net output #0: loss = 1.54316 (* 1 = 1.54316 loss)
I1029 03:13:51.995832 12802 sgd_solver.cpp:105] Iteration 37720, lr = 0.000335383
I1029 03:16:22.786761 12802 solver.cpp:222] Iteration 37760 (0.265274 iter/s, 150.788s/40 iters), loss = 1.80812
I1029 03:16:22.787341 12802 solver.cpp:241]     Train net output #0: loss = 1.80812 (* 1 = 1.80812 loss)
I1029 03:16:22.787359 12802 sgd_solver.cpp:105] Iteration 37760, lr = 0.000334178
I1029 03:16:55.545948 12802 solver.cpp:222] Iteration 37800 (1.22108 iter/s, 32.7579s/40 iters), loss = 1.28041
I1029 03:16:55.546106 12802 solver.cpp:241]     Train net output #0: loss = 1.28041 (* 1 = 1.28041 loss)
I1029 03:16:55.546120 12802 sgd_solver.cpp:105] Iteration 37800, lr = 0.000332977
I1029 03:17:26.116822 12802 solver.cpp:222] Iteration 37840 (1.30847 iter/s, 30.57s/40 iters), loss = 1.38936
I1029 03:17:26.116983 12802 solver.cpp:241]     Train net output #0: loss = 1.38936 (* 1 = 1.38936 loss)
I1029 03:17:26.116998 12802 sgd_solver.cpp:105] Iteration 37840, lr = 0.00033178
I1029 03:17:56.417376 12802 solver.cpp:222] Iteration 37880 (1.32015 iter/s, 30.2997s/40 iters), loss = 1.46118
I1029 03:17:56.417529 12802 solver.cpp:241]     Train net output #0: loss = 1.46118 (* 1 = 1.46118 loss)
I1029 03:17:56.417546 12802 sgd_solver.cpp:105] Iteration 37880, lr = 0.000330588
I1029 03:18:26.198418 12802 solver.cpp:222] Iteration 37920 (1.34317 iter/s, 29.7802s/40 iters), loss = 1.36409
I1029 03:18:26.198477 12802 solver.cpp:241]     Train net output #0: loss = 1.36409 (* 1 = 1.36409 loss)
I1029 03:18:26.198493 12802 sgd_solver.cpp:105] Iteration 37920, lr = 0.0003294
I1029 03:18:55.926563 12802 solver.cpp:222] Iteration 37960 (1.34556 iter/s, 29.7274s/40 iters), loss = 1.68244
I1029 03:18:55.926769 12802 solver.cpp:241]     Train net output #0: loss = 1.68244 (* 1 = 1.68244 loss)
I1029 03:18:55.926786 12802 sgd_solver.cpp:105] Iteration 37960, lr = 0.000328216
I1029 03:19:25.150758 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_38000.caffemodel
I1029 03:19:25.397575 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_38000.solverstate
I1029 03:19:25.510968 12802 solver.cpp:334] Iteration 38000, Testing net (#0)
I1029 03:19:56.724136 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58808
I1029 03:19:56.724391 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80832
I1029 03:19:56.724406 12802 solver.cpp:401]     Test net output #2: loss = 1.83351 (* 1 = 1.83351 loss)
I1029 03:19:57.495283 12802 solver.cpp:222] Iteration 38000 (0.649698 iter/s, 61.5671s/40 iters), loss = 1.57571
I1029 03:19:57.495342 12802 solver.cpp:241]     Train net output #0: loss = 1.57571 (* 1 = 1.57571 loss)
I1029 03:19:57.495358 12802 sgd_solver.cpp:105] Iteration 38000, lr = 0.000327037
I1029 03:20:27.562866 12802 solver.cpp:222] Iteration 38040 (1.33037 iter/s, 30.0668s/40 iters), loss = 1.71827
I1029 03:20:27.563105 12802 solver.cpp:241]     Train net output #0: loss = 1.71827 (* 1 = 1.71827 loss)
I1029 03:20:27.563122 12802 sgd_solver.cpp:105] Iteration 38040, lr = 0.000325861
I1029 03:20:57.212779 12802 solver.cpp:222] Iteration 38080 (1.34912 iter/s, 29.649s/40 iters), loss = 1.49339
I1029 03:20:57.212836 12802 solver.cpp:241]     Train net output #0: loss = 1.49339 (* 1 = 1.49339 loss)
I1029 03:20:57.212852 12802 sgd_solver.cpp:105] Iteration 38080, lr = 0.00032469
I1029 03:21:26.934861 12802 solver.cpp:222] Iteration 38120 (1.34584 iter/s, 29.7213s/40 iters), loss = 1.41292
I1029 03:21:26.935024 12802 solver.cpp:241]     Train net output #0: loss = 1.41292 (* 1 = 1.41292 loss)
I1029 03:21:26.935041 12802 sgd_solver.cpp:105] Iteration 38120, lr = 0.000323523
I1029 03:21:56.670193 12802 solver.cpp:222] Iteration 38160 (1.34524 iter/s, 29.7345s/40 iters), loss = 1.56054
I1029 03:21:56.670251 12802 solver.cpp:241]     Train net output #0: loss = 1.56054 (* 1 = 1.56054 loss)
I1029 03:21:56.670267 12802 sgd_solver.cpp:105] Iteration 38160, lr = 0.000322361
I1029 03:22:26.579900 12802 solver.cpp:222] Iteration 38200 (1.33739 iter/s, 29.9089s/40 iters), loss = 1.35028
I1029 03:22:26.580096 12802 solver.cpp:241]     Train net output #0: loss = 1.35028 (* 1 = 1.35028 loss)
I1029 03:22:26.580113 12802 sgd_solver.cpp:105] Iteration 38200, lr = 0.000321202
I1029 03:22:56.395927 12802 solver.cpp:222] Iteration 38240 (1.3416 iter/s, 29.8151s/40 iters), loss = 1.31251
I1029 03:22:56.395985 12802 solver.cpp:241]     Train net output #0: loss = 1.31251 (* 1 = 1.31251 loss)
I1029 03:22:56.396001 12802 sgd_solver.cpp:105] Iteration 38240, lr = 0.000320048
I1029 03:23:26.614390 12802 solver.cpp:222] Iteration 38280 (1.32373 iter/s, 30.2177s/40 iters), loss = 1.52871
I1029 03:23:26.614585 12802 solver.cpp:241]     Train net output #0: loss = 1.52871 (* 1 = 1.52871 loss)
I1029 03:23:26.614603 12802 sgd_solver.cpp:105] Iteration 38280, lr = 0.000318898
I1029 03:23:57.150588 12802 solver.cpp:222] Iteration 38320 (1.30996 iter/s, 30.5353s/40 iters), loss = 1.45182
I1029 03:23:57.150774 12802 solver.cpp:241]     Train net output #0: loss = 1.45182 (* 1 = 1.45182 loss)
I1029 03:23:57.150787 12802 sgd_solver.cpp:105] Iteration 38320, lr = 0.000317752
I1029 03:24:27.767678 12802 solver.cpp:222] Iteration 38360 (1.3065 iter/s, 30.6162s/40 iters), loss = 1.24656
I1029 03:24:27.767820 12802 solver.cpp:241]     Train net output #0: loss = 1.24656 (* 1 = 1.24656 loss)
I1029 03:24:27.767835 12802 sgd_solver.cpp:105] Iteration 38360, lr = 0.00031661
I1029 03:24:58.339004 12802 solver.cpp:222] Iteration 38400 (1.30845 iter/s, 30.5705s/40 iters), loss = 1.48477
I1029 03:24:58.339217 12802 solver.cpp:241]     Train net output #0: loss = 1.48477 (* 1 = 1.48477 loss)
I1029 03:24:58.339231 12802 sgd_solver.cpp:105] Iteration 38400, lr = 0.000315472
I1029 03:25:28.673269 12802 solver.cpp:222] Iteration 38440 (1.31868 iter/s, 30.3333s/40 iters), loss = 1.38903
I1029 03:25:28.673458 12802 solver.cpp:241]     Train net output #0: loss = 1.38903 (* 1 = 1.38903 loss)
I1029 03:25:28.673475 12802 sgd_solver.cpp:105] Iteration 38440, lr = 0.000314338
I1029 03:25:59.942382 12802 solver.cpp:222] Iteration 38480 (1.27926 iter/s, 31.2682s/40 iters), loss = 1.53345
I1029 03:25:59.942566 12802 solver.cpp:241]     Train net output #0: loss = 1.53345 (* 1 = 1.53345 loss)
I1029 03:25:59.942584 12802 sgd_solver.cpp:105] Iteration 38480, lr = 0.000313208
I1029 03:26:14.895380 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_38500.caffemodel
I1029 03:26:15.048523 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_38500.solverstate
I1029 03:26:15.160799 12802 solver.cpp:334] Iteration 38500, Testing net (#0)
I1029 03:26:46.482394 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 03:26:46.629905 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58452
I1029 03:26:46.629961 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81388
I1029 03:26:46.629971 12802 solver.cpp:401]     Test net output #2: loss = 1.84755 (* 1 = 1.84755 loss)
I1029 03:27:03.013571 12802 solver.cpp:222] Iteration 38520 (0.634221 iter/s, 63.0695s/40 iters), loss = 1.41897
I1029 03:27:03.013630 12802 solver.cpp:241]     Train net output #0: loss = 1.41897 (* 1 = 1.41897 loss)
I1029 03:27:03.013646 12802 sgd_solver.cpp:105] Iteration 38520, lr = 0.000312083
I1029 03:27:33.438966 12802 solver.cpp:222] Iteration 38560 (1.31473 iter/s, 30.4246s/40 iters), loss = 1.49571
I1029 03:27:33.439165 12802 solver.cpp:241]     Train net output #0: loss = 1.49571 (* 1 = 1.49571 loss)
I1029 03:27:33.439184 12802 sgd_solver.cpp:105] Iteration 38560, lr = 0.000310961
I1029 03:28:03.750437 12802 solver.cpp:222] Iteration 38600 (1.31967 iter/s, 30.3105s/40 iters), loss = 1.33839
I1029 03:28:03.750629 12802 solver.cpp:241]     Train net output #0: loss = 1.33839 (* 1 = 1.33839 loss)
I1029 03:28:03.750646 12802 sgd_solver.cpp:105] Iteration 38600, lr = 0.000309844
I1029 03:28:16.172999 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 03:28:33.762569 12802 solver.cpp:222] Iteration 38640 (1.33283 iter/s, 30.0112s/40 iters), loss = 1.3866
I1029 03:28:33.762755 12802 solver.cpp:241]     Train net output #0: loss = 1.3866 (* 1 = 1.3866 loss)
I1029 03:28:33.762770 12802 sgd_solver.cpp:105] Iteration 38640, lr = 0.00030873
I1029 03:29:03.833767 12802 solver.cpp:222] Iteration 38680 (1.33022 iter/s, 30.0703s/40 iters), loss = 1.30041
I1029 03:29:03.833923 12802 solver.cpp:241]     Train net output #0: loss = 1.30041 (* 1 = 1.30041 loss)
I1029 03:29:03.833941 12802 sgd_solver.cpp:105] Iteration 38680, lr = 0.000307621
I1029 03:29:33.722084 12802 solver.cpp:222] Iteration 38720 (1.33835 iter/s, 29.8875s/40 iters), loss = 1.18146
I1029 03:29:33.722147 12802 solver.cpp:241]     Train net output #0: loss = 1.18146 (* 1 = 1.18146 loss)
I1029 03:29:33.722163 12802 sgd_solver.cpp:105] Iteration 38720, lr = 0.000306515
I1029 03:30:03.948570 12802 solver.cpp:222] Iteration 38760 (1.32338 iter/s, 30.2257s/40 iters), loss = 1.40369
I1029 03:30:03.948789 12802 solver.cpp:241]     Train net output #0: loss = 1.40369 (* 1 = 1.40369 loss)
I1029 03:30:03.948803 12802 sgd_solver.cpp:105] Iteration 38760, lr = 0.000305413
I1029 03:30:34.237761 12802 solver.cpp:222] Iteration 38800 (1.32064 iter/s, 30.2882s/40 iters), loss = 1.25962
I1029 03:30:34.237941 12802 solver.cpp:241]     Train net output #0: loss = 1.25962 (* 1 = 1.25962 loss)
I1029 03:30:34.237958 12802 sgd_solver.cpp:105] Iteration 38800, lr = 0.000304316
I1029 03:31:04.405112 12802 solver.cpp:222] Iteration 38840 (1.32598 iter/s, 30.1665s/40 iters), loss = 1.37493
I1029 03:31:04.405279 12802 solver.cpp:241]     Train net output #0: loss = 1.37493 (* 1 = 1.37493 loss)
I1029 03:31:04.405297 12802 sgd_solver.cpp:105] Iteration 38840, lr = 0.000303222
I1029 03:31:37.526057 12802 solver.cpp:222] Iteration 38880 (1.20773 iter/s, 33.12s/40 iters), loss = 1.38977
I1029 03:31:37.526232 12802 solver.cpp:241]     Train net output #0: loss = 1.38977 (* 1 = 1.38977 loss)
I1029 03:31:37.526249 12802 sgd_solver.cpp:105] Iteration 38880, lr = 0.000302133
I1029 03:32:07.167327 12802 solver.cpp:222] Iteration 38920 (1.34951 iter/s, 29.6404s/40 iters), loss = 1.32047
I1029 03:32:07.167384 12802 solver.cpp:241]     Train net output #0: loss = 1.32047 (* 1 = 1.32047 loss)
I1029 03:32:07.167399 12802 sgd_solver.cpp:105] Iteration 38920, lr = 0.000301047
I1029 03:32:37.004945 12802 solver.cpp:222] Iteration 38960 (1.34062 iter/s, 29.8369s/40 iters), loss = 1.50908
I1029 03:32:37.005157 12802 solver.cpp:241]     Train net output #0: loss = 1.50908 (* 1 = 1.50908 loss)
I1029 03:32:37.005177 12802 sgd_solver.cpp:105] Iteration 38960, lr = 0.000299965
I1029 03:33:05.950649 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_39000.caffemodel
I1029 03:33:06.092442 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_39000.solverstate
I1029 03:33:06.206537 12802 solver.cpp:334] Iteration 39000, Testing net (#0)
I1029 03:33:37.509790 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58664
I1029 03:33:37.509984 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80752
I1029 03:33:37.509997 12802 solver.cpp:401]     Test net output #2: loss = 1.84517 (* 1 = 1.84517 loss)
I1029 03:33:38.277109 12802 solver.cpp:222] Iteration 39000 (0.652842 iter/s, 61.2705s/40 iters), loss = 1.73529
I1029 03:33:38.277148 12802 solver.cpp:241]     Train net output #0: loss = 1.73529 (* 1 = 1.73529 loss)
I1029 03:33:38.277166 12802 sgd_solver.cpp:105] Iteration 39000, lr = 0.000298887
I1029 03:34:07.770534 12802 solver.cpp:222] Iteration 39040 (1.35627 iter/s, 29.4927s/40 iters), loss = 1.66192
I1029 03:34:07.770722 12802 solver.cpp:241]     Train net output #0: loss = 1.66192 (* 1 = 1.66192 loss)
I1029 03:34:07.770740 12802 sgd_solver.cpp:105] Iteration 39040, lr = 0.000297813
I1029 03:34:37.244485 12802 solver.cpp:222] Iteration 39080 (1.35717 iter/s, 29.4731s/40 iters), loss = 1.36922
I1029 03:34:37.244547 12802 solver.cpp:241]     Train net output #0: loss = 1.36922 (* 1 = 1.36922 loss)
I1029 03:34:37.244568 12802 sgd_solver.cpp:105] Iteration 39080, lr = 0.000296742
I1029 03:35:07.216965 12802 solver.cpp:222] Iteration 39120 (1.33459 iter/s, 29.9717s/40 iters), loss = 1.52616
I1029 03:35:07.217150 12802 solver.cpp:241]     Train net output #0: loss = 1.52616 (* 1 = 1.52616 loss)
I1029 03:35:07.217167 12802 sgd_solver.cpp:105] Iteration 39120, lr = 0.000295676
I1029 03:35:36.701089 12802 solver.cpp:222] Iteration 39160 (1.3567 iter/s, 29.4832s/40 iters), loss = 1.15071
I1029 03:35:36.701154 12802 solver.cpp:241]     Train net output #0: loss = 1.15071 (* 1 = 1.15071 loss)
I1029 03:35:36.701170 12802 sgd_solver.cpp:105] Iteration 39160, lr = 0.000294613
I1029 03:36:06.297825 12802 solver.cpp:222] Iteration 39200 (1.35154 iter/s, 29.596s/40 iters), loss = 1.1789
I1029 03:36:06.297978 12802 solver.cpp:241]     Train net output #0: loss = 1.1789 (* 1 = 1.1789 loss)
I1029 03:36:06.297996 12802 sgd_solver.cpp:105] Iteration 39200, lr = 0.000293555
I1029 03:36:35.914614 12802 solver.cpp:222] Iteration 39240 (1.35062 iter/s, 29.6159s/40 iters), loss = 1.20922
I1029 03:36:35.914672 12802 solver.cpp:241]     Train net output #0: loss = 1.20922 (* 1 = 1.20922 loss)
I1029 03:36:35.914687 12802 sgd_solver.cpp:105] Iteration 39240, lr = 0.0002925
I1029 03:37:05.738374 12802 solver.cpp:222] Iteration 39280 (1.34125 iter/s, 29.823s/40 iters), loss = 1.24047
I1029 03:37:05.738543 12802 solver.cpp:241]     Train net output #0: loss = 1.24047 (* 1 = 1.24047 loss)
I1029 03:37:05.738557 12802 sgd_solver.cpp:105] Iteration 39280, lr = 0.000291448
I1029 03:37:35.213977 12802 solver.cpp:222] Iteration 39320 (1.35709 iter/s, 29.4747s/40 iters), loss = 1.38225
I1029 03:37:35.214038 12802 solver.cpp:241]     Train net output #0: loss = 1.38225 (* 1 = 1.38225 loss)
I1029 03:37:35.214053 12802 sgd_solver.cpp:105] Iteration 39320, lr = 0.000290401
I1029 03:38:04.685737 12802 solver.cpp:222] Iteration 39360 (1.35727 iter/s, 29.471s/40 iters), loss = 1.40536
I1029 03:38:04.685950 12802 solver.cpp:241]     Train net output #0: loss = 1.40536 (* 1 = 1.40536 loss)
I1029 03:38:04.685966 12802 sgd_solver.cpp:105] Iteration 39360, lr = 0.000289357
I1029 03:38:34.265437 12802 solver.cpp:222] Iteration 39400 (1.35232 iter/s, 29.5788s/40 iters), loss = 1.31944
I1029 03:38:34.265504 12802 solver.cpp:241]     Train net output #0: loss = 1.31944 (* 1 = 1.31944 loss)
I1029 03:38:34.265517 12802 sgd_solver.cpp:105] Iteration 39400, lr = 0.000288317
I1029 03:39:04.000793 12802 solver.cpp:222] Iteration 39440 (1.34524 iter/s, 29.7346s/40 iters), loss = 1.56576
I1029 03:39:04.001013 12802 solver.cpp:241]     Train net output #0: loss = 1.56576 (* 1 = 1.56576 loss)
I1029 03:39:04.001039 12802 sgd_solver.cpp:105] Iteration 39440, lr = 0.000287281
I1029 03:39:34.734024 12802 solver.cpp:222] Iteration 39480 (1.30156 iter/s, 30.7323s/40 iters), loss = 1.67869
I1029 03:39:34.734226 12802 solver.cpp:241]     Train net output #0: loss = 1.67869 (* 1 = 1.67869 loss)
I1029 03:39:34.734241 12802 sgd_solver.cpp:105] Iteration 39480, lr = 0.000286249
I1029 03:39:56.300771 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_39500.caffemodel
I1029 03:40:06.886103 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_39500.solverstate
I1029 03:40:10.210068 12802 solver.cpp:334] Iteration 39500, Testing net (#0)
I1029 03:40:54.891126 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 03:40:55.102720 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5832
I1029 03:40:55.102773 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81344
I1029 03:40:55.102784 12802 solver.cpp:401]     Test net output #2: loss = 1.8434 (* 1 = 1.8434 loss)
I1029 03:41:18.606781 12802 solver.cpp:222] Iteration 39520 (0.385096 iter/s, 103.87s/40 iters), loss = 1.44765
I1029 03:41:18.606843 12802 solver.cpp:241]     Train net output #0: loss = 1.44765 (* 1 = 1.44765 loss)
I1029 03:41:18.606860 12802 sgd_solver.cpp:105] Iteration 39520, lr = 0.00028522
I1029 03:41:49.164367 12802 solver.cpp:222] Iteration 39560 (1.30904 iter/s, 30.5568s/40 iters), loss = 1.71505
I1029 03:41:49.164585 12802 solver.cpp:241]     Train net output #0: loss = 1.71505 (* 1 = 1.71505 loss)
I1029 03:41:49.164603 12802 sgd_solver.cpp:105] Iteration 39560, lr = 0.000284195
I1029 03:42:19.588065 12802 solver.cpp:222] Iteration 39600 (1.3148 iter/s, 30.4228s/40 iters), loss = 1.53951
I1029 03:42:19.588208 12802 solver.cpp:241]     Train net output #0: loss = 1.53951 (* 1 = 1.53951 loss)
I1029 03:42:19.588222 12802 sgd_solver.cpp:105] Iteration 39600, lr = 0.000283174
I1029 03:42:50.144541 12802 solver.cpp:222] Iteration 39640 (1.30909 iter/s, 30.5556s/40 iters), loss = 1.15436
I1029 03:42:50.144716 12802 solver.cpp:241]     Train net output #0: loss = 1.15436 (* 1 = 1.15436 loss)
I1029 03:42:50.144732 12802 sgd_solver.cpp:105] Iteration 39640, lr = 0.000282156
I1029 03:43:24.182844 12802 solver.cpp:222] Iteration 39680 (1.17518 iter/s, 34.0373s/40 iters), loss = 1.2464
I1029 03:43:24.183044 12802 solver.cpp:241]     Train net output #0: loss = 1.2464 (* 1 = 1.2464 loss)
I1029 03:43:24.183066 12802 sgd_solver.cpp:105] Iteration 39680, lr = 0.000281142
I1029 03:43:58.821344 12802 solver.cpp:222] Iteration 39720 (1.15482 iter/s, 34.6375s/40 iters), loss = 1.3747
I1029 03:43:58.821501 12802 solver.cpp:241]     Train net output #0: loss = 1.3747 (* 1 = 1.3747 loss)
I1029 03:43:58.821514 12802 sgd_solver.cpp:105] Iteration 39720, lr = 0.000280132
I1029 03:44:28.869598 12802 solver.cpp:222] Iteration 39760 (1.33123 iter/s, 30.0474s/40 iters), loss = 1.55178
I1029 03:44:28.869807 12802 solver.cpp:241]     Train net output #0: loss = 1.55178 (* 1 = 1.55178 loss)
I1029 03:44:28.869823 12802 sgd_solver.cpp:105] Iteration 39760, lr = 0.000279125
I1029 03:44:58.565960 12802 solver.cpp:222] Iteration 39800 (1.34701 iter/s, 29.6954s/40 iters), loss = 1.49188
I1029 03:44:58.566022 12802 solver.cpp:241]     Train net output #0: loss = 1.49188 (* 1 = 1.49188 loss)
I1029 03:44:58.566038 12802 sgd_solver.cpp:105] Iteration 39800, lr = 0.000278122
I1029 03:45:28.300927 12802 solver.cpp:222] Iteration 39840 (1.34525 iter/s, 29.7342s/40 iters), loss = 1.56037
I1029 03:45:28.301168 12802 solver.cpp:241]     Train net output #0: loss = 1.56037 (* 1 = 1.56037 loss)
I1029 03:45:28.301187 12802 sgd_solver.cpp:105] Iteration 39840, lr = 0.000277122
I1029 03:45:57.940481 12802 solver.cpp:222] Iteration 39880 (1.34959 iter/s, 29.6386s/40 iters), loss = 1.85922
I1029 03:45:57.940543 12802 solver.cpp:241]     Train net output #0: loss = 1.85922 (* 1 = 1.85922 loss)
I1029 03:45:57.940559 12802 sgd_solver.cpp:105] Iteration 39880, lr = 0.000276126
I1029 03:46:27.576103 12802 solver.cpp:222] Iteration 39920 (1.34976 iter/s, 29.6348s/40 iters), loss = 1.22929
I1029 03:46:27.576253 12802 solver.cpp:241]     Train net output #0: loss = 1.22929 (* 1 = 1.22929 loss)
I1029 03:46:27.576270 12802 sgd_solver.cpp:105] Iteration 39920, lr = 0.000275134
I1029 03:46:58.157392 12802 solver.cpp:222] Iteration 39960 (1.30803 iter/s, 30.5804s/40 iters), loss = 1.35694
I1029 03:46:58.157541 12802 solver.cpp:241]     Train net output #0: loss = 1.35694 (* 1 = 1.35694 loss)
I1029 03:46:58.157558 12802 sgd_solver.cpp:105] Iteration 39960, lr = 0.000274145
I1029 03:47:27.741966 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_40000.caffemodel
I1029 03:47:27.897984 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_40000.solverstate
I1029 03:47:28.012558 12802 solver.cpp:334] Iteration 40000, Testing net (#0)
I1029 03:47:59.274067 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58732
I1029 03:47:59.274224 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80948
I1029 03:47:59.274238 12802 solver.cpp:401]     Test net output #2: loss = 1.83496 (* 1 = 1.83496 loss)
I1029 03:48:00.021636 12802 solver.cpp:222] Iteration 40000 (0.646594 iter/s, 61.8626s/40 iters), loss = 1.27283
I1029 03:48:00.021694 12802 solver.cpp:241]     Train net output #0: loss = 1.27283 (* 1 = 1.27283 loss)
I1029 03:48:00.021710 12802 sgd_solver.cpp:105] Iteration 40000, lr = 0.00027316
I1029 03:48:31.972662 12802 solver.cpp:222] Iteration 40040 (1.25195 iter/s, 31.9502s/40 iters), loss = 1.60839
I1029 03:48:31.972836 12802 solver.cpp:241]     Train net output #0: loss = 1.60839 (* 1 = 1.60839 loss)
I1029 03:48:31.972863 12802 sgd_solver.cpp:105] Iteration 40040, lr = 0.000272178
I1029 03:49:02.725539 12802 solver.cpp:222] Iteration 40080 (1.30073 iter/s, 30.752s/40 iters), loss = 1.40997
I1029 03:49:02.725687 12802 solver.cpp:241]     Train net output #0: loss = 1.40997 (* 1 = 1.40997 loss)
I1029 03:49:02.725703 12802 sgd_solver.cpp:105] Iteration 40080, lr = 0.0002712
I1029 03:49:33.559825 12802 solver.cpp:222] Iteration 40120 (1.29729 iter/s, 30.8334s/40 iters), loss = 1.36566
I1029 03:49:33.559973 12802 solver.cpp:241]     Train net output #0: loss = 1.36566 (* 1 = 1.36566 loss)
I1029 03:49:33.559990 12802 sgd_solver.cpp:105] Iteration 40120, lr = 0.000270226
I1029 03:50:06.663723 12802 solver.cpp:222] Iteration 40160 (1.20835 iter/s, 33.103s/40 iters), loss = 1.50839
I1029 03:50:06.663931 12802 solver.cpp:241]     Train net output #0: loss = 1.50839 (* 1 = 1.50839 loss)
I1029 03:50:06.663950 12802 sgd_solver.cpp:105] Iteration 40160, lr = 0.000269254
I1029 03:50:36.646957 12802 solver.cpp:222] Iteration 40200 (1.33412 iter/s, 29.9823s/40 iters), loss = 1.54852
I1029 03:50:36.647016 12802 solver.cpp:241]     Train net output #0: loss = 1.54852 (* 1 = 1.54852 loss)
I1029 03:50:36.647032 12802 sgd_solver.cpp:105] Iteration 40200, lr = 0.000268287
I1029 03:51:06.180541 12802 solver.cpp:222] Iteration 40240 (1.35443 iter/s, 29.5328s/40 iters), loss = 1.63349
I1029 03:51:06.180764 12802 solver.cpp:241]     Train net output #0: loss = 1.63349 (* 1 = 1.63349 loss)
I1029 03:51:06.180788 12802 sgd_solver.cpp:105] Iteration 40240, lr = 0.000267323
I1029 03:51:35.851276 12802 solver.cpp:222] Iteration 40280 (1.34817 iter/s, 29.6698s/40 iters), loss = 1.563
I1029 03:51:35.851335 12802 solver.cpp:241]     Train net output #0: loss = 1.563 (* 1 = 1.563 loss)
I1029 03:51:35.851351 12802 sgd_solver.cpp:105] Iteration 40280, lr = 0.000266362
I1029 03:52:05.308917 12802 solver.cpp:222] Iteration 40320 (1.35792 iter/s, 29.4569s/40 iters), loss = 1.50718
I1029 03:52:05.309124 12802 solver.cpp:241]     Train net output #0: loss = 1.50718 (* 1 = 1.50718 loss)
I1029 03:52:05.309144 12802 sgd_solver.cpp:105] Iteration 40320, lr = 0.000265405
I1029 03:52:34.862207 12802 solver.cpp:222] Iteration 40360 (1.35353 iter/s, 29.5524s/40 iters), loss = 1.50738
I1029 03:52:34.862268 12802 solver.cpp:241]     Train net output #0: loss = 1.50738 (* 1 = 1.50738 loss)
I1029 03:52:34.862282 12802 sgd_solver.cpp:105] Iteration 40360, lr = 0.000264451
I1029 03:53:04.464006 12802 solver.cpp:222] Iteration 40400 (1.3513 iter/s, 29.601s/40 iters), loss = 1.42188
I1029 03:53:04.464169 12802 solver.cpp:241]     Train net output #0: loss = 1.42188 (* 1 = 1.42188 loss)
I1029 03:53:04.464186 12802 sgd_solver.cpp:105] Iteration 40400, lr = 0.0002635
I1029 03:53:34.017213 12802 solver.cpp:222] Iteration 40440 (1.35353 iter/s, 29.5523s/40 iters), loss = 1.63291
I1029 03:53:34.017274 12802 solver.cpp:241]     Train net output #0: loss = 1.63291 (* 1 = 1.63291 loss)
I1029 03:53:34.017289 12802 sgd_solver.cpp:105] Iteration 40440, lr = 0.000262553
I1029 03:54:03.638551 12802 solver.cpp:222] Iteration 40480 (1.35041 iter/s, 29.6206s/40 iters), loss = 1.19215
I1029 03:54:03.638741 12802 solver.cpp:241]     Train net output #0: loss = 1.19215 (* 1 = 1.19215 loss)
I1029 03:54:03.638757 12802 sgd_solver.cpp:105] Iteration 40480, lr = 0.00026161
I1029 03:54:18.095816 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_40500.caffemodel
I1029 03:54:18.582417 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_40500.solverstate
I1029 03:54:18.721019 12802 solver.cpp:334] Iteration 40500, Testing net (#0)
I1029 03:54:49.795136 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 03:54:50.002785 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58372
I1029 03:54:50.002840 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81404
I1029 03:54:50.002851 12802 solver.cpp:401]     Test net output #2: loss = 1.83562 (* 1 = 1.83562 loss)
I1029 03:55:06.450659 12802 solver.cpp:222] Iteration 40520 (0.636837 iter/s, 62.8104s/40 iters), loss = 1.42399
I1029 03:55:06.450718 12802 solver.cpp:241]     Train net output #0: loss = 1.42399 (* 1 = 1.42399 loss)
I1029 03:55:06.450736 12802 sgd_solver.cpp:105] Iteration 40520, lr = 0.00026067
I1029 03:55:53.322360 12802 solver.cpp:222] Iteration 40560 (0.853415 iter/s, 46.8705s/40 iters), loss = 1.64856
I1029 03:55:53.322566 12802 solver.cpp:241]     Train net output #0: loss = 1.64856 (* 1 = 1.64856 loss)
I1029 03:55:53.322584 12802 sgd_solver.cpp:105] Iteration 40560, lr = 0.000259733
I1029 03:56:24.062887 12802 solver.cpp:222] Iteration 40600 (1.30125 iter/s, 30.7396s/40 iters), loss = 1.56262
I1029 03:56:24.063060 12802 solver.cpp:241]     Train net output #0: loss = 1.56262 (* 1 = 1.56262 loss)
I1029 03:56:24.063076 12802 sgd_solver.cpp:105] Iteration 40600, lr = 0.000258799
I1029 03:56:54.284798 12802 solver.cpp:222] Iteration 40640 (1.32358 iter/s, 30.221s/40 iters), loss = 1.04756
I1029 03:56:54.284941 12802 solver.cpp:241]     Train net output #0: loss = 1.04756 (* 1 = 1.04756 loss)
I1029 03:56:54.284960 12802 sgd_solver.cpp:105] Iteration 40640, lr = 0.000257869
I1029 03:57:24.364991 12802 solver.cpp:222] Iteration 40680 (1.32982 iter/s, 30.0793s/40 iters), loss = 1.45895
I1029 03:57:24.365124 12802 solver.cpp:241]     Train net output #0: loss = 1.45895 (* 1 = 1.45895 loss)
I1029 03:57:24.365141 12802 sgd_solver.cpp:105] Iteration 40680, lr = 0.000256943
I1029 03:57:54.491627 12802 solver.cpp:222] Iteration 40720 (1.32777 iter/s, 30.1258s/40 iters), loss = 1.18967
I1029 03:57:54.491801 12802 solver.cpp:241]     Train net output #0: loss = 1.18967 (* 1 = 1.18967 loss)
I1029 03:57:54.491814 12802 sgd_solver.cpp:105] Iteration 40720, lr = 0.000256019
I1029 03:58:24.163295 12802 solver.cpp:222] Iteration 40760 (1.34813 iter/s, 29.6708s/40 iters), loss = 1.59273
I1029 03:58:24.163353 12802 solver.cpp:241]     Train net output #0: loss = 1.59273 (* 1 = 1.59273 loss)
I1029 03:58:24.163367 12802 sgd_solver.cpp:105] Iteration 40760, lr = 0.000255099
I1029 03:58:53.898556 12802 solver.cpp:222] Iteration 40800 (1.34524 iter/s, 29.7345s/40 iters), loss = 1.39611
I1029 03:58:53.898825 12802 solver.cpp:241]     Train net output #0: loss = 1.39611 (* 1 = 1.39611 loss)
I1029 03:58:53.898855 12802 sgd_solver.cpp:105] Iteration 40800, lr = 0.000254182
I1029 03:59:23.973532 12802 solver.cpp:222] Iteration 40840 (1.33005 iter/s, 30.074s/40 iters), loss = 1.65248
I1029 03:59:23.973748 12802 solver.cpp:241]     Train net output #0: loss = 1.65248 (* 1 = 1.65248 loss)
I1029 03:59:23.973765 12802 sgd_solver.cpp:105] Iteration 40840, lr = 0.000253269
I1029 03:59:53.974946 12802 solver.cpp:222] Iteration 40880 (1.33331 iter/s, 30.0005s/40 iters), loss = 1.33226
I1029 03:59:53.975138 12802 solver.cpp:241]     Train net output #0: loss = 1.33226 (* 1 = 1.33226 loss)
I1029 03:59:53.975154 12802 sgd_solver.cpp:105] Iteration 40880, lr = 0.000252359
I1029 04:00:23.937382 12802 solver.cpp:222] Iteration 40920 (1.33505 iter/s, 29.9615s/40 iters), loss = 1.4237
I1029 04:00:23.937443 12802 solver.cpp:241]     Train net output #0: loss = 1.4237 (* 1 = 1.4237 loss)
I1029 04:00:23.937459 12802 sgd_solver.cpp:105] Iteration 40920, lr = 0.000251452
I1029 04:00:53.729799 12802 solver.cpp:222] Iteration 40960 (1.34266 iter/s, 29.7916s/40 iters), loss = 1.34438
I1029 04:00:53.729988 12802 solver.cpp:241]     Train net output #0: loss = 1.34438 (* 1 = 1.34438 loss)
I1029 04:00:53.730005 12802 sgd_solver.cpp:105] Iteration 40960, lr = 0.000250548
I1029 04:01:22.700970 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_41000.caffemodel
I1029 04:01:22.873723 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_41000.solverstate
I1029 04:01:22.988291 12802 solver.cpp:334] Iteration 41000, Testing net (#0)
I1029 04:01:54.200142 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58844
I1029 04:01:54.200327 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.807839
I1029 04:01:54.200341 12802 solver.cpp:401]     Test net output #2: loss = 1.83804 (* 1 = 1.83804 loss)
I1029 04:01:54.964053 12802 solver.cpp:222] Iteration 41000 (0.653247 iter/s, 61.2326s/40 iters), loss = 1.37353
I1029 04:01:54.964110 12802 solver.cpp:241]     Train net output #0: loss = 1.37353 (* 1 = 1.37353 loss)
I1029 04:01:54.964126 12802 sgd_solver.cpp:105] Iteration 41000, lr = 0.000249648
I1029 04:02:25.048877 12802 solver.cpp:222] Iteration 41040 (1.32961 iter/s, 30.084s/40 iters), loss = 1.64436
I1029 04:02:25.049068 12802 solver.cpp:241]     Train net output #0: loss = 1.64436 (* 1 = 1.64436 loss)
I1029 04:02:25.049087 12802 sgd_solver.cpp:105] Iteration 41040, lr = 0.000248751
I1029 04:02:54.918231 12802 solver.cpp:222] Iteration 41080 (1.33921 iter/s, 29.8684s/40 iters), loss = 1.53076
I1029 04:02:54.918293 12802 solver.cpp:241]     Train net output #0: loss = 1.53076 (* 1 = 1.53076 loss)
I1029 04:02:54.918308 12802 sgd_solver.cpp:105] Iteration 41080, lr = 0.000247857
I1029 04:03:24.189477 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 04:03:24.849195 12802 solver.cpp:222] Iteration 41120 (1.33644 iter/s, 29.9302s/40 iters), loss = 1.36915
I1029 04:03:24.849246 12802 solver.cpp:241]     Train net output #0: loss = 1.36915 (* 1 = 1.36915 loss)
I1029 04:03:24.849261 12802 sgd_solver.cpp:105] Iteration 41120, lr = 0.000246966
I1029 04:03:55.186130 12802 solver.cpp:222] Iteration 41160 (1.31856 iter/s, 30.3362s/40 iters), loss = 1.49844
I1029 04:03:55.186275 12802 solver.cpp:241]     Train net output #0: loss = 1.49844 (* 1 = 1.49844 loss)
I1029 04:03:55.186293 12802 sgd_solver.cpp:105] Iteration 41160, lr = 0.000246078
I1029 04:04:25.458683 12802 solver.cpp:222] Iteration 41200 (1.32137 iter/s, 30.2717s/40 iters), loss = 1.24208
I1029 04:04:25.458927 12802 solver.cpp:241]     Train net output #0: loss = 1.24208 (* 1 = 1.24208 loss)
I1029 04:04:25.458945 12802 sgd_solver.cpp:105] Iteration 41200, lr = 0.000245194
I1029 04:04:55.146101 12802 solver.cpp:222] Iteration 41240 (1.34742 iter/s, 29.6865s/40 iters), loss = 1.22189
I1029 04:04:55.146158 12802 solver.cpp:241]     Train net output #0: loss = 1.22189 (* 1 = 1.22189 loss)
I1029 04:04:55.146172 12802 sgd_solver.cpp:105] Iteration 41240, lr = 0.000244313
I1029 04:05:28.358803 12802 solver.cpp:222] Iteration 41280 (1.20439 iter/s, 33.2119s/40 iters), loss = 1.23654
I1029 04:05:28.359118 12802 solver.cpp:241]     Train net output #0: loss = 1.23654 (* 1 = 1.23654 loss)
I1029 04:05:28.359136 12802 sgd_solver.cpp:105] Iteration 41280, lr = 0.000243435
I1029 04:05:59.308063 12802 solver.cpp:222] Iteration 41320 (1.29248 iter/s, 30.9482s/40 iters), loss = 1.62394
I1029 04:05:59.308250 12802 solver.cpp:241]     Train net output #0: loss = 1.62394 (* 1 = 1.62394 loss)
I1029 04:05:59.308269 12802 sgd_solver.cpp:105] Iteration 41320, lr = 0.00024256
I1029 04:06:30.057337 12802 solver.cpp:222] Iteration 41360 (1.30088 iter/s, 30.7484s/40 iters), loss = 1.35227
I1029 04:06:30.057515 12802 solver.cpp:241]     Train net output #0: loss = 1.35227 (* 1 = 1.35227 loss)
I1029 04:06:30.057533 12802 sgd_solver.cpp:105] Iteration 41360, lr = 0.000241688
I1029 04:07:00.909574 12802 solver.cpp:222] Iteration 41400 (1.29654 iter/s, 30.8513s/40 iters), loss = 1.44138
I1029 04:07:00.909773 12802 solver.cpp:241]     Train net output #0: loss = 1.44138 (* 1 = 1.44138 loss)
I1029 04:07:00.909795 12802 sgd_solver.cpp:105] Iteration 41400, lr = 0.00024082
I1029 04:07:30.884239 12802 solver.cpp:222] Iteration 41440 (1.3345 iter/s, 29.9738s/40 iters), loss = 1.26104
I1029 04:07:30.884304 12802 solver.cpp:241]     Train net output #0: loss = 1.26104 (* 1 = 1.26104 loss)
I1029 04:07:30.884316 12802 sgd_solver.cpp:105] Iteration 41440, lr = 0.000239954
I1029 04:08:00.904426 12802 solver.cpp:222] Iteration 41480 (1.33247 iter/s, 30.0194s/40 iters), loss = 1.16693
I1029 04:08:00.904635 12802 solver.cpp:241]     Train net output #0: loss = 1.16693 (* 1 = 1.16693 loss)
I1029 04:08:00.904657 12802 sgd_solver.cpp:105] Iteration 41480, lr = 0.000239092
I1029 04:08:15.224474 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_41500.caffemodel
I1029 04:08:15.364580 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_41500.solverstate
I1029 04:08:15.478454 12802 solver.cpp:334] Iteration 41500, Testing net (#0)
I1029 04:08:46.557729 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 04:08:46.766258 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58348
I1029 04:08:46.766309 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81272
I1029 04:08:46.766319 12802 solver.cpp:401]     Test net output #2: loss = 1.85229 (* 1 = 1.85229 loss)
I1029 04:09:02.587352 12802 solver.cpp:222] Iteration 41520 (0.648495 iter/s, 61.6813s/40 iters), loss = 1.12883
I1029 04:09:02.587436 12802 solver.cpp:241]     Train net output #0: loss = 1.12883 (* 1 = 1.12883 loss)
I1029 04:09:02.587458 12802 sgd_solver.cpp:105] Iteration 41520, lr = 0.000238232
I1029 04:10:31.469632 12802 solver.cpp:222] Iteration 41560 (0.450044 iter/s, 88.8801s/40 iters), loss = 1.36461
I1029 04:10:31.469832 12802 solver.cpp:241]     Train net output #0: loss = 1.36461 (* 1 = 1.36461 loss)
I1029 04:10:31.469854 12802 sgd_solver.cpp:105] Iteration 41560, lr = 0.000237376
I1029 04:11:01.322877 12802 solver.cpp:222] Iteration 41600 (1.33993 iter/s, 29.8524s/40 iters), loss = 1.60993
I1029 04:11:01.322940 12802 solver.cpp:241]     Train net output #0: loss = 1.60993 (* 1 = 1.60993 loss)
I1029 04:11:01.322957 12802 sgd_solver.cpp:105] Iteration 41600, lr = 0.000236523
I1029 04:11:30.978942 12802 solver.cpp:222] Iteration 41640 (1.34883 iter/s, 29.6553s/40 iters), loss = 1.52996
I1029 04:11:30.979187 12802 solver.cpp:241]     Train net output #0: loss = 1.52996 (* 1 = 1.52996 loss)
I1029 04:11:30.979202 12802 sgd_solver.cpp:105] Iteration 41640, lr = 0.000235673
I1029 04:12:01.533273 12802 solver.cpp:222] Iteration 41680 (1.30918 iter/s, 30.5534s/40 iters), loss = 1.27549
I1029 04:12:01.533459 12802 solver.cpp:241]     Train net output #0: loss = 1.27549 (* 1 = 1.27549 loss)
I1029 04:12:01.533478 12802 sgd_solver.cpp:105] Iteration 41680, lr = 0.000234826
I1029 04:12:32.129870 12802 solver.cpp:222] Iteration 41720 (1.30737 iter/s, 30.5957s/40 iters), loss = 1.63157
I1029 04:12:32.130061 12802 solver.cpp:241]     Train net output #0: loss = 1.63157 (* 1 = 1.63157 loss)
I1029 04:12:32.130079 12802 sgd_solver.cpp:105] Iteration 41720, lr = 0.000233982
I1029 04:13:01.596674 12802 solver.cpp:222] Iteration 41760 (1.3575 iter/s, 29.4659s/40 iters), loss = 1.46976
I1029 04:13:01.596732 12802 solver.cpp:241]     Train net output #0: loss = 1.46976 (* 1 = 1.46976 loss)
I1029 04:13:01.596748 12802 sgd_solver.cpp:105] Iteration 41760, lr = 0.000233141
I1029 04:13:31.688819 12802 solver.cpp:222] Iteration 41800 (1.32928 iter/s, 30.0914s/40 iters), loss = 1.23165
I1029 04:13:31.689002 12802 solver.cpp:241]     Train net output #0: loss = 1.23165 (* 1 = 1.23165 loss)
I1029 04:13:31.689018 12802 sgd_solver.cpp:105] Iteration 41800, lr = 0.000232304
I1029 04:14:06.257859 12802 solver.cpp:222] Iteration 41840 (1.15714 iter/s, 34.568s/40 iters), loss = 1.54236
I1029 04:14:06.258054 12802 solver.cpp:241]     Train net output #0: loss = 1.54236 (* 1 = 1.54236 loss)
I1029 04:14:06.258072 12802 sgd_solver.cpp:105] Iteration 41840, lr = 0.000231469
I1029 04:14:51.224073 12802 solver.cpp:222] Iteration 41880 (0.889581 iter/s, 44.965s/40 iters), loss = 1.4457
I1029 04:14:51.224275 12802 solver.cpp:241]     Train net output #0: loss = 1.4457 (* 1 = 1.4457 loss)
I1029 04:14:51.224300 12802 sgd_solver.cpp:105] Iteration 41880, lr = 0.000230637
I1029 04:15:20.882479 12802 solver.cpp:222] Iteration 41920 (1.34873 iter/s, 29.6575s/40 iters), loss = 1.6778
I1029 04:15:20.882544 12802 solver.cpp:241]     Train net output #0: loss = 1.6778 (* 1 = 1.6778 loss)
I1029 04:15:20.882557 12802 sgd_solver.cpp:105] Iteration 41920, lr = 0.000229808
I1029 04:15:51.227509 12802 solver.cpp:222] Iteration 41960 (1.31821 iter/s, 30.3442s/40 iters), loss = 1.24406
I1029 04:15:51.227716 12802 solver.cpp:241]     Train net output #0: loss = 1.24406 (* 1 = 1.24406 loss)
I1029 04:15:51.227735 12802 sgd_solver.cpp:105] Iteration 41960, lr = 0.000228982
I1029 04:16:20.518498 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_42000.caffemodel
I1029 04:16:20.852615 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_42000.solverstate
I1029 04:16:20.961482 12802 solver.cpp:334] Iteration 42000, Testing net (#0)
I1029 04:16:52.123790 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5856
I1029 04:16:52.124186 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80852
I1029 04:16:52.124200 12802 solver.cpp:401]     Test net output #2: loss = 1.83667 (* 1 = 1.83667 loss)
I1029 04:16:52.874086 12802 solver.cpp:222] Iteration 42000 (0.648877 iter/s, 61.6449s/40 iters), loss = 1.33085
I1029 04:16:52.874124 12802 solver.cpp:241]     Train net output #0: loss = 1.33085 (* 1 = 1.33085 loss)
I1029 04:16:52.874138 12802 sgd_solver.cpp:105] Iteration 42000, lr = 0.000228159
I1029 04:17:23.084671 12802 solver.cpp:222] Iteration 42040 (1.32407 iter/s, 30.2098s/40 iters), loss = 1.35321
I1029 04:17:23.084874 12802 solver.cpp:241]     Train net output #0: loss = 1.35321 (* 1 = 1.35321 loss)
I1029 04:17:23.084897 12802 sgd_solver.cpp:105] Iteration 42040, lr = 0.000227339
I1029 04:17:59.420806 12802 solver.cpp:222] Iteration 42080 (1.10087 iter/s, 36.3351s/40 iters), loss = 1.66085
I1029 04:17:59.421058 12802 solver.cpp:241]     Train net output #0: loss = 1.66085 (* 1 = 1.66085 loss)
I1029 04:17:59.421075 12802 sgd_solver.cpp:105] Iteration 42080, lr = 0.000226522
I1029 04:18:29.998625 12802 solver.cpp:222] Iteration 42120 (1.30818 iter/s, 30.5768s/40 iters), loss = 1.25013
I1029 04:18:29.998852 12802 solver.cpp:241]     Train net output #0: loss = 1.25013 (* 1 = 1.25013 loss)
I1029 04:18:29.998869 12802 sgd_solver.cpp:105] Iteration 42120, lr = 0.000225708
I1029 04:19:00.508407 12802 solver.cpp:222] Iteration 42160 (1.3111 iter/s, 30.5088s/40 iters), loss = 1.48502
I1029 04:19:00.508608 12802 solver.cpp:241]     Train net output #0: loss = 1.48502 (* 1 = 1.48502 loss)
I1029 04:19:00.508625 12802 sgd_solver.cpp:105] Iteration 42160, lr = 0.000224897
I1029 04:19:31.010315 12802 solver.cpp:222] Iteration 42200 (1.31143 iter/s, 30.501s/40 iters), loss = 1.51932
I1029 04:19:31.010543 12802 solver.cpp:241]     Train net output #0: loss = 1.51932 (* 1 = 1.51932 loss)
I1029 04:19:31.010560 12802 sgd_solver.cpp:105] Iteration 42200, lr = 0.000224089
I1029 04:20:01.073253 12802 solver.cpp:222] Iteration 42240 (1.33058 iter/s, 30.062s/40 iters), loss = 1.38325
I1029 04:20:01.073448 12802 solver.cpp:241]     Train net output #0: loss = 1.38325 (* 1 = 1.38325 loss)
I1029 04:20:01.073462 12802 sgd_solver.cpp:105] Iteration 42240, lr = 0.000223283
I1029 04:20:30.793025 12802 solver.cpp:222] Iteration 42280 (1.34595 iter/s, 29.7189s/40 iters), loss = 1.52607
I1029 04:20:30.793083 12802 solver.cpp:241]     Train net output #0: loss = 1.52607 (* 1 = 1.52607 loss)
I1029 04:20:30.793097 12802 sgd_solver.cpp:105] Iteration 42280, lr = 0.000222481
I1029 04:21:00.461877 12802 solver.cpp:222] Iteration 42320 (1.34825 iter/s, 29.6681s/40 iters), loss = 1.76427
I1029 04:21:00.462067 12802 solver.cpp:241]     Train net output #0: loss = 1.76427 (* 1 = 1.76427 loss)
I1029 04:21:00.462081 12802 sgd_solver.cpp:105] Iteration 42320, lr = 0.000221681
I1029 04:21:30.128864 12802 solver.cpp:222] Iteration 42360 (1.34834 iter/s, 29.6661s/40 iters), loss = 1.38033
I1029 04:21:30.128931 12802 solver.cpp:241]     Train net output #0: loss = 1.38033 (* 1 = 1.38033 loss)
I1029 04:21:30.128945 12802 sgd_solver.cpp:105] Iteration 42360, lr = 0.000220885
I1029 04:21:59.957779 12802 solver.cpp:222] Iteration 42400 (1.34102 iter/s, 29.8281s/40 iters), loss = 1.54492
I1029 04:21:59.958003 12802 solver.cpp:241]     Train net output #0: loss = 1.54492 (* 1 = 1.54492 loss)
I1029 04:21:59.958024 12802 sgd_solver.cpp:105] Iteration 42400, lr = 0.000220091
I1029 04:22:29.627738 12802 solver.cpp:222] Iteration 42440 (1.34821 iter/s, 29.669s/40 iters), loss = 1.4073
I1029 04:22:29.627797 12802 solver.cpp:241]     Train net output #0: loss = 1.4073 (* 1 = 1.4073 loss)
I1029 04:22:29.627813 12802 sgd_solver.cpp:105] Iteration 42440, lr = 0.0002193
I1029 04:22:59.375433 12802 solver.cpp:222] Iteration 42480 (1.34468 iter/s, 29.7469s/40 iters), loss = 1.47233
I1029 04:22:59.375643 12802 solver.cpp:241]     Train net output #0: loss = 1.47233 (* 1 = 1.47233 loss)
I1029 04:22:59.375659 12802 sgd_solver.cpp:105] Iteration 42480, lr = 0.000218512
I1029 04:23:13.693168 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_42500.caffemodel
I1029 04:23:13.836067 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_42500.solverstate
I1029 04:23:13.978060 12802 solver.cpp:334] Iteration 42500, Testing net (#0)
I1029 04:23:44.925312 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 04:23:45.132818 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58396
I1029 04:23:45.132867 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81464
I1029 04:23:45.132879 12802 solver.cpp:401]     Test net output #2: loss = 1.84123 (* 1 = 1.84123 loss)
I1029 04:24:00.699400 12802 solver.cpp:222] Iteration 42520 (0.652291 iter/s, 61.3223s/40 iters), loss = 1.72138
I1029 04:24:00.699460 12802 solver.cpp:241]     Train net output #0: loss = 1.72138 (* 1 = 1.72138 loss)
I1029 04:24:00.699476 12802 sgd_solver.cpp:105] Iteration 42520, lr = 0.000217727
I1029 04:24:30.571575 12802 solver.cpp:222] Iteration 42560 (1.33907 iter/s, 29.8714s/40 iters), loss = 1.01504
I1029 04:24:30.571820 12802 solver.cpp:241]     Train net output #0: loss = 1.01504 (* 1 = 1.01504 loss)
I1029 04:24:30.571835 12802 sgd_solver.cpp:105] Iteration 42560, lr = 0.000216944
I1029 04:25:00.083595 12802 solver.cpp:222] Iteration 42600 (1.35542 iter/s, 29.5111s/40 iters), loss = 1.46881
I1029 04:25:00.083652 12802 solver.cpp:241]     Train net output #0: loss = 1.46881 (* 1 = 1.46881 loss)
I1029 04:25:00.083667 12802 sgd_solver.cpp:105] Iteration 42600, lr = 0.000216164
I1029 04:25:29.780833 12802 solver.cpp:222] Iteration 42640 (1.34696 iter/s, 29.6965s/40 iters), loss = 1.26923
I1029 04:25:29.780992 12802 solver.cpp:241]     Train net output #0: loss = 1.26923 (* 1 = 1.26923 loss)
I1029 04:25:29.781008 12802 sgd_solver.cpp:105] Iteration 42640, lr = 0.000215388
I1029 04:25:59.482630 12802 solver.cpp:222] Iteration 42680 (1.34676 iter/s, 29.7009s/40 iters), loss = 1.27167
I1029 04:25:59.482691 12802 solver.cpp:241]     Train net output #0: loss = 1.27167 (* 1 = 1.27167 loss)
I1029 04:25:59.482705 12802 sgd_solver.cpp:105] Iteration 42680, lr = 0.000214614
I1029 04:26:29.455312 12802 solver.cpp:222] Iteration 42720 (1.33458 iter/s, 29.9719s/40 iters), loss = 1.08829
I1029 04:26:29.455518 12802 solver.cpp:241]     Train net output #0: loss = 1.08829 (* 1 = 1.08829 loss)
I1029 04:26:29.455531 12802 sgd_solver.cpp:105] Iteration 42720, lr = 0.000213842
I1029 04:27:00.278915 12802 solver.cpp:222] Iteration 42760 (1.29775 iter/s, 30.8227s/40 iters), loss = 1.22618
I1029 04:27:00.279084 12802 solver.cpp:241]     Train net output #0: loss = 1.22618 (* 1 = 1.22618 loss)
I1029 04:27:00.279103 12802 sgd_solver.cpp:105] Iteration 42760, lr = 0.000213074
I1029 04:27:31.768592 12802 solver.cpp:222] Iteration 42800 (1.27029 iter/s, 31.4888s/40 iters), loss = 1.53066
I1029 04:27:31.768790 12802 solver.cpp:241]     Train net output #0: loss = 1.53066 (* 1 = 1.53066 loss)
I1029 04:27:31.768805 12802 sgd_solver.cpp:105] Iteration 42800, lr = 0.000212308
I1029 04:28:03.820538 12802 solver.cpp:222] Iteration 42840 (1.24801 iter/s, 32.051s/40 iters), loss = 1.59403
I1029 04:28:03.820750 12802 solver.cpp:241]     Train net output #0: loss = 1.59403 (* 1 = 1.59403 loss)
I1029 04:28:03.820767 12802 sgd_solver.cpp:105] Iteration 42840, lr = 0.000211545
I1029 04:28:34.221992 12802 solver.cpp:222] Iteration 42880 (1.31577 iter/s, 30.4005s/40 iters), loss = 1.23855
I1029 04:28:34.222160 12802 solver.cpp:241]     Train net output #0: loss = 1.23855 (* 1 = 1.23855 loss)
I1029 04:28:34.222177 12802 sgd_solver.cpp:105] Iteration 42880, lr = 0.000210785
I1029 04:29:03.959627 12802 solver.cpp:222] Iteration 42920 (1.34514 iter/s, 29.7368s/40 iters), loss = 1.27049
I1029 04:29:03.959694 12802 solver.cpp:241]     Train net output #0: loss = 1.27049 (* 1 = 1.27049 loss)
I1029 04:29:03.959710 12802 sgd_solver.cpp:105] Iteration 42920, lr = 0.000210027
I1029 04:29:33.613396 12802 solver.cpp:222] Iteration 42960 (1.34894 iter/s, 29.653s/40 iters), loss = 1.46941
I1029 04:29:33.613571 12802 solver.cpp:241]     Train net output #0: loss = 1.46941 (* 1 = 1.46941 loss)
I1029 04:29:33.613589 12802 sgd_solver.cpp:105] Iteration 42960, lr = 0.000209272
I1029 04:30:02.743948 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_43000.caffemodel
I1029 04:30:02.881366 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_43000.solverstate
I1029 04:30:02.998113 12802 solver.cpp:334] Iteration 43000, Testing net (#0)
I1029 04:30:34.258832 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5882
I1029 04:30:34.259026 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80908
I1029 04:30:34.259039 12802 solver.cpp:401]     Test net output #2: loss = 1.82646 (* 1 = 1.82646 loss)
I1029 04:30:35.033567 12802 solver.cpp:222] Iteration 43000 (0.651269 iter/s, 61.4186s/40 iters), loss = 1.31395
I1029 04:30:35.033607 12802 solver.cpp:241]     Train net output #0: loss = 1.31395 (* 1 = 1.31395 loss)
I1029 04:30:35.033629 12802 sgd_solver.cpp:105] Iteration 43000, lr = 0.00020852
I1029 04:31:04.863210 12802 solver.cpp:222] Iteration 43040 (1.34098 iter/s, 29.8289s/40 iters), loss = 1.50649
I1029 04:31:04.863440 12802 solver.cpp:241]     Train net output #0: loss = 1.50649 (* 1 = 1.50649 loss)
I1029 04:31:04.863456 12802 sgd_solver.cpp:105] Iteration 43040, lr = 0.000207771
I1029 04:31:34.496145 12802 solver.cpp:222] Iteration 43080 (1.34989 iter/s, 29.632s/40 iters), loss = 1.15835
I1029 04:31:34.496201 12802 solver.cpp:241]     Train net output #0: loss = 1.15835 (* 1 = 1.15835 loss)
I1029 04:31:34.496217 12802 sgd_solver.cpp:105] Iteration 43080, lr = 0.000207024
I1029 04:32:04.595160 12802 solver.cpp:222] Iteration 43120 (1.32898 iter/s, 30.0982s/40 iters), loss = 1.20802
I1029 04:32:04.595329 12802 solver.cpp:241]     Train net output #0: loss = 1.20802 (* 1 = 1.20802 loss)
I1029 04:32:04.595346 12802 sgd_solver.cpp:105] Iteration 43120, lr = 0.00020628
I1029 04:32:34.935010 12802 solver.cpp:222] Iteration 43160 (1.31844 iter/s, 30.339s/40 iters), loss = 1.10642
I1029 04:32:34.935148 12802 solver.cpp:241]     Train net output #0: loss = 1.10642 (* 1 = 1.10642 loss)
I1029 04:32:34.935163 12802 sgd_solver.cpp:105] Iteration 43160, lr = 0.000205539
I1029 04:33:04.720589 12802 solver.cpp:222] Iteration 43200 (1.34297 iter/s, 29.7847s/40 iters), loss = 1.42588
I1029 04:33:04.720649 12802 solver.cpp:241]     Train net output #0: loss = 1.42588 (* 1 = 1.42588 loss)
I1029 04:33:04.720661 12802 sgd_solver.cpp:105] Iteration 43200, lr = 0.0002048
I1029 04:33:34.416426 12802 solver.cpp:222] Iteration 43240 (1.34703 iter/s, 29.6951s/40 iters), loss = 1.54442
I1029 04:33:34.416592 12802 solver.cpp:241]     Train net output #0: loss = 1.54442 (* 1 = 1.54442 loss)
I1029 04:33:34.416610 12802 sgd_solver.cpp:105] Iteration 43240, lr = 0.000204064
I1029 04:34:04.751209 12802 solver.cpp:222] Iteration 43280 (1.31866 iter/s, 30.3339s/40 iters), loss = 1.20223
I1029 04:34:04.751346 12802 solver.cpp:241]     Train net output #0: loss = 1.20223 (* 1 = 1.20223 loss)
I1029 04:34:04.751363 12802 sgd_solver.cpp:105] Iteration 43280, lr = 0.000203331
I1029 04:34:35.075367 12802 solver.cpp:222] Iteration 43320 (1.31912 iter/s, 30.3233s/40 iters), loss = 1.31847
I1029 04:34:35.075532 12802 solver.cpp:241]     Train net output #0: loss = 1.31847 (* 1 = 1.31847 loss)
I1029 04:34:35.075551 12802 sgd_solver.cpp:105] Iteration 43320, lr = 0.0002026
I1029 04:35:05.443166 12802 solver.cpp:222] Iteration 43360 (1.31722 iter/s, 30.3669s/40 iters), loss = 1.2232
I1029 04:35:05.443325 12802 solver.cpp:241]     Train net output #0: loss = 1.2232 (* 1 = 1.2232 loss)
I1029 04:35:05.443342 12802 sgd_solver.cpp:105] Iteration 43360, lr = 0.000201872
I1029 04:35:35.636231 12802 solver.cpp:222] Iteration 43400 (1.32485 iter/s, 30.1922s/40 iters), loss = 1.7164
I1029 04:35:35.636332 12802 solver.cpp:241]     Train net output #0: loss = 1.7164 (* 1 = 1.7164 loss)
I1029 04:35:35.636348 12802 sgd_solver.cpp:105] Iteration 43400, lr = 0.000201147
I1029 04:36:05.963403 12802 solver.cpp:222] Iteration 43440 (1.31899 iter/s, 30.3263s/40 iters), loss = 1.41087
I1029 04:36:05.963589 12802 solver.cpp:241]     Train net output #0: loss = 1.41087 (* 1 = 1.41087 loss)
I1029 04:36:05.963606 12802 sgd_solver.cpp:105] Iteration 43440, lr = 0.000200424
I1029 04:36:37.006798 12802 solver.cpp:222] Iteration 43480 (1.28856 iter/s, 31.0425s/40 iters), loss = 1.60004
I1029 04:36:37.007010 12802 solver.cpp:241]     Train net output #0: loss = 1.60004 (* 1 = 1.60004 loss)
I1029 04:36:37.007027 12802 sgd_solver.cpp:105] Iteration 43480, lr = 0.000199703
I1029 04:36:51.414479 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_43500.caffemodel
I1029 04:36:51.552748 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_43500.solverstate
I1029 04:36:51.666771 12802 solver.cpp:334] Iteration 43500, Testing net (#0)
I1029 04:37:22.680652 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 04:37:22.891299 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58568
I1029 04:37:22.891350 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81392
I1029 04:37:22.891360 12802 solver.cpp:401]     Test net output #2: loss = 1.84002 (* 1 = 1.84002 loss)
I1029 04:37:38.929579 12802 solver.cpp:222] Iteration 43520 (0.645983 iter/s, 61.9211s/40 iters), loss = 1.27899
I1029 04:37:38.929639 12802 solver.cpp:241]     Train net output #0: loss = 1.27899 (* 1 = 1.27899 loss)
I1029 04:37:38.929654 12802 sgd_solver.cpp:105] Iteration 43520, lr = 0.000198986
I1029 04:38:08.986680 12802 solver.cpp:222] Iteration 43560 (1.33084 iter/s, 30.0563s/40 iters), loss = 1.23667
I1029 04:38:08.986894 12802 solver.cpp:241]     Train net output #0: loss = 1.23667 (* 1 = 1.23667 loss)
I1029 04:38:08.986908 12802 sgd_solver.cpp:105] Iteration 43560, lr = 0.000198271
I1029 04:39:40.569185 12802 solver.cpp:222] Iteration 43600 (0.436776 iter/s, 91.5801s/40 iters), loss = 1.27751
I1029 04:39:40.569370 12802 solver.cpp:241]     Train net output #0: loss = 1.27751 (* 1 = 1.27751 loss)
I1029 04:39:40.569387 12802 sgd_solver.cpp:105] Iteration 43600, lr = 0.000197558
I1029 04:39:57.020342 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 04:40:11.326380 12802 solver.cpp:222] Iteration 43640 (1.30055 iter/s, 30.7563s/40 iters), loss = 1.1043
I1029 04:40:11.326565 12802 solver.cpp:241]     Train net output #0: loss = 1.1043 (* 1 = 1.1043 loss)
I1029 04:40:11.326581 12802 sgd_solver.cpp:105] Iteration 43640, lr = 0.000196848
I1029 04:40:41.788946 12802 solver.cpp:222] Iteration 43680 (1.31313 iter/s, 30.4617s/40 iters), loss = 1.33627
I1029 04:40:41.789136 12802 solver.cpp:241]     Train net output #0: loss = 1.33627 (* 1 = 1.33627 loss)
I1029 04:40:41.789160 12802 sgd_solver.cpp:105] Iteration 43680, lr = 0.000196141
I1029 04:41:11.751834 12802 solver.cpp:222] Iteration 43720 (1.33502 iter/s, 29.962s/40 iters), loss = 1.42984
I1029 04:41:11.751896 12802 solver.cpp:241]     Train net output #0: loss = 1.42984 (* 1 = 1.42984 loss)
I1029 04:41:11.751912 12802 sgd_solver.cpp:105] Iteration 43720, lr = 0.000195436
I1029 04:41:42.281466 12802 solver.cpp:222] Iteration 43760 (1.31024 iter/s, 30.5288s/40 iters), loss = 1.28405
I1029 04:41:42.281647 12802 solver.cpp:241]     Train net output #0: loss = 1.28405 (* 1 = 1.28405 loss)
I1029 04:41:42.281664 12802 sgd_solver.cpp:105] Iteration 43760, lr = 0.000194733
I1029 04:42:12.528580 12802 solver.cpp:222] Iteration 43800 (1.32248 iter/s, 30.2462s/40 iters), loss = 1.36078
I1029 04:42:12.528760 12802 solver.cpp:241]     Train net output #0: loss = 1.36078 (* 1 = 1.36078 loss)
I1029 04:42:12.528777 12802 sgd_solver.cpp:105] Iteration 43800, lr = 0.000194034
I1029 04:42:43.417913 12802 solver.cpp:222] Iteration 43840 (1.29498 iter/s, 30.8884s/40 iters), loss = 1.23421
I1029 04:42:43.418128 12802 solver.cpp:241]     Train net output #0: loss = 1.23421 (* 1 = 1.23421 loss)
I1029 04:42:43.418144 12802 sgd_solver.cpp:105] Iteration 43840, lr = 0.000193336
I1029 04:43:13.831375 12802 solver.cpp:222] Iteration 43880 (1.31525 iter/s, 30.4125s/40 iters), loss = 1.12895
I1029 04:43:13.831575 12802 solver.cpp:241]     Train net output #0: loss = 1.12895 (* 1 = 1.12895 loss)
I1029 04:43:13.831593 12802 sgd_solver.cpp:105] Iteration 43880, lr = 0.000192641
I1029 04:43:44.023685 12802 solver.cpp:222] Iteration 43920 (1.32488 iter/s, 30.1914s/40 iters), loss = 1.39509
I1029 04:43:44.023887 12802 solver.cpp:241]     Train net output #0: loss = 1.39509 (* 1 = 1.39509 loss)
I1029 04:43:44.023910 12802 sgd_solver.cpp:105] Iteration 43920, lr = 0.000191949
I1029 04:44:14.333937 12802 solver.cpp:222] Iteration 43960 (1.31973 iter/s, 30.3093s/40 iters), loss = 1.39472
I1029 04:44:14.334111 12802 solver.cpp:241]     Train net output #0: loss = 1.39472 (* 1 = 1.39472 loss)
I1029 04:44:14.334128 12802 sgd_solver.cpp:105] Iteration 43960, lr = 0.000191259
I1029 04:44:43.867013 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_44000.caffemodel
I1029 04:44:44.007700 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_44000.solverstate
I1029 04:44:44.122781 12802 solver.cpp:334] Iteration 44000, Testing net (#0)
I1029 04:45:15.345541 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58728
I1029 04:45:15.345824 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8092
I1029 04:45:15.345839 12802 solver.cpp:401]     Test net output #2: loss = 1.84282 (* 1 = 1.84282 loss)
I1029 04:45:16.106248 12802 solver.cpp:222] Iteration 44000 (0.647556 iter/s, 61.7707s/40 iters), loss = 1.37695
I1029 04:45:16.106302 12802 solver.cpp:241]     Train net output #0: loss = 1.37695 (* 1 = 1.37695 loss)
I1029 04:45:16.106324 12802 sgd_solver.cpp:105] Iteration 44000, lr = 0.000190572
I1029 04:45:46.867578 12802 solver.cpp:222] Iteration 44040 (1.30037 iter/s, 30.7605s/40 iters), loss = 1.32681
I1029 04:45:46.867758 12802 solver.cpp:241]     Train net output #0: loss = 1.32681 (* 1 = 1.32681 loss)
I1029 04:45:46.867777 12802 sgd_solver.cpp:105] Iteration 44040, lr = 0.000189887
I1029 04:46:17.327112 12802 solver.cpp:222] Iteration 44080 (1.31326 iter/s, 30.4586s/40 iters), loss = 1.27504
I1029 04:46:17.327302 12802 solver.cpp:241]     Train net output #0: loss = 1.27504 (* 1 = 1.27504 loss)
I1029 04:46:17.327319 12802 sgd_solver.cpp:105] Iteration 44080, lr = 0.000189205
I1029 04:46:46.878728 12802 solver.cpp:222] Iteration 44120 (1.35361 iter/s, 29.5507s/40 iters), loss = 1.41177
I1029 04:46:46.878787 12802 solver.cpp:241]     Train net output #0: loss = 1.41177 (* 1 = 1.41177 loss)
I1029 04:46:46.878800 12802 sgd_solver.cpp:105] Iteration 44120, lr = 0.000188525
I1029 04:47:16.365329 12802 solver.cpp:222] Iteration 44160 (1.35658 iter/s, 29.4858s/40 iters), loss = 1.50448
I1029 04:47:16.365474 12802 solver.cpp:241]     Train net output #0: loss = 1.50448 (* 1 = 1.50448 loss)
I1029 04:47:16.365491 12802 sgd_solver.cpp:105] Iteration 44160, lr = 0.000187847
I1029 04:47:45.874898 12802 solver.cpp:222] Iteration 44200 (1.35553 iter/s, 29.5087s/40 iters), loss = 1.02748
I1029 04:47:45.874961 12802 solver.cpp:241]     Train net output #0: loss = 1.02748 (* 1 = 1.02748 loss)
I1029 04:47:45.874976 12802 sgd_solver.cpp:105] Iteration 44200, lr = 0.000187172
I1029 04:48:15.394002 12802 solver.cpp:222] Iteration 44240 (1.35509 iter/s, 29.5183s/40 iters), loss = 1.56065
I1029 04:48:15.394188 12802 solver.cpp:241]     Train net output #0: loss = 1.56065 (* 1 = 1.56065 loss)
I1029 04:48:15.394202 12802 sgd_solver.cpp:105] Iteration 44240, lr = 0.000186499
I1029 04:48:45.036875 12802 solver.cpp:222] Iteration 44280 (1.34944 iter/s, 29.642s/40 iters), loss = 1.90438
I1029 04:48:45.036936 12802 solver.cpp:241]     Train net output #0: loss = 1.90438 (* 1 = 1.90438 loss)
I1029 04:48:45.036953 12802 sgd_solver.cpp:105] Iteration 44280, lr = 0.000185829
I1029 04:49:14.638813 12802 solver.cpp:222] Iteration 44320 (1.3513 iter/s, 29.6012s/40 iters), loss = 1.41732
I1029 04:49:14.639258 12802 solver.cpp:241]     Train net output #0: loss = 1.41732 (* 1 = 1.41732 loss)
I1029 04:49:14.639272 12802 sgd_solver.cpp:105] Iteration 44320, lr = 0.000185161
I1029 04:49:44.238852 12802 solver.cpp:222] Iteration 44360 (1.3514 iter/s, 29.5989s/40 iters), loss = 1.23644
I1029 04:49:44.238909 12802 solver.cpp:241]     Train net output #0: loss = 1.23644 (* 1 = 1.23644 loss)
I1029 04:49:44.238929 12802 sgd_solver.cpp:105] Iteration 44360, lr = 0.000184496
I1029 04:50:13.843529 12802 solver.cpp:222] Iteration 44400 (1.35117 iter/s, 29.6039s/40 iters), loss = 1.37935
I1029 04:50:13.843698 12802 solver.cpp:241]     Train net output #0: loss = 1.37935 (* 1 = 1.37935 loss)
I1029 04:50:13.843714 12802 sgd_solver.cpp:105] Iteration 44400, lr = 0.000183833
I1029 04:50:43.446612 12802 solver.cpp:222] Iteration 44440 (1.35125 iter/s, 29.6022s/40 iters), loss = 1.15346
I1029 04:50:43.446676 12802 solver.cpp:241]     Train net output #0: loss = 1.15346 (* 1 = 1.15346 loss)
I1029 04:50:43.446691 12802 sgd_solver.cpp:105] Iteration 44440, lr = 0.000183172
I1029 04:51:13.041851 12802 solver.cpp:222] Iteration 44480 (1.3516 iter/s, 29.5945s/40 iters), loss = 1.59151
I1029 04:51:13.042001 12802 solver.cpp:241]     Train net output #0: loss = 1.59151 (* 1 = 1.59151 loss)
I1029 04:51:13.042014 12802 sgd_solver.cpp:105] Iteration 44480, lr = 0.000182514
I1029 04:51:27.092391 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_44500.caffemodel
I1029 04:51:30.039160 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_44500.solverstate
I1029 04:51:30.537647 12802 solver.cpp:334] Iteration 44500, Testing net (#0)
I1029 04:52:01.487545 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 04:52:01.695449 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58452
I1029 04:52:01.695502 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81304
I1029 04:52:01.695513 12802 solver.cpp:401]     Test net output #2: loss = 1.84085 (* 1 = 1.84085 loss)
I1029 04:52:17.476672 12802 solver.cpp:222] Iteration 44520 (0.620798 iter/s, 64.4332s/40 iters), loss = 1.17472
I1029 04:52:17.476732 12802 solver.cpp:241]     Train net output #0: loss = 1.17472 (* 1 = 1.17472 loss)
I1029 04:52:17.476745 12802 sgd_solver.cpp:105] Iteration 44520, lr = 0.000181858
I1029 04:52:47.010067 12802 solver.cpp:222] Iteration 44560 (1.35443 iter/s, 29.5326s/40 iters), loss = 1.38259
I1029 04:52:47.010159 12802 solver.cpp:241]     Train net output #0: loss = 1.38259 (* 1 = 1.38259 loss)
I1029 04:52:47.010175 12802 sgd_solver.cpp:105] Iteration 44560, lr = 0.000181204
I1029 04:53:16.518575 12802 solver.cpp:222] Iteration 44600 (1.35558 iter/s, 29.5077s/40 iters), loss = 1.42086
I1029 04:53:16.518637 12802 solver.cpp:241]     Train net output #0: loss = 1.42086 (* 1 = 1.42086 loss)
I1029 04:53:16.518653 12802 sgd_solver.cpp:105] Iteration 44600, lr = 0.000180553
I1029 04:53:45.966701 12802 solver.cpp:222] Iteration 44640 (1.35836 iter/s, 29.4474s/40 iters), loss = 1.2199
I1029 04:53:45.966792 12802 solver.cpp:241]     Train net output #0: loss = 1.2199 (* 1 = 1.2199 loss)
I1029 04:53:45.966809 12802 sgd_solver.cpp:105] Iteration 44640, lr = 0.000179904
I1029 04:54:15.422420 12802 solver.cpp:222] Iteration 44680 (1.35801 iter/s, 29.4549s/40 iters), loss = 1.30327
I1029 04:54:15.422477 12802 solver.cpp:241]     Train net output #0: loss = 1.30327 (* 1 = 1.30327 loss)
I1029 04:54:15.422489 12802 sgd_solver.cpp:105] Iteration 44680, lr = 0.000179258
I1029 04:54:44.980700 12802 solver.cpp:222] Iteration 44720 (1.35329 iter/s, 29.5575s/40 iters), loss = 1.53039
I1029 04:54:44.980893 12802 solver.cpp:241]     Train net output #0: loss = 1.53039 (* 1 = 1.53039 loss)
I1029 04:54:44.980911 12802 sgd_solver.cpp:105] Iteration 44720, lr = 0.000178614
I1029 04:55:16.398461 12802 solver.cpp:222] Iteration 44760 (1.2732 iter/s, 31.4168s/40 iters), loss = 1.7843
I1029 04:55:16.398666 12802 solver.cpp:241]     Train net output #0: loss = 1.7843 (* 1 = 1.7843 loss)
I1029 04:55:16.398684 12802 sgd_solver.cpp:105] Iteration 44760, lr = 0.000177972
I1029 04:55:51.974467 12802 solver.cpp:222] Iteration 44800 (1.12439 iter/s, 35.575s/40 iters), loss = 1.30146
I1029 04:55:51.974653 12802 solver.cpp:241]     Train net output #0: loss = 1.30146 (* 1 = 1.30146 loss)
I1029 04:55:51.974684 12802 sgd_solver.cpp:105] Iteration 44800, lr = 0.000177332
I1029 04:56:24.826288 12802 solver.cpp:222] Iteration 44840 (1.21762 iter/s, 32.8509s/40 iters), loss = 1.42202
I1029 04:56:24.826489 12802 solver.cpp:241]     Train net output #0: loss = 1.42202 (* 1 = 1.42202 loss)
I1029 04:56:24.826504 12802 sgd_solver.cpp:105] Iteration 44840, lr = 0.000176695
I1029 04:56:54.605638 12802 solver.cpp:222] Iteration 44880 (1.34325 iter/s, 29.7784s/40 iters), loss = 1.573
I1029 04:56:54.605705 12802 solver.cpp:241]     Train net output #0: loss = 1.573 (* 1 = 1.573 loss)
I1029 04:56:54.605717 12802 sgd_solver.cpp:105] Iteration 44880, lr = 0.00017606
I1029 04:57:24.478909 12802 solver.cpp:222] Iteration 44920 (1.33902 iter/s, 29.8725s/40 iters), loss = 1.45447
I1029 04:57:24.479179 12802 solver.cpp:241]     Train net output #0: loss = 1.45447 (* 1 = 1.45447 loss)
I1029 04:57:24.479197 12802 sgd_solver.cpp:105] Iteration 44920, lr = 0.000175427
I1029 04:57:57.860126 12802 solver.cpp:222] Iteration 44960 (1.19832 iter/s, 33.3802s/40 iters), loss = 1.71095
I1029 04:57:57.860306 12802 solver.cpp:241]     Train net output #0: loss = 1.71095 (* 1 = 1.71095 loss)
I1029 04:57:57.860322 12802 sgd_solver.cpp:105] Iteration 44960, lr = 0.000174797
I1029 04:58:34.793146 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_45000.caffemodel
I1029 04:58:34.935392 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_45000.solverstate
I1029 04:58:35.048979 12802 solver.cpp:334] Iteration 45000, Testing net (#0)
I1029 04:59:06.264505 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58788
I1029 04:59:06.264659 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8098
I1029 04:59:06.264672 12802 solver.cpp:401]     Test net output #2: loss = 1.82878 (* 1 = 1.82878 loss)
I1029 04:59:07.037670 12802 solver.cpp:222] Iteration 45000 (0.578237 iter/s, 69.1758s/40 iters), loss = 1.50826
I1029 04:59:07.037734 12802 solver.cpp:241]     Train net output #0: loss = 1.50826 (* 1 = 1.50826 loss)
I1029 04:59:07.037750 12802 sgd_solver.cpp:105] Iteration 45000, lr = 0.000174168
I1029 04:59:37.371235 12802 solver.cpp:222] Iteration 45040 (1.31871 iter/s, 30.3328s/40 iters), loss = 1.32881
I1029 04:59:37.371407 12802 solver.cpp:241]     Train net output #0: loss = 1.32881 (* 1 = 1.32881 loss)
I1029 04:59:37.371428 12802 sgd_solver.cpp:105] Iteration 45040, lr = 0.000173542
I1029 05:00:07.875489 12802 solver.cpp:222] Iteration 45080 (1.31133 iter/s, 30.5034s/40 iters), loss = 1.39044
I1029 05:00:07.875696 12802 solver.cpp:241]     Train net output #0: loss = 1.39044 (* 1 = 1.39044 loss)
I1029 05:00:07.875712 12802 sgd_solver.cpp:105] Iteration 45080, lr = 0.000172919
I1029 05:00:38.390550 12802 solver.cpp:222] Iteration 45120 (1.31087 iter/s, 30.5141s/40 iters), loss = 1.5421
I1029 05:00:38.390756 12802 solver.cpp:241]     Train net output #0: loss = 1.5421 (* 1 = 1.5421 loss)
I1029 05:00:38.390784 12802 sgd_solver.cpp:105] Iteration 45120, lr = 0.000172297
I1029 05:01:09.699475 12802 solver.cpp:222] Iteration 45160 (1.27763 iter/s, 31.308s/40 iters), loss = 1.28551
I1029 05:01:09.699681 12802 solver.cpp:241]     Train net output #0: loss = 1.28551 (* 1 = 1.28551 loss)
I1029 05:01:09.699698 12802 sgd_solver.cpp:105] Iteration 45160, lr = 0.000171678
I1029 05:01:40.679657 12802 solver.cpp:222] Iteration 45200 (1.29119 iter/s, 30.9792s/40 iters), loss = 1.64069
I1029 05:01:40.679855 12802 solver.cpp:241]     Train net output #0: loss = 1.64069 (* 1 = 1.64069 loss)
I1029 05:01:40.679872 12802 sgd_solver.cpp:105] Iteration 45200, lr = 0.000171061
I1029 05:02:10.330744 12802 solver.cpp:222] Iteration 45240 (1.34906 iter/s, 29.6502s/40 iters), loss = 1.4193
I1029 05:02:10.330799 12802 solver.cpp:241]     Train net output #0: loss = 1.4193 (* 1 = 1.4193 loss)
I1029 05:02:10.330816 12802 sgd_solver.cpp:105] Iteration 45240, lr = 0.000170446
I1029 05:02:39.938567 12802 solver.cpp:222] Iteration 45280 (1.35103 iter/s, 29.6071s/40 iters), loss = 1.33905
I1029 05:02:39.938771 12802 solver.cpp:241]     Train net output #0: loss = 1.33905 (* 1 = 1.33905 loss)
I1029 05:02:39.938787 12802 sgd_solver.cpp:105] Iteration 45280, lr = 0.000169834
I1029 05:03:09.626616 12802 solver.cpp:222] Iteration 45320 (1.34738 iter/s, 29.6871s/40 iters), loss = 1.23104
I1029 05:03:09.626682 12802 solver.cpp:241]     Train net output #0: loss = 1.23104 (* 1 = 1.23104 loss)
I1029 05:03:09.626696 12802 sgd_solver.cpp:105] Iteration 45320, lr = 0.000169223
I1029 05:03:39.346877 12802 solver.cpp:222] Iteration 45360 (1.34592 iter/s, 29.7195s/40 iters), loss = 1.13123
I1029 05:03:39.347167 12802 solver.cpp:241]     Train net output #0: loss = 1.13123 (* 1 = 1.13123 loss)
I1029 05:03:39.347198 12802 sgd_solver.cpp:105] Iteration 45360, lr = 0.000168615
I1029 05:04:09.019572 12802 solver.cpp:222] Iteration 45400 (1.34809 iter/s, 29.6717s/40 iters), loss = 1.56069
I1029 05:04:09.019632 12802 solver.cpp:241]     Train net output #0: loss = 1.56069 (* 1 = 1.56069 loss)
I1029 05:04:09.019647 12802 sgd_solver.cpp:105] Iteration 45400, lr = 0.000168009
I1029 05:04:38.628974 12802 solver.cpp:222] Iteration 45440 (1.35096 iter/s, 29.6086s/40 iters), loss = 1.34762
I1029 05:04:38.629168 12802 solver.cpp:241]     Train net output #0: loss = 1.34762 (* 1 = 1.34762 loss)
I1029 05:04:38.629185 12802 sgd_solver.cpp:105] Iteration 45440, lr = 0.000167406
I1029 05:05:08.184653 12802 solver.cpp:222] Iteration 45480 (1.35342 iter/s, 29.5548s/40 iters), loss = 1.25745
I1029 05:05:08.184712 12802 solver.cpp:241]     Train net output #0: loss = 1.25745 (* 1 = 1.25745 loss)
I1029 05:05:08.184728 12802 sgd_solver.cpp:105] Iteration 45480, lr = 0.000166804
I1029 05:05:22.569872 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_45500.caffemodel
I1029 05:05:30.879647 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_45500.solverstate
I1029 05:05:31.012260 12802 solver.cpp:334] Iteration 45500, Testing net (#0)
I1029 05:06:02.017949 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 05:06:02.226311 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58412
I1029 05:06:02.226361 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8142
I1029 05:06:02.226372 12802 solver.cpp:401]     Test net output #2: loss = 1.83125 (* 1 = 1.83125 loss)
I1029 05:06:34.533627 12802 solver.cpp:222] Iteration 45520 (0.463248 iter/s, 86.3469s/40 iters), loss = 1.42134
I1029 05:06:34.533800 12802 solver.cpp:241]     Train net output #0: loss = 1.42134 (* 1 = 1.42134 loss)
I1029 05:06:34.533818 12802 sgd_solver.cpp:105] Iteration 45520, lr = 0.000166204
I1029 05:07:05.440441 12802 solver.cpp:222] Iteration 45560 (1.29425 iter/s, 30.9059s/40 iters), loss = 1.52933
I1029 05:07:05.440659 12802 solver.cpp:241]     Train net output #0: loss = 1.52933 (* 1 = 1.52933 loss)
I1029 05:07:05.440675 12802 sgd_solver.cpp:105] Iteration 45560, lr = 0.000165607
I1029 05:07:35.674353 12802 solver.cpp:222] Iteration 45600 (1.32306 iter/s, 30.233s/40 iters), loss = 1.41096
I1029 05:07:35.674500 12802 solver.cpp:241]     Train net output #0: loss = 1.41096 (* 1 = 1.41096 loss)
I1029 05:07:35.674518 12802 sgd_solver.cpp:105] Iteration 45600, lr = 0.000165012
I1029 05:08:05.841137 12802 solver.cpp:222] Iteration 45640 (1.326 iter/s, 30.1659s/40 iters), loss = 1.43092
I1029 05:08:05.841243 12802 solver.cpp:241]     Train net output #0: loss = 1.43092 (* 1 = 1.43092 loss)
I1029 05:08:05.841261 12802 sgd_solver.cpp:105] Iteration 45640, lr = 0.000164419
I1029 05:08:35.770488 12802 solver.cpp:222] Iteration 45680 (1.33652 iter/s, 29.9285s/40 iters), loss = 1.58635
I1029 05:08:35.770552 12802 solver.cpp:241]     Train net output #0: loss = 1.58635 (* 1 = 1.58635 loss)
I1029 05:08:35.770567 12802 sgd_solver.cpp:105] Iteration 45680, lr = 0.000163828
I1029 05:09:46.516976 12802 solver.cpp:222] Iteration 45720 (0.565413 iter/s, 70.7448s/40 iters), loss = 1.41143
I1029 05:09:46.517148 12802 solver.cpp:241]     Train net output #0: loss = 1.41143 (* 1 = 1.41143 loss)
I1029 05:09:46.517164 12802 sgd_solver.cpp:105] Iteration 45720, lr = 0.000163239
I1029 05:10:16.725945 12802 solver.cpp:222] Iteration 45760 (1.32415 iter/s, 30.2081s/40 iters), loss = 1.24914
I1029 05:10:16.726117 12802 solver.cpp:241]     Train net output #0: loss = 1.24914 (* 1 = 1.24914 loss)
I1029 05:10:16.726135 12802 sgd_solver.cpp:105] Iteration 45760, lr = 0.000162653
I1029 05:10:46.627616 12802 solver.cpp:222] Iteration 45800 (1.33776 iter/s, 29.9008s/40 iters), loss = 1.57462
I1029 05:10:46.627677 12802 solver.cpp:241]     Train net output #0: loss = 1.57462 (* 1 = 1.57462 loss)
I1029 05:10:46.627692 12802 sgd_solver.cpp:105] Iteration 45800, lr = 0.000162068
I1029 05:11:16.667023 12802 solver.cpp:222] Iteration 45840 (1.33162 iter/s, 30.0386s/40 iters), loss = 1.31764
I1029 05:11:16.667289 12802 solver.cpp:241]     Train net output #0: loss = 1.31764 (* 1 = 1.31764 loss)
I1029 05:11:16.667304 12802 sgd_solver.cpp:105] Iteration 45840, lr = 0.000161486
I1029 05:11:46.832706 12802 solver.cpp:222] Iteration 45880 (1.32605 iter/s, 30.1647s/40 iters), loss = 1.65085
I1029 05:11:46.832937 12802 solver.cpp:241]     Train net output #0: loss = 1.65085 (* 1 = 1.65085 loss)
I1029 05:11:46.832955 12802 sgd_solver.cpp:105] Iteration 45880, lr = 0.000160905
I1029 05:12:16.991044 12802 solver.cpp:222] Iteration 45920 (1.32637 iter/s, 30.1574s/40 iters), loss = 1.63005
I1029 05:12:16.991196 12802 solver.cpp:241]     Train net output #0: loss = 1.63005 (* 1 = 1.63005 loss)
I1029 05:12:16.991214 12802 sgd_solver.cpp:105] Iteration 45920, lr = 0.000160327
I1029 05:12:46.912600 12802 solver.cpp:222] Iteration 45960 (1.33687 iter/s, 29.9207s/40 iters), loss = 1.61858
I1029 05:12:46.912660 12802 solver.cpp:241]     Train net output #0: loss = 1.61858 (* 1 = 1.61858 loss)
I1029 05:12:46.912673 12802 sgd_solver.cpp:105] Iteration 45960, lr = 0.000159751
I1029 05:13:16.067616 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_46000.caffemodel
I1029 05:13:16.205832 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_46000.solverstate
I1029 05:13:16.322299 12802 solver.cpp:334] Iteration 46000, Testing net (#0)
I1029 05:13:47.554549 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58744
I1029 05:13:47.554656 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80896
I1029 05:13:47.554669 12802 solver.cpp:401]     Test net output #2: loss = 1.83075 (* 1 = 1.83075 loss)
I1029 05:13:48.313570 12802 solver.cpp:222] Iteration 46000 (0.651471 iter/s, 61.3995s/40 iters), loss = 1.40001
I1029 05:13:48.313627 12802 solver.cpp:241]     Train net output #0: loss = 1.40001 (* 1 = 1.40001 loss)
I1029 05:13:48.313643 12802 sgd_solver.cpp:105] Iteration 46000, lr = 0.000159177
I1029 05:14:18.069874 12802 solver.cpp:222] Iteration 46040 (1.34429 iter/s, 29.7555s/40 iters), loss = 1.35861
I1029 05:14:18.070073 12802 solver.cpp:241]     Train net output #0: loss = 1.35861 (* 1 = 1.35861 loss)
I1029 05:14:18.070091 12802 sgd_solver.cpp:105] Iteration 46040, lr = 0.000158605
I1029 05:14:47.827096 12802 solver.cpp:222] Iteration 46080 (1.34425 iter/s, 29.7563s/40 iters), loss = 1.35299
I1029 05:14:47.827157 12802 solver.cpp:241]     Train net output #0: loss = 1.35299 (* 1 = 1.35299 loss)
I1029 05:14:47.827172 12802 sgd_solver.cpp:105] Iteration 46080, lr = 0.000158035
I1029 05:15:17.440603 12802 solver.cpp:222] Iteration 46120 (1.35077 iter/s, 29.6127s/40 iters), loss = 1.56484
I1029 05:15:17.440816 12802 solver.cpp:241]     Train net output #0: loss = 1.56484 (* 1 = 1.56484 loss)
I1029 05:15:17.440830 12802 sgd_solver.cpp:105] Iteration 46120, lr = 0.000157467
I1029 05:15:19.759624 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 05:15:47.002254 12802 solver.cpp:222] Iteration 46160 (1.35315 iter/s, 29.5607s/40 iters), loss = 1.74795
I1029 05:15:47.002319 12802 solver.cpp:241]     Train net output #0: loss = 1.74795 (* 1 = 1.74795 loss)
I1029 05:15:47.002336 12802 sgd_solver.cpp:105] Iteration 46160, lr = 0.000156901
I1029 05:16:16.459588 12802 solver.cpp:222] Iteration 46200 (1.35793 iter/s, 29.4566s/40 iters), loss = 1.86157
I1029 05:16:16.459722 12802 solver.cpp:241]     Train net output #0: loss = 1.86157 (* 1 = 1.86157 loss)
I1029 05:16:16.459736 12802 sgd_solver.cpp:105] Iteration 46200, lr = 0.000156337
I1029 05:16:45.888664 12802 solver.cpp:222] Iteration 46240 (1.35924 iter/s, 29.4282s/40 iters), loss = 1.67941
I1029 05:16:45.888720 12802 solver.cpp:241]     Train net output #0: loss = 1.67941 (* 1 = 1.67941 loss)
I1029 05:16:45.888736 12802 sgd_solver.cpp:105] Iteration 46240, lr = 0.000155775
I1029 05:17:15.383287 12802 solver.cpp:222] Iteration 46280 (1.35621 iter/s, 29.4939s/40 iters), loss = 1.60215
I1029 05:17:15.383430 12802 solver.cpp:241]     Train net output #0: loss = 1.60215 (* 1 = 1.60215 loss)
I1029 05:17:15.383448 12802 sgd_solver.cpp:105] Iteration 46280, lr = 0.000155215
I1029 05:17:44.972251 12802 solver.cpp:222] Iteration 46320 (1.35189 iter/s, 29.5881s/40 iters), loss = 1.27667
I1029 05:17:44.972306 12802 solver.cpp:241]     Train net output #0: loss = 1.27667 (* 1 = 1.27667 loss)
I1029 05:17:44.972323 12802 sgd_solver.cpp:105] Iteration 46320, lr = 0.000154658
I1029 05:18:14.595304 12802 solver.cpp:222] Iteration 46360 (1.35033 iter/s, 29.6223s/40 iters), loss = 1.1363
I1029 05:18:14.595448 12802 solver.cpp:241]     Train net output #0: loss = 1.1363 (* 1 = 1.1363 loss)
I1029 05:18:14.595463 12802 sgd_solver.cpp:105] Iteration 46360, lr = 0.000154102
I1029 05:18:44.298807 12802 solver.cpp:222] Iteration 46400 (1.34668 iter/s, 29.7027s/40 iters), loss = 1.52089
I1029 05:18:44.298869 12802 solver.cpp:241]     Train net output #0: loss = 1.52089 (* 1 = 1.52089 loss)
I1029 05:18:44.298884 12802 sgd_solver.cpp:105] Iteration 46400, lr = 0.000153548
I1029 05:19:13.760449 12802 solver.cpp:222] Iteration 46440 (1.35773 iter/s, 29.4609s/40 iters), loss = 1.11946
I1029 05:19:13.760612 12802 solver.cpp:241]     Train net output #0: loss = 1.11946 (* 1 = 1.11946 loss)
I1029 05:19:13.760629 12802 sgd_solver.cpp:105] Iteration 46440, lr = 0.000152996
I1029 05:19:43.269342 12802 solver.cpp:222] Iteration 46480 (1.35556 iter/s, 29.508s/40 iters), loss = 1.2048
I1029 05:19:43.269407 12802 solver.cpp:241]     Train net output #0: loss = 1.2048 (* 1 = 1.2048 loss)
I1029 05:19:43.269428 12802 sgd_solver.cpp:105] Iteration 46480, lr = 0.000152446
I1029 05:19:58.197640 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_46500.caffemodel
I1029 05:19:58.344888 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_46500.solverstate
I1029 05:19:58.480196 12802 solver.cpp:334] Iteration 46500, Testing net (#0)
I1029 05:20:29.478232 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 05:20:29.687739 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58496
I1029 05:20:29.687790 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813399
I1029 05:20:29.687800 12802 solver.cpp:401]     Test net output #2: loss = 1.84138 (* 1 = 1.84138 loss)
I1029 05:20:45.189433 12802 solver.cpp:222] Iteration 46520 (0.64601 iter/s, 61.9186s/40 iters), loss = 1.40033
I1029 05:20:45.189492 12802 solver.cpp:241]     Train net output #0: loss = 1.40033 (* 1 = 1.40033 loss)
I1029 05:20:45.189508 12802 sgd_solver.cpp:105] Iteration 46520, lr = 0.000151898
I1029 05:21:15.153779 12802 solver.cpp:222] Iteration 46560 (1.33495 iter/s, 29.9636s/40 iters), loss = 1.54343
I1029 05:21:15.153952 12802 solver.cpp:241]     Train net output #0: loss = 1.54343 (* 1 = 1.54343 loss)
I1029 05:21:15.153970 12802 sgd_solver.cpp:105] Iteration 46560, lr = 0.000151352
I1029 05:21:44.574266 12802 solver.cpp:222] Iteration 46600 (1.35964 iter/s, 29.4196s/40 iters), loss = 1.34804
I1029 05:21:44.574322 12802 solver.cpp:241]     Train net output #0: loss = 1.34804 (* 1 = 1.34804 loss)
I1029 05:21:44.574337 12802 sgd_solver.cpp:105] Iteration 46600, lr = 0.000150809
I1029 05:22:14.030380 12802 solver.cpp:222] Iteration 46640 (1.35799 iter/s, 29.4554s/40 iters), loss = 1.37902
I1029 05:22:14.030468 12802 solver.cpp:241]     Train net output #0: loss = 1.37902 (* 1 = 1.37902 loss)
I1029 05:22:14.030483 12802 sgd_solver.cpp:105] Iteration 46640, lr = 0.000150267
I1029 05:22:43.551581 12802 solver.cpp:222] Iteration 46680 (1.35499 iter/s, 29.5204s/40 iters), loss = 0.907988
I1029 05:22:43.551640 12802 solver.cpp:241]     Train net output #0: loss = 0.907988 (* 1 = 0.907988 loss)
I1029 05:22:43.551656 12802 sgd_solver.cpp:105] Iteration 46680, lr = 0.000149727
I1029 05:23:13.083642 12802 solver.cpp:222] Iteration 46720 (1.3545 iter/s, 29.5313s/40 iters), loss = 1.53768
I1029 05:23:13.083883 12802 solver.cpp:241]     Train net output #0: loss = 1.53768 (* 1 = 1.53768 loss)
I1029 05:23:13.083915 12802 sgd_solver.cpp:105] Iteration 46720, lr = 0.000149188
I1029 05:23:43.198676 12802 solver.cpp:222] Iteration 46760 (1.32828 iter/s, 30.1141s/40 iters), loss = 1.33431
I1029 05:23:43.198807 12802 solver.cpp:241]     Train net output #0: loss = 1.33431 (* 1 = 1.33431 loss)
I1029 05:23:43.198823 12802 sgd_solver.cpp:105] Iteration 46760, lr = 0.000148652
I1029 05:24:12.780000 12802 solver.cpp:222] Iteration 46800 (1.35224 iter/s, 29.5805s/40 iters), loss = 1.18895
I1029 05:24:12.780056 12802 solver.cpp:241]     Train net output #0: loss = 1.18895 (* 1 = 1.18895 loss)
I1029 05:24:12.780069 12802 sgd_solver.cpp:105] Iteration 46800, lr = 0.000148118
I1029 05:24:42.475323 12802 solver.cpp:222] Iteration 46840 (1.34705 iter/s, 29.6946s/40 iters), loss = 1.37887
I1029 05:24:42.475427 12802 solver.cpp:241]     Train net output #0: loss = 1.37887 (* 1 = 1.37887 loss)
I1029 05:24:42.475441 12802 sgd_solver.cpp:105] Iteration 46840, lr = 0.000147586
I1029 05:25:12.541306 12802 solver.cpp:222] Iteration 46880 (1.33044 iter/s, 30.0652s/40 iters), loss = 1.67775
I1029 05:25:12.541443 12802 solver.cpp:241]     Train net output #0: loss = 1.67775 (* 1 = 1.67775 loss)
I1029 05:25:12.541460 12802 sgd_solver.cpp:105] Iteration 46880, lr = 0.000147055
I1029 05:25:43.036857 12802 solver.cpp:222] Iteration 46920 (1.3117 iter/s, 30.4947s/40 iters), loss = 1.24536
I1029 05:25:43.037001 12802 solver.cpp:241]     Train net output #0: loss = 1.24536 (* 1 = 1.24536 loss)
I1029 05:25:43.037026 12802 sgd_solver.cpp:105] Iteration 46920, lr = 0.000146527
I1029 05:27:24.499994 12802 solver.cpp:222] Iteration 46960 (0.394241 iter/s, 101.461s/40 iters), loss = 1.82768
I1029 05:27:24.500198 12802 solver.cpp:241]     Train net output #0: loss = 1.82768 (* 1 = 1.82768 loss)
I1029 05:27:24.500216 12802 sgd_solver.cpp:105] Iteration 46960, lr = 0.000146
I1029 05:27:53.705190 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_47000.caffemodel
I1029 05:27:54.073148 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_47000.solverstate
I1029 05:27:54.184394 12802 solver.cpp:334] Iteration 47000, Testing net (#0)
I1029 05:28:25.439764 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58636
I1029 05:28:25.439937 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.809759
I1029 05:28:25.439950 12802 solver.cpp:401]     Test net output #2: loss = 1.83702 (* 1 = 1.83702 loss)
I1029 05:28:26.191205 12802 solver.cpp:222] Iteration 47000 (0.648407 iter/s, 61.6896s/40 iters), loss = 1.4348
I1029 05:28:26.191251 12802 solver.cpp:241]     Train net output #0: loss = 1.4348 (* 1 = 1.4348 loss)
I1029 05:28:26.191267 12802 sgd_solver.cpp:105] Iteration 47000, lr = 0.000145476
I1029 05:28:55.682653 12802 solver.cpp:222] Iteration 47040 (1.35636 iter/s, 29.4907s/40 iters), loss = 1.01673
I1029 05:28:55.682843 12802 solver.cpp:241]     Train net output #0: loss = 1.01673 (* 1 = 1.01673 loss)
I1029 05:28:55.682857 12802 sgd_solver.cpp:105] Iteration 47040, lr = 0.000144953
I1029 05:29:25.172374 12802 solver.cpp:222] Iteration 47080 (1.35645 iter/s, 29.4888s/40 iters), loss = 1.4086
I1029 05:29:25.172433 12802 solver.cpp:241]     Train net output #0: loss = 1.4086 (* 1 = 1.4086 loss)
I1029 05:29:25.172448 12802 sgd_solver.cpp:105] Iteration 47080, lr = 0.000144432
I1029 05:29:55.104831 12802 solver.cpp:222] Iteration 47120 (1.33638 iter/s, 29.9317s/40 iters), loss = 1.43002
I1029 05:29:55.105031 12802 solver.cpp:241]     Train net output #0: loss = 1.43002 (* 1 = 1.43002 loss)
I1029 05:29:55.105047 12802 sgd_solver.cpp:105] Iteration 47120, lr = 0.000143913
I1029 05:30:25.767879 12802 solver.cpp:222] Iteration 47160 (1.30454 iter/s, 30.6621s/40 iters), loss = 1.49481
I1029 05:30:25.768155 12802 solver.cpp:241]     Train net output #0: loss = 1.49481 (* 1 = 1.49481 loss)
I1029 05:30:25.768193 12802 sgd_solver.cpp:105] Iteration 47160, lr = 0.000143396
I1029 05:31:01.590169 12802 solver.cpp:222] Iteration 47200 (1.11666 iter/s, 35.8212s/40 iters), loss = 1.17744
I1029 05:31:01.590349 12802 solver.cpp:241]     Train net output #0: loss = 1.17744 (* 1 = 1.17744 loss)
I1029 05:31:01.590368 12802 sgd_solver.cpp:105] Iteration 47200, lr = 0.00014288
I1029 05:31:32.014338 12802 solver.cpp:222] Iteration 47240 (1.31478 iter/s, 30.4233s/40 iters), loss = 1.58938
I1029 05:31:32.014506 12802 solver.cpp:241]     Train net output #0: loss = 1.58938 (* 1 = 1.58938 loss)
I1029 05:31:32.014523 12802 sgd_solver.cpp:105] Iteration 47240, lr = 0.000142367
I1029 05:32:01.585016 12802 solver.cpp:222] Iteration 47280 (1.35273 iter/s, 29.5698s/40 iters), loss = 1.40214
I1029 05:32:01.585078 12802 solver.cpp:241]     Train net output #0: loss = 1.40214 (* 1 = 1.40214 loss)
I1029 05:32:01.585093 12802 sgd_solver.cpp:105] Iteration 47280, lr = 0.000141855
I1029 05:32:31.247526 12802 solver.cpp:222] Iteration 47320 (1.34854 iter/s, 29.6617s/40 iters), loss = 1.34956
I1029 05:32:31.247709 12802 solver.cpp:241]     Train net output #0: loss = 1.34956 (* 1 = 1.34956 loss)
I1029 05:32:31.247725 12802 sgd_solver.cpp:105] Iteration 47320, lr = 0.000141345
I1029 05:33:32.183492 12802 solver.cpp:222] Iteration 47360 (0.656444 iter/s, 60.9343s/40 iters), loss = 1.48859
I1029 05:33:32.183704 12802 solver.cpp:241]     Train net output #0: loss = 1.48859 (* 1 = 1.48859 loss)
I1029 05:33:32.183723 12802 sgd_solver.cpp:105] Iteration 47360, lr = 0.000140837
I1029 05:34:10.974813 12802 solver.cpp:222] Iteration 47400 (1.03119 iter/s, 38.7902s/40 iters), loss = 1.11446
I1029 05:34:10.975026 12802 solver.cpp:241]     Train net output #0: loss = 1.11446 (* 1 = 1.11446 loss)
I1029 05:34:10.975041 12802 sgd_solver.cpp:105] Iteration 47400, lr = 0.000140331
I1029 05:34:40.960535 12802 solver.cpp:222] Iteration 47440 (1.33401 iter/s, 29.9848s/40 iters), loss = 1.29157
I1029 05:34:40.960592 12802 solver.cpp:241]     Train net output #0: loss = 1.29157 (* 1 = 1.29157 loss)
I1029 05:34:40.960608 12802 sgd_solver.cpp:105] Iteration 47440, lr = 0.000139827
I1029 05:35:10.557404 12802 solver.cpp:222] Iteration 47480 (1.35153 iter/s, 29.5961s/40 iters), loss = 1.3533
I1029 05:35:10.557632 12802 solver.cpp:241]     Train net output #0: loss = 1.3533 (* 1 = 1.3533 loss)
I1029 05:35:10.557646 12802 sgd_solver.cpp:105] Iteration 47480, lr = 0.000139324
I1029 05:35:24.614341 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_47500.caffemodel
I1029 05:35:24.767524 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_47500.solverstate
I1029 05:35:24.888623 12802 solver.cpp:334] Iteration 47500, Testing net (#0)
I1029 05:35:55.782413 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 05:35:55.989869 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58488
I1029 05:35:55.989924 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.815
I1029 05:35:55.989936 12802 solver.cpp:401]     Test net output #2: loss = 1.83795 (* 1 = 1.83795 loss)
I1029 05:36:11.668027 12802 solver.cpp:222] Iteration 47520 (0.654569 iter/s, 61.109s/40 iters), loss = 1.53515
I1029 05:36:11.668085 12802 solver.cpp:241]     Train net output #0: loss = 1.53515 (* 1 = 1.53515 loss)
I1029 05:36:11.668102 12802 sgd_solver.cpp:105] Iteration 47520, lr = 0.000138824
I1029 05:36:41.219851 12802 solver.cpp:222] Iteration 47560 (1.35359 iter/s, 29.551s/40 iters), loss = 1.36475
I1029 05:36:41.220005 12802 solver.cpp:241]     Train net output #0: loss = 1.36475 (* 1 = 1.36475 loss)
I1029 05:36:41.220021 12802 sgd_solver.cpp:105] Iteration 47560, lr = 0.000138325
I1029 05:37:10.838893 12802 solver.cpp:222] Iteration 47600 (1.35052 iter/s, 29.6182s/40 iters), loss = 1.60738
I1029 05:37:10.838961 12802 solver.cpp:241]     Train net output #0: loss = 1.60738 (* 1 = 1.60738 loss)
I1029 05:37:10.838976 12802 sgd_solver.cpp:105] Iteration 47600, lr = 0.000137828
I1029 05:37:40.413014 12802 solver.cpp:222] Iteration 47640 (1.35257 iter/s, 29.5733s/40 iters), loss = 1.41361
I1029 05:37:40.413247 12802 solver.cpp:241]     Train net output #0: loss = 1.41361 (* 1 = 1.41361 loss)
I1029 05:37:40.413264 12802 sgd_solver.cpp:105] Iteration 47640, lr = 0.000137332
I1029 05:38:10.009024 12802 solver.cpp:222] Iteration 47680 (1.35158 iter/s, 29.5951s/40 iters), loss = 1.31827
I1029 05:38:10.009081 12802 solver.cpp:241]     Train net output #0: loss = 1.31827 (* 1 = 1.31827 loss)
I1029 05:38:10.009096 12802 sgd_solver.cpp:105] Iteration 47680, lr = 0.000136839
I1029 05:38:39.673781 12802 solver.cpp:222] Iteration 47720 (1.34844 iter/s, 29.664s/40 iters), loss = 1.39073
I1029 05:38:39.673959 12802 solver.cpp:241]     Train net output #0: loss = 1.39073 (* 1 = 1.39073 loss)
I1029 05:38:39.673976 12802 sgd_solver.cpp:105] Iteration 47720, lr = 0.000136347
I1029 05:39:09.333547 12802 solver.cpp:222] Iteration 47760 (1.34867 iter/s, 29.6589s/40 iters), loss = 1.21373
I1029 05:39:09.333606 12802 solver.cpp:241]     Train net output #0: loss = 1.21373 (* 1 = 1.21373 loss)
I1029 05:39:09.333619 12802 sgd_solver.cpp:105] Iteration 47760, lr = 0.000135857
I1029 05:39:39.116638 12802 solver.cpp:222] Iteration 47800 (1.34308 iter/s, 29.7823s/40 iters), loss = 1.3982
I1029 05:39:39.116829 12802 solver.cpp:241]     Train net output #0: loss = 1.3982 (* 1 = 1.3982 loss)
I1029 05:39:39.116843 12802 sgd_solver.cpp:105] Iteration 47800, lr = 0.000135369
I1029 05:40:08.792968 12802 solver.cpp:222] Iteration 47840 (1.34792 iter/s, 29.6754s/40 iters), loss = 1.31828
I1029 05:40:08.793026 12802 solver.cpp:241]     Train net output #0: loss = 1.31828 (* 1 = 1.31828 loss)
I1029 05:40:08.793045 12802 sgd_solver.cpp:105] Iteration 47840, lr = 0.000134882
I1029 05:40:38.383723 12802 solver.cpp:222] Iteration 47880 (1.35181 iter/s, 29.59s/40 iters), loss = 1.70155
I1029 05:40:38.383908 12802 solver.cpp:241]     Train net output #0: loss = 1.70155 (* 1 = 1.70155 loss)
I1029 05:40:38.383930 12802 sgd_solver.cpp:105] Iteration 47880, lr = 0.000134398
I1029 05:41:45.608482 12802 solver.cpp:222] Iteration 47920 (0.595034 iter/s, 67.223s/40 iters), loss = 1.69127
I1029 05:41:45.608676 12802 solver.cpp:241]     Train net output #0: loss = 1.69127 (* 1 = 1.69127 loss)
I1029 05:41:45.608698 12802 sgd_solver.cpp:105] Iteration 47920, lr = 0.000133915
I1029 05:42:16.249159 12802 solver.cpp:222] Iteration 47960 (1.30549 iter/s, 30.6398s/40 iters), loss = 1.47881
I1029 05:42:16.249361 12802 solver.cpp:241]     Train net output #0: loss = 1.47881 (* 1 = 1.47881 loss)
I1029 05:42:16.249375 12802 sgd_solver.cpp:105] Iteration 47960, lr = 0.000133433
I1029 05:42:45.616989 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_48000.caffemodel
I1029 05:42:45.770655 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_48000.solverstate
I1029 05:42:45.884994 12802 solver.cpp:334] Iteration 48000, Testing net (#0)
I1029 05:43:17.067756 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5882
I1029 05:43:17.067915 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.809199
I1029 05:43:17.067934 12802 solver.cpp:401]     Test net output #2: loss = 1.82646 (* 1 = 1.82646 loss)
I1029 05:43:17.840942 12802 solver.cpp:222] Iteration 48000 (0.649454 iter/s, 61.5902s/40 iters), loss = 1.75531
I1029 05:43:17.841001 12802 solver.cpp:241]     Train net output #0: loss = 1.75531 (* 1 = 1.75531 loss)
I1029 05:43:17.841017 12802 sgd_solver.cpp:105] Iteration 48000, lr = 0.000132954
I1029 05:43:47.540397 12802 solver.cpp:222] Iteration 48040 (1.34686 iter/s, 29.6987s/40 iters), loss = 1.43783
I1029 05:43:47.540602 12802 solver.cpp:241]     Train net output #0: loss = 1.43783 (* 1 = 1.43783 loss)
I1029 05:43:47.540621 12802 sgd_solver.cpp:105] Iteration 48040, lr = 0.000132476
I1029 05:44:17.029302 12802 solver.cpp:222] Iteration 48080 (1.35648 iter/s, 29.488s/40 iters), loss = 1.75473
I1029 05:44:17.029362 12802 solver.cpp:241]     Train net output #0: loss = 1.75473 (* 1 = 1.75473 loss)
I1029 05:44:17.029378 12802 sgd_solver.cpp:105] Iteration 48080, lr = 0.000132
I1029 05:44:46.626718 12802 solver.cpp:222] Iteration 48120 (1.3515 iter/s, 29.5966s/40 iters), loss = 1.60162
I1029 05:44:46.626950 12802 solver.cpp:241]     Train net output #0: loss = 1.60162 (* 1 = 1.60162 loss)
I1029 05:44:46.626965 12802 sgd_solver.cpp:105] Iteration 48120, lr = 0.000131525
I1029 05:45:16.126621 12802 solver.cpp:222] Iteration 48160 (1.35598 iter/s, 29.499s/40 iters), loss = 1.32286
I1029 05:45:16.126677 12802 solver.cpp:241]     Train net output #0: loss = 1.32286 (* 1 = 1.32286 loss)
I1029 05:45:16.126691 12802 sgd_solver.cpp:105] Iteration 48160, lr = 0.000131053
I1029 05:45:45.793926 12802 solver.cpp:222] Iteration 48200 (1.34832 iter/s, 29.6665s/40 iters), loss = 1.47209
I1029 05:45:45.794111 12802 solver.cpp:241]     Train net output #0: loss = 1.47209 (* 1 = 1.47209 loss)
I1029 05:45:45.794128 12802 sgd_solver.cpp:105] Iteration 48200, lr = 0.000130582
I1029 05:46:15.472584 12802 solver.cpp:222] Iteration 48240 (1.34781 iter/s, 29.6778s/40 iters), loss = 1.65816
I1029 05:46:15.472641 12802 solver.cpp:241]     Train net output #0: loss = 1.65816 (* 1 = 1.65816 loss)
I1029 05:46:15.472657 12802 sgd_solver.cpp:105] Iteration 48240, lr = 0.000130113
I1029 05:46:45.938943 12802 solver.cpp:222] Iteration 48280 (1.31296 iter/s, 30.4656s/40 iters), loss = 1.47954
I1029 05:46:45.939159 12802 solver.cpp:241]     Train net output #0: loss = 1.47954 (* 1 = 1.47954 loss)
I1029 05:46:45.939177 12802 sgd_solver.cpp:105] Iteration 48280, lr = 0.000129645
I1029 05:47:16.376394 12802 solver.cpp:222] Iteration 48320 (1.31421 iter/s, 30.4365s/40 iters), loss = 1.59477
I1029 05:47:16.376569 12802 solver.cpp:241]     Train net output #0: loss = 1.59477 (* 1 = 1.59477 loss)
I1029 05:47:16.376585 12802 sgd_solver.cpp:105] Iteration 48320, lr = 0.000129179
I1029 05:47:46.711256 12802 solver.cpp:222] Iteration 48360 (1.31865 iter/s, 30.334s/40 iters), loss = 1.36474
I1029 05:47:46.711452 12802 solver.cpp:241]     Train net output #0: loss = 1.36474 (* 1 = 1.36474 loss)
I1029 05:47:46.711468 12802 sgd_solver.cpp:105] Iteration 48360, lr = 0.000128715
I1029 05:48:16.619215 12802 solver.cpp:222] Iteration 48400 (1.33748 iter/s, 29.9071s/40 iters), loss = 0.961624
I1029 05:48:16.619272 12802 solver.cpp:241]     Train net output #0: loss = 0.961624 (* 1 = 0.961624 loss)
I1029 05:48:16.619287 12802 sgd_solver.cpp:105] Iteration 48400, lr = 0.000128252
I1029 05:48:46.029785 12802 solver.cpp:222] Iteration 48440 (1.36009 iter/s, 29.4098s/40 iters), loss = 1.2959
I1029 05:48:46.029928 12802 solver.cpp:241]     Train net output #0: loss = 1.2959 (* 1 = 1.2959 loss)
I1029 05:48:46.029947 12802 sgd_solver.cpp:105] Iteration 48440, lr = 0.000127791
I1029 05:49:15.363672 12802 solver.cpp:222] Iteration 48480 (1.36365 iter/s, 29.333s/40 iters), loss = 1.57279
I1029 05:49:15.363730 12802 solver.cpp:241]     Train net output #0: loss = 1.57279 (* 1 = 1.57279 loss)
I1029 05:49:15.363749 12802 sgd_solver.cpp:105] Iteration 48480, lr = 0.000127332
I1029 05:49:29.301348 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_48500.caffemodel
I1029 05:49:29.441678 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_48500.solverstate
I1029 05:49:29.565112 12802 solver.cpp:334] Iteration 48500, Testing net (#0)
I1029 05:50:00.579691 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 05:50:00.791530 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5854
I1029 05:50:00.791581 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8142
I1029 05:50:00.791591 12802 solver.cpp:401]     Test net output #2: loss = 1.83674 (* 1 = 1.83674 loss)
I1029 05:50:16.396255 12802 solver.cpp:222] Iteration 48520 (0.655404 iter/s, 61.0311s/40 iters), loss = 1.61592
I1029 05:50:16.396311 12802 solver.cpp:241]     Train net output #0: loss = 1.61592 (* 1 = 1.61592 loss)
I1029 05:50:16.396327 12802 sgd_solver.cpp:105] Iteration 48520, lr = 0.000126874
I1029 05:50:47.002152 12802 solver.cpp:222] Iteration 48560 (1.30697 iter/s, 30.6051s/40 iters), loss = 1.52353
I1029 05:50:47.002426 12802 solver.cpp:241]     Train net output #0: loss = 1.52353 (* 1 = 1.52353 loss)
I1029 05:50:47.002450 12802 sgd_solver.cpp:105] Iteration 48560, lr = 0.000126418
I1029 05:51:16.491991 12802 solver.cpp:222] Iteration 48600 (1.35644 iter/s, 29.4889s/40 iters), loss = 1.47605
I1029 05:51:16.492048 12802 solver.cpp:241]     Train net output #0: loss = 1.47605 (* 1 = 1.47605 loss)
I1029 05:51:16.492063 12802 sgd_solver.cpp:105] Iteration 48600, lr = 0.000125964
I1029 05:51:35.659538 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 05:51:45.961621 12802 solver.cpp:222] Iteration 48640 (1.35737 iter/s, 29.4689s/40 iters), loss = 1.0935
I1029 05:51:45.961678 12802 solver.cpp:241]     Train net output #0: loss = 1.0935 (* 1 = 1.0935 loss)
I1029 05:51:45.961694 12802 sgd_solver.cpp:105] Iteration 48640, lr = 0.000125511
I1029 05:52:15.474021 12802 solver.cpp:222] Iteration 48680 (1.3554 iter/s, 29.5116s/40 iters), loss = 1.28186
I1029 05:52:15.474174 12802 solver.cpp:241]     Train net output #0: loss = 1.28186 (* 1 = 1.28186 loss)
I1029 05:52:15.474190 12802 sgd_solver.cpp:105] Iteration 48680, lr = 0.00012506
I1029 05:52:45.027220 12802 solver.cpp:222] Iteration 48720 (1.35353 iter/s, 29.5523s/40 iters), loss = 1.6674
I1029 05:52:45.027277 12802 solver.cpp:241]     Train net output #0: loss = 1.6674 (* 1 = 1.6674 loss)
I1029 05:52:45.027293 12802 sgd_solver.cpp:105] Iteration 48720, lr = 0.000124611
I1029 05:53:14.580302 12802 solver.cpp:222] Iteration 48760 (1.35353 iter/s, 29.5523s/40 iters), loss = 1.07301
I1029 05:53:14.580430 12802 solver.cpp:241]     Train net output #0: loss = 1.07301 (* 1 = 1.07301 loss)
I1029 05:53:14.580447 12802 sgd_solver.cpp:105] Iteration 48760, lr = 0.000124163
I1029 05:55:19.314160 12802 solver.cpp:222] Iteration 48800 (0.32069 iter/s, 124.731s/40 iters), loss = 1.43367
I1029 05:55:19.314327 12802 solver.cpp:241]     Train net output #0: loss = 1.43367 (* 1 = 1.43367 loss)
I1029 05:55:19.314344 12802 sgd_solver.cpp:105] Iteration 48800, lr = 0.000123717
I1029 05:55:49.508764 12802 solver.cpp:222] Iteration 48840 (1.32478 iter/s, 30.1937s/40 iters), loss = 1.47706
I1029 05:55:49.508908 12802 solver.cpp:241]     Train net output #0: loss = 1.47706 (* 1 = 1.47706 loss)
I1029 05:55:49.508929 12802 sgd_solver.cpp:105] Iteration 48840, lr = 0.000123272
I1029 05:56:19.868218 12802 solver.cpp:222] Iteration 48880 (1.31758 iter/s, 30.3586s/40 iters), loss = 1.14724
I1029 05:56:19.868415 12802 solver.cpp:241]     Train net output #0: loss = 1.14724 (* 1 = 1.14724 loss)
I1029 05:56:19.868430 12802 sgd_solver.cpp:105] Iteration 48880, lr = 0.000122829
I1029 05:56:50.494307 12802 solver.cpp:222] Iteration 48920 (1.30611 iter/s, 30.6252s/40 iters), loss = 1.41137
I1029 05:56:50.494469 12802 solver.cpp:241]     Train net output #0: loss = 1.41137 (* 1 = 1.41137 loss)
I1029 05:56:50.494487 12802 sgd_solver.cpp:105] Iteration 48920, lr = 0.000122388
I1029 05:57:21.150308 12802 solver.cpp:222] Iteration 48960 (1.30484 iter/s, 30.6551s/40 iters), loss = 1.41867
I1029 05:57:21.150471 12802 solver.cpp:241]     Train net output #0: loss = 1.41867 (* 1 = 1.41867 loss)
I1029 05:57:21.150491 12802 sgd_solver.cpp:105] Iteration 48960, lr = 0.000121948
I1029 05:58:04.413457 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_49000.caffemodel
I1029 05:58:04.543654 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_49000.solverstate
I1029 05:58:04.667551 12802 solver.cpp:334] Iteration 49000, Testing net (#0)
I1029 05:58:35.794061 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58744
I1029 05:58:35.794314 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80996
I1029 05:58:35.794329 12802 solver.cpp:401]     Test net output #2: loss = 1.83506 (* 1 = 1.83506 loss)
I1029 05:58:36.564052 12802 solver.cpp:222] Iteration 49000 (0.530421 iter/s, 75.4118s/40 iters), loss = 1.51941
I1029 05:58:36.564115 12802 solver.cpp:241]     Train net output #0: loss = 1.51941 (* 1 = 1.51941 loss)
I1029 05:58:36.564136 12802 sgd_solver.cpp:105] Iteration 49000, lr = 0.00012151
I1029 05:59:07.846487 12802 solver.cpp:222] Iteration 49040 (1.27871 iter/s, 31.2816s/40 iters), loss = 1.66736
I1029 05:59:07.846680 12802 solver.cpp:241]     Train net output #0: loss = 1.66736 (* 1 = 1.66736 loss)
I1029 05:59:07.846698 12802 sgd_solver.cpp:105] Iteration 49040, lr = 0.000121073
I1029 05:59:39.259858 12802 solver.cpp:222] Iteration 49080 (1.27338 iter/s, 31.4124s/40 iters), loss = 1.21786
I1029 05:59:39.260072 12802 solver.cpp:241]     Train net output #0: loss = 1.21786 (* 1 = 1.21786 loss)
I1029 05:59:39.260087 12802 sgd_solver.cpp:105] Iteration 49080, lr = 0.000120638
I1029 06:00:09.703840 12802 solver.cpp:222] Iteration 49120 (1.31393 iter/s, 30.443s/40 iters), loss = 1.64319
I1029 06:00:09.704046 12802 solver.cpp:241]     Train net output #0: loss = 1.64319 (* 1 = 1.64319 loss)
I1029 06:00:09.704066 12802 sgd_solver.cpp:105] Iteration 49120, lr = 0.000120204
I1029 06:00:40.021548 12802 solver.cpp:222] Iteration 49160 (1.3194 iter/s, 30.3168s/40 iters), loss = 1.39145
I1029 06:00:40.021701 12802 solver.cpp:241]     Train net output #0: loss = 1.39145 (* 1 = 1.39145 loss)
I1029 06:00:40.021718 12802 sgd_solver.cpp:105] Iteration 49160, lr = 0.000119772
I1029 06:01:10.327085 12802 solver.cpp:222] Iteration 49200 (1.31993 iter/s, 30.3047s/40 iters), loss = 1.38845
I1029 06:01:10.327282 12802 solver.cpp:241]     Train net output #0: loss = 1.38845 (* 1 = 1.38845 loss)
I1029 06:01:10.327297 12802 sgd_solver.cpp:105] Iteration 49200, lr = 0.000119342
I1029 06:01:40.811125 12802 solver.cpp:222] Iteration 49240 (1.3122 iter/s, 30.4831s/40 iters), loss = 1.24452
I1029 06:01:40.811331 12802 solver.cpp:241]     Train net output #0: loss = 1.24452 (* 1 = 1.24452 loss)
I1029 06:01:40.811347 12802 sgd_solver.cpp:105] Iteration 49240, lr = 0.000118913
I1029 06:02:11.508910 12802 solver.cpp:222] Iteration 49280 (1.30306 iter/s, 30.6969s/40 iters), loss = 1.268
I1029 06:02:11.509109 12802 solver.cpp:241]     Train net output #0: loss = 1.268 (* 1 = 1.268 loss)
I1029 06:02:11.509126 12802 sgd_solver.cpp:105] Iteration 49280, lr = 0.000118486
I1029 06:02:41.244329 12802 solver.cpp:222] Iteration 49320 (1.34524 iter/s, 29.7345s/40 iters), loss = 1.16737
I1029 06:02:41.244392 12802 solver.cpp:241]     Train net output #0: loss = 1.16737 (* 1 = 1.16737 loss)
I1029 06:02:41.244408 12802 sgd_solver.cpp:105] Iteration 49320, lr = 0.00011806
I1029 06:03:10.960662 12802 solver.cpp:222] Iteration 49360 (1.3461 iter/s, 29.7156s/40 iters), loss = 1.45886
I1029 06:03:10.960819 12802 solver.cpp:241]     Train net output #0: loss = 1.45886 (* 1 = 1.45886 loss)
I1029 06:03:10.960835 12802 sgd_solver.cpp:105] Iteration 49360, lr = 0.000117636
I1029 06:03:40.513424 12802 solver.cpp:222] Iteration 49400 (1.35355 iter/s, 29.5519s/40 iters), loss = 1.58068
I1029 06:03:40.513489 12802 solver.cpp:241]     Train net output #0: loss = 1.58068 (* 1 = 1.58068 loss)
I1029 06:03:40.513505 12802 sgd_solver.cpp:105] Iteration 49400, lr = 0.000117213
I1029 06:04:10.392645 12802 solver.cpp:222] Iteration 49440 (1.33876 iter/s, 29.8784s/40 iters), loss = 1.50938
I1029 06:04:10.392813 12802 solver.cpp:241]     Train net output #0: loss = 1.50938 (* 1 = 1.50938 loss)
I1029 06:04:10.392830 12802 sgd_solver.cpp:105] Iteration 49440, lr = 0.000116792
I1029 06:04:39.878945 12802 solver.cpp:222] Iteration 49480 (1.3566 iter/s, 29.4854s/40 iters), loss = 1.43225
I1029 06:04:39.879003 12802 solver.cpp:241]     Train net output #0: loss = 1.43225 (* 1 = 1.43225 loss)
I1029 06:04:39.879017 12802 sgd_solver.cpp:105] Iteration 49480, lr = 0.000116372
I1029 06:04:53.893996 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_49500.caffemodel
I1029 06:04:59.467905 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_49500.solverstate
I1029 06:04:59.586424 12802 solver.cpp:334] Iteration 49500, Testing net (#0)
I1029 06:05:30.511754 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 06:05:30.720057 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58488
I1029 06:05:30.720106 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81404
I1029 06:05:30.720118 12802 solver.cpp:401]     Test net output #2: loss = 1.84018 (* 1 = 1.84018 loss)
I1029 06:05:46.563087 12802 solver.cpp:222] Iteration 49520 (0.599857 iter/s, 66.6825s/40 iters), loss = 1.38007
I1029 06:05:46.563149 12802 solver.cpp:241]     Train net output #0: loss = 1.38007 (* 1 = 1.38007 loss)
I1029 06:05:46.563164 12802 sgd_solver.cpp:105] Iteration 49520, lr = 0.000115954
I1029 06:06:16.005395 12802 solver.cpp:222] Iteration 49560 (1.35862 iter/s, 29.4415s/40 iters), loss = 1.56352
I1029 06:06:16.005537 12802 solver.cpp:241]     Train net output #0: loss = 1.56352 (* 1 = 1.56352 loss)
I1029 06:06:16.005553 12802 sgd_solver.cpp:105] Iteration 49560, lr = 0.000115537
I1029 06:06:45.465627 12802 solver.cpp:222] Iteration 49600 (1.3578 iter/s, 29.4594s/40 iters), loss = 1.03809
I1029 06:06:45.465687 12802 solver.cpp:241]     Train net output #0: loss = 1.03809 (* 1 = 1.03809 loss)
I1029 06:06:45.465703 12802 sgd_solver.cpp:105] Iteration 49600, lr = 0.000115122
I1029 06:07:14.980144 12802 solver.cpp:222] Iteration 49640 (1.3553 iter/s, 29.5138s/40 iters), loss = 1.53597
I1029 06:07:14.980253 12802 solver.cpp:241]     Train net output #0: loss = 1.53597 (* 1 = 1.53597 loss)
I1029 06:07:14.980276 12802 sgd_solver.cpp:105] Iteration 49640, lr = 0.000114708
I1029 06:07:44.555238 12802 solver.cpp:222] Iteration 49680 (1.35253 iter/s, 29.5743s/40 iters), loss = 1.30884
I1029 06:07:44.555302 12802 solver.cpp:241]     Train net output #0: loss = 1.30884 (* 1 = 1.30884 loss)
I1029 06:07:44.555318 12802 sgd_solver.cpp:105] Iteration 49680, lr = 0.000114296
I1029 06:08:14.719691 12802 solver.cpp:222] Iteration 49720 (1.3261 iter/s, 30.1637s/40 iters), loss = 1.50016
I1029 06:08:14.719868 12802 solver.cpp:241]     Train net output #0: loss = 1.50016 (* 1 = 1.50016 loss)
I1029 06:08:14.719885 12802 sgd_solver.cpp:105] Iteration 49720, lr = 0.000113885
I1029 06:08:44.948204 12802 solver.cpp:222] Iteration 49760 (1.32329 iter/s, 30.2276s/40 iters), loss = 1.71257
I1029 06:08:44.948403 12802 solver.cpp:241]     Train net output #0: loss = 1.71257 (* 1 = 1.71257 loss)
I1029 06:08:44.948421 12802 sgd_solver.cpp:105] Iteration 49760, lr = 0.000113476
I1029 06:09:14.532285 12802 solver.cpp:222] Iteration 49800 (1.35212 iter/s, 29.5832s/40 iters), loss = 1.22154
I1029 06:09:14.532343 12802 solver.cpp:241]     Train net output #0: loss = 1.22154 (* 1 = 1.22154 loss)
I1029 06:09:14.532359 12802 sgd_solver.cpp:105] Iteration 49800, lr = 0.000113068
I1029 06:09:43.942796 12802 solver.cpp:222] Iteration 49840 (1.36009 iter/s, 29.4097s/40 iters), loss = 1.31079
I1029 06:09:43.942979 12802 solver.cpp:241]     Train net output #0: loss = 1.31079 (* 1 = 1.31079 loss)
I1029 06:09:43.942994 12802 sgd_solver.cpp:105] Iteration 49840, lr = 0.000112662
I1029 06:10:13.332515 12802 solver.cpp:222] Iteration 49880 (1.36106 iter/s, 29.3888s/40 iters), loss = 1.34717
I1029 06:10:13.332576 12802 solver.cpp:241]     Train net output #0: loss = 1.34717 (* 1 = 1.34717 loss)
I1029 06:10:13.332592 12802 sgd_solver.cpp:105] Iteration 49880, lr = 0.000112257
I1029 06:10:42.739655 12802 solver.cpp:222] Iteration 49920 (1.36025 iter/s, 29.4064s/40 iters), loss = 1.35109
I1029 06:10:42.739814 12802 solver.cpp:241]     Train net output #0: loss = 1.35109 (* 1 = 1.35109 loss)
I1029 06:10:42.739830 12802 sgd_solver.cpp:105] Iteration 49920, lr = 0.000111853
I1029 06:11:12.199573 12802 solver.cpp:222] Iteration 49960 (1.35782 iter/s, 29.4591s/40 iters), loss = 1.63158
I1029 06:11:12.199638 12802 solver.cpp:241]     Train net output #0: loss = 1.63158 (* 1 = 1.63158 loss)
I1029 06:11:12.199653 12802 sgd_solver.cpp:105] Iteration 49960, lr = 0.000111451
I1029 06:11:41.139084 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_50000.caffemodel
I1029 06:11:41.279363 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_50000.solverstate
I1029 06:11:41.406074 12802 solver.cpp:334] Iteration 50000, Testing net (#0)
I1029 06:12:12.681455 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5888
I1029 06:12:12.681599 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80952
I1029 06:12:12.681613 12802 solver.cpp:401]     Test net output #2: loss = 1.83645 (* 1 = 1.83645 loss)
I1029 06:12:13.449257 12802 solver.cpp:222] Iteration 50000 (0.653081 iter/s, 61.2482s/40 iters), loss = 1.44107
I1029 06:12:13.449314 12802 solver.cpp:241]     Train net output #0: loss = 1.44107 (* 1 = 1.44107 loss)
I1029 06:12:13.449331 12802 sgd_solver.cpp:105] Iteration 50000, lr = 0.000111051
I1029 06:12:43.187119 12802 solver.cpp:222] Iteration 50040 (1.34512 iter/s, 29.7371s/40 iters), loss = 1.30816
I1029 06:12:43.187289 12802 solver.cpp:241]     Train net output #0: loss = 1.30816 (* 1 = 1.30816 loss)
I1029 06:12:43.187304 12802 sgd_solver.cpp:105] Iteration 50040, lr = 0.000110652
I1029 06:13:12.858232 12802 solver.cpp:222] Iteration 50080 (1.34815 iter/s, 29.6702s/40 iters), loss = 1.21594
I1029 06:13:12.858300 12802 solver.cpp:241]     Train net output #0: loss = 1.21594 (* 1 = 1.21594 loss)
I1029 06:13:12.858321 12802 sgd_solver.cpp:105] Iteration 50080, lr = 0.000110254
I1029 06:13:42.529647 12802 solver.cpp:222] Iteration 50120 (1.34813 iter/s, 29.6706s/40 iters), loss = 1.39035
I1029 06:13:42.529836 12802 solver.cpp:241]     Train net output #0: loss = 1.39035 (* 1 = 1.39035 loss)
I1029 06:13:42.529853 12802 sgd_solver.cpp:105] Iteration 50120, lr = 0.000109858
I1029 06:14:12.611654 12802 solver.cpp:222] Iteration 50160 (1.32974 iter/s, 30.0811s/40 iters), loss = 1.242
I1029 06:14:12.611806 12802 solver.cpp:241]     Train net output #0: loss = 1.242 (* 1 = 1.242 loss)
I1029 06:14:12.611821 12802 sgd_solver.cpp:105] Iteration 50160, lr = 0.000109463
I1029 06:14:43.050026 12802 solver.cpp:222] Iteration 50200 (1.31417 iter/s, 30.4375s/40 iters), loss = 1.27878
I1029 06:14:43.050218 12802 solver.cpp:241]     Train net output #0: loss = 1.27878 (* 1 = 1.27878 loss)
I1029 06:14:43.050235 12802 sgd_solver.cpp:105] Iteration 50200, lr = 0.00010907
I1029 06:15:13.355247 12802 solver.cpp:222] Iteration 50240 (1.31994 iter/s, 30.3043s/40 iters), loss = 1.14804
I1029 06:15:13.355438 12802 solver.cpp:241]     Train net output #0: loss = 1.14804 (* 1 = 1.14804 loss)
I1029 06:15:13.355456 12802 sgd_solver.cpp:105] Iteration 50240, lr = 0.000108678
I1029 06:15:42.876003 12802 solver.cpp:222] Iteration 50280 (1.35502 iter/s, 29.5199s/40 iters), loss = 1.29373
I1029 06:15:42.876060 12802 solver.cpp:241]     Train net output #0: loss = 1.29373 (* 1 = 1.29373 loss)
I1029 06:15:42.876075 12802 sgd_solver.cpp:105] Iteration 50280, lr = 0.000108287
I1029 06:16:12.296962 12802 solver.cpp:222] Iteration 50320 (1.35961 iter/s, 29.4202s/40 iters), loss = 1.45232
I1029 06:16:12.297168 12802 solver.cpp:241]     Train net output #0: loss = 1.45232 (* 1 = 1.45232 loss)
I1029 06:16:12.297184 12802 sgd_solver.cpp:105] Iteration 50320, lr = 0.000107898
I1029 06:16:41.878963 12802 solver.cpp:222] Iteration 50360 (1.35222 iter/s, 29.5811s/40 iters), loss = 1.3885
I1029 06:16:41.879036 12802 solver.cpp:241]     Train net output #0: loss = 1.3885 (* 1 = 1.3885 loss)
I1029 06:16:41.879060 12802 sgd_solver.cpp:105] Iteration 50360, lr = 0.00010751
I1029 06:17:11.584468 12802 solver.cpp:222] Iteration 50400 (1.34659 iter/s, 29.7047s/40 iters), loss = 1.39452
I1029 06:17:11.584724 12802 solver.cpp:241]     Train net output #0: loss = 1.39452 (* 1 = 1.39452 loss)
I1029 06:17:11.584743 12802 sgd_solver.cpp:105] Iteration 50400, lr = 0.000107124
I1029 06:17:41.122771 12802 solver.cpp:222] Iteration 50440 (1.35422 iter/s, 29.5374s/40 iters), loss = 1.18544
I1029 06:17:41.122826 12802 solver.cpp:241]     Train net output #0: loss = 1.18544 (* 1 = 1.18544 loss)
I1029 06:17:41.122841 12802 sgd_solver.cpp:105] Iteration 50440, lr = 0.000106739
I1029 06:18:10.706943 12802 solver.cpp:222] Iteration 50480 (1.35211 iter/s, 29.5834s/40 iters), loss = 1.32474
I1029 06:18:10.707095 12802 solver.cpp:241]     Train net output #0: loss = 1.32474 (* 1 = 1.32474 loss)
I1029 06:18:10.707109 12802 sgd_solver.cpp:105] Iteration 50480, lr = 0.000106355
I1029 06:18:24.757936 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_50500.caffemodel
I1029 06:18:24.897212 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_50500.solverstate
I1029 06:18:25.034773 12802 solver.cpp:334] Iteration 50500, Testing net (#0)
I1029 06:18:56.091109 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 06:18:56.298713 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58428
I1029 06:18:56.298763 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81512
I1029 06:18:56.298773 12802 solver.cpp:401]     Test net output #2: loss = 1.83241 (* 1 = 1.83241 loss)
I1029 06:19:11.858153 12802 solver.cpp:222] Iteration 50520 (0.654133 iter/s, 61.1496s/40 iters), loss = 1.38133
I1029 06:19:11.858212 12802 solver.cpp:241]     Train net output #0: loss = 1.38133 (* 1 = 1.38133 loss)
I1029 06:19:11.858225 12802 sgd_solver.cpp:105] Iteration 50520, lr = 0.000105973
I1029 06:19:41.432126 12802 solver.cpp:222] Iteration 50560 (1.35258 iter/s, 29.5732s/40 iters), loss = 1.37506
I1029 06:19:41.432283 12802 solver.cpp:241]     Train net output #0: loss = 1.37506 (* 1 = 1.37506 loss)
I1029 06:19:41.432301 12802 sgd_solver.cpp:105] Iteration 50560, lr = 0.000105592
I1029 06:20:11.072578 12802 solver.cpp:222] Iteration 50600 (1.34955 iter/s, 29.6396s/40 iters), loss = 1.43898
I1029 06:20:11.072639 12802 solver.cpp:241]     Train net output #0: loss = 1.43898 (* 1 = 1.43898 loss)
I1029 06:20:11.072654 12802 sgd_solver.cpp:105] Iteration 50600, lr = 0.000105213
I1029 06:20:40.707620 12802 solver.cpp:222] Iteration 50640 (1.34979 iter/s, 29.6343s/40 iters), loss = 1.74022
I1029 06:20:40.707792 12802 solver.cpp:241]     Train net output #0: loss = 1.74022 (* 1 = 1.74022 loss)
I1029 06:20:40.707809 12802 sgd_solver.cpp:105] Iteration 50640, lr = 0.000104834
I1029 06:21:10.682667 12802 solver.cpp:222] Iteration 50680 (1.33448 iter/s, 29.9742s/40 iters), loss = 1.12087
I1029 06:21:10.682726 12802 solver.cpp:241]     Train net output #0: loss = 1.12087 (* 1 = 1.12087 loss)
I1029 06:21:10.682739 12802 sgd_solver.cpp:105] Iteration 50680, lr = 0.000104458
I1029 06:21:40.724855 12802 solver.cpp:222] Iteration 50720 (1.3315 iter/s, 30.0414s/40 iters), loss = 1.28764
I1029 06:21:40.725065 12802 solver.cpp:241]     Train net output #0: loss = 1.28764 (* 1 = 1.28764 loss)
I1029 06:21:40.725090 12802 sgd_solver.cpp:105] Iteration 50720, lr = 0.000104082
I1029 06:24:32.016927 12802 solver.cpp:222] Iteration 50760 (0.233525 iter/s, 171.288s/40 iters), loss = 1.44013
I1029 06:24:32.017110 12802 solver.cpp:241]     Train net output #0: loss = 1.44013 (* 1 = 1.44013 loss)
I1029 06:24:32.017127 12802 sgd_solver.cpp:105] Iteration 50760, lr = 0.000103708
I1029 06:25:01.926723 12802 solver.cpp:222] Iteration 50800 (1.33739 iter/s, 29.9089s/40 iters), loss = 1.55815
I1029 06:25:01.926780 12802 solver.cpp:241]     Train net output #0: loss = 1.55815 (* 1 = 1.55815 loss)
I1029 06:25:01.926795 12802 sgd_solver.cpp:105] Iteration 50800, lr = 0.000103336
I1029 06:25:31.972709 12802 solver.cpp:222] Iteration 50840 (1.33133 iter/s, 30.0452s/40 iters), loss = 1.2464
I1029 06:25:31.972913 12802 solver.cpp:241]     Train net output #0: loss = 1.2464 (* 1 = 1.2464 loss)
I1029 06:25:31.972934 12802 sgd_solver.cpp:105] Iteration 50840, lr = 0.000102964
I1029 06:26:02.089802 12802 solver.cpp:222] Iteration 50880 (1.32819 iter/s, 30.1162s/40 iters), loss = 1.83053
I1029 06:26:02.090006 12802 solver.cpp:241]     Train net output #0: loss = 1.83053 (* 1 = 1.83053 loss)
I1029 06:26:02.090025 12802 sgd_solver.cpp:105] Iteration 50880, lr = 0.000102594
I1029 06:26:31.966346 12802 solver.cpp:222] Iteration 50920 (1.33888 iter/s, 29.8756s/40 iters), loss = 1.39544
I1029 06:26:31.966418 12802 solver.cpp:241]     Train net output #0: loss = 1.39544 (* 1 = 1.39544 loss)
I1029 06:26:31.966439 12802 sgd_solver.cpp:105] Iteration 50920, lr = 0.000102225
I1029 06:27:02.207847 12802 solver.cpp:222] Iteration 50960 (1.32272 iter/s, 30.2407s/40 iters), loss = 1.72192
I1029 06:27:02.208079 12802 solver.cpp:241]     Train net output #0: loss = 1.72192 (* 1 = 1.72192 loss)
I1029 06:27:02.208097 12802 sgd_solver.cpp:105] Iteration 50960, lr = 0.000101858
I1029 06:27:32.098597 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_51000.caffemodel
I1029 06:27:32.244863 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_51000.solverstate
I1029 06:27:32.361141 12802 solver.cpp:334] Iteration 51000, Testing net (#0)
I1029 06:28:03.473227 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58984
I1029 06:28:03.473372 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8096
I1029 06:28:03.473386 12802 solver.cpp:401]     Test net output #2: loss = 1.82934 (* 1 = 1.82934 loss)
I1029 06:28:04.237638 12802 solver.cpp:222] Iteration 51000 (0.644869 iter/s, 62.0281s/40 iters), loss = 1.53254
I1029 06:28:04.237695 12802 solver.cpp:241]     Train net output #0: loss = 1.53254 (* 1 = 1.53254 loss)
I1029 06:28:04.237722 12802 sgd_solver.cpp:105] Iteration 51000, lr = 0.000101492
I1029 06:28:34.045027 12802 solver.cpp:222] Iteration 51040 (1.34198 iter/s, 29.8066s/40 iters), loss = 1.67313
I1029 06:28:34.045220 12802 solver.cpp:241]     Train net output #0: loss = 1.67313 (* 1 = 1.67313 loss)
I1029 06:28:34.045238 12802 sgd_solver.cpp:105] Iteration 51040, lr = 0.000101127
I1029 06:29:03.861131 12802 solver.cpp:222] Iteration 51080 (1.3416 iter/s, 29.8152s/40 iters), loss = 1.36603
I1029 06:29:03.861191 12802 solver.cpp:241]     Train net output #0: loss = 1.36603 (* 1 = 1.36603 loss)
I1029 06:29:03.861205 12802 sgd_solver.cpp:105] Iteration 51080, lr = 0.000100764
I1029 06:29:34.018316 12802 solver.cpp:222] Iteration 51120 (1.32642 iter/s, 30.1564s/40 iters), loss = 1.47843
I1029 06:29:34.018579 12802 solver.cpp:241]     Train net output #0: loss = 1.47843 (* 1 = 1.47843 loss)
I1029 06:29:34.018595 12802 sgd_solver.cpp:105] Iteration 51120, lr = 0.000100402
I1029 06:29:39.971835 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 06:30:03.693262 12802 solver.cpp:222] Iteration 51160 (1.34798 iter/s, 29.674s/40 iters), loss = 1.54343
I1029 06:30:03.693315 12802 solver.cpp:241]     Train net output #0: loss = 1.54343 (* 1 = 1.54343 loss)
I1029 06:30:03.693328 12802 sgd_solver.cpp:105] Iteration 51160, lr = 0.000100041
I1029 06:30:33.699626 12802 solver.cpp:222] Iteration 51200 (1.33308 iter/s, 30.0056s/40 iters), loss = 1.27727
I1029 06:30:33.699810 12802 solver.cpp:241]     Train net output #0: loss = 1.27727 (* 1 = 1.27727 loss)
I1029 06:30:33.699826 12802 sgd_solver.cpp:105] Iteration 51200, lr = 9.96814e-05
I1029 06:31:03.265076 12802 solver.cpp:222] Iteration 51240 (1.35297 iter/s, 29.5646s/40 iters), loss = 1.34058
I1029 06:31:03.265127 12802 solver.cpp:241]     Train net output #0: loss = 1.34058 (* 1 = 1.34058 loss)
I1029 06:31:03.265142 12802 sgd_solver.cpp:105] Iteration 51240, lr = 9.93231e-05
I1029 06:31:32.944799 12802 solver.cpp:222] Iteration 51280 (1.34776 iter/s, 29.679s/40 iters), loss = 1.58499
I1029 06:31:32.945036 12802 solver.cpp:241]     Train net output #0: loss = 1.58499 (* 1 = 1.58499 loss)
I1029 06:31:32.945053 12802 sgd_solver.cpp:105] Iteration 51280, lr = 9.89662e-05
I1029 06:32:03.360731 12802 solver.cpp:222] Iteration 51320 (1.31514 iter/s, 30.415s/40 iters), loss = 1.18422
I1029 06:32:03.360999 12802 solver.cpp:241]     Train net output #0: loss = 1.18422 (* 1 = 1.18422 loss)
I1029 06:32:03.361014 12802 sgd_solver.cpp:105] Iteration 51320, lr = 9.86105e-05
I1029 06:32:32.922580 12802 solver.cpp:222] Iteration 51360 (1.35314 iter/s, 29.5609s/40 iters), loss = 1.43703
I1029 06:32:32.922631 12802 solver.cpp:241]     Train net output #0: loss = 1.43703 (* 1 = 1.43703 loss)
I1029 06:32:32.922646 12802 sgd_solver.cpp:105] Iteration 51360, lr = 9.82561e-05
I1029 06:33:02.463085 12802 solver.cpp:222] Iteration 51400 (1.35411 iter/s, 29.5397s/40 iters), loss = 1.33872
I1029 06:33:02.463249 12802 solver.cpp:241]     Train net output #0: loss = 1.33872 (* 1 = 1.33872 loss)
I1029 06:33:02.463266 12802 sgd_solver.cpp:105] Iteration 51400, lr = 9.7903e-05
I1029 06:33:31.960752 12802 solver.cpp:222] Iteration 51440 (1.35608 iter/s, 29.4968s/40 iters), loss = 1.51189
I1029 06:33:31.960813 12802 solver.cpp:241]     Train net output #0: loss = 1.51189 (* 1 = 1.51189 loss)
I1029 06:33:31.960826 12802 sgd_solver.cpp:105] Iteration 51440, lr = 9.75512e-05
I1029 06:34:01.513532 12802 solver.cpp:222] Iteration 51480 (1.35355 iter/s, 29.552s/40 iters), loss = 1.27524
I1029 06:34:01.513619 12802 solver.cpp:241]     Train net output #0: loss = 1.27524 (* 1 = 1.27524 loss)
I1029 06:34:01.513635 12802 sgd_solver.cpp:105] Iteration 51480, lr = 9.72006e-05
I1029 06:34:15.597585 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_51500.caffemodel
I1029 06:34:15.738963 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_51500.solverstate
I1029 06:34:15.850163 12802 solver.cpp:334] Iteration 51500, Testing net (#0)
I1029 06:34:46.811990 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 06:34:47.019088 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58384
I1029 06:34:47.019124 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81412
I1029 06:34:47.019135 12802 solver.cpp:401]     Test net output #2: loss = 1.83723 (* 1 = 1.83723 loss)
I1029 06:35:03.036048 12802 solver.cpp:222] Iteration 51520 (0.650185 iter/s, 61.521s/40 iters), loss = 1.39188
I1029 06:35:03.036105 12802 solver.cpp:241]     Train net output #0: loss = 1.39188 (* 1 = 1.39188 loss)
I1029 06:35:03.036120 12802 sgd_solver.cpp:105] Iteration 51520, lr = 9.68513e-05
I1029 06:35:32.666669 12802 solver.cpp:222] Iteration 51560 (1.34999 iter/s, 29.6298s/40 iters), loss = 1.30553
I1029 06:35:32.666869 12802 solver.cpp:241]     Train net output #0: loss = 1.30553 (* 1 = 1.30553 loss)
I1029 06:35:32.666887 12802 sgd_solver.cpp:105] Iteration 51560, lr = 9.65032e-05
I1029 06:36:02.091744 12802 solver.cpp:222] Iteration 51600 (1.35943 iter/s, 29.4242s/40 iters), loss = 1.29602
I1029 06:36:02.091799 12802 solver.cpp:241]     Train net output #0: loss = 1.29602 (* 1 = 1.29602 loss)
I1029 06:36:02.091814 12802 sgd_solver.cpp:105] Iteration 51600, lr = 9.61564e-05
I1029 06:36:31.523648 12802 solver.cpp:222] Iteration 51640 (1.3591 iter/s, 29.4311s/40 iters), loss = 1.69131
I1029 06:36:31.523731 12802 solver.cpp:241]     Train net output #0: loss = 1.69131 (* 1 = 1.69131 loss)
I1029 06:36:31.523747 12802 sgd_solver.cpp:105] Iteration 51640, lr = 9.58108e-05
I1029 06:37:00.977607 12802 solver.cpp:222] Iteration 51680 (1.35809 iter/s, 29.4532s/40 iters), loss = 1.44336
I1029 06:37:00.977669 12802 solver.cpp:241]     Train net output #0: loss = 1.44336 (* 1 = 1.44336 loss)
I1029 06:37:00.977682 12802 sgd_solver.cpp:105] Iteration 51680, lr = 9.54665e-05
I1029 06:37:30.425510 12802 solver.cpp:222] Iteration 51720 (1.35837 iter/s, 29.4471s/40 iters), loss = 1.36199
I1029 06:37:32.669462 12802 solver.cpp:241]     Train net output #0: loss = 1.36199 (* 1 = 1.36199 loss)
I1029 06:37:32.669513 12802 sgd_solver.cpp:105] Iteration 51720, lr = 9.51234e-05
I1029 06:38:02.030905 12802 solver.cpp:222] Iteration 51760 (1.36236 iter/s, 29.3608s/40 iters), loss = 1.59594
I1029 06:38:02.031075 12802 solver.cpp:241]     Train net output #0: loss = 1.59594 (* 1 = 1.59594 loss)
I1029 06:38:02.031095 12802 sgd_solver.cpp:105] Iteration 51760, lr = 9.47815e-05
I1029 06:38:31.380429 12802 solver.cpp:222] Iteration 51800 (1.36292 iter/s, 29.3486s/40 iters), loss = 1.40187
I1029 06:38:31.380486 12802 solver.cpp:241]     Train net output #0: loss = 1.40187 (* 1 = 1.40187 loss)
I1029 06:38:31.380501 12802 sgd_solver.cpp:105] Iteration 51800, lr = 9.44409e-05
I1029 06:39:00.893851 12802 solver.cpp:222] Iteration 51840 (1.35535 iter/s, 29.5127s/40 iters), loss = 1.37091
I1029 06:39:00.894011 12802 solver.cpp:241]     Train net output #0: loss = 1.37091 (* 1 = 1.37091 loss)
I1029 06:39:00.894027 12802 sgd_solver.cpp:105] Iteration 51840, lr = 9.41015e-05
I1029 06:39:57.651579 12802 solver.cpp:222] Iteration 51880 (0.704768 iter/s, 56.7562s/40 iters), loss = 1.4922
I1029 06:39:57.651775 12802 solver.cpp:241]     Train net output #0: loss = 1.4922 (* 1 = 1.4922 loss)
I1029 06:39:57.651793 12802 sgd_solver.cpp:105] Iteration 51880, lr = 9.37633e-05
I1029 06:40:28.121505 12802 solver.cpp:222] Iteration 51920 (1.31281 iter/s, 30.469s/40 iters), loss = 1.58413
I1029 06:40:28.121714 12802 solver.cpp:241]     Train net output #0: loss = 1.58413 (* 1 = 1.58413 loss)
I1029 06:40:28.121732 12802 sgd_solver.cpp:105] Iteration 51920, lr = 9.34264e-05
I1029 06:40:58.037688 12802 solver.cpp:222] Iteration 51960 (1.33711 iter/s, 29.9153s/40 iters), loss = 1.7408
I1029 06:40:58.037755 12802 solver.cpp:241]     Train net output #0: loss = 1.7408 (* 1 = 1.7408 loss)
I1029 06:40:58.037768 12802 sgd_solver.cpp:105] Iteration 51960, lr = 9.30906e-05
I1029 06:41:26.876690 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_52000.caffemodel
I1029 06:41:27.024133 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_52000.solverstate
I1029 06:41:27.137349 12802 solver.cpp:334] Iteration 52000, Testing net (#0)
I1029 06:41:58.345249 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58776
I1029 06:41:58.345387 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80984
I1029 06:41:58.345402 12802 solver.cpp:401]     Test net output #2: loss = 1.83303 (* 1 = 1.83303 loss)
I1029 06:41:59.114168 12802 solver.cpp:222] Iteration 52000 (0.654933 iter/s, 61.075s/40 iters), loss = 1.09874
I1029 06:41:59.114209 12802 solver.cpp:241]     Train net output #0: loss = 1.09874 (* 1 = 1.09874 loss)
I1029 06:41:59.114228 12802 sgd_solver.cpp:105] Iteration 52000, lr = 9.27561e-05
I1029 06:42:28.720387 12802 solver.cpp:222] Iteration 52040 (1.3511 iter/s, 29.6055s/40 iters), loss = 1.26453
I1029 06:42:28.720582 12802 solver.cpp:241]     Train net output #0: loss = 1.26453 (* 1 = 1.26453 loss)
I1029 06:42:28.720598 12802 sgd_solver.cpp:105] Iteration 52040, lr = 9.24227e-05
I1029 06:42:58.296857 12802 solver.cpp:222] Iteration 52080 (1.35247 iter/s, 29.5756s/40 iters), loss = 1.59954
I1029 06:42:58.296911 12802 solver.cpp:241]     Train net output #0: loss = 1.59954 (* 1 = 1.59954 loss)
I1029 06:42:58.296932 12802 sgd_solver.cpp:105] Iteration 52080, lr = 9.20906e-05
I1029 06:43:28.350870 12802 solver.cpp:222] Iteration 52120 (1.33097 iter/s, 30.0532s/40 iters), loss = 1.28761
I1029 06:43:28.351091 12802 solver.cpp:241]     Train net output #0: loss = 1.28761 (* 1 = 1.28761 loss)
I1029 06:43:28.351109 12802 sgd_solver.cpp:105] Iteration 52120, lr = 9.17596e-05
I1029 06:44:05.670791 12802 solver.cpp:222] Iteration 52160 (1.07185 iter/s, 37.3188s/40 iters), loss = 1.2052
I1029 06:44:05.670989 12802 solver.cpp:241]     Train net output #0: loss = 1.2052 (* 1 = 1.2052 loss)
I1029 06:44:05.671006 12802 sgd_solver.cpp:105] Iteration 52160, lr = 9.14298e-05
I1029 06:44:38.085157 12802 solver.cpp:222] Iteration 52200 (1.23406 iter/s, 32.4134s/40 iters), loss = 1.24966
I1029 06:44:38.085481 12802 solver.cpp:241]     Train net output #0: loss = 1.24966 (* 1 = 1.24966 loss)
I1029 06:44:38.085535 12802 sgd_solver.cpp:105] Iteration 52200, lr = 9.11013e-05
I1029 06:45:34.714625 12802 solver.cpp:222] Iteration 52240 (0.706366 iter/s, 56.6279s/40 iters), loss = 1.58384
I1029 06:45:34.714821 12802 solver.cpp:241]     Train net output #0: loss = 1.58384 (* 1 = 1.58384 loss)
I1029 06:45:34.714838 12802 sgd_solver.cpp:105] Iteration 52240, lr = 9.07739e-05
I1029 06:46:04.317071 12802 solver.cpp:222] Iteration 52280 (1.35128 iter/s, 29.6016s/40 iters), loss = 1.70397
I1029 06:46:04.317126 12802 solver.cpp:241]     Train net output #0: loss = 1.70397 (* 1 = 1.70397 loss)
I1029 06:46:04.317142 12802 sgd_solver.cpp:105] Iteration 52280, lr = 9.04476e-05
I1029 06:46:34.338096 12802 solver.cpp:222] Iteration 52320 (1.33243 iter/s, 30.0203s/40 iters), loss = 1.47984
I1029 06:46:34.338301 12802 solver.cpp:241]     Train net output #0: loss = 1.47984 (* 1 = 1.47984 loss)
I1029 06:46:34.338320 12802 sgd_solver.cpp:105] Iteration 52320, lr = 9.01226e-05
I1029 06:47:04.502004 12802 solver.cpp:222] Iteration 52360 (1.32613 iter/s, 30.163s/40 iters), loss = 1.22255
I1029 06:47:04.502156 12802 solver.cpp:241]     Train net output #0: loss = 1.22255 (* 1 = 1.22255 loss)
I1029 06:47:04.502172 12802 sgd_solver.cpp:105] Iteration 52360, lr = 8.97987e-05
I1029 06:47:40.815654 12802 solver.cpp:222] Iteration 52400 (1.10154 iter/s, 36.3126s/40 iters), loss = 1.39341
I1029 06:47:40.815843 12802 solver.cpp:241]     Train net output #0: loss = 1.39341 (* 1 = 1.39341 loss)
I1029 06:47:40.815862 12802 sgd_solver.cpp:105] Iteration 52400, lr = 8.9476e-05
I1029 06:48:22.198408 12802 solver.cpp:222] Iteration 52440 (0.966613 iter/s, 41.3816s/40 iters), loss = 1.13761
I1029 06:48:22.198632 12802 solver.cpp:241]     Train net output #0: loss = 1.13761 (* 1 = 1.13761 loss)
I1029 06:48:22.198655 12802 sgd_solver.cpp:105] Iteration 52440, lr = 8.91544e-05
I1029 06:48:51.726598 12802 solver.cpp:222] Iteration 52480 (1.35468 iter/s, 29.5273s/40 iters), loss = 1.36835
I1029 06:48:51.726652 12802 solver.cpp:241]     Train net output #0: loss = 1.36835 (* 1 = 1.36835 loss)
I1029 06:48:51.726667 12802 sgd_solver.cpp:105] Iteration 52480, lr = 8.8834e-05
I1029 06:49:05.756808 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_52500.caffemodel
I1029 06:49:05.898653 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_52500.solverstate
I1029 06:49:06.011132 12802 solver.cpp:334] Iteration 52500, Testing net (#0)
I1029 06:49:36.888182 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 06:49:37.095249 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58472
I1029 06:49:37.095301 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8144
I1029 06:49:37.095312 12802 solver.cpp:401]     Test net output #2: loss = 1.83822 (* 1 = 1.83822 loss)
I1029 06:49:53.098980 12802 solver.cpp:222] Iteration 52520 (0.651775 iter/s, 61.3709s/40 iters), loss = 1.49728
I1029 06:49:53.099045 12802 solver.cpp:241]     Train net output #0: loss = 1.49728 (* 1 = 1.49728 loss)
I1029 06:49:53.099064 12802 sgd_solver.cpp:105] Iteration 52520, lr = 8.85148e-05
I1029 06:50:22.625519 12802 solver.cpp:222] Iteration 52560 (1.35475 iter/s, 29.5258s/40 iters), loss = 1.36451
I1029 06:50:22.625704 12802 solver.cpp:241]     Train net output #0: loss = 1.36451 (* 1 = 1.36451 loss)
I1029 06:50:22.625720 12802 sgd_solver.cpp:105] Iteration 52560, lr = 8.81967e-05
I1029 06:50:52.231525 12802 solver.cpp:222] Iteration 52600 (1.35112 iter/s, 29.6051s/40 iters), loss = 1.44916
I1029 06:50:52.231578 12802 solver.cpp:241]     Train net output #0: loss = 1.44916 (* 1 = 1.44916 loss)
I1029 06:50:52.231593 12802 sgd_solver.cpp:105] Iteration 52600, lr = 8.78797e-05
I1029 06:51:21.665227 12802 solver.cpp:222] Iteration 52640 (1.35902 iter/s, 29.4329s/40 iters), loss = 1.35438
I1029 06:51:21.665452 12802 solver.cpp:241]     Train net output #0: loss = 1.35438 (* 1 = 1.35438 loss)
I1029 06:51:21.665468 12802 sgd_solver.cpp:105] Iteration 52640, lr = 8.75639e-05
I1029 06:51:51.175192 12802 solver.cpp:222] Iteration 52680 (1.35552 iter/s, 29.509s/40 iters), loss = 1.48194
I1029 06:51:51.175241 12802 solver.cpp:241]     Train net output #0: loss = 1.48194 (* 1 = 1.48194 loss)
I1029 06:51:51.175256 12802 sgd_solver.cpp:105] Iteration 52680, lr = 8.72492e-05
I1029 06:52:20.669148 12802 solver.cpp:222] Iteration 52720 (1.35624 iter/s, 29.4932s/40 iters), loss = 1.26432
I1029 06:52:20.669335 12802 solver.cpp:241]     Train net output #0: loss = 1.26432 (* 1 = 1.26432 loss)
I1029 06:52:20.669353 12802 sgd_solver.cpp:105] Iteration 52720, lr = 8.69356e-05
I1029 06:52:50.186144 12802 solver.cpp:222] Iteration 52760 (1.35519 iter/s, 29.5161s/40 iters), loss = 1.38083
I1029 06:52:50.186192 12802 solver.cpp:241]     Train net output #0: loss = 1.38083 (* 1 = 1.38083 loss)
I1029 06:52:50.186206 12802 sgd_solver.cpp:105] Iteration 52760, lr = 8.66232e-05
I1029 06:53:19.725862 12802 solver.cpp:222] Iteration 52800 (1.35414 iter/s, 29.539s/40 iters), loss = 1.54742
I1029 06:53:19.726044 12802 solver.cpp:241]     Train net output #0: loss = 1.54742 (* 1 = 1.54742 loss)
I1029 06:53:19.726061 12802 sgd_solver.cpp:105] Iteration 52800, lr = 8.63119e-05
I1029 06:53:49.243938 12802 solver.cpp:222] Iteration 52840 (1.35514 iter/s, 29.5172s/40 iters), loss = 1.31652
I1029 06:53:49.243988 12802 solver.cpp:241]     Train net output #0: loss = 1.31652 (* 1 = 1.31652 loss)
I1029 06:53:49.244004 12802 sgd_solver.cpp:105] Iteration 52840, lr = 8.60017e-05
I1029 06:54:18.793834 12802 solver.cpp:222] Iteration 52880 (1.35368 iter/s, 29.5491s/40 iters), loss = 1.34767
I1029 06:54:18.794051 12802 solver.cpp:241]     Train net output #0: loss = 1.34767 (* 1 = 1.34767 loss)
I1029 06:54:18.794070 12802 sgd_solver.cpp:105] Iteration 52880, lr = 8.56926e-05
I1029 06:54:48.819344 12802 solver.cpp:222] Iteration 52920 (1.33224 iter/s, 30.0246s/40 iters), loss = 1.31421
I1029 06:54:48.819500 12802 solver.cpp:241]     Train net output #0: loss = 1.31421 (* 1 = 1.31421 loss)
I1029 06:54:48.819517 12802 sgd_solver.cpp:105] Iteration 52920, lr = 8.53847e-05
I1029 06:55:20.015733 12802 solver.cpp:222] Iteration 52960 (1.28224 iter/s, 31.1955s/40 iters), loss = 1.23273
I1029 06:55:20.015898 12802 solver.cpp:241]     Train net output #0: loss = 1.23273 (* 1 = 1.23273 loss)
I1029 06:55:20.015915 12802 sgd_solver.cpp:105] Iteration 52960, lr = 8.50778e-05
I1029 06:55:49.402333 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_53000.caffemodel
I1029 06:55:49.547024 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_53000.solverstate
I1029 06:55:49.660564 12802 solver.cpp:334] Iteration 53000, Testing net (#0)
I1029 06:56:20.798682 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58872
I1029 06:56:20.798848 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.809599
I1029 06:56:20.798861 12802 solver.cpp:401]     Test net output #2: loss = 1.82781 (* 1 = 1.82781 loss)
I1029 06:56:21.551890 12802 solver.cpp:222] Iteration 53000 (0.650041 iter/s, 61.5345s/40 iters), loss = 1.23366
I1029 06:56:21.551959 12802 solver.cpp:241]     Train net output #0: loss = 1.23366 (* 1 = 1.23366 loss)
I1029 06:56:21.551975 12802 sgd_solver.cpp:105] Iteration 53000, lr = 8.47721e-05
I1029 06:56:51.146144 12802 solver.cpp:222] Iteration 53040 (1.35165 iter/s, 29.5935s/40 iters), loss = 1.38129
I1029 06:56:51.146304 12802 solver.cpp:241]     Train net output #0: loss = 1.38129 (* 1 = 1.38129 loss)
I1029 06:56:51.146322 12802 sgd_solver.cpp:105] Iteration 53040, lr = 8.44674e-05
I1029 06:57:20.730864 12802 solver.cpp:222] Iteration 53080 (1.35209 iter/s, 29.5839s/40 iters), loss = 1.63421
I1029 06:57:20.730927 12802 solver.cpp:241]     Train net output #0: loss = 1.63421 (* 1 = 1.63421 loss)
I1029 06:57:20.730943 12802 sgd_solver.cpp:105] Iteration 53080, lr = 8.41638e-05
I1029 06:57:50.553848 12802 solver.cpp:222] Iteration 53120 (1.34128 iter/s, 29.8222s/40 iters), loss = 1.37822
I1029 06:57:50.554111 12802 solver.cpp:241]     Train net output #0: loss = 1.37822 (* 1 = 1.37822 loss)
I1029 06:57:50.554131 12802 sgd_solver.cpp:105] Iteration 53120, lr = 8.38614e-05
I1029 06:58:20.286974 12802 solver.cpp:222] Iteration 53160 (1.34534 iter/s, 29.7322s/40 iters), loss = 1.43624
I1029 06:58:20.287035 12802 solver.cpp:241]     Train net output #0: loss = 1.43624 (* 1 = 1.43624 loss)
I1029 06:58:20.287051 12802 sgd_solver.cpp:105] Iteration 53160, lr = 8.356e-05
I1029 06:58:50.246351 12802 solver.cpp:222] Iteration 53200 (1.33518 iter/s, 29.9586s/40 iters), loss = 1.38042
I1029 06:58:50.246517 12802 solver.cpp:241]     Train net output #0: loss = 1.38042 (* 1 = 1.38042 loss)
I1029 06:58:50.246532 12802 sgd_solver.cpp:105] Iteration 53200, lr = 8.32597e-05
I1029 06:59:19.958307 12802 solver.cpp:222] Iteration 53240 (1.3463 iter/s, 29.7111s/40 iters), loss = 1.33352
I1029 06:59:19.958366 12802 solver.cpp:241]     Train net output #0: loss = 1.33352 (* 1 = 1.33352 loss)
I1029 06:59:19.958380 12802 sgd_solver.cpp:105] Iteration 53240, lr = 8.29605e-05
I1029 06:59:50.250087 12802 solver.cpp:222] Iteration 53280 (1.32052 iter/s, 30.291s/40 iters), loss = 1.37573
I1029 06:59:50.250279 12802 solver.cpp:241]     Train net output #0: loss = 1.37573 (* 1 = 1.37573 loss)
I1029 06:59:50.250298 12802 sgd_solver.cpp:105] Iteration 53280, lr = 8.26623e-05
I1029 07:00:20.492808 12802 solver.cpp:222] Iteration 53320 (1.32267 iter/s, 30.2418s/40 iters), loss = 0.981708
I1029 07:00:20.493016 12802 solver.cpp:241]     Train net output #0: loss = 0.981708 (* 1 = 0.981708 loss)
I1029 07:00:20.493032 12802 sgd_solver.cpp:105] Iteration 53320, lr = 8.23653e-05
I1029 07:01:15.495645 12802 solver.cpp:222] Iteration 53360 (0.727255 iter/s, 55.0013s/40 iters), loss = 1.16796
I1029 07:01:15.495844 12802 solver.cpp:241]     Train net output #0: loss = 1.16796 (* 1 = 1.16796 loss)
I1029 07:01:15.495862 12802 sgd_solver.cpp:105] Iteration 53360, lr = 8.20693e-05
I1029 07:01:45.820571 12802 solver.cpp:222] Iteration 53400 (1.31909 iter/s, 30.324s/40 iters), loss = 1.38873
I1029 07:01:45.820755 12802 solver.cpp:241]     Train net output #0: loss = 1.38873 (* 1 = 1.38873 loss)
I1029 07:01:45.820771 12802 sgd_solver.cpp:105] Iteration 53400, lr = 8.17743e-05
I1029 07:02:15.300736 12802 solver.cpp:222] Iteration 53440 (1.35689 iter/s, 29.4793s/40 iters), loss = 1.4763
I1029 07:02:15.300799 12802 solver.cpp:241]     Train net output #0: loss = 1.4763 (* 1 = 1.4763 loss)
I1029 07:02:15.300812 12802 sgd_solver.cpp:105] Iteration 53440, lr = 8.14804e-05
I1029 07:02:44.747973 12802 solver.cpp:222] Iteration 53480 (1.3584 iter/s, 29.4465s/40 iters), loss = 1.43075
I1029 07:02:44.748066 12802 solver.cpp:241]     Train net output #0: loss = 1.43075 (* 1 = 1.43075 loss)
I1029 07:02:44.748082 12802 sgd_solver.cpp:105] Iteration 53480, lr = 8.11876e-05
I1029 07:02:58.743201 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_53500.caffemodel
I1029 07:02:58.886193 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_53500.solverstate
I1029 07:02:59.000526 12802 solver.cpp:334] Iteration 53500, Testing net (#0)
I1029 07:03:29.999505 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 07:03:30.207603 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58516
I1029 07:03:30.207656 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.814839
I1029 07:03:30.207666 12802 solver.cpp:401]     Test net output #2: loss = 1.83267 (* 1 = 1.83267 loss)
I1029 07:03:45.804457 12802 solver.cpp:222] Iteration 53520 (0.655147 iter/s, 61.055s/40 iters), loss = 1.23248
I1029 07:03:45.804519 12802 solver.cpp:241]     Train net output #0: loss = 1.23248 (* 1 = 1.23248 loss)
I1029 07:03:45.804534 12802 sgd_solver.cpp:105] Iteration 53520, lr = 8.08958e-05
I1029 07:04:15.355501 12802 solver.cpp:222] Iteration 53560 (1.35363 iter/s, 29.5503s/40 iters), loss = 1.7152
I1029 07:04:15.355643 12802 solver.cpp:241]     Train net output #0: loss = 1.7152 (* 1 = 1.7152 loss)
I1029 07:04:15.355660 12802 sgd_solver.cpp:105] Iteration 53560, lr = 8.06051e-05
I1029 07:04:44.922369 12802 solver.cpp:222] Iteration 53600 (1.3529 iter/s, 29.566s/40 iters), loss = 1.52821
I1029 07:04:44.922433 12802 solver.cpp:241]     Train net output #0: loss = 1.52821 (* 1 = 1.52821 loss)
I1029 07:04:44.922449 12802 sgd_solver.cpp:105] Iteration 53600, lr = 8.03154e-05
I1029 07:05:07.105188 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 07:05:14.392340 12802 solver.cpp:222] Iteration 53640 (1.35735 iter/s, 29.4692s/40 iters), loss = 1.15464
I1029 07:05:14.392401 12802 solver.cpp:241]     Train net output #0: loss = 1.15464 (* 1 = 1.15464 loss)
I1029 07:05:14.392418 12802 sgd_solver.cpp:105] Iteration 53640, lr = 8.00268e-05
I1029 07:05:43.839093 12802 solver.cpp:222] Iteration 53680 (1.35842 iter/s, 29.446s/40 iters), loss = 1.53149
I1029 07:05:43.839265 12802 solver.cpp:241]     Train net output #0: loss = 1.53149 (* 1 = 1.53149 loss)
I1029 07:05:43.839282 12802 sgd_solver.cpp:105] Iteration 53680, lr = 7.97392e-05
I1029 07:06:13.494573 12802 solver.cpp:222] Iteration 53720 (1.34886 iter/s, 29.6546s/40 iters), loss = 1.22449
I1029 07:06:13.494634 12802 solver.cpp:241]     Train net output #0: loss = 1.22449 (* 1 = 1.22449 loss)
I1029 07:06:13.494649 12802 sgd_solver.cpp:105] Iteration 53720, lr = 7.94526e-05
I1029 07:06:43.235515 12802 solver.cpp:222] Iteration 53760 (1.34498 iter/s, 29.7402s/40 iters), loss = 1.52163
I1029 07:06:43.235697 12802 solver.cpp:241]     Train net output #0: loss = 1.52163 (* 1 = 1.52163 loss)
I1029 07:06:43.235714 12802 sgd_solver.cpp:105] Iteration 53760, lr = 7.91671e-05
I1029 07:07:12.904304 12802 solver.cpp:222] Iteration 53800 (1.34826 iter/s, 29.6679s/40 iters), loss = 1.31455
I1029 07:07:12.904372 12802 solver.cpp:241]     Train net output #0: loss = 1.31455 (* 1 = 1.31455 loss)
I1029 07:07:12.904386 12802 sgd_solver.cpp:105] Iteration 53800, lr = 7.88826e-05
I1029 07:07:42.531275 12802 solver.cpp:222] Iteration 53840 (1.35016 iter/s, 29.6262s/40 iters), loss = 1.2895
I1029 07:07:42.531451 12802 solver.cpp:241]     Train net output #0: loss = 1.2895 (* 1 = 1.2895 loss)
I1029 07:07:42.531468 12802 sgd_solver.cpp:105] Iteration 53840, lr = 7.85991e-05
I1029 07:08:12.169862 12802 solver.cpp:222] Iteration 53880 (1.34963 iter/s, 29.6377s/40 iters), loss = 1.1682
I1029 07:08:12.169929 12802 solver.cpp:241]     Train net output #0: loss = 1.1682 (* 1 = 1.1682 loss)
I1029 07:08:12.169946 12802 sgd_solver.cpp:105] Iteration 53880, lr = 7.83166e-05
I1029 07:08:41.763754 12802 solver.cpp:222] Iteration 53920 (1.35167 iter/s, 29.5931s/40 iters), loss = 1.47319
I1029 07:08:41.763902 12802 solver.cpp:241]     Train net output #0: loss = 1.47319 (* 1 = 1.47319 loss)
I1029 07:08:41.763924 12802 sgd_solver.cpp:105] Iteration 53920, lr = 7.80352e-05
I1029 07:09:11.283336 12802 solver.cpp:222] Iteration 53960 (1.35507 iter/s, 29.5187s/40 iters), loss = 1.69346
I1029 07:09:11.283401 12802 solver.cpp:241]     Train net output #0: loss = 1.69346 (* 1 = 1.69346 loss)
I1029 07:09:11.283417 12802 sgd_solver.cpp:105] Iteration 53960, lr = 7.77547e-05
I1029 07:09:40.030587 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_54000.caffemodel
I1029 07:09:40.176697 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_54000.solverstate
I1029 07:09:40.289798 12802 solver.cpp:334] Iteration 54000, Testing net (#0)
I1029 07:10:11.521965 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58856
I1029 07:10:11.522147 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80936
I1029 07:10:11.522161 12802 solver.cpp:401]     Test net output #2: loss = 1.83412 (* 1 = 1.83412 loss)
I1029 07:10:12.280939 12802 solver.cpp:222] Iteration 54000 (0.655779 iter/s, 60.9961s/40 iters), loss = 1.28437
I1029 07:10:12.280999 12802 solver.cpp:241]     Train net output #0: loss = 1.28437 (* 1 = 1.28437 loss)
I1029 07:10:12.281015 12802 sgd_solver.cpp:105] Iteration 54000, lr = 7.74753e-05
I1029 07:10:41.799379 12802 solver.cpp:222] Iteration 54040 (1.35512 iter/s, 29.5177s/40 iters), loss = 1.10552
I1029 07:10:41.799587 12802 solver.cpp:241]     Train net output #0: loss = 1.10552 (* 1 = 1.10552 loss)
I1029 07:10:41.799605 12802 sgd_solver.cpp:105] Iteration 54040, lr = 7.71968e-05
I1029 07:11:11.624971 12802 solver.cpp:222] Iteration 54080 (1.34117 iter/s, 29.8247s/40 iters), loss = 1.5227
I1029 07:11:11.625030 12802 solver.cpp:241]     Train net output #0: loss = 1.5227 (* 1 = 1.5227 loss)
I1029 07:11:11.625044 12802 sgd_solver.cpp:105] Iteration 54080, lr = 7.69194e-05
I1029 07:11:42.479310 12802 solver.cpp:222] Iteration 54120 (1.29645 iter/s, 30.8535s/40 iters), loss = 1.55952
I1029 07:11:42.479498 12802 solver.cpp:241]     Train net output #0: loss = 1.55952 (* 1 = 1.55952 loss)
I1029 07:11:42.479516 12802 sgd_solver.cpp:105] Iteration 54120, lr = 7.6643e-05
I1029 07:12:12.547730 12802 solver.cpp:222] Iteration 54160 (1.33034 iter/s, 30.0675s/40 iters), loss = 1.22457
I1029 07:12:12.547868 12802 solver.cpp:241]     Train net output #0: loss = 1.22457 (* 1 = 1.22457 loss)
I1029 07:12:12.547886 12802 sgd_solver.cpp:105] Iteration 54160, lr = 7.63675e-05
I1029 07:12:44.569869 12802 solver.cpp:222] Iteration 54200 (1.24917 iter/s, 32.0212s/40 iters), loss = 1.36732
I1029 07:12:44.570065 12802 solver.cpp:241]     Train net output #0: loss = 1.36732 (* 1 = 1.36732 loss)
I1029 07:12:44.570082 12802 sgd_solver.cpp:105] Iteration 54200, lr = 7.60931e-05
I1029 07:13:19.611096 12802 solver.cpp:222] Iteration 54240 (1.14155 iter/s, 35.0402s/40 iters), loss = 1.42605
I1029 07:13:19.611304 12802 solver.cpp:241]     Train net output #0: loss = 1.42605 (* 1 = 1.42605 loss)
I1029 07:13:19.611322 12802 sgd_solver.cpp:105] Iteration 54240, lr = 7.58196e-05
I1029 07:14:00.241075 12802 solver.cpp:222] Iteration 54280 (0.984522 iter/s, 40.6288s/40 iters), loss = 1.35094
I1029 07:14:00.241261 12802 solver.cpp:241]     Train net output #0: loss = 1.35094 (* 1 = 1.35094 loss)
I1029 07:14:00.241278 12802 sgd_solver.cpp:105] Iteration 54280, lr = 7.55471e-05
I1029 07:14:30.746385 12802 solver.cpp:222] Iteration 54320 (1.31129 iter/s, 30.5044s/40 iters), loss = 1.54964
I1029 07:14:30.746563 12802 solver.cpp:241]     Train net output #0: loss = 1.54964 (* 1 = 1.54964 loss)
I1029 07:14:30.746582 12802 sgd_solver.cpp:105] Iteration 54320, lr = 7.52756e-05
I1029 07:16:04.356355 12802 solver.cpp:222] Iteration 54360 (0.427315 iter/s, 93.6077s/40 iters), loss = 1.58793
I1029 07:16:04.356518 12802 solver.cpp:241]     Train net output #0: loss = 1.58793 (* 1 = 1.58793 loss)
I1029 07:16:04.356534 12802 sgd_solver.cpp:105] Iteration 54360, lr = 7.50051e-05
I1029 07:16:34.392873 12802 solver.cpp:222] Iteration 54400 (1.33175 iter/s, 30.0357s/40 iters), loss = 1.48326
I1029 07:16:34.393028 12802 solver.cpp:241]     Train net output #0: loss = 1.48326 (* 1 = 1.48326 loss)
I1029 07:16:34.393045 12802 sgd_solver.cpp:105] Iteration 54400, lr = 7.47356e-05
I1029 07:17:04.138751 12802 solver.cpp:222] Iteration 54440 (1.34476 iter/s, 29.7451s/40 iters), loss = 1.20385
I1029 07:17:04.138809 12802 solver.cpp:241]     Train net output #0: loss = 1.20385 (* 1 = 1.20385 loss)
I1029 07:17:04.138824 12802 sgd_solver.cpp:105] Iteration 54440, lr = 7.4467e-05
I1029 07:17:34.872862 12802 solver.cpp:222] Iteration 54480 (1.30152 iter/s, 30.7333s/40 iters), loss = 1.20469
I1029 07:17:34.873039 12802 solver.cpp:241]     Train net output #0: loss = 1.20469 (* 1 = 1.20469 loss)
I1029 07:17:34.873056 12802 sgd_solver.cpp:105] Iteration 54480, lr = 7.41994e-05
I1029 07:17:49.527024 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_54500.caffemodel
I1029 07:17:49.674516 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_54500.solverstate
I1029 07:17:49.798701 12802 solver.cpp:334] Iteration 54500, Testing net (#0)
I1029 07:18:20.644547 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 07:18:20.851408 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58524
I1029 07:18:20.851462 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8152
I1029 07:18:20.851474 12802 solver.cpp:401]     Test net output #2: loss = 1.83634 (* 1 = 1.83634 loss)
I1029 07:18:36.871541 12802 solver.cpp:222] Iteration 54520 (0.645192 iter/s, 61.9971s/40 iters), loss = 1.40968
I1029 07:18:36.871603 12802 solver.cpp:241]     Train net output #0: loss = 1.40968 (* 1 = 1.40968 loss)
I1029 07:18:36.871619 12802 sgd_solver.cpp:105] Iteration 54520, lr = 7.39327e-05
I1029 07:19:07.355278 12802 solver.cpp:222] Iteration 54560 (1.31221 iter/s, 30.483s/40 iters), loss = 1.13489
I1029 07:19:07.355499 12802 solver.cpp:241]     Train net output #0: loss = 1.13489 (* 1 = 1.13489 loss)
I1029 07:19:07.355515 12802 sgd_solver.cpp:105] Iteration 54560, lr = 7.3667e-05
I1029 07:19:37.507896 12802 solver.cpp:222] Iteration 54600 (1.32663 iter/s, 30.1517s/40 iters), loss = 1.56204
I1029 07:19:37.508018 12802 solver.cpp:241]     Train net output #0: loss = 1.56204 (* 1 = 1.56204 loss)
I1029 07:19:37.508033 12802 sgd_solver.cpp:105] Iteration 54600, lr = 7.34023e-05
I1029 07:20:07.175462 12802 solver.cpp:222] Iteration 54640 (1.34831 iter/s, 29.6667s/40 iters), loss = 1.23506
I1029 07:20:07.175520 12802 solver.cpp:241]     Train net output #0: loss = 1.23506 (* 1 = 1.23506 loss)
I1029 07:20:07.175535 12802 sgd_solver.cpp:105] Iteration 54640, lr = 7.31385e-05
I1029 07:20:36.876116 12802 solver.cpp:222] Iteration 54680 (1.34681 iter/s, 29.6999s/40 iters), loss = 1.34508
I1029 07:20:36.876296 12802 solver.cpp:241]     Train net output #0: loss = 1.34508 (* 1 = 1.34508 loss)
I1029 07:20:36.876312 12802 sgd_solver.cpp:105] Iteration 54680, lr = 7.28756e-05
I1029 07:21:06.743707 12802 solver.cpp:222] Iteration 54720 (1.33928 iter/s, 29.8667s/40 iters), loss = 1.12015
I1029 07:21:06.743772 12802 solver.cpp:241]     Train net output #0: loss = 1.12015 (* 1 = 1.12015 loss)
I1029 07:21:06.743785 12802 sgd_solver.cpp:105] Iteration 54720, lr = 7.26137e-05
I1029 07:21:36.692761 12802 solver.cpp:222] Iteration 54760 (1.33564 iter/s, 29.9483s/40 iters), loss = 1.52304
I1029 07:21:36.693199 12802 solver.cpp:241]     Train net output #0: loss = 1.52304 (* 1 = 1.52304 loss)
I1029 07:21:36.693213 12802 sgd_solver.cpp:105] Iteration 54760, lr = 7.23528e-05
I1029 07:22:06.251372 12802 solver.cpp:222] Iteration 54800 (1.3533 iter/s, 29.5575s/40 iters), loss = 1.60372
I1029 07:22:06.251432 12802 solver.cpp:241]     Train net output #0: loss = 1.60372 (* 1 = 1.60372 loss)
I1029 07:22:06.251447 12802 sgd_solver.cpp:105] Iteration 54800, lr = 7.20927e-05
I1029 07:22:35.716168 12802 solver.cpp:222] Iteration 54840 (1.35759 iter/s, 29.464s/40 iters), loss = 1.14468
I1029 07:22:35.716310 12802 solver.cpp:241]     Train net output #0: loss = 1.14468 (* 1 = 1.14468 loss)
I1029 07:22:35.716327 12802 sgd_solver.cpp:105] Iteration 54840, lr = 7.18336e-05
I1029 07:23:05.155683 12802 solver.cpp:222] Iteration 54880 (1.35876 iter/s, 29.4387s/40 iters), loss = 1.52915
I1029 07:23:05.155741 12802 solver.cpp:241]     Train net output #0: loss = 1.52915 (* 1 = 1.52915 loss)
I1029 07:23:05.155755 12802 sgd_solver.cpp:105] Iteration 54880, lr = 7.15755e-05
I1029 07:23:34.632333 12802 solver.cpp:222] Iteration 54920 (1.35704 iter/s, 29.4759s/40 iters), loss = 1.24153
I1029 07:23:34.632429 12802 solver.cpp:241]     Train net output #0: loss = 1.24153 (* 1 = 1.24153 loss)
I1029 07:23:34.632446 12802 sgd_solver.cpp:105] Iteration 54920, lr = 7.13183e-05
I1029 07:24:04.114320 12802 solver.cpp:222] Iteration 54960 (1.3568 iter/s, 29.4812s/40 iters), loss = 1.5562
I1029 07:24:04.114375 12802 solver.cpp:241]     Train net output #0: loss = 1.5562 (* 1 = 1.5562 loss)
I1029 07:24:04.114390 12802 sgd_solver.cpp:105] Iteration 54960, lr = 7.1062e-05
I1029 07:24:33.110663 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_55000.caffemodel
I1029 07:24:33.253970 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_55000.solverstate
I1029 07:24:33.380147 12802 solver.cpp:334] Iteration 55000, Testing net (#0)
I1029 07:25:04.461616 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58892
I1029 07:25:04.461767 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.810399
I1029 07:25:04.461781 12802 solver.cpp:401]     Test net output #2: loss = 1.83216 (* 1 = 1.83216 loss)
I1029 07:25:05.220432 12802 solver.cpp:222] Iteration 55000 (0.654615 iter/s, 61.1046s/40 iters), loss = 1.34475
I1029 07:25:05.220489 12802 solver.cpp:241]     Train net output #0: loss = 1.34475 (* 1 = 1.34475 loss)
I1029 07:25:05.220505 12802 sgd_solver.cpp:105] Iteration 55000, lr = 7.08066e-05
I1029 07:25:34.856238 12802 solver.cpp:222] Iteration 55040 (1.34975 iter/s, 29.635s/40 iters), loss = 1.59496
I1029 07:25:34.856415 12802 solver.cpp:241]     Train net output #0: loss = 1.59496 (* 1 = 1.59496 loss)
I1029 07:25:34.856432 12802 sgd_solver.cpp:105] Iteration 55040, lr = 7.05521e-05
I1029 07:26:04.385079 12802 solver.cpp:222] Iteration 55080 (1.35465 iter/s, 29.528s/40 iters), loss = 1.22994
I1029 07:26:04.385135 12802 solver.cpp:241]     Train net output #0: loss = 1.22994 (* 1 = 1.22994 loss)
I1029 07:26:04.385152 12802 sgd_solver.cpp:105] Iteration 55080, lr = 7.02986e-05
I1029 07:26:34.110993 12802 solver.cpp:222] Iteration 55120 (1.34566 iter/s, 29.7251s/40 iters), loss = 1.12999
I1029 07:26:34.111173 12802 solver.cpp:241]     Train net output #0: loss = 1.12999 (* 1 = 1.12999 loss)
I1029 07:26:34.111191 12802 sgd_solver.cpp:105] Iteration 55120, lr = 7.00459e-05
I1029 07:27:04.432154 12802 solver.cpp:222] Iteration 55160 (1.31925 iter/s, 30.3203s/40 iters), loss = 1.48769
I1029 07:27:04.432354 12802 solver.cpp:241]     Train net output #0: loss = 1.48769 (* 1 = 1.48769 loss)
I1029 07:27:04.432371 12802 sgd_solver.cpp:105] Iteration 55160, lr = 6.97942e-05
I1029 07:27:35.021885 12802 solver.cpp:222] Iteration 55200 (1.30767 iter/s, 30.5888s/40 iters), loss = 1.36851
I1029 07:27:35.022088 12802 solver.cpp:241]     Train net output #0: loss = 1.36851 (* 1 = 1.36851 loss)
I1029 07:27:35.022105 12802 sgd_solver.cpp:105] Iteration 55200, lr = 6.95434e-05
I1029 07:28:05.623006 12802 solver.cpp:222] Iteration 55240 (1.30718 iter/s, 30.6002s/40 iters), loss = 1.42385
I1029 07:28:05.623173 12802 solver.cpp:241]     Train net output #0: loss = 1.42385 (* 1 = 1.42385 loss)
I1029 07:28:05.623190 12802 sgd_solver.cpp:105] Iteration 55240, lr = 6.92934e-05
I1029 07:28:36.303925 12802 solver.cpp:222] Iteration 55280 (1.30378 iter/s, 30.68s/40 iters), loss = 1.39337
I1029 07:28:36.304080 12802 solver.cpp:241]     Train net output #0: loss = 1.39337 (* 1 = 1.39337 loss)
I1029 07:28:36.304097 12802 sgd_solver.cpp:105] Iteration 55280, lr = 6.90444e-05
I1029 07:29:06.978513 12802 solver.cpp:222] Iteration 55320 (1.30405 iter/s, 30.6737s/40 iters), loss = 1.41953
I1029 07:29:06.978709 12802 solver.cpp:241]     Train net output #0: loss = 1.41953 (* 1 = 1.41953 loss)
I1029 07:29:06.978726 12802 sgd_solver.cpp:105] Iteration 55320, lr = 6.87963e-05
I1029 07:29:37.382035 12802 solver.cpp:222] Iteration 55360 (1.31568 iter/s, 30.4026s/40 iters), loss = 1.17352
I1029 07:29:37.382200 12802 solver.cpp:241]     Train net output #0: loss = 1.17352 (* 1 = 1.17352 loss)
I1029 07:29:37.382217 12802 sgd_solver.cpp:105] Iteration 55360, lr = 6.8549e-05
I1029 07:30:08.491757 12802 solver.cpp:222] Iteration 55400 (1.28581 iter/s, 31.1088s/40 iters), loss = 1.48001
I1029 07:30:08.492018 12802 solver.cpp:241]     Train net output #0: loss = 1.48001 (* 1 = 1.48001 loss)
I1029 07:30:08.492035 12802 sgd_solver.cpp:105] Iteration 55400, lr = 6.83027e-05
I1029 07:30:38.256867 12802 solver.cpp:222] Iteration 55440 (1.3439 iter/s, 29.7642s/40 iters), loss = 1.4464
I1029 07:30:38.256930 12802 solver.cpp:241]     Train net output #0: loss = 1.4464 (* 1 = 1.4464 loss)
I1029 07:30:38.256947 12802 sgd_solver.cpp:105] Iteration 55440, lr = 6.80572e-05
I1029 07:31:07.783912 12802 solver.cpp:222] Iteration 55480 (1.35472 iter/s, 29.5263s/40 iters), loss = 1.66473
I1029 07:31:07.784148 12802 solver.cpp:241]     Train net output #0: loss = 1.66473 (* 1 = 1.66473 loss)
I1029 07:31:07.784166 12802 sgd_solver.cpp:105] Iteration 55480, lr = 6.78126e-05
I1029 07:31:21.836890 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_55500.caffemodel
I1029 07:31:21.978318 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_55500.solverstate
I1029 07:31:22.105772 12802 solver.cpp:334] Iteration 55500, Testing net (#0)
I1029 07:31:53.065927 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 07:31:53.274020 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58452
I1029 07:31:53.274071 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81576
I1029 07:31:53.274082 12802 solver.cpp:401]     Test net output #2: loss = 1.82998 (* 1 = 1.82998 loss)
I1029 07:32:09.429325 12802 solver.cpp:222] Iteration 55520 (0.64889 iter/s, 61.6437s/40 iters), loss = 1.17247
I1029 07:32:09.429389 12802 solver.cpp:241]     Train net output #0: loss = 1.17247 (* 1 = 1.17247 loss)
I1029 07:32:09.429404 12802 sgd_solver.cpp:105] Iteration 55520, lr = 6.75689e-05
I1029 07:32:39.291045 12802 solver.cpp:222] Iteration 55560 (1.33954 iter/s, 29.8609s/40 iters), loss = 1.46294
I1029 07:32:39.291219 12802 solver.cpp:241]     Train net output #0: loss = 1.46294 (* 1 = 1.46294 loss)
I1029 07:32:39.291235 12802 sgd_solver.cpp:105] Iteration 55560, lr = 6.73261e-05
I1029 07:33:08.889209 12802 solver.cpp:222] Iteration 55600 (1.35148 iter/s, 29.5973s/40 iters), loss = 1.22077
I1029 07:33:08.889267 12802 solver.cpp:241]     Train net output #0: loss = 1.22077 (* 1 = 1.22077 loss)
I1029 07:33:08.889288 12802 sgd_solver.cpp:105] Iteration 55600, lr = 6.70841e-05
I1029 07:33:38.537446 12802 solver.cpp:222] Iteration 55640 (1.34919 iter/s, 29.6475s/40 iters), loss = 1.65229
I1029 07:33:38.537605 12802 solver.cpp:241]     Train net output #0: loss = 1.65229 (* 1 = 1.65229 loss)
I1029 07:33:38.537621 12802 sgd_solver.cpp:105] Iteration 55640, lr = 6.68431e-05
I1029 07:34:08.347160 12802 solver.cpp:222] Iteration 55680 (1.34188 iter/s, 29.8088s/40 iters), loss = 1.18631
I1029 07:34:08.347218 12802 solver.cpp:241]     Train net output #0: loss = 1.18631 (* 1 = 1.18631 loss)
I1029 07:34:08.347232 12802 sgd_solver.cpp:105] Iteration 55680, lr = 6.66028e-05
I1029 07:34:38.281626 12802 solver.cpp:222] Iteration 55720 (1.33629 iter/s, 29.9337s/40 iters), loss = 1.61626
I1029 07:34:38.281805 12802 solver.cpp:241]     Train net output #0: loss = 1.61626 (* 1 = 1.61626 loss)
I1029 07:34:38.281822 12802 sgd_solver.cpp:105] Iteration 55720, lr = 6.63635e-05
I1029 07:35:08.392524 12802 solver.cpp:222] Iteration 55760 (1.32846 iter/s, 30.11s/40 iters), loss = 1.35971
I1029 07:35:08.392660 12802 solver.cpp:241]     Train net output #0: loss = 1.35971 (* 1 = 1.35971 loss)
I1029 07:35:08.392678 12802 sgd_solver.cpp:105] Iteration 55760, lr = 6.6125e-05
I1029 07:35:38.748842 12802 solver.cpp:222] Iteration 55800 (1.31772 iter/s, 30.3555s/40 iters), loss = 1.46077
I1029 07:35:38.749014 12802 solver.cpp:241]     Train net output #0: loss = 1.46077 (* 1 = 1.46077 loss)
I1029 07:35:38.749032 12802 sgd_solver.cpp:105] Iteration 55800, lr = 6.58873e-05
I1029 07:36:08.976395 12802 solver.cpp:222] Iteration 55840 (1.32333 iter/s, 30.2267s/40 iters), loss = 1.70651
I1029 07:36:08.976593 12802 solver.cpp:241]     Train net output #0: loss = 1.70651 (* 1 = 1.70651 loss)
I1029 07:36:08.976609 12802 sgd_solver.cpp:105] Iteration 55840, lr = 6.56505e-05
I1029 07:36:39.425698 12802 solver.cpp:222] Iteration 55880 (1.3137 iter/s, 30.4484s/40 iters), loss = 1.63648
I1029 07:36:39.425911 12802 solver.cpp:241]     Train net output #0: loss = 1.63648 (* 1 = 1.63648 loss)
I1029 07:36:39.425931 12802 sgd_solver.cpp:105] Iteration 55880, lr = 6.54146e-05
I1029 07:37:10.468961 12802 solver.cpp:222] Iteration 55920 (1.28856 iter/s, 31.0423s/40 iters), loss = 1.3086
I1029 07:37:10.469184 12802 solver.cpp:241]     Train net output #0: loss = 1.3086 (* 1 = 1.3086 loss)
I1029 07:37:10.469200 12802 sgd_solver.cpp:105] Iteration 55920, lr = 6.51795e-05
I1029 07:37:43.864964 12802 solver.cpp:222] Iteration 55960 (1.19779 iter/s, 33.395s/40 iters), loss = 1.46435
I1029 07:37:43.865159 12802 solver.cpp:241]     Train net output #0: loss = 1.46435 (* 1 = 1.46435 loss)
I1029 07:37:43.865177 12802 sgd_solver.cpp:105] Iteration 55960, lr = 6.49453e-05
I1029 07:38:21.967952 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_56000.caffemodel
I1029 07:38:22.129037 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_56000.solverstate
I1029 07:38:22.261060 12802 solver.cpp:334] Iteration 56000, Testing net (#0)
I1029 07:38:53.413847 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58884
I1029 07:38:53.414026 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.808919
I1029 07:38:53.414039 12802 solver.cpp:401]     Test net output #2: loss = 1.82891 (* 1 = 1.82891 loss)
I1029 07:38:54.168033 12802 solver.cpp:222] Iteration 56000 (0.56898 iter/s, 70.3012s/40 iters), loss = 1.53891
I1029 07:38:54.168093 12802 solver.cpp:241]     Train net output #0: loss = 1.53891 (* 1 = 1.53891 loss)
I1029 07:38:54.168109 12802 sgd_solver.cpp:105] Iteration 56000, lr = 6.47119e-05
I1029 07:39:25.286700 12802 solver.cpp:222] Iteration 56040 (1.28544 iter/s, 31.1179s/40 iters), loss = 1.41728
I1029 07:39:25.286898 12802 solver.cpp:241]     Train net output #0: loss = 1.41728 (* 1 = 1.41728 loss)
I1029 07:39:25.286927 12802 sgd_solver.cpp:105] Iteration 56040, lr = 6.44793e-05
I1029 07:39:56.663967 12802 solver.cpp:222] Iteration 56080 (1.27485 iter/s, 31.3763s/40 iters), loss = 1.39133
I1029 07:39:56.664155 12802 solver.cpp:241]     Train net output #0: loss = 1.39133 (* 1 = 1.39133 loss)
I1029 07:39:56.664171 12802 sgd_solver.cpp:105] Iteration 56080, lr = 6.42476e-05
I1029 07:40:27.421998 12802 solver.cpp:222] Iteration 56120 (1.30051 iter/s, 30.7571s/40 iters), loss = 1.31454
I1029 07:40:27.422214 12802 solver.cpp:241]     Train net output #0: loss = 1.31454 (* 1 = 1.31454 loss)
I1029 07:40:27.422230 12802 sgd_solver.cpp:105] Iteration 56120, lr = 6.40167e-05
I1029 07:40:37.037442 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 07:40:58.073969 12802 solver.cpp:222] Iteration 56160 (1.30501 iter/s, 30.651s/40 iters), loss = 1.46707
I1029 07:40:58.074115 12802 solver.cpp:241]     Train net output #0: loss = 1.46707 (* 1 = 1.46707 loss)
I1029 07:40:58.074131 12802 sgd_solver.cpp:105] Iteration 56160, lr = 6.37866e-05
I1029 07:41:52.491924 12802 solver.cpp:222] Iteration 56200 (0.735071 iter/s, 54.4165s/40 iters), loss = 1.16648
I1029 07:41:52.492125 12802 solver.cpp:241]     Train net output #0: loss = 1.16648 (* 1 = 1.16648 loss)
I1029 07:41:52.492141 12802 sgd_solver.cpp:105] Iteration 56200, lr = 6.35574e-05
I1029 07:42:23.055600 12802 solver.cpp:222] Iteration 56240 (1.30878 iter/s, 30.5628s/40 iters), loss = 1.20605
I1029 07:42:23.055752 12802 solver.cpp:241]     Train net output #0: loss = 1.20605 (* 1 = 1.20605 loss)
I1029 07:42:23.055770 12802 sgd_solver.cpp:105] Iteration 56240, lr = 6.3329e-05
I1029 07:42:53.605940 12802 solver.cpp:222] Iteration 56280 (1.30935 iter/s, 30.5495s/40 iters), loss = 1.37829
I1029 07:42:53.606086 12802 solver.cpp:241]     Train net output #0: loss = 1.37829 (* 1 = 1.37829 loss)
I1029 07:42:53.606103 12802 sgd_solver.cpp:105] Iteration 56280, lr = 6.31014e-05
I1029 07:43:23.670615 12802 solver.cpp:222] Iteration 56320 (1.3305 iter/s, 30.0638s/40 iters), loss = 1.17932
I1029 07:43:23.670773 12802 solver.cpp:241]     Train net output #0: loss = 1.17932 (* 1 = 1.17932 loss)
I1029 07:43:23.670789 12802 sgd_solver.cpp:105] Iteration 56320, lr = 6.28746e-05
I1029 07:43:53.347488 12802 solver.cpp:222] Iteration 56360 (1.34789 iter/s, 29.676s/40 iters), loss = 1.72172
I1029 07:43:53.347549 12802 solver.cpp:241]     Train net output #0: loss = 1.72172 (* 1 = 1.72172 loss)
I1029 07:43:53.347564 12802 sgd_solver.cpp:105] Iteration 56360, lr = 6.26487e-05
I1029 07:44:23.334628 12802 solver.cpp:222] Iteration 56400 (1.33394 iter/s, 29.9864s/40 iters), loss = 1.63363
I1029 07:44:23.334858 12802 solver.cpp:241]     Train net output #0: loss = 1.63363 (* 1 = 1.63363 loss)
I1029 07:44:23.334879 12802 sgd_solver.cpp:105] Iteration 56400, lr = 6.24235e-05
I1029 07:44:52.904834 12802 solver.cpp:222] Iteration 56440 (1.35276 iter/s, 29.5693s/40 iters), loss = 1.32643
I1029 07:44:52.904893 12802 solver.cpp:241]     Train net output #0: loss = 1.32643 (* 1 = 1.32643 loss)
I1029 07:44:52.904906 12802 sgd_solver.cpp:105] Iteration 56440, lr = 6.21992e-05
I1029 07:45:22.361174 12802 solver.cpp:222] Iteration 56480 (1.35798 iter/s, 29.4556s/40 iters), loss = 1.25317
I1029 07:45:22.361342 12802 solver.cpp:241]     Train net output #0: loss = 1.25317 (* 1 = 1.25317 loss)
I1029 07:45:22.361359 12802 sgd_solver.cpp:105] Iteration 56480, lr = 6.19756e-05
I1029 07:45:36.336971 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_56500.caffemodel
I1029 07:45:36.491185 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_56500.solverstate
I1029 07:45:36.616385 12802 solver.cpp:334] Iteration 56500, Testing net (#0)
I1029 07:46:07.503507 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 07:46:07.711158 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58444
I1029 07:46:07.711211 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81468
I1029 07:46:07.711222 12802 solver.cpp:401]     Test net output #2: loss = 1.83645 (* 1 = 1.83645 loss)
I1029 07:46:23.312894 12802 solver.cpp:222] Iteration 56520 (0.656274 iter/s, 60.9501s/40 iters), loss = 1.42597
I1029 07:46:23.312960 12802 solver.cpp:241]     Train net output #0: loss = 1.42597 (* 1 = 1.42597 loss)
I1029 07:46:23.312978 12802 sgd_solver.cpp:105] Iteration 56520, lr = 6.17529e-05
I1029 07:46:53.197381 12802 solver.cpp:222] Iteration 56560 (1.33852 iter/s, 29.8837s/40 iters), loss = 1.16818
I1029 07:46:53.197582 12802 solver.cpp:241]     Train net output #0: loss = 1.16818 (* 1 = 1.16818 loss)
I1029 07:46:53.197600 12802 sgd_solver.cpp:105] Iteration 56560, lr = 6.1531e-05
I1029 07:47:23.280273 12802 solver.cpp:222] Iteration 56600 (1.3297 iter/s, 30.082s/40 iters), loss = 1.46965
I1029 07:47:23.280417 12802 solver.cpp:241]     Train net output #0: loss = 1.46965 (* 1 = 1.46965 loss)
I1029 07:47:23.280434 12802 sgd_solver.cpp:105] Iteration 56600, lr = 6.13099e-05
I1029 07:47:52.743191 12802 solver.cpp:222] Iteration 56640 (1.35768 iter/s, 29.4621s/40 iters), loss = 1.46709
I1029 07:47:52.743235 12802 solver.cpp:241]     Train net output #0: loss = 1.46709 (* 1 = 1.46709 loss)
I1029 07:47:52.743250 12802 sgd_solver.cpp:105] Iteration 56640, lr = 6.10895e-05
I1029 07:48:22.271263 12802 solver.cpp:222] Iteration 56680 (1.35468 iter/s, 29.5273s/40 iters), loss = 1.26874
I1029 07:48:22.271386 12802 solver.cpp:241]     Train net output #0: loss = 1.26874 (* 1 = 1.26874 loss)
I1029 07:48:22.271402 12802 sgd_solver.cpp:105] Iteration 56680, lr = 6.087e-05
I1029 07:48:51.830655 12802 solver.cpp:222] Iteration 56720 (1.35325 iter/s, 29.5586s/40 iters), loss = 1.5722
I1029 07:48:51.830713 12802 solver.cpp:241]     Train net output #0: loss = 1.5722 (* 1 = 1.5722 loss)
I1029 07:48:51.830729 12802 sgd_solver.cpp:105] Iteration 56720, lr = 6.06512e-05
I1029 07:49:21.325172 12802 solver.cpp:222] Iteration 56760 (1.35622 iter/s, 29.4938s/40 iters), loss = 1.50168
I1029 07:49:21.325367 12802 solver.cpp:241]     Train net output #0: loss = 1.50168 (* 1 = 1.50168 loss)
I1029 07:49:21.325381 12802 sgd_solver.cpp:105] Iteration 56760, lr = 6.04332e-05
I1029 07:49:50.961047 12802 solver.cpp:222] Iteration 56800 (1.34976 iter/s, 29.635s/40 iters), loss = 1.47971
I1029 07:49:50.961113 12802 solver.cpp:241]     Train net output #0: loss = 1.47971 (* 1 = 1.47971 loss)
I1029 07:49:50.961127 12802 sgd_solver.cpp:105] Iteration 56800, lr = 6.02161e-05
I1029 07:50:20.548722 12802 solver.cpp:222] Iteration 56840 (1.35195 iter/s, 29.5869s/40 iters), loss = 1.37996
I1029 07:50:20.548962 12802 solver.cpp:241]     Train net output #0: loss = 1.37996 (* 1 = 1.37996 loss)
I1029 07:50:20.548979 12802 sgd_solver.cpp:105] Iteration 56840, lr = 5.99997e-05
I1029 07:50:50.178156 12802 solver.cpp:222] Iteration 56880 (1.35005 iter/s, 29.6285s/40 iters), loss = 1.25662
I1029 07:50:50.178215 12802 solver.cpp:241]     Train net output #0: loss = 1.25662 (* 1 = 1.25662 loss)
I1029 07:50:50.178231 12802 sgd_solver.cpp:105] Iteration 56880, lr = 5.9784e-05
I1029 07:51:19.743283 12802 solver.cpp:222] Iteration 56920 (1.35298 iter/s, 29.5644s/40 iters), loss = 1.33146
I1029 07:51:19.743458 12802 solver.cpp:241]     Train net output #0: loss = 1.33146 (* 1 = 1.33146 loss)
I1029 07:51:19.743472 12802 sgd_solver.cpp:105] Iteration 56920, lr = 5.95692e-05
I1029 07:51:49.619935 12802 solver.cpp:222] Iteration 56960 (1.33888 iter/s, 29.8758s/40 iters), loss = 1.3289
I1029 07:51:49.619993 12802 solver.cpp:241]     Train net output #0: loss = 1.3289 (* 1 = 1.3289 loss)
I1029 07:51:49.620009 12802 sgd_solver.cpp:105] Iteration 56960, lr = 5.93551e-05
I1029 07:52:18.438117 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_57000.caffemodel
I1029 07:52:18.581259 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_57000.solverstate
I1029 07:52:18.697453 12802 solver.cpp:334] Iteration 57000, Testing net (#0)
I1029 07:52:49.877771 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58784
I1029 07:52:49.877894 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81024
I1029 07:52:49.877908 12802 solver.cpp:401]     Test net output #2: loss = 1.83146 (* 1 = 1.83146 loss)
I1029 07:52:50.648819 12802 solver.cpp:222] Iteration 57000 (0.655443 iter/s, 61.0274s/40 iters), loss = 1.47793
I1029 07:52:50.648878 12802 solver.cpp:241]     Train net output #0: loss = 1.47793 (* 1 = 1.47793 loss)
I1029 07:52:50.648896 12802 sgd_solver.cpp:105] Iteration 57000, lr = 5.91418e-05
I1029 07:53:20.394940 12802 solver.cpp:222] Iteration 57040 (1.34475 iter/s, 29.7453s/40 iters), loss = 1.15909
I1029 07:53:20.395038 12802 solver.cpp:241]     Train net output #0: loss = 1.15909 (* 1 = 1.15909 loss)
I1029 07:53:20.395056 12802 sgd_solver.cpp:105] Iteration 57040, lr = 5.89292e-05
I1029 07:53:49.985939 12802 solver.cpp:222] Iteration 57080 (1.3518 iter/s, 29.5902s/40 iters), loss = 1.44105
I1029 07:53:49.985999 12802 solver.cpp:241]     Train net output #0: loss = 1.44105 (* 1 = 1.44105 loss)
I1029 07:53:49.986012 12802 sgd_solver.cpp:105] Iteration 57080, lr = 5.87175e-05
I1029 07:54:19.616979 12802 solver.cpp:222] Iteration 57120 (1.34997 iter/s, 29.6303s/40 iters), loss = 1.21393
I1029 07:54:19.617135 12802 solver.cpp:241]     Train net output #0: loss = 1.21393 (* 1 = 1.21393 loss)
I1029 07:54:19.617152 12802 sgd_solver.cpp:105] Iteration 57120, lr = 5.85064e-05
I1029 07:54:49.253381 12802 solver.cpp:222] Iteration 57160 (1.34973 iter/s, 29.6355s/40 iters), loss = 1.26803
I1029 07:54:49.253438 12802 solver.cpp:241]     Train net output #0: loss = 1.26803 (* 1 = 1.26803 loss)
I1029 07:54:49.253454 12802 sgd_solver.cpp:105] Iteration 57160, lr = 5.82962e-05
I1029 07:55:19.046303 12802 solver.cpp:222] Iteration 57200 (1.34264 iter/s, 29.7922s/40 iters), loss = 1.31431
I1029 07:55:19.046499 12802 solver.cpp:241]     Train net output #0: loss = 1.31431 (* 1 = 1.31431 loss)
I1029 07:55:19.046515 12802 sgd_solver.cpp:105] Iteration 57200, lr = 5.80867e-05
I1029 07:55:48.628482 12802 solver.cpp:222] Iteration 57240 (1.35221 iter/s, 29.5813s/40 iters), loss = 1.25846
I1029 07:55:48.628545 12802 solver.cpp:241]     Train net output #0: loss = 1.25846 (* 1 = 1.25846 loss)
I1029 07:55:48.628561 12802 sgd_solver.cpp:105] Iteration 57240, lr = 5.78779e-05
I1029 07:56:20.042774 12802 solver.cpp:222] Iteration 57280 (1.27334 iter/s, 31.4135s/40 iters), loss = 1.40089
I1029 07:56:20.043022 12802 solver.cpp:241]     Train net output #0: loss = 1.40089 (* 1 = 1.40089 loss)
I1029 07:56:20.043050 12802 sgd_solver.cpp:105] Iteration 57280, lr = 5.76699e-05
I1029 07:56:50.974046 12802 solver.cpp:222] Iteration 57320 (1.29323 iter/s, 30.9303s/40 iters), loss = 1.08037
I1029 07:56:50.974192 12802 solver.cpp:241]     Train net output #0: loss = 1.08037 (* 1 = 1.08037 loss)
I1029 07:56:50.974210 12802 sgd_solver.cpp:105] Iteration 57320, lr = 5.74627e-05
I1029 07:57:21.057520 12802 solver.cpp:222] Iteration 57360 (1.32967 iter/s, 30.0826s/40 iters), loss = 1.32436
I1029 07:57:21.057670 12802 solver.cpp:241]     Train net output #0: loss = 1.32436 (* 1 = 1.32436 loss)
I1029 07:57:21.057687 12802 sgd_solver.cpp:105] Iteration 57360, lr = 5.72562e-05
I1029 07:57:50.720173 12802 solver.cpp:222] Iteration 57400 (1.34854 iter/s, 29.6618s/40 iters), loss = 1.25335
I1029 07:57:50.720243 12802 solver.cpp:241]     Train net output #0: loss = 1.25335 (* 1 = 1.25335 loss)
I1029 07:57:50.720266 12802 sgd_solver.cpp:105] Iteration 57400, lr = 5.70504e-05
I1029 07:58:20.914870 12802 solver.cpp:222] Iteration 57440 (1.32477 iter/s, 30.1939s/40 iters), loss = 1.4101
I1029 07:58:20.915066 12802 solver.cpp:241]     Train net output #0: loss = 1.4101 (* 1 = 1.4101 loss)
I1029 07:58:20.915082 12802 sgd_solver.cpp:105] Iteration 57440, lr = 5.68454e-05
I1029 07:59:14.278219 12802 solver.cpp:222] Iteration 57480 (0.749598 iter/s, 53.3619s/40 iters), loss = 1.3938
I1029 07:59:14.278421 12802 solver.cpp:241]     Train net output #0: loss = 1.3938 (* 1 = 1.3938 loss)
I1029 07:59:14.278437 12802 sgd_solver.cpp:105] Iteration 57480, lr = 5.66411e-05
I1029 07:59:34.538985 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_57500.caffemodel
I1029 07:59:34.683451 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_57500.solverstate
I1029 07:59:34.798982 12802 solver.cpp:334] Iteration 57500, Testing net (#0)
I1029 08:00:05.755669 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 08:00:05.965751 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58532
I1029 08:00:05.965795 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81472
I1029 08:00:05.965807 12802 solver.cpp:401]     Test net output #2: loss = 1.83262 (* 1 = 1.83262 loss)
I1029 08:00:22.239532 12802 solver.cpp:222] Iteration 57520 (0.588585 iter/s, 67.9595s/40 iters), loss = 1.45656
I1029 08:00:22.239593 12802 solver.cpp:241]     Train net output #0: loss = 1.45656 (* 1 = 1.45656 loss)
I1029 08:00:22.239606 12802 sgd_solver.cpp:105] Iteration 57520, lr = 5.64375e-05
I1029 08:01:14.404903 12802 solver.cpp:222] Iteration 57560 (0.766811 iter/s, 52.1641s/40 iters), loss = 1.38914
I1029 08:01:14.405104 12802 solver.cpp:241]     Train net output #0: loss = 1.38914 (* 1 = 1.38914 loss)
I1029 08:01:14.405122 12802 sgd_solver.cpp:105] Iteration 57560, lr = 5.62347e-05
I1029 08:02:38.427336 12802 solver.cpp:222] Iteration 57600 (0.476075 iter/s, 84.0203s/40 iters), loss = 1.6569
I1029 08:02:38.427569 12802 solver.cpp:241]     Train net output #0: loss = 1.6569 (* 1 = 1.6569 loss)
I1029 08:02:38.427592 12802 sgd_solver.cpp:105] Iteration 57600, lr = 5.60326e-05
I1029 08:03:10.162984 12802 solver.cpp:222] Iteration 57640 (1.26045 iter/s, 31.7347s/40 iters), loss = 1.42982
I1029 08:03:10.163156 12802 solver.cpp:241]     Train net output #0: loss = 1.42982 (* 1 = 1.42982 loss)
I1029 08:03:10.163173 12802 sgd_solver.cpp:105] Iteration 57640, lr = 5.58312e-05
I1029 08:03:39.678954 12802 solver.cpp:222] Iteration 57680 (1.35524 iter/s, 29.5151s/40 iters), loss = 1.17883
I1029 08:03:39.679019 12802 solver.cpp:241]     Train net output #0: loss = 1.17883 (* 1 = 1.17883 loss)
I1029 08:03:39.679033 12802 sgd_solver.cpp:105] Iteration 57680, lr = 5.56306e-05
I1029 08:04:09.314836 12802 solver.cpp:222] Iteration 57720 (1.34975 iter/s, 29.6351s/40 iters), loss = 1.12797
I1029 08:04:09.315075 12802 solver.cpp:241]     Train net output #0: loss = 1.12797 (* 1 = 1.12797 loss)
I1029 08:04:09.315093 12802 sgd_solver.cpp:105] Iteration 57720, lr = 5.54306e-05
I1029 08:04:38.866253 12802 solver.cpp:222] Iteration 57760 (1.35362 iter/s, 29.5505s/40 iters), loss = 1.40142
I1029 08:04:38.866312 12802 solver.cpp:241]     Train net output #0: loss = 1.40142 (* 1 = 1.40142 loss)
I1029 08:04:38.866327 12802 sgd_solver.cpp:105] Iteration 57760, lr = 5.52314e-05
I1029 08:05:08.431598 12802 solver.cpp:222] Iteration 57800 (1.35297 iter/s, 29.5646s/40 iters), loss = 1.32601
I1029 08:05:08.431787 12802 solver.cpp:241]     Train net output #0: loss = 1.32601 (* 1 = 1.32601 loss)
I1029 08:05:08.431805 12802 sgd_solver.cpp:105] Iteration 57800, lr = 5.50329e-05
I1029 08:05:38.045059 12802 solver.cpp:222] Iteration 57840 (1.35078 iter/s, 29.6126s/40 iters), loss = 1.20311
I1029 08:05:38.045120 12802 solver.cpp:241]     Train net output #0: loss = 1.20311 (* 1 = 1.20311 loss)
I1029 08:05:38.045136 12802 sgd_solver.cpp:105] Iteration 57840, lr = 5.48352e-05
I1029 08:06:07.602233 12802 solver.cpp:222] Iteration 57880 (1.35334 iter/s, 29.5564s/40 iters), loss = 1.44959
I1029 08:06:07.602414 12802 solver.cpp:241]     Train net output #0: loss = 1.44959 (* 1 = 1.44959 loss)
I1029 08:06:07.602432 12802 sgd_solver.cpp:105] Iteration 57880, lr = 5.46381e-05
I1029 08:06:37.666679 12802 solver.cpp:222] Iteration 57920 (1.33051 iter/s, 30.0636s/40 iters), loss = 1.34797
I1029 08:06:37.666805 12802 solver.cpp:241]     Train net output #0: loss = 1.34797 (* 1 = 1.34797 loss)
I1029 08:06:37.666822 12802 sgd_solver.cpp:105] Iteration 57920, lr = 5.44417e-05
I1029 08:07:07.893883 12802 solver.cpp:222] Iteration 57960 (1.32335 iter/s, 30.2264s/40 iters), loss = 1.29834
I1029 08:07:07.894032 12802 solver.cpp:241]     Train net output #0: loss = 1.29834 (* 1 = 1.29834 loss)
I1029 08:07:07.894047 12802 sgd_solver.cpp:105] Iteration 57960, lr = 5.42461e-05
I1029 08:07:37.662077 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_58000.caffemodel
I1029 08:07:37.823460 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_58000.solverstate
I1029 08:07:37.942690 12802 solver.cpp:334] Iteration 58000, Testing net (#0)
I1029 08:08:09.144186 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58876
I1029 08:08:09.144337 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.808879
I1029 08:08:09.144352 12802 solver.cpp:401]     Test net output #2: loss = 1.82849 (* 1 = 1.82849 loss)
I1029 08:08:09.919493 12802 solver.cpp:222] Iteration 58000 (0.644911 iter/s, 62.024s/40 iters), loss = 1.8718
I1029 08:08:09.919535 12802 solver.cpp:241]     Train net output #0: loss = 1.8718 (* 1 = 1.8718 loss)
I1029 08:08:09.919556 12802 sgd_solver.cpp:105] Iteration 58000, lr = 5.40511e-05
I1029 08:08:40.628595 12802 solver.cpp:222] Iteration 58040 (1.30258 iter/s, 30.7083s/40 iters), loss = 1.36254
I1029 08:08:40.628782 12802 solver.cpp:241]     Train net output #0: loss = 1.36254 (* 1 = 1.36254 loss)
I1029 08:08:40.628800 12802 sgd_solver.cpp:105] Iteration 58040, lr = 5.38569e-05
I1029 08:09:23.327877 12802 solver.cpp:222] Iteration 58080 (0.93681 iter/s, 42.6981s/40 iters), loss = 1.52826
I1029 08:09:23.328071 12802 solver.cpp:241]     Train net output #0: loss = 1.52826 (* 1 = 1.52826 loss)
I1029 08:09:23.328088 12802 sgd_solver.cpp:105] Iteration 58080, lr = 5.36633e-05
I1029 08:09:53.537390 12802 solver.cpp:222] Iteration 58120 (1.32413 iter/s, 30.2086s/40 iters), loss = 1.66434
I1029 08:09:53.537600 12802 solver.cpp:241]     Train net output #0: loss = 1.66434 (* 1 = 1.66434 loss)
I1029 08:09:53.537617 12802 sgd_solver.cpp:105] Iteration 58120, lr = 5.34705e-05
I1029 08:10:23.009196 12802 solver.cpp:222] Iteration 58160 (1.35727 iter/s, 29.4709s/40 iters), loss = 1.34125
I1029 08:10:23.009248 12802 solver.cpp:241]     Train net output #0: loss = 1.34125 (* 1 = 1.34125 loss)
I1029 08:10:23.009261 12802 sgd_solver.cpp:105] Iteration 58160, lr = 5.32783e-05
I1029 08:10:52.482820 12802 solver.cpp:222] Iteration 58200 (1.35718 iter/s, 29.4729s/40 iters), loss = 1.56631
I1029 08:10:52.483042 12802 solver.cpp:241]     Train net output #0: loss = 1.56631 (* 1 = 1.56631 loss)
I1029 08:10:52.483058 12802 sgd_solver.cpp:105] Iteration 58200, lr = 5.30868e-05
I1029 08:11:22.114379 12802 solver.cpp:222] Iteration 58240 (1.34995 iter/s, 29.6306s/40 iters), loss = 1.36301
I1029 08:11:22.114434 12802 solver.cpp:241]     Train net output #0: loss = 1.36301 (* 1 = 1.36301 loss)
I1029 08:11:22.114449 12802 sgd_solver.cpp:105] Iteration 58240, lr = 5.28961e-05
I1029 08:11:52.080066 12802 solver.cpp:222] Iteration 58280 (1.33489 iter/s, 29.9649s/40 iters), loss = 1.70628
I1029 08:11:52.080267 12802 solver.cpp:241]     Train net output #0: loss = 1.70628 (* 1 = 1.70628 loss)
I1029 08:11:52.080284 12802 sgd_solver.cpp:105] Iteration 58280, lr = 5.2706e-05
I1029 08:12:23.388978 12802 solver.cpp:222] Iteration 58320 (1.27763 iter/s, 31.308s/40 iters), loss = 1.53107
I1029 08:12:23.389152 12802 solver.cpp:241]     Train net output #0: loss = 1.53107 (* 1 = 1.53107 loss)
I1029 08:12:23.389165 12802 sgd_solver.cpp:105] Iteration 58320, lr = 5.25166e-05
I1029 08:12:55.336555 12802 solver.cpp:222] Iteration 58360 (1.25209 iter/s, 31.9467s/40 iters), loss = 1.44286
I1029 08:12:55.336758 12802 solver.cpp:241]     Train net output #0: loss = 1.44286 (* 1 = 1.44286 loss)
I1029 08:12:55.336776 12802 sgd_solver.cpp:105] Iteration 58360, lr = 5.23278e-05
I1029 08:13:26.660642 12802 solver.cpp:222] Iteration 58400 (1.27701 iter/s, 31.3231s/40 iters), loss = 1.15802
I1029 08:13:26.660862 12802 solver.cpp:241]     Train net output #0: loss = 1.15802 (* 1 = 1.15802 loss)
I1029 08:13:26.660888 12802 sgd_solver.cpp:105] Iteration 58400, lr = 5.21398e-05
I1029 08:13:56.495801 12802 solver.cpp:222] Iteration 58440 (1.34074 iter/s, 29.8342s/40 iters), loss = 1.41599
I1029 08:13:56.495860 12802 solver.cpp:241]     Train net output #0: loss = 1.41599 (* 1 = 1.41599 loss)
I1029 08:13:56.495875 12802 sgd_solver.cpp:105] Iteration 58440, lr = 5.19524e-05
I1029 08:14:26.336858 12802 solver.cpp:222] Iteration 58480 (1.34047 iter/s, 29.8403s/40 iters), loss = 1.1802
I1029 08:14:26.337049 12802 solver.cpp:241]     Train net output #0: loss = 1.1802 (* 1 = 1.1802 loss)
I1029 08:14:26.337066 12802 sgd_solver.cpp:105] Iteration 58480, lr = 5.17657e-05
I1029 08:14:40.501844 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_58500.caffemodel
I1029 08:14:40.643548 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_58500.solverstate
I1029 08:14:40.755610 12802 solver.cpp:334] Iteration 58500, Testing net (#0)
I1029 08:15:11.809592 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 08:15:12.017024 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.585961
I1029 08:15:12.017071 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81496
I1029 08:15:12.017083 12802 solver.cpp:401]     Test net output #2: loss = 1.83171 (* 1 = 1.83171 loss)
I1029 08:15:27.577301 12802 solver.cpp:222] Iteration 58520 (0.65318 iter/s, 61.2388s/40 iters), loss = 1.47343
I1029 08:15:27.577358 12802 solver.cpp:241]     Train net output #0: loss = 1.47343 (* 1 = 1.47343 loss)
I1029 08:15:27.577373 12802 sgd_solver.cpp:105] Iteration 58520, lr = 5.15796e-05
I1029 08:15:57.149777 12802 solver.cpp:222] Iteration 58560 (1.35264 iter/s, 29.5717s/40 iters), loss = 1.48258
I1029 08:15:57.149933 12802 solver.cpp:241]     Train net output #0: loss = 1.48258 (* 1 = 1.48258 loss)
I1029 08:15:57.149951 12802 sgd_solver.cpp:105] Iteration 58560, lr = 5.13943e-05
I1029 08:16:26.680886 12802 solver.cpp:222] Iteration 58600 (1.35454 iter/s, 29.5303s/40 iters), loss = 1.56117
I1029 08:16:26.680945 12802 solver.cpp:241]     Train net output #0: loss = 1.56117 (* 1 = 1.56117 loss)
I1029 08:16:26.680961 12802 sgd_solver.cpp:105] Iteration 58600, lr = 5.12096e-05
I1029 08:16:52.622809 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 08:16:56.361986 12802 solver.cpp:222] Iteration 58640 (1.34769 iter/s, 29.6803s/40 iters), loss = 1.42157
I1029 08:16:56.362043 12802 solver.cpp:241]     Train net output #0: loss = 1.42157 (* 1 = 1.42157 loss)
I1029 08:16:56.362061 12802 sgd_solver.cpp:105] Iteration 58640, lr = 5.10255e-05
I1029 08:17:25.913857 12802 solver.cpp:222] Iteration 58680 (1.35359 iter/s, 29.5511s/40 iters), loss = 1.40533
I1029 08:17:25.914041 12802 solver.cpp:241]     Train net output #0: loss = 1.40533 (* 1 = 1.40533 loss)
I1029 08:17:25.914055 12802 sgd_solver.cpp:105] Iteration 58680, lr = 5.08422e-05
I1029 08:17:55.585115 12802 solver.cpp:222] Iteration 58720 (1.34815 iter/s, 29.6704s/40 iters), loss = 1.47776
I1029 08:17:55.585181 12802 solver.cpp:241]     Train net output #0: loss = 1.47776 (* 1 = 1.47776 loss)
I1029 08:17:55.585196 12802 sgd_solver.cpp:105] Iteration 58720, lr = 5.06594e-05
I1029 08:18:25.139230 12802 solver.cpp:222] Iteration 58760 (1.35348 iter/s, 29.5533s/40 iters), loss = 1.20115
I1029 08:18:25.139427 12802 solver.cpp:241]     Train net output #0: loss = 1.20115 (* 1 = 1.20115 loss)
I1029 08:18:25.139444 12802 sgd_solver.cpp:105] Iteration 58760, lr = 5.04774e-05
I1029 08:18:54.755352 12802 solver.cpp:222] Iteration 58800 (1.35066 iter/s, 29.6152s/40 iters), loss = 1.36676
I1029 08:18:54.755414 12802 solver.cpp:241]     Train net output #0: loss = 1.36676 (* 1 = 1.36676 loss)
I1029 08:18:54.755431 12802 sgd_solver.cpp:105] Iteration 58800, lr = 5.0296e-05
I1029 08:19:24.372190 12802 solver.cpp:222] Iteration 58840 (1.35062 iter/s, 29.6161s/40 iters), loss = 1.59222
I1029 08:19:24.372378 12802 solver.cpp:241]     Train net output #0: loss = 1.59222 (* 1 = 1.59222 loss)
I1029 08:19:24.372401 12802 sgd_solver.cpp:105] Iteration 58840, lr = 5.01152e-05
I1029 08:19:54.159730 12802 solver.cpp:222] Iteration 58880 (1.34288 iter/s, 29.7866s/40 iters), loss = 1.68623
I1029 08:19:54.159795 12802 solver.cpp:241]     Train net output #0: loss = 1.68623 (* 1 = 1.68623 loss)
I1029 08:19:54.159811 12802 sgd_solver.cpp:105] Iteration 58880, lr = 4.99351e-05
I1029 08:20:23.727207 12802 solver.cpp:222] Iteration 58920 (1.35287 iter/s, 29.5667s/40 iters), loss = 1.44019
I1029 08:20:23.727382 12802 solver.cpp:241]     Train net output #0: loss = 1.44019 (* 1 = 1.44019 loss)
I1029 08:20:23.727399 12802 sgd_solver.cpp:105] Iteration 58920, lr = 4.97557e-05
I1029 08:20:53.240669 12802 solver.cpp:222] Iteration 58960 (1.35535 iter/s, 29.5126s/40 iters), loss = 1.43762
I1029 08:20:53.240732 12802 solver.cpp:241]     Train net output #0: loss = 1.43762 (* 1 = 1.43762 loss)
I1029 08:20:53.240746 12802 sgd_solver.cpp:105] Iteration 58960, lr = 4.95768e-05
I1029 08:21:22.041424 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_59000.caffemodel
I1029 08:21:22.183756 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_59000.solverstate
I1029 08:21:22.304144 12802 solver.cpp:334] Iteration 59000, Testing net (#0)
I1029 08:21:53.430266 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5896
I1029 08:21:53.430399 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80984
I1029 08:21:53.430413 12802 solver.cpp:401]     Test net output #2: loss = 1.83341 (* 1 = 1.83341 loss)
I1029 08:21:54.203645 12802 solver.cpp:222] Iteration 59000 (0.656152 iter/s, 60.9615s/40 iters), loss = 1.54382
I1029 08:21:54.203708 12802 solver.cpp:241]     Train net output #0: loss = 1.54382 (* 1 = 1.54382 loss)
I1029 08:21:54.203724 12802 sgd_solver.cpp:105] Iteration 59000, lr = 4.93987e-05
I1029 08:22:24.149909 12802 solver.cpp:222] Iteration 59040 (1.33576 iter/s, 29.9455s/40 iters), loss = 1.42228
I1029 08:22:24.150080 12802 solver.cpp:241]     Train net output #0: loss = 1.42228 (* 1 = 1.42228 loss)
I1029 08:22:24.150094 12802 sgd_solver.cpp:105] Iteration 59040, lr = 4.92211e-05
I1029 08:22:53.885994 12802 solver.cpp:222] Iteration 59080 (1.34521 iter/s, 29.7352s/40 iters), loss = 1.15426
I1029 08:22:53.886049 12802 solver.cpp:241]     Train net output #0: loss = 1.15426 (* 1 = 1.15426 loss)
I1029 08:22:53.886062 12802 sgd_solver.cpp:105] Iteration 59080, lr = 4.90443e-05
I1029 08:23:23.588105 12802 solver.cpp:222] Iteration 59120 (1.34674 iter/s, 29.7013s/40 iters), loss = 1.46437
I1029 08:23:23.588348 12802 solver.cpp:241]     Train net output #0: loss = 1.46437 (* 1 = 1.46437 loss)
I1029 08:23:23.588366 12802 sgd_solver.cpp:105] Iteration 59120, lr = 4.8868e-05
I1029 08:23:53.222841 12802 solver.cpp:222] Iteration 59160 (1.34981 iter/s, 29.6338s/40 iters), loss = 1.35656
I1029 08:23:53.222898 12802 solver.cpp:241]     Train net output #0: loss = 1.35656 (* 1 = 1.35656 loss)
I1029 08:23:53.222913 12802 sgd_solver.cpp:105] Iteration 59160, lr = 4.86924e-05
I1029 08:24:23.653178 12802 solver.cpp:222] Iteration 59200 (1.31451 iter/s, 30.4296s/40 iters), loss = 1.56955
I1029 08:24:23.653367 12802 solver.cpp:241]     Train net output #0: loss = 1.56955 (* 1 = 1.56955 loss)
I1029 08:24:23.653385 12802 sgd_solver.cpp:105] Iteration 59200, lr = 4.85174e-05
I1029 08:24:54.278136 12802 solver.cpp:222] Iteration 59240 (1.30616 iter/s, 30.6241s/40 iters), loss = 1.17906
I1029 08:24:54.278345 12802 solver.cpp:241]     Train net output #0: loss = 1.17906 (* 1 = 1.17906 loss)
I1029 08:24:54.278362 12802 sgd_solver.cpp:105] Iteration 59240, lr = 4.8343e-05
I1029 08:25:24.215430 12802 solver.cpp:222] Iteration 59280 (1.33617 iter/s, 29.9364s/40 iters), loss = 1.55832
I1029 08:25:24.215490 12802 solver.cpp:241]     Train net output #0: loss = 1.55832 (* 1 = 1.55832 loss)
I1029 08:25:24.215505 12802 sgd_solver.cpp:105] Iteration 59280, lr = 4.81693e-05
I1029 08:25:53.629477 12802 solver.cpp:222] Iteration 59320 (1.35993 iter/s, 29.4133s/40 iters), loss = 1.36097
I1029 08:25:53.629676 12802 solver.cpp:241]     Train net output #0: loss = 1.36097 (* 1 = 1.36097 loss)
I1029 08:25:53.629693 12802 sgd_solver.cpp:105] Iteration 59320, lr = 4.79962e-05
I1029 08:26:23.162875 12802 solver.cpp:222] Iteration 59360 (1.35444 iter/s, 29.5325s/40 iters), loss = 1.42619
I1029 08:26:23.162936 12802 solver.cpp:241]     Train net output #0: loss = 1.42619 (* 1 = 1.42619 loss)
I1029 08:26:23.162950 12802 sgd_solver.cpp:105] Iteration 59360, lr = 4.78237e-05
I1029 08:26:53.138674 12802 solver.cpp:222] Iteration 59400 (1.33444 iter/s, 29.975s/40 iters), loss = 1.31738
I1029 08:26:53.138852 12802 solver.cpp:241]     Train net output #0: loss = 1.31738 (* 1 = 1.31738 loss)
I1029 08:26:53.138873 12802 sgd_solver.cpp:105] Iteration 59400, lr = 4.76518e-05
I1029 08:27:23.384917 12802 solver.cpp:222] Iteration 59440 (1.32252 iter/s, 30.2454s/40 iters), loss = 1.41588
I1029 08:27:23.385056 12802 solver.cpp:241]     Train net output #0: loss = 1.41588 (* 1 = 1.41588 loss)
I1029 08:27:23.385073 12802 sgd_solver.cpp:105] Iteration 59440, lr = 4.74806e-05
I1029 08:27:54.287569 12802 solver.cpp:222] Iteration 59480 (1.29442 iter/s, 30.9018s/40 iters), loss = 1.41568
I1029 08:27:54.287761 12802 solver.cpp:241]     Train net output #0: loss = 1.41568 (* 1 = 1.41568 loss)
I1029 08:27:54.287776 12802 sgd_solver.cpp:105] Iteration 59480, lr = 4.73099e-05
I1029 08:28:09.358489 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_59500.caffemodel
I1029 08:28:09.500305 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_59500.solverstate
I1029 08:28:09.611832 12802 solver.cpp:334] Iteration 59500, Testing net (#0)
I1029 08:28:40.581574 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 08:28:40.791834 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58484
I1029 08:28:40.791882 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8146
I1029 08:28:40.791893 12802 solver.cpp:401]     Test net output #2: loss = 1.83494 (* 1 = 1.83494 loss)
I1029 08:29:00.873780 12802 solver.cpp:222] Iteration 59520 (0.600741 iter/s, 66.5845s/40 iters), loss = 1.3868
I1029 08:29:00.873844 12802 solver.cpp:241]     Train net output #0: loss = 1.3868 (* 1 = 1.3868 loss)
I1029 08:29:00.873860 12802 sgd_solver.cpp:105] Iteration 59520, lr = 4.71399e-05
I1029 08:31:11.515794 12802 solver.cpp:222] Iteration 59560 (0.306187 iter/s, 130.639s/40 iters), loss = 1.26078
I1029 08:31:11.516065 12802 solver.cpp:241]     Train net output #0: loss = 1.26078 (* 1 = 1.26078 loss)
I1029 08:31:11.516088 12802 sgd_solver.cpp:105] Iteration 59560, lr = 4.69705e-05
I1029 08:31:41.752209 12802 solver.cpp:222] Iteration 59600 (1.32295 iter/s, 30.2355s/40 iters), loss = 1.49756
I1029 08:31:41.752409 12802 solver.cpp:241]     Train net output #0: loss = 1.49756 (* 1 = 1.49756 loss)
I1029 08:31:41.752426 12802 sgd_solver.cpp:105] Iteration 59600, lr = 4.68017e-05
I1029 08:32:11.759974 12802 solver.cpp:222] Iteration 59640 (1.33303 iter/s, 30.0069s/40 iters), loss = 1.63868
I1029 08:32:11.760143 12802 solver.cpp:241]     Train net output #0: loss = 1.63868 (* 1 = 1.63868 loss)
I1029 08:32:11.760157 12802 sgd_solver.cpp:105] Iteration 59640, lr = 4.66335e-05
I1029 08:32:41.506147 12802 solver.cpp:222] Iteration 59680 (1.34475 iter/s, 29.7453s/40 iters), loss = 1.26412
I1029 08:32:41.506211 12802 solver.cpp:241]     Train net output #0: loss = 1.26412 (* 1 = 1.26412 loss)
I1029 08:32:41.506227 12802 sgd_solver.cpp:105] Iteration 59680, lr = 4.64659e-05
I1029 08:33:11.526408 12802 solver.cpp:222] Iteration 59720 (1.33247 iter/s, 30.0195s/40 iters), loss = 1.53267
I1029 08:33:11.526615 12802 solver.cpp:241]     Train net output #0: loss = 1.53267 (* 1 = 1.53267 loss)
I1029 08:33:11.526631 12802 sgd_solver.cpp:105] Iteration 59720, lr = 4.62989e-05
I1029 08:33:41.639266 12802 solver.cpp:222] Iteration 59760 (1.32838 iter/s, 30.1119s/40 iters), loss = 1.60916
I1029 08:33:41.639420 12802 solver.cpp:241]     Train net output #0: loss = 1.60916 (* 1 = 1.60916 loss)
I1029 08:33:41.639437 12802 sgd_solver.cpp:105] Iteration 59760, lr = 4.61325e-05
I1029 08:34:12.040251 12802 solver.cpp:222] Iteration 59800 (1.31578 iter/s, 30.4001s/40 iters), loss = 1.27412
I1029 08:34:12.040462 12802 solver.cpp:241]     Train net output #0: loss = 1.27412 (* 1 = 1.27412 loss)
I1029 08:34:12.040480 12802 sgd_solver.cpp:105] Iteration 59800, lr = 4.59667e-05
I1029 08:34:42.643052 12802 solver.cpp:222] Iteration 59840 (1.30711 iter/s, 30.6019s/40 iters), loss = 1.45775
I1029 08:34:42.643208 12802 solver.cpp:241]     Train net output #0: loss = 1.45775 (* 1 = 1.45775 loss)
I1029 08:34:42.643225 12802 sgd_solver.cpp:105] Iteration 59840, lr = 4.58015e-05
I1029 08:35:12.383595 12802 solver.cpp:222] Iteration 59880 (1.345 iter/s, 29.7397s/40 iters), loss = 1.28381
I1029 08:35:12.383652 12802 solver.cpp:241]     Train net output #0: loss = 1.28381 (* 1 = 1.28381 loss)
I1029 08:35:12.383667 12802 sgd_solver.cpp:105] Iteration 59880, lr = 4.56369e-05
I1029 08:35:42.276412 12802 solver.cpp:222] Iteration 59920 (1.33815 iter/s, 29.892s/40 iters), loss = 1.45423
I1029 08:35:42.276598 12802 solver.cpp:241]     Train net output #0: loss = 1.45423 (* 1 = 1.45423 loss)
I1029 08:35:42.276617 12802 sgd_solver.cpp:105] Iteration 59920, lr = 4.54729e-05
I1029 08:36:12.771853 12802 solver.cpp:222] Iteration 59960 (1.31171 iter/s, 30.4945s/40 iters), loss = 1.34747
I1029 08:36:12.772001 12802 solver.cpp:241]     Train net output #0: loss = 1.34747 (* 1 = 1.34747 loss)
I1029 08:36:12.772018 12802 sgd_solver.cpp:105] Iteration 59960, lr = 4.53095e-05
I1029 08:36:42.732498 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_60000.caffemodel
I1029 08:36:42.890103 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_60000.solverstate
I1029 08:36:43.013506 12802 solver.cpp:334] Iteration 60000, Testing net (#0)
I1029 08:37:14.216477 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58904
I1029 08:37:14.216732 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81028
I1029 08:37:14.216749 12802 solver.cpp:401]     Test net output #2: loss = 1.82689 (* 1 = 1.82689 loss)
I1029 08:37:14.987529 12802 solver.cpp:222] Iteration 60000 (0.642941 iter/s, 62.2141s/40 iters), loss = 1.64721
I1029 08:37:14.987587 12802 solver.cpp:241]     Train net output #0: loss = 1.64721 (* 1 = 1.64721 loss)
I1029 08:37:14.987603 12802 sgd_solver.cpp:105] Iteration 60000, lr = 4.51467e-05
I1029 08:37:46.161880 12802 solver.cpp:222] Iteration 60040 (1.28314 iter/s, 31.1735s/40 iters), loss = 1.55752
I1029 08:37:46.162046 12802 solver.cpp:241]     Train net output #0: loss = 1.55752 (* 1 = 1.55752 loss)
I1029 08:37:46.162065 12802 sgd_solver.cpp:105] Iteration 60040, lr = 4.49844e-05
I1029 08:38:16.990753 12802 solver.cpp:222] Iteration 60080 (1.29752 iter/s, 30.828s/40 iters), loss = 1.27074
I1029 08:38:16.990938 12802 solver.cpp:241]     Train net output #0: loss = 1.27074 (* 1 = 1.27074 loss)
I1029 08:38:16.990954 12802 sgd_solver.cpp:105] Iteration 60080, lr = 4.48228e-05
I1029 08:38:46.699791 12802 solver.cpp:222] Iteration 60120 (1.34643 iter/s, 29.7081s/40 iters), loss = 1.48778
I1029 08:38:46.699847 12802 solver.cpp:241]     Train net output #0: loss = 1.48778 (* 1 = 1.48778 loss)
I1029 08:38:46.699863 12802 sgd_solver.cpp:105] Iteration 60120, lr = 4.46617e-05
I1029 08:39:17.720683 12802 solver.cpp:222] Iteration 60160 (1.28949 iter/s, 31.0201s/40 iters), loss = 1.30123
I1029 08:39:17.720947 12802 solver.cpp:241]     Train net output #0: loss = 1.30123 (* 1 = 1.30123 loss)
I1029 08:39:17.720973 12802 sgd_solver.cpp:105] Iteration 60160, lr = 4.45012e-05
I1029 08:39:48.547020 12802 solver.cpp:222] Iteration 60200 (1.29763 iter/s, 30.8253s/40 iters), loss = 1.35245
I1029 08:39:48.547214 12802 solver.cpp:241]     Train net output #0: loss = 1.35245 (* 1 = 1.35245 loss)
I1029 08:39:48.547240 12802 sgd_solver.cpp:105] Iteration 60200, lr = 4.43412e-05
I1029 08:40:18.834350 12802 solver.cpp:222] Iteration 60240 (1.32072 iter/s, 30.2864s/40 iters), loss = 1.31574
I1029 08:40:18.834535 12802 solver.cpp:241]     Train net output #0: loss = 1.31574 (* 1 = 1.31574 loss)
I1029 08:40:18.834553 12802 sgd_solver.cpp:105] Iteration 60240, lr = 4.41819e-05
I1029 08:40:49.169596 12802 solver.cpp:222] Iteration 60280 (1.31864 iter/s, 30.3343s/40 iters), loss = 1.27065
I1029 08:40:49.169791 12802 solver.cpp:241]     Train net output #0: loss = 1.27065 (* 1 = 1.27065 loss)
I1029 08:40:49.169808 12802 sgd_solver.cpp:105] Iteration 60280, lr = 4.40231e-05
I1029 08:41:19.765703 12802 solver.cpp:222] Iteration 60320 (1.3074 iter/s, 30.5952s/40 iters), loss = 1.39522
I1029 08:41:19.765918 12802 solver.cpp:241]     Train net output #0: loss = 1.39522 (* 1 = 1.39522 loss)
I1029 08:41:19.765940 12802 sgd_solver.cpp:105] Iteration 60320, lr = 4.38649e-05
I1029 08:41:50.265771 12802 solver.cpp:222] Iteration 60360 (1.31151 iter/s, 30.4991s/40 iters), loss = 1.33285
I1029 08:41:50.265928 12802 solver.cpp:241]     Train net output #0: loss = 1.33285 (* 1 = 1.33285 loss)
I1029 08:41:50.265944 12802 sgd_solver.cpp:105] Iteration 60360, lr = 4.37072e-05
I1029 08:42:20.605098 12802 solver.cpp:222] Iteration 60400 (1.31846 iter/s, 30.3385s/40 iters), loss = 1.23018
I1029 08:42:20.605259 12802 solver.cpp:241]     Train net output #0: loss = 1.23018 (* 1 = 1.23018 loss)
I1029 08:42:20.605274 12802 sgd_solver.cpp:105] Iteration 60400, lr = 4.35502e-05
I1029 08:42:50.385510 12802 solver.cpp:222] Iteration 60440 (1.3432 iter/s, 29.7795s/40 iters), loss = 1.07652
I1029 08:42:50.385566 12802 solver.cpp:241]     Train net output #0: loss = 1.07652 (* 1 = 1.07652 loss)
I1029 08:42:50.385581 12802 sgd_solver.cpp:105] Iteration 60440, lr = 4.33937e-05
I1029 08:43:19.957052 12802 solver.cpp:222] Iteration 60480 (1.35269 iter/s, 29.5708s/40 iters), loss = 1.31275
I1029 08:43:19.957201 12802 solver.cpp:241]     Train net output #0: loss = 1.31275 (* 1 = 1.31275 loss)
I1029 08:43:19.957217 12802 sgd_solver.cpp:105] Iteration 60480, lr = 4.32377e-05
I1029 08:43:33.972419 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_60500.caffemodel
I1029 08:43:34.114552 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_60500.solverstate
I1029 08:43:34.229665 12802 solver.cpp:334] Iteration 60500, Testing net (#0)
I1029 08:44:05.212541 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 08:44:05.420004 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58524
I1029 08:44:05.420051 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81584
I1029 08:44:05.420063 12802 solver.cpp:401]     Test net output #2: loss = 1.83068 (* 1 = 1.83068 loss)
I1029 08:44:20.928822 12802 solver.cpp:222] Iteration 60520 (0.656058 iter/s, 60.9702s/40 iters), loss = 1.53913
I1029 08:44:20.928881 12802 solver.cpp:241]     Train net output #0: loss = 1.53913 (* 1 = 1.53913 loss)
I1029 08:44:20.928897 12802 sgd_solver.cpp:105] Iteration 60520, lr = 4.30823e-05
I1029 08:44:50.297503 12802 solver.cpp:222] Iteration 60560 (1.36203 iter/s, 29.3679s/40 iters), loss = 1.01118
I1029 08:44:50.297653 12802 solver.cpp:241]     Train net output #0: loss = 1.01118 (* 1 = 1.01118 loss)
I1029 08:44:50.297667 12802 sgd_solver.cpp:105] Iteration 60560, lr = 4.29275e-05
I1029 08:45:19.947333 12802 solver.cpp:222] Iteration 60600 (1.34912 iter/s, 29.649s/40 iters), loss = 1.36515
I1029 08:45:19.947393 12802 solver.cpp:241]     Train net output #0: loss = 1.36515 (* 1 = 1.36515 loss)
I1029 08:45:19.947408 12802 sgd_solver.cpp:105] Iteration 60600, lr = 4.27732e-05
I1029 08:45:49.585925 12802 solver.cpp:222] Iteration 60640 (1.34963 iter/s, 29.6378s/40 iters), loss = 1.09963
I1029 08:45:49.586120 12802 solver.cpp:241]     Train net output #0: loss = 1.09963 (* 1 = 1.09963 loss)
I1029 08:45:49.586144 12802 sgd_solver.cpp:105] Iteration 60640, lr = 4.26195e-05
I1029 08:46:19.509412 12802 solver.cpp:222] Iteration 60680 (1.33678 iter/s, 29.9226s/40 iters), loss = 1.60439
I1029 08:46:19.509466 12802 solver.cpp:241]     Train net output #0: loss = 1.60439 (* 1 = 1.60439 loss)
I1029 08:46:19.509482 12802 sgd_solver.cpp:105] Iteration 60680, lr = 4.24663e-05
I1029 08:46:49.355448 12802 solver.cpp:222] Iteration 60720 (1.34025 iter/s, 29.8453s/40 iters), loss = 1.49708
I1029 08:46:49.355656 12802 solver.cpp:241]     Train net output #0: loss = 1.49708 (* 1 = 1.49708 loss)
I1029 08:46:49.355679 12802 sgd_solver.cpp:105] Iteration 60720, lr = 4.23137e-05
I1029 08:47:19.790596 12802 solver.cpp:222] Iteration 60760 (1.31431 iter/s, 30.4342s/40 iters), loss = 1.22873
I1029 08:47:19.790796 12802 solver.cpp:241]     Train net output #0: loss = 1.22873 (* 1 = 1.22873 loss)
I1029 08:47:19.790813 12802 sgd_solver.cpp:105] Iteration 60760, lr = 4.21617e-05
I1029 08:47:49.782603 12802 solver.cpp:222] Iteration 60800 (1.33373 iter/s, 29.9911s/40 iters), loss = 1.47292
I1029 08:47:49.782657 12802 solver.cpp:241]     Train net output #0: loss = 1.47292 (* 1 = 1.47292 loss)
I1029 08:47:49.782672 12802 sgd_solver.cpp:105] Iteration 60800, lr = 4.20101e-05
I1029 08:48:19.831594 12802 solver.cpp:222] Iteration 60840 (1.33119 iter/s, 30.0482s/40 iters), loss = 1.50135
I1029 08:48:19.831804 12802 solver.cpp:241]     Train net output #0: loss = 1.50135 (* 1 = 1.50135 loss)
I1029 08:48:19.831821 12802 sgd_solver.cpp:105] Iteration 60840, lr = 4.18592e-05
I1029 08:48:50.602198 12802 solver.cpp:222] Iteration 60880 (1.29998 iter/s, 30.7697s/40 iters), loss = 1.46128
I1029 08:48:50.602380 12802 solver.cpp:241]     Train net output #0: loss = 1.46128 (* 1 = 1.46128 loss)
I1029 08:48:50.602396 12802 sgd_solver.cpp:105] Iteration 60880, lr = 4.17087e-05
I1029 08:49:21.792937 12802 solver.cpp:222] Iteration 60920 (1.28247 iter/s, 31.1898s/40 iters), loss = 1.70857
I1029 08:49:21.793128 12802 solver.cpp:241]     Train net output #0: loss = 1.70857 (* 1 = 1.70857 loss)
I1029 08:49:21.793145 12802 sgd_solver.cpp:105] Iteration 60920, lr = 4.15588e-05
I1029 08:49:52.437037 12802 solver.cpp:222] Iteration 60960 (1.30535 iter/s, 30.6432s/40 iters), loss = 1.57788
I1029 08:49:52.437275 12802 solver.cpp:241]     Train net output #0: loss = 1.57788 (* 1 = 1.57788 loss)
I1029 08:49:52.437294 12802 sgd_solver.cpp:105] Iteration 60960, lr = 4.14095e-05
I1029 08:50:34.582257 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_61000.caffemodel
I1029 08:50:34.724054 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_61000.solverstate
I1029 08:50:34.834699 12802 solver.cpp:334] Iteration 61000, Testing net (#0)
I1029 08:51:06.028987 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58968
I1029 08:51:06.029129 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80996
I1029 08:51:06.029141 12802 solver.cpp:401]     Test net output #2: loss = 1.82622 (* 1 = 1.82622 loss)
I1029 08:51:06.777096 12802 solver.cpp:222] Iteration 61000 (0.538082 iter/s, 74.3381s/40 iters), loss = 1.50702
I1029 08:51:06.777153 12802 solver.cpp:241]     Train net output #0: loss = 1.50702 (* 1 = 1.50702 loss)
I1029 08:51:06.777168 12802 sgd_solver.cpp:105] Iteration 61000, lr = 4.12607e-05
I1029 08:51:36.737370 12802 solver.cpp:222] Iteration 61040 (1.33514 iter/s, 29.9595s/40 iters), loss = 1.54325
I1029 08:51:36.737555 12802 solver.cpp:241]     Train net output #0: loss = 1.54325 (* 1 = 1.54325 loss)
I1029 08:51:36.737572 12802 sgd_solver.cpp:105] Iteration 61040, lr = 4.11124e-05
I1029 08:52:06.400463 12802 solver.cpp:222] Iteration 61080 (1.34852 iter/s, 29.6622s/40 iters), loss = 1.44348
I1029 08:52:06.400523 12802 solver.cpp:241]     Train net output #0: loss = 1.44348 (* 1 = 1.44348 loss)
I1029 08:52:06.400539 12802 sgd_solver.cpp:105] Iteration 61080, lr = 4.09646e-05
I1029 08:52:36.131564 12802 solver.cpp:222] Iteration 61120 (1.34543 iter/s, 29.7303s/40 iters), loss = 1.18205
I1029 08:52:36.131736 12802 solver.cpp:241]     Train net output #0: loss = 1.18205 (* 1 = 1.18205 loss)
I1029 08:52:36.131753 12802 sgd_solver.cpp:105] Iteration 61120, lr = 4.08174e-05
I1029 08:52:48.918206 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 08:53:05.856957 12802 solver.cpp:222] Iteration 61160 (1.34569 iter/s, 29.7245s/40 iters), loss = 1.49697
I1029 08:53:05.857014 12802 solver.cpp:241]     Train net output #0: loss = 1.49697 (* 1 = 1.49697 loss)
I1029 08:53:05.857030 12802 sgd_solver.cpp:105] Iteration 61160, lr = 4.06707e-05
I1029 08:53:35.560613 12802 solver.cpp:222] Iteration 61200 (1.34667 iter/s, 29.7029s/40 iters), loss = 1.1476
I1029 08:53:35.560750 12802 solver.cpp:241]     Train net output #0: loss = 1.1476 (* 1 = 1.1476 loss)
I1029 08:53:35.560767 12802 sgd_solver.cpp:105] Iteration 61200, lr = 4.05246e-05
I1029 08:54:05.112249 12802 solver.cpp:222] Iteration 61240 (1.3536 iter/s, 29.5508s/40 iters), loss = 1.23656
I1029 08:54:05.112305 12802 solver.cpp:241]     Train net output #0: loss = 1.23656 (* 1 = 1.23656 loss)
I1029 08:54:05.112318 12802 sgd_solver.cpp:105] Iteration 61240, lr = 4.03789e-05
I1029 08:54:34.748720 12802 solver.cpp:222] Iteration 61280 (1.34972 iter/s, 29.6357s/40 iters), loss = 1.60573
I1029 08:54:34.748888 12802 solver.cpp:241]     Train net output #0: loss = 1.60573 (* 1 = 1.60573 loss)
I1029 08:54:34.748905 12802 sgd_solver.cpp:105] Iteration 61280, lr = 4.02338e-05
I1029 08:56:14.349393 12802 solver.cpp:222] Iteration 61320 (0.401614 iter/s, 99.5982s/40 iters), loss = 1.70477
I1029 08:56:14.349596 12802 solver.cpp:241]     Train net output #0: loss = 1.70477 (* 1 = 1.70477 loss)
I1029 08:56:14.349616 12802 sgd_solver.cpp:105] Iteration 61320, lr = 4.00892e-05
I1029 08:56:45.141129 12802 solver.cpp:222] Iteration 61360 (1.29909 iter/s, 30.7908s/40 iters), loss = 1.22908
I1029 08:56:45.141330 12802 solver.cpp:241]     Train net output #0: loss = 1.22908 (* 1 = 1.22908 loss)
I1029 08:56:45.141345 12802 sgd_solver.cpp:105] Iteration 61360, lr = 3.99451e-05
I1029 08:57:15.894258 12802 solver.cpp:222] Iteration 61400 (1.30072 iter/s, 30.7522s/40 iters), loss = 1.32578
I1029 08:57:15.894516 12802 solver.cpp:241]     Train net output #0: loss = 1.32578 (* 1 = 1.32578 loss)
I1029 08:57:15.894554 12802 sgd_solver.cpp:105] Iteration 61400, lr = 3.98016e-05
I1029 08:57:46.270300 12802 solver.cpp:222] Iteration 61440 (1.31687 iter/s, 30.3751s/40 iters), loss = 1.53406
I1029 08:57:46.270454 12802 solver.cpp:241]     Train net output #0: loss = 1.53406 (* 1 = 1.53406 loss)
I1029 08:57:46.270472 12802 sgd_solver.cpp:105] Iteration 61440, lr = 3.96585e-05
I1029 08:58:16.703688 12802 solver.cpp:222] Iteration 61480 (1.31438 iter/s, 30.4325s/40 iters), loss = 1.37485
I1029 08:58:16.703851 12802 solver.cpp:241]     Train net output #0: loss = 1.37485 (* 1 = 1.37485 loss)
I1029 08:58:16.703869 12802 sgd_solver.cpp:105] Iteration 61480, lr = 3.9516e-05
I1029 08:58:31.154220 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_61500.caffemodel
I1029 08:58:31.304878 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_61500.solverstate
I1029 08:58:31.429123 12802 solver.cpp:334] Iteration 61500, Testing net (#0)
I1029 08:59:02.185223 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 08:59:02.393139 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5848
I1029 08:59:02.393188 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.814639
I1029 08:59:02.393199 12802 solver.cpp:401]     Test net output #2: loss = 1.83913 (* 1 = 1.83913 loss)
I1029 08:59:18.440619 12802 solver.cpp:222] Iteration 61520 (0.647927 iter/s, 61.7353s/40 iters), loss = 1.60913
I1029 08:59:18.440678 12802 solver.cpp:241]     Train net output #0: loss = 1.60913 (* 1 = 1.60913 loss)
I1029 08:59:18.440695 12802 sgd_solver.cpp:105] Iteration 61520, lr = 3.9374e-05
I1029 08:59:48.637162 12802 solver.cpp:222] Iteration 61560 (1.32469 iter/s, 30.1958s/40 iters), loss = 1.35567
I1029 08:59:48.637344 12802 solver.cpp:241]     Train net output #0: loss = 1.35567 (* 1 = 1.35567 loss)
I1029 08:59:48.637362 12802 sgd_solver.cpp:105] Iteration 61560, lr = 3.92325e-05
I1029 09:00:18.263185 12802 solver.cpp:222] Iteration 61600 (1.35021 iter/s, 29.6251s/40 iters), loss = 1.23663
I1029 09:00:18.263244 12802 solver.cpp:241]     Train net output #0: loss = 1.23663 (* 1 = 1.23663 loss)
I1029 09:00:18.263259 12802 sgd_solver.cpp:105] Iteration 61600, lr = 3.90915e-05
I1029 09:00:47.900336 12802 solver.cpp:222] Iteration 61640 (1.34969 iter/s, 29.6364s/40 iters), loss = 1.21562
I1029 09:00:47.900560 12802 solver.cpp:241]     Train net output #0: loss = 1.21562 (* 1 = 1.21562 loss)
I1029 09:00:47.900578 12802 sgd_solver.cpp:105] Iteration 61640, lr = 3.8951e-05
I1029 09:01:17.493597 12802 solver.cpp:222] Iteration 61680 (1.3517 iter/s, 29.5923s/40 iters), loss = 1.32767
I1029 09:01:17.493650 12802 solver.cpp:241]     Train net output #0: loss = 1.32767 (* 1 = 1.32767 loss)
I1029 09:01:17.493664 12802 sgd_solver.cpp:105] Iteration 61680, lr = 3.8811e-05
I1029 09:01:47.151435 12802 solver.cpp:222] Iteration 61720 (1.34875 iter/s, 29.6571s/40 iters), loss = 1.52624
I1029 09:01:47.151607 12802 solver.cpp:241]     Train net output #0: loss = 1.52624 (* 1 = 1.52624 loss)
I1029 09:01:47.151621 12802 sgd_solver.cpp:105] Iteration 61720, lr = 3.86716e-05
I1029 09:02:16.751371 12802 solver.cpp:222] Iteration 61760 (1.35139 iter/s, 29.599s/40 iters), loss = 1.65094
I1029 09:02:16.751430 12802 solver.cpp:241]     Train net output #0: loss = 1.65094 (* 1 = 1.65094 loss)
I1029 09:02:16.751444 12802 sgd_solver.cpp:105] Iteration 61760, lr = 3.85326e-05
I1029 09:02:46.359642 12802 solver.cpp:222] Iteration 61800 (1.35101 iter/s, 29.6075s/40 iters), loss = 1.4504
I1029 09:02:46.359788 12802 solver.cpp:241]     Train net output #0: loss = 1.4504 (* 1 = 1.4504 loss)
I1029 09:02:46.359805 12802 sgd_solver.cpp:105] Iteration 61800, lr = 3.83941e-05
I1029 09:03:15.961766 12802 solver.cpp:222] Iteration 61840 (1.35129 iter/s, 29.6013s/40 iters), loss = 1.34307
I1029 09:03:15.961824 12802 solver.cpp:241]     Train net output #0: loss = 1.34307 (* 1 = 1.34307 loss)
I1029 09:03:15.961839 12802 sgd_solver.cpp:105] Iteration 61840, lr = 3.82561e-05
I1029 09:03:45.603962 12802 solver.cpp:222] Iteration 61880 (1.34946 iter/s, 29.6414s/40 iters), loss = 1.78107
I1029 09:03:45.604189 12802 solver.cpp:241]     Train net output #0: loss = 1.78107 (* 1 = 1.78107 loss)
I1029 09:03:45.604207 12802 sgd_solver.cpp:105] Iteration 61880, lr = 3.81186e-05
I1029 09:04:16.131773 12802 solver.cpp:222] Iteration 61920 (1.31032 iter/s, 30.5269s/40 iters), loss = 1.44842
I1029 09:04:16.131912 12802 solver.cpp:241]     Train net output #0: loss = 1.44842 (* 1 = 1.44842 loss)
I1029 09:04:16.131934 12802 sgd_solver.cpp:105] Iteration 61920, lr = 3.79816e-05
I1029 09:04:46.338178 12802 solver.cpp:222] Iteration 61960 (1.32426 iter/s, 30.2055s/40 iters), loss = 1.41811
I1029 09:04:46.338321 12802 solver.cpp:241]     Train net output #0: loss = 1.41811 (* 1 = 1.41811 loss)
I1029 09:04:46.338335 12802 sgd_solver.cpp:105] Iteration 61960, lr = 3.78451e-05
I1029 09:05:15.182404 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_62000.caffemodel
I1029 09:05:15.336829 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_62000.solverstate
I1029 09:05:15.457018 12802 solver.cpp:334] Iteration 62000, Testing net (#0)
I1029 09:05:46.629541 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58824
I1029 09:05:46.629703 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8098
I1029 09:05:46.629715 12802 solver.cpp:401]     Test net output #2: loss = 1.82954 (* 1 = 1.82954 loss)
I1029 09:05:47.373335 12802 solver.cpp:222] Iteration 62000 (0.655377 iter/s, 61.0336s/40 iters), loss = 1.36259
I1029 09:05:47.373373 12802 solver.cpp:241]     Train net output #0: loss = 1.36259 (* 1 = 1.36259 loss)
I1029 09:05:47.373392 12802 sgd_solver.cpp:105] Iteration 62000, lr = 3.77091e-05
I1029 09:06:16.852618 12802 solver.cpp:222] Iteration 62040 (1.35692 iter/s, 29.4785s/40 iters), loss = 1.25695
I1029 09:06:16.852816 12802 solver.cpp:241]     Train net output #0: loss = 1.25695 (* 1 = 1.25695 loss)
I1029 09:06:16.852833 12802 sgd_solver.cpp:105] Iteration 62040, lr = 3.75736e-05
I1029 09:06:46.255645 12802 solver.cpp:222] Iteration 62080 (1.36045 iter/s, 29.4021s/40 iters), loss = 1.78045
I1029 09:06:46.255710 12802 solver.cpp:241]     Train net output #0: loss = 1.78045 (* 1 = 1.78045 loss)
I1029 09:06:46.255726 12802 sgd_solver.cpp:105] Iteration 62080, lr = 3.74386e-05
I1029 09:07:15.692785 12802 solver.cpp:222] Iteration 62120 (1.35886 iter/s, 29.4364s/40 iters), loss = 1.29138
I1029 09:07:15.692881 12802 solver.cpp:241]     Train net output #0: loss = 1.29138 (* 1 = 1.29138 loss)
I1029 09:07:15.692898 12802 sgd_solver.cpp:105] Iteration 62120, lr = 3.7304e-05
I1029 09:07:45.126792 12802 solver.cpp:222] Iteration 62160 (1.35901 iter/s, 29.4332s/40 iters), loss = 1.18298
I1029 09:07:45.126855 12802 solver.cpp:241]     Train net output #0: loss = 1.18298 (* 1 = 1.18298 loss)
I1029 09:07:45.126871 12802 sgd_solver.cpp:105] Iteration 62160, lr = 3.717e-05
I1029 09:08:14.588132 12802 solver.cpp:222] Iteration 62200 (1.35775 iter/s, 29.4606s/40 iters), loss = 1.64586
I1029 09:08:14.588229 12802 solver.cpp:241]     Train net output #0: loss = 1.64586 (* 1 = 1.64586 loss)
I1029 09:08:14.588246 12802 sgd_solver.cpp:105] Iteration 62200, lr = 3.70364e-05
I1029 09:08:44.574599 12802 solver.cpp:222] Iteration 62240 (1.33397 iter/s, 29.9857s/40 iters), loss = 1.28222
I1029 09:08:44.574661 12802 solver.cpp:241]     Train net output #0: loss = 1.28222 (* 1 = 1.28222 loss)
I1029 09:08:44.574676 12802 sgd_solver.cpp:105] Iteration 62240, lr = 3.69033e-05
I1029 09:09:14.557483 12802 solver.cpp:222] Iteration 62280 (1.33413 iter/s, 29.9821s/40 iters), loss = 1.562
I1029 09:09:14.557694 12802 solver.cpp:241]     Train net output #0: loss = 1.562 (* 1 = 1.562 loss)
I1029 09:09:14.557711 12802 sgd_solver.cpp:105] Iteration 62280, lr = 3.67707e-05
I1029 09:09:45.501222 12802 solver.cpp:222] Iteration 62320 (1.29271 iter/s, 30.9428s/40 iters), loss = 1.42371
I1029 09:09:45.501448 12802 solver.cpp:241]     Train net output #0: loss = 1.42371 (* 1 = 1.42371 loss)
I1029 09:09:45.501466 12802 sgd_solver.cpp:105] Iteration 62320, lr = 3.66385e-05
I1029 09:10:15.726789 12802 solver.cpp:222] Iteration 62360 (1.32342 iter/s, 30.2246s/40 iters), loss = 1.41479
I1029 09:10:15.726999 12802 solver.cpp:241]     Train net output #0: loss = 1.41479 (* 1 = 1.41479 loss)
I1029 09:10:15.727015 12802 sgd_solver.cpp:105] Iteration 62360, lr = 3.65068e-05
I1029 09:11:20.993973 12802 solver.cpp:222] Iteration 62400 (0.612882 iter/s, 65.2655s/40 iters), loss = 1.36887
I1029 09:11:20.994117 12802 solver.cpp:241]     Train net output #0: loss = 1.36887 (* 1 = 1.36887 loss)
I1029 09:11:20.994134 12802 sgd_solver.cpp:105] Iteration 62400, lr = 3.63756e-05
I1029 09:11:51.332650 12802 solver.cpp:222] Iteration 62440 (1.31849 iter/s, 30.3378s/40 iters), loss = 1.56564
I1029 09:11:51.332782 12802 solver.cpp:241]     Train net output #0: loss = 1.56564 (* 1 = 1.56564 loss)
I1029 09:11:51.332800 12802 sgd_solver.cpp:105] Iteration 62440, lr = 3.62449e-05
I1029 09:12:21.484864 12802 solver.cpp:222] Iteration 62480 (1.32664 iter/s, 30.1514s/40 iters), loss = 1.36897
I1029 09:12:21.485018 12802 solver.cpp:241]     Train net output #0: loss = 1.36897 (* 1 = 1.36897 loss)
I1029 09:12:21.485031 12802 sgd_solver.cpp:105] Iteration 62480, lr = 3.61147e-05
I1029 09:12:35.560436 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_62500.caffemodel
I1029 09:12:35.698432 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_62500.solverstate
I1029 09:12:35.803632 12802 solver.cpp:334] Iteration 62500, Testing net (#0)
I1029 09:13:06.791204 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 09:13:07.003870 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5846
I1029 09:13:07.003916 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81532
I1029 09:13:07.003931 12802 solver.cpp:401]     Test net output #2: loss = 1.83282 (* 1 = 1.83282 loss)
I1029 09:13:23.035090 12802 solver.cpp:222] Iteration 62520 (0.649893 iter/s, 61.5486s/40 iters), loss = 1.44364
I1029 09:13:23.035158 12802 solver.cpp:241]     Train net output #0: loss = 1.44364 (* 1 = 1.44364 loss)
I1029 09:13:23.035179 12802 sgd_solver.cpp:105] Iteration 62520, lr = 3.59849e-05
I1029 09:13:53.714630 12802 solver.cpp:222] Iteration 62560 (1.30383 iter/s, 30.6787s/40 iters), loss = 1.39405
I1029 09:13:53.714867 12802 solver.cpp:241]     Train net output #0: loss = 1.39405 (* 1 = 1.39405 loss)
I1029 09:13:53.714884 12802 sgd_solver.cpp:105] Iteration 62560, lr = 3.58556e-05
I1029 09:14:23.300161 12802 solver.cpp:222] Iteration 62600 (1.35206 iter/s, 29.5846s/40 iters), loss = 1.66619
I1029 09:14:23.300222 12802 solver.cpp:241]     Train net output #0: loss = 1.66619 (* 1 = 1.66619 loss)
I1029 09:14:23.300235 12802 sgd_solver.cpp:105] Iteration 62600, lr = 3.57267e-05
I1029 09:14:53.462890 12802 solver.cpp:222] Iteration 62640 (1.32617 iter/s, 30.1619s/40 iters), loss = 0.956677
I1029 09:14:53.463081 12802 solver.cpp:241]     Train net output #0: loss = 0.956677 (* 1 = 0.956677 loss)
I1029 09:14:53.463099 12802 sgd_solver.cpp:105] Iteration 62640, lr = 3.55983e-05
I1029 09:15:23.008921 12802 solver.cpp:222] Iteration 62680 (1.35386 iter/s, 29.5451s/40 iters), loss = 1.47845
I1029 09:15:23.008977 12802 solver.cpp:241]     Train net output #0: loss = 1.47845 (* 1 = 1.47845 loss)
I1029 09:15:23.008996 12802 sgd_solver.cpp:105] Iteration 62680, lr = 3.54704e-05
I1029 09:15:52.488261 12802 solver.cpp:222] Iteration 62720 (1.35692 iter/s, 29.4786s/40 iters), loss = 1.78307
I1029 09:15:52.488410 12802 solver.cpp:241]     Train net output #0: loss = 1.78307 (* 1 = 1.78307 loss)
I1029 09:15:52.488427 12802 sgd_solver.cpp:105] Iteration 62720, lr = 3.53429e-05
I1029 09:16:21.933990 12802 solver.cpp:222] Iteration 62760 (1.35847 iter/s, 29.4449s/40 iters), loss = 1.50013
I1029 09:16:21.934048 12802 solver.cpp:241]     Train net output #0: loss = 1.50013 (* 1 = 1.50013 loss)
I1029 09:16:21.934064 12802 sgd_solver.cpp:105] Iteration 62760, lr = 3.52159e-05
I1029 09:16:51.371182 12802 solver.cpp:222] Iteration 62800 (1.35886 iter/s, 29.4364s/40 iters), loss = 1.63306
I1029 09:16:51.371399 12802 solver.cpp:241]     Train net output #0: loss = 1.63306 (* 1 = 1.63306 loss)
I1029 09:16:51.371417 12802 sgd_solver.cpp:105] Iteration 62800, lr = 3.50893e-05
I1029 09:17:20.811797 12802 solver.cpp:222] Iteration 62840 (1.35871 iter/s, 29.4397s/40 iters), loss = 1.47106
I1029 09:17:20.811853 12802 solver.cpp:241]     Train net output #0: loss = 1.47106 (* 1 = 1.47106 loss)
I1029 09:17:20.811868 12802 sgd_solver.cpp:105] Iteration 62840, lr = 3.49632e-05
I1029 09:17:50.250743 12802 solver.cpp:222] Iteration 62880 (1.35878 iter/s, 29.4382s/40 iters), loss = 1.54984
I1029 09:17:50.250830 12802 solver.cpp:241]     Train net output #0: loss = 1.54984 (* 1 = 1.54984 loss)
I1029 09:17:50.250844 12802 sgd_solver.cpp:105] Iteration 62880, lr = 3.48376e-05
I1029 09:18:19.775697 12802 solver.cpp:222] Iteration 62920 (1.35482 iter/s, 29.5242s/40 iters), loss = 1.41664
I1029 09:18:19.775758 12802 solver.cpp:241]     Train net output #0: loss = 1.41664 (* 1 = 1.41664 loss)
I1029 09:18:19.775773 12802 sgd_solver.cpp:105] Iteration 62920, lr = 3.47124e-05
I1029 09:18:49.373365 12802 solver.cpp:222] Iteration 62960 (1.35149 iter/s, 29.5969s/40 iters), loss = 1.4627
I1029 09:18:49.373517 12802 solver.cpp:241]     Train net output #0: loss = 1.4627 (* 1 = 1.4627 loss)
I1029 09:18:49.373533 12802 sgd_solver.cpp:105] Iteration 62960, lr = 3.45876e-05
I1029 09:19:18.230199 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_63000.caffemodel
I1029 09:19:18.371058 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_63000.solverstate
I1029 09:19:18.482241 12802 solver.cpp:334] Iteration 63000, Testing net (#0)
I1029 09:19:49.700929 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58956
I1029 09:19:49.701066 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81008
I1029 09:19:49.701078 12802 solver.cpp:401]     Test net output #2: loss = 1.82728 (* 1 = 1.82728 loss)
I1029 09:19:50.455114 12802 solver.cpp:222] Iteration 63000 (0.654877 iter/s, 61.0802s/40 iters), loss = 1.54707
I1029 09:19:50.455171 12802 solver.cpp:241]     Train net output #0: loss = 1.54707 (* 1 = 1.54707 loss)
I1029 09:19:50.455188 12802 sgd_solver.cpp:105] Iteration 63000, lr = 3.44633e-05
I1029 09:20:20.064075 12802 solver.cpp:222] Iteration 63040 (1.35098 iter/s, 29.6082s/40 iters), loss = 1.38786
I1029 09:20:20.064234 12802 solver.cpp:241]     Train net output #0: loss = 1.38786 (* 1 = 1.38786 loss)
I1029 09:20:20.064251 12802 sgd_solver.cpp:105] Iteration 63040, lr = 3.43395e-05
I1029 09:20:50.079485 12802 solver.cpp:222] Iteration 63080 (1.33269 iter/s, 30.0145s/40 iters), loss = 1.20083
I1029 09:20:50.079617 12802 solver.cpp:241]     Train net output #0: loss = 1.20083 (* 1 = 1.20083 loss)
I1029 09:20:50.079634 12802 sgd_solver.cpp:105] Iteration 63080, lr = 3.4216e-05
I1029 09:21:21.015346 12802 solver.cpp:222] Iteration 63120 (1.29303 iter/s, 30.935s/40 iters), loss = 1.31095
I1029 09:21:21.015516 12802 solver.cpp:241]     Train net output #0: loss = 1.31095 (* 1 = 1.31095 loss)
I1029 09:21:21.015532 12802 sgd_solver.cpp:105] Iteration 63120, lr = 3.40931e-05
I1029 09:21:51.384111 12802 solver.cpp:222] Iteration 63160 (1.31718 iter/s, 30.3679s/40 iters), loss = 1.43089
I1029 09:21:51.384263 12802 solver.cpp:241]     Train net output #0: loss = 1.43089 (* 1 = 1.43089 loss)
I1029 09:21:51.384280 12802 sgd_solver.cpp:105] Iteration 63160, lr = 3.39706e-05
I1029 09:22:21.440732 12802 solver.cpp:222] Iteration 63200 (1.33086 iter/s, 30.0558s/40 iters), loss = 1.26499
I1029 09:22:21.440937 12802 solver.cpp:241]     Train net output #0: loss = 1.26499 (* 1 = 1.26499 loss)
I1029 09:22:21.440955 12802 sgd_solver.cpp:105] Iteration 63200, lr = 3.38485e-05
I1029 09:22:51.217928 12802 solver.cpp:222] Iteration 63240 (1.34335 iter/s, 29.7763s/40 iters), loss = 1.41675
I1029 09:22:51.217980 12802 solver.cpp:241]     Train net output #0: loss = 1.41675 (* 1 = 1.41675 loss)
I1029 09:22:51.217996 12802 sgd_solver.cpp:105] Iteration 63240, lr = 3.37268e-05
I1029 09:25:24.465617 12802 solver.cpp:222] Iteration 63280 (0.261021 iter/s, 153.244s/40 iters), loss = 1.64155
I1029 09:25:24.465828 12802 solver.cpp:241]     Train net output #0: loss = 1.64155 (* 1 = 1.64155 loss)
I1029 09:25:24.465847 12802 sgd_solver.cpp:105] Iteration 63280, lr = 3.36056e-05
I1029 09:26:25.552381 12802 solver.cpp:222] Iteration 63320 (0.654823 iter/s, 61.0852s/40 iters), loss = 1.62806
I1029 09:26:25.552580 12802 solver.cpp:241]     Train net output #0: loss = 1.62806 (* 1 = 1.62806 loss)
I1029 09:26:25.552597 12802 sgd_solver.cpp:105] Iteration 63320, lr = 3.34848e-05
I1029 09:27:04.983039 12802 solver.cpp:222] Iteration 63360 (1.01447 iter/s, 39.4296s/40 iters), loss = 1.41841
I1029 09:27:04.983234 12802 solver.cpp:241]     Train net output #0: loss = 1.41841 (* 1 = 1.41841 loss)
I1029 09:27:04.983252 12802 sgd_solver.cpp:105] Iteration 63360, lr = 3.33645e-05
I1029 09:27:35.496299 12802 solver.cpp:222] Iteration 63400 (1.31094 iter/s, 30.5124s/40 iters), loss = 1.32493
I1029 09:27:35.496485 12802 solver.cpp:241]     Train net output #0: loss = 1.32493 (* 1 = 1.32493 loss)
I1029 09:27:35.496506 12802 sgd_solver.cpp:105] Iteration 63400, lr = 3.32446e-05
I1029 09:28:05.093487 12802 solver.cpp:222] Iteration 63440 (1.35152 iter/s, 29.5963s/40 iters), loss = 1.29585
I1029 09:28:05.093547 12802 solver.cpp:241]     Train net output #0: loss = 1.29585 (* 1 = 1.29585 loss)
I1029 09:28:05.093562 12802 sgd_solver.cpp:105] Iteration 63440, lr = 3.31251e-05
I1029 09:28:34.783105 12802 solver.cpp:222] Iteration 63480 (1.34731 iter/s, 29.6889s/40 iters), loss = 1.48225
I1029 09:28:34.783339 12802 solver.cpp:241]     Train net output #0: loss = 1.48225 (* 1 = 1.48225 loss)
I1029 09:28:34.783356 12802 sgd_solver.cpp:105] Iteration 63480, lr = 3.30061e-05
I1029 09:28:48.835965 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_63500.caffemodel
I1029 09:28:48.978170 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_63500.solverstate
I1029 09:28:49.098740 12802 solver.cpp:334] Iteration 63500, Testing net (#0)
I1029 09:29:19.988937 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 09:29:20.196094 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.584801
I1029 09:29:20.196142 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81524
I1029 09:29:20.196154 12802 solver.cpp:401]     Test net output #2: loss = 1.83019 (* 1 = 1.83019 loss)
I1029 09:29:36.329715 12802 solver.cpp:222] Iteration 63520 (0.649932 iter/s, 61.5449s/40 iters), loss = 1.5148
I1029 09:29:36.329761 12802 solver.cpp:241]     Train net output #0: loss = 1.5148 (* 1 = 1.5148 loss)
I1029 09:29:36.329776 12802 sgd_solver.cpp:105] Iteration 63520, lr = 3.28875e-05
I1029 09:30:06.152658 12802 solver.cpp:222] Iteration 63560 (1.34128 iter/s, 29.8222s/40 iters), loss = 1.32435
I1029 09:30:06.152853 12802 solver.cpp:241]     Train net output #0: loss = 1.32435 (* 1 = 1.32435 loss)
I1029 09:30:06.152869 12802 sgd_solver.cpp:105] Iteration 63560, lr = 3.27693e-05
I1029 09:30:35.693076 12802 solver.cpp:222] Iteration 63600 (1.35412 iter/s, 29.5395s/40 iters), loss = 1.38939
I1029 09:30:35.693137 12802 solver.cpp:241]     Train net output #0: loss = 1.38939 (* 1 = 1.38939 loss)
I1029 09:30:35.693150 12802 sgd_solver.cpp:105] Iteration 63600, lr = 3.26515e-05
I1029 09:31:04.654335 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 09:31:05.291642 12802 solver.cpp:222] Iteration 63640 (1.35145 iter/s, 29.5978s/40 iters), loss = 1.33811
I1029 09:31:05.291702 12802 solver.cpp:241]     Train net output #0: loss = 1.33811 (* 1 = 1.33811 loss)
I1029 09:31:05.291714 12802 sgd_solver.cpp:105] Iteration 63640, lr = 3.25342e-05
I1029 09:31:34.937438 12802 solver.cpp:222] Iteration 63680 (1.3493 iter/s, 29.645s/40 iters), loss = 1.50603
I1029 09:31:34.937674 12802 solver.cpp:241]     Train net output #0: loss = 1.50603 (* 1 = 1.50603 loss)
I1029 09:31:34.937695 12802 sgd_solver.cpp:105] Iteration 63680, lr = 3.24172e-05
I1029 09:32:04.431104 12802 solver.cpp:222] Iteration 63720 (1.35627 iter/s, 29.4927s/40 iters), loss = 1.23718
I1029 09:32:04.431160 12802 solver.cpp:241]     Train net output #0: loss = 1.23718 (* 1 = 1.23718 loss)
I1029 09:32:04.431176 12802 sgd_solver.cpp:105] Iteration 63720, lr = 3.23007e-05
I1029 09:32:34.015453 12802 solver.cpp:222] Iteration 63760 (1.3521 iter/s, 29.5836s/40 iters), loss = 1.27948
I1029 09:32:34.015641 12802 solver.cpp:241]     Train net output #0: loss = 1.27948 (* 1 = 1.27948 loss)
I1029 09:32:34.015655 12802 sgd_solver.cpp:105] Iteration 63760, lr = 3.21847e-05
I1029 09:33:03.461658 12802 solver.cpp:222] Iteration 63800 (1.35845 iter/s, 29.4453s/40 iters), loss = 1.51492
I1029 09:33:03.461714 12802 solver.cpp:241]     Train net output #0: loss = 1.51492 (* 1 = 1.51492 loss)
I1029 09:33:03.461729 12802 sgd_solver.cpp:105] Iteration 63800, lr = 3.2069e-05
I1029 09:33:32.904722 12802 solver.cpp:222] Iteration 63840 (1.35859 iter/s, 29.4423s/40 iters), loss = 1.1503
I1029 09:33:32.904863 12802 solver.cpp:241]     Train net output #0: loss = 1.1503 (* 1 = 1.1503 loss)
I1029 09:33:32.904880 12802 sgd_solver.cpp:105] Iteration 63840, lr = 3.19537e-05
I1029 09:34:02.361086 12802 solver.cpp:222] Iteration 63880 (1.35798 iter/s, 29.4555s/40 iters), loss = 1.44246
I1029 09:34:02.361141 12802 solver.cpp:241]     Train net output #0: loss = 1.44246 (* 1 = 1.44246 loss)
I1029 09:34:02.361161 12802 sgd_solver.cpp:105] Iteration 63880, lr = 3.18389e-05
I1029 09:34:31.803318 12802 solver.cpp:222] Iteration 63920 (1.35863 iter/s, 29.4415s/40 iters), loss = 1.59335
I1029 09:34:31.803411 12802 solver.cpp:241]     Train net output #0: loss = 1.59335 (* 1 = 1.59335 loss)
I1029 09:34:31.803424 12802 sgd_solver.cpp:105] Iteration 63920, lr = 3.17245e-05
I1029 09:35:01.304076 12802 solver.cpp:222] Iteration 63960 (1.35593 iter/s, 29.5s/40 iters), loss = 1.41198
I1029 09:35:01.304136 12802 solver.cpp:241]     Train net output #0: loss = 1.41198 (* 1 = 1.41198 loss)
I1029 09:35:01.304150 12802 sgd_solver.cpp:105] Iteration 63960, lr = 3.16105e-05
I1029 09:35:30.072026 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_64000.caffemodel
I1029 09:35:30.215911 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_64000.solverstate
I1029 09:35:30.337234 12802 solver.cpp:334] Iteration 64000, Testing net (#0)
I1029 09:36:01.375385 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58948
I1029 09:36:01.375452 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.810159
I1029 09:36:01.375464 12802 solver.cpp:401]     Test net output #2: loss = 1.83372 (* 1 = 1.83372 loss)
I1029 09:36:02.128249 12802 solver.cpp:222] Iteration 64000 (0.657649 iter/s, 60.8227s/40 iters), loss = 1.35172
I1029 09:36:02.128314 12802 solver.cpp:241]     Train net output #0: loss = 1.35172 (* 1 = 1.35172 loss)
I1029 09:36:02.128329 12802 sgd_solver.cpp:105] Iteration 64000, lr = 3.14969e-05
I1029 09:36:31.674430 12802 solver.cpp:222] Iteration 64040 (1.35385 iter/s, 29.5454s/40 iters), loss = 1.17721
I1029 09:36:31.674536 12802 solver.cpp:241]     Train net output #0: loss = 1.17721 (* 1 = 1.17721 loss)
I1029 09:36:31.674553 12802 sgd_solver.cpp:105] Iteration 64040, lr = 3.13837e-05
I1029 09:37:01.282747 12802 solver.cpp:222] Iteration 64080 (1.35101 iter/s, 29.6075s/40 iters), loss = 1.48602
I1029 09:37:01.282806 12802 solver.cpp:241]     Train net output #0: loss = 1.48602 (* 1 = 1.48602 loss)
I1029 09:37:01.282822 12802 sgd_solver.cpp:105] Iteration 64080, lr = 3.12709e-05
I1029 09:37:31.138005 12802 solver.cpp:222] Iteration 64120 (1.33983 iter/s, 29.8545s/40 iters), loss = 1.51449
I1029 09:37:31.138159 12802 solver.cpp:241]     Train net output #0: loss = 1.51449 (* 1 = 1.51449 loss)
I1029 09:37:31.138200 12802 sgd_solver.cpp:105] Iteration 64120, lr = 3.11585e-05
I1029 09:38:00.639904 12802 solver.cpp:222] Iteration 64160 (1.35588 iter/s, 29.501s/40 iters), loss = 1.35303
I1029 09:38:00.639966 12802 solver.cpp:241]     Train net output #0: loss = 1.35303 (* 1 = 1.35303 loss)
I1029 09:38:00.639981 12802 sgd_solver.cpp:105] Iteration 64160, lr = 3.10465e-05
I1029 09:38:30.176389 12802 solver.cpp:222] Iteration 64200 (1.35429 iter/s, 29.5357s/40 iters), loss = 1.34781
I1029 09:38:30.176532 12802 solver.cpp:241]     Train net output #0: loss = 1.34781 (* 1 = 1.34781 loss)
I1029 09:38:30.176548 12802 sgd_solver.cpp:105] Iteration 64200, lr = 3.0935e-05
I1029 09:38:59.769526 12802 solver.cpp:222] Iteration 64240 (1.3517 iter/s, 29.5923s/40 iters), loss = 1.49388
I1029 09:38:59.769583 12802 solver.cpp:241]     Train net output #0: loss = 1.49388 (* 1 = 1.49388 loss)
I1029 09:38:59.769598 12802 sgd_solver.cpp:105] Iteration 64240, lr = 3.08238e-05
I1029 09:39:29.349855 12802 solver.cpp:222] Iteration 64280 (1.35229 iter/s, 29.5796s/40 iters), loss = 1.28638
I1029 09:39:29.349951 12802 solver.cpp:241]     Train net output #0: loss = 1.28638 (* 1 = 1.28638 loss)
I1029 09:39:29.349968 12802 sgd_solver.cpp:105] Iteration 64280, lr = 3.0713e-05
I1029 09:39:59.031635 12802 solver.cpp:222] Iteration 64320 (1.34766 iter/s, 29.681s/40 iters), loss = 1.33013
I1029 09:39:59.031697 12802 solver.cpp:241]     Train net output #0: loss = 1.33013 (* 1 = 1.33013 loss)
I1029 09:39:59.031711 12802 sgd_solver.cpp:105] Iteration 64320, lr = 3.06026e-05
I1029 09:40:28.551354 12802 solver.cpp:222] Iteration 64360 (1.35506 iter/s, 29.519s/40 iters), loss = 1.2851
I1029 09:40:28.551558 12802 solver.cpp:241]     Train net output #0: loss = 1.2851 (* 1 = 1.2851 loss)
I1029 09:40:28.551574 12802 sgd_solver.cpp:105] Iteration 64360, lr = 3.04927e-05
I1029 09:40:58.208041 12802 solver.cpp:222] Iteration 64400 (1.34881 iter/s, 29.6558s/40 iters), loss = 1.25037
I1029 09:40:58.208101 12802 solver.cpp:241]     Train net output #0: loss = 1.25037 (* 1 = 1.25037 loss)
I1029 09:40:58.208117 12802 sgd_solver.cpp:105] Iteration 64400, lr = 3.03831e-05
I1029 09:41:27.684391 12802 solver.cpp:222] Iteration 64440 (1.35706 iter/s, 29.4756s/40 iters), loss = 1.45179
I1029 09:41:27.684550 12802 solver.cpp:241]     Train net output #0: loss = 1.45179 (* 1 = 1.45179 loss)
I1029 09:41:27.684566 12802 sgd_solver.cpp:105] Iteration 64440, lr = 3.02739e-05
I1029 09:41:57.128320 12802 solver.cpp:222] Iteration 64480 (1.35855 iter/s, 29.4431s/40 iters), loss = 1.38828
I1029 09:41:57.128379 12802 solver.cpp:241]     Train net output #0: loss = 1.38828 (* 1 = 1.38828 loss)
I1029 09:41:57.128394 12802 sgd_solver.cpp:105] Iteration 64480, lr = 3.01651e-05
I1029 09:42:11.096290 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_64500.caffemodel
I1029 09:42:11.242180 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_64500.solverstate
I1029 09:42:11.356037 12802 solver.cpp:334] Iteration 64500, Testing net (#0)
I1029 09:42:42.321199 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 09:42:42.534835 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58516
I1029 09:42:42.534891 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81508
I1029 09:42:42.534903 12802 solver.cpp:401]     Test net output #2: loss = 1.83357 (* 1 = 1.83357 loss)
I1029 09:42:58.349201 12802 solver.cpp:222] Iteration 64520 (0.653388 iter/s, 61.2194s/40 iters), loss = 1.28314
I1029 09:42:58.349261 12802 solver.cpp:241]     Train net output #0: loss = 1.28314 (* 1 = 1.28314 loss)
I1029 09:42:58.349277 12802 sgd_solver.cpp:105] Iteration 64520, lr = 3.00567e-05
I1029 09:43:27.973500 12802 solver.cpp:222] Iteration 64560 (1.35028 iter/s, 29.6235s/40 iters), loss = 1.28916
I1029 09:43:27.973753 12802 solver.cpp:241]     Train net output #0: loss = 1.28916 (* 1 = 1.28916 loss)
I1029 09:43:27.973772 12802 sgd_solver.cpp:105] Iteration 64560, lr = 2.99487e-05
I1029 09:43:57.579524 12802 solver.cpp:222] Iteration 64600 (1.35112 iter/s, 29.6051s/40 iters), loss = 1.53453
I1029 09:43:57.579581 12802 solver.cpp:241]     Train net output #0: loss = 1.53453 (* 1 = 1.53453 loss)
I1029 09:43:57.579597 12802 sgd_solver.cpp:105] Iteration 64600, lr = 2.9841e-05
I1029 09:44:27.656417 12802 solver.cpp:222] Iteration 64640 (1.32996 iter/s, 30.0761s/40 iters), loss = 1.31279
I1029 09:44:27.656646 12802 solver.cpp:241]     Train net output #0: loss = 1.31279 (* 1 = 1.31279 loss)
I1029 09:44:27.656663 12802 sgd_solver.cpp:105] Iteration 64640, lr = 2.97338e-05
I1029 09:44:57.427271 12802 solver.cpp:222] Iteration 64680 (1.34364 iter/s, 29.7699s/40 iters), loss = 1.35086
I1029 09:44:57.427330 12802 solver.cpp:241]     Train net output #0: loss = 1.35086 (* 1 = 1.35086 loss)
I1029 09:44:57.427345 12802 sgd_solver.cpp:105] Iteration 64680, lr = 2.96269e-05
I1029 09:45:27.060792 12802 solver.cpp:222] Iteration 64720 (1.34986 iter/s, 29.6328s/40 iters), loss = 1.17386
I1029 09:45:27.060933 12802 solver.cpp:241]     Train net output #0: loss = 1.17386 (* 1 = 1.17386 loss)
I1029 09:45:27.060950 12802 sgd_solver.cpp:105] Iteration 64720, lr = 2.95204e-05
I1029 09:45:57.818147 12802 solver.cpp:222] Iteration 64760 (1.30054 iter/s, 30.7565s/40 iters), loss = 1.54237
I1029 09:45:57.818290 12802 solver.cpp:241]     Train net output #0: loss = 1.54237 (* 1 = 1.54237 loss)
I1029 09:45:57.818307 12802 sgd_solver.cpp:105] Iteration 64760, lr = 2.94144e-05
I1029 09:46:27.402602 12802 solver.cpp:222] Iteration 64800 (1.3521 iter/s, 29.5836s/40 iters), loss = 1.54012
I1029 09:46:27.402664 12802 solver.cpp:241]     Train net output #0: loss = 1.54012 (* 1 = 1.54012 loss)
I1029 09:46:27.402680 12802 sgd_solver.cpp:105] Iteration 64800, lr = 2.93086e-05
I1029 09:46:57.549302 12802 solver.cpp:222] Iteration 64840 (1.32688 iter/s, 30.1459s/40 iters), loss = 1.19889
I1029 09:46:57.549506 12802 solver.cpp:241]     Train net output #0: loss = 1.19889 (* 1 = 1.19889 loss)
I1029 09:46:57.549521 12802 sgd_solver.cpp:105] Iteration 64840, lr = 2.92033e-05
I1029 09:47:27.258865 12802 solver.cpp:222] Iteration 64880 (1.34641 iter/s, 29.7087s/40 iters), loss = 1.53517
I1029 09:47:27.258927 12802 solver.cpp:241]     Train net output #0: loss = 1.53517 (* 1 = 1.53517 loss)
I1029 09:47:27.258941 12802 sgd_solver.cpp:105] Iteration 64880, lr = 2.90984e-05
I1029 09:47:56.798697 12802 solver.cpp:222] Iteration 64920 (1.35414 iter/s, 29.5391s/40 iters), loss = 1.55804
I1029 09:47:56.798866 12802 solver.cpp:241]     Train net output #0: loss = 1.55804 (* 1 = 1.55804 loss)
I1029 09:47:56.798882 12802 sgd_solver.cpp:105] Iteration 64920, lr = 2.89938e-05
I1029 09:48:26.208853 12802 solver.cpp:222] Iteration 64960 (1.36011 iter/s, 29.4093s/40 iters), loss = 1.01826
I1029 09:48:26.208909 12802 solver.cpp:241]     Train net output #0: loss = 1.01826 (* 1 = 1.01826 loss)
I1029 09:48:26.208930 12802 sgd_solver.cpp:105] Iteration 64960, lr = 2.88896e-05
I1029 09:48:54.892750 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_65000.caffemodel
I1029 09:48:55.045604 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_65000.solverstate
I1029 09:48:55.157754 12802 solver.cpp:334] Iteration 65000, Testing net (#0)
I1029 09:49:26.382690 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58904
I1029 09:49:26.382766 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81064
I1029 09:49:26.382778 12802 solver.cpp:401]     Test net output #2: loss = 1.82847 (* 1 = 1.82847 loss)
I1029 09:49:27.139979 12802 solver.cpp:222] Iteration 65000 (0.656495 iter/s, 60.9297s/40 iters), loss = 1.5582
I1029 09:49:27.140036 12802 solver.cpp:241]     Train net output #0: loss = 1.5582 (* 1 = 1.5582 loss)
I1029 09:49:27.140053 12802 sgd_solver.cpp:105] Iteration 65000, lr = 2.87858e-05
I1029 09:49:56.536048 12802 solver.cpp:222] Iteration 65040 (1.36076 iter/s, 29.3953s/40 iters), loss = 1.3667
I1029 09:49:56.536164 12802 solver.cpp:241]     Train net output #0: loss = 1.3667 (* 1 = 1.3667 loss)
I1029 09:49:56.536178 12802 sgd_solver.cpp:105] Iteration 65040, lr = 2.86823e-05
I1029 09:50:26.006414 12802 solver.cpp:222] Iteration 65080 (1.35733 iter/s, 29.4695s/40 iters), loss = 1.34676
I1029 09:50:26.006476 12802 solver.cpp:241]     Train net output #0: loss = 1.34676 (* 1 = 1.34676 loss)
I1029 09:50:26.006492 12802 sgd_solver.cpp:105] Iteration 65080, lr = 2.85792e-05
I1029 09:50:55.501782 12802 solver.cpp:222] Iteration 65120 (1.35618 iter/s, 29.4946s/40 iters), loss = 1.08944
I1029 09:50:55.502015 12802 solver.cpp:241]     Train net output #0: loss = 1.08944 (* 1 = 1.08944 loss)
I1029 09:50:55.502033 12802 sgd_solver.cpp:105] Iteration 65120, lr = 2.84765e-05
I1029 09:51:24.986515 12802 solver.cpp:222] Iteration 65160 (1.35668 iter/s, 29.4838s/40 iters), loss = 1.63424
I1029 09:51:24.986572 12802 solver.cpp:241]     Train net output #0: loss = 1.63424 (* 1 = 1.63424 loss)
I1029 09:51:24.986587 12802 sgd_solver.cpp:105] Iteration 65160, lr = 2.83742e-05
I1029 09:51:54.525751 12802 solver.cpp:222] Iteration 65200 (1.35417 iter/s, 29.5385s/40 iters), loss = 1.3467
I1029 09:51:54.525923 12802 solver.cpp:241]     Train net output #0: loss = 1.3467 (* 1 = 1.3467 loss)
I1029 09:51:54.525938 12802 sgd_solver.cpp:105] Iteration 65200, lr = 2.82722e-05
I1029 09:52:24.288097 12802 solver.cpp:222] Iteration 65240 (1.34402 iter/s, 29.7615s/40 iters), loss = 1.44478
I1029 09:52:24.288161 12802 solver.cpp:241]     Train net output #0: loss = 1.44478 (* 1 = 1.44478 loss)
I1029 09:52:24.288178 12802 sgd_solver.cpp:105] Iteration 65240, lr = 2.81706e-05
I1029 09:53:53.223093 12802 solver.cpp:222] Iteration 65280 (0.449777 iter/s, 88.9329s/40 iters), loss = 1.44491
I1029 09:53:53.223275 12802 solver.cpp:241]     Train net output #0: loss = 1.44491 (* 1 = 1.44491 loss)
I1029 09:53:53.223292 12802 sgd_solver.cpp:105] Iteration 65280, lr = 2.80694e-05
I1029 09:54:35.288151 12802 solver.cpp:222] Iteration 65320 (0.950934 iter/s, 42.0639s/40 iters), loss = 1.24544
I1029 09:54:35.288285 12802 solver.cpp:241]     Train net output #0: loss = 1.24544 (* 1 = 1.24544 loss)
I1029 09:54:35.288301 12802 sgd_solver.cpp:105] Iteration 65320, lr = 2.79685e-05
I1029 09:55:33.420969 12802 solver.cpp:222] Iteration 65360 (0.688097 iter/s, 58.1314s/40 iters), loss = 1.30979
I1029 09:55:33.421104 12802 solver.cpp:241]     Train net output #0: loss = 1.30979 (* 1 = 1.30979 loss)
I1029 09:55:33.421120 12802 sgd_solver.cpp:105] Iteration 65360, lr = 2.7868e-05
I1029 09:56:03.924207 12802 solver.cpp:222] Iteration 65400 (1.31137 iter/s, 30.5024s/40 iters), loss = 1.39625
I1029 09:56:03.924417 12802 solver.cpp:241]     Train net output #0: loss = 1.39625 (* 1 = 1.39625 loss)
I1029 09:56:03.924435 12802 sgd_solver.cpp:105] Iteration 65400, lr = 2.77678e-05
I1029 09:56:34.234161 12802 solver.cpp:222] Iteration 65440 (1.31974 iter/s, 30.309s/40 iters), loss = 1.24063
I1029 09:56:34.234362 12802 solver.cpp:241]     Train net output #0: loss = 1.24063 (* 1 = 1.24063 loss)
I1029 09:56:34.234380 12802 sgd_solver.cpp:105] Iteration 65440, lr = 2.7668e-05
I1029 09:57:03.949694 12802 solver.cpp:222] Iteration 65480 (1.34614 iter/s, 29.7146s/40 iters), loss = 1.18557
I1029 09:57:03.949753 12802 solver.cpp:241]     Train net output #0: loss = 1.18557 (* 1 = 1.18557 loss)
I1029 09:57:03.949769 12802 sgd_solver.cpp:105] Iteration 65480, lr = 2.75686e-05
I1029 09:57:18.122027 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_65500.caffemodel
I1029 09:57:18.279239 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_65500.solverstate
I1029 09:57:18.393064 12802 solver.cpp:334] Iteration 65500, Testing net (#0)
I1029 09:57:49.234467 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 09:57:49.441004 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58476
I1029 09:57:49.441056 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81616
I1029 09:57:49.441067 12802 solver.cpp:401]     Test net output #2: loss = 1.83266 (* 1 = 1.83266 loss)
I1029 09:58:04.940270 12802 solver.cpp:222] Iteration 65520 (0.655855 iter/s, 60.9891s/40 iters), loss = 1.48947
I1029 09:58:04.940333 12802 solver.cpp:241]     Train net output #0: loss = 1.48947 (* 1 = 1.48947 loss)
I1029 09:58:04.940351 12802 sgd_solver.cpp:105] Iteration 65520, lr = 2.74695e-05
I1029 09:58:34.876528 12802 solver.cpp:222] Iteration 65560 (1.33621 iter/s, 29.9355s/40 iters), loss = 1.13591
I1029 09:58:34.876699 12802 solver.cpp:241]     Train net output #0: loss = 1.13591 (* 1 = 1.13591 loss)
I1029 09:58:34.876716 12802 sgd_solver.cpp:105] Iteration 65560, lr = 2.73708e-05
I1029 09:59:04.566632 12802 solver.cpp:222] Iteration 65600 (1.34729 iter/s, 29.6892s/40 iters), loss = 1.57658
I1029 09:59:04.566691 12802 solver.cpp:241]     Train net output #0: loss = 1.57658 (* 1 = 1.57658 loss)
I1029 09:59:04.566707 12802 sgd_solver.cpp:105] Iteration 65600, lr = 2.72724e-05
I1029 09:59:34.232175 12802 solver.cpp:222] Iteration 65640 (1.3484 iter/s, 29.6648s/40 iters), loss = 1.43926
I1029 09:59:34.232394 12802 solver.cpp:241]     Train net output #0: loss = 1.43926 (* 1 = 1.43926 loss)
I1029 09:59:34.232412 12802 sgd_solver.cpp:105] Iteration 65640, lr = 2.71744e-05
I1029 10:00:04.336024 12802 solver.cpp:222] Iteration 65680 (1.32878 iter/s, 30.1029s/40 iters), loss = 1.4896
I1029 10:00:04.336239 12802 solver.cpp:241]     Train net output #0: loss = 1.4896 (* 1 = 1.4896 loss)
I1029 10:00:04.336262 12802 sgd_solver.cpp:105] Iteration 65680, lr = 2.70768e-05
I1029 10:00:34.383970 12802 solver.cpp:222] Iteration 65720 (1.33125 iter/s, 30.047s/40 iters), loss = 1.46101
I1029 10:00:34.384150 12802 solver.cpp:241]     Train net output #0: loss = 1.46101 (* 1 = 1.46101 loss)
I1029 10:00:34.384166 12802 sgd_solver.cpp:105] Iteration 65720, lr = 2.69795e-05
I1029 10:01:04.456980 12802 solver.cpp:222] Iteration 65760 (1.33014 iter/s, 30.0721s/40 iters), loss = 1.53745
I1029 10:01:04.457183 12802 solver.cpp:241]     Train net output #0: loss = 1.53745 (* 1 = 1.53745 loss)
I1029 10:01:04.457198 12802 sgd_solver.cpp:105] Iteration 65760, lr = 2.68825e-05
I1029 10:01:34.079540 12802 solver.cpp:222] Iteration 65800 (1.35036 iter/s, 29.6217s/40 iters), loss = 1.42335
I1029 10:01:34.079599 12802 solver.cpp:241]     Train net output #0: loss = 1.42335 (* 1 = 1.42335 loss)
I1029 10:01:34.079612 12802 sgd_solver.cpp:105] Iteration 65800, lr = 2.67859e-05
I1029 10:02:03.671212 12802 solver.cpp:222] Iteration 65840 (1.35177 iter/s, 29.5909s/40 iters), loss = 1.1784
I1029 10:02:03.671382 12802 solver.cpp:241]     Train net output #0: loss = 1.1784 (* 1 = 1.1784 loss)
I1029 10:02:03.671401 12802 sgd_solver.cpp:105] Iteration 65840, lr = 2.66896e-05
I1029 10:02:33.343220 12802 solver.cpp:222] Iteration 65880 (1.34811 iter/s, 29.6711s/40 iters), loss = 1.736
I1029 10:02:33.343281 12802 solver.cpp:241]     Train net output #0: loss = 1.736 (* 1 = 1.736 loss)
I1029 10:02:33.343297 12802 sgd_solver.cpp:105] Iteration 65880, lr = 2.65937e-05
I1029 10:03:02.883049 12802 solver.cpp:222] Iteration 65920 (1.35414 iter/s, 29.5391s/40 iters), loss = 1.31749
I1029 10:03:02.883222 12802 solver.cpp:241]     Train net output #0: loss = 1.31749 (* 1 = 1.31749 loss)
I1029 10:03:02.883239 12802 sgd_solver.cpp:105] Iteration 65920, lr = 2.64981e-05
I1029 10:03:32.395886 12802 solver.cpp:222] Iteration 65960 (1.35538 iter/s, 29.512s/40 iters), loss = 1.51024
I1029 10:03:32.395951 12802 solver.cpp:241]     Train net output #0: loss = 1.51024 (* 1 = 1.51024 loss)
I1029 10:03:32.395967 12802 sgd_solver.cpp:105] Iteration 65960, lr = 2.64029e-05
I1029 10:04:01.185901 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_66000.caffemodel
I1029 10:04:01.332517 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_66000.solverstate
I1029 10:04:01.445268 12802 solver.cpp:334] Iteration 66000, Testing net (#0)
I1029 10:04:32.528417 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58896
I1029 10:04:32.528508 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8094
I1029 10:04:32.528520 12802 solver.cpp:401]     Test net output #2: loss = 1.82626 (* 1 = 1.82626 loss)
I1029 10:04:33.287382 12802 solver.cpp:222] Iteration 66000 (0.656922 iter/s, 60.89s/40 iters), loss = 1.43212
I1029 10:04:33.287446 12802 solver.cpp:241]     Train net output #0: loss = 1.43212 (* 1 = 1.43212 loss)
I1029 10:04:33.287467 12802 sgd_solver.cpp:105] Iteration 66000, lr = 2.6308e-05
I1029 10:05:02.859638 12802 solver.cpp:222] Iteration 66040 (1.35265 iter/s, 29.5715s/40 iters), loss = 1.34008
I1029 10:05:02.859791 12802 solver.cpp:241]     Train net output #0: loss = 1.34008 (* 1 = 1.34008 loss)
I1029 10:05:02.859807 12802 sgd_solver.cpp:105] Iteration 66040, lr = 2.62135e-05
I1029 10:05:32.350836 12802 solver.cpp:222] Iteration 66080 (1.35638 iter/s, 29.4903s/40 iters), loss = 1.41154
I1029 10:05:32.350894 12802 solver.cpp:241]     Train net output #0: loss = 1.41154 (* 1 = 1.41154 loss)
I1029 10:05:32.350910 12802 sgd_solver.cpp:105] Iteration 66080, lr = 2.61193e-05
I1029 10:06:01.833643 12802 solver.cpp:222] Iteration 66120 (1.35676 iter/s, 29.482s/40 iters), loss = 1.61472
I1029 10:06:01.833731 12802 solver.cpp:241]     Train net output #0: loss = 1.61472 (* 1 = 1.61472 loss)
I1029 10:06:01.833747 12802 sgd_solver.cpp:105] Iteration 66120, lr = 2.60254e-05
I1029 10:06:17.436934 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 10:06:31.333333 12802 solver.cpp:222] Iteration 66160 (1.35598 iter/s, 29.4989s/40 iters), loss = 1.04031
I1029 10:06:31.333405 12802 solver.cpp:241]     Train net output #0: loss = 1.04031 (* 1 = 1.04031 loss)
I1029 10:06:31.333420 12802 sgd_solver.cpp:105] Iteration 66160, lr = 2.59319e-05
I1029 10:07:00.826833 12802 solver.cpp:222] Iteration 66200 (1.35627 iter/s, 29.4927s/40 iters), loss = 1.4366
I1029 10:07:00.826975 12802 solver.cpp:241]     Train net output #0: loss = 1.4366 (* 1 = 1.4366 loss)
I1029 10:07:00.826992 12802 sgd_solver.cpp:105] Iteration 66200, lr = 2.58387e-05
I1029 10:07:30.793076 12802 solver.cpp:222] Iteration 66240 (1.33487 iter/s, 29.9654s/40 iters), loss = 1.35704
I1029 10:07:30.793134 12802 solver.cpp:241]     Train net output #0: loss = 1.35704 (* 1 = 1.35704 loss)
I1029 10:07:30.793150 12802 sgd_solver.cpp:105] Iteration 66240, lr = 2.57458e-05
I1029 10:08:01.515638 12802 solver.cpp:222] Iteration 66280 (1.30201 iter/s, 30.7218s/40 iters), loss = 1.96878
I1029 10:08:01.515813 12802 solver.cpp:241]     Train net output #0: loss = 1.96878 (* 1 = 1.96878 loss)
I1029 10:08:01.515830 12802 sgd_solver.cpp:105] Iteration 66280, lr = 2.56533e-05
I1029 10:08:31.530199 12802 solver.cpp:222] Iteration 66320 (1.33273 iter/s, 30.0137s/40 iters), loss = 1.30717
I1029 10:08:31.530352 12802 solver.cpp:241]     Train net output #0: loss = 1.30717 (* 1 = 1.30717 loss)
I1029 10:08:31.530369 12802 sgd_solver.cpp:105] Iteration 66320, lr = 2.55611e-05
I1029 10:09:01.899839 12802 solver.cpp:222] Iteration 66360 (1.31714 iter/s, 30.3688s/40 iters), loss = 1.39609
I1029 10:09:01.900012 12802 solver.cpp:241]     Train net output #0: loss = 1.39609 (* 1 = 1.39609 loss)
I1029 10:09:01.900030 12802 sgd_solver.cpp:105] Iteration 66360, lr = 2.54692e-05
I1029 10:09:32.340615 12802 solver.cpp:222] Iteration 66400 (1.31407 iter/s, 30.4399s/40 iters), loss = 1.18928
I1029 10:09:32.340785 12802 solver.cpp:241]     Train net output #0: loss = 1.18928 (* 1 = 1.18928 loss)
I1029 10:09:32.340802 12802 sgd_solver.cpp:105] Iteration 66400, lr = 2.53777e-05
I1029 10:10:02.916925 12802 solver.cpp:222] Iteration 66440 (1.30824 iter/s, 30.5754s/40 iters), loss = 1.55215
I1029 10:10:02.917132 12802 solver.cpp:241]     Train net output #0: loss = 1.55215 (* 1 = 1.55215 loss)
I1029 10:10:02.917147 12802 sgd_solver.cpp:105] Iteration 66440, lr = 2.52865e-05
I1029 10:10:33.217160 12802 solver.cpp:222] Iteration 66480 (1.32016 iter/s, 30.2993s/40 iters), loss = 1.60874
I1029 10:10:33.217386 12802 solver.cpp:241]     Train net output #0: loss = 1.60874 (* 1 = 1.60874 loss)
I1029 10:10:33.217403 12802 sgd_solver.cpp:105] Iteration 66480, lr = 2.51956e-05
I1029 10:10:47.655367 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_66500.caffemodel
I1029 10:10:47.814762 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_66500.solverstate
I1029 10:10:47.940547 12802 solver.cpp:334] Iteration 66500, Testing net (#0)
I1029 10:11:18.932571 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 10:11:19.144147 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58492
I1029 10:11:19.144197 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.814999
I1029 10:11:19.144207 12802 solver.cpp:401]     Test net output #2: loss = 1.83779 (* 1 = 1.83779 loss)
I1029 10:11:35.120497 12802 solver.cpp:222] Iteration 66520 (0.646186 iter/s, 61.9016s/40 iters), loss = 1.20661
I1029 10:11:35.120556 12802 solver.cpp:241]     Train net output #0: loss = 1.20661 (* 1 = 1.20661 loss)
I1029 10:11:35.120573 12802 sgd_solver.cpp:105] Iteration 66520, lr = 2.51051e-05
I1029 10:12:05.449004 12802 solver.cpp:222] Iteration 66560 (1.31893 iter/s, 30.3277s/40 iters), loss = 1.62239
I1029 10:12:05.449208 12802 solver.cpp:241]     Train net output #0: loss = 1.62239 (* 1 = 1.62239 loss)
I1029 10:12:05.449225 12802 sgd_solver.cpp:105] Iteration 66560, lr = 2.50149e-05
I1029 10:12:35.660303 12802 solver.cpp:222] Iteration 66600 (1.32405 iter/s, 30.2104s/40 iters), loss = 1.39636
I1029 10:12:35.660431 12802 solver.cpp:241]     Train net output #0: loss = 1.39636 (* 1 = 1.39636 loss)
I1029 10:12:35.660449 12802 sgd_solver.cpp:105] Iteration 66600, lr = 2.4925e-05
I1029 10:13:17.331104 12802 solver.cpp:222] Iteration 66640 (0.95993 iter/s, 41.6697s/40 iters), loss = 1.1541
I1029 10:13:17.331265 12802 solver.cpp:241]     Train net output #0: loss = 1.1541 (* 1 = 1.1541 loss)
I1029 10:13:17.331279 12802 sgd_solver.cpp:105] Iteration 66640, lr = 2.48354e-05
I1029 10:13:47.477376 12802 solver.cpp:222] Iteration 66680 (1.3269 iter/s, 30.1454s/40 iters), loss = 1.35469
I1029 10:13:47.477545 12802 solver.cpp:241]     Train net output #0: loss = 1.35469 (* 1 = 1.35469 loss)
I1029 10:13:47.477563 12802 sgd_solver.cpp:105] Iteration 66680, lr = 2.47461e-05
I1029 10:14:17.222313 12802 solver.cpp:222] Iteration 66720 (1.34481 iter/s, 29.7441s/40 iters), loss = 1.43087
I1029 10:14:17.222371 12802 solver.cpp:241]     Train net output #0: loss = 1.43087 (* 1 = 1.43087 loss)
I1029 10:14:17.222386 12802 sgd_solver.cpp:105] Iteration 66720, lr = 2.46572e-05
I1029 10:14:46.797412 12802 solver.cpp:222] Iteration 66760 (1.35252 iter/s, 29.5743s/40 iters), loss = 1.66508
I1029 10:14:46.797579 12802 solver.cpp:241]     Train net output #0: loss = 1.66508 (* 1 = 1.66508 loss)
I1029 10:14:46.797595 12802 sgd_solver.cpp:105] Iteration 66760, lr = 2.45686e-05
I1029 10:15:16.381719 12802 solver.cpp:222] Iteration 66800 (1.35211 iter/s, 29.5834s/40 iters), loss = 1.48349
I1029 10:15:16.381778 12802 solver.cpp:241]     Train net output #0: loss = 1.48349 (* 1 = 1.48349 loss)
I1029 10:15:16.381791 12802 sgd_solver.cpp:105] Iteration 66800, lr = 2.44803e-05
I1029 10:15:45.841022 12802 solver.cpp:222] Iteration 66840 (1.35784 iter/s, 29.4585s/40 iters), loss = 1.5514
I1029 10:15:45.841195 12802 solver.cpp:241]     Train net output #0: loss = 1.5514 (* 1 = 1.5514 loss)
I1029 10:15:45.841212 12802 sgd_solver.cpp:105] Iteration 66840, lr = 2.43923e-05
I1029 10:16:15.275782 12802 solver.cpp:222] Iteration 66880 (1.35898 iter/s, 29.4339s/40 iters), loss = 1.22569
I1029 10:16:15.275838 12802 solver.cpp:241]     Train net output #0: loss = 1.22569 (* 1 = 1.22569 loss)
I1029 10:16:15.275854 12802 sgd_solver.cpp:105] Iteration 66880, lr = 2.43047e-05
I1029 10:16:44.719269 12802 solver.cpp:222] Iteration 66920 (1.35857 iter/s, 29.4427s/40 iters), loss = 1.34282
I1029 10:16:44.719496 12802 solver.cpp:241]     Train net output #0: loss = 1.34282 (* 1 = 1.34282 loss)
I1029 10:16:44.719513 12802 sgd_solver.cpp:105] Iteration 66920, lr = 2.42173e-05
I1029 10:17:14.224350 12802 solver.cpp:222] Iteration 66960 (1.35574 iter/s, 29.5042s/40 iters), loss = 1.25183
I1029 10:17:14.224408 12802 solver.cpp:241]     Train net output #0: loss = 1.25183 (* 1 = 1.25183 loss)
I1029 10:17:14.224421 12802 sgd_solver.cpp:105] Iteration 66960, lr = 2.41303e-05
I1029 10:17:42.995615 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_67000.caffemodel
I1029 10:17:43.137606 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_67000.solverstate
I1029 10:17:43.251894 12802 solver.cpp:334] Iteration 67000, Testing net (#0)
I1029 10:18:14.423581 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58896
I1029 10:18:14.423673 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81012
I1029 10:18:14.423686 12802 solver.cpp:401]     Test net output #2: loss = 1.82901 (* 1 = 1.82901 loss)
I1029 10:18:15.199110 12802 solver.cpp:222] Iteration 67000 (0.656025 iter/s, 60.9733s/40 iters), loss = 1.35558
I1029 10:18:15.199173 12802 solver.cpp:241]     Train net output #0: loss = 1.35558 (* 1 = 1.35558 loss)
I1029 10:18:15.199189 12802 sgd_solver.cpp:105] Iteration 67000, lr = 2.40436e-05
I1029 10:18:44.988627 12802 solver.cpp:222] Iteration 67040 (1.34279 iter/s, 29.7887s/40 iters), loss = 1.60738
I1029 10:18:44.988786 12802 solver.cpp:241]     Train net output #0: loss = 1.60738 (* 1 = 1.60738 loss)
I1029 10:18:44.988802 12802 sgd_solver.cpp:105] Iteration 67040, lr = 2.39571e-05
I1029 10:19:14.690632 12802 solver.cpp:222] Iteration 67080 (1.34675 iter/s, 29.7011s/40 iters), loss = 0.982371
I1029 10:19:14.690691 12802 solver.cpp:241]     Train net output #0: loss = 0.982371 (* 1 = 0.982371 loss)
I1029 10:19:14.690708 12802 sgd_solver.cpp:105] Iteration 67080, lr = 2.38711e-05
I1029 10:19:44.116080 12802 solver.cpp:222] Iteration 67120 (1.3594 iter/s, 29.4247s/40 iters), loss = 1.41046
I1029 10:19:44.116262 12802 solver.cpp:241]     Train net output #0: loss = 1.41046 (* 1 = 1.41046 loss)
I1029 10:19:44.116279 12802 sgd_solver.cpp:105] Iteration 67120, lr = 2.37853e-05
I1029 10:20:13.527571 12802 solver.cpp:222] Iteration 67160 (1.36005 iter/s, 29.4106s/40 iters), loss = 1.42638
I1029 10:20:13.527629 12802 solver.cpp:241]     Train net output #0: loss = 1.42638 (* 1 = 1.42638 loss)
I1029 10:20:13.527647 12802 sgd_solver.cpp:105] Iteration 67160, lr = 2.36998e-05
I1029 10:20:42.846160 12802 solver.cpp:222] Iteration 67200 (1.36436 iter/s, 29.3178s/40 iters), loss = 1.44155
I1029 10:20:42.846352 12802 solver.cpp:241]     Train net output #0: loss = 1.44155 (* 1 = 1.44155 loss)
I1029 10:20:42.846369 12802 sgd_solver.cpp:105] Iteration 67200, lr = 2.36146e-05
I1029 10:21:12.904036 12802 solver.cpp:222] Iteration 67240 (1.33081 iter/s, 30.057s/40 iters), loss = 1.27409
I1029 10:21:12.904208 12802 solver.cpp:241]     Train net output #0: loss = 1.27409 (* 1 = 1.27409 loss)
I1029 10:21:12.904225 12802 sgd_solver.cpp:105] Iteration 67240, lr = 2.35297e-05
I1029 10:21:43.125316 12802 solver.cpp:222] Iteration 67280 (1.32361 iter/s, 30.2204s/40 iters), loss = 1.33464
I1029 10:21:43.125504 12802 solver.cpp:241]     Train net output #0: loss = 1.33464 (* 1 = 1.33464 loss)
I1029 10:21:43.125520 12802 sgd_solver.cpp:105] Iteration 67280, lr = 2.34452e-05
I1029 10:22:12.712879 12802 solver.cpp:222] Iteration 67320 (1.35196 iter/s, 29.5867s/40 iters), loss = 1.3166
I1029 10:22:12.712939 12802 solver.cpp:241]     Train net output #0: loss = 1.3166 (* 1 = 1.3166 loss)
I1029 10:22:12.712955 12802 sgd_solver.cpp:105] Iteration 67320, lr = 2.33609e-05
I1029 10:22:42.753543 12802 solver.cpp:222] Iteration 67360 (1.33156 iter/s, 30.0399s/40 iters), loss = 1.71864
I1029 10:22:42.753805 12802 solver.cpp:241]     Train net output #0: loss = 1.71864 (* 1 = 1.71864 loss)
I1029 10:22:42.753840 12802 sgd_solver.cpp:105] Iteration 67360, lr = 2.3277e-05
I1029 10:22:54.139889 12854 blocking_queue.cpp:49] Waiting for data
I1029 10:23:55.130028 12802 solver.cpp:222] Iteration 67400 (0.55268 iter/s, 72.3746s/40 iters), loss = 1.2853
I1029 10:23:55.130213 12802 solver.cpp:241]     Train net output #0: loss = 1.2853 (* 1 = 1.2853 loss)
I1029 10:23:55.130229 12802 sgd_solver.cpp:105] Iteration 67400, lr = 2.31933e-05
I1029 10:25:03.644752 12802 solver.cpp:222] Iteration 67440 (0.583831 iter/s, 68.513s/40 iters), loss = 1.3403
I1029 10:25:03.644912 12802 solver.cpp:241]     Train net output #0: loss = 1.3403 (* 1 = 1.3403 loss)
I1029 10:25:03.644933 12802 sgd_solver.cpp:105] Iteration 67440, lr = 2.311e-05
I1029 10:25:33.272994 12802 solver.cpp:222] Iteration 67480 (1.3501 iter/s, 29.6274s/40 iters), loss = 1.33886
I1029 10:25:33.273047 12802 solver.cpp:241]     Train net output #0: loss = 1.33886 (* 1 = 1.33886 loss)
I1029 10:25:33.273062 12802 sgd_solver.cpp:105] Iteration 67480, lr = 2.30269e-05
I1029 10:25:47.432885 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_67500.caffemodel
I1029 10:25:47.575165 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_67500.solverstate
I1029 10:25:47.697608 12802 solver.cpp:334] Iteration 67500, Testing net (#0)
I1029 10:26:18.555999 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 10:26:18.762836 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58544
I1029 10:26:18.762887 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.815519
I1029 10:26:18.762898 12802 solver.cpp:401]     Test net output #2: loss = 1.83342 (* 1 = 1.83342 loss)
I1029 10:26:34.417106 12802 solver.cpp:222] Iteration 67520 (0.654208 iter/s, 61.1426s/40 iters), loss = 1.52127
I1029 10:26:34.417186 12802 solver.cpp:241]     Train net output #0: loss = 1.52127 (* 1 = 1.52127 loss)
I1029 10:26:34.417208 12802 sgd_solver.cpp:105] Iteration 67520, lr = 2.29442e-05
I1029 10:27:35.423303 12802 solver.cpp:222] Iteration 67560 (0.655687 iter/s, 61.0047s/40 iters), loss = 1.27279
I1029 10:27:35.423476 12802 solver.cpp:241]     Train net output #0: loss = 1.27279 (* 1 = 1.27279 loss)
I1029 10:27:35.423491 12802 sgd_solver.cpp:105] Iteration 67560, lr = 2.28617e-05
I1029 10:28:05.898562 12802 solver.cpp:222] Iteration 67600 (1.31258 iter/s, 30.4744s/40 iters), loss = 1.23465
I1029 10:28:05.898761 12802 solver.cpp:241]     Train net output #0: loss = 1.23465 (* 1 = 1.23465 loss)
I1029 10:28:05.898778 12802 sgd_solver.cpp:105] Iteration 67600, lr = 2.27795e-05
I1029 10:28:36.298578 12802 solver.cpp:222] Iteration 67640 (1.31583 iter/s, 30.3991s/40 iters), loss = 1.59586
I1029 10:28:36.298738 12802 solver.cpp:241]     Train net output #0: loss = 1.59586 (* 1 = 1.59586 loss)
I1029 10:28:36.298755 12802 sgd_solver.cpp:105] Iteration 67640, lr = 2.26977e-05
I1029 10:29:06.007481 12802 solver.cpp:222] Iteration 67680 (1.34644 iter/s, 29.708s/40 iters), loss = 1.47172
I1029 10:29:06.007542 12802 solver.cpp:241]     Train net output #0: loss = 1.47172 (* 1 = 1.47172 loss)
I1029 10:29:06.007557 12802 sgd_solver.cpp:105] Iteration 67680, lr = 2.26161e-05
I1029 10:29:35.635221 12802 solver.cpp:222] Iteration 67720 (1.35012 iter/s, 29.627s/40 iters), loss = 1.25349
I1029 10:29:35.635372 12802 solver.cpp:241]     Train net output #0: loss = 1.25349 (* 1 = 1.25349 loss)
I1029 10:29:35.635388 12802 sgd_solver.cpp:105] Iteration 67720, lr = 2.25348e-05
I1029 10:30:05.205489 12802 solver.cpp:222] Iteration 67760 (1.35275 iter/s, 29.5694s/40 iters), loss = 1.53199
I1029 10:30:05.205554 12802 solver.cpp:241]     Train net output #0: loss = 1.53199 (* 1 = 1.53199 loss)
I1029 10:30:05.205569 12802 sgd_solver.cpp:105] Iteration 67760, lr = 2.24538e-05
I1029 10:30:34.790807 12802 solver.cpp:222] Iteration 67800 (1.35206 iter/s, 29.5846s/40 iters), loss = 1.349
I1029 10:30:34.791057 12802 solver.cpp:241]     Train net output #0: loss = 1.349 (* 1 = 1.349 loss)
I1029 10:30:34.791081 12802 sgd_solver.cpp:105] Iteration 67800, lr = 2.23731e-05
I1029 10:31:04.330070 12802 solver.cpp:222] Iteration 67840 (1.35417 iter/s, 29.5383s/40 iters), loss = 1.22169
I1029 10:31:04.330123 12802 solver.cpp:241]     Train net output #0: loss = 1.22169 (* 1 = 1.22169 loss)
I1029 10:31:04.330138 12802 sgd_solver.cpp:105] Iteration 67840, lr = 2.22927e-05
I1029 10:31:33.827982 12802 solver.cpp:222] Iteration 67880 (1.35606 iter/s, 29.4972s/40 iters), loss = 1.52532
I1029 10:31:33.828130 12802 solver.cpp:241]     Train net output #0: loss = 1.52532 (* 1 = 1.52532 loss)
I1029 10:31:33.828145 12802 sgd_solver.cpp:105] Iteration 67880, lr = 2.22126e-05
I1029 10:32:03.329324 12802 solver.cpp:222] Iteration 67920 (1.35591 iter/s, 29.5005s/40 iters), loss = 1.36386
I1029 10:32:03.329388 12802 solver.cpp:241]     Train net output #0: loss = 1.36386 (* 1 = 1.36386 loss)
I1029 10:32:03.329403 12802 sgd_solver.cpp:105] Iteration 67920, lr = 2.21328e-05
I1029 10:32:32.822336 12802 solver.cpp:222] Iteration 67960 (1.35629 iter/s, 29.4922s/40 iters), loss = 1.39662
I1029 10:32:32.822443 12802 solver.cpp:241]     Train net output #0: loss = 1.39662 (* 1 = 1.39662 loss)
I1029 10:32:32.822459 12802 sgd_solver.cpp:105] Iteration 67960, lr = 2.20533e-05
I1029 10:33:01.488945 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_68000.caffemodel
I1029 10:33:01.665405 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_68000.solverstate
I1029 10:33:01.777420 12802 solver.cpp:334] Iteration 68000, Testing net (#0)
I1029 10:33:32.825368 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5894
I1029 10:33:32.825517 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80956
I1029 10:33:32.825531 12802 solver.cpp:401]     Test net output #2: loss = 1.82775 (* 1 = 1.82775 loss)
I1029 10:33:33.579233 12802 solver.cpp:222] Iteration 68000 (0.658378 iter/s, 60.7554s/40 iters), loss = 1.42813
I1029 10:33:33.579289 12802 solver.cpp:241]     Train net output #0: loss = 1.42813 (* 1 = 1.42813 loss)
I1029 10:33:33.579305 12802 sgd_solver.cpp:105] Iteration 68000, lr = 2.1974e-05
I1029 10:34:12.433779 12802 solver.cpp:222] Iteration 68040 (1.02951 iter/s, 38.8535s/40 iters), loss = 1.23068
I1029 10:34:12.433910 12802 solver.cpp:241]     Train net output #0: loss = 1.23068 (* 1 = 1.23068 loss)
I1029 10:34:12.433938 12802 sgd_solver.cpp:105] Iteration 68040, lr = 2.1895e-05
I1029 10:35:22.136683 12802 solver.cpp:222] Iteration 68080 (0.573879 iter/s, 69.7012s/40 iters), loss = 1.5294
I1029 10:35:22.136835 12802 solver.cpp:241]     Train net output #0: loss = 1.5294 (* 1 = 1.5294 loss)
I1029 10:35:22.136849 12802 sgd_solver.cpp:105] Iteration 68080, lr = 2.18163e-05
I1029 10:35:51.595870 12802 solver.cpp:222] Iteration 68120 (1.35785 iter/s, 29.4583s/40 iters), loss = 1.41997
I1029 10:35:51.595932 12802 solver.cpp:241]     Train net output #0: loss = 1.41997 (* 1 = 1.41997 loss)
I1029 10:35:51.595947 12802 sgd_solver.cpp:105] Iteration 68120, lr = 2.17379e-05
I1029 10:36:21.123231 12802 solver.cpp:222] Iteration 68160 (1.35471 iter/s, 29.5266s/40 iters), loss = 1.27016
I1029 10:36:21.123368 12802 solver.cpp:241]     Train net output #0: loss = 1.27016 (* 1 = 1.27016 loss)
I1029 10:36:21.123385 12802 sgd_solver.cpp:105] Iteration 68160, lr = 2.16598e-05
I1029 10:36:50.647819 12802 solver.cpp:222] Iteration 68200 (1.35484 iter/s, 29.5238s/40 iters), loss = 1.41232
I1029 10:36:50.647881 12802 solver.cpp:241]     Train net output #0: loss = 1.41232 (* 1 = 1.41232 loss)
I1029 10:36:50.647897 12802 sgd_solver.cpp:105] Iteration 68200, lr = 2.1582e-05
I1029 10:37:20.148313 12802 solver.cpp:222] Iteration 68240 (1.35594 iter/s, 29.4997s/40 iters), loss = 1.32648
I1029 10:37:20.148404 12802 solver.cpp:241]     Train net output #0: loss = 1.32648 (* 1 = 1.32648 loss)
I1029 10:37:20.148418 12802 sgd_solver.cpp:105] Iteration 68240, lr = 2.15044e-05
I1029 10:37:49.775471 12802 solver.cpp:222] Iteration 68280 (1.35015 iter/s, 29.6264s/40 iters), loss = 1.66234
I1029 10:37:49.775527 12802 solver.cpp:241]     Train net output #0: loss = 1.66234 (* 1 = 1.66234 loss)
I1029 10:37:49.775540 12802 sgd_solver.cpp:105] Iteration 68280, lr = 2.14271e-05
I1029 10:38:19.787010 12802 solver.cpp:222] Iteration 68320 (1.33286 iter/s, 30.0108s/40 iters), loss = 1.50562
I1029 10:38:19.787255 12802 solver.cpp:241]     Train net output #0: loss = 1.50562 (* 1 = 1.50562 loss)
I1029 10:38:19.787276 12802 sgd_solver.cpp:105] Iteration 68320, lr = 2.13501e-05
I1029 10:38:51.064065 12802 solver.cpp:222] Iteration 68360 (1.27893 iter/s, 31.2761s/40 iters), loss = 1.57742
I1029 10:38:51.064285 12802 solver.cpp:241]     Train net output #0: loss = 1.57742 (* 1 = 1.57742 loss)
I1029 10:38:51.064312 12802 sgd_solver.cpp:105] Iteration 68360, lr = 2.12734e-05
I1029 10:39:36.207860 12802 solver.cpp:222] Iteration 68400 (0.886082 iter/s, 45.1425s/40 iters), loss = 1.17344
I1029 10:39:36.208035 12802 solver.cpp:241]     Train net output #0: loss = 1.17344 (* 1 = 1.17344 loss)
I1029 10:39:36.208052 12802 sgd_solver.cpp:105] Iteration 68400, lr = 2.11969e-05
I1029 10:40:05.975172 12802 solver.cpp:222] Iteration 68440 (1.3438 iter/s, 29.7664s/40 iters), loss = 1.32178
I1029 10:40:05.975229 12802 solver.cpp:241]     Train net output #0: loss = 1.32178 (* 1 = 1.32178 loss)
I1029 10:40:05.975244 12802 sgd_solver.cpp:105] Iteration 68440, lr = 2.11208e-05
I1029 10:40:35.709789 12802 solver.cpp:222] Iteration 68480 (1.34527 iter/s, 29.7339s/40 iters), loss = 1.5746
I1029 10:40:35.709960 12802 solver.cpp:241]     Train net output #0: loss = 1.5746 (* 1 = 1.5746 loss)
I1029 10:40:35.709977 12802 sgd_solver.cpp:105] Iteration 68480, lr = 2.10449e-05
I1029 10:40:49.815878 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_68500.caffemodel
I1029 10:40:49.953707 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_68500.solverstate
I1029 10:40:50.060312 12802 solver.cpp:334] Iteration 68500, Testing net (#0)
I1029 10:41:21.184084 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 10:41:21.394805 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58512
I1029 10:41:21.394855 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81536
I1029 10:41:21.394865 12802 solver.cpp:401]     Test net output #2: loss = 1.82938 (* 1 = 1.82938 loss)
I1029 10:41:36.988258 12802 solver.cpp:222] Iteration 68520 (0.652775 iter/s, 61.2769s/40 iters), loss = 1.52488
I1029 10:41:36.988317 12802 solver.cpp:241]     Train net output #0: loss = 1.52488 (* 1 = 1.52488 loss)
I1029 10:41:36.988332 12802 sgd_solver.cpp:105] Iteration 68520, lr = 2.09692e-05
I1029 10:42:06.996019 12802 solver.cpp:222] Iteration 68560 (1.33302 iter/s, 30.007s/40 iters), loss = 1.88489
I1029 10:42:06.996196 12802 solver.cpp:241]     Train net output #0: loss = 1.88489 (* 1 = 1.88489 loss)
I1029 10:42:06.996213 12802 sgd_solver.cpp:105] Iteration 68560, lr = 2.08939e-05
I1029 10:42:36.447721 12802 solver.cpp:222] Iteration 68600 (1.3582 iter/s, 29.4508s/40 iters), loss = 1.58606
I1029 10:42:36.447777 12802 solver.cpp:241]     Train net output #0: loss = 1.58606 (* 1 = 1.58606 loss)
I1029 10:42:36.447790 12802 sgd_solver.cpp:105] Iteration 68600, lr = 2.08188e-05
I1029 10:43:06.179661 12802 solver.cpp:222] Iteration 68640 (1.34539 iter/s, 29.7312s/40 iters), loss = 1.09893
I1029 10:43:06.179831 12802 solver.cpp:241]     Train net output #0: loss = 1.09893 (* 1 = 1.09893 loss)
I1029 10:43:06.179848 12802 sgd_solver.cpp:105] Iteration 68640, lr = 2.0744e-05
I1029 10:43:09.172668 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 10:43:36.053908 12802 solver.cpp:222] Iteration 68680 (1.33899 iter/s, 29.8734s/40 iters), loss = 1.38536
I1029 10:43:36.053972 12802 solver.cpp:241]     Train net output #0: loss = 1.38536 (* 1 = 1.38536 loss)
I1029 10:43:36.053987 12802 sgd_solver.cpp:105] Iteration 68680, lr = 2.06694e-05
I1029 10:44:06.019418 12802 solver.cpp:222] Iteration 68720 (1.3349 iter/s, 29.9647s/40 iters), loss = 1.37818
I1029 10:44:06.019680 12802 solver.cpp:241]     Train net output #0: loss = 1.37818 (* 1 = 1.37818 loss)
I1029 10:44:06.019701 12802 sgd_solver.cpp:105] Iteration 68720, lr = 2.05951e-05
I1029 10:44:36.020295 12802 solver.cpp:222] Iteration 68760 (1.33334 iter/s, 29.9999s/40 iters), loss = 1.27447
I1029 10:44:36.020454 12802 solver.cpp:241]     Train net output #0: loss = 1.27447 (* 1 = 1.27447 loss)
I1029 10:44:36.020472 12802 sgd_solver.cpp:105] Iteration 68760, lr = 2.05211e-05
I1029 10:45:05.835877 12802 solver.cpp:222] Iteration 68800 (1.34162 iter/s, 29.8147s/40 iters), loss = 1.53647
I1029 10:45:05.835942 12802 solver.cpp:241]     Train net output #0: loss = 1.53647 (* 1 = 1.53647 loss)
I1029 10:45:05.835958 12802 sgd_solver.cpp:105] Iteration 68800, lr = 2.04474e-05
I1029 10:45:35.409703 12802 solver.cpp:222] Iteration 68840 (1.35258 iter/s, 29.5731s/40 iters), loss = 1.32897
I1029 10:45:35.409910 12802 solver.cpp:241]     Train net output #0: loss = 1.32897 (* 1 = 1.32897 loss)
I1029 10:45:35.409931 12802 sgd_solver.cpp:105] Iteration 68840, lr = 2.03739e-05
I1029 10:46:05.126438 12802 solver.cpp:222] Iteration 68880 (1.34608 iter/s, 29.7158s/40 iters), loss = 1.66426
I1029 10:46:05.126497 12802 solver.cpp:241]     Train net output #0: loss = 1.66426 (* 1 = 1.66426 loss)
I1029 10:46:05.126513 12802 sgd_solver.cpp:105] Iteration 68880, lr = 2.03007e-05
I1029 10:46:34.787888 12802 solver.cpp:222] Iteration 68920 (1.34859 iter/s, 29.6607s/40 iters), loss = 1.38707
I1029 10:46:34.788061 12802 solver.cpp:241]     Train net output #0: loss = 1.38707 (* 1 = 1.38707 loss)
I1029 10:46:34.788085 12802 sgd_solver.cpp:105] Iteration 68920, lr = 2.02277e-05
I1029 10:47:04.284518 12802 solver.cpp:222] Iteration 68960 (1.35613 iter/s, 29.4958s/40 iters), loss = 1.30465
I1029 10:47:04.284579 12802 solver.cpp:241]     Train net output #0: loss = 1.30465 (* 1 = 1.30465 loss)
I1029 10:47:04.284592 12802 sgd_solver.cpp:105] Iteration 68960, lr = 2.0155e-05
I1029 10:47:33.059533 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_69000.caffemodel
I1029 10:47:33.211074 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_69000.solverstate
I1029 10:47:33.338619 12802 solver.cpp:334] Iteration 69000, Testing net (#0)
I1029 10:48:04.612025 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.59
I1029 10:48:04.612138 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80992
I1029 10:48:04.612151 12802 solver.cpp:401]     Test net output #2: loss = 1.83294 (* 1 = 1.83294 loss)
I1029 10:48:05.363181 12802 solver.cpp:222] Iteration 69000 (0.654909 iter/s, 61.0772s/40 iters), loss = 1.44921
I1029 10:48:05.363245 12802 solver.cpp:241]     Train net output #0: loss = 1.44921 (* 1 = 1.44921 loss)
I1029 10:48:05.363260 12802 sgd_solver.cpp:105] Iteration 69000, lr = 2.00826e-05
I1029 10:48:34.809316 12802 solver.cpp:222] Iteration 69040 (1.35845 iter/s, 29.4454s/40 iters), loss = 1.18358
I1029 10:48:34.809438 12802 solver.cpp:241]     Train net output #0: loss = 1.18358 (* 1 = 1.18358 loss)
I1029 10:48:34.809454 12802 sgd_solver.cpp:105] Iteration 69040, lr = 2.00104e-05
I1029 10:49:04.271409 12802 solver.cpp:222] Iteration 69080 (1.35771 iter/s, 29.4613s/40 iters), loss = 1.16884
I1029 10:49:04.271464 12802 solver.cpp:241]     Train net output #0: loss = 1.16884 (* 1 = 1.16884 loss)
I1029 10:49:04.271481 12802 sgd_solver.cpp:105] Iteration 69080, lr = 1.99385e-05
I1029 10:49:33.730953 12802 solver.cpp:222] Iteration 69120 (1.35783 iter/s, 29.4588s/40 iters), loss = 1.31249
I1029 10:49:33.731043 12802 solver.cpp:241]     Train net output #0: loss = 1.31249 (* 1 = 1.31249 loss)
I1029 10:49:33.731057 12802 sgd_solver.cpp:105] Iteration 69120, lr = 1.98668e-05
I1029 10:50:03.176501 12802 solver.cpp:222] Iteration 69160 (1.35848 iter/s, 29.4448s/40 iters), loss = 1.37117
I1029 10:50:03.176563 12802 solver.cpp:241]     Train net output #0: loss = 1.37117 (* 1 = 1.37117 loss)
I1029 10:50:03.176578 12802 sgd_solver.cpp:105] Iteration 69160, lr = 1.97954e-05
I1029 10:50:32.692580 12802 solver.cpp:222] Iteration 69200 (1.35523 iter/s, 29.5153s/40 iters), loss = 1.55141
I1029 10:50:32.692808 12802 solver.cpp:241]     Train net output #0: loss = 1.55141 (* 1 = 1.55141 loss)
I1029 10:50:32.692826 12802 sgd_solver.cpp:105] Iteration 69200, lr = 1.97243e-05
I1029 10:51:02.261744 12802 solver.cpp:222] Iteration 69240 (1.3528 iter/s, 29.5682s/40 iters), loss = 1.41365
I1029 10:51:02.261806 12802 solver.cpp:241]     Train net output #0: loss = 1.41365 (* 1 = 1.41365 loss)
I1029 10:51:02.261821 12802 sgd_solver.cpp:105] Iteration 69240, lr = 1.96534e-05
I1029 10:51:31.919329 12802 solver.cpp:222] Iteration 69280 (1.34876 iter/s, 29.6568s/40 iters), loss = 1.7088
I1029 10:51:31.919471 12802 solver.cpp:241]     Train net output #0: loss = 1.7088 (* 1 = 1.7088 loss)
I1029 10:51:31.919488 12802 sgd_solver.cpp:105] Iteration 69280, lr = 1.95828e-05
I1029 10:52:01.402932 12802 solver.cpp:222] Iteration 69320 (1.35672 iter/s, 29.4828s/40 iters), loss = 1.50921
I1029 10:52:01.402988 12802 solver.cpp:241]     Train net output #0: loss = 1.50921 (* 1 = 1.50921 loss)
I1029 10:52:01.403002 12802 sgd_solver.cpp:105] Iteration 69320, lr = 1.95124e-05
I1029 10:52:30.874253 12802 solver.cpp:222] Iteration 69360 (1.35729 iter/s, 29.4706s/40 iters), loss = 1.48926
I1029 10:52:30.874346 12802 solver.cpp:241]     Train net output #0: loss = 1.48926 (* 1 = 1.48926 loss)
I1029 10:52:30.874361 12802 sgd_solver.cpp:105] Iteration 69360, lr = 1.94423e-05
I1029 10:53:00.295202 12802 solver.cpp:222] Iteration 69400 (1.35961 iter/s, 29.4202s/40 iters), loss = 1.22241
I1029 10:53:00.295262 12802 solver.cpp:241]     Train net output #0: loss = 1.22241 (* 1 = 1.22241 loss)
I1029 10:53:00.295279 12802 sgd_solver.cpp:105] Iteration 69400, lr = 1.93724e-05
I1029 10:53:29.745851 12802 solver.cpp:222] Iteration 69440 (1.35824 iter/s, 29.4499s/40 iters), loss = 1.28433
I1029 10:53:29.745944 12802 solver.cpp:241]     Train net output #0: loss = 1.28433 (* 1 = 1.28433 loss)
I1029 10:53:29.745959 12802 sgd_solver.cpp:105] Iteration 69440, lr = 1.93028e-05
I1029 10:53:59.184113 12802 solver.cpp:222] Iteration 69480 (1.35881 iter/s, 29.4375s/40 iters), loss = 1.23822
I1029 10:53:59.184171 12802 solver.cpp:241]     Train net output #0: loss = 1.23822 (* 1 = 1.23822 loss)
I1029 10:53:59.184186 12802 sgd_solver.cpp:105] Iteration 69480, lr = 1.92334e-05
I1029 10:54:13.152133 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_69500.caffemodel
I1029 10:54:13.297787 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_69500.solverstate
I1029 10:54:13.412209 12802 solver.cpp:334] Iteration 69500, Testing net (#0)
I1029 10:54:44.362099 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 10:54:44.569552 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58524
I1029 10:54:44.569604 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81556
I1029 10:54:44.569615 12802 solver.cpp:401]     Test net output #2: loss = 1.8324 (* 1 = 1.8324 loss)
I1029 10:55:00.074867 12802 solver.cpp:222] Iteration 69520 (0.65693 iter/s, 60.8893s/40 iters), loss = 1.39315
I1029 10:55:00.074929 12802 solver.cpp:241]     Train net output #0: loss = 1.39315 (* 1 = 1.39315 loss)
I1029 10:55:00.074945 12802 sgd_solver.cpp:105] Iteration 69520, lr = 1.91643e-05
I1029 10:55:29.874006 12802 solver.cpp:222] Iteration 69560 (1.34236 iter/s, 29.7984s/40 iters), loss = 1.20818
I1029 10:55:29.874228 12802 solver.cpp:241]     Train net output #0: loss = 1.20818 (* 1 = 1.20818 loss)
I1029 10:55:29.874241 12802 sgd_solver.cpp:105] Iteration 69560, lr = 1.90954e-05
I1029 10:56:25.456487 12802 solver.cpp:222] Iteration 69600 (0.719671 iter/s, 55.581s/40 iters), loss = 1.02225
I1029 10:56:25.456712 12802 solver.cpp:241]     Train net output #0: loss = 1.02225 (* 1 = 1.02225 loss)
I1029 10:56:25.456730 12802 sgd_solver.cpp:105] Iteration 69600, lr = 1.90268e-05
I1029 10:57:24.941670 12802 solver.cpp:222] Iteration 69640 (0.672454 iter/s, 59.4836s/40 iters), loss = 1.42778
I1029 10:57:24.941845 12802 solver.cpp:241]     Train net output #0: loss = 1.42778 (* 1 = 1.42778 loss)
I1029 10:57:24.941862 12802 sgd_solver.cpp:105] Iteration 69640, lr = 1.89584e-05
I1029 10:57:54.962052 12802 solver.cpp:222] Iteration 69680 (1.33247 iter/s, 30.0195s/40 iters), loss = 1.3177
I1029 10:57:54.962209 12802 solver.cpp:241]     Train net output #0: loss = 1.3177 (* 1 = 1.3177 loss)
I1029 10:57:54.962226 12802 sgd_solver.cpp:105] Iteration 69680, lr = 1.88903e-05
I1029 10:58:25.692574 12802 solver.cpp:222] Iteration 69720 (1.30167 iter/s, 30.7297s/40 iters), loss = 1.33204
I1029 10:58:25.692762 12802 solver.cpp:241]     Train net output #0: loss = 1.33204 (* 1 = 1.33204 loss)
I1029 10:58:25.692777 12802 sgd_solver.cpp:105] Iteration 69720, lr = 1.88224e-05
I1029 10:58:55.854902 12802 solver.cpp:222] Iteration 69760 (1.3262 iter/s, 30.1614s/40 iters), loss = 1.62881
I1029 10:58:55.855059 12802 solver.cpp:241]     Train net output #0: loss = 1.62881 (* 1 = 1.62881 loss)
I1029 10:58:55.855077 12802 sgd_solver.cpp:105] Iteration 69760, lr = 1.87548e-05
I1029 10:59:35.270400 12802 solver.cpp:222] Iteration 69800 (1.01486 iter/s, 39.4144s/40 iters), loss = 1.47984
I1029 10:59:35.270565 12802 solver.cpp:241]     Train net output #0: loss = 1.47984 (* 1 = 1.47984 loss)
I1029 10:59:35.270582 12802 sgd_solver.cpp:105] Iteration 69800, lr = 1.86874e-05
I1029 11:00:05.649266 12802 solver.cpp:222] Iteration 69840 (1.31674 iter/s, 30.378s/40 iters), loss = 1.65079
I1029 11:00:05.649433 12802 solver.cpp:241]     Train net output #0: loss = 1.65079 (* 1 = 1.65079 loss)
I1029 11:00:05.649456 12802 sgd_solver.cpp:105] Iteration 69840, lr = 1.86202e-05
I1029 11:00:35.608568 12802 solver.cpp:222] Iteration 69880 (1.33518 iter/s, 29.9584s/40 iters), loss = 1.45789
I1029 11:00:35.608626 12802 solver.cpp:241]     Train net output #0: loss = 1.45789 (* 1 = 1.45789 loss)
I1029 11:00:35.608642 12802 sgd_solver.cpp:105] Iteration 69880, lr = 1.85533e-05
I1029 11:01:05.162302 12802 solver.cpp:222] Iteration 69920 (1.3535 iter/s, 29.553s/40 iters), loss = 1.39734
I1029 11:01:05.162483 12802 solver.cpp:241]     Train net output #0: loss = 1.39734 (* 1 = 1.39734 loss)
I1029 11:01:05.162511 12802 sgd_solver.cpp:105] Iteration 69920, lr = 1.84866e-05
I1029 11:01:46.738953 12802 solver.cpp:222] Iteration 69960 (0.962105 iter/s, 41.5755s/40 iters), loss = 1.49885
I1029 11:01:46.739094 12802 solver.cpp:241]     Train net output #0: loss = 1.49885 (* 1 = 1.49885 loss)
I1029 11:01:46.739111 12802 sgd_solver.cpp:105] Iteration 69960, lr = 1.84202e-05
I1029 11:02:16.345022 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_70000.caffemodel
I1029 11:02:16.490309 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_70000.solverstate
I1029 11:02:16.605721 12802 solver.cpp:334] Iteration 70000, Testing net (#0)
I1029 11:02:47.716372 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58988
I1029 11:02:47.716563 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80988
I1029 11:02:47.716576 12802 solver.cpp:401]     Test net output #2: loss = 1.82864 (* 1 = 1.82864 loss)
I1029 11:02:48.482862 12802 solver.cpp:222] Iteration 70000 (0.647854 iter/s, 61.7423s/40 iters), loss = 1.52826
I1029 11:02:48.482897 12802 solver.cpp:241]     Train net output #0: loss = 1.52826 (* 1 = 1.52826 loss)
I1029 11:02:48.482915 12802 sgd_solver.cpp:105] Iteration 70000, lr = 1.8354e-05
I1029 11:03:18.476481 12802 solver.cpp:222] Iteration 70040 (1.33365 iter/s, 29.9929s/40 iters), loss = 1.44107
I1029 11:03:18.476644 12802 solver.cpp:241]     Train net output #0: loss = 1.44107 (* 1 = 1.44107 loss)
I1029 11:03:18.476660 12802 sgd_solver.cpp:105] Iteration 70040, lr = 1.8288e-05
I1029 11:03:48.117758 12802 solver.cpp:222] Iteration 70080 (1.34951 iter/s, 29.6404s/40 iters), loss = 1.37477
I1029 11:03:48.117812 12802 solver.cpp:241]     Train net output #0: loss = 1.37477 (* 1 = 1.37477 loss)
I1029 11:03:48.117828 12802 sgd_solver.cpp:105] Iteration 70080, lr = 1.82223e-05
I1029 11:04:17.531527 12802 solver.cpp:222] Iteration 70120 (1.35994 iter/s, 29.413s/40 iters), loss = 1.19825
I1029 11:04:17.531675 12802 solver.cpp:241]     Train net output #0: loss = 1.19825 (* 1 = 1.19825 loss)
I1029 11:04:17.531693 12802 sgd_solver.cpp:105] Iteration 70120, lr = 1.81568e-05
I1029 11:04:46.937896 12802 solver.cpp:222] Iteration 70160 (1.36029 iter/s, 29.4055s/40 iters), loss = 1.7938
I1029 11:04:46.937963 12802 solver.cpp:241]     Train net output #0: loss = 1.7938 (* 1 = 1.7938 loss)
I1029 11:04:46.937979 12802 sgd_solver.cpp:105] Iteration 70160, lr = 1.80915e-05
I1029 11:05:16.512521 12802 solver.cpp:222] Iteration 70200 (1.35255 iter/s, 29.5739s/40 iters), loss = 1.31701
I1029 11:05:16.512707 12802 solver.cpp:241]     Train net output #0: loss = 1.31701 (* 1 = 1.31701 loss)
I1029 11:05:16.512722 12802 sgd_solver.cpp:105] Iteration 70200, lr = 1.80265e-05
I1029 11:05:46.183943 12802 solver.cpp:222] Iteration 70240 (1.34814 iter/s, 29.6705s/40 iters), loss = 1.52342
I1029 11:05:46.183993 12802 solver.cpp:241]     Train net output #0: loss = 1.52342 (* 1 = 1.52342 loss)
I1029 11:05:46.184010 12802 sgd_solver.cpp:105] Iteration 70240, lr = 1.79617e-05
I1029 11:06:28.901800 12802 solver.cpp:222] Iteration 70280 (0.9364 iter/s, 42.7168s/40 iters), loss = 1.52382
I1029 11:06:28.901993 12802 solver.cpp:241]     Train net output #0: loss = 1.52382 (* 1 = 1.52382 loss)
I1029 11:06:28.902011 12802 sgd_solver.cpp:105] Iteration 70280, lr = 1.78972e-05
I1029 11:07:03.006567 12802 solver.cpp:222] Iteration 70320 (1.17289 iter/s, 34.1038s/40 iters), loss = 1.40314
I1029 11:07:03.006763 12802 solver.cpp:241]     Train net output #0: loss = 1.40314 (* 1 = 1.40314 loss)
I1029 11:07:03.006781 12802 sgd_solver.cpp:105] Iteration 70320, lr = 1.78329e-05
I1029 11:07:33.594362 12802 solver.cpp:222] Iteration 70360 (1.30775 iter/s, 30.5869s/40 iters), loss = 1.30941
I1029 11:07:33.594559 12802 solver.cpp:241]     Train net output #0: loss = 1.30941 (* 1 = 1.30941 loss)
I1029 11:07:33.594575 12802 sgd_solver.cpp:105] Iteration 70360, lr = 1.77688e-05
I1029 11:08:03.247730 12802 solver.cpp:222] Iteration 70400 (1.34896 iter/s, 29.6525s/40 iters), loss = 1.95556
I1029 11:08:03.247786 12802 solver.cpp:241]     Train net output #0: loss = 1.95556 (* 1 = 1.95556 loss)
I1029 11:08:03.247800 12802 sgd_solver.cpp:105] Iteration 70400, lr = 1.77049e-05
I1029 11:08:32.976104 12802 solver.cpp:222] Iteration 70440 (1.34555 iter/s, 29.7276s/40 iters), loss = 1.19111
I1029 11:08:32.976260 12802 solver.cpp:241]     Train net output #0: loss = 1.19111 (* 1 = 1.19111 loss)
I1029 11:08:32.976274 12802 sgd_solver.cpp:105] Iteration 70440, lr = 1.76413e-05
I1029 11:09:02.640497 12802 solver.cpp:222] Iteration 70480 (1.34846 iter/s, 29.6635s/40 iters), loss = 1.76083
I1029 11:09:02.640560 12802 solver.cpp:241]     Train net output #0: loss = 1.76083 (* 1 = 1.76083 loss)
I1029 11:09:02.640573 12802 sgd_solver.cpp:105] Iteration 70480, lr = 1.75779e-05
I1029 11:09:16.714138 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_70500.caffemodel
I1029 11:09:16.851963 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_70500.solverstate
I1029 11:09:16.966166 12802 solver.cpp:334] Iteration 70500, Testing net (#0)
I1029 11:09:47.842851 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 11:09:48.049646 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5854
I1029 11:09:48.049691 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.815559
I1029 11:09:48.049702 12802 solver.cpp:401]     Test net output #2: loss = 1.83152 (* 1 = 1.83152 loss)
I1029 11:10:03.900030 12802 solver.cpp:222] Iteration 70520 (0.652976 iter/s, 61.258s/40 iters), loss = 1.5821
I1029 11:10:03.900090 12802 solver.cpp:241]     Train net output #0: loss = 1.5821 (* 1 = 1.5821 loss)
I1029 11:10:03.900105 12802 sgd_solver.cpp:105] Iteration 70520, lr = 1.75147e-05
I1029 11:10:33.736376 12802 solver.cpp:222] Iteration 70560 (1.34068 iter/s, 29.8356s/40 iters), loss = 1.26391
I1029 11:10:33.736623 12802 solver.cpp:241]     Train net output #0: loss = 1.26391 (* 1 = 1.26391 loss)
I1029 11:10:33.736641 12802 sgd_solver.cpp:105] Iteration 70560, lr = 1.74518e-05
I1029 11:11:03.506666 12802 solver.cpp:222] Iteration 70600 (1.34366 iter/s, 29.7693s/40 iters), loss = 1.08789
I1029 11:11:03.506721 12802 solver.cpp:241]     Train net output #0: loss = 1.08789 (* 1 = 1.08789 loss)
I1029 11:11:03.506737 12802 sgd_solver.cpp:105] Iteration 70600, lr = 1.73891e-05
I1029 11:11:32.929008 12802 solver.cpp:222] Iteration 70640 (1.35955 iter/s, 29.4216s/40 iters), loss = 1.53426
I1029 11:11:32.929183 12802 solver.cpp:241]     Train net output #0: loss = 1.53426 (* 1 = 1.53426 loss)
I1029 11:11:32.929199 12802 sgd_solver.cpp:105] Iteration 70640, lr = 1.73266e-05
I1029 11:12:02.354547 12802 solver.cpp:222] Iteration 70680 (1.3594 iter/s, 29.4247s/40 iters), loss = 1.23837
I1029 11:12:02.354601 12802 solver.cpp:241]     Train net output #0: loss = 1.23837 (* 1 = 1.23837 loss)
I1029 11:12:02.354616 12802 sgd_solver.cpp:105] Iteration 70680, lr = 1.72643e-05
I1029 11:12:31.788805 12802 solver.cpp:222] Iteration 70720 (1.359 iter/s, 29.4335s/40 iters), loss = 1.43825
I1029 11:12:31.788898 12802 solver.cpp:241]     Train net output #0: loss = 1.43825 (* 1 = 1.43825 loss)
I1029 11:12:31.788911 12802 sgd_solver.cpp:105] Iteration 70720, lr = 1.72023e-05
I1029 11:13:01.196234 12802 solver.cpp:222] Iteration 70760 (1.36024 iter/s, 29.4066s/40 iters), loss = 1.25119
I1029 11:13:01.196301 12802 solver.cpp:241]     Train net output #0: loss = 1.25119 (* 1 = 1.25119 loss)
I1029 11:13:01.196317 12802 sgd_solver.cpp:105] Iteration 70760, lr = 1.71404e-05
I1029 11:13:30.755403 12802 solver.cpp:222] Iteration 70800 (1.35325 iter/s, 29.5584s/40 iters), loss = 1.58094
I1029 11:13:30.755590 12802 solver.cpp:241]     Train net output #0: loss = 1.58094 (* 1 = 1.58094 loss)
I1029 11:13:30.755607 12802 sgd_solver.cpp:105] Iteration 70800, lr = 1.70788e-05
I1029 11:14:00.418838 12802 solver.cpp:222] Iteration 70840 (1.3485 iter/s, 29.6625s/40 iters), loss = 1.22023
I1029 11:14:00.418895 12802 solver.cpp:241]     Train net output #0: loss = 1.22023 (* 1 = 1.22023 loss)
I1029 11:14:00.418910 12802 sgd_solver.cpp:105] Iteration 70840, lr = 1.70175e-05
I1029 11:14:30.342011 12802 solver.cpp:222] Iteration 70880 (1.33679 iter/s, 29.9224s/40 iters), loss = 1.13242
I1029 11:14:30.342241 12802 solver.cpp:241]     Train net output #0: loss = 1.13242 (* 1 = 1.13242 loss)
I1029 11:14:30.342258 12802 sgd_solver.cpp:105] Iteration 70880, lr = 1.69563e-05
I1029 11:15:00.240906 12802 solver.cpp:222] Iteration 70920 (1.33788 iter/s, 29.898s/40 iters), loss = 1.18791
I1029 11:15:00.240968 12802 solver.cpp:241]     Train net output #0: loss = 1.18791 (* 1 = 1.18791 loss)
I1029 11:15:00.240983 12802 sgd_solver.cpp:105] Iteration 70920, lr = 1.68954e-05
I1029 11:15:47.195374 12802 solver.cpp:222] Iteration 70960 (0.85191 iter/s, 46.9533s/40 iters), loss = 1.3327
I1029 11:15:47.195569 12802 solver.cpp:241]     Train net output #0: loss = 1.3327 (* 1 = 1.3327 loss)
I1029 11:15:47.195583 12802 sgd_solver.cpp:105] Iteration 70960, lr = 1.68346e-05
I1029 11:16:17.293208 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_71000.caffemodel
I1029 11:16:17.439918 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_71000.solverstate
I1029 11:16:17.563239 12802 solver.cpp:334] Iteration 71000, Testing net (#0)
I1029 11:16:48.745729 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58952
I1029 11:16:48.746182 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.809799
I1029 11:16:48.746197 12802 solver.cpp:401]     Test net output #2: loss = 1.82519 (* 1 = 1.82519 loss)
I1029 11:16:49.512969 12802 solver.cpp:222] Iteration 71000 (0.64189 iter/s, 62.316s/40 iters), loss = 1.78905
I1029 11:16:49.513005 12802 solver.cpp:241]     Train net output #0: loss = 1.78905 (* 1 = 1.78905 loss)
I1029 11:16:49.513025 12802 sgd_solver.cpp:105] Iteration 71000, lr = 1.67741e-05
I1029 11:17:19.504830 12802 solver.cpp:222] Iteration 71040 (1.33373 iter/s, 29.9911s/40 iters), loss = 1.17768
I1029 11:17:19.505012 12802 solver.cpp:241]     Train net output #0: loss = 1.17768 (* 1 = 1.17768 loss)
I1029 11:17:19.505028 12802 sgd_solver.cpp:105] Iteration 71040, lr = 1.67139e-05
I1029 11:17:49.014971 12802 solver.cpp:222] Iteration 71080 (1.35551 iter/s, 29.5093s/40 iters), loss = 1.3398
I1029 11:17:49.015033 12802 solver.cpp:241]     Train net output #0: loss = 1.3398 (* 1 = 1.3398 loss)
I1029 11:17:49.015045 12802 sgd_solver.cpp:105] Iteration 71080, lr = 1.66538e-05
I1029 11:18:18.637682 12802 solver.cpp:222] Iteration 71120 (1.35035 iter/s, 29.6219s/40 iters), loss = 1.3776
I1029 11:18:18.637786 12802 solver.cpp:241]     Train net output #0: loss = 1.3776 (* 1 = 1.3776 loss)
I1029 11:18:18.637802 12802 sgd_solver.cpp:105] Iteration 71120, lr = 1.65939e-05
I1029 11:18:37.974788 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 11:18:48.273434 12802 solver.cpp:222] Iteration 71160 (1.34976 iter/s, 29.6349s/40 iters), loss = 1.69982
I1029 11:18:48.273494 12802 solver.cpp:241]     Train net output #0: loss = 1.69982 (* 1 = 1.69982 loss)
I1029 11:18:48.273509 12802 sgd_solver.cpp:105] Iteration 71160, lr = 1.65343e-05
I1029 11:19:17.941583 12802 solver.cpp:222] Iteration 71200 (1.34828 iter/s, 29.6674s/40 iters), loss = 1.5556
I1029 11:19:17.941725 12802 solver.cpp:241]     Train net output #0: loss = 1.5556 (* 1 = 1.5556 loss)
I1029 11:19:17.941741 12802 sgd_solver.cpp:105] Iteration 71200, lr = 1.64749e-05
I1029 11:19:47.617458 12802 solver.cpp:222] Iteration 71240 (1.34793 iter/s, 29.675s/40 iters), loss = 1.22334
I1029 11:19:47.617517 12802 solver.cpp:241]     Train net output #0: loss = 1.22334 (* 1 = 1.22334 loss)
I1029 11:19:47.617534 12802 sgd_solver.cpp:105] Iteration 71240, lr = 1.64157e-05
I1029 11:20:17.299347 12802 solver.cpp:222] Iteration 71280 (1.34766 iter/s, 29.6811s/40 iters), loss = 1.40907
I1029 11:20:17.299536 12802 solver.cpp:241]     Train net output #0: loss = 1.40907 (* 1 = 1.40907 loss)
I1029 11:20:17.299554 12802 sgd_solver.cpp:105] Iteration 71280, lr = 1.63567e-05
I1029 11:20:46.939425 12802 solver.cpp:222] Iteration 71320 (1.34956 iter/s, 29.6392s/40 iters), loss = 1.56731
I1029 11:20:46.939486 12802 solver.cpp:241]     Train net output #0: loss = 1.56731 (* 1 = 1.56731 loss)
I1029 11:20:46.939502 12802 sgd_solver.cpp:105] Iteration 71320, lr = 1.62979e-05
I1029 11:21:16.757788 12802 solver.cpp:222] Iteration 71360 (1.34149 iter/s, 29.8176s/40 iters), loss = 1.55053
I1029 11:21:16.758112 12802 solver.cpp:241]     Train net output #0: loss = 1.55053 (* 1 = 1.55053 loss)
I1029 11:21:16.758129 12802 sgd_solver.cpp:105] Iteration 71360, lr = 1.62393e-05
I1029 11:21:46.349138 12802 solver.cpp:222] Iteration 71400 (1.35179 iter/s, 29.5903s/40 iters), loss = 1.23973
I1029 11:21:46.349194 12802 solver.cpp:241]     Train net output #0: loss = 1.23973 (* 1 = 1.23973 loss)
I1029 11:21:46.349208 12802 sgd_solver.cpp:105] Iteration 71400, lr = 1.6181e-05
I1029 11:22:15.830473 12802 solver.cpp:222] Iteration 71440 (1.35683 iter/s, 29.4806s/40 iters), loss = 1.60395
I1029 11:22:15.830646 12802 solver.cpp:241]     Train net output #0: loss = 1.60395 (* 1 = 1.60395 loss)
I1029 11:22:15.830659 12802 sgd_solver.cpp:105] Iteration 71440, lr = 1.61228e-05
I1029 11:22:45.293570 12802 solver.cpp:222] Iteration 71480 (1.35767 iter/s, 29.4622s/40 iters), loss = 1.2504
I1029 11:22:45.293627 12802 solver.cpp:241]     Train net output #0: loss = 1.2504 (* 1 = 1.2504 loss)
I1029 11:22:45.293642 12802 sgd_solver.cpp:105] Iteration 71480, lr = 1.60649e-05
I1029 11:22:59.271821 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_71500.caffemodel
I1029 11:22:59.414523 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_71500.solverstate
I1029 11:22:59.539209 12802 solver.cpp:334] Iteration 71500, Testing net (#0)
I1029 11:23:30.487802 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 11:23:30.700489 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5856
I1029 11:23:30.700541 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8156
I1029 11:23:30.700552 12802 solver.cpp:401]     Test net output #2: loss = 1.83726 (* 1 = 1.83726 loss)
I1029 11:23:46.211663 12802 solver.cpp:222] Iteration 71520 (0.656635 iter/s, 60.9166s/40 iters), loss = 1.71408
I1029 11:23:46.211717 12802 solver.cpp:241]     Train net output #0: loss = 1.71408 (* 1 = 1.71408 loss)
I1029 11:23:46.211733 12802 sgd_solver.cpp:105] Iteration 71520, lr = 1.60071e-05
I1029 11:24:15.599321 12802 solver.cpp:222] Iteration 71560 (1.36115 iter/s, 29.3869s/40 iters), loss = 1.59098
I1029 11:24:15.599439 12802 solver.cpp:241]     Train net output #0: loss = 1.59098 (* 1 = 1.59098 loss)
I1029 11:24:15.599455 12802 sgd_solver.cpp:105] Iteration 71560, lr = 1.59496e-05
I1029 11:24:44.983402 12802 solver.cpp:222] Iteration 71600 (1.36132 iter/s, 29.3833s/40 iters), loss = 1.48709
I1029 11:24:44.983456 12802 solver.cpp:241]     Train net output #0: loss = 1.48709 (* 1 = 1.48709 loss)
I1029 11:24:44.983472 12802 sgd_solver.cpp:105] Iteration 71600, lr = 1.58923e-05
I1029 11:25:15.711125 12802 solver.cpp:222] Iteration 71640 (1.30179 iter/s, 30.7269s/40 iters), loss = 1.31267
I1029 11:25:15.711324 12802 solver.cpp:241]     Train net output #0: loss = 1.31267 (* 1 = 1.31267 loss)
I1029 11:25:15.711347 12802 sgd_solver.cpp:105] Iteration 71640, lr = 1.58352e-05
I1029 11:26:20.729894 12802 solver.cpp:222] Iteration 71680 (0.615223 iter/s, 65.0171s/40 iters), loss = 1.67548
I1029 11:26:20.730115 12802 solver.cpp:241]     Train net output #0: loss = 1.67548 (* 1 = 1.67548 loss)
I1029 11:26:20.730144 12802 sgd_solver.cpp:105] Iteration 71680, lr = 1.57783e-05
I1029 11:28:12.229521 12802 solver.cpp:222] Iteration 71720 (0.358754 iter/s, 111.497s/40 iters), loss = 1.51184
I1029 11:28:12.229698 12802 solver.cpp:241]     Train net output #0: loss = 1.51184 (* 1 = 1.51184 loss)
I1029 11:28:12.229715 12802 sgd_solver.cpp:105] Iteration 71720, lr = 1.57216e-05
I1029 11:28:42.338057 12802 solver.cpp:222] Iteration 71760 (1.32857 iter/s, 30.1077s/40 iters), loss = 1.38899
I1029 11:28:42.338217 12802 solver.cpp:241]     Train net output #0: loss = 1.38899 (* 1 = 1.38899 loss)
I1029 11:28:42.338234 12802 sgd_solver.cpp:105] Iteration 71760, lr = 1.56651e-05
I1029 11:29:24.696854 12802 solver.cpp:222] Iteration 71800 (0.944339 iter/s, 42.3577s/40 iters), loss = 1.55004
I1029 11:29:24.697072 12802 solver.cpp:241]     Train net output #0: loss = 1.55004 (* 1 = 1.55004 loss)
I1029 11:29:24.697088 12802 sgd_solver.cpp:105] Iteration 71800, lr = 1.56088e-05
I1029 11:29:58.443390 12802 solver.cpp:222] Iteration 71840 (1.18534 iter/s, 33.7455s/40 iters), loss = 1.5054
I1029 11:29:58.443593 12802 solver.cpp:241]     Train net output #0: loss = 1.5054 (* 1 = 1.5054 loss)
I1029 11:29:58.443611 12802 sgd_solver.cpp:105] Iteration 71840, lr = 1.55527e-05
I1029 11:30:28.656536 12802 solver.cpp:222] Iteration 71880 (1.32397 iter/s, 30.2122s/40 iters), loss = 1.20018
I1029 11:30:28.656705 12802 solver.cpp:241]     Train net output #0: loss = 1.20018 (* 1 = 1.20018 loss)
I1029 11:30:28.656719 12802 sgd_solver.cpp:105] Iteration 71880, lr = 1.54968e-05
I1029 11:30:58.236774 12802 solver.cpp:222] Iteration 71920 (1.35229 iter/s, 29.5794s/40 iters), loss = 1.34319
I1029 11:30:58.236840 12802 solver.cpp:241]     Train net output #0: loss = 1.34319 (* 1 = 1.34319 loss)
I1029 11:30:58.236855 12802 sgd_solver.cpp:105] Iteration 71920, lr = 1.54411e-05
I1029 11:31:27.777076 12802 solver.cpp:222] Iteration 71960 (1.35412 iter/s, 29.5395s/40 iters), loss = 1.44481
I1029 11:31:27.777348 12802 solver.cpp:241]     Train net output #0: loss = 1.44481 (* 1 = 1.44481 loss)
I1029 11:31:27.777375 12802 sgd_solver.cpp:105] Iteration 71960, lr = 1.53856e-05
I1029 11:31:57.053261 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_72000.caffemodel
I1029 11:31:57.221843 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_72000.solverstate
I1029 11:31:57.341130 12802 solver.cpp:334] Iteration 72000, Testing net (#0)
I1029 11:32:28.436683 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58872
I1029 11:32:28.436848 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81004
I1029 11:32:28.436862 12802 solver.cpp:401]     Test net output #2: loss = 1.82869 (* 1 = 1.82869 loss)
I1029 11:32:29.212385 12802 solver.cpp:222] Iteration 72000 (0.651109 iter/s, 61.4336s/40 iters), loss = 1.70931
I1029 11:32:29.212421 12802 solver.cpp:241]     Train net output #0: loss = 1.70931 (* 1 = 1.70931 loss)
I1029 11:32:29.212436 12802 sgd_solver.cpp:105] Iteration 72000, lr = 1.53303e-05
I1029 11:32:58.954406 12802 solver.cpp:222] Iteration 72040 (1.34493 iter/s, 29.7413s/40 iters), loss = 1.30647
I1029 11:32:58.954596 12802 solver.cpp:241]     Train net output #0: loss = 1.30647 (* 1 = 1.30647 loss)
I1029 11:32:58.954609 12802 sgd_solver.cpp:105] Iteration 72040, lr = 1.52752e-05
I1029 11:33:28.548264 12802 solver.cpp:222] Iteration 72080 (1.35167 iter/s, 29.593s/40 iters), loss = 1.74949
I1029 11:33:28.548321 12802 solver.cpp:241]     Train net output #0: loss = 1.74949 (* 1 = 1.74949 loss)
I1029 11:33:28.548336 12802 sgd_solver.cpp:105] Iteration 72080, lr = 1.52203e-05
I1029 11:33:58.156574 12802 solver.cpp:222] Iteration 72120 (1.35101 iter/s, 29.6075s/40 iters), loss = 1.51499
I1029 11:33:58.156777 12802 solver.cpp:241]     Train net output #0: loss = 1.51499 (* 1 = 1.51499 loss)
I1029 11:33:58.156795 12802 sgd_solver.cpp:105] Iteration 72120, lr = 1.51656e-05
I1029 11:34:27.657857 12802 solver.cpp:222] Iteration 72160 (1.35591 iter/s, 29.5004s/40 iters), loss = 1.69279
I1029 11:34:27.657917 12802 solver.cpp:241]     Train net output #0: loss = 1.69279 (* 1 = 1.69279 loss)
I1029 11:34:27.657933 12802 sgd_solver.cpp:105] Iteration 72160, lr = 1.51111e-05
I1029 11:34:57.100582 12802 solver.cpp:222] Iteration 72200 (1.35861 iter/s, 29.442s/40 iters), loss = 1.33091
I1029 11:34:57.100761 12802 solver.cpp:241]     Train net output #0: loss = 1.33091 (* 1 = 1.33091 loss)
I1029 11:34:57.100778 12802 sgd_solver.cpp:105] Iteration 72200, lr = 1.50568e-05
I1029 11:35:30.562991 12802 solver.cpp:222] Iteration 72240 (1.19541 iter/s, 33.4614s/40 iters), loss = 1.49887
I1029 11:35:30.563149 12802 solver.cpp:241]     Train net output #0: loss = 1.49887 (* 1 = 1.49887 loss)
I1029 11:35:30.563169 12802 sgd_solver.cpp:105] Iteration 72240, lr = 1.50027e-05
I1029 11:36:00.291555 12802 solver.cpp:222] Iteration 72280 (1.34555 iter/s, 29.7277s/40 iters), loss = 1.28427
I1029 11:36:00.291615 12802 solver.cpp:241]     Train net output #0: loss = 1.28427 (* 1 = 1.28427 loss)
I1029 11:36:00.291628 12802 sgd_solver.cpp:105] Iteration 72280, lr = 1.49488e-05
I1029 11:36:29.872351 12802 solver.cpp:222] Iteration 72320 (1.35226 iter/s, 29.58s/40 iters), loss = 1.3413
I1029 11:36:29.872529 12802 solver.cpp:241]     Train net output #0: loss = 1.3413 (* 1 = 1.3413 loss)
I1029 11:36:29.872546 12802 sgd_solver.cpp:105] Iteration 72320, lr = 1.48951e-05
I1029 11:37:07.682610 12802 solver.cpp:222] Iteration 72360 (1.05794 iter/s, 37.8092s/40 iters), loss = 1.25296
I1029 11:37:07.682790 12802 solver.cpp:241]     Train net output #0: loss = 1.25296 (* 1 = 1.25296 loss)
I1029 11:37:07.682806 12802 sgd_solver.cpp:105] Iteration 72360, lr = 1.48415e-05
I1029 11:37:38.369127 12802 solver.cpp:222] Iteration 72400 (1.30354 iter/s, 30.6856s/40 iters), loss = 1.45926
I1029 11:37:38.369406 12802 solver.cpp:241]     Train net output #0: loss = 1.45926 (* 1 = 1.45926 loss)
I1029 11:37:38.369436 12802 sgd_solver.cpp:105] Iteration 72400, lr = 1.47882e-05
I1029 11:38:08.614071 12802 solver.cpp:222] Iteration 72440 (1.32258 iter/s, 30.244s/40 iters), loss = 1.42728
I1029 11:38:08.614240 12802 solver.cpp:241]     Train net output #0: loss = 1.42728 (* 1 = 1.42728 loss)
I1029 11:38:08.614259 12802 sgd_solver.cpp:105] Iteration 72440, lr = 1.4735e-05
I1029 11:38:38.158995 12802 solver.cpp:222] Iteration 72480 (1.35391 iter/s, 29.5441s/40 iters), loss = 1.36223
I1029 11:38:38.159056 12802 solver.cpp:241]     Train net output #0: loss = 1.36223 (* 1 = 1.36223 loss)
I1029 11:38:38.159070 12802 sgd_solver.cpp:105] Iteration 72480, lr = 1.46821e-05
I1029 11:38:52.174224 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_72500.caffemodel
I1029 11:38:52.327208 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_72500.solverstate
I1029 11:38:52.442864 12802 solver.cpp:334] Iteration 72500, Testing net (#0)
I1029 11:39:23.325099 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 11:39:23.533282 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58548
I1029 11:39:23.533331 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.815319
I1029 11:39:23.533342 12802 solver.cpp:401]     Test net output #2: loss = 1.83338 (* 1 = 1.83338 loss)
I1029 11:39:39.109668 12802 solver.cpp:222] Iteration 72520 (0.656284 iter/s, 60.9492s/40 iters), loss = 1.3656
I1029 11:39:39.109724 12802 solver.cpp:241]     Train net output #0: loss = 1.3656 (* 1 = 1.3656 loss)
I1029 11:39:39.109740 12802 sgd_solver.cpp:105] Iteration 72520, lr = 1.46293e-05
I1029 11:40:08.657194 12802 solver.cpp:222] Iteration 72560 (1.35379 iter/s, 29.5468s/40 iters), loss = 1.42948
I1029 11:40:08.657362 12802 solver.cpp:241]     Train net output #0: loss = 1.42948 (* 1 = 1.42948 loss)
I1029 11:40:08.657379 12802 sgd_solver.cpp:105] Iteration 72560, lr = 1.45767e-05
I1029 11:40:38.277694 12802 solver.cpp:222] Iteration 72600 (1.35046 iter/s, 29.6196s/40 iters), loss = 1.67937
I1029 11:40:38.277753 12802 solver.cpp:241]     Train net output #0: loss = 1.67937 (* 1 = 1.67937 loss)
I1029 11:40:38.277771 12802 sgd_solver.cpp:105] Iteration 72600, lr = 1.45244e-05
I1029 11:41:09.790052 12802 solver.cpp:222] Iteration 72640 (1.26938 iter/s, 31.5116s/40 iters), loss = 1.43082
I1029 11:41:09.790240 12802 solver.cpp:241]     Train net output #0: loss = 1.43082 (* 1 = 1.43082 loss)
I1029 11:41:09.790258 12802 sgd_solver.cpp:105] Iteration 72640, lr = 1.44722e-05
I1029 11:41:40.862457 12802 solver.cpp:222] Iteration 72680 (1.28735 iter/s, 31.0715s/40 iters), loss = 1.32387
I1029 11:41:40.862653 12802 solver.cpp:241]     Train net output #0: loss = 1.32387 (* 1 = 1.32387 loss)
I1029 11:41:40.862670 12802 sgd_solver.cpp:105] Iteration 72680, lr = 1.44202e-05
I1029 11:42:11.547590 12802 solver.cpp:222] Iteration 72720 (1.3036 iter/s, 30.6842s/40 iters), loss = 1.29221
I1029 11:42:11.547739 12802 solver.cpp:241]     Train net output #0: loss = 1.29221 (* 1 = 1.29221 loss)
I1029 11:42:11.547756 12802 sgd_solver.cpp:105] Iteration 72720, lr = 1.43683e-05
I1029 11:42:41.894062 12802 solver.cpp:222] Iteration 72760 (1.31815 iter/s, 30.3456s/40 iters), loss = 1.3226
I1029 11:42:41.894238 12802 solver.cpp:241]     Train net output #0: loss = 1.3226 (* 1 = 1.3226 loss)
I1029 11:42:41.894256 12802 sgd_solver.cpp:105] Iteration 72760, lr = 1.43167e-05
I1029 11:43:11.882751 12802 solver.cpp:222] Iteration 72800 (1.33388 iter/s, 29.9878s/40 iters), loss = 1.53961
I1029 11:43:11.882812 12802 solver.cpp:241]     Train net output #0: loss = 1.53961 (* 1 = 1.53961 loss)
I1029 11:43:11.882828 12802 sgd_solver.cpp:105] Iteration 72800, lr = 1.42652e-05
I1029 11:43:41.225833 12802 solver.cpp:222] Iteration 72840 (1.36322 iter/s, 29.3423s/40 iters), loss = 1.41357
I1029 11:43:41.225993 12802 solver.cpp:241]     Train net output #0: loss = 1.41357 (* 1 = 1.41357 loss)
I1029 11:43:41.226037 12802 sgd_solver.cpp:105] Iteration 72840, lr = 1.4214e-05
I1029 11:44:10.594204 12802 solver.cpp:222] Iteration 72880 (1.36205 iter/s, 29.3675s/40 iters), loss = 1.20102
I1029 11:44:10.594262 12802 solver.cpp:241]     Train net output #0: loss = 1.20102 (* 1 = 1.20102 loss)
I1029 11:44:10.594275 12802 sgd_solver.cpp:105] Iteration 72880, lr = 1.41629e-05
I1029 11:44:40.008774 12802 solver.cpp:222] Iteration 72920 (1.35991 iter/s, 29.4138s/40 iters), loss = 1.57142
I1029 11:44:40.008918 12802 solver.cpp:241]     Train net output #0: loss = 1.57142 (* 1 = 1.57142 loss)
I1029 11:44:40.008939 12802 sgd_solver.cpp:105] Iteration 72920, lr = 1.4112e-05
I1029 11:45:09.495952 12802 solver.cpp:222] Iteration 72960 (1.35656 iter/s, 29.4863s/40 iters), loss = 1.47912
I1029 11:45:09.496013 12802 solver.cpp:241]     Train net output #0: loss = 1.47912 (* 1 = 1.47912 loss)
I1029 11:45:09.496029 12802 sgd_solver.cpp:105] Iteration 72960, lr = 1.40613e-05
I1029 11:45:38.547374 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_73000.caffemodel
I1029 11:45:38.698175 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_73000.solverstate
I1029 11:45:38.821259 12802 solver.cpp:334] Iteration 73000, Testing net (#0)
I1029 11:46:09.991837 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58956
I1029 11:46:09.991931 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81016
I1029 11:46:09.991943 12802 solver.cpp:401]     Test net output #2: loss = 1.82908 (* 1 = 1.82908 loss)
I1029 11:46:10.759991 12802 solver.cpp:222] Iteration 73000 (0.652927 iter/s, 61.2626s/40 iters), loss = 1.97789
I1029 11:46:10.760031 12802 solver.cpp:241]     Train net output #0: loss = 1.97789 (* 1 = 1.97789 loss)
I1029 11:46:10.760066 12802 sgd_solver.cpp:105] Iteration 73000, lr = 1.40107e-05
I1029 11:46:40.600322 12802 solver.cpp:222] Iteration 73040 (1.3405 iter/s, 29.8396s/40 iters), loss = 1.38066
I1029 11:46:40.600492 12802 solver.cpp:241]     Train net output #0: loss = 1.38066 (* 1 = 1.38066 loss)
I1029 11:46:40.600508 12802 sgd_solver.cpp:105] Iteration 73040, lr = 1.39604e-05
I1029 11:47:11.407635 12802 solver.cpp:222] Iteration 73080 (1.29843 iter/s, 30.8064s/40 iters), loss = 1.07466
I1029 11:47:11.407821 12802 solver.cpp:241]     Train net output #0: loss = 1.07466 (* 1 = 1.07466 loss)
I1029 11:47:11.407840 12802 sgd_solver.cpp:105] Iteration 73080, lr = 1.39102e-05
I1029 11:47:42.763778 12802 solver.cpp:222] Iteration 73120 (1.2757 iter/s, 31.3552s/40 iters), loss = 1.55287
I1029 11:47:42.763957 12802 solver.cpp:241]     Train net output #0: loss = 1.55287 (* 1 = 1.55287 loss)
I1029 11:47:42.763975 12802 sgd_solver.cpp:105] Iteration 73120, lr = 1.38602e-05
I1029 11:48:13.218001 12802 solver.cpp:222] Iteration 73160 (1.31349 iter/s, 30.4533s/40 iters), loss = 1.36447
I1029 11:48:13.218183 12802 solver.cpp:241]     Train net output #0: loss = 1.36447 (* 1 = 1.36447 loss)
I1029 11:48:13.218200 12802 sgd_solver.cpp:105] Iteration 73160, lr = 1.38104e-05
I1029 11:48:42.865232 12802 solver.cpp:222] Iteration 73200 (1.34924 iter/s, 29.6463s/40 iters), loss = 1.428
I1029 11:48:42.865293 12802 solver.cpp:241]     Train net output #0: loss = 1.428 (* 1 = 1.428 loss)
I1029 11:48:42.865306 12802 sgd_solver.cpp:105] Iteration 73200, lr = 1.37608e-05
I1029 11:49:12.554208 12802 solver.cpp:222] Iteration 73240 (1.34734 iter/s, 29.6882s/40 iters), loss = 1.24742
I1029 11:49:12.554394 12802 solver.cpp:241]     Train net output #0: loss = 1.24742 (* 1 = 1.24742 loss)
I1029 11:49:12.554411 12802 sgd_solver.cpp:105] Iteration 73240, lr = 1.37113e-05
I1029 11:50:01.879125 12802 solver.cpp:222] Iteration 73280 (0.810971 iter/s, 49.3236s/40 iters), loss = 1.77502
I1029 11:50:01.879287 12802 solver.cpp:241]     Train net output #0: loss = 1.77502 (* 1 = 1.77502 loss)
I1029 11:50:01.879303 12802 sgd_solver.cpp:105] Iteration 73280, lr = 1.36621e-05
I1029 11:50:31.733227 12802 solver.cpp:222] Iteration 73320 (1.33989 iter/s, 29.8532s/40 iters), loss = 1.51325
I1029 11:50:31.733292 12802 solver.cpp:241]     Train net output #0: loss = 1.51325 (* 1 = 1.51325 loss)
I1029 11:50:31.733309 12802 sgd_solver.cpp:105] Iteration 73320, lr = 1.3613e-05
I1029 11:51:02.311436 12802 solver.cpp:222] Iteration 73360 (1.30815 iter/s, 30.5774s/40 iters), loss = 1.49023
I1029 11:51:02.311661 12802 solver.cpp:241]     Train net output #0: loss = 1.49023 (* 1 = 1.49023 loss)
I1029 11:51:02.311678 12802 sgd_solver.cpp:105] Iteration 73360, lr = 1.3564e-05
I1029 11:51:32.836498 12802 solver.cpp:222] Iteration 73400 (1.31044 iter/s, 30.5241s/40 iters), loss = 1.01776
I1029 11:51:32.836666 12802 solver.cpp:241]     Train net output #0: loss = 1.01776 (* 1 = 1.01776 loss)
I1029 11:51:32.836685 12802 sgd_solver.cpp:105] Iteration 73400, lr = 1.35153e-05
I1029 11:52:02.787247 12802 solver.cpp:222] Iteration 73440 (1.33556 iter/s, 29.9499s/40 iters), loss = 1.72383
I1029 11:52:02.787304 12802 solver.cpp:241]     Train net output #0: loss = 1.72383 (* 1 = 1.72383 loss)
I1029 11:52:02.787318 12802 sgd_solver.cpp:105] Iteration 73440, lr = 1.34667e-05
I1029 11:52:32.496294 12802 solver.cpp:222] Iteration 73480 (1.34643 iter/s, 29.7083s/40 iters), loss = 1.32709
I1029 11:52:32.496484 12802 solver.cpp:241]     Train net output #0: loss = 1.32709 (* 1 = 1.32709 loss)
I1029 11:52:32.496498 12802 sgd_solver.cpp:105] Iteration 73480, lr = 1.34183e-05
I1029 11:52:46.663023 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_73500.caffemodel
I1029 11:52:46.802047 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_73500.solverstate
I1029 11:52:46.915971 12802 solver.cpp:334] Iteration 73500, Testing net (#0)
I1029 11:53:17.761484 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 11:53:17.968385 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58548
I1029 11:53:17.968435 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81516
I1029 11:53:17.968446 12802 solver.cpp:401]     Test net output #2: loss = 1.83064 (* 1 = 1.83064 loss)
I1029 11:53:33.647346 12802 solver.cpp:222] Iteration 73520 (0.654135 iter/s, 61.1494s/40 iters), loss = 1.34057
I1029 11:53:33.647428 12802 solver.cpp:241]     Train net output #0: loss = 1.34057 (* 1 = 1.34057 loss)
I1029 11:53:33.647452 12802 sgd_solver.cpp:105] Iteration 73520, lr = 1.33701e-05
I1029 11:54:04.782992 12802 solver.cpp:222] Iteration 73560 (1.28473 iter/s, 31.1348s/40 iters), loss = 1.11278
I1029 11:54:04.783162 12802 solver.cpp:241]     Train net output #0: loss = 1.11278 (* 1 = 1.11278 loss)
I1029 11:54:04.783179 12802 sgd_solver.cpp:105] Iteration 73560, lr = 1.33221e-05
I1029 11:55:03.538833 12802 solver.cpp:222] Iteration 73600 (0.680801 iter/s, 58.7543s/40 iters), loss = 1.0693
I1029 11:55:03.539011 12802 solver.cpp:241]     Train net output #0: loss = 1.0693 (* 1 = 1.0693 loss)
I1029 11:55:03.539036 12802 sgd_solver.cpp:105] Iteration 73600, lr = 1.32742e-05
I1029 11:55:41.333780 12802 solver.cpp:222] Iteration 73640 (1.05837 iter/s, 37.7939s/40 iters), loss = 1.304
I1029 11:55:41.334071 12802 solver.cpp:241]     Train net output #0: loss = 1.304 (* 1 = 1.304 loss)
I1029 11:55:41.334092 12802 sgd_solver.cpp:105] Iteration 73640, lr = 1.32265e-05
I1029 11:56:07.441365 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 11:56:30.368218 12802 solver.cpp:222] Iteration 73680 (0.815777 iter/s, 49.033s/40 iters), loss = 1.11253
I1029 11:56:30.368427 12802 solver.cpp:241]     Train net output #0: loss = 1.11253 (* 1 = 1.11253 loss)
I1029 11:56:30.368444 12802 sgd_solver.cpp:105] Iteration 73680, lr = 1.31789e-05
I1029 11:57:00.552422 12802 solver.cpp:222] Iteration 73720 (1.32524 iter/s, 30.1833s/40 iters), loss = 1.27883
I1029 11:57:00.552618 12802 solver.cpp:241]     Train net output #0: loss = 1.27883 (* 1 = 1.27883 loss)
I1029 11:57:00.552634 12802 sgd_solver.cpp:105] Iteration 73720, lr = 1.31316e-05
I1029 11:57:30.401181 12802 solver.cpp:222] Iteration 73760 (1.34013 iter/s, 29.8479s/40 iters), loss = 1.21803
I1029 11:57:30.401237 12802 solver.cpp:241]     Train net output #0: loss = 1.21803 (* 1 = 1.21803 loss)
I1029 11:57:30.401250 12802 sgd_solver.cpp:105] Iteration 73760, lr = 1.30844e-05
I1029 11:58:00.215723 12802 solver.cpp:222] Iteration 73800 (1.34166 iter/s, 29.8138s/40 iters), loss = 1.34231
I1029 11:58:00.215939 12802 solver.cpp:241]     Train net output #0: loss = 1.34231 (* 1 = 1.34231 loss)
I1029 11:58:00.215960 12802 sgd_solver.cpp:105] Iteration 73800, lr = 1.30374e-05
I1029 11:58:30.228106 12802 solver.cpp:222] Iteration 73840 (1.33283 iter/s, 30.0114s/40 iters), loss = 1.38222
I1029 11:58:30.228350 12802 solver.cpp:241]     Train net output #0: loss = 1.38222 (* 1 = 1.38222 loss)
I1029 11:58:30.228400 12802 sgd_solver.cpp:105] Iteration 73840, lr = 1.29905e-05
I1029 11:58:59.983141 12802 solver.cpp:222] Iteration 73880 (1.34435 iter/s, 29.7541s/40 iters), loss = 1.38054
I1029 11:58:59.983204 12802 solver.cpp:241]     Train net output #0: loss = 1.38054 (* 1 = 1.38054 loss)
I1029 11:58:59.983220 12802 sgd_solver.cpp:105] Iteration 73880, lr = 1.29438e-05
I1029 11:59:29.616576 12802 solver.cpp:222] Iteration 73920 (1.34986 iter/s, 29.6327s/40 iters), loss = 1.56132
I1029 11:59:29.616722 12802 solver.cpp:241]     Train net output #0: loss = 1.56132 (* 1 = 1.56132 loss)
I1029 11:59:29.616739 12802 sgd_solver.cpp:105] Iteration 73920, lr = 1.28973e-05
I1029 11:59:59.301839 12802 solver.cpp:222] Iteration 73960 (1.34751 iter/s, 29.6844s/40 iters), loss = 1.41868
I1029 11:59:59.301898 12802 solver.cpp:241]     Train net output #0: loss = 1.41868 (* 1 = 1.41868 loss)
I1029 11:59:59.301913 12802 sgd_solver.cpp:105] Iteration 73960, lr = 1.2851e-05
I1029 12:00:28.255841 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_74000.caffemodel
I1029 12:00:28.397459 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_74000.solverstate
I1029 12:00:28.514133 12802 solver.cpp:334] Iteration 74000, Testing net (#0)
I1029 12:01:00.197794 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.59
I1029 12:01:00.197942 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8102
I1029 12:01:00.197955 12802 solver.cpp:401]     Test net output #2: loss = 1.83212 (* 1 = 1.83212 loss)
I1029 12:01:00.953656 12802 solver.cpp:222] Iteration 74000 (0.648821 iter/s, 61.6503s/40 iters), loss = 1.22225
I1029 12:01:00.953721 12802 solver.cpp:241]     Train net output #0: loss = 1.22225 (* 1 = 1.22225 loss)
I1029 12:01:00.953737 12802 sgd_solver.cpp:105] Iteration 74000, lr = 1.28048e-05
I1029 12:01:30.607070 12802 solver.cpp:222] Iteration 74040 (1.34895 iter/s, 29.6526s/40 iters), loss = 1.13441
I1029 12:01:30.607276 12802 solver.cpp:241]     Train net output #0: loss = 1.13441 (* 1 = 1.13441 loss)
I1029 12:01:30.607295 12802 sgd_solver.cpp:105] Iteration 74040, lr = 1.27588e-05
I1029 12:02:00.218657 12802 solver.cpp:222] Iteration 74080 (1.35086 iter/s, 29.6107s/40 iters), loss = 1.64654
I1029 12:02:00.218714 12802 solver.cpp:241]     Train net output #0: loss = 1.64654 (* 1 = 1.64654 loss)
I1029 12:02:00.218730 12802 sgd_solver.cpp:105] Iteration 74080, lr = 1.27129e-05
I1029 12:02:30.364882 12802 solver.cpp:222] Iteration 74120 (1.3269 iter/s, 30.1454s/40 iters), loss = 1.42414
I1029 12:02:30.365034 12802 solver.cpp:241]     Train net output #0: loss = 1.42414 (* 1 = 1.42414 loss)
I1029 12:02:30.365051 12802 sgd_solver.cpp:105] Iteration 74120, lr = 1.26672e-05
I1029 12:03:00.797938 12802 solver.cpp:222] Iteration 74160 (1.3144 iter/s, 30.4322s/40 iters), loss = 1.33634
I1029 12:03:00.798163 12802 solver.cpp:241]     Train net output #0: loss = 1.33634 (* 1 = 1.33634 loss)
I1029 12:03:00.798182 12802 sgd_solver.cpp:105] Iteration 74160, lr = 1.26217e-05
I1029 12:03:30.732833 12802 solver.cpp:222] Iteration 74200 (1.33628 iter/s, 29.934s/40 iters), loss = 1.62536
I1029 12:03:30.732890 12802 solver.cpp:241]     Train net output #0: loss = 1.62536 (* 1 = 1.62536 loss)
I1029 12:03:30.732905 12802 sgd_solver.cpp:105] Iteration 74200, lr = 1.25763e-05
I1029 12:04:00.952991 12802 solver.cpp:222] Iteration 74240 (1.32365 iter/s, 30.2194s/40 iters), loss = 1.43119
I1029 12:04:00.953223 12802 solver.cpp:241]     Train net output #0: loss = 1.43119 (* 1 = 1.43119 loss)
I1029 12:04:00.953239 12802 sgd_solver.cpp:105] Iteration 74240, lr = 1.25311e-05
I1029 12:04:31.571704 12802 solver.cpp:222] Iteration 74280 (1.30643 iter/s, 30.6178s/40 iters), loss = 1.27131
I1029 12:04:31.571846 12802 solver.cpp:241]     Train net output #0: loss = 1.27131 (* 1 = 1.27131 loss)
I1029 12:04:31.571863 12802 sgd_solver.cpp:105] Iteration 74280, lr = 1.24861e-05
I1029 12:05:02.215533 12802 solver.cpp:222] Iteration 74320 (1.30536 iter/s, 30.643s/40 iters), loss = 1.49207
I1029 12:05:02.215628 12802 solver.cpp:241]     Train net output #0: loss = 1.49207 (* 1 = 1.49207 loss)
I1029 12:05:02.215646 12802 sgd_solver.cpp:105] Iteration 74320, lr = 1.24412e-05
I1029 12:05:31.882236 12802 solver.cpp:222] Iteration 74360 (1.34835 iter/s, 29.6659s/40 iters), loss = 1.17407
I1029 12:05:31.882285 12802 solver.cpp:241]     Train net output #0: loss = 1.17407 (* 1 = 1.17407 loss)
I1029 12:05:31.882302 12802 sgd_solver.cpp:105] Iteration 74360, lr = 1.23965e-05
I1029 12:06:02.529018 12802 solver.cpp:222] Iteration 74400 (1.30523 iter/s, 30.646s/40 iters), loss = 1.59493
I1029 12:06:02.529209 12802 solver.cpp:241]     Train net output #0: loss = 1.59493 (* 1 = 1.59493 loss)
I1029 12:06:02.529234 12802 sgd_solver.cpp:105] Iteration 74400, lr = 1.2352e-05
I1029 12:06:32.768287 12802 solver.cpp:222] Iteration 74440 (1.32282 iter/s, 30.2384s/40 iters), loss = 1.33879
I1029 12:06:32.768393 12802 solver.cpp:241]     Train net output #0: loss = 1.33879 (* 1 = 1.33879 loss)
I1029 12:06:32.768414 12802 sgd_solver.cpp:105] Iteration 74440, lr = 1.23076e-05
I1029 12:07:02.362222 12802 solver.cpp:222] Iteration 74480 (1.35167 iter/s, 29.5931s/40 iters), loss = 1.33016
I1029 12:07:02.362280 12802 solver.cpp:241]     Train net output #0: loss = 1.33016 (* 1 = 1.33016 loss)
I1029 12:07:02.362296 12802 sgd_solver.cpp:105] Iteration 74480, lr = 1.22633e-05
I1029 12:07:16.408243 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_74500.caffemodel
I1029 12:07:16.549633 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_74500.solverstate
I1029 12:07:16.660938 12802 solver.cpp:334] Iteration 74500, Testing net (#0)
I1029 12:07:47.522368 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 12:07:47.730444 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58472
I1029 12:07:47.730494 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.815
I1029 12:07:47.730504 12802 solver.cpp:401]     Test net output #2: loss = 1.83316 (* 1 = 1.83316 loss)
I1029 12:08:03.699043 12802 solver.cpp:222] Iteration 74520 (0.652153 iter/s, 61.3353s/40 iters), loss = 1.07838
I1029 12:08:03.699100 12802 solver.cpp:241]     Train net output #0: loss = 1.07838 (* 1 = 1.07838 loss)
I1029 12:08:03.699116 12802 sgd_solver.cpp:105] Iteration 74520, lr = 1.22193e-05
I1029 12:08:33.742075 12802 solver.cpp:222] Iteration 74560 (1.33146 iter/s, 30.0422s/40 iters), loss = 1.43341
I1029 12:08:33.742266 12802 solver.cpp:241]     Train net output #0: loss = 1.43341 (* 1 = 1.43341 loss)
I1029 12:08:33.742287 12802 sgd_solver.cpp:105] Iteration 74560, lr = 1.21754e-05
I1029 12:09:04.341907 12802 solver.cpp:222] Iteration 74600 (1.30724 iter/s, 30.5989s/40 iters), loss = 1.37101
I1029 12:09:04.342108 12802 solver.cpp:241]     Train net output #0: loss = 1.37101 (* 1 = 1.37101 loss)
I1029 12:09:04.342128 12802 sgd_solver.cpp:105] Iteration 74600, lr = 1.21316e-05
I1029 12:09:34.221302 12802 solver.cpp:222] Iteration 74640 (1.33876 iter/s, 29.8785s/40 iters), loss = 1.41205
I1029 12:09:34.221357 12802 solver.cpp:241]     Train net output #0: loss = 1.41205 (* 1 = 1.41205 loss)
I1029 12:09:34.221372 12802 sgd_solver.cpp:105] Iteration 74640, lr = 1.2088e-05
I1029 12:10:03.684764 12802 solver.cpp:222] Iteration 74680 (1.35765 iter/s, 29.4627s/40 iters), loss = 1.47014
I1029 12:10:03.685168 12802 solver.cpp:241]     Train net output #0: loss = 1.47014 (* 1 = 1.47014 loss)
I1029 12:10:03.685186 12802 sgd_solver.cpp:105] Iteration 74680, lr = 1.20446e-05
I1029 12:10:33.103835 12802 solver.cpp:222] Iteration 74720 (1.35971 iter/s, 29.418s/40 iters), loss = 1.35132
I1029 12:10:33.103893 12802 solver.cpp:241]     Train net output #0: loss = 1.35132 (* 1 = 1.35132 loss)
I1029 12:10:33.103909 12802 sgd_solver.cpp:105] Iteration 74720, lr = 1.20013e-05
I1029 12:11:02.533426 12802 solver.cpp:222] Iteration 74760 (1.35921 iter/s, 29.4288s/40 iters), loss = 1.42187
I1029 12:11:02.533587 12802 solver.cpp:241]     Train net output #0: loss = 1.42187 (* 1 = 1.42187 loss)
I1029 12:11:02.533603 12802 sgd_solver.cpp:105] Iteration 74760, lr = 1.19581e-05
I1029 12:11:32.106156 12802 solver.cpp:222] Iteration 74800 (1.35264 iter/s, 29.5719s/40 iters), loss = 1.53183
I1029 12:11:32.106212 12802 solver.cpp:241]     Train net output #0: loss = 1.53183 (* 1 = 1.53183 loss)
I1029 12:11:32.106227 12802 sgd_solver.cpp:105] Iteration 74800, lr = 1.19152e-05
I1029 12:12:01.717547 12802 solver.cpp:222] Iteration 74840 (1.35087 iter/s, 29.6106s/40 iters), loss = 1.43309
I1029 12:12:01.717697 12802 solver.cpp:241]     Train net output #0: loss = 1.43309 (* 1 = 1.43309 loss)
I1029 12:12:01.717712 12802 sgd_solver.cpp:105] Iteration 74840, lr = 1.18723e-05
I1029 12:12:31.255910 12802 solver.cpp:222] Iteration 74880 (1.35421 iter/s, 29.5375s/40 iters), loss = 1.62296
I1029 12:12:31.255973 12802 solver.cpp:241]     Train net output #0: loss = 1.62296 (* 1 = 1.62296 loss)
I1029 12:12:31.255988 12802 sgd_solver.cpp:105] Iteration 74880, lr = 1.18297e-05
I1029 12:13:00.825212 12802 solver.cpp:222] Iteration 74920 (1.35279 iter/s, 29.5685s/40 iters), loss = 1.85258
I1029 12:13:00.825359 12802 solver.cpp:241]     Train net output #0: loss = 1.85258 (* 1 = 1.85258 loss)
I1029 12:13:00.825376 12802 sgd_solver.cpp:105] Iteration 74920, lr = 1.17872e-05
I1029 12:13:30.460296 12802 solver.cpp:222] Iteration 74960 (1.34979 iter/s, 29.6342s/40 iters), loss = 1.2658
I1029 12:13:30.460352 12802 solver.cpp:241]     Train net output #0: loss = 1.2658 (* 1 = 1.2658 loss)
I1029 12:13:30.460367 12802 sgd_solver.cpp:105] Iteration 74960, lr = 1.17448e-05
I1029 12:13:59.326300 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_75000.caffemodel
I1029 12:13:59.478533 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_75000.solverstate
I1029 12:13:59.605824 12802 solver.cpp:334] Iteration 75000, Testing net (#0)
I1029 12:14:30.763841 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58952
I1029 12:14:30.763936 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80976
I1029 12:14:30.763949 12802 solver.cpp:401]     Test net output #2: loss = 1.82808 (* 1 = 1.82808 loss)
I1029 12:14:31.518848 12802 solver.cpp:222] Iteration 75000 (0.655125 iter/s, 61.0571s/40 iters), loss = 1.79775
I1029 12:14:31.518906 12802 solver.cpp:241]     Train net output #0: loss = 1.79775 (* 1 = 1.79775 loss)
I1029 12:14:31.518925 12802 sgd_solver.cpp:105] Iteration 75000, lr = 1.17026e-05
I1029 12:15:01.215111 12802 solver.cpp:222] Iteration 75040 (1.34701 iter/s, 29.6955s/40 iters), loss = 1.75322
I1029 12:15:01.215270 12802 solver.cpp:241]     Train net output #0: loss = 1.75322 (* 1 = 1.75322 loss)
I1029 12:15:01.215286 12802 sgd_solver.cpp:105] Iteration 75040, lr = 1.16605e-05
I1029 12:15:30.898769 12802 solver.cpp:222] Iteration 75080 (1.34758 iter/s, 29.6828s/40 iters), loss = 1.14031
I1029 12:15:30.898834 12802 solver.cpp:241]     Train net output #0: loss = 1.14031 (* 1 = 1.14031 loss)
I1029 12:15:30.898850 12802 sgd_solver.cpp:105] Iteration 75080, lr = 1.16186e-05
I1029 12:16:00.383404 12802 solver.cpp:222] Iteration 75120 (1.35667 iter/s, 29.4839s/40 iters), loss = 1.28448
I1029 12:16:00.383622 12802 solver.cpp:241]     Train net output #0: loss = 1.28448 (* 1 = 1.28448 loss)
I1029 12:16:00.383641 12802 sgd_solver.cpp:105] Iteration 75120, lr = 1.15769e-05
I1029 12:16:29.935178 12802 solver.cpp:222] Iteration 75160 (1.3536 iter/s, 29.5509s/40 iters), loss = 1.34349
I1029 12:16:29.935235 12802 solver.cpp:241]     Train net output #0: loss = 1.34349 (* 1 = 1.34349 loss)
I1029 12:16:29.935251 12802 sgd_solver.cpp:105] Iteration 75160, lr = 1.15353e-05
I1029 12:16:59.468274 12802 solver.cpp:222] Iteration 75200 (1.35445 iter/s, 29.5323s/40 iters), loss = 1.43908
I1029 12:16:59.468426 12802 solver.cpp:241]     Train net output #0: loss = 1.43908 (* 1 = 1.43908 loss)
I1029 12:16:59.468441 12802 sgd_solver.cpp:105] Iteration 75200, lr = 1.14938e-05
I1029 12:17:28.966120 12802 solver.cpp:222] Iteration 75240 (1.35607 iter/s, 29.497s/40 iters), loss = 1.50001
I1029 12:17:28.966181 12802 solver.cpp:241]     Train net output #0: loss = 1.50001 (* 1 = 1.50001 loss)
I1029 12:17:28.966197 12802 sgd_solver.cpp:105] Iteration 75240, lr = 1.14525e-05
I1029 12:17:58.542024 12802 solver.cpp:222] Iteration 75280 (1.35249 iter/s, 29.5751s/40 iters), loss = 1.44296
I1029 12:17:58.542167 12802 solver.cpp:241]     Train net output #0: loss = 1.44296 (* 1 = 1.44296 loss)
I1029 12:17:58.542182 12802 sgd_solver.cpp:105] Iteration 75280, lr = 1.14114e-05
I1029 12:18:28.116724 12802 solver.cpp:222] Iteration 75320 (1.35255 iter/s, 29.5739s/40 iters), loss = 1.30248
I1029 12:18:28.116791 12802 solver.cpp:241]     Train net output #0: loss = 1.30248 (* 1 = 1.30248 loss)
I1029 12:18:28.116806 12802 sgd_solver.cpp:105] Iteration 75320, lr = 1.13703e-05
I1029 12:18:57.813383 12802 solver.cpp:222] Iteration 75360 (1.34699 iter/s, 29.6959s/40 iters), loss = 1.30234
I1029 12:18:57.813544 12802 solver.cpp:241]     Train net output #0: loss = 1.30234 (* 1 = 1.30234 loss)
I1029 12:18:57.813561 12802 sgd_solver.cpp:105] Iteration 75360, lr = 1.13295e-05
I1029 12:19:31.367135 12802 solver.cpp:222] Iteration 75400 (1.19215 iter/s, 33.5528s/40 iters), loss = 1.51434
I1029 12:19:31.367295 12802 solver.cpp:241]     Train net output #0: loss = 1.51434 (* 1 = 1.51434 loss)
I1029 12:19:31.367311 12802 sgd_solver.cpp:105] Iteration 75400, lr = 1.12888e-05
I1029 12:20:03.101428 12802 solver.cpp:222] Iteration 75440 (1.2605 iter/s, 31.7334s/40 iters), loss = 1.5198
I1029 12:20:03.101596 12802 solver.cpp:241]     Train net output #0: loss = 1.5198 (* 1 = 1.5198 loss)
I1029 12:20:03.101613 12802 sgd_solver.cpp:105] Iteration 75440, lr = 1.12482e-05
I1029 12:22:12.247092 12802 solver.cpp:222] Iteration 75480 (0.309735 iter/s, 129.143s/40 iters), loss = 1.61779
I1029 12:22:12.247251 12802 solver.cpp:241]     Train net output #0: loss = 1.61779 (* 1 = 1.61779 loss)
I1029 12:22:12.247272 12802 sgd_solver.cpp:105] Iteration 75480, lr = 1.12078e-05
I1029 12:22:50.805418 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_75500.caffemodel
I1029 12:22:50.980931 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_75500.solverstate
I1029 12:22:51.094403 12802 solver.cpp:334] Iteration 75500, Testing net (#0)
I1029 12:23:22.036355 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 12:23:22.245070 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58568
I1029 12:23:22.245120 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.815
I1029 12:23:22.245131 12802 solver.cpp:401]     Test net output #2: loss = 1.83291 (* 1 = 1.83291 loss)
I1029 12:23:40.133450 12802 solver.cpp:222] Iteration 75520 (0.455144 iter/s, 87.8842s/40 iters), loss = 1.379
I1029 12:23:40.133509 12802 solver.cpp:241]     Train net output #0: loss = 1.379 (* 1 = 1.379 loss)
I1029 12:23:40.133525 12802 sgd_solver.cpp:105] Iteration 75520, lr = 1.11675e-05
I1029 12:24:09.864320 12802 solver.cpp:222] Iteration 75560 (1.34544 iter/s, 29.7301s/40 iters), loss = 1.33561
I1029 12:24:09.864642 12802 solver.cpp:241]     Train net output #0: loss = 1.33561 (* 1 = 1.33561 loss)
I1029 12:24:09.864679 12802 sgd_solver.cpp:105] Iteration 75560, lr = 1.11274e-05
I1029 12:24:39.445847 12802 solver.cpp:222] Iteration 75600 (1.35224 iter/s, 29.5805s/40 iters), loss = 1.46039
I1029 12:24:39.445912 12802 solver.cpp:241]     Train net output #0: loss = 1.46039 (* 1 = 1.46039 loss)
I1029 12:24:39.445933 12802 sgd_solver.cpp:105] Iteration 75600, lr = 1.10874e-05
I1029 12:25:09.353757 12802 solver.cpp:222] Iteration 75640 (1.33747 iter/s, 29.9071s/40 iters), loss = 1.53332
I1029 12:25:09.353941 12802 solver.cpp:241]     Train net output #0: loss = 1.53332 (* 1 = 1.53332 loss)
I1029 12:25:09.353960 12802 sgd_solver.cpp:105] Iteration 75640, lr = 1.10475e-05
I1029 12:25:39.047749 12802 solver.cpp:222] Iteration 75680 (1.34711 iter/s, 29.6931s/40 iters), loss = 1.58884
I1029 12:25:39.047811 12802 solver.cpp:241]     Train net output #0: loss = 1.58884 (* 1 = 1.58884 loss)
I1029 12:25:39.047827 12802 sgd_solver.cpp:105] Iteration 75680, lr = 1.10078e-05
I1029 12:26:08.932158 12802 solver.cpp:222] Iteration 75720 (1.33853 iter/s, 29.8836s/40 iters), loss = 1.69747
I1029 12:26:08.932301 12802 solver.cpp:241]     Train net output #0: loss = 1.69747 (* 1 = 1.69747 loss)
I1029 12:26:08.932318 12802 sgd_solver.cpp:105] Iteration 75720, lr = 1.09683e-05
I1029 12:26:39.572911 12802 solver.cpp:222] Iteration 75760 (1.30549 iter/s, 30.6399s/40 iters), loss = 1.21948
I1029 12:26:39.573081 12802 solver.cpp:241]     Train net output #0: loss = 1.21948 (* 1 = 1.21948 loss)
I1029 12:26:39.573097 12802 sgd_solver.cpp:105] Iteration 75760, lr = 1.09288e-05
I1029 12:27:09.589133 12802 solver.cpp:222] Iteration 75800 (1.33265 iter/s, 30.0153s/40 iters), loss = 1.30507
I1029 12:27:09.589314 12802 solver.cpp:241]     Train net output #0: loss = 1.30507 (* 1 = 1.30507 loss)
I1029 12:27:09.589335 12802 sgd_solver.cpp:105] Iteration 75800, lr = 1.08896e-05
I1029 12:27:39.413491 12802 solver.cpp:222] Iteration 75840 (1.34123 iter/s, 29.8235s/40 iters), loss = 1.21002
I1029 12:27:39.413554 12802 solver.cpp:241]     Train net output #0: loss = 1.21002 (* 1 = 1.21002 loss)
I1029 12:27:39.413569 12802 sgd_solver.cpp:105] Iteration 75840, lr = 1.08504e-05
I1029 12:28:09.358794 12802 solver.cpp:222] Iteration 75880 (1.3358 iter/s, 29.9445s/40 iters), loss = 1.35034
I1029 12:28:09.359002 12802 solver.cpp:241]     Train net output #0: loss = 1.35034 (* 1 = 1.35034 loss)
I1029 12:28:09.359016 12802 sgd_solver.cpp:105] Iteration 75880, lr = 1.08114e-05
I1029 12:28:39.345091 12802 solver.cpp:222] Iteration 75920 (1.33398 iter/s, 29.9854s/40 iters), loss = 1.26595
I1029 12:28:39.345151 12802 solver.cpp:241]     Train net output #0: loss = 1.26595 (* 1 = 1.26595 loss)
I1029 12:28:39.345167 12802 sgd_solver.cpp:105] Iteration 75920, lr = 1.07726e-05
I1029 12:29:59.280807 12802 solver.cpp:222] Iteration 75960 (0.500414 iter/s, 79.9338s/40 iters), loss = 1.12459
I1029 12:29:59.281127 12802 solver.cpp:241]     Train net output #0: loss = 1.12459 (* 1 = 1.12459 loss)
I1029 12:29:59.281146 12802 sgd_solver.cpp:105] Iteration 75960, lr = 1.07339e-05
I1029 12:30:29.127405 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_76000.caffemodel
I1029 12:30:29.273727 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_76000.solverstate
I1029 12:30:29.396612 12802 solver.cpp:334] Iteration 76000, Testing net (#0)
I1029 12:31:00.486366 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58948
I1029 12:31:00.486459 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.810039
I1029 12:31:00.486471 12802 solver.cpp:401]     Test net output #2: loss = 1.82592 (* 1 = 1.82592 loss)
I1029 12:31:01.254071 12802 solver.cpp:222] Iteration 76000 (0.645458 iter/s, 61.9715s/40 iters), loss = 1.47423
I1029 12:31:01.254122 12802 solver.cpp:241]     Train net output #0: loss = 1.47423 (* 1 = 1.47423 loss)
I1029 12:31:01.254142 12802 sgd_solver.cpp:105] Iteration 76000, lr = 1.06953e-05
I1029 12:31:31.950512 12802 solver.cpp:222] Iteration 76040 (1.30312 iter/s, 30.6956s/40 iters), loss = 1.05491
I1029 12:31:31.950789 12802 solver.cpp:241]     Train net output #0: loss = 1.05491 (* 1 = 1.05491 loss)
I1029 12:31:31.950827 12802 sgd_solver.cpp:105] Iteration 76040, lr = 1.06569e-05
I1029 12:32:01.494894 12802 solver.cpp:222] Iteration 76080 (1.35394 iter/s, 29.5434s/40 iters), loss = 1.60106
I1029 12:32:01.494956 12802 solver.cpp:241]     Train net output #0: loss = 1.60106 (* 1 = 1.60106 loss)
I1029 12:32:01.494971 12802 sgd_solver.cpp:105] Iteration 76080, lr = 1.06186e-05
I1029 12:32:31.092293 12802 solver.cpp:222] Iteration 76120 (1.35151 iter/s, 29.5966s/40 iters), loss = 1.23233
I1029 12:32:31.092455 12802 solver.cpp:241]     Train net output #0: loss = 1.23233 (* 1 = 1.23233 loss)
I1029 12:32:31.092473 12802 sgd_solver.cpp:105] Iteration 76120, lr = 1.05804e-05
I1029 12:32:54.044392 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 12:33:00.659168 12802 solver.cpp:222] Iteration 76160 (1.35291 iter/s, 29.566s/40 iters), loss = 1.58384
I1029 12:33:00.659224 12802 solver.cpp:241]     Train net output #0: loss = 1.58384 (* 1 = 1.58384 loss)
I1029 12:33:00.659241 12802 sgd_solver.cpp:105] Iteration 76160, lr = 1.05424e-05
I1029 12:33:30.185539 12802 solver.cpp:222] Iteration 76200 (1.35476 iter/s, 29.5256s/40 iters), loss = 1.29054
I1029 12:33:30.185631 12802 solver.cpp:241]     Train net output #0: loss = 1.29054 (* 1 = 1.29054 loss)
I1029 12:33:30.185645 12802 sgd_solver.cpp:105] Iteration 76200, lr = 1.05045e-05
I1029 12:33:59.686434 12802 solver.cpp:222] Iteration 76240 (1.35593 iter/s, 29.5001s/40 iters), loss = 1.44275
I1029 12:33:59.686492 12802 solver.cpp:241]     Train net output #0: loss = 1.44275 (* 1 = 1.44275 loss)
I1029 12:33:59.686514 12802 sgd_solver.cpp:105] Iteration 76240, lr = 1.04667e-05
I1029 12:34:29.186195 12802 solver.cpp:222] Iteration 76280 (1.35598 iter/s, 29.499s/40 iters), loss = 1.12873
I1029 12:34:29.186290 12802 solver.cpp:241]     Train net output #0: loss = 1.12873 (* 1 = 1.12873 loss)
I1029 12:34:29.186305 12802 sgd_solver.cpp:105] Iteration 76280, lr = 1.04291e-05
I1029 12:34:58.640224 12802 solver.cpp:222] Iteration 76320 (1.35809 iter/s, 29.4532s/40 iters), loss = 1.65916
I1029 12:34:58.640286 12802 solver.cpp:241]     Train net output #0: loss = 1.65916 (* 1 = 1.65916 loss)
I1029 12:34:58.640301 12802 sgd_solver.cpp:105] Iteration 76320, lr = 1.03916e-05
I1029 12:35:28.058264 12802 solver.cpp:222] Iteration 76360 (1.35975 iter/s, 29.4173s/40 iters), loss = 1.68584
I1029 12:35:28.058359 12802 solver.cpp:241]     Train net output #0: loss = 1.68584 (* 1 = 1.68584 loss)
I1029 12:35:28.058375 12802 sgd_solver.cpp:105] Iteration 76360, lr = 1.03543e-05
I1029 12:35:57.469987 12802 solver.cpp:222] Iteration 76400 (1.36004 iter/s, 29.4109s/40 iters), loss = 1.35719
I1029 12:35:57.470044 12802 solver.cpp:241]     Train net output #0: loss = 1.35719 (* 1 = 1.35719 loss)
I1029 12:35:57.470060 12802 sgd_solver.cpp:105] Iteration 76400, lr = 1.03171e-05
I1029 12:36:26.860482 12802 solver.cpp:222] Iteration 76440 (1.36102 iter/s, 29.3897s/40 iters), loss = 1.26388
I1029 12:36:26.860576 12802 solver.cpp:241]     Train net output #0: loss = 1.26388 (* 1 = 1.26388 loss)
I1029 12:36:26.860592 12802 sgd_solver.cpp:105] Iteration 76440, lr = 1.028e-05
I1029 12:36:56.235747 12802 solver.cpp:222] Iteration 76480 (1.36173 iter/s, 29.3745s/40 iters), loss = 0.999811
I1029 12:36:56.235802 12802 solver.cpp:241]     Train net output #0: loss = 0.999811 (* 1 = 0.999811 loss)
I1029 12:36:56.235818 12802 sgd_solver.cpp:105] Iteration 76480, lr = 1.02431e-05
I1029 12:37:10.165323 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_76500.caffemodel
I1029 12:37:10.308307 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_76500.solverstate
I1029 12:37:10.429406 12802 solver.cpp:334] Iteration 76500, Testing net (#0)
I1029 12:37:41.310088 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 12:37:41.517069 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5852
I1029 12:37:41.517120 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8152
I1029 12:37:41.517132 12802 solver.cpp:401]     Test net output #2: loss = 1.83631 (* 1 = 1.83631 loss)
I1029 12:37:57.142850 12802 solver.cpp:222] Iteration 76520 (0.656754 iter/s, 60.9056s/40 iters), loss = 1.81425
I1029 12:37:57.142902 12802 solver.cpp:241]     Train net output #0: loss = 1.81425 (* 1 = 1.81425 loss)
I1029 12:37:57.142922 12802 sgd_solver.cpp:105] Iteration 76520, lr = 1.02062e-05
I1029 12:38:26.559695 12802 solver.cpp:222] Iteration 76560 (1.3598 iter/s, 29.4161s/40 iters), loss = 1.29114
I1029 12:38:26.559810 12802 solver.cpp:241]     Train net output #0: loss = 1.29114 (* 1 = 1.29114 loss)
I1029 12:38:26.559825 12802 sgd_solver.cpp:105] Iteration 76560, lr = 1.01696e-05
I1029 12:38:55.960237 12802 solver.cpp:222] Iteration 76600 (1.36056 iter/s, 29.3997s/40 iters), loss = 1.78065
I1029 12:38:55.960289 12802 solver.cpp:241]     Train net output #0: loss = 1.78065 (* 1 = 1.78065 loss)
I1029 12:38:55.960304 12802 sgd_solver.cpp:105] Iteration 76600, lr = 1.0133e-05
I1029 12:39:25.422889 12802 solver.cpp:222] Iteration 76640 (1.35769 iter/s, 29.4619s/40 iters), loss = 1.30042
I1029 12:39:25.422982 12802 solver.cpp:241]     Train net output #0: loss = 1.30042 (* 1 = 1.30042 loss)
I1029 12:39:25.422998 12802 sgd_solver.cpp:105] Iteration 76640, lr = 1.00966e-05
I1029 12:39:54.931195 12802 solver.cpp:222] Iteration 76680 (1.35559 iter/s, 29.5075s/40 iters), loss = 1.39393
I1029 12:39:54.931248 12802 solver.cpp:241]     Train net output #0: loss = 1.39393 (* 1 = 1.39393 loss)
I1029 12:39:54.931263 12802 sgd_solver.cpp:105] Iteration 76680, lr = 1.00603e-05
I1029 12:40:24.550534 12802 solver.cpp:222] Iteration 76720 (1.3505 iter/s, 29.6186s/40 iters), loss = 1.65162
I1029 12:40:24.550761 12802 solver.cpp:241]     Train net output #0: loss = 1.65162 (* 1 = 1.65162 loss)
I1029 12:40:24.550778 12802 sgd_solver.cpp:105] Iteration 76720, lr = 1.00242e-05
I1029 12:40:54.109254 12802 solver.cpp:222] Iteration 76760 (1.35328 iter/s, 29.5578s/40 iters), loss = 1.11325
I1029 12:40:54.109313 12802 solver.cpp:241]     Train net output #0: loss = 1.11325 (* 1 = 1.11325 loss)
I1029 12:40:54.109328 12802 sgd_solver.cpp:105] Iteration 76760, lr = 9.98814e-06
I1029 12:41:24.035827 12802 solver.cpp:222] Iteration 76800 (1.33664 iter/s, 29.9258s/40 iters), loss = 1.3936
I1029 12:41:24.036026 12802 solver.cpp:241]     Train net output #0: loss = 1.3936 (* 1 = 1.3936 loss)
I1029 12:41:24.036044 12802 sgd_solver.cpp:105] Iteration 76800, lr = 9.95224e-06
I1029 12:41:53.599407 12802 solver.cpp:222] Iteration 76840 (1.35306 iter/s, 29.5627s/40 iters), loss = 1.56806
I1029 12:41:53.599470 12802 solver.cpp:241]     Train net output #0: loss = 1.56806 (* 1 = 1.56806 loss)
I1029 12:41:53.599483 12802 sgd_solver.cpp:105] Iteration 76840, lr = 9.91648e-06
I1029 12:42:23.167131 12802 solver.cpp:222] Iteration 76880 (1.35286 iter/s, 29.567s/40 iters), loss = 1.43645
I1029 12:42:23.167220 12802 solver.cpp:241]     Train net output #0: loss = 1.43645 (* 1 = 1.43645 loss)
I1029 12:42:23.167237 12802 sgd_solver.cpp:105] Iteration 76880, lr = 9.88084e-06
I1029 12:42:52.757670 12802 solver.cpp:222] Iteration 76920 (1.35182 iter/s, 29.5897s/40 iters), loss = 1.56348
I1029 12:42:52.757731 12802 solver.cpp:241]     Train net output #0: loss = 1.56348 (* 1 = 1.56348 loss)
I1029 12:42:52.757746 12802 sgd_solver.cpp:105] Iteration 76920, lr = 9.84533e-06
I1029 12:43:22.361948 12802 solver.cpp:222] Iteration 76960 (1.35119 iter/s, 29.6035s/40 iters), loss = 1.47146
I1029 12:43:22.362040 12802 solver.cpp:241]     Train net output #0: loss = 1.47146 (* 1 = 1.47146 loss)
I1029 12:43:22.362053 12802 sgd_solver.cpp:105] Iteration 76960, lr = 9.80995e-06
I1029 12:43:51.715272 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_77000.caffemodel
I1029 12:43:51.857091 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_77000.solverstate
I1029 12:43:51.979619 12802 solver.cpp:334] Iteration 77000, Testing net (#0)
I1029 12:44:23.164883 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5894
I1029 12:44:23.165166 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80992
I1029 12:44:23.165181 12802 solver.cpp:401]     Test net output #2: loss = 1.82827 (* 1 = 1.82827 loss)
I1029 12:44:23.937604 12802 solver.cpp:222] Iteration 77000 (0.649624 iter/s, 61.5741s/40 iters), loss = 1.5886
I1029 12:44:23.937664 12802 solver.cpp:241]     Train net output #0: loss = 1.5886 (* 1 = 1.5886 loss)
I1029 12:44:23.937685 12802 sgd_solver.cpp:105] Iteration 77000, lr = 9.77469e-06
I1029 12:44:55.706204 12802 solver.cpp:222] Iteration 77040 (1.25914 iter/s, 31.7678s/40 iters), loss = 1.32653
I1029 12:44:55.706415 12802 solver.cpp:241]     Train net output #0: loss = 1.32653 (* 1 = 1.32653 loss)
I1029 12:44:55.706434 12802 sgd_solver.cpp:105] Iteration 77040, lr = 9.73956e-06
I1029 12:45:25.148675 12802 solver.cpp:222] Iteration 77080 (1.35862 iter/s, 29.4416s/40 iters), loss = 1.44434
I1029 12:45:25.148730 12802 solver.cpp:241]     Train net output #0: loss = 1.44434 (* 1 = 1.44434 loss)
I1029 12:45:25.148744 12802 sgd_solver.cpp:105] Iteration 77080, lr = 9.70456e-06
I1029 12:45:54.725014 12802 solver.cpp:222] Iteration 77120 (1.35247 iter/s, 29.5756s/40 iters), loss = 1.16906
I1029 12:45:54.725147 12802 solver.cpp:241]     Train net output #0: loss = 1.16906 (* 1 = 1.16906 loss)
I1029 12:45:54.725162 12802 sgd_solver.cpp:105] Iteration 77120, lr = 9.66968e-06
I1029 12:46:24.347167 12802 solver.cpp:222] Iteration 77160 (1.35038 iter/s, 29.6213s/40 iters), loss = 1.58226
I1029 12:46:24.347215 12802 solver.cpp:241]     Train net output #0: loss = 1.58226 (* 1 = 1.58226 loss)
I1029 12:46:24.347229 12802 sgd_solver.cpp:105] Iteration 77160, lr = 9.63493e-06
I1029 12:47:05.753021 12802 solver.cpp:222] Iteration 77200 (0.966071 iter/s, 41.4048s/40 iters), loss = 1.30179
I1029 12:47:05.753208 12802 solver.cpp:241]     Train net output #0: loss = 1.30179 (* 1 = 1.30179 loss)
I1029 12:47:05.753226 12802 sgd_solver.cpp:105] Iteration 77200, lr = 9.60031e-06
I1029 12:47:35.345540 12802 solver.cpp:222] Iteration 77240 (1.35173 iter/s, 29.5916s/40 iters), loss = 1.98864
I1029 12:47:35.345597 12802 solver.cpp:241]     Train net output #0: loss = 1.98864 (* 1 = 1.98864 loss)
I1029 12:47:35.345612 12802 sgd_solver.cpp:105] Iteration 77240, lr = 9.5658e-06
I1029 12:48:04.990476 12802 solver.cpp:222] Iteration 77280 (1.34934 iter/s, 29.6442s/40 iters), loss = 1.45484
I1029 12:48:04.990561 12802 solver.cpp:241]     Train net output #0: loss = 1.45484 (* 1 = 1.45484 loss)
I1029 12:48:04.990577 12802 sgd_solver.cpp:105] Iteration 77280, lr = 9.53143e-06
I1029 12:48:34.526749 12802 solver.cpp:222] Iteration 77320 (1.3543 iter/s, 29.5355s/40 iters), loss = 1.73034
I1029 12:48:34.526806 12802 solver.cpp:241]     Train net output #0: loss = 1.73034 (* 1 = 1.73034 loss)
I1029 12:48:34.526823 12802 sgd_solver.cpp:105] Iteration 77320, lr = 9.49717e-06
I1029 12:49:04.204015 12802 solver.cpp:222] Iteration 77360 (1.34787 iter/s, 29.6765s/40 iters), loss = 1.78065
I1029 12:49:04.204195 12802 solver.cpp:241]     Train net output #0: loss = 1.78065 (* 1 = 1.78065 loss)
I1029 12:49:04.204213 12802 sgd_solver.cpp:105] Iteration 77360, lr = 9.46304e-06
I1029 12:50:31.189010 12802 solver.cpp:222] Iteration 77400 (0.459861 iter/s, 86.9828s/40 iters), loss = 1.39858
I1029 12:50:31.189221 12802 solver.cpp:241]     Train net output #0: loss = 1.39858 (* 1 = 1.39858 loss)
I1029 12:50:31.189239 12802 sgd_solver.cpp:105] Iteration 77400, lr = 9.42903e-06
I1029 12:51:02.883852 12802 solver.cpp:222] Iteration 77440 (1.26207 iter/s, 31.6939s/40 iters), loss = 1.58959
I1029 12:51:02.884044 12802 solver.cpp:241]     Train net output #0: loss = 1.58959 (* 1 = 1.58959 loss)
I1029 12:51:02.884058 12802 sgd_solver.cpp:105] Iteration 77440, lr = 9.39515e-06
I1029 12:51:34.019917 12802 solver.cpp:222] Iteration 77480 (1.28472 iter/s, 31.1352s/40 iters), loss = 1.35838
I1029 12:51:34.020231 12802 solver.cpp:241]     Train net output #0: loss = 1.35838 (* 1 = 1.35838 loss)
I1029 12:51:34.020268 12802 sgd_solver.cpp:105] Iteration 77480, lr = 9.36138e-06
I1029 12:51:48.522095 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_77500.caffemodel
I1029 12:51:48.665719 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_77500.solverstate
I1029 12:51:48.785714 12802 solver.cpp:334] Iteration 77500, Testing net (#0)
I1029 12:52:19.740991 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 12:52:19.952536 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58544
I1029 12:52:19.952589 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81488
I1029 12:52:19.952600 12802 solver.cpp:401]     Test net output #2: loss = 1.83277 (* 1 = 1.83277 loss)
I1029 12:52:36.066786 12802 solver.cpp:222] Iteration 77520 (0.644692 iter/s, 62.0451s/40 iters), loss = 1.47986
I1029 12:52:36.066844 12802 solver.cpp:241]     Train net output #0: loss = 1.47986 (* 1 = 1.47986 loss)
I1029 12:52:36.066860 12802 sgd_solver.cpp:105] Iteration 77520, lr = 9.32774e-06
I1029 12:53:07.230868 12802 solver.cpp:222] Iteration 77560 (1.28356 iter/s, 31.1633s/40 iters), loss = 1.65063
I1029 12:53:07.231070 12802 solver.cpp:241]     Train net output #0: loss = 1.65063 (* 1 = 1.65063 loss)
I1029 12:53:07.231087 12802 sgd_solver.cpp:105] Iteration 77560, lr = 9.29422e-06
I1029 12:53:38.042670 12802 solver.cpp:222] Iteration 77600 (1.29824 iter/s, 30.8109s/40 iters), loss = 1.9291
I1029 12:53:38.042819 12802 solver.cpp:241]     Train net output #0: loss = 1.9291 (* 1 = 1.9291 loss)
I1029 12:53:38.042835 12802 sgd_solver.cpp:105] Iteration 77600, lr = 9.26082e-06
I1029 12:54:19.646173 12802 solver.cpp:222] Iteration 77640 (0.961483 iter/s, 41.6024s/40 iters), loss = 1.35369
I1029 12:54:19.646360 12802 solver.cpp:241]     Train net output #0: loss = 1.35369 (* 1 = 1.35369 loss)
I1029 12:54:19.646378 12802 sgd_solver.cpp:105] Iteration 77640, lr = 9.22753e-06
I1029 12:54:55.439309 12802 solver.cpp:222] Iteration 77680 (1.11756 iter/s, 35.7921s/40 iters), loss = 1.5528
I1029 12:54:55.439484 12802 solver.cpp:241]     Train net output #0: loss = 1.5528 (* 1 = 1.5528 loss)
I1029 12:54:55.439502 12802 sgd_solver.cpp:105] Iteration 77680, lr = 9.19437e-06
I1029 12:55:54.495913 12802 solver.cpp:222] Iteration 77720 (0.677334 iter/s, 59.0551s/40 iters), loss = 1.23576
I1029 12:55:54.496093 12802 solver.cpp:241]     Train net output #0: loss = 1.23576 (* 1 = 1.23576 loss)
I1029 12:55:54.496109 12802 sgd_solver.cpp:105] Iteration 77720, lr = 9.16133e-06
I1029 12:56:25.291115 12802 solver.cpp:222] Iteration 77760 (1.29894 iter/s, 30.7943s/40 iters), loss = 1.34427
I1029 12:56:25.291309 12802 solver.cpp:241]     Train net output #0: loss = 1.34427 (* 1 = 1.34427 loss)
I1029 12:56:25.291326 12802 sgd_solver.cpp:105] Iteration 77760, lr = 9.12841e-06
I1029 12:56:55.011670 12802 solver.cpp:222] Iteration 77800 (1.34591 iter/s, 29.7197s/40 iters), loss = 1.48499
I1029 12:56:55.011729 12802 solver.cpp:241]     Train net output #0: loss = 1.48499 (* 1 = 1.48499 loss)
I1029 12:56:55.011742 12802 sgd_solver.cpp:105] Iteration 77800, lr = 9.0956e-06
I1029 12:57:24.556704 12802 solver.cpp:222] Iteration 77840 (1.3539 iter/s, 29.5443s/40 iters), loss = 1.45224
I1029 12:57:24.556917 12802 solver.cpp:241]     Train net output #0: loss = 1.45224 (* 1 = 1.45224 loss)
I1029 12:57:24.556938 12802 sgd_solver.cpp:105] Iteration 77840, lr = 9.06291e-06
I1029 12:57:54.234405 12802 solver.cpp:222] Iteration 77880 (1.34785 iter/s, 29.6768s/40 iters), loss = 1.25169
I1029 12:57:54.234459 12802 solver.cpp:241]     Train net output #0: loss = 1.25169 (* 1 = 1.25169 loss)
I1029 12:57:54.234474 12802 sgd_solver.cpp:105] Iteration 77880, lr = 9.03034e-06
I1029 12:58:23.865779 12802 solver.cpp:222] Iteration 77920 (1.34995 iter/s, 29.6306s/40 iters), loss = 1.38409
I1029 12:58:23.866003 12802 solver.cpp:241]     Train net output #0: loss = 1.38409 (* 1 = 1.38409 loss)
I1029 12:58:23.866021 12802 sgd_solver.cpp:105] Iteration 77920, lr = 8.99789e-06
I1029 12:58:53.395635 12802 solver.cpp:222] Iteration 77960 (1.3546 iter/s, 29.5289s/40 iters), loss = 1.54129
I1029 12:58:53.395697 12802 solver.cpp:241]     Train net output #0: loss = 1.54129 (* 1 = 1.54129 loss)
I1029 12:58:53.395714 12802 sgd_solver.cpp:105] Iteration 77960, lr = 8.96555e-06
I1029 12:59:22.380095 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_78000.caffemodel
I1029 12:59:22.532749 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_78000.solverstate
I1029 12:59:22.651219 12802 solver.cpp:334] Iteration 78000, Testing net (#0)
I1029 12:59:53.811666 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58928
I1029 12:59:53.811817 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8098
I1029 12:59:53.811831 12802 solver.cpp:401]     Test net output #2: loss = 1.82772 (* 1 = 1.82772 loss)
I1029 12:59:54.582706 12802 solver.cpp:222] Iteration 78000 (0.653749 iter/s, 61.1856s/40 iters), loss = 1.40851
I1029 12:59:54.582742 12802 solver.cpp:241]     Train net output #0: loss = 1.40851 (* 1 = 1.40851 loss)
I1029 12:59:54.582762 12802 sgd_solver.cpp:105] Iteration 78000, lr = 8.93333e-06
I1029 13:00:24.563753 12802 solver.cpp:222] Iteration 78040 (1.33421 iter/s, 29.9803s/40 iters), loss = 1.50925
I1029 13:00:24.563946 12802 solver.cpp:241]     Train net output #0: loss = 1.50925 (* 1 = 1.50925 loss)
I1029 13:00:24.563964 12802 sgd_solver.cpp:105] Iteration 78040, lr = 8.90123e-06
I1029 13:00:54.999167 12802 solver.cpp:222] Iteration 78080 (1.3143 iter/s, 30.4345s/40 iters), loss = 1.12269
I1029 13:00:54.999335 12802 solver.cpp:241]     Train net output #0: loss = 1.12269 (* 1 = 1.12269 loss)
I1029 13:00:54.999351 12802 sgd_solver.cpp:105] Iteration 78080, lr = 8.86924e-06
I1029 13:01:25.817239 12802 solver.cpp:222] Iteration 78120 (1.29798 iter/s, 30.8172s/40 iters), loss = 1.32404
I1029 13:01:25.817420 12802 solver.cpp:241]     Train net output #0: loss = 1.32404 (* 1 = 1.32404 loss)
I1029 13:01:25.817438 12802 sgd_solver.cpp:105] Iteration 78120, lr = 8.83736e-06
I1029 13:01:56.617616 12802 solver.cpp:222] Iteration 78160 (1.29872 iter/s, 30.7995s/40 iters), loss = 1.89478
I1029 13:01:56.617779 12802 solver.cpp:241]     Train net output #0: loss = 1.89478 (* 1 = 1.89478 loss)
I1029 13:01:56.617794 12802 sgd_solver.cpp:105] Iteration 78160, lr = 8.8056e-06
I1029 13:02:26.644577 12802 solver.cpp:222] Iteration 78200 (1.33218 iter/s, 30.0261s/40 iters), loss = 1.37362
I1029 13:02:26.644758 12802 solver.cpp:241]     Train net output #0: loss = 1.37362 (* 1 = 1.37362 loss)
I1029 13:02:26.644773 12802 sgd_solver.cpp:105] Iteration 78200, lr = 8.77396e-06
I1029 13:02:56.294605 12802 solver.cpp:222] Iteration 78240 (1.34911 iter/s, 29.6491s/40 iters), loss = 1.63195
I1029 13:02:56.294661 12802 solver.cpp:241]     Train net output #0: loss = 1.63195 (* 1 = 1.63195 loss)
I1029 13:02:56.294677 12802 sgd_solver.cpp:105] Iteration 78240, lr = 8.74243e-06
I1029 13:03:26.307601 12802 solver.cpp:222] Iteration 78280 (1.33279 iter/s, 30.0122s/40 iters), loss = 1.4699
I1029 13:03:26.307790 12802 solver.cpp:241]     Train net output #0: loss = 1.4699 (* 1 = 1.4699 loss)
I1029 13:03:26.307807 12802 sgd_solver.cpp:105] Iteration 78280, lr = 8.71101e-06
I1029 13:03:56.343185 12802 solver.cpp:222] Iteration 78320 (1.33179 iter/s, 30.0347s/40 iters), loss = 1.14668
I1029 13:03:56.343361 12802 solver.cpp:241]     Train net output #0: loss = 1.14668 (* 1 = 1.14668 loss)
I1029 13:03:56.343377 12802 sgd_solver.cpp:105] Iteration 78320, lr = 8.6797e-06
I1029 13:04:26.780761 12802 solver.cpp:222] Iteration 78360 (1.3142 iter/s, 30.4367s/40 iters), loss = 1.7935
I1029 13:04:26.781056 12802 solver.cpp:241]     Train net output #0: loss = 1.7935 (* 1 = 1.7935 loss)
I1029 13:04:26.781075 12802 sgd_solver.cpp:105] Iteration 78360, lr = 8.64851e-06
I1029 13:04:57.481374 12802 solver.cpp:222] Iteration 78400 (1.30295 iter/s, 30.6996s/40 iters), loss = 1.22622
I1029 13:04:57.481555 12802 solver.cpp:241]     Train net output #0: loss = 1.22622 (* 1 = 1.22622 loss)
I1029 13:04:57.481572 12802 sgd_solver.cpp:105] Iteration 78400, lr = 8.61743e-06
I1029 13:05:28.206549 12802 solver.cpp:222] Iteration 78440 (1.3019 iter/s, 30.7243s/40 iters), loss = 1.39817
I1029 13:05:28.206743 12802 solver.cpp:241]     Train net output #0: loss = 1.39817 (* 1 = 1.39817 loss)
I1029 13:05:28.206760 12802 sgd_solver.cpp:105] Iteration 78440, lr = 8.58646e-06
I1029 13:05:58.495203 12802 solver.cpp:222] Iteration 78480 (1.32067 iter/s, 30.2877s/40 iters), loss = 1.41063
I1029 13:05:58.495365 12802 solver.cpp:241]     Train net output #0: loss = 1.41063 (* 1 = 1.41063 loss)
I1029 13:05:58.495383 12802 sgd_solver.cpp:105] Iteration 78480, lr = 8.5556e-06
I1029 13:06:12.462095 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_78500.caffemodel
I1029 13:06:12.608534 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_78500.solverstate
I1029 13:06:12.722882 12802 solver.cpp:334] Iteration 78500, Testing net (#0)
I1029 13:06:43.550499 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 13:06:43.757498 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58536
I1029 13:06:43.757552 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8156
I1029 13:06:43.757565 12802 solver.cpp:401]     Test net output #2: loss = 1.83069 (* 1 = 1.83069 loss)
I1029 13:06:59.248687 12802 solver.cpp:222] Iteration 78520 (0.658416 iter/s, 60.7519s/40 iters), loss = 1.56911
I1029 13:06:59.248749 12802 solver.cpp:241]     Train net output #0: loss = 1.56911 (* 1 = 1.56911 loss)
I1029 13:06:59.248764 12802 sgd_solver.cpp:105] Iteration 78520, lr = 8.52485e-06
I1029 13:07:29.911433 12802 solver.cpp:222] Iteration 78560 (1.30455 iter/s, 30.662s/40 iters), loss = 1.48785
I1029 13:07:29.911597 12802 solver.cpp:241]     Train net output #0: loss = 1.48785 (* 1 = 1.48785 loss)
I1029 13:07:29.911615 12802 sgd_solver.cpp:105] Iteration 78560, lr = 8.49422e-06
I1029 13:08:00.691656 12802 solver.cpp:222] Iteration 78600 (1.29957 iter/s, 30.7793s/40 iters), loss = 1.3848
I1029 13:08:00.691814 12802 solver.cpp:241]     Train net output #0: loss = 1.3848 (* 1 = 1.3848 loss)
I1029 13:08:00.691833 12802 sgd_solver.cpp:105] Iteration 78600, lr = 8.46369e-06
I1029 13:08:30.502073 12802 solver.cpp:222] Iteration 78640 (1.34185 iter/s, 29.8095s/40 iters), loss = 1.44157
I1029 13:08:30.502131 12802 solver.cpp:241]     Train net output #0: loss = 1.44157 (* 1 = 1.44157 loss)
I1029 13:08:30.502146 12802 sgd_solver.cpp:105] Iteration 78640, lr = 8.43327e-06
I1029 13:08:40.236003 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 13:09:00.126900 12802 solver.cpp:222] Iteration 78680 (1.35025 iter/s, 29.6241s/40 iters), loss = 1.79247
I1029 13:09:00.126965 12802 solver.cpp:241]     Train net output #0: loss = 1.79247 (* 1 = 1.79247 loss)
I1029 13:09:00.126979 12802 sgd_solver.cpp:105] Iteration 78680, lr = 8.40296e-06
I1029 13:09:29.773419 12802 solver.cpp:222] Iteration 78720 (1.34927 iter/s, 29.6458s/40 iters), loss = 1.39143
I1029 13:09:29.773566 12802 solver.cpp:241]     Train net output #0: loss = 1.39143 (* 1 = 1.39143 loss)
I1029 13:09:29.773583 12802 sgd_solver.cpp:105] Iteration 78720, lr = 8.37277e-06
I1029 13:10:00.296438 12802 solver.cpp:222] Iteration 78760 (1.31052 iter/s, 30.5222s/40 iters), loss = 1.78524
I1029 13:10:00.296627 12802 solver.cpp:241]     Train net output #0: loss = 1.78524 (* 1 = 1.78524 loss)
I1029 13:10:00.296644 12802 sgd_solver.cpp:105] Iteration 78760, lr = 8.34268e-06
I1029 13:10:31.224344 12802 solver.cpp:222] Iteration 78800 (1.29337 iter/s, 30.927s/40 iters), loss = 1.35202
I1029 13:10:31.224620 12802 solver.cpp:241]     Train net output #0: loss = 1.35202 (* 1 = 1.35202 loss)
I1029 13:10:31.224654 12802 sgd_solver.cpp:105] Iteration 78800, lr = 8.31269e-06
I1029 13:11:12.109747 12802 solver.cpp:222] Iteration 78840 (0.978373 iter/s, 40.8842s/40 iters), loss = 1.51925
I1029 13:11:12.109937 12802 solver.cpp:241]     Train net output #0: loss = 1.51925 (* 1 = 1.51925 loss)
I1029 13:11:12.109956 12802 sgd_solver.cpp:105] Iteration 78840, lr = 8.28282e-06
I1029 13:11:42.739269 12802 solver.cpp:222] Iteration 78880 (1.30597 iter/s, 30.6286s/40 iters), loss = 1.2784
I1029 13:11:42.739455 12802 solver.cpp:241]     Train net output #0: loss = 1.2784 (* 1 = 1.2784 loss)
I1029 13:11:42.739473 12802 sgd_solver.cpp:105] Iteration 78880, lr = 8.25305e-06
I1029 13:12:13.077569 12802 solver.cpp:222] Iteration 78920 (1.3185 iter/s, 30.3374s/40 iters), loss = 1.30246
I1029 13:12:13.077730 12802 solver.cpp:241]     Train net output #0: loss = 1.30246 (* 1 = 1.30246 loss)
I1029 13:12:13.077747 12802 sgd_solver.cpp:105] Iteration 78920, lr = 8.22339e-06
I1029 13:12:42.586114 12802 solver.cpp:222] Iteration 78960 (1.35558 iter/s, 29.5077s/40 iters), loss = 1.39715
I1029 13:12:42.586174 12802 solver.cpp:241]     Train net output #0: loss = 1.39715 (* 1 = 1.39715 loss)
I1029 13:12:42.586189 12802 sgd_solver.cpp:105] Iteration 78960, lr = 8.19384e-06
I1029 13:13:11.630357 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_79000.caffemodel
I1029 13:13:11.801316 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_79000.solverstate
I1029 13:13:11.927670 12802 solver.cpp:334] Iteration 79000, Testing net (#0)
I1029 13:13:43.202993 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58932
I1029 13:13:43.203169 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80996
I1029 13:13:43.203183 12802 solver.cpp:401]     Test net output #2: loss = 1.83144 (* 1 = 1.83144 loss)
I1029 13:13:43.958211 12802 solver.cpp:222] Iteration 79000 (0.651778 iter/s, 61.3706s/40 iters), loss = 1.13814
I1029 13:13:43.958272 12802 solver.cpp:241]     Train net output #0: loss = 1.13814 (* 1 = 1.13814 loss)
I1029 13:13:43.958288 12802 sgd_solver.cpp:105] Iteration 79000, lr = 8.16439e-06
I1029 13:14:13.477495 12802 solver.cpp:222] Iteration 79040 (1.35508 iter/s, 29.5185s/40 iters), loss = 1.38354
I1029 13:14:13.477639 12802 solver.cpp:241]     Train net output #0: loss = 1.38354 (* 1 = 1.38354 loss)
I1029 13:14:13.477658 12802 sgd_solver.cpp:105] Iteration 79040, lr = 8.13505e-06
I1029 13:14:42.931439 12802 solver.cpp:222] Iteration 79080 (1.35809 iter/s, 29.4531s/40 iters), loss = 1.43049
I1029 13:14:42.931501 12802 solver.cpp:241]     Train net output #0: loss = 1.43049 (* 1 = 1.43049 loss)
I1029 13:14:42.931514 12802 sgd_solver.cpp:105] Iteration 79080, lr = 8.10582e-06
I1029 13:15:12.396239 12802 solver.cpp:222] Iteration 79120 (1.35759 iter/s, 29.464s/40 iters), loss = 1.40537
I1029 13:15:12.396405 12802 solver.cpp:241]     Train net output #0: loss = 1.40537 (* 1 = 1.40537 loss)
I1029 13:15:12.396421 12802 sgd_solver.cpp:105] Iteration 79120, lr = 8.07668e-06
I1029 13:15:41.920307 12802 solver.cpp:222] Iteration 79160 (1.35487 iter/s, 29.5232s/40 iters), loss = 1.5793
I1029 13:15:41.920367 12802 solver.cpp:241]     Train net output #0: loss = 1.5793 (* 1 = 1.5793 loss)
I1029 13:15:41.920380 12802 sgd_solver.cpp:105] Iteration 79160, lr = 8.04766e-06
I1029 13:16:15.854076 12802 solver.cpp:222] Iteration 79200 (1.1788 iter/s, 33.9329s/40 iters), loss = 1.19371
I1029 13:16:15.854248 12802 solver.cpp:241]     Train net output #0: loss = 1.19371 (* 1 = 1.19371 loss)
I1029 13:16:15.854262 12802 sgd_solver.cpp:105] Iteration 79200, lr = 8.01874e-06
I1029 13:16:45.346354 12802 solver.cpp:222] Iteration 79240 (1.35633 iter/s, 29.4914s/40 iters), loss = 1.38865
I1029 13:16:45.346410 12802 solver.cpp:241]     Train net output #0: loss = 1.38865 (* 1 = 1.38865 loss)
I1029 13:16:45.346426 12802 sgd_solver.cpp:105] Iteration 79240, lr = 7.98992e-06
I1029 13:17:14.815472 12802 solver.cpp:222] Iteration 79280 (1.35739 iter/s, 29.4684s/40 iters), loss = 1.42335
I1029 13:17:14.815690 12802 solver.cpp:241]     Train net output #0: loss = 1.42335 (* 1 = 1.42335 loss)
I1029 13:17:14.815706 12802 sgd_solver.cpp:105] Iteration 79280, lr = 7.9612e-06
I1029 13:17:44.363715 12802 solver.cpp:222] Iteration 79320 (1.35376 iter/s, 29.5473s/40 iters), loss = 1.39506
I1029 13:17:44.363771 12802 solver.cpp:241]     Train net output #0: loss = 1.39506 (* 1 = 1.39506 loss)
I1029 13:17:44.363785 12802 sgd_solver.cpp:105] Iteration 79320, lr = 7.93259e-06
I1029 13:18:13.914023 12802 solver.cpp:222] Iteration 79360 (1.35366 iter/s, 29.5496s/40 iters), loss = 1.69803
I1029 13:18:13.914115 12802 solver.cpp:241]     Train net output #0: loss = 1.69803 (* 1 = 1.69803 loss)
I1029 13:18:13.914131 12802 sgd_solver.cpp:105] Iteration 79360, lr = 7.90409e-06
I1029 13:18:43.478827 12802 solver.cpp:222] Iteration 79400 (1.353 iter/s, 29.564s/40 iters), loss = 1.24035
I1029 13:18:43.478888 12802 solver.cpp:241]     Train net output #0: loss = 1.24035 (* 1 = 1.24035 loss)
I1029 13:18:43.478902 12802 sgd_solver.cpp:105] Iteration 79400, lr = 7.87568e-06
I1029 13:19:12.981705 12802 solver.cpp:222] Iteration 79440 (1.35583 iter/s, 29.5021s/40 iters), loss = 1.38525
I1029 13:19:12.981807 12802 solver.cpp:241]     Train net output #0: loss = 1.38525 (* 1 = 1.38525 loss)
I1029 13:19:12.981824 12802 sgd_solver.cpp:105] Iteration 79440, lr = 7.84738e-06
I1029 13:19:42.490300 12802 solver.cpp:222] Iteration 79480 (1.35557 iter/s, 29.5078s/40 iters), loss = 1.17963
I1029 13:19:42.490356 12802 solver.cpp:241]     Train net output #0: loss = 1.17963 (* 1 = 1.17963 loss)
I1029 13:19:42.490371 12802 sgd_solver.cpp:105] Iteration 79480, lr = 7.81917e-06
I1029 13:19:56.469655 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_79500.caffemodel
I1029 13:19:56.609669 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_79500.solverstate
I1029 13:19:56.721585 12802 solver.cpp:334] Iteration 79500, Testing net (#0)
I1029 13:20:27.809692 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 13:20:28.018939 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58512
I1029 13:20:28.018985 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81504
I1029 13:20:28.018996 12802 solver.cpp:401]     Test net output #2: loss = 1.83261 (* 1 = 1.83261 loss)
I1029 13:20:43.561429 12802 solver.cpp:222] Iteration 79520 (0.65499 iter/s, 61.0696s/40 iters), loss = 1.28555
I1029 13:20:43.561489 12802 solver.cpp:241]     Train net output #0: loss = 1.28555 (* 1 = 1.28555 loss)
I1029 13:20:43.561506 12802 sgd_solver.cpp:105] Iteration 79520, lr = 7.79107e-06
I1029 13:21:13.046869 12802 solver.cpp:222] Iteration 79560 (1.35664 iter/s, 29.4847s/40 iters), loss = 1.33187
I1029 13:21:13.047032 12802 solver.cpp:241]     Train net output #0: loss = 1.33187 (* 1 = 1.33187 loss)
I1029 13:21:13.047046 12802 sgd_solver.cpp:105] Iteration 79560, lr = 7.76307e-06
I1029 13:21:42.556818 12802 solver.cpp:222] Iteration 79600 (1.35551 iter/s, 29.5091s/40 iters), loss = 1.47829
I1029 13:21:42.556875 12802 solver.cpp:241]     Train net output #0: loss = 1.47829 (* 1 = 1.47829 loss)
I1029 13:21:42.556891 12802 sgd_solver.cpp:105] Iteration 79600, lr = 7.73517e-06
I1029 13:22:12.607219 12802 solver.cpp:222] Iteration 79640 (1.33113 iter/s, 30.0496s/40 iters), loss = 1.21842
I1029 13:22:12.607381 12802 solver.cpp:241]     Train net output #0: loss = 1.21842 (* 1 = 1.21842 loss)
I1029 13:22:12.607395 12802 sgd_solver.cpp:105] Iteration 79640, lr = 7.70738e-06
I1029 13:22:42.337689 12802 solver.cpp:222] Iteration 79680 (1.34546 iter/s, 29.7296s/40 iters), loss = 1.56873
I1029 13:22:42.337748 12802 solver.cpp:241]     Train net output #0: loss = 1.56873 (* 1 = 1.56873 loss)
I1029 13:22:42.337760 12802 sgd_solver.cpp:105] Iteration 79680, lr = 7.67968e-06
I1029 13:23:19.084486 12802 solver.cpp:222] Iteration 79720 (1.08856 iter/s, 36.7459s/40 iters), loss = 1.21512
I1029 13:23:19.084709 12802 solver.cpp:241]     Train net output #0: loss = 1.21512 (* 1 = 1.21512 loss)
I1029 13:23:19.084728 12802 sgd_solver.cpp:105] Iteration 79720, lr = 7.65208e-06
I1029 13:23:49.133100 12802 solver.cpp:222] Iteration 79760 (1.33122 iter/s, 30.0477s/40 iters), loss = 1.31425
I1029 13:23:49.133265 12802 solver.cpp:241]     Train net output #0: loss = 1.31425 (* 1 = 1.31425 loss)
I1029 13:23:49.133280 12802 sgd_solver.cpp:105] Iteration 79760, lr = 7.62458e-06
I1029 13:24:19.991890 12802 solver.cpp:222] Iteration 79800 (1.29626 iter/s, 30.8579s/40 iters), loss = 1.25039
I1029 13:24:19.992077 12802 solver.cpp:241]     Train net output #0: loss = 1.25039 (* 1 = 1.25039 loss)
I1029 13:24:19.992095 12802 sgd_solver.cpp:105] Iteration 79800, lr = 7.59718e-06
I1029 13:25:50.074630 12802 solver.cpp:222] Iteration 79840 (0.444047 iter/s, 90.0805s/40 iters), loss = 1.33381
I1029 13:25:50.074828 12802 solver.cpp:241]     Train net output #0: loss = 1.33381 (* 1 = 1.33381 loss)
I1029 13:25:50.074846 12802 sgd_solver.cpp:105] Iteration 79840, lr = 7.56987e-06
I1029 13:26:20.023304 12802 solver.cpp:222] Iteration 79880 (1.33566 iter/s, 29.9478s/40 iters), loss = 1.37619
I1029 13:26:20.023365 12802 solver.cpp:241]     Train net output #0: loss = 1.37619 (* 1 = 1.37619 loss)
I1029 13:26:20.023378 12802 sgd_solver.cpp:105] Iteration 79880, lr = 7.54267e-06
I1029 13:26:49.583717 12802 solver.cpp:222] Iteration 79920 (1.3532 iter/s, 29.5597s/40 iters), loss = 1.40394
I1029 13:26:49.583874 12802 solver.cpp:241]     Train net output #0: loss = 1.40394 (* 1 = 1.40394 loss)
I1029 13:26:49.583891 12802 sgd_solver.cpp:105] Iteration 79920, lr = 7.51556e-06
I1029 13:27:19.356812 12802 solver.cpp:222] Iteration 79960 (1.34353 iter/s, 29.7722s/40 iters), loss = 1.37124
I1029 13:27:19.356883 12802 solver.cpp:241]     Train net output #0: loss = 1.37124 (* 1 = 1.37124 loss)
I1029 13:27:19.356899 12802 sgd_solver.cpp:105] Iteration 79960, lr = 7.48855e-06
I1029 13:27:50.120719 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_80000.caffemodel
I1029 13:27:50.269816 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_80000.solverstate
I1029 13:27:50.409550 12802 solver.cpp:334] Iteration 80000, Testing net (#0)
I1029 13:28:21.461895 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58968
I1029 13:28:21.462031 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80996
I1029 13:28:21.462045 12802 solver.cpp:401]     Test net output #2: loss = 1.8286 (* 1 = 1.8286 loss)
I1029 13:28:22.214395 12802 solver.cpp:222] Iteration 80000 (0.636374 iter/s, 62.8561s/40 iters), loss = 1.28542
I1029 13:28:22.214431 12802 solver.cpp:241]     Train net output #0: loss = 1.28542 (* 1 = 1.28542 loss)
I1029 13:28:22.214445 12802 sgd_solver.cpp:105] Iteration 80000, lr = 7.46164e-06
I1029 13:28:52.642189 12802 solver.cpp:222] Iteration 80040 (1.31462 iter/s, 30.427s/40 iters), loss = 1.45855
I1029 13:28:52.642366 12802 solver.cpp:241]     Train net output #0: loss = 1.45855 (* 1 = 1.45855 loss)
I1029 13:28:52.642390 12802 sgd_solver.cpp:105] Iteration 80040, lr = 7.43482e-06
I1029 13:29:22.450361 12802 solver.cpp:222] Iteration 80080 (1.34195 iter/s, 29.8073s/40 iters), loss = 1.15391
I1029 13:29:22.450422 12802 solver.cpp:241]     Train net output #0: loss = 1.15391 (* 1 = 1.15391 loss)
I1029 13:29:22.450438 12802 sgd_solver.cpp:105] Iteration 80080, lr = 7.4081e-06
I1029 13:29:52.015388 12802 solver.cpp:222] Iteration 80120 (1.35299 iter/s, 29.5643s/40 iters), loss = 1.52963
I1029 13:29:52.015559 12802 solver.cpp:241]     Train net output #0: loss = 1.52963 (* 1 = 1.52963 loss)
I1029 13:29:52.015576 12802 sgd_solver.cpp:105] Iteration 80120, lr = 7.38148e-06
I1029 13:30:21.606504 12802 solver.cpp:222] Iteration 80160 (1.3518 iter/s, 29.5902s/40 iters), loss = 1.32226
I1029 13:30:21.606567 12802 solver.cpp:241]     Train net output #0: loss = 1.32226 (* 1 = 1.32226 loss)
I1029 13:30:21.606583 12802 sgd_solver.cpp:105] Iteration 80160, lr = 7.35495e-06
I1029 13:30:51.706836 12802 solver.cpp:222] Iteration 80200 (1.32892 iter/s, 30.0995s/40 iters), loss = 1.56252
I1029 13:30:51.707088 12802 solver.cpp:241]     Train net output #0: loss = 1.56252 (* 1 = 1.56252 loss)
I1029 13:30:51.707105 12802 sgd_solver.cpp:105] Iteration 80200, lr = 7.32852e-06
I1029 13:31:21.165387 12802 solver.cpp:222] Iteration 80240 (1.35788 iter/s, 29.4576s/40 iters), loss = 1.40984
I1029 13:31:21.165452 12802 solver.cpp:241]     Train net output #0: loss = 1.40984 (* 1 = 1.40984 loss)
I1029 13:31:21.165467 12802 sgd_solver.cpp:105] Iteration 80240, lr = 7.30218e-06
I1029 13:31:50.777986 12802 solver.cpp:222] Iteration 80280 (1.35081 iter/s, 29.6118s/40 iters), loss = 1.44974
I1029 13:31:50.778156 12802 solver.cpp:241]     Train net output #0: loss = 1.44974 (* 1 = 1.44974 loss)
I1029 13:31:50.778173 12802 sgd_solver.cpp:105] Iteration 80280, lr = 7.27594e-06
I1029 13:32:20.284704 12802 solver.cpp:222] Iteration 80320 (1.35566 iter/s, 29.5058s/40 iters), loss = 1.14798
I1029 13:32:20.284765 12802 solver.cpp:241]     Train net output #0: loss = 1.14798 (* 1 = 1.14798 loss)
I1029 13:32:20.284781 12802 sgd_solver.cpp:105] Iteration 80320, lr = 7.24979e-06
I1029 13:32:55.097285 12802 solver.cpp:222] Iteration 80360 (1.14904 iter/s, 34.8117s/40 iters), loss = 1.24347
I1029 13:32:55.097533 12802 solver.cpp:241]     Train net output #0: loss = 1.24347 (* 1 = 1.24347 loss)
I1029 13:32:55.097560 12802 sgd_solver.cpp:105] Iteration 80360, lr = 7.22374e-06
I1029 13:33:40.219652 12802 solver.cpp:222] Iteration 80400 (0.886504 iter/s, 45.1211s/40 iters), loss = 1.65378
I1029 13:33:40.219861 12802 solver.cpp:241]     Train net output #0: loss = 1.65378 (* 1 = 1.65378 loss)
I1029 13:33:40.219899 12802 sgd_solver.cpp:105] Iteration 80400, lr = 7.19778e-06
I1029 13:34:10.815397 12802 solver.cpp:222] Iteration 80440 (1.30741 iter/s, 30.5948s/40 iters), loss = 2.0102
I1029 13:34:10.815582 12802 solver.cpp:241]     Train net output #0: loss = 2.0102 (* 1 = 2.0102 loss)
I1029 13:34:10.815605 12802 sgd_solver.cpp:105] Iteration 80440, lr = 7.17191e-06
I1029 13:34:52.830514 12802 solver.cpp:222] Iteration 80480 (0.952065 iter/s, 42.014s/40 iters), loss = 1.34486
I1029 13:34:52.830703 12802 solver.cpp:241]     Train net output #0: loss = 1.34486 (* 1 = 1.34486 loss)
I1029 13:34:52.830720 12802 sgd_solver.cpp:105] Iteration 80480, lr = 7.14614e-06
I1029 13:35:07.193323 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_80500.caffemodel
I1029 13:35:07.338410 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_80500.solverstate
I1029 13:35:07.454366 12802 solver.cpp:334] Iteration 80500, Testing net (#0)
I1029 13:35:38.340899 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 13:35:38.548463 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5856
I1029 13:35:38.548512 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81516
I1029 13:35:38.548522 12802 solver.cpp:401]     Test net output #2: loss = 1.83306 (* 1 = 1.83306 loss)
I1029 13:35:54.865803 12802 solver.cpp:222] Iteration 80520 (0.644811 iter/s, 62.0337s/40 iters), loss = 1.32155
I1029 13:35:54.865860 12802 solver.cpp:241]     Train net output #0: loss = 1.32155 (* 1 = 1.32155 loss)
I1029 13:35:54.865876 12802 sgd_solver.cpp:105] Iteration 80520, lr = 7.12045e-06
I1029 13:36:24.763025 12802 solver.cpp:222] Iteration 80560 (1.33795 iter/s, 29.8965s/40 iters), loss = 1.32124
I1029 13:36:24.763227 12802 solver.cpp:241]     Train net output #0: loss = 1.32124 (* 1 = 1.32124 loss)
I1029 13:36:24.763244 12802 sgd_solver.cpp:105] Iteration 80560, lr = 7.09486e-06
I1029 13:36:54.385537 12802 solver.cpp:222] Iteration 80600 (1.35037 iter/s, 29.6216s/40 iters), loss = 1.73339
I1029 13:36:54.385596 12802 solver.cpp:241]     Train net output #0: loss = 1.73339 (* 1 = 1.73339 loss)
I1029 13:36:54.385610 12802 sgd_solver.cpp:105] Iteration 80600, lr = 7.06937e-06
I1029 13:37:24.331079 12802 solver.cpp:222] Iteration 80640 (1.33579 iter/s, 29.9448s/40 iters), loss = 1.53139
I1029 13:37:24.331339 12802 solver.cpp:241]     Train net output #0: loss = 1.53139 (* 1 = 1.53139 loss)
I1029 13:37:24.331362 12802 sgd_solver.cpp:105] Iteration 80640, lr = 7.04396e-06
I1029 13:37:54.283953 12802 solver.cpp:222] Iteration 80680 (1.33547 iter/s, 29.9519s/40 iters), loss = 1.33089
I1029 13:37:54.284014 12802 solver.cpp:241]     Train net output #0: loss = 1.33089 (* 1 = 1.33089 loss)
I1029 13:37:54.284029 12802 sgd_solver.cpp:105] Iteration 80680, lr = 7.01865e-06
I1029 13:38:23.728045 12802 solver.cpp:222] Iteration 80720 (1.35854 iter/s, 29.4433s/40 iters), loss = 1.5171
I1029 13:38:23.728240 12802 solver.cpp:241]     Train net output #0: loss = 1.5171 (* 1 = 1.5171 loss)
I1029 13:38:23.728256 12802 sgd_solver.cpp:105] Iteration 80720, lr = 6.99342e-06
I1029 13:38:53.261303 12802 solver.cpp:222] Iteration 80760 (1.35445 iter/s, 29.5324s/40 iters), loss = 1.49067
I1029 13:38:53.261358 12802 solver.cpp:241]     Train net output #0: loss = 1.49067 (* 1 = 1.49067 loss)
I1029 13:38:53.261373 12802 sgd_solver.cpp:105] Iteration 80760, lr = 6.96829e-06
I1029 13:39:23.216575 12802 solver.cpp:222] Iteration 80800 (1.33536 iter/s, 29.9545s/40 iters), loss = 1.45928
I1029 13:39:23.216773 12802 solver.cpp:241]     Train net output #0: loss = 1.45928 (* 1 = 1.45928 loss)
I1029 13:39:23.216790 12802 sgd_solver.cpp:105] Iteration 80800, lr = 6.94325e-06
I1029 13:39:55.525455 12802 solver.cpp:222] Iteration 80840 (1.23809 iter/s, 32.3079s/40 iters), loss = 1.20051
I1029 13:39:55.525605 12802 solver.cpp:241]     Train net output #0: loss = 1.20051 (* 1 = 1.20051 loss)
I1029 13:39:55.525627 12802 sgd_solver.cpp:105] Iteration 80840, lr = 6.91829e-06
I1029 13:40:25.027191 12802 solver.cpp:222] Iteration 80880 (1.35589 iter/s, 29.5009s/40 iters), loss = 1.34987
I1029 13:40:25.027246 12802 solver.cpp:241]     Train net output #0: loss = 1.34987 (* 1 = 1.34987 loss)
I1029 13:40:25.027262 12802 sgd_solver.cpp:105] Iteration 80880, lr = 6.89343e-06
I1029 13:40:55.080915 12802 solver.cpp:222] Iteration 80920 (1.33098 iter/s, 30.0529s/40 iters), loss = 1.26534
I1029 13:40:55.081065 12802 solver.cpp:241]     Train net output #0: loss = 1.26534 (* 1 = 1.26534 loss)
I1029 13:40:55.081084 12802 sgd_solver.cpp:105] Iteration 80920, lr = 6.86866e-06
I1029 13:41:25.733530 12802 solver.cpp:222] Iteration 80960 (1.30498 iter/s, 30.6517s/40 iters), loss = 1.28252
I1029 13:41:25.733784 12802 solver.cpp:241]     Train net output #0: loss = 1.28252 (* 1 = 1.28252 loss)
I1029 13:41:25.733809 12802 sgd_solver.cpp:105] Iteration 80960, lr = 6.84397e-06
I1029 13:42:30.642161 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_81000.caffemodel
I1029 13:42:30.795923 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_81000.solverstate
I1029 13:42:30.909734 12802 solver.cpp:334] Iteration 81000, Testing net (#0)
I1029 13:43:02.118891 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58912
I1029 13:43:02.119065 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80956
I1029 13:43:02.119079 12802 solver.cpp:401]     Test net output #2: loss = 1.82749 (* 1 = 1.82749 loss)
I1029 13:43:02.867828 12802 solver.cpp:222] Iteration 81000 (0.411812 iter/s, 97.1318s/40 iters), loss = 1.36995
I1029 13:43:02.867887 12802 solver.cpp:241]     Train net output #0: loss = 1.36995 (* 1 = 1.36995 loss)
I1029 13:43:02.867905 12802 sgd_solver.cpp:105] Iteration 81000, lr = 6.81938e-06
I1029 13:43:40.799300 12802 solver.cpp:222] Iteration 81040 (1.05456 iter/s, 37.9305s/40 iters), loss = 1.57525
I1029 13:43:40.799509 12802 solver.cpp:241]     Train net output #0: loss = 1.57525 (* 1 = 1.57525 loss)
I1029 13:43:40.799525 12802 sgd_solver.cpp:105] Iteration 81040, lr = 6.79487e-06
I1029 13:44:10.423458 12802 solver.cpp:222] Iteration 81080 (1.35029 iter/s, 29.6233s/40 iters), loss = 1.02579
I1029 13:44:10.423516 12802 solver.cpp:241]     Train net output #0: loss = 1.02579 (* 1 = 1.02579 loss)
I1029 13:44:10.423532 12802 sgd_solver.cpp:105] Iteration 81080, lr = 6.77045e-06
I1029 13:44:39.999866 12802 solver.cpp:222] Iteration 81120 (1.35246 iter/s, 29.5756s/40 iters), loss = 1.33425
I1029 13:44:40.000110 12802 solver.cpp:241]     Train net output #0: loss = 1.33425 (* 1 = 1.33425 loss)
I1029 13:44:40.000129 12802 sgd_solver.cpp:105] Iteration 81120, lr = 6.74612e-06
I1029 13:45:06.072388 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 13:45:09.679910 12802 solver.cpp:222] Iteration 81160 (1.34775 iter/s, 29.6791s/40 iters), loss = 1.62701
I1029 13:45:09.679975 12802 solver.cpp:241]     Train net output #0: loss = 1.62701 (* 1 = 1.62701 loss)
I1029 13:45:09.679989 12802 sgd_solver.cpp:105] Iteration 81160, lr = 6.72187e-06
I1029 13:45:39.446178 12802 solver.cpp:222] Iteration 81200 (1.34384 iter/s, 29.7655s/40 iters), loss = 1.39787
I1029 13:45:39.446363 12802 solver.cpp:241]     Train net output #0: loss = 1.39787 (* 1 = 1.39787 loss)
I1029 13:45:39.446382 12802 sgd_solver.cpp:105] Iteration 81200, lr = 6.69772e-06
I1029 13:46:09.314018 12802 solver.cpp:222] Iteration 81240 (1.33927 iter/s, 29.8669s/40 iters), loss = 1.50085
I1029 13:46:09.314076 12802 solver.cpp:241]     Train net output #0: loss = 1.50085 (* 1 = 1.50085 loss)
I1029 13:46:09.314091 12802 sgd_solver.cpp:105] Iteration 81240, lr = 6.67365e-06
I1029 13:46:38.967053 12802 solver.cpp:222] Iteration 81280 (1.34897 iter/s, 29.6523s/40 iters), loss = 1.42255
I1029 13:46:38.967242 12802 solver.cpp:241]     Train net output #0: loss = 1.42255 (* 1 = 1.42255 loss)
I1029 13:46:38.967258 12802 sgd_solver.cpp:105] Iteration 81280, lr = 6.64966e-06
I1029 13:47:08.531999 12802 solver.cpp:222] Iteration 81320 (1.35299 iter/s, 29.5641s/40 iters), loss = 1.36377
I1029 13:47:08.532058 12802 solver.cpp:241]     Train net output #0: loss = 1.36377 (* 1 = 1.36377 loss)
I1029 13:47:08.532073 12802 sgd_solver.cpp:105] Iteration 81320, lr = 6.62577e-06
I1029 13:47:38.056499 12802 solver.cpp:222] Iteration 81360 (1.35484 iter/s, 29.5237s/40 iters), loss = 1.06549
I1029 13:47:38.056607 12802 solver.cpp:241]     Train net output #0: loss = 1.06549 (* 1 = 1.06549 loss)
I1029 13:47:38.056623 12802 sgd_solver.cpp:105] Iteration 81360, lr = 6.60195e-06
I1029 13:48:07.562291 12802 solver.cpp:222] Iteration 81400 (1.3557 iter/s, 29.505s/40 iters), loss = 1.28935
I1029 13:48:07.562347 12802 solver.cpp:241]     Train net output #0: loss = 1.28935 (* 1 = 1.28935 loss)
I1029 13:48:07.562362 12802 sgd_solver.cpp:105] Iteration 81400, lr = 6.57823e-06
I1029 13:48:37.067081 12802 solver.cpp:222] Iteration 81440 (1.35575 iter/s, 29.504s/40 iters), loss = 1.36711
I1029 13:48:37.067217 12802 solver.cpp:241]     Train net output #0: loss = 1.36711 (* 1 = 1.36711 loss)
I1029 13:48:37.067234 12802 sgd_solver.cpp:105] Iteration 81440, lr = 6.55459e-06
I1029 13:49:06.630882 12802 solver.cpp:222] Iteration 81480 (1.35304 iter/s, 29.563s/40 iters), loss = 1.28047
I1029 13:49:06.630944 12802 solver.cpp:241]     Train net output #0: loss = 1.28047 (* 1 = 1.28047 loss)
I1029 13:49:06.630960 12802 sgd_solver.cpp:105] Iteration 81480, lr = 6.53103e-06
I1029 13:49:20.709470 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_81500.caffemodel
I1029 13:49:20.862380 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_81500.solverstate
I1029 13:49:20.976742 12802 solver.cpp:334] Iteration 81500, Testing net (#0)
I1029 13:49:51.874261 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 13:49:52.081404 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5852
I1029 13:49:52.081459 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.815319
I1029 13:49:52.081470 12802 solver.cpp:401]     Test net output #2: loss = 1.83542 (* 1 = 1.83542 loss)
I1029 13:50:07.657137 12802 solver.cpp:222] Iteration 81520 (0.655472 iter/s, 61.0247s/40 iters), loss = 1.39438
I1029 13:50:07.657197 12802 solver.cpp:241]     Train net output #0: loss = 1.39438 (* 1 = 1.39438 loss)
I1029 13:50:07.657213 12802 sgd_solver.cpp:105] Iteration 81520, lr = 6.50756e-06
I1029 13:50:37.364363 12802 solver.cpp:222] Iteration 81560 (1.34651 iter/s, 29.7065s/40 iters), loss = 1.61471
I1029 13:50:37.364599 12802 solver.cpp:241]     Train net output #0: loss = 1.61471 (* 1 = 1.61471 loss)
I1029 13:50:37.364616 12802 sgd_solver.cpp:105] Iteration 81560, lr = 6.48417e-06
I1029 13:51:06.925633 12802 solver.cpp:222] Iteration 81600 (1.35317 iter/s, 29.5603s/40 iters), loss = 1.13198
I1029 13:51:06.925698 12802 solver.cpp:241]     Train net output #0: loss = 1.13198 (* 1 = 1.13198 loss)
I1029 13:51:06.925712 12802 sgd_solver.cpp:105] Iteration 81600, lr = 6.46087e-06
I1029 13:51:36.572284 12802 solver.cpp:222] Iteration 81640 (1.34926 iter/s, 29.6459s/40 iters), loss = 1.68569
I1029 13:51:36.572432 12802 solver.cpp:241]     Train net output #0: loss = 1.68569 (* 1 = 1.68569 loss)
I1029 13:51:36.572449 12802 sgd_solver.cpp:105] Iteration 81640, lr = 6.43765e-06
I1029 13:52:06.087864 12802 solver.cpp:222] Iteration 81680 (1.35526 iter/s, 29.5147s/40 iters), loss = 1.71596
I1029 13:52:06.087924 12802 solver.cpp:241]     Train net output #0: loss = 1.71596 (* 1 = 1.71596 loss)
I1029 13:52:06.087939 12802 sgd_solver.cpp:105] Iteration 81680, lr = 6.41451e-06
I1029 13:52:35.656616 12802 solver.cpp:222] Iteration 81720 (1.35281 iter/s, 29.568s/40 iters), loss = 1.59604
I1029 13:52:35.656774 12802 solver.cpp:241]     Train net output #0: loss = 1.59604 (* 1 = 1.59604 loss)
I1029 13:52:35.656790 12802 sgd_solver.cpp:105] Iteration 81720, lr = 6.39146e-06
I1029 13:53:05.219060 12802 solver.cpp:222] Iteration 81760 (1.35311 iter/s, 29.5616s/40 iters), loss = 1.51925
I1029 13:53:05.219125 12802 solver.cpp:241]     Train net output #0: loss = 1.51925 (* 1 = 1.51925 loss)
I1029 13:53:05.219138 12802 sgd_solver.cpp:105] Iteration 81760, lr = 6.36849e-06
I1029 13:53:35.428057 12802 solver.cpp:222] Iteration 81800 (1.32414 iter/s, 30.2082s/40 iters), loss = 1.70858
I1029 13:53:35.428252 12802 solver.cpp:241]     Train net output #0: loss = 1.70858 (* 1 = 1.70858 loss)
I1029 13:53:35.428269 12802 sgd_solver.cpp:105] Iteration 81800, lr = 6.34561e-06
I1029 13:54:05.962327 12802 solver.cpp:222] Iteration 81840 (1.31004 iter/s, 30.5333s/40 iters), loss = 1.41435
I1029 13:54:05.962527 12802 solver.cpp:241]     Train net output #0: loss = 1.41435 (* 1 = 1.41435 loss)
I1029 13:54:05.962543 12802 sgd_solver.cpp:105] Iteration 81840, lr = 6.3228e-06
I1029 13:55:28.623248 12802 solver.cpp:222] Iteration 81880 (0.483917 iter/s, 82.6588s/40 iters), loss = 1.58135
I1029 13:55:28.623455 12802 solver.cpp:241]     Train net output #0: loss = 1.58135 (* 1 = 1.58135 loss)
I1029 13:55:28.623471 12802 sgd_solver.cpp:105] Iteration 81880, lr = 6.30008e-06
I1029 13:55:58.447906 12802 solver.cpp:222] Iteration 81920 (1.34121 iter/s, 29.8238s/40 iters), loss = 1.49803
I1029 13:55:58.447970 12802 solver.cpp:241]     Train net output #0: loss = 1.49803 (* 1 = 1.49803 loss)
I1029 13:55:58.447986 12802 sgd_solver.cpp:105] Iteration 81920, lr = 6.27744e-06
I1029 13:56:28.431478 12802 solver.cpp:222] Iteration 81960 (1.3341 iter/s, 29.9828s/40 iters), loss = 1.4089
I1029 13:56:28.431634 12802 solver.cpp:241]     Train net output #0: loss = 1.4089 (* 1 = 1.4089 loss)
I1029 13:56:28.431650 12802 sgd_solver.cpp:105] Iteration 81960, lr = 6.25488e-06
I1029 13:56:57.592633 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_82000.caffemodel
I1029 13:56:57.741580 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_82000.solverstate
I1029 13:56:57.859519 12802 solver.cpp:334] Iteration 82000, Testing net (#0)
I1029 13:57:28.919131 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58928
I1029 13:57:28.919365 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80988
I1029 13:57:28.919380 12802 solver.cpp:401]     Test net output #2: loss = 1.82892 (* 1 = 1.82892 loss)
I1029 13:57:29.704620 12802 solver.cpp:222] Iteration 82000 (0.652831 iter/s, 61.2716s/40 iters), loss = 1.44841
I1029 13:57:29.704677 12802 solver.cpp:241]     Train net output #0: loss = 1.44841 (* 1 = 1.44841 loss)
I1029 13:57:29.704699 12802 sgd_solver.cpp:105] Iteration 82000, lr = 6.2324e-06
I1029 13:58:06.562376 12802 solver.cpp:222] Iteration 82040 (1.08528 iter/s, 36.8568s/40 iters), loss = 1.5191
I1029 13:58:06.562551 12802 solver.cpp:241]     Train net output #0: loss = 1.5191 (* 1 = 1.5191 loss)
I1029 13:58:06.562568 12802 sgd_solver.cpp:105] Iteration 82040, lr = 6.21e-06
I1029 13:58:36.318351 12802 solver.cpp:222] Iteration 82080 (1.34431 iter/s, 29.7551s/40 iters), loss = 1.30045
I1029 13:58:36.318406 12802 solver.cpp:241]     Train net output #0: loss = 1.30045 (* 1 = 1.30045 loss)
I1029 13:58:36.318421 12802 sgd_solver.cpp:105] Iteration 82080, lr = 6.18768e-06
I1029 13:59:05.964017 12802 solver.cpp:222] Iteration 82120 (1.3493 iter/s, 29.6449s/40 iters), loss = 1.35925
I1029 13:59:05.964215 12802 solver.cpp:241]     Train net output #0: loss = 1.35925 (* 1 = 1.35925 loss)
I1029 13:59:05.964231 12802 sgd_solver.cpp:105] Iteration 82120, lr = 6.16544e-06
I1029 13:59:36.040401 12802 solver.cpp:222] Iteration 82160 (1.32999 iter/s, 30.0755s/40 iters), loss = 1.49816
I1029 13:59:36.040498 12802 solver.cpp:241]     Train net output #0: loss = 1.49816 (* 1 = 1.49816 loss)
I1029 13:59:36.040514 12802 sgd_solver.cpp:105] Iteration 82160, lr = 6.14329e-06
I1029 14:00:06.304239 12802 solver.cpp:222] Iteration 82200 (1.32174 iter/s, 30.263s/40 iters), loss = 1.48941
I1029 14:00:06.304402 12802 solver.cpp:241]     Train net output #0: loss = 1.48941 (* 1 = 1.48941 loss)
I1029 14:00:06.304425 12802 sgd_solver.cpp:105] Iteration 82200, lr = 6.12121e-06
I1029 14:00:36.147421 12802 solver.cpp:222] Iteration 82240 (1.34038 iter/s, 29.8423s/40 iters), loss = 1.69887
I1029 14:00:36.147476 12802 solver.cpp:241]     Train net output #0: loss = 1.69887 (* 1 = 1.69887 loss)
I1029 14:00:36.147493 12802 sgd_solver.cpp:105] Iteration 82240, lr = 6.09921e-06
I1029 14:01:05.996984 12802 solver.cpp:222] Iteration 82280 (1.34009 iter/s, 29.8488s/40 iters), loss = 1.75402
I1029 14:01:05.997174 12802 solver.cpp:241]     Train net output #0: loss = 1.75402 (* 1 = 1.75402 loss)
I1029 14:01:05.997190 12802 sgd_solver.cpp:105] Iteration 82280, lr = 6.07729e-06
I1029 14:01:35.559449 12802 solver.cpp:222] Iteration 82320 (1.35311 iter/s, 29.5616s/40 iters), loss = 1.57748
I1029 14:01:35.559502 12802 solver.cpp:241]     Train net output #0: loss = 1.57748 (* 1 = 1.57748 loss)
I1029 14:01:35.559517 12802 sgd_solver.cpp:105] Iteration 82320, lr = 6.05545e-06
I1029 14:02:05.296764 12802 solver.cpp:222] Iteration 82360 (1.34515 iter/s, 29.7366s/40 iters), loss = 1.38866
I1029 14:02:05.296905 12802 solver.cpp:241]     Train net output #0: loss = 1.38866 (* 1 = 1.38866 loss)
I1029 14:02:05.296924 12802 sgd_solver.cpp:105] Iteration 82360, lr = 6.03369e-06
I1029 14:02:36.049878 12802 solver.cpp:222] Iteration 82400 (1.30072 iter/s, 30.7522s/40 iters), loss = 1.50954
I1029 14:02:36.050043 12802 solver.cpp:241]     Train net output #0: loss = 1.50954 (* 1 = 1.50954 loss)
I1029 14:02:36.050061 12802 sgd_solver.cpp:105] Iteration 82400, lr = 6.012e-06
I1029 14:03:09.025223 12802 solver.cpp:222] Iteration 82440 (1.21306 iter/s, 32.9744s/40 iters), loss = 1.50808
I1029 14:03:09.025421 12802 solver.cpp:241]     Train net output #0: loss = 1.50808 (* 1 = 1.50808 loss)
I1029 14:03:09.025439 12802 sgd_solver.cpp:105] Iteration 82440, lr = 5.9904e-06
I1029 14:03:39.999511 12802 solver.cpp:222] Iteration 82480 (1.29143 iter/s, 30.9734s/40 iters), loss = 1.23799
I1029 14:03:39.999722 12802 solver.cpp:241]     Train net output #0: loss = 1.23799 (* 1 = 1.23799 loss)
I1029 14:03:39.999739 12802 sgd_solver.cpp:105] Iteration 82480, lr = 5.96887e-06
I1029 14:03:54.415717 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_82500.caffemodel
I1029 14:03:54.556654 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_82500.solverstate
I1029 14:03:54.661192 12802 solver.cpp:334] Iteration 82500, Testing net (#0)
I1029 14:04:25.566161 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 14:04:25.775763 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5854
I1029 14:04:25.775815 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81516
I1029 14:04:25.775825 12802 solver.cpp:401]     Test net output #2: loss = 1.8327 (* 1 = 1.8327 loss)
I1029 14:04:41.370376 12802 solver.cpp:222] Iteration 82520 (0.651792 iter/s, 61.3692s/40 iters), loss = 1.42876
I1029 14:04:41.370435 12802 solver.cpp:241]     Train net output #0: loss = 1.42876 (* 1 = 1.42876 loss)
I1029 14:04:41.370450 12802 sgd_solver.cpp:105] Iteration 82520, lr = 5.94742e-06
I1029 14:05:14.604323 12802 solver.cpp:222] Iteration 82560 (1.20362 iter/s, 33.2331s/40 iters), loss = 1.55497
I1029 14:05:14.604507 12802 solver.cpp:241]     Train net output #0: loss = 1.55497 (* 1 = 1.55497 loss)
I1029 14:05:14.604524 12802 sgd_solver.cpp:105] Iteration 82560, lr = 5.92605e-06
I1029 14:05:57.052037 12802 solver.cpp:222] Iteration 82600 (0.942362 iter/s, 42.4465s/40 iters), loss = 1.42323
I1029 14:05:57.052227 12802 solver.cpp:241]     Train net output #0: loss = 1.42323 (* 1 = 1.42323 loss)
I1029 14:05:57.052242 12802 sgd_solver.cpp:105] Iteration 82600, lr = 5.90475e-06
I1029 14:06:28.404000 12802 solver.cpp:222] Iteration 82640 (1.27587 iter/s, 31.351s/40 iters), loss = 1.3936
I1029 14:06:28.404167 12802 solver.cpp:241]     Train net output #0: loss = 1.3936 (* 1 = 1.3936 loss)
I1029 14:06:28.404188 12802 sgd_solver.cpp:105] Iteration 82640, lr = 5.88353e-06
I1029 14:06:58.775059 12802 solver.cpp:222] Iteration 82680 (1.31708 iter/s, 30.3702s/40 iters), loss = 1.56168
I1029 14:06:58.775255 12802 solver.cpp:241]     Train net output #0: loss = 1.56168 (* 1 = 1.56168 loss)
I1029 14:06:58.775274 12802 sgd_solver.cpp:105] Iteration 82680, lr = 5.86238e-06
I1029 14:07:29.147572 12802 solver.cpp:222] Iteration 82720 (1.31702 iter/s, 30.3716s/40 iters), loss = 1.76164
I1029 14:07:29.147716 12802 solver.cpp:241]     Train net output #0: loss = 1.76164 (* 1 = 1.76164 loss)
I1029 14:07:29.147732 12802 sgd_solver.cpp:105] Iteration 82720, lr = 5.84132e-06
I1029 14:07:59.590384 12802 solver.cpp:222] Iteration 82760 (1.31398 iter/s, 30.442s/40 iters), loss = 1.48385
I1029 14:07:59.590535 12802 solver.cpp:241]     Train net output #0: loss = 1.48385 (* 1 = 1.48385 loss)
I1029 14:07:59.590553 12802 sgd_solver.cpp:105] Iteration 82760, lr = 5.82032e-06
I1029 14:08:29.477308 12802 solver.cpp:222] Iteration 82800 (1.33842 iter/s, 29.8861s/40 iters), loss = 1.54116
I1029 14:08:29.477368 12802 solver.cpp:241]     Train net output #0: loss = 1.54116 (* 1 = 1.54116 loss)
I1029 14:08:29.477381 12802 sgd_solver.cpp:105] Iteration 82800, lr = 5.79941e-06
I1029 14:08:59.422793 12802 solver.cpp:222] Iteration 82840 (1.33579 iter/s, 29.9447s/40 iters), loss = 1.1616
I1029 14:08:59.422955 12802 solver.cpp:241]     Train net output #0: loss = 1.1616 (* 1 = 1.1616 loss)
I1029 14:08:59.422972 12802 sgd_solver.cpp:105] Iteration 82840, lr = 5.77856e-06
I1029 14:09:29.484071 12802 solver.cpp:222] Iteration 82880 (1.33065 iter/s, 30.0604s/40 iters), loss = 1.3271
I1029 14:09:29.484215 12802 solver.cpp:241]     Train net output #0: loss = 1.3271 (* 1 = 1.3271 loss)
I1029 14:09:29.484231 12802 sgd_solver.cpp:105] Iteration 82880, lr = 5.7578e-06
I1029 14:10:00.138917 12802 solver.cpp:222] Iteration 82920 (1.30489 iter/s, 30.654s/40 iters), loss = 1.42443
I1029 14:10:00.139089 12802 solver.cpp:241]     Train net output #0: loss = 1.42443 (* 1 = 1.42443 loss)
I1029 14:10:00.139107 12802 sgd_solver.cpp:105] Iteration 82920, lr = 5.7371e-06
I1029 14:10:29.786103 12802 solver.cpp:222] Iteration 82960 (1.34924 iter/s, 29.6463s/40 iters), loss = 1.43154
I1029 14:10:29.786162 12802 solver.cpp:241]     Train net output #0: loss = 1.43154 (* 1 = 1.43154 loss)
I1029 14:10:29.786177 12802 sgd_solver.cpp:105] Iteration 82960, lr = 5.71649e-06
I1029 14:10:58.633699 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_83000.caffemodel
I1029 14:11:14.320547 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_83000.solverstate
I1029 14:11:14.740751 12802 solver.cpp:334] Iteration 83000, Testing net (#0)
I1029 14:11:45.918287 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58944
I1029 14:11:45.918376 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80992
I1029 14:11:45.918388 12802 solver.cpp:401]     Test net output #2: loss = 1.82839 (* 1 = 1.82839 loss)
I1029 14:11:46.665315 12802 solver.cpp:222] Iteration 83000 (0.520309 iter/s, 76.8774s/40 iters), loss = 1.41492
I1029 14:11:46.665375 12802 solver.cpp:241]     Train net output #0: loss = 1.41492 (* 1 = 1.41492 loss)
I1029 14:11:46.665391 12802 sgd_solver.cpp:105] Iteration 83000, lr = 5.69594e-06
I1029 14:12:16.333724 12802 solver.cpp:222] Iteration 83040 (1.34827 iter/s, 29.6676s/40 iters), loss = 1.50596
I1029 14:12:16.333849 12802 solver.cpp:241]     Train net output #0: loss = 1.50596 (* 1 = 1.50596 loss)
I1029 14:12:16.333868 12802 sgd_solver.cpp:105] Iteration 83040, lr = 5.67547e-06
I1029 14:12:46.711052 12802 solver.cpp:222] Iteration 83080 (1.31681 iter/s, 30.3765s/40 iters), loss = 1.3449
I1029 14:12:46.711218 12802 solver.cpp:241]     Train net output #0: loss = 1.3449 (* 1 = 1.3449 loss)
I1029 14:12:46.711235 12802 sgd_solver.cpp:105] Iteration 83080, lr = 5.65508e-06
I1029 14:13:17.219116 12802 solver.cpp:222] Iteration 83120 (1.31117 iter/s, 30.5072s/40 iters), loss = 1.78518
I1029 14:13:17.219274 12802 solver.cpp:241]     Train net output #0: loss = 1.78518 (* 1 = 1.78518 loss)
I1029 14:13:17.219291 12802 sgd_solver.cpp:105] Iteration 83120, lr = 5.63475e-06
I1029 14:13:47.809643 12802 solver.cpp:222] Iteration 83160 (1.30763 iter/s, 30.5896s/40 iters), loss = 1.64809
I1029 14:13:47.809803 12802 solver.cpp:241]     Train net output #0: loss = 1.64809 (* 1 = 1.64809 loss)
I1029 14:13:47.809820 12802 sgd_solver.cpp:105] Iteration 83160, lr = 5.6145e-06
I1029 14:14:18.246753 12802 solver.cpp:222] Iteration 83200 (1.31422 iter/s, 30.4362s/40 iters), loss = 1.48509
I1029 14:14:18.246928 12802 solver.cpp:241]     Train net output #0: loss = 1.48509 (* 1 = 1.48509 loss)
I1029 14:14:18.246945 12802 sgd_solver.cpp:105] Iteration 83200, lr = 5.59432e-06
I1029 14:14:47.934406 12802 solver.cpp:222] Iteration 83240 (1.3474 iter/s, 29.6868s/40 iters), loss = 1.30053
I1029 14:14:47.934464 12802 solver.cpp:241]     Train net output #0: loss = 1.30053 (* 1 = 1.30053 loss)
I1029 14:14:47.934479 12802 sgd_solver.cpp:105] Iteration 83240, lr = 5.57422e-06
I1029 14:15:17.897290 12802 solver.cpp:222] Iteration 83280 (1.33502 iter/s, 29.9621s/40 iters), loss = 1.64729
I1029 14:15:17.897490 12802 solver.cpp:241]     Train net output #0: loss = 1.64729 (* 1 = 1.64729 loss)
I1029 14:15:17.897507 12802 sgd_solver.cpp:105] Iteration 83280, lr = 5.55419e-06
I1029 14:15:47.502568 12802 solver.cpp:222] Iteration 83320 (1.35115 iter/s, 29.6044s/40 iters), loss = 1.50362
I1029 14:15:47.502622 12802 solver.cpp:241]     Train net output #0: loss = 1.50362 (* 1 = 1.50362 loss)
I1029 14:15:47.502638 12802 sgd_solver.cpp:105] Iteration 83320, lr = 5.53423e-06
I1029 14:16:17.766620 12802 solver.cpp:222] Iteration 83360 (1.32173 iter/s, 30.2633s/40 iters), loss = 1.29297
I1029 14:16:17.766808 12802 solver.cpp:241]     Train net output #0: loss = 1.29297 (* 1 = 1.29297 loss)
I1029 14:16:17.766824 12802 sgd_solver.cpp:105] Iteration 83360, lr = 5.51434e-06
I1029 14:16:48.910831 12802 solver.cpp:222] Iteration 83400 (1.28439 iter/s, 31.1433s/40 iters), loss = 1.44481
I1029 14:16:48.911005 12802 solver.cpp:241]     Train net output #0: loss = 1.44481 (* 1 = 1.44481 loss)
I1029 14:16:48.911020 12802 sgd_solver.cpp:105] Iteration 83400, lr = 5.49452e-06
I1029 14:17:19.429615 12802 solver.cpp:222] Iteration 83440 (1.31071 iter/s, 30.5179s/40 iters), loss = 1.50735
I1029 14:17:19.429884 12802 solver.cpp:241]     Train net output #0: loss = 1.50735 (* 1 = 1.50735 loss)
I1029 14:17:19.429913 12802 sgd_solver.cpp:105] Iteration 83440, lr = 5.47477e-06
I1029 14:17:49.041163 12802 solver.cpp:222] Iteration 83480 (1.35087 iter/s, 29.6106s/40 iters), loss = 1.7976
I1029 14:17:49.041224 12802 solver.cpp:241]     Train net output #0: loss = 1.7976 (* 1 = 1.7976 loss)
I1029 14:17:49.041239 12802 sgd_solver.cpp:105] Iteration 83480, lr = 5.4551e-06
I1029 14:18:03.095897 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_83500.caffemodel
I1029 14:18:03.252065 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_83500.solverstate
I1029 14:18:03.366586 12802 solver.cpp:334] Iteration 83500, Testing net (#0)
I1029 14:18:34.174522 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 14:18:34.382094 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5854
I1029 14:18:34.382141 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81556
I1029 14:18:34.382153 12802 solver.cpp:401]     Test net output #2: loss = 1.83134 (* 1 = 1.83134 loss)
I1029 14:18:50.333988 12802 solver.cpp:222] Iteration 83520 (0.652621 iter/s, 61.2913s/40 iters), loss = 1.63948
I1029 14:18:50.334039 12802 solver.cpp:241]     Train net output #0: loss = 1.63948 (* 1 = 1.63948 loss)
I1029 14:18:50.334054 12802 sgd_solver.cpp:105] Iteration 83520, lr = 5.43549e-06
I1029 14:19:20.768529 12802 solver.cpp:222] Iteration 83560 (1.31433 iter/s, 30.4338s/40 iters), loss = 1.10494
I1029 14:19:20.768746 12802 solver.cpp:241]     Train net output #0: loss = 1.10494 (* 1 = 1.10494 loss)
I1029 14:19:20.768771 12802 sgd_solver.cpp:105] Iteration 83560, lr = 5.41596e-06
I1029 14:19:51.594813 12802 solver.cpp:222] Iteration 83600 (1.29763 iter/s, 30.8253s/40 iters), loss = 1.54878
I1029 14:19:51.595023 12802 solver.cpp:241]     Train net output #0: loss = 1.54878 (* 1 = 1.54878 loss)
I1029 14:19:51.595038 12802 sgd_solver.cpp:105] Iteration 83600, lr = 5.3965e-06
I1029 14:20:21.202047 12802 solver.cpp:222] Iteration 83640 (1.35106 iter/s, 29.6063s/40 iters), loss = 1.41843
I1029 14:20:21.202107 12802 solver.cpp:241]     Train net output #0: loss = 1.41843 (* 1 = 1.41843 loss)
I1029 14:20:21.202123 12802 sgd_solver.cpp:105] Iteration 83640, lr = 5.3771e-06
I1029 14:20:34.015234 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 14:20:50.864464 12802 solver.cpp:222] Iteration 83680 (1.34854 iter/s, 29.6616s/40 iters), loss = 1.43762
I1029 14:20:50.864522 12802 solver.cpp:241]     Train net output #0: loss = 1.43762 (* 1 = 1.43762 loss)
I1029 14:20:50.864537 12802 sgd_solver.cpp:105] Iteration 83680, lr = 5.35778e-06
I1029 14:21:20.964660 12802 solver.cpp:222] Iteration 83720 (1.32893 iter/s, 30.0994s/40 iters), loss = 1.53616
I1029 14:21:20.964824 12802 solver.cpp:241]     Train net output #0: loss = 1.53616 (* 1 = 1.53616 loss)
I1029 14:21:20.964840 12802 sgd_solver.cpp:105] Iteration 83720, lr = 5.33852e-06
I1029 14:22:11.267439 12802 solver.cpp:222] Iteration 83760 (0.795206 iter/s, 50.3014s/40 iters), loss = 1.19366
I1029 14:22:11.267626 12802 solver.cpp:241]     Train net output #0: loss = 1.19366 (* 1 = 1.19366 loss)
I1029 14:22:11.267642 12802 sgd_solver.cpp:105] Iteration 83760, lr = 5.31934e-06
I1029 14:22:41.762768 12802 solver.cpp:222] Iteration 83800 (1.31171 iter/s, 30.4944s/40 iters), loss = 1.13244
I1029 14:22:41.763216 12802 solver.cpp:241]     Train net output #0: loss = 1.13244 (* 1 = 1.13244 loss)
I1029 14:22:41.763233 12802 sgd_solver.cpp:105] Iteration 83800, lr = 5.30022e-06
I1029 14:23:12.175995 12802 solver.cpp:222] Iteration 83840 (1.31527 iter/s, 30.4121s/40 iters), loss = 1.45519
I1029 14:23:12.176221 12802 solver.cpp:241]     Train net output #0: loss = 1.45519 (* 1 = 1.45519 loss)
I1029 14:23:12.176244 12802 sgd_solver.cpp:105] Iteration 83840, lr = 5.28117e-06
I1029 14:23:45.337523 12802 solver.cpp:222] Iteration 83880 (1.20625 iter/s, 33.1605s/40 iters), loss = 1.34121
I1029 14:23:45.337677 12802 solver.cpp:241]     Train net output #0: loss = 1.34121 (* 1 = 1.34121 loss)
I1029 14:23:45.337694 12802 sgd_solver.cpp:105] Iteration 83880, lr = 5.26219e-06
I1029 14:24:15.128132 12802 solver.cpp:222] Iteration 83920 (1.34274 iter/s, 29.7897s/40 iters), loss = 1.50552
I1029 14:24:15.128193 12802 solver.cpp:241]     Train net output #0: loss = 1.50552 (* 1 = 1.50552 loss)
I1029 14:24:15.128207 12802 sgd_solver.cpp:105] Iteration 83920, lr = 5.24328e-06
I1029 14:24:44.847664 12802 solver.cpp:222] Iteration 83960 (1.34595 iter/s, 29.7188s/40 iters), loss = 1.4145
I1029 14:24:44.847849 12802 solver.cpp:241]     Train net output #0: loss = 1.4145 (* 1 = 1.4145 loss)
I1029 14:24:44.847865 12802 sgd_solver.cpp:105] Iteration 83960, lr = 5.22444e-06
I1029 14:25:16.480969 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_84000.caffemodel
I1029 14:25:16.628988 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_84000.solverstate
I1029 14:25:16.762320 12802 solver.cpp:334] Iteration 84000, Testing net (#0)
I1029 14:25:47.771250 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58928
I1029 14:25:47.771390 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80996
I1029 14:25:47.771404 12802 solver.cpp:401]     Test net output #2: loss = 1.83076 (* 1 = 1.83076 loss)
I1029 14:25:48.537087 12802 solver.cpp:222] Iteration 84000 (0.628064 iter/s, 63.6878s/40 iters), loss = 1.33552
I1029 14:25:48.537145 12802 solver.cpp:241]     Train net output #0: loss = 1.33552 (* 1 = 1.33552 loss)
I1029 14:25:48.537169 12802 sgd_solver.cpp:105] Iteration 84000, lr = 5.20566e-06
I1029 14:26:27.230484 12802 solver.cpp:222] Iteration 84040 (1.03379 iter/s, 38.6924s/40 iters), loss = 1.29825
I1029 14:26:27.230646 12802 solver.cpp:241]     Train net output #0: loss = 1.29825 (* 1 = 1.29825 loss)
I1029 14:26:27.230664 12802 sgd_solver.cpp:105] Iteration 84040, lr = 5.18695e-06
I1029 14:26:56.861940 12802 solver.cpp:222] Iteration 84080 (1.34996 iter/s, 29.6306s/40 iters), loss = 1.36303
I1029 14:26:56.862000 12802 solver.cpp:241]     Train net output #0: loss = 1.36303 (* 1 = 1.36303 loss)
I1029 14:26:56.862016 12802 sgd_solver.cpp:105] Iteration 84080, lr = 5.16831e-06
I1029 14:27:26.428637 12802 solver.cpp:222] Iteration 84120 (1.35291 iter/s, 29.5659s/40 iters), loss = 1.3709
I1029 14:27:26.428803 12802 solver.cpp:241]     Train net output #0: loss = 1.3709 (* 1 = 1.3709 loss)
I1029 14:27:26.428820 12802 sgd_solver.cpp:105] Iteration 84120, lr = 5.14974e-06
I1029 14:27:56.736454 12802 solver.cpp:222] Iteration 84160 (1.31983 iter/s, 30.3069s/40 iters), loss = 1.12397
I1029 14:27:56.736644 12802 solver.cpp:241]     Train net output #0: loss = 1.12397 (* 1 = 1.12397 loss)
I1029 14:27:56.736660 12802 sgd_solver.cpp:105] Iteration 84160, lr = 5.13123e-06
I1029 14:28:26.506264 12802 solver.cpp:222] Iteration 84200 (1.34368 iter/s, 29.7689s/40 iters), loss = 1.3107
I1029 14:28:26.506325 12802 solver.cpp:241]     Train net output #0: loss = 1.3107 (* 1 = 1.3107 loss)
I1029 14:28:26.506340 12802 sgd_solver.cpp:105] Iteration 84200, lr = 5.11279e-06
I1029 14:28:56.223306 12802 solver.cpp:222] Iteration 84240 (1.34606 iter/s, 29.7163s/40 iters), loss = 1.38175
I1029 14:28:56.223500 12802 solver.cpp:241]     Train net output #0: loss = 1.38175 (* 1 = 1.38175 loss)
I1029 14:28:56.223515 12802 sgd_solver.cpp:105] Iteration 84240, lr = 5.09442e-06
I1029 14:29:25.813787 12802 solver.cpp:222] Iteration 84280 (1.35183 iter/s, 29.5896s/40 iters), loss = 1.13049
I1029 14:29:25.813844 12802 solver.cpp:241]     Train net output #0: loss = 1.13049 (* 1 = 1.13049 loss)
I1029 14:29:25.813859 12802 sgd_solver.cpp:105] Iteration 84280, lr = 5.07611e-06
I1029 14:29:55.461345 12802 solver.cpp:222] Iteration 84320 (1.34922 iter/s, 29.6468s/40 iters), loss = 1.62172
I1029 14:29:55.461563 12802 solver.cpp:241]     Train net output #0: loss = 1.62172 (* 1 = 1.62172 loss)
I1029 14:29:55.461581 12802 sgd_solver.cpp:105] Iteration 84320, lr = 5.05787e-06
I1029 14:30:33.093904 12802 solver.cpp:222] Iteration 84360 (1.06294 iter/s, 37.6315s/40 iters), loss = 1.3415
I1029 14:30:33.094092 12802 solver.cpp:241]     Train net output #0: loss = 1.3415 (* 1 = 1.3415 loss)
I1029 14:30:33.094110 12802 sgd_solver.cpp:105] Iteration 84360, lr = 5.03969e-06
I1029 14:31:02.746037 12802 solver.cpp:222] Iteration 84400 (1.34902 iter/s, 29.6512s/40 iters), loss = 1.45722
I1029 14:31:02.746101 12802 solver.cpp:241]     Train net output #0: loss = 1.45722 (* 1 = 1.45722 loss)
I1029 14:31:02.746117 12802 sgd_solver.cpp:105] Iteration 84400, lr = 5.02158e-06
I1029 14:31:32.296855 12802 solver.cpp:222] Iteration 84440 (1.35364 iter/s, 29.5501s/40 iters), loss = 1.55733
I1029 14:31:32.297008 12802 solver.cpp:241]     Train net output #0: loss = 1.55733 (* 1 = 1.55733 loss)
I1029 14:31:32.297024 12802 sgd_solver.cpp:105] Iteration 84440, lr = 5.00353e-06
I1029 14:32:01.913796 12802 solver.cpp:222] Iteration 84480 (1.35062 iter/s, 29.6161s/40 iters), loss = 1.77028
I1029 14:32:01.913852 12802 solver.cpp:241]     Train net output #0: loss = 1.77028 (* 1 = 1.77028 loss)
I1029 14:32:01.913868 12802 sgd_solver.cpp:105] Iteration 84480, lr = 4.98555e-06
I1029 14:32:15.895066 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_84500.caffemodel
I1029 14:32:16.036362 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_84500.solverstate
I1029 14:32:16.162528 12802 solver.cpp:334] Iteration 84500, Testing net (#0)
I1029 14:32:47.001631 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 14:32:47.209179 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58528
I1029 14:32:47.209233 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.815
I1029 14:32:47.209244 12802 solver.cpp:401]     Test net output #2: loss = 1.83349 (* 1 = 1.83349 loss)
I1029 14:33:02.880736 12802 solver.cpp:222] Iteration 84520 (0.656109 iter/s, 60.9654s/40 iters), loss = 1.2883
I1029 14:33:02.880800 12802 solver.cpp:241]     Train net output #0: loss = 1.2883 (* 1 = 1.2883 loss)
I1029 14:33:02.880816 12802 sgd_solver.cpp:105] Iteration 84520, lr = 4.96763e-06
I1029 14:33:32.279003 12802 solver.cpp:222] Iteration 84560 (1.36066 iter/s, 29.3975s/40 iters), loss = 1.3265
I1029 14:33:32.279170 12802 solver.cpp:241]     Train net output #0: loss = 1.3265 (* 1 = 1.3265 loss)
I1029 14:33:32.279187 12802 sgd_solver.cpp:105] Iteration 84560, lr = 4.94978e-06
I1029 14:34:12.263695 12802 solver.cpp:222] Iteration 84600 (1.00041 iter/s, 39.9836s/40 iters), loss = 1.86528
I1029 14:34:12.263877 12802 solver.cpp:241]     Train net output #0: loss = 1.86528 (* 1 = 1.86528 loss)
I1029 14:34:12.263895 12802 sgd_solver.cpp:105] Iteration 84600, lr = 4.93199e-06
I1029 14:34:43.459440 12802 solver.cpp:222] Iteration 84640 (1.28226 iter/s, 31.1948s/40 iters), loss = 1.33885
I1029 14:34:43.459656 12802 solver.cpp:241]     Train net output #0: loss = 1.33885 (* 1 = 1.33885 loss)
I1029 14:34:43.459678 12802 sgd_solver.cpp:105] Iteration 84640, lr = 4.91427e-06
I1029 14:35:13.209527 12802 solver.cpp:222] Iteration 84680 (1.34458 iter/s, 29.7492s/40 iters), loss = 1.62755
I1029 14:35:13.209590 12802 solver.cpp:241]     Train net output #0: loss = 1.62755 (* 1 = 1.62755 loss)
I1029 14:35:13.209605 12802 sgd_solver.cpp:105] Iteration 84680, lr = 4.89661e-06
I1029 14:35:57.497965 12802 solver.cpp:222] Iteration 84720 (0.903193 iter/s, 44.2873s/40 iters), loss = 1.55001
I1029 14:35:57.498127 12802 solver.cpp:241]     Train net output #0: loss = 1.55001 (* 1 = 1.55001 loss)
I1029 14:35:57.498144 12802 sgd_solver.cpp:105] Iteration 84720, lr = 4.87901e-06
I1029 14:36:27.714557 12802 solver.cpp:222] Iteration 84760 (1.32381 iter/s, 30.2157s/40 iters), loss = 1.53782
I1029 14:36:27.714767 12802 solver.cpp:241]     Train net output #0: loss = 1.53782 (* 1 = 1.53782 loss)
I1029 14:36:27.714785 12802 sgd_solver.cpp:105] Iteration 84760, lr = 4.86147e-06
I1029 14:37:14.647135 12802 solver.cpp:222] Iteration 84800 (0.85231 iter/s, 46.9313s/40 iters), loss = 1.40606
I1029 14:37:14.647320 12802 solver.cpp:241]     Train net output #0: loss = 1.40606 (* 1 = 1.40606 loss)
I1029 14:37:14.647338 12802 sgd_solver.cpp:105] Iteration 84800, lr = 4.844e-06
I1029 14:37:44.963842 12802 solver.cpp:222] Iteration 84840 (1.31944 iter/s, 30.3158s/40 iters), loss = 1.41243
I1029 14:37:44.963980 12802 solver.cpp:241]     Train net output #0: loss = 1.41243 (* 1 = 1.41243 loss)
I1029 14:37:44.963997 12802 sgd_solver.cpp:105] Iteration 84840, lr = 4.82659e-06
I1029 14:38:15.062052 12802 solver.cpp:222] Iteration 84880 (1.32902 iter/s, 30.0974s/40 iters), loss = 1.00414
I1029 14:38:15.062242 12802 solver.cpp:241]     Train net output #0: loss = 1.00414 (* 1 = 1.00414 loss)
I1029 14:38:15.062258 12802 sgd_solver.cpp:105] Iteration 84880, lr = 4.80925e-06
I1029 14:38:44.692255 12802 solver.cpp:222] Iteration 84920 (1.35001 iter/s, 29.6293s/40 iters), loss = 1.4156
I1029 14:38:44.692314 12802 solver.cpp:241]     Train net output #0: loss = 1.4156 (* 1 = 1.4156 loss)
I1029 14:38:44.692330 12802 sgd_solver.cpp:105] Iteration 84920, lr = 4.79196e-06
I1029 14:39:14.178853 12802 solver.cpp:222] Iteration 84960 (1.35658 iter/s, 29.4858s/40 iters), loss = 1.44997
I1029 14:39:14.179047 12802 solver.cpp:241]     Train net output #0: loss = 1.44997 (* 1 = 1.44997 loss)
I1029 14:39:14.179064 12802 sgd_solver.cpp:105] Iteration 84960, lr = 4.77474e-06
I1029 14:39:43.031952 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_85000.caffemodel
I1029 14:39:43.175230 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_85000.solverstate
I1029 14:39:43.301954 12802 solver.cpp:334] Iteration 85000, Testing net (#0)
I1029 14:40:14.506801 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58944
I1029 14:40:14.507115 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80988
I1029 14:40:14.507129 12802 solver.cpp:401]     Test net output #2: loss = 1.82854 (* 1 = 1.82854 loss)
I1029 14:40:15.275104 12802 solver.cpp:222] Iteration 85000 (0.654722 iter/s, 61.0946s/40 iters), loss = 1.31701
I1029 14:40:15.275166 12802 solver.cpp:241]     Train net output #0: loss = 1.31701 (* 1 = 1.31701 loss)
I1029 14:40:15.275182 12802 sgd_solver.cpp:105] Iteration 85000, lr = 4.75758e-06
I1029 14:40:58.043364 12802 solver.cpp:222] Iteration 85040 (0.935297 iter/s, 42.7672s/40 iters), loss = 1.30664
I1029 14:40:58.043550 12802 solver.cpp:241]     Train net output #0: loss = 1.30664 (* 1 = 1.30664 loss)
I1029 14:40:58.043567 12802 sgd_solver.cpp:105] Iteration 85040, lr = 4.74049e-06
I1029 14:41:28.537071 12802 solver.cpp:222] Iteration 85080 (1.31179 iter/s, 30.4928s/40 iters), loss = 1.50772
I1029 14:41:28.537205 12802 solver.cpp:241]     Train net output #0: loss = 1.50772 (* 1 = 1.50772 loss)
I1029 14:41:28.537222 12802 sgd_solver.cpp:105] Iteration 85080, lr = 4.72345e-06
I1029 14:41:59.049316 12802 solver.cpp:222] Iteration 85120 (1.31099 iter/s, 30.5114s/40 iters), loss = 1.29185
I1029 14:41:59.049399 12802 solver.cpp:241]     Train net output #0: loss = 1.29185 (* 1 = 1.29185 loss)
I1029 14:41:59.049415 12802 sgd_solver.cpp:105] Iteration 85120, lr = 4.70647e-06
I1029 14:42:29.592108 12802 solver.cpp:222] Iteration 85160 (1.30967 iter/s, 30.542s/40 iters), loss = 1.31783
I1029 14:42:29.592269 12802 solver.cpp:241]     Train net output #0: loss = 1.31783 (* 1 = 1.31783 loss)
I1029 14:42:29.592286 12802 sgd_solver.cpp:105] Iteration 85160, lr = 4.68956e-06
I1029 14:42:59.492444 12802 solver.cpp:222] Iteration 85200 (1.33782 iter/s, 29.8995s/40 iters), loss = 1.37977
I1029 14:42:59.492501 12802 solver.cpp:241]     Train net output #0: loss = 1.37977 (* 1 = 1.37977 loss)
I1029 14:42:59.492516 12802 sgd_solver.cpp:105] Iteration 85200, lr = 4.67271e-06
I1029 14:43:28.926738 12802 solver.cpp:222] Iteration 85240 (1.35899 iter/s, 29.4336s/40 iters), loss = 1.20629
I1029 14:43:28.926863 12802 solver.cpp:241]     Train net output #0: loss = 1.20629 (* 1 = 1.20629 loss)
I1029 14:43:28.926900 12802 sgd_solver.cpp:105] Iteration 85240, lr = 4.65591e-06
I1029 14:43:58.343363 12802 solver.cpp:222] Iteration 85280 (1.35981 iter/s, 29.4158s/40 iters), loss = 1.31243
I1029 14:43:58.343405 12802 solver.cpp:241]     Train net output #0: loss = 1.31243 (* 1 = 1.31243 loss)
I1029 14:43:58.343418 12802 sgd_solver.cpp:105] Iteration 85280, lr = 4.63918e-06
I1029 14:44:27.845495 12802 solver.cpp:222] Iteration 85320 (1.35587 iter/s, 29.5014s/40 iters), loss = 1.17354
I1029 14:44:27.845609 12802 solver.cpp:241]     Train net output #0: loss = 1.17354 (* 1 = 1.17354 loss)
I1029 14:44:27.845625 12802 sgd_solver.cpp:105] Iteration 85320, lr = 4.62251e-06
I1029 14:44:57.407598 12802 solver.cpp:222] Iteration 85360 (1.35312 iter/s, 29.5613s/40 iters), loss = 1.53968
I1029 14:44:57.407661 12802 solver.cpp:241]     Train net output #0: loss = 1.53968 (* 1 = 1.53968 loss)
I1029 14:44:57.407675 12802 sgd_solver.cpp:105] Iteration 85360, lr = 4.6059e-06
I1029 14:45:27.167053 12802 solver.cpp:222] Iteration 85400 (1.34415 iter/s, 29.7587s/40 iters), loss = 1.37527
I1029 14:45:27.167234 12802 solver.cpp:241]     Train net output #0: loss = 1.37527 (* 1 = 1.37527 loss)
I1029 14:45:27.167251 12802 sgd_solver.cpp:105] Iteration 85400, lr = 4.58934e-06
I1029 14:45:56.789873 12802 solver.cpp:222] Iteration 85440 (1.35035 iter/s, 29.6219s/40 iters), loss = 1.2417
I1029 14:45:56.789923 12802 solver.cpp:241]     Train net output #0: loss = 1.2417 (* 1 = 1.2417 loss)
I1029 14:45:56.789939 12802 sgd_solver.cpp:105] Iteration 85440, lr = 4.57285e-06
I1029 14:46:27.246846 12802 solver.cpp:222] Iteration 85480 (1.31336 iter/s, 30.4562s/40 iters), loss = 1.53358
I1029 14:46:27.247066 12802 solver.cpp:241]     Train net output #0: loss = 1.53358 (* 1 = 1.53358 loss)
I1029 14:46:27.247084 12802 sgd_solver.cpp:105] Iteration 85480, lr = 4.55642e-06
I1029 14:46:41.722471 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_85500.caffemodel
I1029 14:46:41.895612 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_85500.solverstate
I1029 14:46:42.032325 12802 solver.cpp:334] Iteration 85500, Testing net (#0)
I1029 14:47:12.983700 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 14:47:13.191323 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58548
I1029 14:47:13.191366 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81488
I1029 14:47:13.191378 12802 solver.cpp:401]     Test net output #2: loss = 1.8329 (* 1 = 1.8329 loss)
I1029 14:47:29.265987 12802 solver.cpp:222] Iteration 85520 (0.644979 iter/s, 62.0175s/40 iters), loss = 1.31981
I1029 14:47:29.266050 12802 solver.cpp:241]     Train net output #0: loss = 1.31981 (* 1 = 1.31981 loss)
I1029 14:47:29.266065 12802 sgd_solver.cpp:105] Iteration 85520, lr = 4.54004e-06
I1029 14:48:09.079578 12802 solver.cpp:222] Iteration 85560 (1.00471 iter/s, 39.8126s/40 iters), loss = 1.65893
I1029 14:48:09.079751 12802 solver.cpp:241]     Train net output #0: loss = 1.65893 (* 1 = 1.65893 loss)
I1029 14:48:09.079767 12802 sgd_solver.cpp:105] Iteration 85560, lr = 4.52373e-06
I1029 14:48:38.581174 12802 solver.cpp:222] Iteration 85600 (1.3559 iter/s, 29.5007s/40 iters), loss = 1.50677
I1029 14:48:38.581220 12802 solver.cpp:241]     Train net output #0: loss = 1.50677 (* 1 = 1.50677 loss)
I1029 14:48:38.581233 12802 sgd_solver.cpp:105] Iteration 85600, lr = 4.50747e-06
I1029 14:49:08.044788 12802 solver.cpp:222] Iteration 85640 (1.35764 iter/s, 29.4629s/40 iters), loss = 1.42117
I1029 14:49:08.044952 12802 solver.cpp:241]     Train net output #0: loss = 1.42117 (* 1 = 1.42117 loss)
I1029 14:49:08.044966 12802 sgd_solver.cpp:105] Iteration 85640, lr = 4.49127e-06
I1029 14:49:37.499927 12802 solver.cpp:222] Iteration 85680 (1.35804 iter/s, 29.4543s/40 iters), loss = 1.1991
I1029 14:49:37.499984 12802 solver.cpp:241]     Train net output #0: loss = 1.1991 (* 1 = 1.1991 loss)
I1029 14:49:37.500000 12802 sgd_solver.cpp:105] Iteration 85680, lr = 4.47513e-06
I1029 14:50:06.960003 12802 solver.cpp:222] Iteration 85720 (1.3578 iter/s, 29.4593s/40 iters), loss = 1.09227
I1029 14:50:06.960229 12802 solver.cpp:241]     Train net output #0: loss = 1.09227 (* 1 = 1.09227 loss)
I1029 14:50:06.960247 12802 sgd_solver.cpp:105] Iteration 85720, lr = 4.45905e-06
I1029 14:50:36.433748 12802 solver.cpp:222] Iteration 85760 (1.35718 iter/s, 29.4728s/40 iters), loss = 1.28162
I1029 14:50:36.433801 12802 solver.cpp:241]     Train net output #0: loss = 1.28162 (* 1 = 1.28162 loss)
I1029 14:50:36.433816 12802 sgd_solver.cpp:105] Iteration 85760, lr = 4.44302e-06
I1029 14:51:32.372207 12802 solver.cpp:222] Iteration 85800 (0.715089 iter/s, 55.9371s/40 iters), loss = 1.71521
I1029 14:51:32.372390 12802 solver.cpp:241]     Train net output #0: loss = 1.71521 (* 1 = 1.71521 loss)
I1029 14:51:32.372406 12802 sgd_solver.cpp:105] Iteration 85800, lr = 4.42705e-06
I1029 14:52:03.570147 12802 solver.cpp:222] Iteration 85840 (1.28217 iter/s, 31.197s/40 iters), loss = 1.66222
I1029 14:52:03.570334 12802 solver.cpp:241]     Train net output #0: loss = 1.66222 (* 1 = 1.66222 loss)
I1029 14:52:03.570350 12802 sgd_solver.cpp:105] Iteration 85840, lr = 4.41114e-06
I1029 14:52:35.941236 12802 solver.cpp:222] Iteration 85880 (1.23571 iter/s, 32.3701s/40 iters), loss = 1.30021
I1029 14:52:35.941399 12802 solver.cpp:241]     Train net output #0: loss = 1.30021 (* 1 = 1.30021 loss)
I1029 14:52:35.941416 12802 sgd_solver.cpp:105] Iteration 85880, lr = 4.39529e-06
I1029 14:53:06.283815 12802 solver.cpp:222] Iteration 85920 (1.31832 iter/s, 30.3417s/40 iters), loss = 1.72091
I1029 14:53:06.284124 12802 solver.cpp:241]     Train net output #0: loss = 1.72091 (* 1 = 1.72091 loss)
I1029 14:53:06.284157 12802 sgd_solver.cpp:105] Iteration 85920, lr = 4.37949e-06
I1029 14:53:39.303354 12802 solver.cpp:222] Iteration 85960 (1.21144 iter/s, 33.0185s/40 iters), loss = 1.70219
I1029 14:53:39.303540 12802 solver.cpp:241]     Train net output #0: loss = 1.70219 (* 1 = 1.70219 loss)
I1029 14:53:39.303555 12802 sgd_solver.cpp:105] Iteration 85960, lr = 4.36376e-06
I1029 14:54:46.781380 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_86000.caffemodel
I1029 14:54:46.920949 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_86000.solverstate
I1029 14:54:47.040869 12802 solver.cpp:334] Iteration 86000, Testing net (#0)
I1029 14:55:18.094159 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58952
I1029 14:55:18.094326 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80956
I1029 14:55:18.094341 12802 solver.cpp:401]     Test net output #2: loss = 1.82751 (* 1 = 1.82751 loss)
I1029 14:55:18.862764 12802 solver.cpp:222] Iteration 86000 (0.40178 iter/s, 99.557s/40 iters), loss = 1.53989
I1029 14:55:18.862821 12802 solver.cpp:241]     Train net output #0: loss = 1.53989 (* 1 = 1.53989 loss)
I1029 14:55:18.862835 12802 sgd_solver.cpp:105] Iteration 86000, lr = 4.34807e-06
I1029 14:55:56.326025 12802 solver.cpp:222] Iteration 86040 (1.06774 iter/s, 37.4623s/40 iters), loss = 1.38149
I1029 14:55:56.326186 12802 solver.cpp:241]     Train net output #0: loss = 1.38149 (* 1 = 1.38149 loss)
I1029 14:55:56.326203 12802 sgd_solver.cpp:105] Iteration 86040, lr = 4.33245e-06
I1029 14:56:26.739610 12802 solver.cpp:222] Iteration 86080 (1.31524 iter/s, 30.4127s/40 iters), loss = 1.24773
I1029 14:56:26.739748 12802 solver.cpp:241]     Train net output #0: loss = 1.24773 (* 1 = 1.24773 loss)
I1029 14:56:26.739761 12802 sgd_solver.cpp:105] Iteration 86080, lr = 4.31688e-06
I1029 14:56:57.641691 12802 solver.cpp:222] Iteration 86120 (1.29445 iter/s, 30.9012s/40 iters), loss = 1.31197
I1029 14:56:57.642060 12802 solver.cpp:241]     Train net output #0: loss = 1.31197 (* 1 = 1.31197 loss)
I1029 14:56:57.642112 12802 sgd_solver.cpp:105] Iteration 86120, lr = 4.30136e-06
I1029 14:58:13.714948 12802 solver.cpp:222] Iteration 86160 (0.525823 iter/s, 76.0712s/40 iters), loss = 1.213
I1029 14:58:13.715128 12802 solver.cpp:241]     Train net output #0: loss = 1.213 (* 1 = 1.213 loss)
I1029 14:58:13.715145 12802 sgd_solver.cpp:105] Iteration 86160, lr = 4.28591e-06
I1029 14:58:13.827461 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 14:58:44.009718 12802 solver.cpp:222] Iteration 86200 (1.3204 iter/s, 30.2939s/40 iters), loss = 1.15733
I1029 14:58:44.009917 12802 solver.cpp:241]     Train net output #0: loss = 1.15733 (* 1 = 1.15733 loss)
I1029 14:58:44.009940 12802 sgd_solver.cpp:105] Iteration 86200, lr = 4.2705e-06
I1029 14:59:13.715431 12802 solver.cpp:222] Iteration 86240 (1.34658 iter/s, 29.7048s/40 iters), loss = 1.26452
I1029 14:59:13.715497 12802 solver.cpp:241]     Train net output #0: loss = 1.26452 (* 1 = 1.26452 loss)
I1029 14:59:13.715512 12802 sgd_solver.cpp:105] Iteration 86240, lr = 4.25515e-06
I1029 14:59:43.210845 12802 solver.cpp:222] Iteration 86280 (1.35618 iter/s, 29.4947s/40 iters), loss = 1.40161
I1029 14:59:43.211076 12802 solver.cpp:241]     Train net output #0: loss = 1.40161 (* 1 = 1.40161 loss)
I1029 14:59:43.211092 12802 sgd_solver.cpp:105] Iteration 86280, lr = 4.23986e-06
I1029 15:00:12.792948 12802 solver.cpp:222] Iteration 86320 (1.35221 iter/s, 29.5812s/40 iters), loss = 1.42663
I1029 15:00:12.793007 12802 solver.cpp:241]     Train net output #0: loss = 1.42663 (* 1 = 1.42663 loss)
I1029 15:00:12.793023 12802 sgd_solver.cpp:105] Iteration 86320, lr = 4.22463e-06
I1029 15:00:42.363369 12802 solver.cpp:222] Iteration 86360 (1.35274 iter/s, 29.5697s/40 iters), loss = 1.48782
I1029 15:00:42.363569 12802 solver.cpp:241]     Train net output #0: loss = 1.48782 (* 1 = 1.48782 loss)
I1029 15:00:42.363585 12802 sgd_solver.cpp:105] Iteration 86360, lr = 4.20944e-06
I1029 15:01:11.861896 12802 solver.cpp:222] Iteration 86400 (1.35604 iter/s, 29.4976s/40 iters), loss = 1.25861
I1029 15:01:11.861958 12802 solver.cpp:241]     Train net output #0: loss = 1.25861 (* 1 = 1.25861 loss)
I1029 15:01:11.861971 12802 sgd_solver.cpp:105] Iteration 86400, lr = 4.19431e-06
I1029 15:01:49.551692 12802 solver.cpp:222] Iteration 86440 (1.06132 iter/s, 37.6888s/40 iters), loss = 1.24774
I1029 15:01:49.551882 12802 solver.cpp:241]     Train net output #0: loss = 1.24774 (* 1 = 1.24774 loss)
I1029 15:01:49.551899 12802 sgd_solver.cpp:105] Iteration 86440, lr = 4.17924e-06
I1029 15:02:19.894587 12802 solver.cpp:222] Iteration 86480 (1.31831 iter/s, 30.342s/40 iters), loss = 1.24477
I1029 15:02:19.894788 12802 solver.cpp:241]     Train net output #0: loss = 1.24477 (* 1 = 1.24477 loss)
I1029 15:02:19.894809 12802 sgd_solver.cpp:105] Iteration 86480, lr = 4.16422e-06
I1029 15:02:34.336307 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_86500.caffemodel
I1029 15:02:34.494284 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_86500.solverstate
I1029 15:02:34.608742 12802 solver.cpp:334] Iteration 86500, Testing net (#0)
I1029 15:03:05.468875 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 15:03:05.676442 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5852
I1029 15:03:05.676496 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8156
I1029 15:03:05.676507 12802 solver.cpp:401]     Test net output #2: loss = 1.83501 (* 1 = 1.83501 loss)
I1029 15:03:21.262683 12802 solver.cpp:222] Iteration 86520 (0.651822 iter/s, 61.3665s/40 iters), loss = 1.16489
I1029 15:03:21.262748 12802 solver.cpp:241]     Train net output #0: loss = 1.16489 (* 1 = 1.16489 loss)
I1029 15:03:21.262763 12802 sgd_solver.cpp:105] Iteration 86520, lr = 4.14926e-06
I1029 15:03:50.838416 12802 solver.cpp:222] Iteration 86560 (1.3525 iter/s, 29.575s/40 iters), loss = 1.25023
I1029 15:03:50.838635 12802 solver.cpp:241]     Train net output #0: loss = 1.25023 (* 1 = 1.25023 loss)
I1029 15:03:50.838654 12802 sgd_solver.cpp:105] Iteration 86560, lr = 4.13435e-06
I1029 15:04:20.403201 12802 solver.cpp:222] Iteration 86600 (1.353 iter/s, 29.5639s/40 iters), loss = 1.42279
I1029 15:04:20.403259 12802 solver.cpp:241]     Train net output #0: loss = 1.42279 (* 1 = 1.42279 loss)
I1029 15:04:20.403271 12802 sgd_solver.cpp:105] Iteration 86600, lr = 4.11949e-06
I1029 15:04:49.906167 12802 solver.cpp:222] Iteration 86640 (1.35583 iter/s, 29.5022s/40 iters), loss = 1.3523
I1029 15:04:49.906276 12802 solver.cpp:241]     Train net output #0: loss = 1.3523 (* 1 = 1.3523 loss)
I1029 15:04:49.906293 12802 sgd_solver.cpp:105] Iteration 86640, lr = 4.10468e-06
I1029 15:05:19.390066 12802 solver.cpp:222] Iteration 86680 (1.35671 iter/s, 29.4831s/40 iters), loss = 1.42347
I1029 15:05:19.390125 12802 solver.cpp:241]     Train net output #0: loss = 1.42347 (* 1 = 1.42347 loss)
I1029 15:05:19.390139 12802 sgd_solver.cpp:105] Iteration 86680, lr = 4.08993e-06
I1029 15:05:48.832186 12802 solver.cpp:222] Iteration 86720 (1.35863 iter/s, 29.4414s/40 iters), loss = 1.20283
I1029 15:05:48.832346 12802 solver.cpp:241]     Train net output #0: loss = 1.20283 (* 1 = 1.20283 loss)
I1029 15:05:48.832361 12802 sgd_solver.cpp:105] Iteration 86720, lr = 4.07523e-06
I1029 15:06:18.496148 12802 solver.cpp:222] Iteration 86760 (1.34848 iter/s, 29.6631s/40 iters), loss = 1.36843
I1029 15:06:18.496206 12802 solver.cpp:241]     Train net output #0: loss = 1.36843 (* 1 = 1.36843 loss)
I1029 15:06:18.496220 12802 sgd_solver.cpp:105] Iteration 86760, lr = 4.06059e-06
I1029 15:06:48.531752 12802 solver.cpp:222] Iteration 86800 (1.33179 iter/s, 30.0348s/40 iters), loss = 1.43901
I1029 15:06:48.531927 12802 solver.cpp:241]     Train net output #0: loss = 1.43901 (* 1 = 1.43901 loss)
I1029 15:06:48.531949 12802 sgd_solver.cpp:105] Iteration 86800, lr = 4.04599e-06
I1029 15:07:18.845515 12802 solver.cpp:222] Iteration 86840 (1.31957 iter/s, 30.3129s/40 iters), loss = 1.31508
I1029 15:07:18.845715 12802 solver.cpp:241]     Train net output #0: loss = 1.31508 (* 1 = 1.31508 loss)
I1029 15:07:18.845732 12802 sgd_solver.cpp:105] Iteration 86840, lr = 4.03145e-06
I1029 15:07:56.601316 12802 solver.cpp:222] Iteration 86880 (1.05947 iter/s, 37.7547s/40 iters), loss = 1.51159
I1029 15:07:56.601501 12802 solver.cpp:241]     Train net output #0: loss = 1.51159 (* 1 = 1.51159 loss)
I1029 15:07:56.601519 12802 sgd_solver.cpp:105] Iteration 86880, lr = 4.01696e-06
I1029 15:08:26.484431 12802 solver.cpp:222] Iteration 86920 (1.33859 iter/s, 29.8822s/40 iters), loss = 1.32001
I1029 15:08:26.484489 12802 solver.cpp:241]     Train net output #0: loss = 1.32001 (* 1 = 1.32001 loss)
I1029 15:08:26.484505 12802 sgd_solver.cpp:105] Iteration 86920, lr = 4.00253e-06
I1029 15:08:56.868706 12802 solver.cpp:222] Iteration 86960 (1.3165 iter/s, 30.3835s/40 iters), loss = 1.42908
I1029 15:08:56.868916 12802 solver.cpp:241]     Train net output #0: loss = 1.42908 (* 1 = 1.42908 loss)
I1029 15:08:56.868948 12802 sgd_solver.cpp:105] Iteration 86960, lr = 3.98814e-06
I1029 15:09:26.210984 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_87000.caffemodel
I1029 15:09:26.357204 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_87000.solverstate
I1029 15:09:26.472216 12802 solver.cpp:334] Iteration 87000, Testing net (#0)
I1029 15:09:57.616313 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5894
I1029 15:09:57.616467 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80972
I1029 15:09:57.616480 12802 solver.cpp:401]     Test net output #2: loss = 1.82944 (* 1 = 1.82944 loss)
I1029 15:09:58.384713 12802 solver.cpp:222] Iteration 87000 (0.650255 iter/s, 61.5144s/40 iters), loss = 1.53326
I1029 15:09:58.384768 12802 solver.cpp:241]     Train net output #0: loss = 1.53326 (* 1 = 1.53326 loss)
I1029 15:09:58.384783 12802 sgd_solver.cpp:105] Iteration 87000, lr = 3.97381e-06
I1029 15:10:28.762204 12802 solver.cpp:222] Iteration 87040 (1.3168 iter/s, 30.3767s/40 iters), loss = 1.20849
I1029 15:10:28.762431 12802 solver.cpp:241]     Train net output #0: loss = 1.20849 (* 1 = 1.20849 loss)
I1029 15:10:28.762449 12802 sgd_solver.cpp:105] Iteration 87040, lr = 3.95953e-06
I1029 15:10:58.546452 12802 solver.cpp:222] Iteration 87080 (1.34303 iter/s, 29.7833s/40 iters), loss = 1.11233
I1029 15:10:58.546517 12802 solver.cpp:241]     Train net output #0: loss = 1.11233 (* 1 = 1.11233 loss)
I1029 15:10:58.546533 12802 sgd_solver.cpp:105] Iteration 87080, lr = 3.9453e-06
I1029 15:11:28.789866 12802 solver.cpp:222] Iteration 87120 (1.32264 iter/s, 30.2426s/40 iters), loss = 1.30231
I1029 15:11:28.790038 12802 solver.cpp:241]     Train net output #0: loss = 1.30231 (* 1 = 1.30231 loss)
I1029 15:11:28.790057 12802 sgd_solver.cpp:105] Iteration 87120, lr = 3.93112e-06
I1029 15:11:59.370440 12802 solver.cpp:222] Iteration 87160 (1.30806 iter/s, 30.5797s/40 iters), loss = 1.47114
I1029 15:11:59.370625 12802 solver.cpp:241]     Train net output #0: loss = 1.47114 (* 1 = 1.47114 loss)
I1029 15:11:59.370641 12802 sgd_solver.cpp:105] Iteration 87160, lr = 3.91699e-06
I1029 15:12:29.276888 12802 solver.cpp:222] Iteration 87200 (1.33754 iter/s, 29.9056s/40 iters), loss = 1.28905
I1029 15:12:29.276954 12802 solver.cpp:241]     Train net output #0: loss = 1.28905 (* 1 = 1.28905 loss)
I1029 15:12:29.276970 12802 sgd_solver.cpp:105] Iteration 87200, lr = 3.90292e-06
I1029 15:12:58.963379 12802 solver.cpp:222] Iteration 87240 (1.34745 iter/s, 29.6857s/40 iters), loss = 1.39229
I1029 15:12:58.963572 12802 solver.cpp:241]     Train net output #0: loss = 1.39229 (* 1 = 1.39229 loss)
I1029 15:12:58.963587 12802 sgd_solver.cpp:105] Iteration 87240, lr = 3.88889e-06
I1029 15:13:29.101378 12802 solver.cpp:222] Iteration 87280 (1.32727 iter/s, 30.1371s/40 iters), loss = 1.62274
I1029 15:13:29.101575 12802 solver.cpp:241]     Train net output #0: loss = 1.62274 (* 1 = 1.62274 loss)
I1029 15:13:29.101593 12802 sgd_solver.cpp:105] Iteration 87280, lr = 3.87492e-06
I1029 15:13:58.837163 12802 solver.cpp:222] Iteration 87320 (1.34522 iter/s, 29.7349s/40 iters), loss = 1.42076
I1029 15:13:58.837220 12802 solver.cpp:241]     Train net output #0: loss = 1.42076 (* 1 = 1.42076 loss)
I1029 15:13:58.837236 12802 sgd_solver.cpp:105] Iteration 87320, lr = 3.86099e-06
I1029 15:14:28.548380 12802 solver.cpp:222] Iteration 87360 (1.34633 iter/s, 29.7105s/40 iters), loss = 1.17248
I1029 15:14:28.548581 12802 solver.cpp:241]     Train net output #0: loss = 1.17248 (* 1 = 1.17248 loss)
I1029 15:14:28.548597 12802 sgd_solver.cpp:105] Iteration 87360, lr = 3.84711e-06
I1029 15:14:59.038475 12802 solver.cpp:222] Iteration 87400 (1.31194 iter/s, 30.4892s/40 iters), loss = 1.07132
I1029 15:14:59.038642 12802 solver.cpp:241]     Train net output #0: loss = 1.07132 (* 1 = 1.07132 loss)
I1029 15:14:59.038656 12802 sgd_solver.cpp:105] Iteration 87400, lr = 3.83329e-06
I1029 15:15:32.370267 12802 solver.cpp:222] Iteration 87440 (1.20009 iter/s, 33.3308s/40 iters), loss = 1.3816
I1029 15:15:32.370434 12802 solver.cpp:241]     Train net output #0: loss = 1.3816 (* 1 = 1.3816 loss)
I1029 15:15:32.370451 12802 sgd_solver.cpp:105] Iteration 87440, lr = 3.81951e-06
I1029 15:16:02.678717 12802 solver.cpp:222] Iteration 87480 (1.3198 iter/s, 30.3076s/40 iters), loss = 1.66842
I1029 15:16:02.678937 12802 solver.cpp:241]     Train net output #0: loss = 1.66842 (* 1 = 1.66842 loss)
I1029 15:16:02.678956 12802 sgd_solver.cpp:105] Iteration 87480, lr = 3.80579e-06
I1029 15:16:16.829201 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_87500.caffemodel
I1029 15:16:16.971282 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_87500.solverstate
I1029 15:16:17.093587 12802 solver.cpp:334] Iteration 87500, Testing net (#0)
I1029 15:16:48.056252 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 15:16:48.265924 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58536
I1029 15:16:48.265974 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.815399
I1029 15:16:48.265986 12802 solver.cpp:401]     Test net output #2: loss = 1.83325 (* 1 = 1.83325 loss)
I1029 15:17:04.234894 12802 solver.cpp:222] Iteration 87520 (0.64983 iter/s, 61.5545s/40 iters), loss = 1.46334
I1029 15:17:04.234952 12802 solver.cpp:241]     Train net output #0: loss = 1.46334 (* 1 = 1.46334 loss)
I1029 15:17:04.234968 12802 sgd_solver.cpp:105] Iteration 87520, lr = 3.79211e-06
I1029 15:17:34.271740 12802 solver.cpp:222] Iteration 87560 (1.33173 iter/s, 30.0361s/40 iters), loss = 1.52767
I1029 15:17:34.271945 12802 solver.cpp:241]     Train net output #0: loss = 1.52767 (* 1 = 1.52767 loss)
I1029 15:17:34.271963 12802 sgd_solver.cpp:105] Iteration 87560, lr = 3.77848e-06
I1029 15:18:04.660404 12802 solver.cpp:222] Iteration 87600 (1.31632 iter/s, 30.3877s/40 iters), loss = 1.46361
I1029 15:18:04.660547 12802 solver.cpp:241]     Train net output #0: loss = 1.46361 (* 1 = 1.46361 loss)
I1029 15:18:04.660565 12802 sgd_solver.cpp:105] Iteration 87600, lr = 3.7649e-06
I1029 15:18:34.963758 12802 solver.cpp:222] Iteration 87640 (1.32002 iter/s, 30.3025s/40 iters), loss = 1.40858
I1029 15:18:34.963894 12802 solver.cpp:241]     Train net output #0: loss = 1.40858 (* 1 = 1.40858 loss)
I1029 15:18:34.963912 12802 sgd_solver.cpp:105] Iteration 87640, lr = 3.75137e-06
I1029 15:19:05.376662 12802 solver.cpp:222] Iteration 87680 (1.31527 iter/s, 30.412s/40 iters), loss = 1.66227
I1029 15:19:05.376806 12802 solver.cpp:241]     Train net output #0: loss = 1.66227 (* 1 = 1.66227 loss)
I1029 15:19:05.376821 12802 sgd_solver.cpp:105] Iteration 87680, lr = 3.73789e-06
I1029 15:19:35.498724 12802 solver.cpp:222] Iteration 87720 (1.32797 iter/s, 30.1212s/40 iters), loss = 1.72676
I1029 15:19:35.498883 12802 solver.cpp:241]     Train net output #0: loss = 1.72676 (* 1 = 1.72676 loss)
I1029 15:19:35.498899 12802 sgd_solver.cpp:105] Iteration 87720, lr = 3.72446e-06
I1029 15:20:06.167605 12802 solver.cpp:222] Iteration 87760 (1.30429 iter/s, 30.668s/40 iters), loss = 1.21896
I1029 15:20:06.167783 12802 solver.cpp:241]     Train net output #0: loss = 1.21896 (* 1 = 1.21896 loss)
I1029 15:20:06.167800 12802 sgd_solver.cpp:105] Iteration 87760, lr = 3.71107e-06
I1029 15:20:36.371927 12802 solver.cpp:222] Iteration 87800 (1.32435 iter/s, 30.2034s/40 iters), loss = 1.75886
I1029 15:20:36.372099 12802 solver.cpp:241]     Train net output #0: loss = 1.75886 (* 1 = 1.75886 loss)
I1029 15:20:36.372117 12802 sgd_solver.cpp:105] Iteration 87800, lr = 3.69773e-06
I1029 15:21:06.695402 12802 solver.cpp:222] Iteration 87840 (1.31915 iter/s, 30.3226s/40 iters), loss = 1.37377
I1029 15:21:06.695533 12802 solver.cpp:241]     Train net output #0: loss = 1.37377 (* 1 = 1.37377 loss)
I1029 15:21:06.695547 12802 sgd_solver.cpp:105] Iteration 87840, lr = 3.68444e-06
I1029 15:21:36.459643 12802 solver.cpp:222] Iteration 87880 (1.34393 iter/s, 29.7634s/40 iters), loss = 1.77848
I1029 15:21:36.459702 12802 solver.cpp:241]     Train net output #0: loss = 1.77848 (* 1 = 1.77848 loss)
I1029 15:21:36.459715 12802 sgd_solver.cpp:105] Iteration 87880, lr = 3.6712e-06
I1029 15:22:06.355967 12802 solver.cpp:222] Iteration 87920 (1.33799 iter/s, 29.8956s/40 iters), loss = 1.54464
I1029 15:22:06.356142 12802 solver.cpp:241]     Train net output #0: loss = 1.54464 (* 1 = 1.54464 loss)
I1029 15:22:06.356159 12802 sgd_solver.cpp:105] Iteration 87920, lr = 3.65801e-06
I1029 15:22:36.219512 12802 solver.cpp:222] Iteration 87960 (1.33947 iter/s, 29.8627s/40 iters), loss = 1.40282
I1029 15:22:36.219578 12802 solver.cpp:241]     Train net output #0: loss = 1.40282 (* 1 = 1.40282 loss)
I1029 15:22:36.219594 12802 sgd_solver.cpp:105] Iteration 87960, lr = 3.64486e-06
I1029 15:23:05.071018 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_88000.caffemodel
I1029 15:23:05.217541 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_88000.solverstate
I1029 15:23:05.340735 12802 solver.cpp:334] Iteration 88000, Testing net (#0)
I1029 15:23:36.508221 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58972
I1029 15:23:36.508368 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80976
I1029 15:23:36.508383 12802 solver.cpp:401]     Test net output #2: loss = 1.82817 (* 1 = 1.82817 loss)
I1029 15:23:37.282850 12802 solver.cpp:222] Iteration 88000 (0.655073 iter/s, 61.0619s/40 iters), loss = 1.62369
I1029 15:23:37.282891 12802 solver.cpp:241]     Train net output #0: loss = 1.62369 (* 1 = 1.62369 loss)
I1029 15:23:37.282912 12802 sgd_solver.cpp:105] Iteration 88000, lr = 3.63176e-06
I1029 15:24:06.926856 12802 solver.cpp:222] Iteration 88040 (1.34938 iter/s, 29.6433s/40 iters), loss = 1.3122
I1029 15:24:06.927011 12802 solver.cpp:241]     Train net output #0: loss = 1.3122 (* 1 = 1.3122 loss)
I1029 15:24:06.927028 12802 sgd_solver.cpp:105] Iteration 88040, lr = 3.61871e-06
I1029 15:24:37.147107 12802 solver.cpp:222] Iteration 88080 (1.32365 iter/s, 30.2194s/40 iters), loss = 1.10591
I1029 15:24:37.147285 12802 solver.cpp:241]     Train net output #0: loss = 1.10591 (* 1 = 1.10591 loss)
I1029 15:24:37.147300 12802 sgd_solver.cpp:105] Iteration 88080, lr = 3.60571e-06
I1029 15:25:07.538123 12802 solver.cpp:222] Iteration 88120 (1.31622 iter/s, 30.3901s/40 iters), loss = 1.12755
I1029 15:25:07.538314 12802 solver.cpp:241]     Train net output #0: loss = 1.12755 (* 1 = 1.12755 loss)
I1029 15:25:07.538331 12802 sgd_solver.cpp:105] Iteration 88120, lr = 3.59275e-06
I1029 15:25:52.294380 12802 solver.cpp:222] Iteration 88160 (0.893755 iter/s, 44.755s/40 iters), loss = 1.13793
I1029 15:25:52.294571 12802 solver.cpp:241]     Train net output #0: loss = 1.13793 (* 1 = 1.13793 loss)
I1029 15:25:52.294594 12802 sgd_solver.cpp:105] Iteration 88160, lr = 3.57984e-06
I1029 15:26:22.472748 12802 solver.cpp:222] Iteration 88200 (1.32549 iter/s, 30.1775s/40 iters), loss = 1.2835
I1029 15:26:22.472944 12802 solver.cpp:241]     Train net output #0: loss = 1.2835 (* 1 = 1.2835 loss)
I1029 15:26:22.472959 12802 sgd_solver.cpp:105] Iteration 88200, lr = 3.56697e-06
I1029 15:26:52.190753 12802 solver.cpp:222] Iteration 88240 (1.34603 iter/s, 29.7171s/40 iters), loss = 1.34852
I1029 15:26:52.190814 12802 solver.cpp:241]     Train net output #0: loss = 1.34852 (* 1 = 1.34852 loss)
I1029 15:26:52.190826 12802 sgd_solver.cpp:105] Iteration 88240, lr = 3.55415e-06
I1029 15:27:21.988844 12802 solver.cpp:222] Iteration 88280 (1.3424 iter/s, 29.7973s/40 iters), loss = 1.70878
I1029 15:27:21.989033 12802 solver.cpp:241]     Train net output #0: loss = 1.70878 (* 1 = 1.70878 loss)
I1029 15:27:21.989050 12802 sgd_solver.cpp:105] Iteration 88280, lr = 3.54138e-06
I1029 15:27:51.638425 12802 solver.cpp:222] Iteration 88320 (1.34913 iter/s, 29.6487s/40 iters), loss = 1.33172
I1029 15:27:51.638480 12802 solver.cpp:241]     Train net output #0: loss = 1.33172 (* 1 = 1.33172 loss)
I1029 15:27:51.638494 12802 sgd_solver.cpp:105] Iteration 88320, lr = 3.52865e-06
I1029 15:28:21.653491 12802 solver.cpp:222] Iteration 88360 (1.3327 iter/s, 30.0143s/40 iters), loss = 1.6671
I1029 15:28:21.653671 12802 solver.cpp:241]     Train net output #0: loss = 1.6671 (* 1 = 1.6671 loss)
I1029 15:28:21.653687 12802 sgd_solver.cpp:105] Iteration 88360, lr = 3.51597e-06
I1029 15:28:55.850376 12802 solver.cpp:222] Iteration 88400 (1.16973 iter/s, 34.1959s/40 iters), loss = 1.58517
I1029 15:28:55.850571 12802 solver.cpp:241]     Train net output #0: loss = 1.58517 (* 1 = 1.58517 loss)
I1029 15:28:55.850589 12802 sgd_solver.cpp:105] Iteration 88400, lr = 3.50334e-06
I1029 15:29:30.113858 12802 solver.cpp:222] Iteration 88440 (1.16746 iter/s, 34.2625s/40 iters), loss = 1.31044
I1029 15:29:30.114066 12802 solver.cpp:241]     Train net output #0: loss = 1.31044 (* 1 = 1.31044 loss)
I1029 15:29:30.114084 12802 sgd_solver.cpp:105] Iteration 88440, lr = 3.49075e-06
I1029 15:29:59.791004 12802 solver.cpp:222] Iteration 88480 (1.34788 iter/s, 29.6762s/40 iters), loss = 1.42371
I1029 15:29:59.791064 12802 solver.cpp:241]     Train net output #0: loss = 1.42371 (* 1 = 1.42371 loss)
I1029 15:29:59.791080 12802 sgd_solver.cpp:105] Iteration 88480, lr = 3.4782e-06
I1029 15:30:13.881345 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_88500.caffemodel
I1029 15:30:14.023636 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_88500.solverstate
I1029 15:30:14.138063 12802 solver.cpp:334] Iteration 88500, Testing net (#0)
I1029 15:30:45.015581 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 15:30:45.222729 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58584
I1029 15:30:45.222782 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81544
I1029 15:30:45.222792 12802 solver.cpp:401]     Test net output #2: loss = 1.83202 (* 1 = 1.83202 loss)
I1029 15:31:00.975184 12802 solver.cpp:222] Iteration 88520 (0.65378 iter/s, 61.1827s/40 iters), loss = 1.598
I1029 15:31:00.975242 12802 solver.cpp:241]     Train net output #0: loss = 1.598 (* 1 = 1.598 loss)
I1029 15:31:00.975256 12802 sgd_solver.cpp:105] Iteration 88520, lr = 3.4657e-06
I1029 15:31:31.403815 12802 solver.cpp:222] Iteration 88560 (1.31459 iter/s, 30.4278s/40 iters), loss = 1.51565
I1029 15:31:31.404012 12802 solver.cpp:241]     Train net output #0: loss = 1.51565 (* 1 = 1.51565 loss)
I1029 15:31:31.404031 12802 sgd_solver.cpp:105] Iteration 88560, lr = 3.45325e-06
I1029 15:32:03.237556 12802 solver.cpp:222] Iteration 88600 (1.25657 iter/s, 31.8328s/40 iters), loss = 1.34194
I1029 15:32:03.237730 12802 solver.cpp:241]     Train net output #0: loss = 1.34194 (* 1 = 1.34194 loss)
I1029 15:32:03.237747 12802 sgd_solver.cpp:105] Iteration 88600, lr = 3.44084e-06
I1029 15:32:33.038434 12802 solver.cpp:222] Iteration 88640 (1.34228 iter/s, 29.8s/40 iters), loss = 1.48789
I1029 15:32:33.038496 12802 solver.cpp:241]     Train net output #0: loss = 1.48789 (* 1 = 1.48789 loss)
I1029 15:32:33.038513 12802 sgd_solver.cpp:105] Iteration 88640, lr = 3.42847e-06
I1029 15:32:49.307683 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 15:33:02.449064 12802 solver.cpp:222] Iteration 88680 (1.36009 iter/s, 29.4099s/40 iters), loss = 1.15654
I1029 15:33:02.449120 12802 solver.cpp:241]     Train net output #0: loss = 1.15654 (* 1 = 1.15654 loss)
I1029 15:33:02.449133 12802 sgd_solver.cpp:105] Iteration 88680, lr = 3.41615e-06
I1029 15:33:32.826069 12802 solver.cpp:222] Iteration 88720 (1.31682 iter/s, 30.3762s/40 iters), loss = 1.49871
I1029 15:33:32.826205 12802 solver.cpp:241]     Train net output #0: loss = 1.49871 (* 1 = 1.49871 loss)
I1029 15:33:32.826225 12802 sgd_solver.cpp:105] Iteration 88720, lr = 3.40387e-06
I1029 15:34:03.001144 12802 solver.cpp:222] Iteration 88760 (1.32563 iter/s, 30.1742s/40 iters), loss = 1.42925
I1029 15:34:03.001299 12802 solver.cpp:241]     Train net output #0: loss = 1.42925 (* 1 = 1.42925 loss)
I1029 15:34:03.001317 12802 sgd_solver.cpp:105] Iteration 88760, lr = 3.39164e-06
I1029 15:34:32.432837 12802 solver.cpp:222] Iteration 88800 (1.35912 iter/s, 29.4308s/40 iters), loss = 1.2318
I1029 15:34:32.432893 12802 solver.cpp:241]     Train net output #0: loss = 1.2318 (* 1 = 1.2318 loss)
I1029 15:34:32.432909 12802 sgd_solver.cpp:105] Iteration 88800, lr = 3.37945e-06
I1029 15:35:02.009232 12802 solver.cpp:222] Iteration 88840 (1.35246 iter/s, 29.5756s/40 iters), loss = 1.2864
I1029 15:35:02.009367 12802 solver.cpp:241]     Train net output #0: loss = 1.2864 (* 1 = 1.2864 loss)
I1029 15:35:02.009384 12802 sgd_solver.cpp:105] Iteration 88840, lr = 3.36731e-06
I1029 15:35:31.613042 12802 solver.cpp:222] Iteration 88880 (1.35122 iter/s, 29.603s/40 iters), loss = 1.10553
I1029 15:35:31.613098 12802 solver.cpp:241]     Train net output #0: loss = 1.10553 (* 1 = 1.10553 loss)
I1029 15:35:31.613114 12802 sgd_solver.cpp:105] Iteration 88880, lr = 3.3552e-06
I1029 15:36:01.202652 12802 solver.cpp:222] Iteration 88920 (1.35186 iter/s, 29.5888s/40 iters), loss = 1.28232
I1029 15:36:01.202884 12802 solver.cpp:241]     Train net output #0: loss = 1.28232 (* 1 = 1.28232 loss)
I1029 15:36:01.202903 12802 sgd_solver.cpp:105] Iteration 88920, lr = 3.34315e-06
I1029 15:36:30.794515 12802 solver.cpp:222] Iteration 88960 (1.35177 iter/s, 29.5909s/40 iters), loss = 1.47178
I1029 15:36:30.794576 12802 solver.cpp:241]     Train net output #0: loss = 1.47178 (* 1 = 1.47178 loss)
I1029 15:36:30.794592 12802 sgd_solver.cpp:105] Iteration 88960, lr = 3.33113e-06
I1029 15:36:59.638810 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_89000.caffemodel
I1029 15:36:59.778831 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_89000.solverstate
I1029 15:36:59.900256 12802 solver.cpp:334] Iteration 89000, Testing net (#0)
I1029 15:37:31.092622 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58956
I1029 15:37:31.092707 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80988
I1029 15:37:31.092720 12802 solver.cpp:401]     Test net output #2: loss = 1.82975 (* 1 = 1.82975 loss)
I1029 15:37:31.847292 12802 solver.cpp:222] Iteration 89000 (0.655187 iter/s, 61.0513s/40 iters), loss = 1.32714
I1029 15:37:31.847331 12802 solver.cpp:241]     Train net output #0: loss = 1.32714 (* 1 = 1.32714 loss)
I1029 15:37:31.847347 12802 sgd_solver.cpp:105] Iteration 89000, lr = 3.31916e-06
I1029 15:38:01.716889 12802 solver.cpp:222] Iteration 89040 (1.33919 iter/s, 29.8688s/40 iters), loss = 1.31744
I1029 15:38:01.717049 12802 solver.cpp:241]     Train net output #0: loss = 1.31744 (* 1 = 1.31744 loss)
I1029 15:38:01.717067 12802 sgd_solver.cpp:105] Iteration 89040, lr = 3.30723e-06
I1029 15:38:32.542289 12802 solver.cpp:222] Iteration 89080 (1.29767 iter/s, 30.8245s/40 iters), loss = 1.2821
I1029 15:38:32.542440 12802 solver.cpp:241]     Train net output #0: loss = 1.2821 (* 1 = 1.2821 loss)
I1029 15:38:32.542457 12802 sgd_solver.cpp:105] Iteration 89080, lr = 3.29535e-06
I1029 15:39:03.371930 12802 solver.cpp:222] Iteration 89120 (1.29749 iter/s, 30.8288s/40 iters), loss = 1.79859
I1029 15:39:03.372133 12802 solver.cpp:241]     Train net output #0: loss = 1.79859 (* 1 = 1.79859 loss)
I1029 15:39:03.372149 12802 sgd_solver.cpp:105] Iteration 89120, lr = 3.2835e-06
I1029 15:39:33.842759 12802 solver.cpp:222] Iteration 89160 (1.31277 iter/s, 30.4699s/40 iters), loss = 1.14912
I1029 15:39:33.842957 12802 solver.cpp:241]     Train net output #0: loss = 1.14912 (* 1 = 1.14912 loss)
I1029 15:39:33.842975 12802 sgd_solver.cpp:105] Iteration 89160, lr = 3.2717e-06
I1029 15:40:04.270519 12802 solver.cpp:222] Iteration 89200 (1.31463 iter/s, 30.4268s/40 iters), loss = 1.15833
I1029 15:40:04.270680 12802 solver.cpp:241]     Train net output #0: loss = 1.15833 (* 1 = 1.15833 loss)
I1029 15:40:04.270696 12802 sgd_solver.cpp:105] Iteration 89200, lr = 3.25994e-06
I1029 15:40:46.593853 12802 solver.cpp:222] Iteration 89240 (0.945131 iter/s, 42.3222s/40 iters), loss = 1.27677
I1029 15:40:46.594027 12802 solver.cpp:241]     Train net output #0: loss = 1.27677 (* 1 = 1.27677 loss)
I1029 15:40:46.594044 12802 sgd_solver.cpp:105] Iteration 89240, lr = 3.24823e-06
I1029 15:41:17.902294 12802 solver.cpp:222] Iteration 89280 (1.27765 iter/s, 31.3075s/40 iters), loss = 0.987405
I1029 15:41:17.902484 12802 solver.cpp:241]     Train net output #0: loss = 0.987405 (* 1 = 0.987405 loss)
I1029 15:41:17.902503 12802 sgd_solver.cpp:105] Iteration 89280, lr = 3.23656e-06
I1029 15:41:47.416004 12802 solver.cpp:222] Iteration 89320 (1.35534 iter/s, 29.5128s/40 iters), loss = 1.58277
I1029 15:41:47.416045 12802 solver.cpp:241]     Train net output #0: loss = 1.58277 (* 1 = 1.58277 loss)
I1029 15:41:47.416059 12802 sgd_solver.cpp:105] Iteration 89320, lr = 3.22492e-06
I1029 15:42:16.883850 12802 solver.cpp:222] Iteration 89360 (1.35745 iter/s, 29.4671s/40 iters), loss = 1.23592
I1029 15:42:16.884166 12802 solver.cpp:241]     Train net output #0: loss = 1.23592 (* 1 = 1.23592 loss)
I1029 15:42:16.884213 12802 sgd_solver.cpp:105] Iteration 89360, lr = 3.21333e-06
I1029 15:42:46.967664 12802 solver.cpp:222] Iteration 89400 (1.32966 iter/s, 30.0828s/40 iters), loss = 1.48805
I1029 15:42:46.967839 12802 solver.cpp:241]     Train net output #0: loss = 1.48805 (* 1 = 1.48805 loss)
I1029 15:42:46.967854 12802 sgd_solver.cpp:105] Iteration 89400, lr = 3.20179e-06
I1029 15:43:16.834548 12802 solver.cpp:222] Iteration 89440 (1.33932 iter/s, 29.866s/40 iters), loss = 1.31587
I1029 15:43:16.834614 12802 solver.cpp:241]     Train net output #0: loss = 1.31587 (* 1 = 1.31587 loss)
I1029 15:43:16.834626 12802 sgd_solver.cpp:105] Iteration 89440, lr = 3.19028e-06
I1029 15:43:46.407361 12802 solver.cpp:222] Iteration 89480 (1.35263 iter/s, 29.572s/40 iters), loss = 1.05966
I1029 15:43:46.407551 12802 solver.cpp:241]     Train net output #0: loss = 1.05966 (* 1 = 1.05966 loss)
I1029 15:43:46.407567 12802 sgd_solver.cpp:105] Iteration 89480, lr = 3.17881e-06
I1029 15:44:36.669068 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_89500.caffemodel
I1029 15:44:36.817162 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_89500.solverstate
I1029 15:44:36.928333 12802 solver.cpp:334] Iteration 89500, Testing net (#0)
I1029 15:45:07.845772 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 15:45:08.053076 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58528
I1029 15:45:08.053122 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81516
I1029 15:45:08.053133 12802 solver.cpp:401]     Test net output #2: loss = 1.8334 (* 1 = 1.8334 loss)
I1029 15:45:23.704478 12802 solver.cpp:222] Iteration 89520 (0.411122 iter/s, 97.2947s/40 iters), loss = 1.38504
I1029 15:45:23.704541 12802 solver.cpp:241]     Train net output #0: loss = 1.38504 (* 1 = 1.38504 loss)
I1029 15:45:23.704557 12802 sgd_solver.cpp:105] Iteration 89520, lr = 3.16739e-06
I1029 15:45:53.130499 12802 solver.cpp:222] Iteration 89560 (1.35938 iter/s, 29.4253s/40 iters), loss = 1.15926
I1029 15:45:53.130583 12802 solver.cpp:241]     Train net output #0: loss = 1.15926 (* 1 = 1.15926 loss)
I1029 15:45:53.130599 12802 sgd_solver.cpp:105] Iteration 89560, lr = 3.15601e-06
I1029 15:46:22.564561 12802 solver.cpp:222] Iteration 89600 (1.35901 iter/s, 29.4333s/40 iters), loss = 1.47258
I1029 15:46:22.564617 12802 solver.cpp:241]     Train net output #0: loss = 1.47258 (* 1 = 1.47258 loss)
I1029 15:46:22.564631 12802 sgd_solver.cpp:105] Iteration 89600, lr = 3.14467e-06
I1029 15:46:52.074118 12802 solver.cpp:222] Iteration 89640 (1.35553 iter/s, 29.5088s/40 iters), loss = 1.72683
I1029 15:46:52.074301 12802 solver.cpp:241]     Train net output #0: loss = 1.72683 (* 1 = 1.72683 loss)
I1029 15:46:52.074314 12802 sgd_solver.cpp:105] Iteration 89640, lr = 3.13336e-06
I1029 15:47:21.515169 12802 solver.cpp:222] Iteration 89680 (1.35869 iter/s, 29.4402s/40 iters), loss = 1.44084
I1029 15:47:21.515225 12802 solver.cpp:241]     Train net output #0: loss = 1.44084 (* 1 = 1.44084 loss)
I1029 15:47:21.515240 12802 sgd_solver.cpp:105] Iteration 89680, lr = 3.1221e-06
I1029 15:47:51.022066 12802 solver.cpp:222] Iteration 89720 (1.35565 iter/s, 29.5061s/40 iters), loss = 1.37915
I1029 15:47:51.022238 12802 solver.cpp:241]     Train net output #0: loss = 1.37915 (* 1 = 1.37915 loss)
I1029 15:47:51.022255 12802 sgd_solver.cpp:105] Iteration 89720, lr = 3.11088e-06
I1029 15:48:20.558229 12802 solver.cpp:222] Iteration 89760 (1.35431 iter/s, 29.5353s/40 iters), loss = 1.35928
I1029 15:48:20.558284 12802 solver.cpp:241]     Train net output #0: loss = 1.35928 (* 1 = 1.35928 loss)
I1029 15:48:20.558300 12802 sgd_solver.cpp:105] Iteration 89760, lr = 3.0997e-06
I1029 15:49:07.691998 12802 solver.cpp:222] Iteration 89800 (0.848669 iter/s, 47.1326s/40 iters), loss = 1.40269
I1029 15:49:07.692245 12802 solver.cpp:241]     Train net output #0: loss = 1.40269 (* 1 = 1.40269 loss)
I1029 15:49:07.692263 12802 sgd_solver.cpp:105] Iteration 89800, lr = 3.08856e-06
I1029 15:49:46.156594 12802 solver.cpp:222] Iteration 89840 (1.03995 iter/s, 38.4634s/40 iters), loss = 1.74136
I1029 15:49:46.156747 12802 solver.cpp:241]     Train net output #0: loss = 1.74136 (* 1 = 1.74136 loss)
I1029 15:49:46.156764 12802 sgd_solver.cpp:105] Iteration 89840, lr = 3.07746e-06
I1029 15:50:16.499841 12802 solver.cpp:222] Iteration 89880 (1.31829 iter/s, 30.3424s/40 iters), loss = 1.21514
I1029 15:50:16.500079 12802 solver.cpp:241]     Train net output #0: loss = 1.21514 (* 1 = 1.21514 loss)
I1029 15:50:16.500093 12802 sgd_solver.cpp:105] Iteration 89880, lr = 3.0664e-06
I1029 15:50:46.311837 12802 solver.cpp:222] Iteration 89920 (1.34178 iter/s, 29.8111s/40 iters), loss = 1.37642
I1029 15:50:46.311892 12802 solver.cpp:241]     Train net output #0: loss = 1.37642 (* 1 = 1.37642 loss)
I1029 15:50:46.311908 12802 sgd_solver.cpp:105] Iteration 89920, lr = 3.05538e-06
I1029 15:51:16.513801 12802 solver.cpp:222] Iteration 89960 (1.32445 iter/s, 30.2012s/40 iters), loss = 1.04162
I1029 15:51:16.514003 12802 solver.cpp:241]     Train net output #0: loss = 1.04162 (* 1 = 1.04162 loss)
I1029 15:51:16.514020 12802 sgd_solver.cpp:105] Iteration 89960, lr = 3.0444e-06
I1029 15:51:57.307379 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_90000.caffemodel
I1029 15:51:57.452428 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_90000.solverstate
I1029 15:51:57.627876 12802 solver.cpp:334] Iteration 90000, Testing net (#0)
I1029 15:52:28.757872 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58956
I1029 15:52:28.758029 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80976
I1029 15:52:28.758059 12802 solver.cpp:401]     Test net output #2: loss = 1.82844 (* 1 = 1.82844 loss)
I1029 15:52:29.524997 12802 solver.cpp:222] Iteration 90000 (0.547875 iter/s, 73.0093s/40 iters), loss = 1.25535
I1029 15:52:29.525063 12802 solver.cpp:241]     Train net output #0: loss = 1.25535 (* 1 = 1.25535 loss)
I1029 15:52:29.525086 12802 sgd_solver.cpp:105] Iteration 90000, lr = 3.03346e-06
I1029 15:52:59.811313 12802 solver.cpp:222] Iteration 90040 (1.32076 iter/s, 30.2855s/40 iters), loss = 1.43157
I1029 15:52:59.811522 12802 solver.cpp:241]     Train net output #0: loss = 1.43157 (* 1 = 1.43157 loss)
I1029 15:52:59.811539 12802 sgd_solver.cpp:105] Iteration 90040, lr = 3.02256e-06
I1029 15:53:29.508051 12802 solver.cpp:222] Iteration 90080 (1.34699 iter/s, 29.6958s/40 iters), loss = 1.43969
I1029 15:53:29.508126 12802 solver.cpp:241]     Train net output #0: loss = 1.43969 (* 1 = 1.43969 loss)
I1029 15:53:29.508148 12802 sgd_solver.cpp:105] Iteration 90080, lr = 3.0117e-06
I1029 15:53:59.331770 12802 solver.cpp:222] Iteration 90120 (1.34125 iter/s, 29.8229s/40 iters), loss = 1.42294
I1029 15:53:59.331941 12802 solver.cpp:241]     Train net output #0: loss = 1.42294 (* 1 = 1.42294 loss)
I1029 15:53:59.331959 12802 sgd_solver.cpp:105] Iteration 90120, lr = 3.00087e-06
I1029 15:54:29.010412 12802 solver.cpp:222] Iteration 90160 (1.34781 iter/s, 29.6778s/40 iters), loss = 1.43862
I1029 15:54:29.010466 12802 solver.cpp:241]     Train net output #0: loss = 1.43862 (* 1 = 1.43862 loss)
I1029 15:54:29.010481 12802 sgd_solver.cpp:105] Iteration 90160, lr = 2.99009e-06
I1029 15:54:58.627125 12802 solver.cpp:222] Iteration 90200 (1.35062 iter/s, 29.6159s/40 iters), loss = 1.3093
I1029 15:54:58.627310 12802 solver.cpp:241]     Train net output #0: loss = 1.3093 (* 1 = 1.3093 loss)
I1029 15:54:58.627326 12802 sgd_solver.cpp:105] Iteration 90200, lr = 2.97934e-06
I1029 15:55:28.229034 12802 solver.cpp:222] Iteration 90240 (1.35131 iter/s, 29.601s/40 iters), loss = 1.36808
I1029 15:55:28.229095 12802 solver.cpp:241]     Train net output #0: loss = 1.36808 (* 1 = 1.36808 loss)
I1029 15:55:28.229110 12802 sgd_solver.cpp:105] Iteration 90240, lr = 2.96864e-06
I1029 15:55:57.900794 12802 solver.cpp:222] Iteration 90280 (1.34812 iter/s, 29.671s/40 iters), loss = 1.36015
I1029 15:55:57.901089 12802 solver.cpp:241]     Train net output #0: loss = 1.36015 (* 1 = 1.36015 loss)
I1029 15:55:57.901129 12802 sgd_solver.cpp:105] Iteration 90280, lr = 2.95797e-06
I1029 15:56:27.953853 12802 solver.cpp:222] Iteration 90320 (1.33102 iter/s, 30.0521s/40 iters), loss = 1.29706
I1029 15:56:27.954051 12802 solver.cpp:241]     Train net output #0: loss = 1.29706 (* 1 = 1.29706 loss)
I1029 15:56:27.954067 12802 sgd_solver.cpp:105] Iteration 90320, lr = 2.94734e-06
I1029 15:56:58.429533 12802 solver.cpp:222] Iteration 90360 (1.31256 iter/s, 30.4747s/40 iters), loss = 1.20981
I1029 15:56:58.429720 12802 solver.cpp:241]     Train net output #0: loss = 1.20981 (* 1 = 1.20981 loss)
I1029 15:56:58.429736 12802 sgd_solver.cpp:105] Iteration 90360, lr = 2.93675e-06
I1029 15:57:32.027524 12802 solver.cpp:222] Iteration 90400 (1.19058 iter/s, 33.597s/40 iters), loss = 1.3409
I1029 15:57:32.027704 12802 solver.cpp:241]     Train net output #0: loss = 1.3409 (* 1 = 1.3409 loss)
I1029 15:57:32.027721 12802 sgd_solver.cpp:105] Iteration 90400, lr = 2.92619e-06
I1029 15:58:05.479972 12802 solver.cpp:222] Iteration 90440 (1.19576 iter/s, 33.4515s/40 iters), loss = 1.27435
I1029 15:58:05.480172 12802 solver.cpp:241]     Train net output #0: loss = 1.27435 (* 1 = 1.27435 loss)
I1029 15:58:05.480188 12802 sgd_solver.cpp:105] Iteration 90440, lr = 2.91568e-06
I1029 15:58:35.262683 12802 solver.cpp:222] Iteration 90480 (1.3431 iter/s, 29.7818s/40 iters), loss = 1.56072
I1029 15:58:35.262744 12802 solver.cpp:241]     Train net output #0: loss = 1.56072 (* 1 = 1.56072 loss)
I1029 15:58:35.262758 12802 sgd_solver.cpp:105] Iteration 90480, lr = 2.9052e-06
I1029 15:58:49.297616 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_90500.caffemodel
I1029 15:58:49.442293 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_90500.solverstate
I1029 15:58:49.569247 12802 solver.cpp:334] Iteration 90500, Testing net (#0)
I1029 15:59:20.508890 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 15:59:20.718438 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58544
I1029 15:59:20.718487 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81528
I1029 15:59:20.718499 12802 solver.cpp:401]     Test net output #2: loss = 1.8324 (* 1 = 1.8324 loss)
I1029 15:59:36.329504 12802 solver.cpp:222] Iteration 90520 (0.655036 iter/s, 61.0653s/40 iters), loss = 1.46693
I1029 15:59:36.329560 12802 solver.cpp:241]     Train net output #0: loss = 1.46693 (* 1 = 1.46693 loss)
I1029 15:59:36.329574 12802 sgd_solver.cpp:105] Iteration 90520, lr = 2.89476e-06
I1029 16:00:05.912039 12802 solver.cpp:222] Iteration 90560 (1.35218 iter/s, 29.5818s/40 iters), loss = 1.16657
I1029 16:00:05.912245 12802 solver.cpp:241]     Train net output #0: loss = 1.16657 (* 1 = 1.16657 loss)
I1029 16:00:05.912261 12802 sgd_solver.cpp:105] Iteration 90560, lr = 2.88435e-06
I1029 16:00:35.576923 12802 solver.cpp:222] Iteration 90600 (1.34844 iter/s, 29.664s/40 iters), loss = 1.25237
I1029 16:00:35.576987 12802 solver.cpp:241]     Train net output #0: loss = 1.25237 (* 1 = 1.25237 loss)
I1029 16:00:35.577003 12802 sgd_solver.cpp:105] Iteration 90600, lr = 2.87399e-06
I1029 16:01:05.166281 12802 solver.cpp:222] Iteration 90640 (1.35187 iter/s, 29.5886s/40 iters), loss = 1.39202
I1029 16:01:05.166447 12802 solver.cpp:241]     Train net output #0: loss = 1.39202 (* 1 = 1.39202 loss)
I1029 16:01:05.166465 12802 sgd_solver.cpp:105] Iteration 90640, lr = 2.86366e-06
I1029 16:01:34.750686 12802 solver.cpp:222] Iteration 90680 (1.3521 iter/s, 29.5835s/40 iters), loss = 1.23806
I1029 16:01:34.750742 12802 solver.cpp:241]     Train net output #0: loss = 1.23806 (* 1 = 1.23806 loss)
I1029 16:01:34.750758 12802 sgd_solver.cpp:105] Iteration 90680, lr = 2.85337e-06
I1029 16:02:04.374264 12802 solver.cpp:222] Iteration 90720 (1.35031 iter/s, 29.6228s/40 iters), loss = 1.1289
I1029 16:02:04.374475 12802 solver.cpp:241]     Train net output #0: loss = 1.1289 (* 1 = 1.1289 loss)
I1029 16:02:04.374493 12802 sgd_solver.cpp:105] Iteration 90720, lr = 2.84311e-06
I1029 16:02:33.799569 12802 solver.cpp:222] Iteration 90760 (1.35942 iter/s, 29.4244s/40 iters), loss = 1.34861
I1029 16:02:33.799631 12802 solver.cpp:241]     Train net output #0: loss = 1.34861 (* 1 = 1.34861 loss)
I1029 16:02:33.799646 12802 sgd_solver.cpp:105] Iteration 90760, lr = 2.8329e-06
I1029 16:03:03.556833 12802 solver.cpp:222] Iteration 90800 (1.34424 iter/s, 29.7565s/40 iters), loss = 1.24862
I1029 16:03:03.557015 12802 solver.cpp:241]     Train net output #0: loss = 1.24862 (* 1 = 1.24862 loss)
I1029 16:03:03.557029 12802 sgd_solver.cpp:105] Iteration 90800, lr = 2.82271e-06
I1029 16:03:33.324187 12802 solver.cpp:222] Iteration 90840 (1.34379 iter/s, 29.7665s/40 iters), loss = 1.23944
I1029 16:03:33.324239 12802 solver.cpp:241]     Train net output #0: loss = 1.23944 (* 1 = 1.23944 loss)
I1029 16:03:33.324251 12802 sgd_solver.cpp:105] Iteration 90840, lr = 2.81257e-06
I1029 16:04:02.836107 12802 solver.cpp:222] Iteration 90880 (1.35542 iter/s, 29.5112s/40 iters), loss = 1.56605
I1029 16:04:02.836309 12802 solver.cpp:241]     Train net output #0: loss = 1.56605 (* 1 = 1.56605 loss)
I1029 16:04:02.836323 12802 sgd_solver.cpp:105] Iteration 90880, lr = 2.80246e-06
I1029 16:04:32.332175 12802 solver.cpp:222] Iteration 90920 (1.35615 iter/s, 29.4952s/40 iters), loss = 1.15408
I1029 16:04:32.332227 12802 solver.cpp:241]     Train net output #0: loss = 1.15408 (* 1 = 1.15408 loss)
I1029 16:04:32.332242 12802 sgd_solver.cpp:105] Iteration 90920, lr = 2.79239e-06
I1029 16:05:02.756728 12802 solver.cpp:222] Iteration 90960 (1.31476 iter/s, 30.4238s/40 iters), loss = 1.39494
I1029 16:05:02.756947 12802 solver.cpp:241]     Train net output #0: loss = 1.39494 (* 1 = 1.39494 loss)
I1029 16:05:02.762714 12802 sgd_solver.cpp:105] Iteration 90960, lr = 2.78236e-06
I1029 16:05:32.056612 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_91000.caffemodel
I1029 16:05:32.196867 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_91000.solverstate
I1029 16:05:32.310637 12802 solver.cpp:334] Iteration 91000, Testing net (#0)
I1029 16:06:03.487252 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5896
I1029 16:06:03.487412 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80944
I1029 16:06:03.487426 12802 solver.cpp:401]     Test net output #2: loss = 1.82785 (* 1 = 1.82785 loss)
I1029 16:06:04.258101 12802 solver.cpp:222] Iteration 91000 (0.65041 iter/s, 61.4997s/40 iters), loss = 1.6294
I1029 16:06:04.258157 12802 solver.cpp:241]     Train net output #0: loss = 1.6294 (* 1 = 1.6294 loss)
I1029 16:06:04.258172 12802 sgd_solver.cpp:105] Iteration 91000, lr = 2.77236e-06
I1029 16:06:33.978157 12802 solver.cpp:222] Iteration 91040 (1.34593 iter/s, 29.7193s/40 iters), loss = 1.24429
I1029 16:06:33.978317 12802 solver.cpp:241]     Train net output #0: loss = 1.24429 (* 1 = 1.24429 loss)
I1029 16:06:33.978332 12802 sgd_solver.cpp:105] Iteration 91040, lr = 2.76239e-06
I1029 16:07:03.594235 12802 solver.cpp:222] Iteration 91080 (1.35066 iter/s, 29.6152s/40 iters), loss = 1.24457
I1029 16:07:03.594296 12802 solver.cpp:241]     Train net output #0: loss = 1.24457 (* 1 = 1.24457 loss)
I1029 16:07:03.594311 12802 sgd_solver.cpp:105] Iteration 91080, lr = 2.75247e-06
I1029 16:07:33.161201 12802 solver.cpp:222] Iteration 91120 (1.3529 iter/s, 29.5662s/40 iters), loss = 1.27545
I1029 16:07:33.161339 12802 solver.cpp:241]     Train net output #0: loss = 1.27545 (* 1 = 1.27545 loss)
I1029 16:07:33.161355 12802 sgd_solver.cpp:105] Iteration 91120, lr = 2.74257e-06
I1029 16:10:05.534755 12802 solver.cpp:222] Iteration 91160 (0.262519 iter/s, 152.37s/40 iters), loss = 1.71411
I1029 16:10:05.534946 12802 solver.cpp:241]     Train net output #0: loss = 1.71411 (* 1 = 1.71411 loss)
I1029 16:10:05.534971 12802 sgd_solver.cpp:105] Iteration 91160, lr = 2.73272e-06
I1029 16:10:12.219163 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 16:10:41.492074 12802 solver.cpp:222] Iteration 91200 (1.11246 iter/s, 35.9563s/40 iters), loss = 1.23495
I1029 16:10:41.492347 12802 solver.cpp:241]     Train net output #0: loss = 1.23495 (* 1 = 1.23495 loss)
I1029 16:10:41.492373 12802 sgd_solver.cpp:105] Iteration 91200, lr = 2.7229e-06
I1029 16:11:11.267712 12802 solver.cpp:222] Iteration 91240 (1.34342 iter/s, 29.7747s/40 iters), loss = 1.28669
I1029 16:11:11.267772 12802 solver.cpp:241]     Train net output #0: loss = 1.28669 (* 1 = 1.28669 loss)
I1029 16:11:11.267787 12802 sgd_solver.cpp:105] Iteration 91240, lr = 2.71311e-06
I1029 16:11:40.743894 12802 solver.cpp:222] Iteration 91280 (1.35706 iter/s, 29.4754s/40 iters), loss = 1.51045
I1029 16:11:40.744045 12802 solver.cpp:241]     Train net output #0: loss = 1.51045 (* 1 = 1.51045 loss)
I1029 16:11:40.744062 12802 sgd_solver.cpp:105] Iteration 91280, lr = 2.70336e-06
I1029 16:12:10.313999 12802 solver.cpp:222] Iteration 91320 (1.35276 iter/s, 29.5693s/40 iters), loss = 1.40463
I1029 16:12:10.314055 12802 solver.cpp:241]     Train net output #0: loss = 1.40463 (* 1 = 1.40463 loss)
I1029 16:12:10.314070 12802 sgd_solver.cpp:105] Iteration 91320, lr = 2.69365e-06
I1029 16:12:39.847671 12802 solver.cpp:222] Iteration 91360 (1.35442 iter/s, 29.5329s/40 iters), loss = 1.29414
I1029 16:12:39.847825 12802 solver.cpp:241]     Train net output #0: loss = 1.29414 (* 1 = 1.29414 loss)
I1029 16:12:39.847838 12802 sgd_solver.cpp:105] Iteration 91360, lr = 2.68396e-06
I1029 16:13:09.638623 12802 solver.cpp:222] Iteration 91400 (1.34273 iter/s, 29.7901s/40 iters), loss = 1.38532
I1029 16:13:09.638684 12802 solver.cpp:241]     Train net output #0: loss = 1.38532 (* 1 = 1.38532 loss)
I1029 16:13:09.638703 12802 sgd_solver.cpp:105] Iteration 91400, lr = 2.67432e-06
I1029 16:13:40.388108 12802 solver.cpp:222] Iteration 91440 (1.30087 iter/s, 30.7487s/40 iters), loss = 1.31999
I1029 16:13:40.388300 12802 solver.cpp:241]     Train net output #0: loss = 1.31999 (* 1 = 1.31999 loss)
I1029 16:13:40.388321 12802 sgd_solver.cpp:105] Iteration 91440, lr = 2.66471e-06
I1029 16:14:11.285156 12802 solver.cpp:222] Iteration 91480 (1.29466 iter/s, 30.8961s/40 iters), loss = 1.31259
I1029 16:14:11.285327 12802 solver.cpp:241]     Train net output #0: loss = 1.31259 (* 1 = 1.31259 loss)
I1029 16:14:11.285344 12802 sgd_solver.cpp:105] Iteration 91480, lr = 2.65513e-06
I1029 16:14:25.331418 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_91500.caffemodel
I1029 16:14:25.473284 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_91500.solverstate
I1029 16:14:25.589175 12802 solver.cpp:334] Iteration 91500, Testing net (#0)
I1029 16:14:56.600584 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 16:14:56.808020 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58528
I1029 16:14:56.808069 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81504
I1029 16:14:56.808079 12802 solver.cpp:401]     Test net output #2: loss = 1.83429 (* 1 = 1.83429 loss)
I1029 16:15:13.032742 12802 solver.cpp:222] Iteration 91520 (0.647816 iter/s, 61.746s/40 iters), loss = 1.35539
I1029 16:15:13.032793 12802 solver.cpp:241]     Train net output #0: loss = 1.35539 (* 1 = 1.35539 loss)
I1029 16:15:13.032809 12802 sgd_solver.cpp:105] Iteration 91520, lr = 2.64559e-06
I1029 16:15:43.464771 12802 solver.cpp:222] Iteration 91560 (1.31444 iter/s, 30.4312s/40 iters), loss = 1.08377
I1029 16:15:43.465191 12802 solver.cpp:241]     Train net output #0: loss = 1.08377 (* 1 = 1.08377 loss)
I1029 16:15:43.465207 12802 sgd_solver.cpp:105] Iteration 91560, lr = 2.63608e-06
I1029 16:16:13.019342 12802 solver.cpp:222] Iteration 91600 (1.35348 iter/s, 29.5534s/40 iters), loss = 1.59167
I1029 16:16:13.019398 12802 solver.cpp:241]     Train net output #0: loss = 1.59167 (* 1 = 1.59167 loss)
I1029 16:16:13.019414 12802 sgd_solver.cpp:105] Iteration 91600, lr = 2.62661e-06
I1029 16:16:43.079422 12802 solver.cpp:222] Iteration 91640 (1.3307 iter/s, 30.0593s/40 iters), loss = 1.19334
I1029 16:16:43.079659 12802 solver.cpp:241]     Train net output #0: loss = 1.19334 (* 1 = 1.19334 loss)
I1029 16:16:43.079677 12802 sgd_solver.cpp:105] Iteration 91640, lr = 2.61717e-06
I1029 16:17:12.590476 12802 solver.cpp:222] Iteration 91680 (1.35547 iter/s, 29.5101s/40 iters), loss = 1.29769
I1029 16:17:12.590534 12802 solver.cpp:241]     Train net output #0: loss = 1.29769 (* 1 = 1.29769 loss)
I1029 16:17:12.590549 12802 sgd_solver.cpp:105] Iteration 91680, lr = 2.60776e-06
I1029 16:17:42.207698 12802 solver.cpp:222] Iteration 91720 (1.3506 iter/s, 29.6164s/40 iters), loss = 1.15016
I1029 16:17:42.207901 12802 solver.cpp:241]     Train net output #0: loss = 1.15016 (* 1 = 1.15016 loss)
I1029 16:17:42.207916 12802 sgd_solver.cpp:105] Iteration 91720, lr = 2.59839e-06
I1029 16:18:11.758195 12802 solver.cpp:222] Iteration 91760 (1.35366 iter/s, 29.5496s/40 iters), loss = 1.80704
I1029 16:18:11.758255 12802 solver.cpp:241]     Train net output #0: loss = 1.80704 (* 1 = 1.80704 loss)
I1029 16:18:11.758270 12802 sgd_solver.cpp:105] Iteration 91760, lr = 2.58905e-06
I1029 16:18:41.536454 12802 solver.cpp:222] Iteration 91800 (1.3433 iter/s, 29.7775s/40 iters), loss = 1.58046
I1029 16:18:41.536643 12802 solver.cpp:241]     Train net output #0: loss = 1.58046 (* 1 = 1.58046 loss)
I1029 16:18:41.536659 12802 sgd_solver.cpp:105] Iteration 91800, lr = 2.57975e-06
I1029 16:19:11.751049 12802 solver.cpp:222] Iteration 91840 (1.3239 iter/s, 30.2137s/40 iters), loss = 1.42862
I1029 16:19:11.751240 12802 solver.cpp:241]     Train net output #0: loss = 1.42862 (* 1 = 1.42862 loss)
I1029 16:19:11.751253 12802 sgd_solver.cpp:105] Iteration 91840, lr = 2.57048e-06
I1029 16:19:41.999402 12802 solver.cpp:222] Iteration 91880 (1.32243 iter/s, 30.2474s/40 iters), loss = 1.28279
I1029 16:19:41.999598 12802 solver.cpp:241]     Train net output #0: loss = 1.28279 (* 1 = 1.28279 loss)
I1029 16:19:41.999615 12802 sgd_solver.cpp:105] Iteration 91880, lr = 2.56124e-06
I1029 16:20:11.907014 12802 solver.cpp:222] Iteration 91920 (1.33749 iter/s, 29.9067s/40 iters), loss = 1.11379
I1029 16:20:11.907078 12802 solver.cpp:241]     Train net output #0: loss = 1.11379 (* 1 = 1.11379 loss)
I1029 16:20:11.907094 12802 sgd_solver.cpp:105] Iteration 91920, lr = 2.55203e-06
I1029 16:20:42.279654 12802 solver.cpp:222] Iteration 91960 (1.31701 iter/s, 30.3719s/40 iters), loss = 1.61157
I1029 16:20:42.279836 12802 solver.cpp:241]     Train net output #0: loss = 1.61157 (* 1 = 1.61157 loss)
I1029 16:20:42.279852 12802 sgd_solver.cpp:105] Iteration 91960, lr = 2.54286e-06
I1029 16:21:11.638579 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_92000.caffemodel
I1029 16:21:11.774595 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_92000.solverstate
I1029 16:21:11.891209 12802 solver.cpp:334] Iteration 92000, Testing net (#0)
I1029 16:21:43.066555 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58948
I1029 16:21:43.066756 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81012
I1029 16:21:43.066771 12802 solver.cpp:401]     Test net output #2: loss = 1.82951 (* 1 = 1.82951 loss)
I1029 16:21:43.837327 12802 solver.cpp:222] Iteration 92000 (0.649814 iter/s, 61.556s/40 iters), loss = 1.46236
I1029 16:21:48.600111 12802 solver.cpp:241]     Train net output #0: loss = 1.46236 (* 1 = 1.46236 loss)
I1029 16:21:48.600296 12802 sgd_solver.cpp:105] Iteration 92000, lr = 2.53372e-06
I1029 16:22:19.951778 12802 solver.cpp:222] Iteration 92040 (1.27588 iter/s, 31.3509s/40 iters), loss = 1.61765
I1029 16:22:19.952056 12802 solver.cpp:241]     Train net output #0: loss = 1.61765 (* 1 = 1.61765 loss)
I1029 16:22:19.952071 12802 sgd_solver.cpp:105] Iteration 92040, lr = 2.52462e-06
I1029 16:22:49.875897 12802 solver.cpp:222] Iteration 92080 (1.33676 iter/s, 29.9231s/40 iters), loss = 1.456
I1029 16:22:49.875955 12802 solver.cpp:241]     Train net output #0: loss = 1.456 (* 1 = 1.456 loss)
I1029 16:22:49.875970 12802 sgd_solver.cpp:105] Iteration 92080, lr = 2.51555e-06
I1029 16:23:19.403631 12802 solver.cpp:222] Iteration 92120 (1.35469 iter/s, 29.527s/40 iters), loss = 1.45368
I1029 16:23:19.403861 12802 solver.cpp:241]     Train net output #0: loss = 1.45368 (* 1 = 1.45368 loss)
I1029 16:23:19.403878 12802 sgd_solver.cpp:105] Iteration 92120, lr = 2.50651e-06
I1029 16:23:49.747287 12802 solver.cpp:222] Iteration 92160 (1.31827 iter/s, 30.3427s/40 iters), loss = 1.64619
I1029 16:23:49.747448 12802 solver.cpp:241]     Train net output #0: loss = 1.64619 (* 1 = 1.64619 loss)
I1029 16:23:49.747465 12802 sgd_solver.cpp:105] Iteration 92160, lr = 2.4975e-06
I1029 16:24:20.488274 12802 solver.cpp:222] Iteration 92200 (1.30123 iter/s, 30.7401s/40 iters), loss = 1.52327
I1029 16:24:20.488417 12802 solver.cpp:241]     Train net output #0: loss = 1.52327 (* 1 = 1.52327 loss)
I1029 16:24:20.488431 12802 sgd_solver.cpp:105] Iteration 92200, lr = 2.48852e-06
I1029 16:24:50.095191 12802 solver.cpp:222] Iteration 92240 (1.35107 iter/s, 29.6061s/40 iters), loss = 1.44314
I1029 16:24:50.095237 12802 solver.cpp:241]     Train net output #0: loss = 1.44314 (* 1 = 1.44314 loss)
I1029 16:24:50.095250 12802 sgd_solver.cpp:105] Iteration 92240, lr = 2.47958e-06
I1029 16:25:19.571862 12802 solver.cpp:222] Iteration 92280 (1.35704 iter/s, 29.4759s/40 iters), loss = 1.33506
I1029 16:25:19.572039 12802 solver.cpp:241]     Train net output #0: loss = 1.33506 (* 1 = 1.33506 loss)
I1029 16:25:19.572057 12802 sgd_solver.cpp:105] Iteration 92280, lr = 2.47067e-06
I1029 16:25:49.031517 12802 solver.cpp:222] Iteration 92320 (1.35783 iter/s, 29.4588s/40 iters), loss = 1.54636
I1029 16:25:49.031579 12802 solver.cpp:241]     Train net output #0: loss = 1.54636 (* 1 = 1.54636 loss)
I1029 16:25:49.031594 12802 sgd_solver.cpp:105] Iteration 92320, lr = 2.46179e-06
I1029 16:26:18.604671 12802 solver.cpp:222] Iteration 92360 (1.35261 iter/s, 29.5724s/40 iters), loss = 1.11886
I1029 16:26:18.604799 12802 solver.cpp:241]     Train net output #0: loss = 1.11886 (* 1 = 1.11886 loss)
I1029 16:26:18.604822 12802 sgd_solver.cpp:105] Iteration 92360, lr = 2.45294e-06
I1029 16:26:48.263491 12802 solver.cpp:222] Iteration 92400 (1.34871 iter/s, 29.658s/40 iters), loss = 1.40609
I1029 16:26:48.263555 12802 solver.cpp:241]     Train net output #0: loss = 1.40609 (* 1 = 1.40609 loss)
I1029 16:26:48.263567 12802 sgd_solver.cpp:105] Iteration 92400, lr = 2.44413e-06
I1029 16:27:17.772430 12802 solver.cpp:222] Iteration 92440 (1.35556 iter/s, 29.5082s/40 iters), loss = 1.3174
I1029 16:27:17.772526 12802 solver.cpp:241]     Train net output #0: loss = 1.3174 (* 1 = 1.3174 loss)
I1029 16:27:17.772542 12802 sgd_solver.cpp:105] Iteration 92440, lr = 2.43534e-06
I1029 16:27:47.260498 12802 solver.cpp:222] Iteration 92480 (1.35652 iter/s, 29.4873s/40 iters), loss = 1.4124
I1029 16:27:47.260560 12802 solver.cpp:241]     Train net output #0: loss = 1.4124 (* 1 = 1.4124 loss)
I1029 16:27:47.260571 12802 sgd_solver.cpp:105] Iteration 92480, lr = 2.42659e-06
I1029 16:28:01.288856 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_92500.caffemodel
I1029 16:28:01.435513 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_92500.solverstate
I1029 16:28:01.554327 12802 solver.cpp:334] Iteration 92500, Testing net (#0)
I1029 16:28:32.390592 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 16:28:32.598331 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58532
I1029 16:28:32.598381 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81528
I1029 16:28:32.598392 12802 solver.cpp:401]     Test net output #2: loss = 1.83326 (* 1 = 1.83326 loss)
I1029 16:28:48.642944 12802 solver.cpp:222] Iteration 92520 (0.651668 iter/s, 61.381s/40 iters), loss = 1.17982
I1029 16:28:48.642988 12802 solver.cpp:241]     Train net output #0: loss = 1.17982 (* 1 = 1.17982 loss)
I1029 16:28:48.643004 12802 sgd_solver.cpp:105] Iteration 92520, lr = 2.41787e-06
I1029 16:29:19.395978 12802 solver.cpp:222] Iteration 92560 (1.30072 iter/s, 30.7523s/40 iters), loss = 1.04563
I1029 16:29:19.396075 12802 solver.cpp:241]     Train net output #0: loss = 1.04563 (* 1 = 1.04563 loss)
I1029 16:29:19.396090 12802 sgd_solver.cpp:105] Iteration 92560, lr = 2.40918e-06
I1029 16:29:50.305661 12802 solver.cpp:222] Iteration 92600 (1.29413 iter/s, 30.9089s/40 iters), loss = 1.44756
I1029 16:29:50.305778 12802 solver.cpp:241]     Train net output #0: loss = 1.44756 (* 1 = 1.44756 loss)
I1029 16:29:50.305794 12802 sgd_solver.cpp:105] Iteration 92600, lr = 2.40052e-06
I1029 16:30:20.950366 12802 solver.cpp:222] Iteration 92640 (1.30532 iter/s, 30.6439s/40 iters), loss = 1.50746
I1029 16:30:20.950521 12802 solver.cpp:241]     Train net output #0: loss = 1.50746 (* 1 = 1.50746 loss)
I1029 16:30:20.950537 12802 sgd_solver.cpp:105] Iteration 92640, lr = 2.39189e-06
I1029 16:30:50.339898 12802 solver.cpp:222] Iteration 92680 (1.36107 iter/s, 29.3887s/40 iters), loss = 1.44369
I1029 16:30:50.339957 12802 solver.cpp:241]     Train net output #0: loss = 1.44369 (* 1 = 1.44369 loss)
I1029 16:30:50.339972 12802 sgd_solver.cpp:105] Iteration 92680, lr = 2.3833e-06
I1029 16:31:19.851089 12802 solver.cpp:222] Iteration 92720 (1.35545 iter/s, 29.5104s/40 iters), loss = 1.45868
I1029 16:31:19.851231 12802 solver.cpp:241]     Train net output #0: loss = 1.45868 (* 1 = 1.45868 loss)
I1029 16:31:19.851248 12802 sgd_solver.cpp:105] Iteration 92720, lr = 2.37473e-06
I1029 16:31:49.466425 12802 solver.cpp:222] Iteration 92760 (1.35069 iter/s, 29.6145s/40 iters), loss = 1.27412
I1029 16:31:49.466490 12802 solver.cpp:241]     Train net output #0: loss = 1.27412 (* 1 = 1.27412 loss)
I1029 16:31:49.466512 12802 sgd_solver.cpp:105] Iteration 92760, lr = 2.3662e-06
I1029 16:32:19.036622 12802 solver.cpp:222] Iteration 92800 (1.35275 iter/s, 29.5694s/40 iters), loss = 1.27165
I1029 16:32:19.036768 12802 solver.cpp:241]     Train net output #0: loss = 1.27165 (* 1 = 1.27165 loss)
I1029 16:32:19.036787 12802 sgd_solver.cpp:105] Iteration 92800, lr = 2.3577e-06
I1029 16:32:49.381306 12802 solver.cpp:222] Iteration 92840 (1.31823 iter/s, 30.3438s/40 iters), loss = 1.56286
I1029 16:32:49.381400 12802 solver.cpp:241]     Train net output #0: loss = 1.56286 (* 1 = 1.56286 loss)
I1029 16:32:49.381417 12802 sgd_solver.cpp:105] Iteration 92840, lr = 2.34922e-06
I1029 16:33:19.434841 12802 solver.cpp:222] Iteration 92880 (1.33099 iter/s, 30.0527s/40 iters), loss = 1.50541
I1029 16:33:19.435003 12802 solver.cpp:241]     Train net output #0: loss = 1.50541 (* 1 = 1.50541 loss)
I1029 16:33:19.435715 12802 sgd_solver.cpp:105] Iteration 92880, lr = 2.34078e-06
I1029 16:33:48.912225 12802 solver.cpp:222] Iteration 92920 (1.35701 iter/s, 29.4765s/40 iters), loss = 1.6822
I1029 16:33:48.912268 12802 solver.cpp:241]     Train net output #0: loss = 1.6822 (* 1 = 1.6822 loss)
I1029 16:33:48.912282 12802 sgd_solver.cpp:105] Iteration 92920, lr = 2.33237e-06
I1029 16:34:18.360851 12802 solver.cpp:222] Iteration 92960 (1.35833 iter/s, 29.4479s/40 iters), loss = 1.47049
I1029 16:34:18.360913 12802 solver.cpp:241]     Train net output #0: loss = 1.47049 (* 1 = 1.47049 loss)
I1029 16:34:18.360934 12802 sgd_solver.cpp:105] Iteration 92960, lr = 2.32399e-06
I1029 16:34:47.110631 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_93000.caffemodel
I1029 16:34:47.928314 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_93000.solverstate
I1029 16:34:48.367458 12802 solver.cpp:334] Iteration 93000, Testing net (#0)
I1029 16:35:19.619787 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58976
I1029 16:35:19.619870 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80996
I1029 16:35:19.619882 12802 solver.cpp:401]     Test net output #2: loss = 1.82829 (* 1 = 1.82829 loss)
I1029 16:35:20.368978 12802 solver.cpp:222] Iteration 93000 (0.645092 iter/s, 62.0066s/40 iters), loss = 1.47181
I1029 16:35:20.369012 12802 solver.cpp:241]     Train net output #0: loss = 1.47181 (* 1 = 1.47181 loss)
I1029 16:35:20.369027 12802 sgd_solver.cpp:105] Iteration 93000, lr = 2.31563e-06
I1029 16:35:49.895494 12802 solver.cpp:222] Iteration 93040 (1.35475 iter/s, 29.5258s/40 iters), loss = 1.46089
I1029 16:35:49.895586 12802 solver.cpp:241]     Train net output #0: loss = 1.46089 (* 1 = 1.46089 loss)
I1029 16:35:49.895601 12802 sgd_solver.cpp:105] Iteration 93040, lr = 2.30731e-06
I1029 16:36:19.464592 12802 solver.cpp:222] Iteration 93080 (1.3528 iter/s, 29.5683s/40 iters), loss = 1.62553
I1029 16:36:19.464658 12802 solver.cpp:241]     Train net output #0: loss = 1.62553 (* 1 = 1.62553 loss)
I1029 16:36:19.464673 12802 sgd_solver.cpp:105] Iteration 93080, lr = 2.29902e-06
I1029 16:36:49.032768 12802 solver.cpp:222] Iteration 93120 (1.35284 iter/s, 29.5674s/40 iters), loss = 1.64812
I1029 16:36:49.032858 12802 solver.cpp:241]     Train net output #0: loss = 1.64812 (* 1 = 1.64812 loss)
I1029 16:36:49.032874 12802 sgd_solver.cpp:105] Iteration 93120, lr = 2.29076e-06
I1029 16:37:18.598960 12802 solver.cpp:222] Iteration 93160 (1.35293 iter/s, 29.5654s/40 iters), loss = 1.68454
I1029 16:37:18.599022 12802 solver.cpp:241]     Train net output #0: loss = 1.68454 (* 1 = 1.68454 loss)
I1029 16:37:18.599037 12802 sgd_solver.cpp:105] Iteration 93160, lr = 2.28252e-06
I1029 16:37:48.127008 12802 solver.cpp:222] Iteration 93200 (1.35468 iter/s, 29.5273s/40 iters), loss = 1.33695
I1029 16:37:48.127151 12802 solver.cpp:241]     Train net output #0: loss = 1.33695 (* 1 = 1.33695 loss)
I1029 16:37:48.127166 12802 sgd_solver.cpp:105] Iteration 93200, lr = 2.27432e-06
I1029 16:38:17.670356 12802 solver.cpp:222] Iteration 93240 (1.35398 iter/s, 29.5425s/40 iters), loss = 1.38667
I1029 16:38:17.670418 12802 solver.cpp:241]     Train net output #0: loss = 1.38667 (* 1 = 1.38667 loss)
I1029 16:38:17.670433 12802 sgd_solver.cpp:105] Iteration 93240, lr = 2.26615e-06
I1029 16:38:47.226176 12802 solver.cpp:222] Iteration 93280 (1.35341 iter/s, 29.555s/40 iters), loss = 1.42841
I1029 16:38:47.226330 12802 solver.cpp:241]     Train net output #0: loss = 1.42841 (* 1 = 1.42841 loss)
I1029 16:38:47.226348 12802 sgd_solver.cpp:105] Iteration 93280, lr = 2.258e-06
I1029 16:39:16.803217 12802 solver.cpp:222] Iteration 93320 (1.35244 iter/s, 29.5762s/40 iters), loss = 1.40774
I1029 16:39:16.803274 12802 solver.cpp:241]     Train net output #0: loss = 1.40774 (* 1 = 1.40774 loss)
I1029 16:39:16.803290 12802 sgd_solver.cpp:105] Iteration 93320, lr = 2.24989e-06
I1029 16:39:46.731040 12802 solver.cpp:222] Iteration 93360 (1.33658 iter/s, 29.927s/40 iters), loss = 1.45067
I1029 16:39:46.731222 12802 solver.cpp:241]     Train net output #0: loss = 1.45067 (* 1 = 1.45067 loss)
I1029 16:39:46.731240 12802 sgd_solver.cpp:105] Iteration 93360, lr = 2.2418e-06
I1029 16:40:26.717766 12802 solver.cpp:222] Iteration 93400 (1.00036 iter/s, 39.9856s/40 iters), loss = 1.52333
I1029 16:40:26.718001 12802 solver.cpp:241]     Train net output #0: loss = 1.52333 (* 1 = 1.52333 loss)
I1029 16:40:26.718019 12802 sgd_solver.cpp:105] Iteration 93400, lr = 2.23375e-06
I1029 16:43:30.453307 12802 solver.cpp:222] Iteration 93440 (0.217709 iter/s, 183.731s/40 iters), loss = 1.34475
I1029 16:43:30.453482 12802 solver.cpp:241]     Train net output #0: loss = 1.34475 (* 1 = 1.34475 loss)
I1029 16:43:30.453500 12802 sgd_solver.cpp:105] Iteration 93440, lr = 2.22572e-06
I1029 16:44:00.098647 12802 solver.cpp:222] Iteration 93480 (1.34932 iter/s, 29.6445s/40 iters), loss = 1.54165
I1029 16:44:00.098703 12802 solver.cpp:241]     Train net output #0: loss = 1.54165 (* 1 = 1.54165 loss)
I1029 16:44:00.098719 12802 sgd_solver.cpp:105] Iteration 93480, lr = 2.21772e-06
I1029 16:44:14.193774 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_93500.caffemodel
I1029 16:44:15.307785 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_93500.solverstate
I1029 16:44:15.681193 12802 solver.cpp:334] Iteration 93500, Testing net (#0)
I1029 16:44:46.715247 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 16:44:46.928930 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58592
I1029 16:44:46.928979 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81544
I1029 16:44:46.928990 12802 solver.cpp:401]     Test net output #2: loss = 1.83209 (* 1 = 1.83209 loss)
I1029 16:45:02.510960 12802 solver.cpp:222] Iteration 93520 (0.640914 iter/s, 62.4108s/40 iters), loss = 1.58036
I1029 16:45:02.511016 12802 solver.cpp:241]     Train net output #0: loss = 1.58036 (* 1 = 1.58036 loss)
I1029 16:45:02.511032 12802 sgd_solver.cpp:105] Iteration 93520, lr = 2.20975e-06
I1029 16:45:35.225850 12802 solver.cpp:222] Iteration 93560 (1.22272 iter/s, 32.7141s/40 iters), loss = 1.44298
I1029 16:45:35.226032 12802 solver.cpp:241]     Train net output #0: loss = 1.44298 (* 1 = 1.44298 loss)
I1029 16:45:35.226049 12802 sgd_solver.cpp:105] Iteration 93560, lr = 2.20181e-06
I1029 16:46:09.307724 12802 solver.cpp:222] Iteration 93600 (1.17368 iter/s, 34.0809s/40 iters), loss = 1.6045
I1029 16:46:09.307901 12802 solver.cpp:241]     Train net output #0: loss = 1.6045 (* 1 = 1.6045 loss)
I1029 16:46:09.307922 12802 sgd_solver.cpp:105] Iteration 93600, lr = 2.1939e-06
I1029 16:46:40.062224 12802 solver.cpp:222] Iteration 93640 (1.30066 iter/s, 30.7536s/40 iters), loss = 1.27038
I1029 16:46:40.062397 12802 solver.cpp:241]     Train net output #0: loss = 1.27038 (* 1 = 1.27038 loss)
I1029 16:46:40.062412 12802 sgd_solver.cpp:105] Iteration 93640, lr = 2.18601e-06
I1029 16:47:00.246731 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 16:47:09.798636 12802 solver.cpp:222] Iteration 93680 (1.34519 iter/s, 29.7355s/40 iters), loss = 1.13062
I1029 16:47:09.798696 12802 solver.cpp:241]     Train net output #0: loss = 1.13062 (* 1 = 1.13062 loss)
I1029 16:47:09.798712 12802 sgd_solver.cpp:105] Iteration 93680, lr = 2.17816e-06
I1029 16:47:39.335187 12802 solver.cpp:222] Iteration 93720 (1.35429 iter/s, 29.5358s/40 iters), loss = 1.45531
I1029 16:47:39.335395 12802 solver.cpp:241]     Train net output #0: loss = 1.45531 (* 1 = 1.45531 loss)
I1029 16:47:39.335410 12802 sgd_solver.cpp:105] Iteration 93720, lr = 2.17033e-06
I1029 16:48:09.092775 12802 solver.cpp:222] Iteration 93760 (1.34424 iter/s, 29.7567s/40 iters), loss = 1.07494
I1029 16:48:09.092833 12802 solver.cpp:241]     Train net output #0: loss = 1.07494 (* 1 = 1.07494 loss)
I1029 16:48:09.092849 12802 sgd_solver.cpp:105] Iteration 93760, lr = 2.16253e-06
I1029 16:48:38.706688 12802 solver.cpp:222] Iteration 93800 (1.35075 iter/s, 29.6131s/40 iters), loss = 1.0987
I1029 16:48:38.706946 12802 solver.cpp:241]     Train net output #0: loss = 1.0987 (* 1 = 1.0987 loss)
I1029 16:48:38.706964 12802 sgd_solver.cpp:105] Iteration 93800, lr = 2.15476e-06
I1029 16:49:08.590972 12802 solver.cpp:222] Iteration 93840 (1.33854 iter/s, 29.8833s/40 iters), loss = 1.01988
I1029 16:49:08.591030 12802 solver.cpp:241]     Train net output #0: loss = 1.01988 (* 1 = 1.01988 loss)
I1029 16:49:08.591045 12802 sgd_solver.cpp:105] Iteration 93840, lr = 2.14701e-06
I1029 16:49:39.050817 12802 solver.cpp:222] Iteration 93880 (1.31324 iter/s, 30.4591s/40 iters), loss = 1.70009
I1029 16:49:39.051040 12802 solver.cpp:241]     Train net output #0: loss = 1.70009 (* 1 = 1.70009 loss)
I1029 16:49:39.051059 12802 sgd_solver.cpp:105] Iteration 93880, lr = 2.1393e-06
I1029 16:50:08.854138 12802 solver.cpp:222] Iteration 93920 (1.34217 iter/s, 29.8024s/40 iters), loss = 1.55858
I1029 16:50:08.854193 12802 solver.cpp:241]     Train net output #0: loss = 1.55858 (* 1 = 1.55858 loss)
I1029 16:50:08.854208 12802 sgd_solver.cpp:105] Iteration 93920, lr = 2.13161e-06
I1029 16:50:39.037509 12802 solver.cpp:222] Iteration 93960 (1.32527 iter/s, 30.1826s/40 iters), loss = 1.41107
I1029 16:50:39.037772 12802 solver.cpp:241]     Train net output #0: loss = 1.41107 (* 1 = 1.41107 loss)
I1029 16:50:39.037796 12802 sgd_solver.cpp:105] Iteration 93960, lr = 2.12395e-06
I1029 16:51:09.300544 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_94000.caffemodel
I1029 16:51:09.439874 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_94000.solverstate
I1029 16:51:09.573983 12802 solver.cpp:334] Iteration 94000, Testing net (#0)
I1029 16:51:40.697494 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58956
I1029 16:51:40.697664 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80988
I1029 16:51:40.697676 12802 solver.cpp:401]     Test net output #2: loss = 1.82917 (* 1 = 1.82917 loss)
I1029 16:51:41.458581 12802 solver.cpp:222] Iteration 94000 (0.640827 iter/s, 62.4193s/40 iters), loss = 1.42144
I1029 16:51:41.458643 12802 solver.cpp:241]     Train net output #0: loss = 1.42144 (* 1 = 1.42144 loss)
I1029 16:51:41.458664 12802 sgd_solver.cpp:105] Iteration 94000, lr = 2.11631e-06
I1029 16:53:04.085238 12802 solver.cpp:222] Iteration 94040 (0.484117 iter/s, 82.6246s/40 iters), loss = 1.208
I1029 16:53:04.085356 12802 solver.cpp:241]     Train net output #0: loss = 1.208 (* 1 = 1.208 loss)
I1029 16:53:04.085379 12802 sgd_solver.cpp:105] Iteration 94040, lr = 2.10871e-06
I1029 16:53:48.604877 12802 solver.cpp:222] Iteration 94080 (0.898504 iter/s, 44.5185s/40 iters), loss = 1.42987
I1029 16:53:48.605087 12802 solver.cpp:241]     Train net output #0: loss = 1.42987 (* 1 = 1.42987 loss)
I1029 16:53:48.605120 12802 sgd_solver.cpp:105] Iteration 94080, lr = 2.10113e-06
I1029 16:55:08.891329 12802 solver.cpp:222] Iteration 94120 (0.498229 iter/s, 80.2844s/40 iters), loss = 1.33213
I1029 16:55:08.891540 12802 solver.cpp:241]     Train net output #0: loss = 1.33213 (* 1 = 1.33213 loss)
I1029 16:55:08.891571 12802 sgd_solver.cpp:105] Iteration 94120, lr = 2.09358e-06
I1029 16:55:46.963599 12802 solver.cpp:222] Iteration 94160 (1.05066 iter/s, 38.0712s/40 iters), loss = 1.43678
I1029 16:55:46.963877 12802 solver.cpp:241]     Train net output #0: loss = 1.43678 (* 1 = 1.43678 loss)
I1029 16:55:46.963932 12802 sgd_solver.cpp:105] Iteration 94160, lr = 2.08606e-06
I1029 16:56:24.102063 12802 solver.cpp:222] Iteration 94200 (1.07708 iter/s, 37.1374s/40 iters), loss = 1.09132
I1029 16:56:24.102275 12802 solver.cpp:241]     Train net output #0: loss = 1.09132 (* 1 = 1.09132 loss)
I1029 16:56:24.102293 12802 sgd_solver.cpp:105] Iteration 94200, lr = 2.07856e-06
I1029 16:56:53.739472 12802 solver.cpp:222] Iteration 94240 (1.34969 iter/s, 29.6365s/40 iters), loss = 1.38666
I1029 16:56:53.739526 12802 solver.cpp:241]     Train net output #0: loss = 1.38666 (* 1 = 1.38666 loss)
I1029 16:56:53.739542 12802 sgd_solver.cpp:105] Iteration 94240, lr = 2.07109e-06
I1029 16:57:23.343799 12802 solver.cpp:222] Iteration 94280 (1.35119 iter/s, 29.6036s/40 iters), loss = 1.33775
I1029 16:57:23.343991 12802 solver.cpp:241]     Train net output #0: loss = 1.33775 (* 1 = 1.33775 loss)
I1029 16:57:23.344009 12802 sgd_solver.cpp:105] Iteration 94280, lr = 2.06365e-06
I1029 16:57:53.053812 12802 solver.cpp:222] Iteration 94320 (1.34639 iter/s, 29.7091s/40 iters), loss = 1.1076
I1029 16:57:53.053865 12802 solver.cpp:241]     Train net output #0: loss = 1.1076 (* 1 = 1.1076 loss)
I1029 16:57:53.053880 12802 sgd_solver.cpp:105] Iteration 94320, lr = 2.05623e-06
I1029 16:58:22.619067 12802 solver.cpp:222] Iteration 94360 (1.35297 iter/s, 29.5645s/40 iters), loss = 1.65682
I1029 16:58:22.619254 12802 solver.cpp:241]     Train net output #0: loss = 1.65682 (* 1 = 1.65682 loss)
I1029 16:58:22.619271 12802 sgd_solver.cpp:105] Iteration 94360, lr = 2.04884e-06
I1029 16:58:52.063458 12802 solver.cpp:222] Iteration 94400 (1.35853 iter/s, 29.4435s/40 iters), loss = 1.49045
I1029 16:58:52.063508 12802 solver.cpp:241]     Train net output #0: loss = 1.49045 (* 1 = 1.49045 loss)
I1029 16:58:52.063522 12802 sgd_solver.cpp:105] Iteration 94400, lr = 2.04148e-06
I1029 16:59:21.502907 12802 solver.cpp:222] Iteration 94440 (1.35876 iter/s, 29.4387s/40 iters), loss = 1.06708
I1029 16:59:21.503118 12802 solver.cpp:241]     Train net output #0: loss = 1.06708 (* 1 = 1.06708 loss)
I1029 16:59:21.503136 12802 sgd_solver.cpp:105] Iteration 94440, lr = 2.03414e-06
I1029 16:59:51.018600 12802 solver.cpp:222] Iteration 94480 (1.35525 iter/s, 29.5148s/40 iters), loss = 1.44968
I1029 16:59:51.018661 12802 solver.cpp:241]     Train net output #0: loss = 1.44968 (* 1 = 1.44968 loss)
I1029 16:59:51.018676 12802 sgd_solver.cpp:105] Iteration 94480, lr = 2.02683e-06
I1029 17:00:05.151002 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_94500.caffemodel
I1029 17:00:05.505519 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_94500.solverstate
I1029 17:00:05.618518 12802 solver.cpp:334] Iteration 94500, Testing net (#0)
I1029 17:00:36.668931 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 17:00:36.876754 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58532
I1029 17:00:36.876797 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81524
I1029 17:00:36.876808 12802 solver.cpp:401]     Test net output #2: loss = 1.83367 (* 1 = 1.83367 loss)
I1029 17:00:52.823874 12802 solver.cpp:222] Iteration 94520 (0.64721 iter/s, 61.8037s/40 iters), loss = 1.17817
I1029 17:00:52.823940 12802 solver.cpp:241]     Train net output #0: loss = 1.17817 (* 1 = 1.17817 loss)
I1029 17:00:52.823957 12802 sgd_solver.cpp:105] Iteration 94520, lr = 2.01955e-06
I1029 17:01:23.604651 12802 solver.cpp:222] Iteration 94560 (1.29955 iter/s, 30.78s/40 iters), loss = 1.4855
I1029 17:01:23.604840 12802 solver.cpp:241]     Train net output #0: loss = 1.4855 (* 1 = 1.4855 loss)
I1029 17:01:23.604862 12802 sgd_solver.cpp:105] Iteration 94560, lr = 2.01229e-06
I1029 17:01:53.948015 12802 solver.cpp:222] Iteration 94600 (1.31829 iter/s, 30.3424s/40 iters), loss = 1.62126
I1029 17:01:53.948194 12802 solver.cpp:241]     Train net output #0: loss = 1.62126 (* 1 = 1.62126 loss)
I1029 17:01:53.948211 12802 sgd_solver.cpp:105] Iteration 94600, lr = 2.00506e-06
I1029 17:02:24.316347 12802 solver.cpp:222] Iteration 94640 (1.3172 iter/s, 30.3674s/40 iters), loss = 1.36797
I1029 17:02:24.316572 12802 solver.cpp:241]     Train net output #0: loss = 1.36797 (* 1 = 1.36797 loss)
I1029 17:02:24.316587 12802 sgd_solver.cpp:105] Iteration 94640, lr = 1.99785e-06
I1029 17:02:54.897320 12802 solver.cpp:222] Iteration 94680 (1.30804 iter/s, 30.58s/40 iters), loss = 1.3902
I1029 17:02:54.897490 12802 solver.cpp:241]     Train net output #0: loss = 1.3902 (* 1 = 1.3902 loss)
I1029 17:02:54.897505 12802 sgd_solver.cpp:105] Iteration 94680, lr = 1.99067e-06
I1029 17:03:25.125618 12802 solver.cpp:222] Iteration 94720 (1.3233 iter/s, 30.2274s/40 iters), loss = 1.42349
I1029 17:03:25.125782 12802 solver.cpp:241]     Train net output #0: loss = 1.42349 (* 1 = 1.42349 loss)
I1029 17:03:25.125797 12802 sgd_solver.cpp:105] Iteration 94720, lr = 1.98352e-06
I1029 17:03:54.431175 12802 solver.cpp:222] Iteration 94760 (1.36497 iter/s, 29.3047s/40 iters), loss = 1.41442
I1029 17:03:54.431223 12802 solver.cpp:241]     Train net output #0: loss = 1.41442 (* 1 = 1.41442 loss)
I1029 17:03:54.431236 12802 sgd_solver.cpp:105] Iteration 94760, lr = 1.97639e-06
I1029 17:04:23.641880 12802 solver.cpp:222] Iteration 94800 (1.3694 iter/s, 29.21s/40 iters), loss = 1.3391
I1029 17:04:23.642051 12802 solver.cpp:241]     Train net output #0: loss = 1.3391 (* 1 = 1.3391 loss)
I1029 17:04:23.642069 12802 sgd_solver.cpp:105] Iteration 94800, lr = 1.96929e-06
I1029 17:04:52.824208 12802 solver.cpp:222] Iteration 94840 (1.37073 iter/s, 29.1815s/40 iters), loss = 1.65324
I1029 17:04:52.824259 12802 solver.cpp:241]     Train net output #0: loss = 1.65324 (* 1 = 1.65324 loss)
I1029 17:04:52.824272 12802 sgd_solver.cpp:105] Iteration 94840, lr = 1.96221e-06
I1029 17:05:22.032435 12802 solver.cpp:222] Iteration 94880 (1.36951 iter/s, 29.2075s/40 iters), loss = 1.23122
I1029 17:05:22.032639 12802 solver.cpp:241]     Train net output #0: loss = 1.23122 (* 1 = 1.23122 loss)
I1029 17:05:22.032655 12802 sgd_solver.cpp:105] Iteration 94880, lr = 1.95516e-06
I1029 17:05:51.391834 12802 solver.cpp:222] Iteration 94920 (1.36247 iter/s, 29.3585s/40 iters), loss = 1.09287
I1029 17:05:51.391890 12802 solver.cpp:241]     Train net output #0: loss = 1.09287 (* 1 = 1.09287 loss)
I1029 17:05:51.391903 12802 sgd_solver.cpp:105] Iteration 94920, lr = 1.94813e-06
I1029 17:06:21.219040 12802 solver.cpp:222] Iteration 94960 (1.34109 iter/s, 29.8264s/40 iters), loss = 1.47093
I1029 17:06:21.219235 12802 solver.cpp:241]     Train net output #0: loss = 1.47093 (* 1 = 1.47093 loss)
I1029 17:06:21.219252 12802 sgd_solver.cpp:105] Iteration 94960, lr = 1.94113e-06
I1029 17:06:50.965330 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_95000.caffemodel
I1029 17:06:51.288564 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_95000.solverstate
I1029 17:06:51.529636 12802 solver.cpp:334] Iteration 95000, Testing net (#0)
I1029 17:07:22.691601 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58968
I1029 17:07:22.691748 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80984
I1029 17:07:22.691762 12802 solver.cpp:401]     Test net output #2: loss = 1.82842 (* 1 = 1.82842 loss)
I1029 17:07:23.462370 12802 solver.cpp:222] Iteration 95000 (0.642656 iter/s, 62.2417s/40 iters), loss = 1.29967
I1029 17:07:23.462430 12802 solver.cpp:241]     Train net output #0: loss = 1.29967 (* 1 = 1.29967 loss)
I1029 17:07:23.462455 12802 sgd_solver.cpp:105] Iteration 95000, lr = 1.93415e-06
I1029 17:07:54.122841 12802 solver.cpp:222] Iteration 95040 (1.30465 iter/s, 30.6597s/40 iters), loss = 1.647
I1029 17:07:54.123001 12802 solver.cpp:241]     Train net output #0: loss = 1.647 (* 1 = 1.647 loss)
I1029 17:07:54.123018 12802 sgd_solver.cpp:105] Iteration 95040, lr = 1.9272e-06
I1029 17:08:24.903007 12802 solver.cpp:222] Iteration 95080 (1.29958 iter/s, 30.7793s/40 iters), loss = 1.32956
I1029 17:08:24.903170 12802 solver.cpp:241]     Train net output #0: loss = 1.32956 (* 1 = 1.32956 loss)
I1029 17:08:24.903187 12802 sgd_solver.cpp:105] Iteration 95080, lr = 1.92028e-06
I1029 17:08:55.752274 12802 solver.cpp:222] Iteration 95120 (1.29667 iter/s, 30.8484s/40 iters), loss = 1.18215
I1029 17:08:55.752416 12802 solver.cpp:241]     Train net output #0: loss = 1.18215 (* 1 = 1.18215 loss)
I1029 17:08:55.752431 12802 sgd_solver.cpp:105] Iteration 95120, lr = 1.91337e-06
I1029 17:09:26.562170 12802 solver.cpp:222] Iteration 95160 (1.29832 iter/s, 30.809s/40 iters), loss = 1.34404
I1029 17:09:26.562317 12802 solver.cpp:241]     Train net output #0: loss = 1.34404 (* 1 = 1.34404 loss)
I1029 17:09:26.562335 12802 sgd_solver.cpp:105] Iteration 95160, lr = 1.9065e-06
I1029 17:09:56.831928 12802 solver.cpp:222] Iteration 95200 (1.32149 iter/s, 30.2689s/40 iters), loss = 1.34427
I1029 17:09:56.832118 12802 solver.cpp:241]     Train net output #0: loss = 1.34427 (* 1 = 1.34427 loss)
I1029 17:09:56.832137 12802 sgd_solver.cpp:105] Iteration 95200, lr = 1.89965e-06
I1029 17:10:26.559150 12802 solver.cpp:222] Iteration 95240 (1.34561 iter/s, 29.7263s/40 iters), loss = 1.36403
I1029 17:10:26.559208 12802 solver.cpp:241]     Train net output #0: loss = 1.36403 (* 1 = 1.36403 loss)
I1029 17:10:26.559224 12802 sgd_solver.cpp:105] Iteration 95240, lr = 1.89282e-06
I1029 17:10:56.209741 12802 solver.cpp:222] Iteration 95280 (1.34908 iter/s, 29.6498s/40 iters), loss = 1.40209
I1029 17:10:56.209950 12802 solver.cpp:241]     Train net output #0: loss = 1.40209 (* 1 = 1.40209 loss)
I1029 17:10:56.209967 12802 sgd_solver.cpp:105] Iteration 95280, lr = 1.88602e-06
I1029 17:11:25.723212 12802 solver.cpp:222] Iteration 95320 (1.35536 iter/s, 29.5126s/40 iters), loss = 1.28473
I1029 17:11:25.723263 12802 solver.cpp:241]     Train net output #0: loss = 1.28473 (* 1 = 1.28473 loss)
I1029 17:11:25.723278 12802 sgd_solver.cpp:105] Iteration 95320, lr = 1.87924e-06
I1029 17:11:55.895828 12802 solver.cpp:222] Iteration 95360 (1.32574 iter/s, 30.1718s/40 iters), loss = 1.30327
I1029 17:11:55.896059 12802 solver.cpp:241]     Train net output #0: loss = 1.30327 (* 1 = 1.30327 loss)
I1029 17:11:55.896078 12802 sgd_solver.cpp:105] Iteration 95360, lr = 1.87249e-06
I1029 17:12:26.811497 12802 solver.cpp:222] Iteration 95400 (1.29388 iter/s, 30.9147s/40 iters), loss = 1.32005
I1029 17:12:26.811673 12802 solver.cpp:241]     Train net output #0: loss = 1.32005 (* 1 = 1.32005 loss)
I1029 17:12:26.811691 12802 sgd_solver.cpp:105] Iteration 95400, lr = 1.86576e-06
I1029 17:12:57.082542 12802 solver.cpp:222] Iteration 95440 (1.32143 iter/s, 30.2701s/40 iters), loss = 1.34222
I1029 17:12:57.082720 12802 solver.cpp:241]     Train net output #0: loss = 1.34222 (* 1 = 1.34222 loss)
I1029 17:12:57.082739 12802 sgd_solver.cpp:105] Iteration 95440, lr = 1.85905e-06
I1029 17:13:27.602876 12802 solver.cpp:222] Iteration 95480 (1.31064 iter/s, 30.5194s/40 iters), loss = 1.25848
I1029 17:13:27.603018 12802 solver.cpp:241]     Train net output #0: loss = 1.25848 (* 1 = 1.25848 loss)
I1029 17:13:27.609444 12802 sgd_solver.cpp:105] Iteration 95480, lr = 1.85237e-06
I1029 17:13:42.342483 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_95500.caffemodel
I1029 17:13:42.481369 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_95500.solverstate
I1029 17:13:42.598892 12802 solver.cpp:334] Iteration 95500, Testing net (#0)
I1029 17:14:13.615445 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 17:14:13.823611 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58548
I1029 17:14:13.823673 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81536
I1029 17:14:13.823684 12802 solver.cpp:401]     Test net output #2: loss = 1.83246 (* 1 = 1.83246 loss)
I1029 17:14:29.905241 12802 solver.cpp:222] Iteration 95520 (0.642047 iter/s, 62.3008s/40 iters), loss = 1.19395
I1029 17:14:29.905303 12802 solver.cpp:241]     Train net output #0: loss = 1.19395 (* 1 = 1.19395 loss)
I1029 17:14:29.905320 12802 sgd_solver.cpp:105] Iteration 95520, lr = 1.84571e-06
I1029 17:15:00.582871 12802 solver.cpp:222] Iteration 95560 (1.30392 iter/s, 30.6768s/40 iters), loss = 1.364
I1029 17:15:00.583084 12802 solver.cpp:241]     Train net output #0: loss = 1.364 (* 1 = 1.364 loss)
I1029 17:15:00.583101 12802 sgd_solver.cpp:105] Iteration 95560, lr = 1.83908e-06
I1029 17:15:31.377506 12802 solver.cpp:222] Iteration 95600 (1.29897 iter/s, 30.7937s/40 iters), loss = 1.64248
I1029 17:15:31.377698 12802 solver.cpp:241]     Train net output #0: loss = 1.64248 (* 1 = 1.64248 loss)
I1029 17:15:31.377715 12802 sgd_solver.cpp:105] Iteration 95600, lr = 1.83247e-06
I1029 17:16:02.203064 12802 solver.cpp:222] Iteration 95640 (1.29766 iter/s, 30.8246s/40 iters), loss = 1.40939
I1029 17:16:02.203232 12802 solver.cpp:241]     Train net output #0: loss = 1.40939 (* 1 = 1.40939 loss)
I1029 17:16:02.203246 12802 sgd_solver.cpp:105] Iteration 95640, lr = 1.82588e-06
I1029 17:16:33.349822 12802 solver.cpp:222] Iteration 95680 (1.28428 iter/s, 31.1458s/40 iters), loss = 1.43342
I1029 17:16:33.350004 12802 solver.cpp:241]     Train net output #0: loss = 1.43342 (* 1 = 1.43342 loss)
I1029 17:16:33.350020 12802 sgd_solver.cpp:105] Iteration 95680, lr = 1.81932e-06
I1029 17:17:04.198153 12802 solver.cpp:222] Iteration 95720 (1.29671 iter/s, 30.8474s/40 iters), loss = 1.64797
I1029 17:17:04.198329 12802 solver.cpp:241]     Train net output #0: loss = 1.64797 (* 1 = 1.64797 loss)
I1029 17:17:04.198346 12802 sgd_solver.cpp:105] Iteration 95720, lr = 1.81278e-06
I1029 17:17:36.723995 12802 solver.cpp:222] Iteration 95760 (1.22983 iter/s, 32.5249s/40 iters), loss = 1.45956
I1029 17:17:36.724187 12802 solver.cpp:241]     Train net output #0: loss = 1.45956 (* 1 = 1.45956 loss)
I1029 17:17:36.724202 12802 sgd_solver.cpp:105] Iteration 95760, lr = 1.80627e-06
I1029 17:18:18.308441 12802 solver.cpp:222] Iteration 95800 (0.961925 iter/s, 41.5833s/40 iters), loss = 1.2965
I1029 17:18:18.308636 12802 solver.cpp:241]     Train net output #0: loss = 1.2965 (* 1 = 1.2965 loss)
I1029 17:18:18.308653 12802 sgd_solver.cpp:105] Iteration 95800, lr = 1.79978e-06
I1029 17:18:50.049393 12802 solver.cpp:222] Iteration 95840 (1.26024 iter/s, 31.74s/40 iters), loss = 1.3207
I1029 17:18:50.049582 12802 solver.cpp:241]     Train net output #0: loss = 1.3207 (* 1 = 1.3207 loss)
I1029 17:18:50.049598 12802 sgd_solver.cpp:105] Iteration 95840, lr = 1.79331e-06
I1029 17:19:57.735541 12802 solver.cpp:222] Iteration 95880 (0.590978 iter/s, 67.6844s/40 iters), loss = 1.5783
I1029 17:19:57.735750 12802 solver.cpp:241]     Train net output #0: loss = 1.5783 (* 1 = 1.5783 loss)
I1029 17:19:57.735767 12802 sgd_solver.cpp:105] Iteration 95880, lr = 1.78687e-06
I1029 17:20:35.344633 12802 solver.cpp:222] Iteration 95920 (1.0636 iter/s, 37.608s/40 iters), loss = 1.3676
I1029 17:20:35.344817 12802 solver.cpp:241]     Train net output #0: loss = 1.3676 (* 1 = 1.3676 loss)
I1029 17:20:35.344835 12802 sgd_solver.cpp:105] Iteration 95920, lr = 1.78044e-06
I1029 17:21:05.821974 12802 solver.cpp:222] Iteration 95960 (1.31249 iter/s, 30.4764s/40 iters), loss = 1.09774
I1029 17:21:05.822180 12802 solver.cpp:241]     Train net output #0: loss = 1.09774 (* 1 = 1.09774 loss)
I1029 17:21:05.822201 12802 sgd_solver.cpp:105] Iteration 95960, lr = 1.77405e-06
I1029 17:21:42.479816 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_96000.caffemodel
I1029 17:21:42.624001 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_96000.solverstate
I1029 17:21:42.789742 12802 solver.cpp:334] Iteration 96000, Testing net (#0)
I1029 17:22:13.939967 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5896
I1029 17:22:13.940135 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80956
I1029 17:22:13.940148 12802 solver.cpp:401]     Test net output #2: loss = 1.82743 (* 1 = 1.82743 loss)
I1029 17:22:14.703902 12802 solver.cpp:222] Iteration 96000 (0.580719 iter/s, 68.8801s/40 iters), loss = 1.31648
I1029 17:22:14.703966 12802 solver.cpp:241]     Train net output #0: loss = 1.31648 (* 1 = 1.31648 loss)
I1029 17:22:14.703982 12802 sgd_solver.cpp:105] Iteration 96000, lr = 1.76767e-06
I1029 17:22:45.647496 12802 solver.cpp:222] Iteration 96040 (1.29271 iter/s, 30.9428s/40 iters), loss = 1.46891
I1029 17:22:45.647693 12802 solver.cpp:241]     Train net output #0: loss = 1.46891 (* 1 = 1.46891 loss)
I1029 17:22:45.647711 12802 sgd_solver.cpp:105] Iteration 96040, lr = 1.76132e-06
I1029 17:23:15.395807 12802 solver.cpp:222] Iteration 96080 (1.34466 iter/s, 29.7474s/40 iters), loss = 1.36386
I1029 17:23:15.395867 12802 solver.cpp:241]     Train net output #0: loss = 1.36386 (* 1 = 1.36386 loss)
I1029 17:23:15.395884 12802 sgd_solver.cpp:105] Iteration 96080, lr = 1.75499e-06
I1029 17:23:45.145408 12802 solver.cpp:222] Iteration 96120 (1.34459 iter/s, 29.7488s/40 iters), loss = 1.22983
I1029 17:23:45.145586 12802 solver.cpp:241]     Train net output #0: loss = 1.22983 (* 1 = 1.22983 loss)
I1029 17:23:45.145602 12802 sgd_solver.cpp:105] Iteration 96120, lr = 1.74868e-06
I1029 17:24:15.794338 12802 solver.cpp:222] Iteration 96160 (1.30514 iter/s, 30.648s/40 iters), loss = 1.44538
I1029 17:24:15.794551 12802 solver.cpp:241]     Train net output #0: loss = 1.44538 (* 1 = 1.44538 loss)
I1029 17:24:15.794569 12802 sgd_solver.cpp:105] Iteration 96160, lr = 1.7424e-06
I1029 17:24:22.728302 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 17:24:45.870285 12802 solver.cpp:222] Iteration 96200 (1.33001 iter/s, 30.075s/40 iters), loss = 1.45713
I1029 17:24:45.870467 12802 solver.cpp:241]     Train net output #0: loss = 1.45713 (* 1 = 1.45713 loss)
I1029 17:24:45.870484 12802 sgd_solver.cpp:105] Iteration 96200, lr = 1.73613e-06
I1029 17:25:15.254209 12802 solver.cpp:222] Iteration 96240 (1.36133 iter/s, 29.383s/40 iters), loss = 1.37362
I1029 17:25:15.254266 12802 solver.cpp:241]     Train net output #0: loss = 1.37362 (* 1 = 1.37362 loss)
I1029 17:25:15.254281 12802 sgd_solver.cpp:105] Iteration 96240, lr = 1.72989e-06
I1029 17:25:45.440848 12802 solver.cpp:222] Iteration 96280 (1.32512 iter/s, 30.1859s/40 iters), loss = 1.46888
I1029 17:25:45.441110 12802 solver.cpp:241]     Train net output #0: loss = 1.46888 (* 1 = 1.46888 loss)
I1029 17:25:45.441129 12802 sgd_solver.cpp:105] Iteration 96280, lr = 1.72368e-06
I1029 17:26:15.006269 12802 solver.cpp:222] Iteration 96320 (1.35298 iter/s, 29.5644s/40 iters), loss = 1.1651
I1029 17:26:15.006326 12802 solver.cpp:241]     Train net output #0: loss = 1.1651 (* 1 = 1.1651 loss)
I1029 17:26:15.006340 12802 sgd_solver.cpp:105] Iteration 96320, lr = 1.71748e-06
I1029 17:26:44.846168 12802 solver.cpp:222] Iteration 96360 (1.34052 iter/s, 29.8391s/40 iters), loss = 1.15559
I1029 17:26:44.846318 12802 solver.cpp:241]     Train net output #0: loss = 1.15559 (* 1 = 1.15559 loss)
I1029 17:26:44.846334 12802 sgd_solver.cpp:105] Iteration 96360, lr = 1.71131e-06
I1029 17:27:14.462014 12802 solver.cpp:222] Iteration 96400 (1.35067 iter/s, 29.615s/40 iters), loss = 0.900857
I1029 17:27:14.462074 12802 solver.cpp:241]     Train net output #0: loss = 0.900857 (* 1 = 0.900857 loss)
I1029 17:27:14.462086 12802 sgd_solver.cpp:105] Iteration 96400, lr = 1.70516e-06
I1029 17:27:44.091400 12802 solver.cpp:222] Iteration 96440 (1.35005 iter/s, 29.6286s/40 iters), loss = 1.20014
I1029 17:27:44.091562 12802 solver.cpp:241]     Train net output #0: loss = 1.20014 (* 1 = 1.20014 loss)
I1029 17:27:44.091576 12802 sgd_solver.cpp:105] Iteration 96440, lr = 1.69903e-06
I1029 17:28:14.413821 12802 solver.cpp:222] Iteration 96480 (1.31919 iter/s, 30.3215s/40 iters), loss = 1.52266
I1029 17:28:14.414046 12802 solver.cpp:241]     Train net output #0: loss = 1.52266 (* 1 = 1.52266 loss)
I1029 17:28:14.414063 12802 sgd_solver.cpp:105] Iteration 96480, lr = 1.69293e-06
I1029 17:28:28.767441 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_96500.caffemodel
I1029 17:28:28.918712 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_96500.solverstate
I1029 17:28:29.040971 12802 solver.cpp:334] Iteration 96500, Testing net (#0)
I1029 17:28:59.912693 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 17:29:00.120214 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58536
I1029 17:29:00.120265 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81516
I1029 17:29:00.120276 12802 solver.cpp:401]     Test net output #2: loss = 1.83337 (* 1 = 1.83337 loss)
I1029 17:29:16.241576 12802 solver.cpp:222] Iteration 96520 (0.646976 iter/s, 61.8261s/40 iters), loss = 1.34713
I1029 17:29:16.241636 12802 solver.cpp:241]     Train net output #0: loss = 1.34713 (* 1 = 1.34713 loss)
I1029 17:29:16.241653 12802 sgd_solver.cpp:105] Iteration 96520, lr = 1.68684e-06
I1029 17:29:46.915145 12802 solver.cpp:222] Iteration 96560 (1.30409 iter/s, 30.6728s/40 iters), loss = 1.36946
I1029 17:29:46.915331 12802 solver.cpp:241]     Train net output #0: loss = 1.36946 (* 1 = 1.36946 loss)
I1029 17:29:46.915349 12802 sgd_solver.cpp:105] Iteration 96560, lr = 1.68078e-06
I1029 17:30:16.602218 12802 solver.cpp:222] Iteration 96600 (1.34743 iter/s, 29.6862s/40 iters), loss = 1.29556
I1029 17:30:16.602279 12802 solver.cpp:241]     Train net output #0: loss = 1.29556 (* 1 = 1.29556 loss)
I1029 17:30:16.602294 12802 sgd_solver.cpp:105] Iteration 96600, lr = 1.67474e-06
I1029 17:30:47.070849 12802 solver.cpp:222] Iteration 96640 (1.31286 iter/s, 30.4678s/40 iters), loss = 1.56901
I1029 17:30:47.071058 12802 solver.cpp:241]     Train net output #0: loss = 1.56901 (* 1 = 1.56901 loss)
I1029 17:30:47.071076 12802 sgd_solver.cpp:105] Iteration 96640, lr = 1.66872e-06
I1029 17:31:16.954516 12802 solver.cpp:222] Iteration 96680 (1.33857 iter/s, 29.8827s/40 iters), loss = 1.68364
I1029 17:31:16.954572 12802 solver.cpp:241]     Train net output #0: loss = 1.68364 (* 1 = 1.68364 loss)
I1029 17:31:16.954587 12802 sgd_solver.cpp:105] Iteration 96680, lr = 1.66272e-06
I1029 17:31:46.777788 12802 solver.cpp:222] Iteration 96720 (1.34127 iter/s, 29.8225s/40 iters), loss = 1.43258
I1029 17:31:46.778045 12802 solver.cpp:241]     Train net output #0: loss = 1.43258 (* 1 = 1.43258 loss)
I1029 17:31:46.778069 12802 sgd_solver.cpp:105] Iteration 96720, lr = 1.65675e-06
I1029 17:32:17.712251 12802 solver.cpp:222] Iteration 96760 (1.2931 iter/s, 30.9335s/40 iters), loss = 1.12264
I1029 17:32:17.712415 12802 solver.cpp:241]     Train net output #0: loss = 1.12264 (* 1 = 1.12264 loss)
I1029 17:32:17.712430 12802 sgd_solver.cpp:105] Iteration 96760, lr = 1.65079e-06
I1029 17:32:48.093407 12802 solver.cpp:222] Iteration 96800 (1.31664 iter/s, 30.3803s/40 iters), loss = 1.15192
I1029 17:32:48.093490 12802 solver.cpp:241]     Train net output #0: loss = 1.15192 (* 1 = 1.15192 loss)
I1029 17:32:48.093506 12802 sgd_solver.cpp:105] Iteration 96800, lr = 1.64486e-06
I1029 17:33:17.894470 12802 solver.cpp:222] Iteration 96840 (1.34227 iter/s, 29.8003s/40 iters), loss = 1.46802
I1029 17:33:17.894533 12802 solver.cpp:241]     Train net output #0: loss = 1.46802 (* 1 = 1.46802 loss)
I1029 17:33:17.894546 12802 sgd_solver.cpp:105] Iteration 96840, lr = 1.63895e-06
I1029 17:33:48.060886 12802 solver.cpp:222] Iteration 96880 (1.32601 iter/s, 30.1656s/40 iters), loss = 1.40779
I1029 17:33:48.060986 12802 solver.cpp:241]     Train net output #0: loss = 1.40779 (* 1 = 1.40779 loss)
I1029 17:33:48.061002 12802 sgd_solver.cpp:105] Iteration 96880, lr = 1.63306e-06
I1029 17:34:17.468945 12802 solver.cpp:222] Iteration 96920 (1.36021 iter/s, 29.4073s/40 iters), loss = 1.46346
I1029 17:34:17.469007 12802 solver.cpp:241]     Train net output #0: loss = 1.46346 (* 1 = 1.46346 loss)
I1029 17:34:17.469022 12802 sgd_solver.cpp:105] Iteration 96920, lr = 1.62719e-06
I1029 17:34:46.960093 12802 solver.cpp:222] Iteration 96960 (1.35637 iter/s, 29.4904s/40 iters), loss = 1.41922
I1029 17:34:46.960187 12802 solver.cpp:241]     Train net output #0: loss = 1.41922 (* 1 = 1.41922 loss)
I1029 17:34:46.960204 12802 sgd_solver.cpp:105] Iteration 96960, lr = 1.62134e-06
I1029 17:35:15.728647 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_97000.caffemodel
I1029 17:35:15.875674 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_97000.solverstate
I1029 17:35:15.990854 12802 solver.cpp:334] Iteration 97000, Testing net (#0)
I1029 17:35:47.188845 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5894
I1029 17:35:47.189085 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8098
I1029 17:35:47.189105 12802 solver.cpp:401]     Test net output #2: loss = 1.82921 (* 1 = 1.82921 loss)
I1029 17:35:47.952602 12802 solver.cpp:222] Iteration 97000 (0.655835 iter/s, 60.991s/40 iters), loss = 1.2003
I1029 17:35:47.952663 12802 solver.cpp:241]     Train net output #0: loss = 1.2003 (* 1 = 1.2003 loss)
I1029 17:35:47.952683 12802 sgd_solver.cpp:105] Iteration 97000, lr = 1.61552e-06
I1029 17:36:17.846953 12802 solver.cpp:222] Iteration 97040 (1.33808 iter/s, 29.8936s/40 iters), loss = 1.26689
I1029 17:36:17.847115 12802 solver.cpp:241]     Train net output #0: loss = 1.26689 (* 1 = 1.26689 loss)
I1029 17:36:17.847129 12802 sgd_solver.cpp:105] Iteration 97040, lr = 1.60971e-06
I1029 17:36:47.257525 12802 solver.cpp:222] Iteration 97080 (1.3601 iter/s, 29.4097s/40 iters), loss = 1.14377
I1029 17:36:47.257585 12802 solver.cpp:241]     Train net output #0: loss = 1.14377 (* 1 = 1.14377 loss)
I1029 17:36:47.257598 12802 sgd_solver.cpp:105] Iteration 97080, lr = 1.60393e-06
I1029 17:37:16.831912 12802 solver.cpp:222] Iteration 97120 (1.35256 iter/s, 29.5736s/40 iters), loss = 1.39046
I1029 17:37:16.832154 12802 solver.cpp:241]     Train net output #0: loss = 1.39046 (* 1 = 1.39046 loss)
I1029 17:37:16.832175 12802 sgd_solver.cpp:105] Iteration 97120, lr = 1.59816e-06
I1029 17:37:47.469712 12802 solver.cpp:222] Iteration 97160 (1.30562 iter/s, 30.6368s/40 iters), loss = 1.2628
I1029 17:37:47.469890 12802 solver.cpp:241]     Train net output #0: loss = 1.2628 (* 1 = 1.2628 loss)
I1029 17:37:47.469907 12802 sgd_solver.cpp:105] Iteration 97160, lr = 1.59242e-06
I1029 17:38:18.336165 12802 solver.cpp:222] Iteration 97200 (1.29594 iter/s, 30.8655s/40 iters), loss = 1.43453
I1029 17:38:18.336329 12802 solver.cpp:241]     Train net output #0: loss = 1.43453 (* 1 = 1.43453 loss)
I1029 17:38:18.336347 12802 sgd_solver.cpp:105] Iteration 97200, lr = 1.5867e-06
I1029 17:38:48.167374 12802 solver.cpp:222] Iteration 97240 (1.34092 iter/s, 29.8303s/40 iters), loss = 1.2524
I1029 17:38:48.167426 12802 solver.cpp:241]     Train net output #0: loss = 1.2524 (* 1 = 1.2524 loss)
I1029 17:38:48.167439 12802 sgd_solver.cpp:105] Iteration 97240, lr = 1.58099e-06
I1029 17:39:19.183780 12802 solver.cpp:222] Iteration 97280 (1.28967 iter/s, 31.0156s/40 iters), loss = 1.54682
I1029 17:39:19.184018 12802 solver.cpp:241]     Train net output #0: loss = 1.54682 (* 1 = 1.54682 loss)
I1029 17:39:19.184036 12802 sgd_solver.cpp:105] Iteration 97280, lr = 1.57531e-06
I1029 17:39:49.850523 12802 solver.cpp:222] Iteration 97320 (1.30439 iter/s, 30.6658s/40 iters), loss = 1.46197
I1029 17:39:49.850677 12802 solver.cpp:241]     Train net output #0: loss = 1.46197 (* 1 = 1.46197 loss)
I1029 17:39:49.850695 12802 sgd_solver.cpp:105] Iteration 97320, lr = 1.56965e-06
I1029 17:40:20.406038 12802 solver.cpp:222] Iteration 97360 (1.30913 iter/s, 30.5546s/40 iters), loss = 1.2629
I1029 17:40:20.406220 12802 solver.cpp:241]     Train net output #0: loss = 1.2629 (* 1 = 1.2629 loss)
I1029 17:40:20.406251 12802 sgd_solver.cpp:105] Iteration 97360, lr = 1.56401e-06
I1029 17:40:50.994904 12802 solver.cpp:222] Iteration 97400 (1.3077 iter/s, 30.588s/40 iters), loss = 1.68493
I1029 17:40:50.995065 12802 solver.cpp:241]     Train net output #0: loss = 1.68493 (* 1 = 1.68493 loss)
I1029 17:40:50.995084 12802 sgd_solver.cpp:105] Iteration 97400, lr = 1.55839e-06
I1029 17:41:21.040951 12802 solver.cpp:222] Iteration 97440 (1.33133 iter/s, 30.0452s/40 iters), loss = 1.55697
I1029 17:41:21.041100 12802 solver.cpp:241]     Train net output #0: loss = 1.55697 (* 1 = 1.55697 loss)
I1029 17:41:21.041117 12802 sgd_solver.cpp:105] Iteration 97440, lr = 1.55279e-06
I1029 17:41:50.694559 12802 solver.cpp:222] Iteration 97480 (1.34895 iter/s, 29.6527s/40 iters), loss = 1.29129
I1029 17:41:50.694627 12802 solver.cpp:241]     Train net output #0: loss = 1.29129 (* 1 = 1.29129 loss)
I1029 17:41:50.694643 12802 sgd_solver.cpp:105] Iteration 97480, lr = 1.54721e-06
I1029 17:42:05.125706 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_97500.caffemodel
I1029 17:42:16.040451 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_97500.solverstate
I1029 17:42:16.943820 12802 solver.cpp:334] Iteration 97500, Testing net (#0)
I1029 17:42:47.924170 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 17:42:48.136023 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5856
I1029 17:42:48.136075 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81548
I1029 17:42:48.136085 12802 solver.cpp:401]     Test net output #2: loss = 1.83263 (* 1 = 1.83263 loss)
I1029 17:43:04.161517 12802 solver.cpp:222] Iteration 97520 (0.544476 iter/s, 73.4652s/40 iters), loss = 1.55669
I1029 17:43:04.161573 12802 solver.cpp:241]     Train net output #0: loss = 1.55669 (* 1 = 1.55669 loss)
I1029 17:43:04.161587 12802 sgd_solver.cpp:105] Iteration 97520, lr = 1.54165e-06
I1029 17:43:34.678594 12802 solver.cpp:222] Iteration 97560 (1.31078 iter/s, 30.5163s/40 iters), loss = 1.50258
I1029 17:43:34.678686 12802 solver.cpp:241]     Train net output #0: loss = 1.50258 (* 1 = 1.50258 loss)
I1029 17:43:34.678700 12802 sgd_solver.cpp:105] Iteration 97560, lr = 1.53611e-06
I1029 17:44:05.217463 12802 solver.cpp:222] Iteration 97600 (1.30984 iter/s, 30.538s/40 iters), loss = 1.46332
I1029 17:44:05.217627 12802 solver.cpp:241]     Train net output #0: loss = 1.46332 (* 1 = 1.46332 loss)
I1029 17:44:05.217644 12802 sgd_solver.cpp:105] Iteration 97600, lr = 1.53059e-06
I1029 17:44:35.923533 12802 solver.cpp:222] Iteration 97640 (1.30271 iter/s, 30.7052s/40 iters), loss = 1.32429
I1029 17:44:35.923686 12802 solver.cpp:241]     Train net output #0: loss = 1.32429 (* 1 = 1.32429 loss)
I1029 17:44:35.923701 12802 sgd_solver.cpp:105] Iteration 97640, lr = 1.52509e-06
I1029 17:45:10.150161 12802 solver.cpp:222] Iteration 97680 (1.16871 iter/s, 34.2257s/40 iters), loss = 1.38063
I1029 17:45:10.150352 12802 solver.cpp:241]     Train net output #0: loss = 1.38063 (* 1 = 1.38063 loss)
I1029 17:45:10.150370 12802 sgd_solver.cpp:105] Iteration 97680, lr = 1.5196e-06
I1029 17:45:40.769218 12802 solver.cpp:222] Iteration 97720 (1.30642 iter/s, 30.6181s/40 iters), loss = 1.41562
I1029 17:45:40.769412 12802 solver.cpp:241]     Train net output #0: loss = 1.41562 (* 1 = 1.41562 loss)
I1029 17:45:40.769430 12802 sgd_solver.cpp:105] Iteration 97720, lr = 1.51414e-06
I1029 17:46:11.707221 12802 solver.cpp:222] Iteration 97760 (1.29295 iter/s, 30.9371s/40 iters), loss = 1.81707
I1029 17:46:11.707418 12802 solver.cpp:241]     Train net output #0: loss = 1.81707 (* 1 = 1.81707 loss)
I1029 17:46:11.707435 12802 sgd_solver.cpp:105] Iteration 97760, lr = 1.5087e-06
I1029 17:46:42.651540 12802 solver.cpp:222] Iteration 97800 (1.29268 iter/s, 30.9434s/40 iters), loss = 1.39634
I1029 17:46:42.651727 12802 solver.cpp:241]     Train net output #0: loss = 1.39634 (* 1 = 1.39634 loss)
I1029 17:46:42.651741 12802 sgd_solver.cpp:105] Iteration 97800, lr = 1.50328e-06
I1029 17:47:31.308954 12802 solver.cpp:222] Iteration 97840 (0.822097 iter/s, 48.6561s/40 iters), loss = 1.49129
I1029 17:47:31.309151 12802 solver.cpp:241]     Train net output #0: loss = 1.49129 (* 1 = 1.49129 loss)
I1029 17:47:31.309170 12802 sgd_solver.cpp:105] Iteration 97840, lr = 1.49788e-06
I1029 17:48:01.510936 12802 solver.cpp:222] Iteration 97880 (1.32446 iter/s, 30.2011s/40 iters), loss = 1.18494
I1029 17:48:01.511129 12802 solver.cpp:241]     Train net output #0: loss = 1.18494 (* 1 = 1.18494 loss)
I1029 17:48:01.511147 12802 sgd_solver.cpp:105] Iteration 97880, lr = 1.49249e-06
I1029 17:48:31.558930 12802 solver.cpp:222] Iteration 97920 (1.33124 iter/s, 30.0471s/40 iters), loss = 1.35008
I1029 17:48:31.559106 12802 solver.cpp:241]     Train net output #0: loss = 1.35008 (* 1 = 1.35008 loss)
I1029 17:48:31.559123 12802 sgd_solver.cpp:105] Iteration 97920, lr = 1.48713e-06
I1029 17:49:01.592388 12802 solver.cpp:222] Iteration 97960 (1.33189 iter/s, 30.0326s/40 iters), loss = 1.32855
I1029 17:49:01.592568 12802 solver.cpp:241]     Train net output #0: loss = 1.32855 (* 1 = 1.32855 loss)
I1029 17:49:01.592586 12802 sgd_solver.cpp:105] Iteration 97960, lr = 1.48179e-06
I1029 17:49:31.641218 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_98000.caffemodel
I1029 17:49:31.786075 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_98000.solverstate
I1029 17:49:31.900751 12802 solver.cpp:334] Iteration 98000, Testing net (#0)
I1029 17:50:03.061545 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58952
I1029 17:50:03.061722 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8098
I1029 17:50:03.061736 12802 solver.cpp:401]     Test net output #2: loss = 1.82787 (* 1 = 1.82787 loss)
I1029 17:50:03.837988 12802 solver.cpp:222] Iteration 98000 (0.642633 iter/s, 62.244s/40 iters), loss = 1.40676
I1029 17:50:03.838049 12802 solver.cpp:241]     Train net output #0: loss = 1.40676 (* 1 = 1.40676 loss)
I1029 17:50:03.838071 12802 sgd_solver.cpp:105] Iteration 98000, lr = 1.47646e-06
I1029 17:50:34.716480 12802 solver.cpp:222] Iteration 98040 (1.29543 iter/s, 30.8777s/40 iters), loss = 1.27019
I1029 17:50:34.716720 12802 solver.cpp:241]     Train net output #0: loss = 1.27019 (* 1 = 1.27019 loss)
I1029 17:50:34.716738 12802 sgd_solver.cpp:105] Iteration 98040, lr = 1.47115e-06
I1029 17:51:05.836156 12802 solver.cpp:222] Iteration 98080 (1.2854 iter/s, 31.1187s/40 iters), loss = 1.4501
I1029 17:51:05.836340 12802 solver.cpp:241]     Train net output #0: loss = 1.4501 (* 1 = 1.4501 loss)
I1029 17:51:05.836359 12802 sgd_solver.cpp:105] Iteration 98080, lr = 1.46587e-06
I1029 17:52:50.481616 12802 solver.cpp:222] Iteration 98120 (0.382253 iter/s, 104.643s/40 iters), loss = 1.49756
I1029 17:52:50.481820 12802 solver.cpp:241]     Train net output #0: loss = 1.49756 (* 1 = 1.49756 loss)
I1029 17:52:50.481842 12802 sgd_solver.cpp:105] Iteration 98120, lr = 1.4606e-06
I1029 17:53:39.154824 12802 solver.cpp:222] Iteration 98160 (0.82183 iter/s, 48.6719s/40 iters), loss = 1.32784
I1029 17:53:39.155037 12802 solver.cpp:241]     Train net output #0: loss = 1.32784 (* 1 = 1.32784 loss)
I1029 17:53:39.155062 12802 sgd_solver.cpp:105] Iteration 98160, lr = 1.45535e-06
I1029 17:54:35.166159 12802 solver.cpp:222] Iteration 98200 (0.71416 iter/s, 56.0098s/40 iters), loss = 1.39418
I1029 17:54:35.166354 12802 solver.cpp:241]     Train net output #0: loss = 1.39418 (* 1 = 1.39418 loss)
I1029 17:54:35.166371 12802 sgd_solver.cpp:105] Iteration 98200, lr = 1.45012e-06
I1029 17:55:05.594060 12802 solver.cpp:222] Iteration 98240 (1.31462 iter/s, 30.427s/40 iters), loss = 1.59918
I1029 17:55:05.594244 12802 solver.cpp:241]     Train net output #0: loss = 1.59918 (* 1 = 1.59918 loss)
I1029 17:55:05.594257 12802 sgd_solver.cpp:105] Iteration 98240, lr = 1.44491e-06
I1029 17:55:36.312714 12802 solver.cpp:222] Iteration 98280 (1.30218 iter/s, 30.7178s/40 iters), loss = 1.26629
I1029 17:55:36.312907 12802 solver.cpp:241]     Train net output #0: loss = 1.26629 (* 1 = 1.26629 loss)
I1029 17:55:36.312929 12802 sgd_solver.cpp:105] Iteration 98280, lr = 1.43972e-06
I1029 17:56:06.969405 12802 solver.cpp:222] Iteration 98320 (1.30481 iter/s, 30.6558s/40 iters), loss = 1.36746
I1029 17:56:06.969612 12802 solver.cpp:241]     Train net output #0: loss = 1.36746 (* 1 = 1.36746 loss)
I1029 17:56:06.969630 12802 sgd_solver.cpp:105] Iteration 98320, lr = 1.43454e-06
I1029 17:56:37.965934 12802 solver.cpp:222] Iteration 98360 (1.29051 iter/s, 30.9956s/40 iters), loss = 1.22969
I1029 17:56:37.966125 12802 solver.cpp:241]     Train net output #0: loss = 1.22969 (* 1 = 1.22969 loss)
I1029 17:56:37.966141 12802 sgd_solver.cpp:105] Iteration 98360, lr = 1.42939e-06
I1029 17:57:08.025306 12802 solver.cpp:222] Iteration 98400 (1.33074 iter/s, 30.0585s/40 iters), loss = 1.31944
I1029 17:57:08.025488 12802 solver.cpp:241]     Train net output #0: loss = 1.31944 (* 1 = 1.31944 loss)
I1029 17:57:08.025502 12802 sgd_solver.cpp:105] Iteration 98400, lr = 1.42425e-06
I1029 17:57:38.419265 12802 solver.cpp:222] Iteration 98440 (1.31609 iter/s, 30.3931s/40 iters), loss = 1.61616
I1029 17:57:38.419451 12802 solver.cpp:241]     Train net output #0: loss = 1.61616 (* 1 = 1.61616 loss)
I1029 17:57:38.419469 12802 sgd_solver.cpp:105] Iteration 98440, lr = 1.41913e-06
I1029 17:58:08.600993 12802 solver.cpp:222] Iteration 98480 (1.32534 iter/s, 30.1808s/40 iters), loss = 1.3333
I1029 17:58:08.601214 12802 solver.cpp:241]     Train net output #0: loss = 1.3333 (* 1 = 1.3333 loss)
I1029 17:58:08.601233 12802 sgd_solver.cpp:105] Iteration 98480, lr = 1.41403e-06
I1029 17:58:22.545650 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_98500.caffemodel
I1029 17:58:22.675765 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_98500.solverstate
I1029 17:58:22.795253 12802 solver.cpp:334] Iteration 98500, Testing net (#0)
I1029 17:58:53.910601 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 17:58:54.117600 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5854
I1029 17:58:54.117645 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81536
I1029 17:58:54.117656 12802 solver.cpp:401]     Test net output #2: loss = 1.83183 (* 1 = 1.83183 loss)
I1029 17:59:09.816126 12802 solver.cpp:222] Iteration 98520 (0.653451 iter/s, 61.2135s/40 iters), loss = 1.33685
I1029 17:59:09.816181 12802 solver.cpp:241]     Train net output #0: loss = 1.33685 (* 1 = 1.33685 loss)
I1029 17:59:09.816197 12802 sgd_solver.cpp:105] Iteration 98520, lr = 1.40895e-06
I1029 17:59:39.786263 12802 solver.cpp:222] Iteration 98560 (1.3347 iter/s, 29.9693s/40 iters), loss = 1.38104
I1029 17:59:39.786487 12802 solver.cpp:241]     Train net output #0: loss = 1.38104 (* 1 = 1.38104 loss)
I1029 17:59:39.786507 12802 sgd_solver.cpp:105] Iteration 98560, lr = 1.40389e-06
I1029 18:00:09.936858 12802 solver.cpp:222] Iteration 98600 (1.32671 iter/s, 30.1497s/40 iters), loss = 0.996624
I1029 18:00:09.937067 12802 solver.cpp:241]     Train net output #0: loss = 0.996624 (* 1 = 0.996624 loss)
I1029 18:00:09.937084 12802 sgd_solver.cpp:105] Iteration 98600, lr = 1.39884e-06
I1029 18:00:40.379534 12802 solver.cpp:222] Iteration 98640 (1.31399 iter/s, 30.4417s/40 iters), loss = 1.56353
I1029 18:00:40.379761 12802 solver.cpp:241]     Train net output #0: loss = 1.56353 (* 1 = 1.56353 loss)
I1029 18:00:40.379776 12802 sgd_solver.cpp:105] Iteration 98640, lr = 1.39381e-06
I1029 18:01:04.209614 12850 data_layer.cpp:73] Restarting data prefetching from start.
I1029 18:01:11.078819 12802 solver.cpp:222] Iteration 98680 (1.303 iter/s, 30.6983s/40 iters), loss = 1.55558
I1029 18:01:11.079005 12802 solver.cpp:241]     Train net output #0: loss = 1.55558 (* 1 = 1.55558 loss)
I1029 18:01:11.079022 12802 sgd_solver.cpp:105] Iteration 98680, lr = 1.3888e-06
I1029 18:01:42.225636 12802 solver.cpp:222] Iteration 98720 (1.28428 iter/s, 31.1459s/40 iters), loss = 1.21767
I1029 18:01:42.225816 12802 solver.cpp:241]     Train net output #0: loss = 1.21767 (* 1 = 1.21767 loss)
I1029 18:01:42.225832 12802 sgd_solver.cpp:105] Iteration 98720, lr = 1.38381e-06
I1029 18:02:12.581068 12802 solver.cpp:222] Iteration 98760 (1.31776 iter/s, 30.3545s/40 iters), loss = 1.34083
I1029 18:02:12.581254 12802 solver.cpp:241]     Train net output #0: loss = 1.34083 (* 1 = 1.34083 loss)
I1029 18:02:12.581272 12802 sgd_solver.cpp:105] Iteration 98760, lr = 1.37884e-06
I1029 18:02:42.598184 12802 solver.cpp:222] Iteration 98800 (1.33261 iter/s, 30.0162s/40 iters), loss = 1.77294
I1029 18:02:42.598388 12802 solver.cpp:241]     Train net output #0: loss = 1.77294 (* 1 = 1.77294 loss)
I1029 18:02:42.598404 12802 sgd_solver.cpp:105] Iteration 98800, lr = 1.37388e-06
I1029 18:03:12.140364 12802 solver.cpp:222] Iteration 98840 (1.35404 iter/s, 29.5413s/40 iters), loss = 1.14126
I1029 18:03:12.140422 12802 solver.cpp:241]     Train net output #0: loss = 1.14126 (* 1 = 1.14126 loss)
I1029 18:03:12.140436 12802 sgd_solver.cpp:105] Iteration 98840, lr = 1.36895e-06
I1029 18:03:41.519354 12802 solver.cpp:222] Iteration 98880 (1.36155 iter/s, 29.3782s/40 iters), loss = 1.26441
I1029 18:03:41.519518 12802 solver.cpp:241]     Train net output #0: loss = 1.26441 (* 1 = 1.26441 loss)
I1029 18:03:41.519536 12802 sgd_solver.cpp:105] Iteration 98880, lr = 1.36403e-06
I1029 18:04:11.091265 12802 solver.cpp:222] Iteration 98920 (1.35267 iter/s, 29.5711s/40 iters), loss = 1.37839
I1029 18:04:11.091323 12802 solver.cpp:241]     Train net output #0: loss = 1.37839 (* 1 = 1.37839 loss)
I1029 18:04:11.091339 12802 sgd_solver.cpp:105] Iteration 98920, lr = 1.35913e-06
I1029 18:04:41.237043 12802 solver.cpp:222] Iteration 98960 (1.32692 iter/s, 30.145s/40 iters), loss = 1.66153
I1029 18:04:41.237218 12802 solver.cpp:241]     Train net output #0: loss = 1.66153 (* 1 = 1.66153 loss)
I1029 18:04:41.237236 12802 sgd_solver.cpp:105] Iteration 98960, lr = 1.35424e-06
I1029 18:05:10.574818 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_99000.caffemodel
I1029 18:05:10.725291 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_99000.solverstate
I1029 18:05:10.836314 12802 solver.cpp:334] Iteration 99000, Testing net (#0)
I1029 18:05:41.888542 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58964
I1029 18:05:41.888780 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80984
I1029 18:05:41.888795 12802 solver.cpp:401]     Test net output #2: loss = 1.8286 (* 1 = 1.8286 loss)
I1029 18:05:42.652117 12802 solver.cpp:222] Iteration 99000 (0.651323 iter/s, 61.4135s/40 iters), loss = 1.27448
I1029 18:05:42.652175 12802 solver.cpp:241]     Train net output #0: loss = 1.27448 (* 1 = 1.27448 loss)
I1029 18:05:42.652191 12802 sgd_solver.cpp:105] Iteration 99000, lr = 1.34937e-06
I1029 18:06:12.368171 12802 solver.cpp:222] Iteration 99040 (1.34611 iter/s, 29.7153s/40 iters), loss = 1.18957
I1029 18:06:12.368350 12802 solver.cpp:241]     Train net output #0: loss = 1.18957 (* 1 = 1.18957 loss)
I1029 18:06:12.368365 12802 sgd_solver.cpp:105] Iteration 99040, lr = 1.34452e-06
I1029 18:06:42.085877 12802 solver.cpp:222] Iteration 99080 (1.34604 iter/s, 29.7168s/40 iters), loss = 1.65845
I1029 18:06:42.085937 12802 solver.cpp:241]     Train net output #0: loss = 1.65845 (* 1 = 1.65845 loss)
I1029 18:06:42.085952 12802 sgd_solver.cpp:105] Iteration 99080, lr = 1.33969e-06
I1029 18:07:12.000084 12802 solver.cpp:222] Iteration 99120 (1.33719 iter/s, 29.9134s/40 iters), loss = 1.2622
I1029 18:07:12.000278 12802 solver.cpp:241]     Train net output #0: loss = 1.2622 (* 1 = 1.2622 loss)
I1029 18:07:12.000296 12802 sgd_solver.cpp:105] Iteration 99120, lr = 1.33488e-06
I1029 18:07:42.097259 12802 solver.cpp:222] Iteration 99160 (1.32907 iter/s, 30.0963s/40 iters), loss = 1.4476
I1029 18:07:42.097442 12802 solver.cpp:241]     Train net output #0: loss = 1.4476 (* 1 = 1.4476 loss)
I1029 18:07:42.097465 12802 sgd_solver.cpp:105] Iteration 99160, lr = 1.33008e-06
I1029 18:08:12.276634 12802 solver.cpp:222] Iteration 99200 (1.32545 iter/s, 30.1785s/40 iters), loss = 1.19193
I1029 18:08:12.276813 12802 solver.cpp:241]     Train net output #0: loss = 1.19193 (* 1 = 1.19193 loss)
I1029 18:08:12.276829 12802 sgd_solver.cpp:105] Iteration 99200, lr = 1.3253e-06
I1029 18:08:42.777259 12802 solver.cpp:222] Iteration 99240 (1.31149 iter/s, 30.4997s/40 iters), loss = 1.4162
I1029 18:08:42.777437 12802 solver.cpp:241]     Train net output #0: loss = 1.4162 (* 1 = 1.4162 loss)
I1029 18:08:42.777454 12802 sgd_solver.cpp:105] Iteration 99240, lr = 1.32054e-06
I1029 18:09:13.142725 12802 solver.cpp:222] Iteration 99280 (1.31732 iter/s, 30.3646s/40 iters), loss = 1.75882
I1029 18:09:13.142818 12802 solver.cpp:241]     Train net output #0: loss = 1.75882 (* 1 = 1.75882 loss)
I1029 18:09:13.142832 12802 sgd_solver.cpp:105] Iteration 99280, lr = 1.31579e-06
I1029 18:09:42.874502 12802 solver.cpp:222] Iteration 99320 (1.3454 iter/s, 29.731s/40 iters), loss = 1.35137
I1029 18:09:42.874567 12802 solver.cpp:241]     Train net output #0: loss = 1.35137 (* 1 = 1.35137 loss)
I1029 18:09:42.874579 12802 sgd_solver.cpp:105] Iteration 99320, lr = 1.31106e-06
I1029 18:10:12.486831 12802 solver.cpp:222] Iteration 99360 (1.35082 iter/s, 29.6116s/40 iters), loss = 1.28462
I1029 18:10:12.486995 12802 solver.cpp:241]     Train net output #0: loss = 1.28462 (* 1 = 1.28462 loss)
I1029 18:10:12.487012 12802 sgd_solver.cpp:105] Iteration 99360, lr = 1.30635e-06
I1029 18:10:42.120430 12802 solver.cpp:222] Iteration 99400 (1.34986 iter/s, 29.6327s/40 iters), loss = 1.69202
I1029 18:10:42.120491 12802 solver.cpp:241]     Train net output #0: loss = 1.69202 (* 1 = 1.69202 loss)
I1029 18:10:42.120506 12802 sgd_solver.cpp:105] Iteration 99400, lr = 1.30166e-06
I1029 18:11:11.894995 12802 solver.cpp:222] Iteration 99440 (1.34346 iter/s, 29.7738s/40 iters), loss = 1.26234
I1029 18:11:11.895146 12802 solver.cpp:241]     Train net output #0: loss = 1.26234 (* 1 = 1.26234 loss)
I1029 18:11:11.895164 12802 sgd_solver.cpp:105] Iteration 99440, lr = 1.29698e-06
I1029 18:11:41.797144 12802 solver.cpp:222] Iteration 99480 (1.33774 iter/s, 29.9013s/40 iters), loss = 1.48869
I1029 18:11:41.797199 12802 solver.cpp:241]     Train net output #0: loss = 1.48869 (* 1 = 1.48869 loss)
I1029 18:11:41.797212 12802 sgd_solver.cpp:105] Iteration 99480, lr = 1.29232e-06
I1029 18:11:55.862143 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_99500.caffemodel
I1029 18:11:56.022660 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_99500.solverstate
I1029 18:11:56.145321 12802 solver.cpp:334] Iteration 99500, Testing net (#0)
I1029 18:12:27.136721 12851 data_layer.cpp:73] Restarting data prefetching from start.
I1029 18:12:27.349963 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58544
I1029 18:12:27.350005 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81528
I1029 18:12:27.350016 12802 solver.cpp:401]     Test net output #2: loss = 1.83304 (* 1 = 1.83304 loss)
I1029 18:12:43.610808 12802 solver.cpp:222] Iteration 99520 (0.647122 iter/s, 61.8121s/40 iters), loss = 1.37321
I1029 18:12:43.610865 12802 solver.cpp:241]     Train net output #0: loss = 1.37321 (* 1 = 1.37321 loss)
I1029 18:12:43.610882 12802 sgd_solver.cpp:105] Iteration 99520, lr = 1.28767e-06
I1029 18:13:14.300235 12802 solver.cpp:222] Iteration 99560 (1.30341 iter/s, 30.6886s/40 iters), loss = 1.83697
I1029 18:13:14.300436 12802 solver.cpp:241]     Train net output #0: loss = 1.83697 (* 1 = 1.83697 loss)
I1029 18:13:14.300451 12802 sgd_solver.cpp:105] Iteration 99560, lr = 1.28305e-06
I1029 18:13:44.672502 12802 solver.cpp:222] Iteration 99600 (1.31703 iter/s, 30.3713s/40 iters), loss = 1.61562
I1029 18:13:44.672698 12802 solver.cpp:241]     Train net output #0: loss = 1.61562 (* 1 = 1.61562 loss)
I1029 18:13:44.672715 12802 sgd_solver.cpp:105] Iteration 99600, lr = 1.27844e-06
I1029 18:14:15.553988 12802 solver.cpp:222] Iteration 99640 (1.29531 iter/s, 30.8805s/40 iters), loss = 1.14136
I1029 18:14:15.554189 12802 solver.cpp:241]     Train net output #0: loss = 1.14136 (* 1 = 1.14136 loss)
I1029 18:14:15.554204 12802 sgd_solver.cpp:105] Iteration 99640, lr = 1.27384e-06
I1029 18:14:46.046900 12802 solver.cpp:222] Iteration 99680 (1.31182 iter/s, 30.492s/40 iters), loss = 1.11989
I1029 18:14:46.047091 12802 solver.cpp:241]     Train net output #0: loss = 1.11989 (* 1 = 1.11989 loss)
I1029 18:14:46.047108 12802 sgd_solver.cpp:105] Iteration 99680, lr = 1.26926e-06
I1029 18:15:17.138445 12802 solver.cpp:222] Iteration 99720 (1.28656 iter/s, 31.0906s/40 iters), loss = 1.65401
I1029 18:15:17.138631 12802 solver.cpp:241]     Train net output #0: loss = 1.65401 (* 1 = 1.65401 loss)
I1029 18:15:17.138649 12802 sgd_solver.cpp:105] Iteration 99720, lr = 1.2647e-06
I1029 18:15:47.238896 12802 solver.cpp:222] Iteration 99760 (1.32892 iter/s, 30.0995s/40 iters), loss = 1.47896
I1029 18:15:47.239068 12802 solver.cpp:241]     Train net output #0: loss = 1.47896 (* 1 = 1.47896 loss)
I1029 18:15:47.239084 12802 sgd_solver.cpp:105] Iteration 99760, lr = 1.26016e-06
I1029 18:16:17.596447 12802 solver.cpp:222] Iteration 99800 (1.31767 iter/s, 30.3567s/40 iters), loss = 1.39305
I1029 18:16:17.596621 12802 solver.cpp:241]     Train net output #0: loss = 1.39305 (* 1 = 1.39305 loss)
I1029 18:16:17.596638 12802 sgd_solver.cpp:105] Iteration 99800, lr = 1.25563e-06
I1029 18:16:48.204530 12802 solver.cpp:222] Iteration 99840 (1.30688 iter/s, 30.6072s/40 iters), loss = 1.52002
I1029 18:16:48.204716 12802 solver.cpp:241]     Train net output #0: loss = 1.52002 (* 1 = 1.52002 loss)
I1029 18:16:48.204735 12802 sgd_solver.cpp:105] Iteration 99840, lr = 1.25111e-06
I1029 18:17:18.474005 12802 solver.cpp:222] Iteration 99880 (1.3215 iter/s, 30.2686s/40 iters), loss = 1.30934
I1029 18:17:18.474179 12802 solver.cpp:241]     Train net output #0: loss = 1.30934 (* 1 = 1.30934 loss)
I1029 18:17:18.474195 12802 sgd_solver.cpp:105] Iteration 99880, lr = 1.24662e-06
I1029 18:17:48.147467 12802 solver.cpp:222] Iteration 99920 (1.34805 iter/s, 29.6726s/40 iters), loss = 1.26659
I1029 18:17:48.147521 12802 solver.cpp:241]     Train net output #0: loss = 1.26659 (* 1 = 1.26659 loss)
I1029 18:17:48.147536 12802 sgd_solver.cpp:105] Iteration 99920, lr = 1.24214e-06
I1029 18:18:17.963778 12802 solver.cpp:222] Iteration 99960 (1.34158 iter/s, 29.8155s/40 iters), loss = 1.17058
I1029 18:18:17.964057 12802 solver.cpp:241]     Train net output #0: loss = 1.17058 (* 1 = 1.17058 loss)
I1029 18:18:17.964092 12802 sgd_solver.cpp:105] Iteration 99960, lr = 1.23767e-06
I1029 18:18:47.339835 12802 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_100000.caffemodel
I1029 18:18:47.513530 12802 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_exp_iter_100000.solverstate
I1029 18:18:47.792271 12802 solver.cpp:314] Iteration 100000, loss = 1.4829
I1029 18:18:47.792299 12802 solver.cpp:334] Iteration 100000, Testing net (#0)
I1029 18:19:19.044276 12802 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58956
I1029 18:19:19.044422 12802 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80988
I1029 18:19:19.044435 12802 solver.cpp:401]     Test net output #2: loss = 1.82849 (* 1 = 1.82849 loss)
I1029 18:19:19.044441 12802 solver.cpp:319] Optimization Done.
I1029 18:19:42.451488 12802 caffe.cpp:259] Optimization Done.
