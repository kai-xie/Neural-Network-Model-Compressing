nohup: ignoring input
I1028 17:19:26.138355 29475 caffe.cpp:218] Using GPUs 0, 1, 2, 3
I1028 17:19:26.139268 29475 caffe.cpp:223] GPU 0: Tesla P40
I1028 17:19:26.139674 29475 caffe.cpp:223] GPU 1: Tesla P40
I1028 17:19:26.140061 29475 caffe.cpp:223] GPU 2: Tesla P40
I1028 17:19:26.140450 29475 caffe.cpp:223] GPU 3: Tesla P40
I1028 17:19:26.774721 29475 solver.cpp:44] Initializing solver from parameters: 
test_iter: 500
test_interval: 500
base_lr: 0.01
display: 40
max_iter: 100000
lr_policy: "poly"
power: 1.3
momentum: 0.9
weight_decay: 0.0002
snapshot: 500
snapshot_prefix: "SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40"
solver_mode: GPU
device_id: 0
random_seed: 42
net: "SqueezeNet/SqueezeNet_v1.1/train_val_inq_40.prototxt"
train_state {
  level: 0
  stage: ""
}
I1028 17:19:26.775110 29475 solver.cpp:87] Creating training net from net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_40.prototxt
I1028 17:19:26.777098 29475 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1028 17:19:26.777164 29475 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top1
I1028 17:19:26.777175 29475 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top5
I1028 17:19:26.777887 29475 net.cpp:51] Initializing net from parameters: 
name: "SqueezeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/data/caffe-imagenet/ilsvrc12_train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "INQConvolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "fire3/concat"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire4/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool3"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "fire5/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire4/concat"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "fire5/concat"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire6/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool5"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "fire9/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire8/concat"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "INQConvolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "pool10"
  bottom: "label"
  top: "loss"
}
I1028 17:19:26.778319 29475 layer_factory.hpp:77] Creating layer data
I1028 17:19:26.778816 29475 db_lmdb.cpp:35] Opened lmdb /home/data/caffe-imagenet/ilsvrc12_train_lmdb
I1028 17:19:26.778870 29475 net.cpp:84] Creating Layer data
I1028 17:19:26.778883 29475 net.cpp:387] data -> data
I1028 17:19:26.778915 29475 net.cpp:387] data -> label
I1028 17:19:26.780686 29475 data_layer.cpp:45] output data size: 128,3,227,227
I1028 17:19:26.977221 29475 net.cpp:127] Setting up data
I1028 17:19:26.977293 29475 net.cpp:136] Top shape: 128 3 227 227 (19787136)
I1028 17:19:26.977309 29475 net.cpp:136] Top shape: 128 (128)
I1028 17:19:26.977315 29475 net.cpp:144] Memory required for data: 79149056
I1028 17:19:26.977335 29475 layer_factory.hpp:77] Creating layer conv1
I1028 17:19:26.977363 29475 net.cpp:84] Creating Layer conv1
I1028 17:19:26.977373 29475 net.cpp:413] conv1 <- data
I1028 17:19:26.977393 29475 net.cpp:387] conv1 -> conv1
I1028 17:19:26.980479 29475 net.cpp:127] Setting up conv1
I1028 17:19:26.980499 29475 net.cpp:136] Top shape: 128 64 113 113 (104603648)
I1028 17:19:26.980505 29475 net.cpp:144] Memory required for data: 497563648
I1028 17:19:26.980526 29475 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1028 17:19:26.980538 29475 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1028 17:19:26.980551 29475 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1028 17:19:26.980559 29475 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1028 17:19:26.980564 29475 layer_factory.hpp:77] Creating layer relu_conv1
I1028 17:19:26.980579 29475 net.cpp:84] Creating Layer relu_conv1
I1028 17:19:26.980585 29475 net.cpp:413] relu_conv1 <- conv1
I1028 17:19:26.980592 29475 net.cpp:374] relu_conv1 -> conv1 (in-place)
I1028 17:19:27.346036 29475 net.cpp:127] Setting up relu_conv1
I1028 17:19:27.346086 29475 net.cpp:136] Top shape: 128 64 113 113 (104603648)
I1028 17:19:27.346093 29475 net.cpp:144] Memory required for data: 915978240
I1028 17:19:27.346102 29475 layer_factory.hpp:77] Creating layer pool1
I1028 17:19:27.346122 29475 net.cpp:84] Creating Layer pool1
I1028 17:19:27.346130 29475 net.cpp:413] pool1 <- conv1
I1028 17:19:27.346144 29475 net.cpp:387] pool1 -> pool1
I1028 17:19:27.346258 29475 net.cpp:127] Setting up pool1
I1028 17:19:27.346269 29475 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 17:19:27.346312 29475 net.cpp:144] Memory required for data: 1018738688
I1028 17:19:27.346318 29475 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I1028 17:19:27.346334 29475 net.cpp:84] Creating Layer fire2/squeeze1x1
I1028 17:19:27.346341 29475 net.cpp:413] fire2/squeeze1x1 <- pool1
I1028 17:19:27.346350 29475 net.cpp:387] fire2/squeeze1x1 -> fire2/squeeze1x1
I1028 17:19:27.348079 29475 net.cpp:127] Setting up fire2/squeeze1x1
I1028 17:19:27.348100 29475 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 17:19:27.348105 29475 net.cpp:144] Memory required for data: 1044428800
I1028 17:19:27.348117 29475 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1028 17:19:27.348127 29475 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1028 17:19:27.348134 29475 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1028 17:19:27.348142 29475 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1028 17:19:27.348151 29475 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I1028 17:19:27.348160 29475 net.cpp:84] Creating Layer fire2/relu_squeeze1x1
I1028 17:19:27.348165 29475 net.cpp:413] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I1028 17:19:27.348172 29475 net.cpp:374] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I1028 17:19:27.351274 29475 net.cpp:127] Setting up fire2/relu_squeeze1x1
I1028 17:19:27.351294 29475 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 17:19:27.351303 29475 net.cpp:144] Memory required for data: 1070118912
I1028 17:19:27.351310 29475 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1028 17:19:27.351322 29475 net.cpp:84] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1028 17:19:27.351328 29475 net.cpp:413] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I1028 17:19:27.351336 29475 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1028 17:19:27.351347 29475 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1028 17:19:27.351395 29475 net.cpp:127] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1028 17:19:27.351404 29475 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 17:19:27.351410 29475 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 17:19:27.351414 29475 net.cpp:144] Memory required for data: 1121499136
I1028 17:19:27.351419 29475 layer_factory.hpp:77] Creating layer fire2/expand1x1
I1028 17:19:27.351428 29475 net.cpp:84] Creating Layer fire2/expand1x1
I1028 17:19:27.351433 29475 net.cpp:413] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1028 17:19:27.351440 29475 net.cpp:387] fire2/expand1x1 -> fire2/expand1x1
I1028 17:19:27.351754 29475 net.cpp:127] Setting up fire2/expand1x1
I1028 17:19:27.351765 29475 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 17:19:27.351770 29475 net.cpp:144] Memory required for data: 1224259584
I1028 17:19:27.351781 29475 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1028 17:19:27.351789 29475 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1028 17:19:27.351795 29475 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1028 17:19:27.351801 29475 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1028 17:19:27.351806 29475 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I1028 17:19:27.351815 29475 net.cpp:84] Creating Layer fire2/relu_expand1x1
I1028 17:19:27.351820 29475 net.cpp:413] fire2/relu_expand1x1 <- fire2/expand1x1
I1028 17:19:27.351826 29475 net.cpp:374] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I1028 17:19:27.352020 29475 net.cpp:127] Setting up fire2/relu_expand1x1
I1028 17:19:27.352030 29475 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 17:19:27.352042 29475 net.cpp:144] Memory required for data: 1327020032
I1028 17:19:27.352061 29475 layer_factory.hpp:77] Creating layer fire2/expand3x3
I1028 17:19:27.352072 29475 net.cpp:84] Creating Layer fire2/expand3x3
I1028 17:19:27.352077 29475 net.cpp:413] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1028 17:19:27.352085 29475 net.cpp:387] fire2/expand3x3 -> fire2/expand3x3
I1028 17:19:27.352489 29475 net.cpp:127] Setting up fire2/expand3x3
I1028 17:19:27.352501 29475 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 17:19:27.352507 29475 net.cpp:144] Memory required for data: 1429780480
I1028 17:19:27.352514 29475 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1028 17:19:27.352520 29475 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1028 17:19:27.352526 29475 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1028 17:19:27.352531 29475 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1028 17:19:27.352537 29475 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I1028 17:19:27.352545 29475 net.cpp:84] Creating Layer fire2/relu_expand3x3
I1028 17:19:27.352553 29475 net.cpp:413] fire2/relu_expand3x3 <- fire2/expand3x3
I1028 17:19:27.352560 29475 net.cpp:374] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I1028 17:19:27.352751 29475 net.cpp:127] Setting up fire2/relu_expand3x3
I1028 17:19:27.352761 29475 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 17:19:27.352766 29475 net.cpp:144] Memory required for data: 1532540928
I1028 17:19:27.352772 29475 layer_factory.hpp:77] Creating layer fire2/concat
I1028 17:19:27.352783 29475 net.cpp:84] Creating Layer fire2/concat
I1028 17:19:27.352788 29475 net.cpp:413] fire2/concat <- fire2/expand1x1
I1028 17:19:27.352795 29475 net.cpp:413] fire2/concat <- fire2/expand3x3
I1028 17:19:27.352802 29475 net.cpp:387] fire2/concat -> fire2/concat
I1028 17:19:27.352833 29475 net.cpp:127] Setting up fire2/concat
I1028 17:19:27.352841 29475 net.cpp:136] Top shape: 128 128 56 56 (51380224)
I1028 17:19:27.352845 29475 net.cpp:144] Memory required for data: 1738061824
I1028 17:19:27.352850 29475 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I1028 17:19:27.352859 29475 net.cpp:84] Creating Layer fire3/squeeze1x1
I1028 17:19:27.352864 29475 net.cpp:413] fire3/squeeze1x1 <- fire2/concat
I1028 17:19:27.352872 29475 net.cpp:387] fire3/squeeze1x1 -> fire3/squeeze1x1
I1028 17:19:27.353178 29475 net.cpp:127] Setting up fire3/squeeze1x1
I1028 17:19:27.353188 29475 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 17:19:27.353193 29475 net.cpp:144] Memory required for data: 1763751936
I1028 17:19:27.353202 29475 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1028 17:19:27.353211 29475 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1028 17:19:27.353217 29475 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1028 17:19:27.353224 29475 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1028 17:19:27.353229 29475 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I1028 17:19:27.353236 29475 net.cpp:84] Creating Layer fire3/relu_squeeze1x1
I1028 17:19:27.353241 29475 net.cpp:413] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I1028 17:19:27.353248 29475 net.cpp:374] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I1028 17:19:27.354737 29475 net.cpp:127] Setting up fire3/relu_squeeze1x1
I1028 17:19:27.354758 29475 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 17:19:27.354763 29475 net.cpp:144] Memory required for data: 1789442048
I1028 17:19:27.354768 29475 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1028 17:19:27.354777 29475 net.cpp:84] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1028 17:19:27.354782 29475 net.cpp:413] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I1028 17:19:27.354797 29475 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1028 17:19:27.354821 29475 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1028 17:19:27.360883 29475 net.cpp:127] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1028 17:19:27.360894 29475 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 17:19:27.360901 29475 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1028 17:19:27.360905 29475 net.cpp:144] Memory required for data: 1840822272
I1028 17:19:27.360910 29475 layer_factory.hpp:77] Creating layer fire3/expand1x1
I1028 17:19:27.360919 29475 net.cpp:84] Creating Layer fire3/expand1x1
I1028 17:19:27.360925 29475 net.cpp:413] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1028 17:19:27.360934 29475 net.cpp:387] fire3/expand1x1 -> fire3/expand1x1
I1028 17:19:27.361235 29475 net.cpp:127] Setting up fire3/expand1x1
I1028 17:19:27.361248 29475 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 17:19:27.361253 29475 net.cpp:144] Memory required for data: 1943582720
I1028 17:19:27.361260 29475 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1028 17:19:27.361268 29475 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1028 17:19:27.361273 29475 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1028 17:19:27.361277 29475 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1028 17:19:27.361282 29475 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I1028 17:19:27.361291 29475 net.cpp:84] Creating Layer fire3/relu_expand1x1
I1028 17:19:27.361304 29475 net.cpp:413] fire3/relu_expand1x1 <- fire3/expand1x1
I1028 17:19:27.361310 29475 net.cpp:374] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I1028 17:19:27.361506 29475 net.cpp:127] Setting up fire3/relu_expand1x1
I1028 17:19:27.361518 29475 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 17:19:27.361524 29475 net.cpp:144] Memory required for data: 2046343168
I1028 17:19:27.361529 29475 layer_factory.hpp:77] Creating layer fire3/expand3x3
I1028 17:19:27.361539 29475 net.cpp:84] Creating Layer fire3/expand3x3
I1028 17:19:27.361544 29475 net.cpp:413] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1028 17:19:27.361552 29475 net.cpp:387] fire3/expand3x3 -> fire3/expand3x3
I1028 17:19:27.361948 29475 net.cpp:127] Setting up fire3/expand3x3
I1028 17:19:27.361958 29475 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 17:19:27.361963 29475 net.cpp:144] Memory required for data: 2149103616
I1028 17:19:27.361969 29475 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1028 17:19:27.361975 29475 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1028 17:19:27.361981 29475 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1028 17:19:27.361986 29475 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1028 17:19:27.361991 29475 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I1028 17:19:27.361999 29475 net.cpp:84] Creating Layer fire3/relu_expand3x3
I1028 17:19:27.362005 29475 net.cpp:413] fire3/relu_expand3x3 <- fire3/expand3x3
I1028 17:19:27.362011 29475 net.cpp:374] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I1028 17:19:27.362220 29475 net.cpp:127] Setting up fire3/relu_expand3x3
I1028 17:19:27.362231 29475 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1028 17:19:27.362236 29475 net.cpp:144] Memory required for data: 2251864064
I1028 17:19:27.362242 29475 layer_factory.hpp:77] Creating layer fire3/concat
I1028 17:19:27.362249 29475 net.cpp:84] Creating Layer fire3/concat
I1028 17:19:27.362254 29475 net.cpp:413] fire3/concat <- fire3/expand1x1
I1028 17:19:27.362260 29475 net.cpp:413] fire3/concat <- fire3/expand3x3
I1028 17:19:27.362267 29475 net.cpp:387] fire3/concat -> fire3/concat
I1028 17:19:27.362309 29475 net.cpp:127] Setting up fire3/concat
I1028 17:19:27.362319 29475 net.cpp:136] Top shape: 128 128 56 56 (51380224)
I1028 17:19:27.362336 29475 net.cpp:144] Memory required for data: 2457384960
I1028 17:19:27.362341 29475 layer_factory.hpp:77] Creating layer pool3
I1028 17:19:27.362351 29475 net.cpp:84] Creating Layer pool3
I1028 17:19:27.362357 29475 net.cpp:413] pool3 <- fire3/concat
I1028 17:19:27.362363 29475 net.cpp:387] pool3 -> pool3
I1028 17:19:27.362411 29475 net.cpp:127] Setting up pool3
I1028 17:19:27.362421 29475 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 17:19:27.362426 29475 net.cpp:144] Memory required for data: 2508765184
I1028 17:19:27.362432 29475 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I1028 17:19:27.362442 29475 net.cpp:84] Creating Layer fire4/squeeze1x1
I1028 17:19:27.362448 29475 net.cpp:413] fire4/squeeze1x1 <- pool3
I1028 17:19:27.362457 29475 net.cpp:387] fire4/squeeze1x1 -> fire4/squeeze1x1
I1028 17:19:27.362802 29475 net.cpp:127] Setting up fire4/squeeze1x1
I1028 17:19:27.362812 29475 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 17:19:27.362818 29475 net.cpp:144] Memory required for data: 2521610240
I1028 17:19:27.362823 29475 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1028 17:19:27.362830 29475 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1028 17:19:27.362835 29475 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1028 17:19:27.362840 29475 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1028 17:19:27.362845 29475 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I1028 17:19:27.362854 29475 net.cpp:84] Creating Layer fire4/relu_squeeze1x1
I1028 17:19:27.362859 29475 net.cpp:413] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I1028 17:19:27.362865 29475 net.cpp:374] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I1028 17:19:27.363076 29475 net.cpp:127] Setting up fire4/relu_squeeze1x1
I1028 17:19:27.363087 29475 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 17:19:27.363092 29475 net.cpp:144] Memory required for data: 2534455296
I1028 17:19:27.363098 29475 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1028 17:19:27.363106 29475 net.cpp:84] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1028 17:19:27.363111 29475 net.cpp:413] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I1028 17:19:27.363119 29475 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1028 17:19:27.363128 29475 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1028 17:19:27.363171 29475 net.cpp:127] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1028 17:19:27.363188 29475 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 17:19:27.363193 29475 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 17:19:27.363199 29475 net.cpp:144] Memory required for data: 2560145408
I1028 17:19:27.363204 29475 layer_factory.hpp:77] Creating layer fire4/expand1x1
I1028 17:19:27.363212 29475 net.cpp:84] Creating Layer fire4/expand1x1
I1028 17:19:27.363219 29475 net.cpp:413] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1028 17:19:27.363226 29475 net.cpp:387] fire4/expand1x1 -> fire4/expand1x1
I1028 17:19:27.363560 29475 net.cpp:127] Setting up fire4/expand1x1
I1028 17:19:27.363571 29475 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 17:19:27.363576 29475 net.cpp:144] Memory required for data: 2611525632
I1028 17:19:27.363590 29475 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1028 17:19:27.363600 29475 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1028 17:19:27.363606 29475 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1028 17:19:27.363613 29475 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1028 17:19:27.363626 29475 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I1028 17:19:27.363643 29475 net.cpp:84] Creating Layer fire4/relu_expand1x1
I1028 17:19:27.363649 29475 net.cpp:413] fire4/relu_expand1x1 <- fire4/expand1x1
I1028 17:19:27.363656 29475 net.cpp:374] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I1028 17:19:27.365020 29475 net.cpp:127] Setting up fire4/relu_expand1x1
I1028 17:19:27.365041 29475 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 17:19:27.365046 29475 net.cpp:144] Memory required for data: 2662905856
I1028 17:19:27.365051 29475 layer_factory.hpp:77] Creating layer fire4/expand3x3
I1028 17:19:27.365063 29475 net.cpp:84] Creating Layer fire4/expand3x3
I1028 17:19:27.365072 29475 net.cpp:413] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1028 17:19:27.365082 29475 net.cpp:387] fire4/expand3x3 -> fire4/expand3x3
I1028 17:19:27.366966 29475 net.cpp:127] Setting up fire4/expand3x3
I1028 17:19:27.366986 29475 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 17:19:27.366991 29475 net.cpp:144] Memory required for data: 2714286080
I1028 17:19:27.366998 29475 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1028 17:19:27.367005 29475 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1028 17:19:27.367012 29475 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1028 17:19:27.367019 29475 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1028 17:19:27.367025 29475 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I1028 17:19:27.367039 29475 net.cpp:84] Creating Layer fire4/relu_expand3x3
I1028 17:19:27.367046 29475 net.cpp:413] fire4/relu_expand3x3 <- fire4/expand3x3
I1028 17:19:27.367053 29475 net.cpp:374] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I1028 17:19:27.367274 29475 net.cpp:127] Setting up fire4/relu_expand3x3
I1028 17:19:27.367285 29475 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 17:19:27.367290 29475 net.cpp:144] Memory required for data: 2765666304
I1028 17:19:27.367301 29475 layer_factory.hpp:77] Creating layer fire4/concat
I1028 17:19:27.367311 29475 net.cpp:84] Creating Layer fire4/concat
I1028 17:19:27.367316 29475 net.cpp:413] fire4/concat <- fire4/expand1x1
I1028 17:19:27.367323 29475 net.cpp:413] fire4/concat <- fire4/expand3x3
I1028 17:19:27.367331 29475 net.cpp:387] fire4/concat -> fire4/concat
I1028 17:19:27.367364 29475 net.cpp:127] Setting up fire4/concat
I1028 17:19:27.367372 29475 net.cpp:136] Top shape: 128 256 28 28 (25690112)
I1028 17:19:27.367377 29475 net.cpp:144] Memory required for data: 2868426752
I1028 17:19:27.367380 29475 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I1028 17:19:27.367393 29475 net.cpp:84] Creating Layer fire5/squeeze1x1
I1028 17:19:27.367398 29475 net.cpp:413] fire5/squeeze1x1 <- fire4/concat
I1028 17:19:27.367406 29475 net.cpp:387] fire5/squeeze1x1 -> fire5/squeeze1x1
I1028 17:19:27.367790 29475 net.cpp:127] Setting up fire5/squeeze1x1
I1028 17:19:27.367801 29475 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 17:19:27.367806 29475 net.cpp:144] Memory required for data: 2881271808
I1028 17:19:27.367812 29475 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1028 17:19:27.367820 29475 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1028 17:19:27.367825 29475 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1028 17:19:27.367831 29475 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1028 17:19:27.367835 29475 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I1028 17:19:27.367846 29475 net.cpp:84] Creating Layer fire5/relu_squeeze1x1
I1028 17:19:27.367851 29475 net.cpp:413] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I1028 17:19:27.367856 29475 net.cpp:374] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I1028 17:19:27.368067 29475 net.cpp:127] Setting up fire5/relu_squeeze1x1
I1028 17:19:27.368084 29475 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 17:19:27.368110 29475 net.cpp:144] Memory required for data: 2894116864
I1028 17:19:27.368116 29475 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1028 17:19:27.368127 29475 net.cpp:84] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1028 17:19:27.368132 29475 net.cpp:413] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I1028 17:19:27.368144 29475 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1028 17:19:27.368152 29475 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1028 17:19:27.368198 29475 net.cpp:127] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1028 17:19:27.368207 29475 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 17:19:27.368214 29475 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1028 17:19:27.368221 29475 net.cpp:144] Memory required for data: 2919806976
I1028 17:19:27.368225 29475 layer_factory.hpp:77] Creating layer fire5/expand1x1
I1028 17:19:27.368240 29475 net.cpp:84] Creating Layer fire5/expand1x1
I1028 17:19:27.368247 29475 net.cpp:413] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1028 17:19:27.368254 29475 net.cpp:387] fire5/expand1x1 -> fire5/expand1x1
I1028 17:19:27.368597 29475 net.cpp:127] Setting up fire5/expand1x1
I1028 17:19:27.368609 29475 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 17:19:27.368614 29475 net.cpp:144] Memory required for data: 2971187200
I1028 17:19:27.368620 29475 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1028 17:19:27.368628 29475 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1028 17:19:27.368638 29475 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1028 17:19:27.368645 29475 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1028 17:19:27.368650 29475 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I1028 17:19:27.368657 29475 net.cpp:84] Creating Layer fire5/relu_expand1x1
I1028 17:19:27.368662 29475 net.cpp:413] fire5/relu_expand1x1 <- fire5/expand1x1
I1028 17:19:27.368670 29475 net.cpp:374] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I1028 17:19:27.368877 29475 net.cpp:127] Setting up fire5/relu_expand1x1
I1028 17:19:27.368888 29475 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 17:19:27.368894 29475 net.cpp:144] Memory required for data: 3022567424
I1028 17:19:27.368901 29475 layer_factory.hpp:77] Creating layer fire5/expand3x3
I1028 17:19:27.368911 29475 net.cpp:84] Creating Layer fire5/expand3x3
I1028 17:19:27.368916 29475 net.cpp:413] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1028 17:19:27.368926 29475 net.cpp:387] fire5/expand3x3 -> fire5/expand3x3
I1028 17:19:27.369530 29475 net.cpp:127] Setting up fire5/expand3x3
I1028 17:19:27.369544 29475 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 17:19:27.369549 29475 net.cpp:144] Memory required for data: 3073947648
I1028 17:19:27.369554 29475 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1028 17:19:27.369560 29475 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1028 17:19:27.369566 29475 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1028 17:19:27.369571 29475 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1028 17:19:27.369576 29475 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I1028 17:19:27.369585 29475 net.cpp:84] Creating Layer fire5/relu_expand3x3
I1028 17:19:27.369592 29475 net.cpp:413] fire5/relu_expand3x3 <- fire5/expand3x3
I1028 17:19:27.369601 29475 net.cpp:374] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I1028 17:19:27.370971 29475 net.cpp:127] Setting up fire5/relu_expand3x3
I1028 17:19:27.370990 29475 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1028 17:19:27.371002 29475 net.cpp:144] Memory required for data: 3125327872
I1028 17:19:27.371019 29475 layer_factory.hpp:77] Creating layer fire5/concat
I1028 17:19:27.371031 29475 net.cpp:84] Creating Layer fire5/concat
I1028 17:19:27.371039 29475 net.cpp:413] fire5/concat <- fire5/expand1x1
I1028 17:19:27.371047 29475 net.cpp:413] fire5/concat <- fire5/expand3x3
I1028 17:19:27.371053 29475 net.cpp:387] fire5/concat -> fire5/concat
I1028 17:19:27.371086 29475 net.cpp:127] Setting up fire5/concat
I1028 17:19:27.371094 29475 net.cpp:136] Top shape: 128 256 28 28 (25690112)
I1028 17:19:27.371099 29475 net.cpp:144] Memory required for data: 3228088320
I1028 17:19:27.371104 29475 layer_factory.hpp:77] Creating layer pool5
I1028 17:19:27.371114 29475 net.cpp:84] Creating Layer pool5
I1028 17:19:27.371119 29475 net.cpp:413] pool5 <- fire5/concat
I1028 17:19:27.371126 29475 net.cpp:387] pool5 -> pool5
I1028 17:19:27.371170 29475 net.cpp:127] Setting up pool5
I1028 17:19:27.371176 29475 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 17:19:27.371181 29475 net.cpp:144] Memory required for data: 3253778432
I1028 17:19:27.371186 29475 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I1028 17:19:27.371197 29475 net.cpp:84] Creating Layer fire6/squeeze1x1
I1028 17:19:27.371202 29475 net.cpp:413] fire6/squeeze1x1 <- pool5
I1028 17:19:27.371210 29475 net.cpp:387] fire6/squeeze1x1 -> fire6/squeeze1x1
I1028 17:19:27.371645 29475 net.cpp:127] Setting up fire6/squeeze1x1
I1028 17:19:27.371657 29475 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 17:19:27.371662 29475 net.cpp:144] Memory required for data: 3258595328
I1028 17:19:27.371670 29475 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1028 17:19:27.371676 29475 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1028 17:19:27.371681 29475 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1028 17:19:27.371686 29475 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1028 17:19:27.371692 29475 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I1028 17:19:27.371701 29475 net.cpp:84] Creating Layer fire6/relu_squeeze1x1
I1028 17:19:27.371709 29475 net.cpp:413] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I1028 17:19:27.371717 29475 net.cpp:374] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I1028 17:19:27.371922 29475 net.cpp:127] Setting up fire6/relu_squeeze1x1
I1028 17:19:27.371934 29475 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 17:19:27.371939 29475 net.cpp:144] Memory required for data: 3263412224
I1028 17:19:27.371945 29475 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1028 17:19:27.371954 29475 net.cpp:84] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1028 17:19:27.371959 29475 net.cpp:413] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I1028 17:19:27.371966 29475 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1028 17:19:27.371974 29475 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1028 17:19:27.372035 29475 net.cpp:127] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1028 17:19:27.372045 29475 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 17:19:27.372051 29475 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 17:19:27.372056 29475 net.cpp:144] Memory required for data: 3273046016
I1028 17:19:27.372061 29475 layer_factory.hpp:77] Creating layer fire6/expand1x1
I1028 17:19:27.372071 29475 net.cpp:84] Creating Layer fire6/expand1x1
I1028 17:19:27.372076 29475 net.cpp:413] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1028 17:19:27.372086 29475 net.cpp:387] fire6/expand1x1 -> fire6/expand1x1
I1028 17:19:27.372475 29475 net.cpp:127] Setting up fire6/expand1x1
I1028 17:19:27.372488 29475 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 17:19:27.372498 29475 net.cpp:144] Memory required for data: 3292313600
I1028 17:19:27.372504 29475 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1028 17:19:27.372524 29475 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1028 17:19:27.372531 29475 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1028 17:19:27.372539 29475 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1028 17:19:27.372544 29475 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I1028 17:19:27.372550 29475 net.cpp:84] Creating Layer fire6/relu_expand1x1
I1028 17:19:27.372555 29475 net.cpp:413] fire6/relu_expand1x1 <- fire6/expand1x1
I1028 17:19:27.372566 29475 net.cpp:374] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I1028 17:19:27.372771 29475 net.cpp:127] Setting up fire6/relu_expand1x1
I1028 17:19:27.372783 29475 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 17:19:27.372788 29475 net.cpp:144] Memory required for data: 3311581184
I1028 17:19:27.372794 29475 layer_factory.hpp:77] Creating layer fire6/expand3x3
I1028 17:19:27.372805 29475 net.cpp:84] Creating Layer fire6/expand3x3
I1028 17:19:27.372810 29475 net.cpp:413] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1028 17:19:27.372820 29475 net.cpp:387] fire6/expand3x3 -> fire6/expand3x3
I1028 17:19:27.375099 29475 net.cpp:127] Setting up fire6/expand3x3
I1028 17:19:27.375118 29475 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 17:19:27.375124 29475 net.cpp:144] Memory required for data: 3330848768
I1028 17:19:27.375131 29475 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1028 17:19:27.375138 29475 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1028 17:19:27.375144 29475 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1028 17:19:27.375151 29475 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1028 17:19:27.375156 29475 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I1028 17:19:27.375166 29475 net.cpp:84] Creating Layer fire6/relu_expand3x3
I1028 17:19:27.375174 29475 net.cpp:413] fire6/relu_expand3x3 <- fire6/expand3x3
I1028 17:19:27.375182 29475 net.cpp:374] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I1028 17:19:27.375409 29475 net.cpp:127] Setting up fire6/relu_expand3x3
I1028 17:19:27.375422 29475 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 17:19:27.375427 29475 net.cpp:144] Memory required for data: 3350116352
I1028 17:19:27.375434 29475 layer_factory.hpp:77] Creating layer fire6/concat
I1028 17:19:27.375443 29475 net.cpp:84] Creating Layer fire6/concat
I1028 17:19:27.375448 29475 net.cpp:413] fire6/concat <- fire6/expand1x1
I1028 17:19:27.375455 29475 net.cpp:413] fire6/concat <- fire6/expand3x3
I1028 17:19:27.375461 29475 net.cpp:387] fire6/concat -> fire6/concat
I1028 17:19:27.375494 29475 net.cpp:127] Setting up fire6/concat
I1028 17:19:27.375502 29475 net.cpp:136] Top shape: 128 384 14 14 (9633792)
I1028 17:19:27.375506 29475 net.cpp:144] Memory required for data: 3388651520
I1028 17:19:27.375511 29475 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I1028 17:19:27.375525 29475 net.cpp:84] Creating Layer fire7/squeeze1x1
I1028 17:19:27.375530 29475 net.cpp:413] fire7/squeeze1x1 <- fire6/concat
I1028 17:19:27.375537 29475 net.cpp:387] fire7/squeeze1x1 -> fire7/squeeze1x1
I1028 17:19:27.376008 29475 net.cpp:127] Setting up fire7/squeeze1x1
I1028 17:19:27.376019 29475 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 17:19:27.376024 29475 net.cpp:144] Memory required for data: 3393468416
I1028 17:19:27.376039 29475 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1028 17:19:27.376049 29475 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1028 17:19:27.376055 29475 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1028 17:19:27.376062 29475 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1028 17:19:27.376075 29475 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I1028 17:19:27.376096 29475 net.cpp:84] Creating Layer fire7/relu_squeeze1x1
I1028 17:19:27.376101 29475 net.cpp:413] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I1028 17:19:27.376108 29475 net.cpp:374] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I1028 17:19:27.377471 29475 net.cpp:127] Setting up fire7/relu_squeeze1x1
I1028 17:19:27.377492 29475 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 17:19:27.377498 29475 net.cpp:144] Memory required for data: 3398285312
I1028 17:19:27.377503 29475 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1028 17:19:27.377511 29475 net.cpp:84] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1028 17:19:27.377516 29475 net.cpp:413] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I1028 17:19:27.377526 29475 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1028 17:19:27.377537 29475 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1028 17:19:27.377589 29475 net.cpp:127] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1028 17:19:27.377598 29475 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 17:19:27.377602 29475 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1028 17:19:27.377607 29475 net.cpp:144] Memory required for data: 3407919104
I1028 17:19:27.377611 29475 layer_factory.hpp:77] Creating layer fire7/expand1x1
I1028 17:19:27.377624 29475 net.cpp:84] Creating Layer fire7/expand1x1
I1028 17:19:27.377629 29475 net.cpp:413] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1028 17:19:27.377637 29475 net.cpp:387] fire7/expand1x1 -> fire7/expand1x1
I1028 17:19:27.378032 29475 net.cpp:127] Setting up fire7/expand1x1
I1028 17:19:27.378043 29475 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 17:19:27.378048 29475 net.cpp:144] Memory required for data: 3427186688
I1028 17:19:27.378056 29475 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1028 17:19:27.378062 29475 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1028 17:19:27.378067 29475 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1028 17:19:27.378072 29475 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1028 17:19:27.378077 29475 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I1028 17:19:27.378087 29475 net.cpp:84] Creating Layer fire7/relu_expand1x1
I1028 17:19:27.378093 29475 net.cpp:413] fire7/relu_expand1x1 <- fire7/expand1x1
I1028 17:19:27.378098 29475 net.cpp:374] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I1028 17:19:27.378315 29475 net.cpp:127] Setting up fire7/relu_expand1x1
I1028 17:19:27.378329 29475 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 17:19:27.378334 29475 net.cpp:144] Memory required for data: 3446454272
I1028 17:19:27.378342 29475 layer_factory.hpp:77] Creating layer fire7/expand3x3
I1028 17:19:27.378353 29475 net.cpp:84] Creating Layer fire7/expand3x3
I1028 17:19:27.378358 29475 net.cpp:413] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1028 17:19:27.378370 29475 net.cpp:387] fire7/expand3x3 -> fire7/expand3x3
I1028 17:19:27.379354 29475 net.cpp:127] Setting up fire7/expand3x3
I1028 17:19:27.379369 29475 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 17:19:27.379374 29475 net.cpp:144] Memory required for data: 3465721856
I1028 17:19:27.379379 29475 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1028 17:19:27.379386 29475 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1028 17:19:27.379391 29475 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1028 17:19:27.379397 29475 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1028 17:19:27.379413 29475 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I1028 17:19:27.379436 29475 net.cpp:84] Creating Layer fire7/relu_expand3x3
I1028 17:19:27.379441 29475 net.cpp:413] fire7/relu_expand3x3 <- fire7/expand3x3
I1028 17:19:27.379448 29475 net.cpp:374] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I1028 17:19:27.379662 29475 net.cpp:127] Setting up fire7/relu_expand3x3
I1028 17:19:27.379674 29475 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1028 17:19:27.379679 29475 net.cpp:144] Memory required for data: 3484989440
I1028 17:19:27.379685 29475 layer_factory.hpp:77] Creating layer fire7/concat
I1028 17:19:27.379693 29475 net.cpp:84] Creating Layer fire7/concat
I1028 17:19:27.379698 29475 net.cpp:413] fire7/concat <- fire7/expand1x1
I1028 17:19:27.379704 29475 net.cpp:413] fire7/concat <- fire7/expand3x3
I1028 17:19:27.379710 29475 net.cpp:387] fire7/concat -> fire7/concat
I1028 17:19:27.379743 29475 net.cpp:127] Setting up fire7/concat
I1028 17:19:27.379751 29475 net.cpp:136] Top shape: 128 384 14 14 (9633792)
I1028 17:19:27.379755 29475 net.cpp:144] Memory required for data: 3523524608
I1028 17:19:27.379760 29475 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I1028 17:19:27.379775 29475 net.cpp:84] Creating Layer fire8/squeeze1x1
I1028 17:19:27.379779 29475 net.cpp:413] fire8/squeeze1x1 <- fire7/concat
I1028 17:19:27.379788 29475 net.cpp:387] fire8/squeeze1x1 -> fire8/squeeze1x1
I1028 17:19:27.380304 29475 net.cpp:127] Setting up fire8/squeeze1x1
I1028 17:19:27.380316 29475 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 17:19:27.380321 29475 net.cpp:144] Memory required for data: 3529947136
I1028 17:19:27.380328 29475 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1028 17:19:27.380334 29475 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1028 17:19:27.380340 29475 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1028 17:19:27.380345 29475 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1028 17:19:27.380352 29475 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I1028 17:19:27.380359 29475 net.cpp:84] Creating Layer fire8/relu_squeeze1x1
I1028 17:19:27.380367 29475 net.cpp:413] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I1028 17:19:27.380375 29475 net.cpp:374] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I1028 17:19:27.381742 29475 net.cpp:127] Setting up fire8/relu_squeeze1x1
I1028 17:19:27.381760 29475 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 17:19:27.381767 29475 net.cpp:144] Memory required for data: 3536369664
I1028 17:19:27.381772 29475 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1028 17:19:27.381780 29475 net.cpp:84] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1028 17:19:27.381785 29475 net.cpp:413] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I1028 17:19:27.381794 29475 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1028 17:19:27.381804 29475 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1028 17:19:27.381856 29475 net.cpp:127] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1028 17:19:27.381865 29475 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 17:19:27.381870 29475 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 17:19:27.381875 29475 net.cpp:144] Memory required for data: 3549214720
I1028 17:19:27.381880 29475 layer_factory.hpp:77] Creating layer fire8/expand1x1
I1028 17:19:27.381894 29475 net.cpp:84] Creating Layer fire8/expand1x1
I1028 17:19:27.381899 29475 net.cpp:413] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1028 17:19:27.381906 29475 net.cpp:387] fire8/expand1x1 -> fire8/expand1x1
I1028 17:19:27.382359 29475 net.cpp:127] Setting up fire8/expand1x1
I1028 17:19:27.382371 29475 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 17:19:27.382382 29475 net.cpp:144] Memory required for data: 3574904832
I1028 17:19:27.382390 29475 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1028 17:19:27.382412 29475 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1028 17:19:27.382422 29475 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1028 17:19:27.382428 29475 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1028 17:19:27.382432 29475 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I1028 17:19:27.382441 29475 net.cpp:84] Creating Layer fire8/relu_expand1x1
I1028 17:19:27.382446 29475 net.cpp:413] fire8/relu_expand1x1 <- fire8/expand1x1
I1028 17:19:27.382452 29475 net.cpp:374] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I1028 17:19:27.382658 29475 net.cpp:127] Setting up fire8/relu_expand1x1
I1028 17:19:27.382670 29475 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 17:19:27.382675 29475 net.cpp:144] Memory required for data: 3600594944
I1028 17:19:27.382681 29475 layer_factory.hpp:77] Creating layer fire8/expand3x3
I1028 17:19:27.382694 29475 net.cpp:84] Creating Layer fire8/expand3x3
I1028 17:19:27.382699 29475 net.cpp:413] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1028 17:19:27.382710 29475 net.cpp:387] fire8/expand3x3 -> fire8/expand3x3
I1028 17:19:27.385493 29475 net.cpp:127] Setting up fire8/expand3x3
I1028 17:19:27.385512 29475 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 17:19:27.385517 29475 net.cpp:144] Memory required for data: 3626285056
I1028 17:19:27.385524 29475 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1028 17:19:27.385531 29475 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1028 17:19:27.385537 29475 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1028 17:19:27.385542 29475 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1028 17:19:27.385547 29475 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I1028 17:19:27.385558 29475 net.cpp:84] Creating Layer fire8/relu_expand3x3
I1028 17:19:27.385565 29475 net.cpp:413] fire8/relu_expand3x3 <- fire8/expand3x3
I1028 17:19:27.385572 29475 net.cpp:374] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I1028 17:19:27.385792 29475 net.cpp:127] Setting up fire8/relu_expand3x3
I1028 17:19:27.385804 29475 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 17:19:27.385809 29475 net.cpp:144] Memory required for data: 3651975168
I1028 17:19:27.385815 29475 layer_factory.hpp:77] Creating layer fire8/concat
I1028 17:19:27.385825 29475 net.cpp:84] Creating Layer fire8/concat
I1028 17:19:27.385830 29475 net.cpp:413] fire8/concat <- fire8/expand1x1
I1028 17:19:27.385836 29475 net.cpp:413] fire8/concat <- fire8/expand3x3
I1028 17:19:27.385843 29475 net.cpp:387] fire8/concat -> fire8/concat
I1028 17:19:27.385877 29475 net.cpp:127] Setting up fire8/concat
I1028 17:19:27.385885 29475 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1028 17:19:27.385890 29475 net.cpp:144] Memory required for data: 3703355392
I1028 17:19:27.385895 29475 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I1028 17:19:27.385905 29475 net.cpp:84] Creating Layer fire9/squeeze1x1
I1028 17:19:27.385910 29475 net.cpp:413] fire9/squeeze1x1 <- fire8/concat
I1028 17:19:27.385921 29475 net.cpp:387] fire9/squeeze1x1 -> fire9/squeeze1x1
I1028 17:19:27.386503 29475 net.cpp:127] Setting up fire9/squeeze1x1
I1028 17:19:27.386514 29475 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 17:19:27.386519 29475 net.cpp:144] Memory required for data: 3709777920
I1028 17:19:27.386526 29475 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1028 17:19:27.386533 29475 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1028 17:19:27.386538 29475 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1028 17:19:27.386544 29475 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1028 17:19:27.386555 29475 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I1028 17:19:27.386579 29475 net.cpp:84] Creating Layer fire9/relu_squeeze1x1
I1028 17:19:27.386585 29475 net.cpp:413] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I1028 17:19:27.386591 29475 net.cpp:374] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I1028 17:19:27.386804 29475 net.cpp:127] Setting up fire9/relu_squeeze1x1
I1028 17:19:27.386816 29475 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 17:19:27.386821 29475 net.cpp:144] Memory required for data: 3716200448
I1028 17:19:27.386827 29475 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1028 17:19:27.386842 29475 net.cpp:84] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1028 17:19:27.386848 29475 net.cpp:413] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I1028 17:19:27.386855 29475 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1028 17:19:27.386867 29475 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1028 17:19:27.386914 29475 net.cpp:127] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1028 17:19:27.386924 29475 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 17:19:27.386929 29475 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1028 17:19:27.386935 29475 net.cpp:144] Memory required for data: 3729045504
I1028 17:19:27.386940 29475 layer_factory.hpp:77] Creating layer fire9/expand1x1
I1028 17:19:27.386951 29475 net.cpp:84] Creating Layer fire9/expand1x1
I1028 17:19:27.386956 29475 net.cpp:413] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1028 17:19:27.386965 29475 net.cpp:387] fire9/expand1x1 -> fire9/expand1x1
I1028 17:19:27.387416 29475 net.cpp:127] Setting up fire9/expand1x1
I1028 17:19:27.387428 29475 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 17:19:27.387432 29475 net.cpp:144] Memory required for data: 3754735616
I1028 17:19:27.387439 29475 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1028 17:19:27.387445 29475 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1028 17:19:27.387451 29475 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1028 17:19:27.387456 29475 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1028 17:19:27.387461 29475 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I1028 17:19:27.387471 29475 net.cpp:84] Creating Layer fire9/relu_expand1x1
I1028 17:19:27.387478 29475 net.cpp:413] fire9/relu_expand1x1 <- fire9/expand1x1
I1028 17:19:27.387485 29475 net.cpp:374] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I1028 17:19:27.388859 29475 net.cpp:127] Setting up fire9/relu_expand1x1
I1028 17:19:27.388878 29475 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 17:19:27.388885 29475 net.cpp:144] Memory required for data: 3780425728
I1028 17:19:27.388891 29475 layer_factory.hpp:77] Creating layer fire9/expand3x3
I1028 17:19:27.388902 29475 net.cpp:84] Creating Layer fire9/expand3x3
I1028 17:19:27.388911 29475 net.cpp:413] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1028 17:19:27.388921 29475 net.cpp:387] fire9/expand3x3 -> fire9/expand3x3
I1028 17:19:27.390416 29475 net.cpp:127] Setting up fire9/expand3x3
I1028 17:19:27.390429 29475 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 17:19:27.390434 29475 net.cpp:144] Memory required for data: 3806115840
I1028 17:19:27.390440 29475 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1028 17:19:27.390447 29475 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1028 17:19:27.390452 29475 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1028 17:19:27.390457 29475 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1028 17:19:27.390470 29475 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I1028 17:19:27.390493 29475 net.cpp:84] Creating Layer fire9/relu_expand3x3
I1028 17:19:27.390499 29475 net.cpp:413] fire9/relu_expand3x3 <- fire9/expand3x3
I1028 17:19:27.390506 29475 net.cpp:374] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I1028 17:19:27.390709 29475 net.cpp:127] Setting up fire9/relu_expand3x3
I1028 17:19:27.390722 29475 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1028 17:19:27.390727 29475 net.cpp:144] Memory required for data: 3831805952
I1028 17:19:27.390733 29475 layer_factory.hpp:77] Creating layer fire9/concat
I1028 17:19:27.390743 29475 net.cpp:84] Creating Layer fire9/concat
I1028 17:19:27.390748 29475 net.cpp:413] fire9/concat <- fire9/expand1x1
I1028 17:19:27.390753 29475 net.cpp:413] fire9/concat <- fire9/expand3x3
I1028 17:19:27.390760 29475 net.cpp:387] fire9/concat -> fire9/concat
I1028 17:19:27.390792 29475 net.cpp:127] Setting up fire9/concat
I1028 17:19:27.390800 29475 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1028 17:19:27.390805 29475 net.cpp:144] Memory required for data: 3883186176
I1028 17:19:27.390810 29475 layer_factory.hpp:77] Creating layer drop9
I1028 17:19:27.390820 29475 net.cpp:84] Creating Layer drop9
I1028 17:19:27.390825 29475 net.cpp:413] drop9 <- fire9/concat
I1028 17:19:27.390835 29475 net.cpp:374] drop9 -> fire9/concat (in-place)
I1028 17:19:27.390869 29475 net.cpp:127] Setting up drop9
I1028 17:19:27.390877 29475 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1028 17:19:27.390882 29475 net.cpp:144] Memory required for data: 3934566400
I1028 17:19:27.390887 29475 layer_factory.hpp:77] Creating layer conv10
I1028 17:19:27.390898 29475 net.cpp:84] Creating Layer conv10
I1028 17:19:27.390903 29475 net.cpp:413] conv10 <- fire9/concat
I1028 17:19:27.390913 29475 net.cpp:387] conv10 -> conv10
I1028 17:19:27.400362 29475 net.cpp:127] Setting up conv10
I1028 17:19:27.400382 29475 net.cpp:136] Top shape: 128 1000 14 14 (25088000)
I1028 17:19:27.400388 29475 net.cpp:144] Memory required for data: 4034918400
I1028 17:19:27.400396 29475 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1028 17:19:27.400403 29475 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1028 17:19:27.400409 29475 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1028 17:19:27.400415 29475 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1028 17:19:27.400423 29475 layer_factory.hpp:77] Creating layer relu_conv10
I1028 17:19:27.400434 29475 net.cpp:84] Creating Layer relu_conv10
I1028 17:19:27.400439 29475 net.cpp:413] relu_conv10 <- conv10
I1028 17:19:27.400449 29475 net.cpp:374] relu_conv10 -> conv10 (in-place)
I1028 17:19:27.400681 29475 net.cpp:127] Setting up relu_conv10
I1028 17:19:27.400693 29475 net.cpp:136] Top shape: 128 1000 14 14 (25088000)
I1028 17:19:27.400698 29475 net.cpp:144] Memory required for data: 4135270400
I1028 17:19:27.400705 29475 layer_factory.hpp:77] Creating layer pool10
I1028 17:19:27.400713 29475 net.cpp:84] Creating Layer pool10
I1028 17:19:27.400718 29475 net.cpp:413] pool10 <- conv10
I1028 17:19:27.400727 29475 net.cpp:387] pool10 -> pool10
I1028 17:19:27.400967 29475 net.cpp:127] Setting up pool10
I1028 17:19:27.400980 29475 net.cpp:136] Top shape: 128 1000 1 1 (128000)
I1028 17:19:27.400988 29475 net.cpp:144] Memory required for data: 4135782400
I1028 17:19:27.400995 29475 layer_factory.hpp:77] Creating layer loss
I1028 17:19:27.401005 29475 net.cpp:84] Creating Layer loss
I1028 17:19:27.401010 29475 net.cpp:413] loss <- pool10
I1028 17:19:27.401017 29475 net.cpp:413] loss <- label
I1028 17:19:27.401026 29475 net.cpp:387] loss -> loss
I1028 17:19:27.401039 29475 layer_factory.hpp:77] Creating layer loss
I1028 17:19:27.403920 29475 net.cpp:127] Setting up loss
I1028 17:19:27.403942 29475 net.cpp:136] Top shape: (1)
I1028 17:19:27.403949 29475 net.cpp:139]     with loss weight 1
I1028 17:19:27.403975 29475 net.cpp:144] Memory required for data: 4135782404
I1028 17:19:27.403990 29475 net.cpp:205] loss needs backward computation.
I1028 17:19:27.403996 29475 net.cpp:205] pool10 needs backward computation.
I1028 17:19:27.404014 29475 net.cpp:205] relu_conv10 needs backward computation.
I1028 17:19:27.404019 29475 net.cpp:205] conv10 needs backward computation.
I1028 17:19:27.404024 29475 net.cpp:205] drop9 needs backward computation.
I1028 17:19:27.404028 29475 net.cpp:205] fire9/concat needs backward computation.
I1028 17:19:27.404034 29475 net.cpp:205] fire9/relu_expand3x3 needs backward computation.
I1028 17:19:27.404038 29475 net.cpp:205] fire9/expand3x3 needs backward computation.
I1028 17:19:27.404042 29475 net.cpp:205] fire9/relu_expand1x1 needs backward computation.
I1028 17:19:27.404047 29475 net.cpp:205] fire9/expand1x1 needs backward computation.
I1028 17:19:27.404053 29475 net.cpp:205] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I1028 17:19:27.404057 29475 net.cpp:205] fire9/relu_squeeze1x1 needs backward computation.
I1028 17:19:27.404062 29475 net.cpp:205] fire9/squeeze1x1 needs backward computation.
I1028 17:19:27.404067 29475 net.cpp:205] fire8/concat needs backward computation.
I1028 17:19:27.404072 29475 net.cpp:205] fire8/relu_expand3x3 needs backward computation.
I1028 17:19:27.404076 29475 net.cpp:205] fire8/expand3x3 needs backward computation.
I1028 17:19:27.404080 29475 net.cpp:205] fire8/relu_expand1x1 needs backward computation.
I1028 17:19:27.404085 29475 net.cpp:205] fire8/expand1x1 needs backward computation.
I1028 17:19:27.404089 29475 net.cpp:205] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I1028 17:19:27.404094 29475 net.cpp:205] fire8/relu_squeeze1x1 needs backward computation.
I1028 17:19:27.404099 29475 net.cpp:205] fire8/squeeze1x1 needs backward computation.
I1028 17:19:27.404103 29475 net.cpp:205] fire7/concat needs backward computation.
I1028 17:19:27.404109 29475 net.cpp:205] fire7/relu_expand3x3 needs backward computation.
I1028 17:19:27.404112 29475 net.cpp:205] fire7/expand3x3 needs backward computation.
I1028 17:19:27.404117 29475 net.cpp:205] fire7/relu_expand1x1 needs backward computation.
I1028 17:19:27.404121 29475 net.cpp:205] fire7/expand1x1 needs backward computation.
I1028 17:19:27.404126 29475 net.cpp:205] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I1028 17:19:27.404130 29475 net.cpp:205] fire7/relu_squeeze1x1 needs backward computation.
I1028 17:19:27.404135 29475 net.cpp:205] fire7/squeeze1x1 needs backward computation.
I1028 17:19:27.404139 29475 net.cpp:205] fire6/concat needs backward computation.
I1028 17:19:27.404145 29475 net.cpp:205] fire6/relu_expand3x3 needs backward computation.
I1028 17:19:27.404150 29475 net.cpp:205] fire6/expand3x3 needs backward computation.
I1028 17:19:27.404153 29475 net.cpp:205] fire6/relu_expand1x1 needs backward computation.
I1028 17:19:27.404158 29475 net.cpp:205] fire6/expand1x1 needs backward computation.
I1028 17:19:27.404162 29475 net.cpp:205] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I1028 17:19:27.404167 29475 net.cpp:205] fire6/relu_squeeze1x1 needs backward computation.
I1028 17:19:27.404171 29475 net.cpp:205] fire6/squeeze1x1 needs backward computation.
I1028 17:19:27.404176 29475 net.cpp:205] pool5 needs backward computation.
I1028 17:19:27.404181 29475 net.cpp:205] fire5/concat needs backward computation.
I1028 17:19:27.404186 29475 net.cpp:205] fire5/relu_expand3x3 needs backward computation.
I1028 17:19:27.404189 29475 net.cpp:205] fire5/expand3x3 needs backward computation.
I1028 17:19:27.404194 29475 net.cpp:205] fire5/relu_expand1x1 needs backward computation.
I1028 17:19:27.404198 29475 net.cpp:205] fire5/expand1x1 needs backward computation.
I1028 17:19:27.404203 29475 net.cpp:205] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I1028 17:19:27.404207 29475 net.cpp:205] fire5/relu_squeeze1x1 needs backward computation.
I1028 17:19:27.404212 29475 net.cpp:205] fire5/squeeze1x1 needs backward computation.
I1028 17:19:27.404217 29475 net.cpp:205] fire4/concat needs backward computation.
I1028 17:19:27.404225 29475 net.cpp:205] fire4/relu_expand3x3 needs backward computation.
I1028 17:19:27.404237 29475 net.cpp:205] fire4/expand3x3 needs backward computation.
I1028 17:19:27.404240 29475 net.cpp:205] fire4/relu_expand1x1 needs backward computation.
I1028 17:19:27.404245 29475 net.cpp:205] fire4/expand1x1 needs backward computation.
I1028 17:19:27.404249 29475 net.cpp:205] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I1028 17:19:27.404254 29475 net.cpp:205] fire4/relu_squeeze1x1 needs backward computation.
I1028 17:19:27.404258 29475 net.cpp:205] fire4/squeeze1x1 needs backward computation.
I1028 17:19:27.404263 29475 net.cpp:205] pool3 needs backward computation.
I1028 17:19:27.404268 29475 net.cpp:205] fire3/concat needs backward computation.
I1028 17:19:27.404273 29475 net.cpp:205] fire3/relu_expand3x3 needs backward computation.
I1028 17:19:27.404278 29475 net.cpp:205] fire3/expand3x3 needs backward computation.
I1028 17:19:27.404283 29475 net.cpp:205] fire3/relu_expand1x1 needs backward computation.
I1028 17:19:27.404286 29475 net.cpp:205] fire3/expand1x1 needs backward computation.
I1028 17:19:27.404291 29475 net.cpp:205] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I1028 17:19:27.404295 29475 net.cpp:205] fire3/relu_squeeze1x1 needs backward computation.
I1028 17:19:27.404307 29475 net.cpp:205] fire3/squeeze1x1 needs backward computation.
I1028 17:19:27.404312 29475 net.cpp:205] fire2/concat needs backward computation.
I1028 17:19:27.404317 29475 net.cpp:205] fire2/relu_expand3x3 needs backward computation.
I1028 17:19:27.404323 29475 net.cpp:205] fire2/expand3x3 needs backward computation.
I1028 17:19:27.404330 29475 net.cpp:205] fire2/relu_expand1x1 needs backward computation.
I1028 17:19:27.404333 29475 net.cpp:205] fire2/expand1x1 needs backward computation.
I1028 17:19:27.404338 29475 net.cpp:205] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I1028 17:19:27.404343 29475 net.cpp:205] fire2/relu_squeeze1x1 needs backward computation.
I1028 17:19:27.404347 29475 net.cpp:205] fire2/squeeze1x1 needs backward computation.
I1028 17:19:27.404352 29475 net.cpp:205] pool1 needs backward computation.
I1028 17:19:27.404357 29475 net.cpp:205] relu_conv1 needs backward computation.
I1028 17:19:27.404362 29475 net.cpp:205] conv1 needs backward computation.
I1028 17:19:27.404373 29475 net.cpp:207] data does not need backward computation.
I1028 17:19:27.404378 29475 net.cpp:249] This network produces output loss
I1028 17:19:27.404434 29475 net.cpp:262] Network initialization done.
I1028 17:19:27.406234 29475 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_40.prototxt
I1028 17:19:27.406343 29475 net.cpp:301] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1028 17:19:27.407100 29475 net.cpp:51] Initializing net from parameters: 
name: "SqueezeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/data/caffe-imagenet/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "INQConvolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "fire3/concat"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire4/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool3"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "fire5/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire4/concat"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "fire5/concat"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire6/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool5"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "fire9/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire8/concat"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "INQConvolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
  inq_convolution_param {
    portion: 0.2
    portion: 0.4
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "pool10"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy_top1"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy_top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy_top5"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy_top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I1028 17:19:27.407488 29475 layer_factory.hpp:77] Creating layer data
I1028 17:19:27.407567 29475 db_lmdb.cpp:35] Opened lmdb /home/data/caffe-imagenet/ilsvrc12_val_lmdb
I1028 17:19:27.407589 29475 net.cpp:84] Creating Layer data
I1028 17:19:27.407598 29475 net.cpp:387] data -> data
I1028 17:19:27.407613 29475 net.cpp:387] data -> label
I1028 17:19:27.408025 29475 data_layer.cpp:45] output data size: 50,3,227,227
I1028 17:19:27.492040 29475 net.cpp:127] Setting up data
I1028 17:19:27.492089 29475 net.cpp:136] Top shape: 50 3 227 227 (7729350)
I1028 17:19:27.492099 29475 net.cpp:136] Top shape: 50 (50)
I1028 17:19:27.492103 29475 net.cpp:144] Memory required for data: 30917600
I1028 17:19:27.492116 29475 layer_factory.hpp:77] Creating layer label_data_1_split
I1028 17:19:27.492144 29475 net.cpp:84] Creating Layer label_data_1_split
I1028 17:19:27.492154 29475 net.cpp:413] label_data_1_split <- label
I1028 17:19:27.492164 29475 net.cpp:387] label_data_1_split -> label_data_1_split_0
I1028 17:19:27.492179 29475 net.cpp:387] label_data_1_split -> label_data_1_split_1
I1028 17:19:27.492188 29475 net.cpp:387] label_data_1_split -> label_data_1_split_2
I1028 17:19:27.492513 29475 net.cpp:127] Setting up label_data_1_split
I1028 17:19:27.492528 29475 net.cpp:136] Top shape: 50 (50)
I1028 17:19:27.492534 29475 net.cpp:136] Top shape: 50 (50)
I1028 17:19:27.492542 29475 net.cpp:136] Top shape: 50 (50)
I1028 17:19:27.492547 29475 net.cpp:144] Memory required for data: 30918200
I1028 17:19:27.492552 29475 layer_factory.hpp:77] Creating layer conv1
I1028 17:19:27.492574 29475 net.cpp:84] Creating Layer conv1
I1028 17:19:27.492579 29475 net.cpp:413] conv1 <- data
I1028 17:19:27.492588 29475 net.cpp:387] conv1 -> conv1
I1028 17:19:27.493007 29475 net.cpp:127] Setting up conv1
I1028 17:19:27.493019 29475 net.cpp:136] Top shape: 50 64 113 113 (40860800)
I1028 17:19:27.493024 29475 net.cpp:144] Memory required for data: 194361400
I1028 17:19:27.493034 29475 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1028 17:19:27.493044 29475 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1028 17:19:27.493053 29475 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1028 17:19:27.493060 29475 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1028 17:19:27.493067 29475 layer_factory.hpp:77] Creating layer relu_conv1
I1028 17:19:27.493080 29475 net.cpp:84] Creating Layer relu_conv1
I1028 17:19:27.493086 29475 net.cpp:413] relu_conv1 <- conv1
I1028 17:19:27.493093 29475 net.cpp:374] relu_conv1 -> conv1 (in-place)
I1028 17:19:27.493372 29475 net.cpp:127] Setting up relu_conv1
I1028 17:19:27.493386 29475 net.cpp:136] Top shape: 50 64 113 113 (40860800)
I1028 17:19:27.493392 29475 net.cpp:144] Memory required for data: 357804600
I1028 17:19:27.493399 29475 layer_factory.hpp:77] Creating layer pool1
I1028 17:19:27.493414 29475 net.cpp:84] Creating Layer pool1
I1028 17:19:27.493420 29475 net.cpp:413] pool1 <- conv1
I1028 17:19:27.493427 29475 net.cpp:387] pool1 -> pool1
I1028 17:19:27.493502 29475 net.cpp:127] Setting up pool1
I1028 17:19:27.493512 29475 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 17:19:27.493517 29475 net.cpp:144] Memory required for data: 397945400
I1028 17:19:27.493522 29475 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I1028 17:19:27.493540 29475 net.cpp:84] Creating Layer fire2/squeeze1x1
I1028 17:19:27.493546 29475 net.cpp:413] fire2/squeeze1x1 <- pool1
I1028 17:19:27.493553 29475 net.cpp:387] fire2/squeeze1x1 -> fire2/squeeze1x1
I1028 17:19:27.493949 29475 net.cpp:127] Setting up fire2/squeeze1x1
I1028 17:19:27.493960 29475 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 17:19:27.493965 29475 net.cpp:144] Memory required for data: 407980600
I1028 17:19:27.493973 29475 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1028 17:19:27.493983 29475 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1028 17:19:27.493991 29475 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1028 17:19:27.493998 29475 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1028 17:19:27.494002 29475 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I1028 17:19:27.494014 29475 net.cpp:84] Creating Layer fire2/relu_squeeze1x1
I1028 17:19:27.494033 29475 net.cpp:413] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I1028 17:19:27.494065 29475 net.cpp:374] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I1028 17:19:27.496632 29475 net.cpp:127] Setting up fire2/relu_squeeze1x1
I1028 17:19:27.496646 29475 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 17:19:27.496651 29475 net.cpp:144] Memory required for data: 418015800
I1028 17:19:27.496656 29475 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1028 17:19:27.496665 29475 net.cpp:84] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1028 17:19:27.496670 29475 net.cpp:413] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I1028 17:19:27.496677 29475 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1028 17:19:27.496686 29475 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1028 17:19:27.496737 29475 net.cpp:127] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1028 17:19:27.496747 29475 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 17:19:27.496752 29475 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 17:19:27.496757 29475 net.cpp:144] Memory required for data: 438086200
I1028 17:19:27.496760 29475 layer_factory.hpp:77] Creating layer fire2/expand1x1
I1028 17:19:27.496774 29475 net.cpp:84] Creating Layer fire2/expand1x1
I1028 17:19:27.496780 29475 net.cpp:413] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1028 17:19:27.496789 29475 net.cpp:387] fire2/expand1x1 -> fire2/expand1x1
I1028 17:19:27.497143 29475 net.cpp:127] Setting up fire2/expand1x1
I1028 17:19:27.497153 29475 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 17:19:27.497158 29475 net.cpp:144] Memory required for data: 478227000
I1028 17:19:27.497166 29475 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1028 17:19:27.497174 29475 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1028 17:19:27.497180 29475 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1028 17:19:27.497189 29475 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1028 17:19:27.497195 29475 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I1028 17:19:27.497205 29475 net.cpp:84] Creating Layer fire2/relu_expand1x1
I1028 17:19:27.497210 29475 net.cpp:413] fire2/relu_expand1x1 <- fire2/expand1x1
I1028 17:19:27.497217 29475 net.cpp:374] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I1028 17:19:27.498641 29475 net.cpp:127] Setting up fire2/relu_expand1x1
I1028 17:19:27.498661 29475 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 17:19:27.498667 29475 net.cpp:144] Memory required for data: 518367800
I1028 17:19:27.498672 29475 layer_factory.hpp:77] Creating layer fire2/expand3x3
I1028 17:19:27.498687 29475 net.cpp:84] Creating Layer fire2/expand3x3
I1028 17:19:27.498693 29475 net.cpp:413] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1028 17:19:27.498703 29475 net.cpp:387] fire2/expand3x3 -> fire2/expand3x3
I1028 17:19:27.499155 29475 net.cpp:127] Setting up fire2/expand3x3
I1028 17:19:27.499166 29475 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 17:19:27.499171 29475 net.cpp:144] Memory required for data: 558508600
I1028 17:19:27.499178 29475 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1028 17:19:27.499184 29475 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1028 17:19:27.499191 29475 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1028 17:19:27.499195 29475 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1028 17:19:27.499204 29475 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I1028 17:19:27.499213 29475 net.cpp:84] Creating Layer fire2/relu_expand3x3
I1028 17:19:27.499219 29475 net.cpp:413] fire2/relu_expand3x3 <- fire2/expand3x3
I1028 17:19:27.499233 29475 net.cpp:374] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I1028 17:19:27.499469 29475 net.cpp:127] Setting up fire2/relu_expand3x3
I1028 17:19:27.499485 29475 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 17:19:27.499490 29475 net.cpp:144] Memory required for data: 598649400
I1028 17:19:27.499495 29475 layer_factory.hpp:77] Creating layer fire2/concat
I1028 17:19:27.499507 29475 net.cpp:84] Creating Layer fire2/concat
I1028 17:19:27.499512 29475 net.cpp:413] fire2/concat <- fire2/expand1x1
I1028 17:19:27.499519 29475 net.cpp:413] fire2/concat <- fire2/expand3x3
I1028 17:19:27.499526 29475 net.cpp:387] fire2/concat -> fire2/concat
I1028 17:19:27.499562 29475 net.cpp:127] Setting up fire2/concat
I1028 17:19:27.499570 29475 net.cpp:136] Top shape: 50 128 56 56 (20070400)
I1028 17:19:27.499574 29475 net.cpp:144] Memory required for data: 678931000
I1028 17:19:27.499579 29475 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I1028 17:19:27.499590 29475 net.cpp:84] Creating Layer fire3/squeeze1x1
I1028 17:19:27.499595 29475 net.cpp:413] fire3/squeeze1x1 <- fire2/concat
I1028 17:19:27.499604 29475 net.cpp:387] fire3/squeeze1x1 -> fire3/squeeze1x1
I1028 17:19:27.499969 29475 net.cpp:127] Setting up fire3/squeeze1x1
I1028 17:19:27.499980 29475 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 17:19:27.499985 29475 net.cpp:144] Memory required for data: 688966200
I1028 17:19:27.499994 29475 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1028 17:19:27.500002 29475 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1028 17:19:27.500008 29475 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1028 17:19:27.500013 29475 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1028 17:19:27.500020 29475 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I1028 17:19:27.500031 29475 net.cpp:84] Creating Layer fire3/relu_squeeze1x1
I1028 17:19:27.500037 29475 net.cpp:413] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I1028 17:19:27.500043 29475 net.cpp:374] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I1028 17:19:27.500253 29475 net.cpp:127] Setting up fire3/relu_squeeze1x1
I1028 17:19:27.500265 29475 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 17:19:27.500270 29475 net.cpp:144] Memory required for data: 699001400
I1028 17:19:27.500277 29475 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1028 17:19:27.500283 29475 net.cpp:84] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1028 17:19:27.500288 29475 net.cpp:413] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I1028 17:19:27.500301 29475 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1028 17:19:27.500310 29475 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1028 17:19:27.500363 29475 net.cpp:127] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1028 17:19:27.500372 29475 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 17:19:27.500378 29475 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1028 17:19:27.500382 29475 net.cpp:144] Memory required for data: 719071800
I1028 17:19:27.500387 29475 layer_factory.hpp:77] Creating layer fire3/expand1x1
I1028 17:19:27.500401 29475 net.cpp:84] Creating Layer fire3/expand1x1
I1028 17:19:27.500406 29475 net.cpp:413] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1028 17:19:27.500416 29475 net.cpp:387] fire3/expand1x1 -> fire3/expand1x1
I1028 17:19:27.500772 29475 net.cpp:127] Setting up fire3/expand1x1
I1028 17:19:27.500783 29475 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 17:19:27.500788 29475 net.cpp:144] Memory required for data: 759212600
I1028 17:19:27.500795 29475 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1028 17:19:27.500802 29475 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1028 17:19:27.500813 29475 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1028 17:19:27.500830 29475 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1028 17:19:27.500836 29475 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I1028 17:19:27.500844 29475 net.cpp:84] Creating Layer fire3/relu_expand1x1
I1028 17:19:27.500849 29475 net.cpp:413] fire3/relu_expand1x1 <- fire3/expand1x1
I1028 17:19:27.500856 29475 net.cpp:374] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I1028 17:19:27.501072 29475 net.cpp:127] Setting up fire3/relu_expand1x1
I1028 17:19:27.501085 29475 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 17:19:27.501090 29475 net.cpp:144] Memory required for data: 799353400
I1028 17:19:27.501096 29475 layer_factory.hpp:77] Creating layer fire3/expand3x3
I1028 17:19:27.501107 29475 net.cpp:84] Creating Layer fire3/expand3x3
I1028 17:19:27.501112 29475 net.cpp:413] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1028 17:19:27.501122 29475 net.cpp:387] fire3/expand3x3 -> fire3/expand3x3
I1028 17:19:27.501562 29475 net.cpp:127] Setting up fire3/expand3x3
I1028 17:19:27.501574 29475 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 17:19:27.501579 29475 net.cpp:144] Memory required for data: 839494200
I1028 17:19:27.501585 29475 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1028 17:19:27.501591 29475 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1028 17:19:27.501596 29475 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1028 17:19:27.501601 29475 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1028 17:19:27.501606 29475 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I1028 17:19:27.501613 29475 net.cpp:84] Creating Layer fire3/relu_expand3x3
I1028 17:19:27.501621 29475 net.cpp:413] fire3/relu_expand3x3 <- fire3/expand3x3
I1028 17:19:27.501631 29475 net.cpp:374] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I1028 17:19:27.503026 29475 net.cpp:127] Setting up fire3/relu_expand3x3
I1028 17:19:27.503046 29475 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1028 17:19:27.503051 29475 net.cpp:144] Memory required for data: 879635000
I1028 17:19:27.503057 29475 layer_factory.hpp:77] Creating layer fire3/concat
I1028 17:19:27.503064 29475 net.cpp:84] Creating Layer fire3/concat
I1028 17:19:27.503070 29475 net.cpp:413] fire3/concat <- fire3/expand1x1
I1028 17:19:27.503077 29475 net.cpp:413] fire3/concat <- fire3/expand3x3
I1028 17:19:27.503085 29475 net.cpp:387] fire3/concat -> fire3/concat
I1028 17:19:27.503125 29475 net.cpp:127] Setting up fire3/concat
I1028 17:19:27.503135 29475 net.cpp:136] Top shape: 50 128 56 56 (20070400)
I1028 17:19:27.503139 29475 net.cpp:144] Memory required for data: 959916600
I1028 17:19:27.503144 29475 layer_factory.hpp:77] Creating layer pool3
I1028 17:19:27.503151 29475 net.cpp:84] Creating Layer pool3
I1028 17:19:27.503156 29475 net.cpp:413] pool3 <- fire3/concat
I1028 17:19:27.503162 29475 net.cpp:387] pool3 -> pool3
I1028 17:19:27.503211 29475 net.cpp:127] Setting up pool3
I1028 17:19:27.503218 29475 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 17:19:27.503222 29475 net.cpp:144] Memory required for data: 979987000
I1028 17:19:27.503229 29475 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I1028 17:19:27.503242 29475 net.cpp:84] Creating Layer fire4/squeeze1x1
I1028 17:19:27.503247 29475 net.cpp:413] fire4/squeeze1x1 <- pool3
I1028 17:19:27.503257 29475 net.cpp:387] fire4/squeeze1x1 -> fire4/squeeze1x1
I1028 17:19:27.503660 29475 net.cpp:127] Setting up fire4/squeeze1x1
I1028 17:19:27.503674 29475 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 17:19:27.503679 29475 net.cpp:144] Memory required for data: 985004600
I1028 17:19:27.503685 29475 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1028 17:19:27.503691 29475 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1028 17:19:27.503703 29475 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1028 17:19:27.503721 29475 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1028 17:19:27.503726 29475 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I1028 17:19:27.503734 29475 net.cpp:84] Creating Layer fire4/relu_squeeze1x1
I1028 17:19:27.503739 29475 net.cpp:413] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I1028 17:19:27.503746 29475 net.cpp:374] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I1028 17:19:27.503959 29475 net.cpp:127] Setting up fire4/relu_squeeze1x1
I1028 17:19:27.503971 29475 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 17:19:27.503976 29475 net.cpp:144] Memory required for data: 990022200
I1028 17:19:27.503983 29475 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1028 17:19:27.503989 29475 net.cpp:84] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1028 17:19:27.503994 29475 net.cpp:413] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I1028 17:19:27.504004 29475 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1028 17:19:27.504014 29475 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1028 17:19:27.504065 29475 net.cpp:127] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1028 17:19:27.504073 29475 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 17:19:27.504081 29475 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 17:19:27.504086 29475 net.cpp:144] Memory required for data: 1000057400
I1028 17:19:27.504091 29475 layer_factory.hpp:77] Creating layer fire4/expand1x1
I1028 17:19:27.504103 29475 net.cpp:84] Creating Layer fire4/expand1x1
I1028 17:19:27.504109 29475 net.cpp:413] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1028 17:19:27.504117 29475 net.cpp:387] fire4/expand1x1 -> fire4/expand1x1
I1028 17:19:27.504492 29475 net.cpp:127] Setting up fire4/expand1x1
I1028 17:19:27.504503 29475 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 17:19:27.504508 29475 net.cpp:144] Memory required for data: 1020127800
I1028 17:19:27.504518 29475 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1028 17:19:27.504528 29475 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1028 17:19:27.504534 29475 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1028 17:19:27.504540 29475 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1028 17:19:27.504546 29475 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I1028 17:19:27.504557 29475 net.cpp:84] Creating Layer fire4/relu_expand1x1
I1028 17:19:27.504562 29475 net.cpp:413] fire4/relu_expand1x1 <- fire4/expand1x1
I1028 17:19:27.504570 29475 net.cpp:374] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I1028 17:19:27.504789 29475 net.cpp:127] Setting up fire4/relu_expand1x1
I1028 17:19:27.504801 29475 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 17:19:27.504806 29475 net.cpp:144] Memory required for data: 1040198200
I1028 17:19:27.504812 29475 layer_factory.hpp:77] Creating layer fire4/expand3x3
I1028 17:19:27.504827 29475 net.cpp:84] Creating Layer fire4/expand3x3
I1028 17:19:27.504832 29475 net.cpp:413] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1028 17:19:27.504840 29475 net.cpp:387] fire4/expand3x3 -> fire4/expand3x3
I1028 17:19:27.505509 29475 net.cpp:127] Setting up fire4/expand3x3
I1028 17:19:27.505522 29475 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 17:19:27.505527 29475 net.cpp:144] Memory required for data: 1060268600
I1028 17:19:27.505532 29475 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1028 17:19:27.505539 29475 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1028 17:19:27.505544 29475 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1028 17:19:27.505565 29475 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1028 17:19:27.505574 29475 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I1028 17:19:27.505581 29475 net.cpp:84] Creating Layer fire4/relu_expand3x3
I1028 17:19:27.505587 29475 net.cpp:413] fire4/relu_expand3x3 <- fire4/expand3x3
I1028 17:19:27.505594 29475 net.cpp:374] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I1028 17:19:27.505806 29475 net.cpp:127] Setting up fire4/relu_expand3x3
I1028 17:19:27.505818 29475 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 17:19:27.505823 29475 net.cpp:144] Memory required for data: 1080339000
I1028 17:19:27.505831 29475 layer_factory.hpp:77] Creating layer fire4/concat
I1028 17:19:27.505838 29475 net.cpp:84] Creating Layer fire4/concat
I1028 17:19:27.505842 29475 net.cpp:413] fire4/concat <- fire4/expand1x1
I1028 17:19:27.505849 29475 net.cpp:413] fire4/concat <- fire4/expand3x3
I1028 17:19:27.505857 29475 net.cpp:387] fire4/concat -> fire4/concat
I1028 17:19:27.505888 29475 net.cpp:127] Setting up fire4/concat
I1028 17:19:27.505898 29475 net.cpp:136] Top shape: 50 256 28 28 (10035200)
I1028 17:19:27.505903 29475 net.cpp:144] Memory required for data: 1120479800
I1028 17:19:27.505908 29475 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I1028 17:19:27.505916 29475 net.cpp:84] Creating Layer fire5/squeeze1x1
I1028 17:19:27.505921 29475 net.cpp:413] fire5/squeeze1x1 <- fire4/concat
I1028 17:19:27.505931 29475 net.cpp:387] fire5/squeeze1x1 -> fire5/squeeze1x1
I1028 17:19:27.506361 29475 net.cpp:127] Setting up fire5/squeeze1x1
I1028 17:19:27.506373 29475 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 17:19:27.506377 29475 net.cpp:144] Memory required for data: 1125497400
I1028 17:19:27.506384 29475 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1028 17:19:27.506391 29475 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1028 17:19:27.506395 29475 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1028 17:19:27.506400 29475 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1028 17:19:27.506405 29475 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I1028 17:19:27.506414 29475 net.cpp:84] Creating Layer fire5/relu_squeeze1x1
I1028 17:19:27.506424 29475 net.cpp:413] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I1028 17:19:27.506433 29475 net.cpp:374] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I1028 17:19:27.507829 29475 net.cpp:127] Setting up fire5/relu_squeeze1x1
I1028 17:19:27.507848 29475 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 17:19:27.507853 29475 net.cpp:144] Memory required for data: 1130515000
I1028 17:19:27.507859 29475 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1028 17:19:27.507874 29475 net.cpp:84] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1028 17:19:27.507879 29475 net.cpp:413] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I1028 17:19:27.507890 29475 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1028 17:19:27.507903 29475 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1028 17:19:27.507956 29475 net.cpp:127] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1028 17:19:27.507963 29475 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 17:19:27.507971 29475 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1028 17:19:27.507975 29475 net.cpp:144] Memory required for data: 1140550200
I1028 17:19:27.507979 29475 layer_factory.hpp:77] Creating layer fire5/expand1x1
I1028 17:19:27.507990 29475 net.cpp:84] Creating Layer fire5/expand1x1
I1028 17:19:27.507997 29475 net.cpp:413] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1028 17:19:27.508005 29475 net.cpp:387] fire5/expand1x1 -> fire5/expand1x1
I1028 17:19:27.508405 29475 net.cpp:127] Setting up fire5/expand1x1
I1028 17:19:27.508430 29475 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 17:19:27.508435 29475 net.cpp:144] Memory required for data: 1160620600
I1028 17:19:27.508442 29475 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1028 17:19:27.508448 29475 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1028 17:19:27.508455 29475 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1028 17:19:27.508460 29475 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1028 17:19:27.508466 29475 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I1028 17:19:27.508476 29475 net.cpp:84] Creating Layer fire5/relu_expand1x1
I1028 17:19:27.508483 29475 net.cpp:413] fire5/relu_expand1x1 <- fire5/expand1x1
I1028 17:19:27.508491 29475 net.cpp:374] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I1028 17:19:27.508705 29475 net.cpp:127] Setting up fire5/relu_expand1x1
I1028 17:19:27.508718 29475 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 17:19:27.508723 29475 net.cpp:144] Memory required for data: 1180691000
I1028 17:19:27.508729 29475 layer_factory.hpp:77] Creating layer fire5/expand3x3
I1028 17:19:27.508743 29475 net.cpp:84] Creating Layer fire5/expand3x3
I1028 17:19:27.508749 29475 net.cpp:413] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1028 17:19:27.508756 29475 net.cpp:387] fire5/expand3x3 -> fire5/expand3x3
I1028 17:19:27.509425 29475 net.cpp:127] Setting up fire5/expand3x3
I1028 17:19:27.509438 29475 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 17:19:27.509443 29475 net.cpp:144] Memory required for data: 1200761400
I1028 17:19:27.509449 29475 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1028 17:19:27.509454 29475 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1028 17:19:27.509460 29475 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1028 17:19:27.509465 29475 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1028 17:19:27.509474 29475 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I1028 17:19:27.509483 29475 net.cpp:84] Creating Layer fire5/relu_expand3x3
I1028 17:19:27.509490 29475 net.cpp:413] fire5/relu_expand3x3 <- fire5/expand3x3
I1028 17:19:27.509497 29475 net.cpp:374] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I1028 17:19:27.509711 29475 net.cpp:127] Setting up fire5/relu_expand3x3
I1028 17:19:27.509722 29475 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1028 17:19:27.509727 29475 net.cpp:144] Memory required for data: 1220831800
I1028 17:19:27.509733 29475 layer_factory.hpp:77] Creating layer fire5/concat
I1028 17:19:27.509742 29475 net.cpp:84] Creating Layer fire5/concat
I1028 17:19:27.509747 29475 net.cpp:413] fire5/concat <- fire5/expand1x1
I1028 17:19:27.509752 29475 net.cpp:413] fire5/concat <- fire5/expand3x3
I1028 17:19:27.509759 29475 net.cpp:387] fire5/concat -> fire5/concat
I1028 17:19:27.509793 29475 net.cpp:127] Setting up fire5/concat
I1028 17:19:27.509800 29475 net.cpp:136] Top shape: 50 256 28 28 (10035200)
I1028 17:19:27.509804 29475 net.cpp:144] Memory required for data: 1260972600
I1028 17:19:27.509809 29475 layer_factory.hpp:77] Creating layer pool5
I1028 17:19:27.509819 29475 net.cpp:84] Creating Layer pool5
I1028 17:19:27.509824 29475 net.cpp:413] pool5 <- fire5/concat
I1028 17:19:27.509829 29475 net.cpp:387] pool5 -> pool5
I1028 17:19:27.509881 29475 net.cpp:127] Setting up pool5
I1028 17:19:27.509889 29475 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 17:19:27.509894 29475 net.cpp:144] Memory required for data: 1271007800
I1028 17:19:27.509901 29475 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I1028 17:19:27.509912 29475 net.cpp:84] Creating Layer fire6/squeeze1x1
I1028 17:19:27.509917 29475 net.cpp:413] fire6/squeeze1x1 <- pool5
I1028 17:19:27.509929 29475 net.cpp:387] fire6/squeeze1x1 -> fire6/squeeze1x1
I1028 17:19:27.510401 29475 net.cpp:127] Setting up fire6/squeeze1x1
I1028 17:19:27.510426 29475 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 17:19:27.510432 29475 net.cpp:144] Memory required for data: 1272889400
I1028 17:19:27.510437 29475 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1028 17:19:27.510444 29475 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1028 17:19:27.510450 29475 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1028 17:19:27.510455 29475 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1028 17:19:27.510460 29475 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I1028 17:19:27.510469 29475 net.cpp:84] Creating Layer fire6/relu_squeeze1x1
I1028 17:19:27.510478 29475 net.cpp:413] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I1028 17:19:27.510486 29475 net.cpp:374] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I1028 17:19:27.510699 29475 net.cpp:127] Setting up fire6/relu_squeeze1x1
I1028 17:19:27.510711 29475 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 17:19:27.510716 29475 net.cpp:144] Memory required for data: 1274771000
I1028 17:19:27.510722 29475 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1028 17:19:27.510730 29475 net.cpp:84] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1028 17:19:27.510735 29475 net.cpp:413] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I1028 17:19:27.510746 29475 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1028 17:19:27.510753 29475 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1028 17:19:27.510826 29475 net.cpp:127] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1028 17:19:27.510838 29475 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 17:19:27.510843 29475 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 17:19:27.510848 29475 net.cpp:144] Memory required for data: 1278534200
I1028 17:19:27.510854 29475 layer_factory.hpp:77] Creating layer fire6/expand1x1
I1028 17:19:27.510865 29475 net.cpp:84] Creating Layer fire6/expand1x1
I1028 17:19:27.510871 29475 net.cpp:413] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1028 17:19:27.510879 29475 net.cpp:387] fire6/expand1x1 -> fire6/expand1x1
I1028 17:19:27.511294 29475 net.cpp:127] Setting up fire6/expand1x1
I1028 17:19:27.511312 29475 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 17:19:27.511317 29475 net.cpp:144] Memory required for data: 1286060600
I1028 17:19:27.511322 29475 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1028 17:19:27.511329 29475 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1028 17:19:27.511334 29475 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1028 17:19:27.511339 29475 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1028 17:19:27.511344 29475 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I1028 17:19:27.511358 29475 net.cpp:84] Creating Layer fire6/relu_expand1x1
I1028 17:19:27.511364 29475 net.cpp:413] fire6/relu_expand1x1 <- fire6/expand1x1
I1028 17:19:27.511370 29475 net.cpp:374] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I1028 17:19:27.512776 29475 net.cpp:127] Setting up fire6/relu_expand1x1
I1028 17:19:27.512797 29475 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 17:19:27.512804 29475 net.cpp:144] Memory required for data: 1293587000
I1028 17:19:27.512809 29475 layer_factory.hpp:77] Creating layer fire6/expand3x3
I1028 17:19:27.512820 29475 net.cpp:84] Creating Layer fire6/expand3x3
I1028 17:19:27.512825 29475 net.cpp:413] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1028 17:19:27.512836 29475 net.cpp:387] fire6/expand3x3 -> fire6/expand3x3
I1028 17:19:27.513921 29475 net.cpp:127] Setting up fire6/expand3x3
I1028 17:19:27.513936 29475 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 17:19:27.513955 29475 net.cpp:144] Memory required for data: 1301113400
I1028 17:19:27.513962 29475 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1028 17:19:27.513972 29475 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1028 17:19:27.513979 29475 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1028 17:19:27.513988 29475 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1028 17:19:27.513993 29475 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I1028 17:19:27.514001 29475 net.cpp:84] Creating Layer fire6/relu_expand3x3
I1028 17:19:27.514008 29475 net.cpp:413] fire6/relu_expand3x3 <- fire6/expand3x3
I1028 17:19:27.514014 29475 net.cpp:374] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I1028 17:19:27.514226 29475 net.cpp:127] Setting up fire6/relu_expand3x3
I1028 17:19:27.514238 29475 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 17:19:27.514247 29475 net.cpp:144] Memory required for data: 1308639800
I1028 17:19:27.514252 29475 layer_factory.hpp:77] Creating layer fire6/concat
I1028 17:19:27.514261 29475 net.cpp:84] Creating Layer fire6/concat
I1028 17:19:27.514266 29475 net.cpp:413] fire6/concat <- fire6/expand1x1
I1028 17:19:27.514271 29475 net.cpp:413] fire6/concat <- fire6/expand3x3
I1028 17:19:27.514278 29475 net.cpp:387] fire6/concat -> fire6/concat
I1028 17:19:27.514320 29475 net.cpp:127] Setting up fire6/concat
I1028 17:19:27.514330 29475 net.cpp:136] Top shape: 50 384 14 14 (3763200)
I1028 17:19:27.514334 29475 net.cpp:144] Memory required for data: 1323692600
I1028 17:19:27.514340 29475 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I1028 17:19:27.514351 29475 net.cpp:84] Creating Layer fire7/squeeze1x1
I1028 17:19:27.514358 29475 net.cpp:413] fire7/squeeze1x1 <- fire6/concat
I1028 17:19:27.514369 29475 net.cpp:387] fire7/squeeze1x1 -> fire7/squeeze1x1
I1028 17:19:27.514883 29475 net.cpp:127] Setting up fire7/squeeze1x1
I1028 17:19:27.514894 29475 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 17:19:27.514899 29475 net.cpp:144] Memory required for data: 1325574200
I1028 17:19:27.514914 29475 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1028 17:19:27.514924 29475 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1028 17:19:27.514930 29475 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1028 17:19:27.514940 29475 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1028 17:19:27.514945 29475 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I1028 17:19:27.514952 29475 net.cpp:84] Creating Layer fire7/relu_squeeze1x1
I1028 17:19:27.514957 29475 net.cpp:413] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I1028 17:19:27.514966 29475 net.cpp:374] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I1028 17:19:27.515178 29475 net.cpp:127] Setting up fire7/relu_squeeze1x1
I1028 17:19:27.515190 29475 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 17:19:27.515195 29475 net.cpp:144] Memory required for data: 1327455800
I1028 17:19:27.515202 29475 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1028 17:19:27.515210 29475 net.cpp:84] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1028 17:19:27.515216 29475 net.cpp:413] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I1028 17:19:27.515225 29475 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1028 17:19:27.515234 29475 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1028 17:19:27.515285 29475 net.cpp:127] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1028 17:19:27.515293 29475 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 17:19:27.515311 29475 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1028 17:19:27.515318 29475 net.cpp:144] Memory required for data: 1331219000
I1028 17:19:27.515333 29475 layer_factory.hpp:77] Creating layer fire7/expand1x1
I1028 17:19:27.515347 29475 net.cpp:84] Creating Layer fire7/expand1x1
I1028 17:19:27.515352 29475 net.cpp:413] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1028 17:19:27.515362 29475 net.cpp:387] fire7/expand1x1 -> fire7/expand1x1
I1028 17:19:27.515784 29475 net.cpp:127] Setting up fire7/expand1x1
I1028 17:19:27.515795 29475 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 17:19:27.515800 29475 net.cpp:144] Memory required for data: 1338745400
I1028 17:19:27.515807 29475 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1028 17:19:27.515813 29475 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1028 17:19:27.515820 29475 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1028 17:19:27.515825 29475 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1028 17:19:27.515830 29475 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I1028 17:19:27.515836 29475 net.cpp:84] Creating Layer fire7/relu_expand1x1
I1028 17:19:27.515842 29475 net.cpp:413] fire7/relu_expand1x1 <- fire7/expand1x1
I1028 17:19:27.515853 29475 net.cpp:374] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I1028 17:19:27.517251 29475 net.cpp:127] Setting up fire7/relu_expand1x1
I1028 17:19:27.517269 29475 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 17:19:27.517276 29475 net.cpp:144] Memory required for data: 1346271800
I1028 17:19:27.517280 29475 layer_factory.hpp:77] Creating layer fire7/expand3x3
I1028 17:19:27.517293 29475 net.cpp:84] Creating Layer fire7/expand3x3
I1028 17:19:27.517303 29475 net.cpp:413] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1028 17:19:27.517318 29475 net.cpp:387] fire7/expand3x3 -> fire7/expand3x3
I1028 17:19:27.518399 29475 net.cpp:127] Setting up fire7/expand3x3
I1028 17:19:27.518412 29475 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 17:19:27.518417 29475 net.cpp:144] Memory required for data: 1353798200
I1028 17:19:27.518424 29475 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1028 17:19:27.518431 29475 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1028 17:19:27.518437 29475 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1028 17:19:27.518442 29475 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1028 17:19:27.518447 29475 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I1028 17:19:27.518456 29475 net.cpp:84] Creating Layer fire7/relu_expand3x3
I1028 17:19:27.518465 29475 net.cpp:413] fire7/relu_expand3x3 <- fire7/expand3x3
I1028 17:19:27.518476 29475 net.cpp:374] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I1028 17:19:27.518690 29475 net.cpp:127] Setting up fire7/relu_expand3x3
I1028 17:19:27.518702 29475 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1028 17:19:27.518707 29475 net.cpp:144] Memory required for data: 1361324600
I1028 17:19:27.518714 29475 layer_factory.hpp:77] Creating layer fire7/concat
I1028 17:19:27.518721 29475 net.cpp:84] Creating Layer fire7/concat
I1028 17:19:27.518726 29475 net.cpp:413] fire7/concat <- fire7/expand1x1
I1028 17:19:27.518733 29475 net.cpp:413] fire7/concat <- fire7/expand3x3
I1028 17:19:27.518743 29475 net.cpp:387] fire7/concat -> fire7/concat
I1028 17:19:27.518775 29475 net.cpp:127] Setting up fire7/concat
I1028 17:19:27.518785 29475 net.cpp:136] Top shape: 50 384 14 14 (3763200)
I1028 17:19:27.518790 29475 net.cpp:144] Memory required for data: 1376377400
I1028 17:19:27.518795 29475 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I1028 17:19:27.518803 29475 net.cpp:84] Creating Layer fire8/squeeze1x1
I1028 17:19:27.518808 29475 net.cpp:413] fire8/squeeze1x1 <- fire7/concat
I1028 17:19:27.518822 29475 net.cpp:387] fire8/squeeze1x1 -> fire8/squeeze1x1
I1028 17:19:27.520720 29475 net.cpp:127] Setting up fire8/squeeze1x1
I1028 17:19:27.520751 29475 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 17:19:27.520756 29475 net.cpp:144] Memory required for data: 1378886200
I1028 17:19:27.520764 29475 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1028 17:19:27.520771 29475 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1028 17:19:27.520777 29475 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1028 17:19:27.520782 29475 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1028 17:19:27.520787 29475 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I1028 17:19:27.520798 29475 net.cpp:84] Creating Layer fire8/relu_squeeze1x1
I1028 17:19:27.520805 29475 net.cpp:413] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I1028 17:19:27.520812 29475 net.cpp:374] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I1028 17:19:27.521044 29475 net.cpp:127] Setting up fire8/relu_squeeze1x1
I1028 17:19:27.521056 29475 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 17:19:27.521061 29475 net.cpp:144] Memory required for data: 1381395000
I1028 17:19:27.521067 29475 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1028 17:19:27.521076 29475 net.cpp:84] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1028 17:19:27.521081 29475 net.cpp:413] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I1028 17:19:27.521090 29475 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1028 17:19:27.521100 29475 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1028 17:19:27.521152 29475 net.cpp:127] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1028 17:19:27.521162 29475 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 17:19:27.521169 29475 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 17:19:27.521174 29475 net.cpp:144] Memory required for data: 1386412600
I1028 17:19:27.521180 29475 layer_factory.hpp:77] Creating layer fire8/expand1x1
I1028 17:19:27.521193 29475 net.cpp:84] Creating Layer fire8/expand1x1
I1028 17:19:27.521198 29475 net.cpp:413] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1028 17:19:27.521209 29475 net.cpp:387] fire8/expand1x1 -> fire8/expand1x1
I1028 17:19:27.521698 29475 net.cpp:127] Setting up fire8/expand1x1
I1028 17:19:27.521710 29475 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 17:19:27.521715 29475 net.cpp:144] Memory required for data: 1396447800
I1028 17:19:27.521721 29475 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1028 17:19:27.521728 29475 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1028 17:19:27.521733 29475 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1028 17:19:27.521739 29475 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1028 17:19:27.521744 29475 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I1028 17:19:27.521752 29475 net.cpp:84] Creating Layer fire8/relu_expand1x1
I1028 17:19:27.521761 29475 net.cpp:413] fire8/relu_expand1x1 <- fire8/expand1x1
I1028 17:19:27.521769 29475 net.cpp:374] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I1028 17:19:27.521986 29475 net.cpp:127] Setting up fire8/relu_expand1x1
I1028 17:19:27.521998 29475 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 17:19:27.522003 29475 net.cpp:144] Memory required for data: 1406483000
I1028 17:19:27.522009 29475 layer_factory.hpp:77] Creating layer fire8/expand3x3
I1028 17:19:27.522022 29475 net.cpp:84] Creating Layer fire8/expand3x3
I1028 17:19:27.522030 29475 net.cpp:413] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1028 17:19:27.522038 29475 net.cpp:387] fire8/expand3x3 -> fire8/expand3x3
I1028 17:19:27.524853 29475 net.cpp:127] Setting up fire8/expand3x3
I1028 17:19:27.524878 29475 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 17:19:27.524896 29475 net.cpp:144] Memory required for data: 1416518200
I1028 17:19:27.524904 29475 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1028 17:19:27.524911 29475 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1028 17:19:27.524924 29475 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1028 17:19:27.524931 29475 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1028 17:19:27.524938 29475 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I1028 17:19:27.524947 29475 net.cpp:84] Creating Layer fire8/relu_expand3x3
I1028 17:19:27.524953 29475 net.cpp:413] fire8/relu_expand3x3 <- fire8/expand3x3
I1028 17:19:27.524962 29475 net.cpp:374] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I1028 17:19:27.526386 29475 net.cpp:127] Setting up fire8/relu_expand3x3
I1028 17:19:27.526406 29475 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 17:19:27.526412 29475 net.cpp:144] Memory required for data: 1426553400
I1028 17:19:27.526417 29475 layer_factory.hpp:77] Creating layer fire8/concat
I1028 17:19:27.526424 29475 net.cpp:84] Creating Layer fire8/concat
I1028 17:19:27.526430 29475 net.cpp:413] fire8/concat <- fire8/expand1x1
I1028 17:19:27.526439 29475 net.cpp:413] fire8/concat <- fire8/expand3x3
I1028 17:19:27.526449 29475 net.cpp:387] fire8/concat -> fire8/concat
I1028 17:19:27.526489 29475 net.cpp:127] Setting up fire8/concat
I1028 17:19:27.526499 29475 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1028 17:19:27.526504 29475 net.cpp:144] Memory required for data: 1446623800
I1028 17:19:27.526509 29475 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I1028 17:19:27.526518 29475 net.cpp:84] Creating Layer fire9/squeeze1x1
I1028 17:19:27.526523 29475 net.cpp:413] fire9/squeeze1x1 <- fire8/concat
I1028 17:19:27.526533 29475 net.cpp:387] fire9/squeeze1x1 -> fire9/squeeze1x1
I1028 17:19:27.527153 29475 net.cpp:127] Setting up fire9/squeeze1x1
I1028 17:19:27.527163 29475 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 17:19:27.527168 29475 net.cpp:144] Memory required for data: 1449132600
I1028 17:19:27.527175 29475 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1028 17:19:27.527181 29475 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1028 17:19:27.527187 29475 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1028 17:19:27.527192 29475 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1028 17:19:27.527199 29475 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I1028 17:19:27.527215 29475 net.cpp:84] Creating Layer fire9/relu_squeeze1x1
I1028 17:19:27.527222 29475 net.cpp:413] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I1028 17:19:27.527230 29475 net.cpp:374] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I1028 17:19:27.527453 29475 net.cpp:127] Setting up fire9/relu_squeeze1x1
I1028 17:19:27.527467 29475 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 17:19:27.527472 29475 net.cpp:144] Memory required for data: 1451641400
I1028 17:19:27.527478 29475 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1028 17:19:27.527485 29475 net.cpp:84] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1028 17:19:27.527490 29475 net.cpp:413] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I1028 17:19:27.527500 29475 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1028 17:19:27.527509 29475 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1028 17:19:27.527560 29475 net.cpp:127] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1028 17:19:27.527570 29475 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 17:19:27.527580 29475 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1028 17:19:27.527591 29475 net.cpp:144] Memory required for data: 1456659000
I1028 17:19:27.527608 29475 layer_factory.hpp:77] Creating layer fire9/expand1x1
I1028 17:19:27.527622 29475 net.cpp:84] Creating Layer fire9/expand1x1
I1028 17:19:27.527628 29475 net.cpp:413] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1028 17:19:27.527635 29475 net.cpp:387] fire9/expand1x1 -> fire9/expand1x1
I1028 17:19:27.528128 29475 net.cpp:127] Setting up fire9/expand1x1
I1028 17:19:27.528141 29475 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 17:19:27.528146 29475 net.cpp:144] Memory required for data: 1466694200
I1028 17:19:27.528153 29475 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1028 17:19:27.528159 29475 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1028 17:19:27.528165 29475 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1028 17:19:27.528170 29475 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1028 17:19:27.528175 29475 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I1028 17:19:27.528182 29475 net.cpp:84] Creating Layer fire9/relu_expand1x1
I1028 17:19:27.528187 29475 net.cpp:413] fire9/relu_expand1x1 <- fire9/expand1x1
I1028 17:19:27.528193 29475 net.cpp:374] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I1028 17:19:27.528416 29475 net.cpp:127] Setting up fire9/relu_expand1x1
I1028 17:19:27.528429 29475 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 17:19:27.528434 29475 net.cpp:144] Memory required for data: 1476729400
I1028 17:19:27.528441 29475 layer_factory.hpp:77] Creating layer fire9/expand3x3
I1028 17:19:27.528452 29475 net.cpp:84] Creating Layer fire9/expand3x3
I1028 17:19:27.528458 29475 net.cpp:413] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1028 17:19:27.528468 29475 net.cpp:387] fire9/expand3x3 -> fire9/expand3x3
I1028 17:19:27.531301 29475 net.cpp:127] Setting up fire9/expand3x3
I1028 17:19:27.531322 29475 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 17:19:27.531327 29475 net.cpp:144] Memory required for data: 1486764600
I1028 17:19:27.531334 29475 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1028 17:19:27.531342 29475 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1028 17:19:27.531347 29475 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1028 17:19:27.531352 29475 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1028 17:19:27.531358 29475 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I1028 17:19:27.531369 29475 net.cpp:84] Creating Layer fire9/relu_expand3x3
I1028 17:19:27.531376 29475 net.cpp:413] fire9/relu_expand3x3 <- fire9/expand3x3
I1028 17:19:27.531384 29475 net.cpp:374] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I1028 17:19:27.531608 29475 net.cpp:127] Setting up fire9/relu_expand3x3
I1028 17:19:27.531620 29475 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1028 17:19:27.531625 29475 net.cpp:144] Memory required for data: 1496799800
I1028 17:19:27.531631 29475 layer_factory.hpp:77] Creating layer fire9/concat
I1028 17:19:27.531641 29475 net.cpp:84] Creating Layer fire9/concat
I1028 17:19:27.531646 29475 net.cpp:413] fire9/concat <- fire9/expand1x1
I1028 17:19:27.531652 29475 net.cpp:413] fire9/concat <- fire9/expand3x3
I1028 17:19:27.531659 29475 net.cpp:387] fire9/concat -> fire9/concat
I1028 17:19:27.531695 29475 net.cpp:127] Setting up fire9/concat
I1028 17:19:27.531703 29475 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1028 17:19:27.531708 29475 net.cpp:144] Memory required for data: 1516870200
I1028 17:19:27.531713 29475 layer_factory.hpp:77] Creating layer drop9
I1028 17:19:27.531721 29475 net.cpp:84] Creating Layer drop9
I1028 17:19:27.531726 29475 net.cpp:413] drop9 <- fire9/concat
I1028 17:19:27.531734 29475 net.cpp:374] drop9 -> fire9/concat (in-place)
I1028 17:19:27.531764 29475 net.cpp:127] Setting up drop9
I1028 17:19:27.531780 29475 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1028 17:19:27.531802 29475 net.cpp:144] Memory required for data: 1536940600
I1028 17:19:27.531808 29475 layer_factory.hpp:77] Creating layer conv10
I1028 17:19:27.531818 29475 net.cpp:84] Creating Layer conv10
I1028 17:19:27.531824 29475 net.cpp:413] conv10 <- fire9/concat
I1028 17:19:27.531834 29475 net.cpp:387] conv10 -> conv10
I1028 17:19:27.542536 29475 net.cpp:127] Setting up conv10
I1028 17:19:27.542557 29475 net.cpp:136] Top shape: 50 1000 14 14 (9800000)
I1028 17:19:27.542562 29475 net.cpp:144] Memory required for data: 1576140600
I1028 17:19:27.542569 29475 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1028 17:19:27.542577 29475 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1028 17:19:27.542582 29475 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1028 17:19:27.542587 29475 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1028 17:19:27.542593 29475 layer_factory.hpp:77] Creating layer relu_conv10
I1028 17:19:27.542603 29475 net.cpp:84] Creating Layer relu_conv10
I1028 17:19:27.542609 29475 net.cpp:413] relu_conv10 <- conv10
I1028 17:19:27.542618 29475 net.cpp:374] relu_conv10 -> conv10 (in-place)
I1028 17:19:27.544035 29475 net.cpp:127] Setting up relu_conv10
I1028 17:19:27.544054 29475 net.cpp:136] Top shape: 50 1000 14 14 (9800000)
I1028 17:19:27.544060 29475 net.cpp:144] Memory required for data: 1615340600
I1028 17:19:27.544065 29475 layer_factory.hpp:77] Creating layer pool10
I1028 17:19:27.544075 29475 net.cpp:84] Creating Layer pool10
I1028 17:19:27.544080 29475 net.cpp:413] pool10 <- conv10
I1028 17:19:27.544090 29475 net.cpp:387] pool10 -> pool10
I1028 17:19:27.544333 29475 net.cpp:127] Setting up pool10
I1028 17:19:27.544348 29475 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1028 17:19:27.544353 29475 net.cpp:144] Memory required for data: 1615540600
I1028 17:19:27.544360 29475 layer_factory.hpp:77] Creating layer pool10_pool10_0_split
I1028 17:19:27.544368 29475 net.cpp:84] Creating Layer pool10_pool10_0_split
I1028 17:19:27.544373 29475 net.cpp:413] pool10_pool10_0_split <- pool10
I1028 17:19:27.544381 29475 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_0
I1028 17:19:27.544390 29475 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_1
I1028 17:19:27.544397 29475 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_2
I1028 17:19:27.544464 29475 net.cpp:127] Setting up pool10_pool10_0_split
I1028 17:19:27.544473 29475 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1028 17:19:27.544481 29475 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1028 17:19:27.544486 29475 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1028 17:19:27.544490 29475 net.cpp:144] Memory required for data: 1616140600
I1028 17:19:27.544494 29475 layer_factory.hpp:77] Creating layer loss
I1028 17:19:27.544503 29475 net.cpp:84] Creating Layer loss
I1028 17:19:27.544508 29475 net.cpp:413] loss <- pool10_pool10_0_split_0
I1028 17:19:27.544515 29475 net.cpp:413] loss <- label_data_1_split_0
I1028 17:19:27.544522 29475 net.cpp:387] loss -> loss
I1028 17:19:27.544533 29475 layer_factory.hpp:77] Creating layer loss
I1028 17:19:27.544898 29475 net.cpp:127] Setting up loss
I1028 17:19:27.544912 29475 net.cpp:136] Top shape: (1)
I1028 17:19:27.544917 29475 net.cpp:139]     with loss weight 1
I1028 17:19:27.544929 29475 net.cpp:144] Memory required for data: 1616140604
I1028 17:19:27.544934 29475 layer_factory.hpp:77] Creating layer accuracy_top1
I1028 17:19:27.544947 29475 net.cpp:84] Creating Layer accuracy_top1
I1028 17:19:27.544955 29475 net.cpp:413] accuracy_top1 <- pool10_pool10_0_split_1
I1028 17:19:27.544961 29475 net.cpp:413] accuracy_top1 <- label_data_1_split_1
I1028 17:19:27.544968 29475 net.cpp:387] accuracy_top1 -> accuracy_top1
I1028 17:19:27.544981 29475 net.cpp:127] Setting up accuracy_top1
I1028 17:19:27.544988 29475 net.cpp:136] Top shape: (1)
I1028 17:19:27.544992 29475 net.cpp:144] Memory required for data: 1616140608
I1028 17:19:27.545003 29475 layer_factory.hpp:77] Creating layer accuracy_top5
I1028 17:19:27.545025 29475 net.cpp:84] Creating Layer accuracy_top5
I1028 17:19:27.545032 29475 net.cpp:413] accuracy_top5 <- pool10_pool10_0_split_2
I1028 17:19:27.545037 29475 net.cpp:413] accuracy_top5 <- label_data_1_split_2
I1028 17:19:27.545047 29475 net.cpp:387] accuracy_top5 -> accuracy_top5
I1028 17:19:27.545061 29475 net.cpp:127] Setting up accuracy_top5
I1028 17:19:27.545068 29475 net.cpp:136] Top shape: (1)
I1028 17:19:27.545073 29475 net.cpp:144] Memory required for data: 1616140612
I1028 17:19:27.545078 29475 net.cpp:207] accuracy_top5 does not need backward computation.
I1028 17:19:27.545083 29475 net.cpp:207] accuracy_top1 does not need backward computation.
I1028 17:19:27.545089 29475 net.cpp:205] loss needs backward computation.
I1028 17:19:27.545094 29475 net.cpp:205] pool10_pool10_0_split needs backward computation.
I1028 17:19:27.545099 29475 net.cpp:205] pool10 needs backward computation.
I1028 17:19:27.545104 29475 net.cpp:205] relu_conv10 needs backward computation.
I1028 17:19:27.545107 29475 net.cpp:205] conv10 needs backward computation.
I1028 17:19:27.545112 29475 net.cpp:205] drop9 needs backward computation.
I1028 17:19:27.545116 29475 net.cpp:205] fire9/concat needs backward computation.
I1028 17:19:27.545121 29475 net.cpp:205] fire9/relu_expand3x3 needs backward computation.
I1028 17:19:27.545126 29475 net.cpp:205] fire9/expand3x3 needs backward computation.
I1028 17:19:27.545131 29475 net.cpp:205] fire9/relu_expand1x1 needs backward computation.
I1028 17:19:27.545135 29475 net.cpp:205] fire9/expand1x1 needs backward computation.
I1028 17:19:27.545141 29475 net.cpp:205] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I1028 17:19:27.545145 29475 net.cpp:205] fire9/relu_squeeze1x1 needs backward computation.
I1028 17:19:27.545150 29475 net.cpp:205] fire9/squeeze1x1 needs backward computation.
I1028 17:19:27.545156 29475 net.cpp:205] fire8/concat needs backward computation.
I1028 17:19:27.545161 29475 net.cpp:205] fire8/relu_expand3x3 needs backward computation.
I1028 17:19:27.545164 29475 net.cpp:205] fire8/expand3x3 needs backward computation.
I1028 17:19:27.545169 29475 net.cpp:205] fire8/relu_expand1x1 needs backward computation.
I1028 17:19:27.545173 29475 net.cpp:205] fire8/expand1x1 needs backward computation.
I1028 17:19:27.545178 29475 net.cpp:205] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I1028 17:19:27.545183 29475 net.cpp:205] fire8/relu_squeeze1x1 needs backward computation.
I1028 17:19:27.545187 29475 net.cpp:205] fire8/squeeze1x1 needs backward computation.
I1028 17:19:27.545192 29475 net.cpp:205] fire7/concat needs backward computation.
I1028 17:19:27.545198 29475 net.cpp:205] fire7/relu_expand3x3 needs backward computation.
I1028 17:19:27.545203 29475 net.cpp:205] fire7/expand3x3 needs backward computation.
I1028 17:19:27.545207 29475 net.cpp:205] fire7/relu_expand1x1 needs backward computation.
I1028 17:19:27.545212 29475 net.cpp:205] fire7/expand1x1 needs backward computation.
I1028 17:19:27.545217 29475 net.cpp:205] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I1028 17:19:27.545222 29475 net.cpp:205] fire7/relu_squeeze1x1 needs backward computation.
I1028 17:19:27.545225 29475 net.cpp:205] fire7/squeeze1x1 needs backward computation.
I1028 17:19:27.545230 29475 net.cpp:205] fire6/concat needs backward computation.
I1028 17:19:27.545235 29475 net.cpp:205] fire6/relu_expand3x3 needs backward computation.
I1028 17:19:27.545240 29475 net.cpp:205] fire6/expand3x3 needs backward computation.
I1028 17:19:27.545244 29475 net.cpp:205] fire6/relu_expand1x1 needs backward computation.
I1028 17:19:27.545249 29475 net.cpp:205] fire6/expand1x1 needs backward computation.
I1028 17:19:27.545253 29475 net.cpp:205] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I1028 17:19:27.545258 29475 net.cpp:205] fire6/relu_squeeze1x1 needs backward computation.
I1028 17:19:27.545262 29475 net.cpp:205] fire6/squeeze1x1 needs backward computation.
I1028 17:19:27.545271 29475 net.cpp:205] pool5 needs backward computation.
I1028 17:19:27.545281 29475 net.cpp:205] fire5/concat needs backward computation.
I1028 17:19:27.545286 29475 net.cpp:205] fire5/relu_expand3x3 needs backward computation.
I1028 17:19:27.545291 29475 net.cpp:205] fire5/expand3x3 needs backward computation.
I1028 17:19:27.545295 29475 net.cpp:205] fire5/relu_expand1x1 needs backward computation.
I1028 17:19:27.545307 29475 net.cpp:205] fire5/expand1x1 needs backward computation.
I1028 17:19:27.545312 29475 net.cpp:205] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I1028 17:19:27.545317 29475 net.cpp:205] fire5/relu_squeeze1x1 needs backward computation.
I1028 17:19:27.545321 29475 net.cpp:205] fire5/squeeze1x1 needs backward computation.
I1028 17:19:27.545325 29475 net.cpp:205] fire4/concat needs backward computation.
I1028 17:19:27.545331 29475 net.cpp:205] fire4/relu_expand3x3 needs backward computation.
I1028 17:19:27.545334 29475 net.cpp:205] fire4/expand3x3 needs backward computation.
I1028 17:19:27.545339 29475 net.cpp:205] fire4/relu_expand1x1 needs backward computation.
I1028 17:19:27.545343 29475 net.cpp:205] fire4/expand1x1 needs backward computation.
I1028 17:19:27.545348 29475 net.cpp:205] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I1028 17:19:27.545352 29475 net.cpp:205] fire4/relu_squeeze1x1 needs backward computation.
I1028 17:19:27.545357 29475 net.cpp:205] fire4/squeeze1x1 needs backward computation.
I1028 17:19:27.545361 29475 net.cpp:205] pool3 needs backward computation.
I1028 17:19:27.545367 29475 net.cpp:205] fire3/concat needs backward computation.
I1028 17:19:27.545370 29475 net.cpp:205] fire3/relu_expand3x3 needs backward computation.
I1028 17:19:27.545375 29475 net.cpp:205] fire3/expand3x3 needs backward computation.
I1028 17:19:27.545379 29475 net.cpp:205] fire3/relu_expand1x1 needs backward computation.
I1028 17:19:27.545383 29475 net.cpp:205] fire3/expand1x1 needs backward computation.
I1028 17:19:27.545388 29475 net.cpp:205] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I1028 17:19:27.545392 29475 net.cpp:205] fire3/relu_squeeze1x1 needs backward computation.
I1028 17:19:27.545397 29475 net.cpp:205] fire3/squeeze1x1 needs backward computation.
I1028 17:19:27.545402 29475 net.cpp:205] fire2/concat needs backward computation.
I1028 17:19:27.545406 29475 net.cpp:205] fire2/relu_expand3x3 needs backward computation.
I1028 17:19:27.545410 29475 net.cpp:205] fire2/expand3x3 needs backward computation.
I1028 17:19:27.545415 29475 net.cpp:205] fire2/relu_expand1x1 needs backward computation.
I1028 17:19:27.545421 29475 net.cpp:205] fire2/expand1x1 needs backward computation.
I1028 17:19:27.545430 29475 net.cpp:205] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I1028 17:19:27.545434 29475 net.cpp:205] fire2/relu_squeeze1x1 needs backward computation.
I1028 17:19:27.545439 29475 net.cpp:205] fire2/squeeze1x1 needs backward computation.
I1028 17:19:27.545444 29475 net.cpp:205] pool1 needs backward computation.
I1028 17:19:27.545449 29475 net.cpp:205] relu_conv1 needs backward computation.
I1028 17:19:27.545454 29475 net.cpp:205] conv1 needs backward computation.
I1028 17:19:27.545459 29475 net.cpp:207] label_data_1_split does not need backward computation.
I1028 17:19:27.545467 29475 net.cpp:207] data does not need backward computation.
I1028 17:19:27.545472 29475 net.cpp:249] This network produces output accuracy_top1
I1028 17:19:27.545477 29475 net.cpp:249] This network produces output accuracy_top5
I1028 17:19:27.545482 29475 net.cpp:249] This network produces output loss
I1028 17:19:27.545537 29475 net.cpp:262] Network initialization done.
I1028 17:19:27.545819 29475 solver.cpp:56] Solver scaffolding done.
I1028 17:19:27.550457 29475 caffe.cpp:155] Finetuning from SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_170000.caffemodel
I1028 17:19:27.569380 29475 caffe.cpp:248] Starting Optimization
I1028 17:19:31.494951 29527 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_40.prototxt
I1028 17:19:31.502506 29526 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_40.prototxt
I1028 17:19:31.547646 29525 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_40.prototxt
I1028 17:19:32.466270 29475 solver.cpp:276] Solving SqueezeNet
I1028 17:19:32.466346 29475 solver.cpp:277] Learning Rate Policy: poly
I1028 17:19:32.466920 29475 solver.cpp:334] Iteration 0, Testing net (#0)
I1028 17:20:03.913996 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.59
I1028 17:20:03.914121 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.811479
I1028 17:20:03.914137 29475 solver.cpp:401]     Test net output #2: loss = 1.81772 (* 1 = 1.81772 loss)
I1028 17:20:03.914258 29475 inq_conv_layer.cu:52] conv1 (INQConvolution):  Shaping the weights...
I1028 17:20:03.914319 29475 inq_conv_layer.cpp:263] Max_power = 0
I1028 17:20:03.914330 29475 inq_conv_layer.cpp:264] Min_power = -6
I1028 17:20:03.914352 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0231% -> 39.9884%)
I1028 17:20:03.914369 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 1728/1728
I1028 17:20:03.914376 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 345/1037/1382
I1028 17:20:03.914530 29475 inq_conv_layer.cu:62] conv1 (INQConvolution):  Shaping the bias...
I1028 17:20:03.914567 29475 inq_conv_layer.cpp:263] Max_power = -2
I1028 17:20:03.914577 29475 inq_conv_layer.cpp:264] Min_power = -8
I1028 17:20:03.914584 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.3125% -> 40.625%)
I1028 17:20:03.914597 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 64/64
I1028 17:20:03.914602 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 13/38/51
I1028 17:20:03.927640 29475 inq_conv_layer.cu:52] fire2/squeeze1x1 (INQConvolution):  Shaping the weights...
I1028 17:20:03.945029 29475 inq_conv_layer.cpp:263] Max_power = 0
I1028 17:20:03.945044 29475 inq_conv_layer.cpp:264] Min_power = -6
I1028 17:20:03.945065 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0195% -> 40.0391%)
I1028 17:20:03.945080 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 1024/1024
I1028 17:20:03.945087 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 205/614/819
I1028 17:20:03.945178 29475 inq_conv_layer.cu:62] fire2/squeeze1x1 (INQConvolution):  Shaping the bias...
I1028 17:20:03.945214 29475 inq_conv_layer.cpp:263] Max_power = -2
I1028 17:20:03.945224 29475 inq_conv_layer.cpp:264] Min_power = -8
I1028 17:20:03.945232 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 18.75% -> 37.5%)
I1028 17:20:03.945245 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 16/16
I1028 17:20:03.945250 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 3/10/13
I1028 17:20:03.948758 29475 inq_conv_layer.cu:52] fire2/expand1x1 (INQConvolution):  Shaping the weights...
I1028 17:20:03.949019 29475 inq_conv_layer.cpp:263] Max_power = 0
I1028 17:20:03.949033 29475 inq_conv_layer.cpp:264] Min_power = -6
I1028 17:20:03.949053 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0195% -> 40.0391%)
I1028 17:20:03.949067 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 1024/1024
I1028 17:20:03.949074 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 205/614/819
I1028 17:20:03.949167 29475 inq_conv_layer.cu:62] fire2/expand1x1 (INQConvolution):  Shaping the bias...
I1028 17:20:03.949203 29475 inq_conv_layer.cpp:263] Max_power = -3
I1028 17:20:03.949211 29475 inq_conv_layer.cpp:264] Min_power = -9
I1028 17:20:03.949224 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.3125% -> 40.625%)
I1028 17:20:03.949237 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 64/64
I1028 17:20:03.949244 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 13/38/51
I1028 17:20:03.953351 29475 inq_conv_layer.cu:52] fire2/expand3x3 (INQConvolution):  Shaping the weights...
I1028 17:20:03.954531 29475 inq_conv_layer.cpp:263] Max_power = -1
I1028 17:20:03.954545 29475 inq_conv_layer.cpp:264] Min_power = -7
I1028 17:20:03.954623 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9978% -> 39.9957%)
I1028 17:20:03.954643 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 9216/9216
I1028 17:20:03.954650 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 1843/5530/7373
I1028 17:20:03.955531 29475 inq_conv_layer.cu:62] fire2/expand3x3 (INQConvolution):  Shaping the bias...
I1028 17:20:03.955575 29475 inq_conv_layer.cpp:263] Max_power = -4
I1028 17:20:03.955600 29475 inq_conv_layer.cpp:264] Min_power = -10
I1028 17:20:03.955608 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.3125% -> 40.625%)
I1028 17:20:03.955620 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 64/64
I1028 17:20:03.955624 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 13/38/51
I1028 17:20:03.964972 29475 inq_conv_layer.cu:52] fire3/squeeze1x1 (INQConvolution):  Shaping the weights...
I1028 17:20:03.968379 29475 inq_conv_layer.cpp:263] Max_power = 0
I1028 17:20:03.968391 29475 inq_conv_layer.cpp:264] Min_power = -6
I1028 17:20:03.968412 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0195% -> 39.9902%)
I1028 17:20:03.968426 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 2048/2048
I1028 17:20:03.968432 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 409/1229/1638
I1028 17:20:03.968616 29475 inq_conv_layer.cu:62] fire3/squeeze1x1 (INQConvolution):  Shaping the bias...
I1028 17:20:03.968653 29475 inq_conv_layer.cpp:263] Max_power = -2
I1028 17:20:03.968662 29475 inq_conv_layer.cpp:264] Min_power = -8
I1028 17:20:03.968669 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 18.75% -> 37.5%)
I1028 17:20:03.968682 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 16/16
I1028 17:20:03.968689 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 3/10/13
I1028 17:20:03.972146 29475 inq_conv_layer.cu:52] fire3/expand1x1 (INQConvolution):  Shaping the weights...
I1028 17:20:03.972898 29475 inq_conv_layer.cpp:263] Max_power = 0
I1028 17:20:03.972909 29475 inq_conv_layer.cpp:264] Min_power = -6
I1028 17:20:03.972924 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0195% -> 40.0391%)
I1028 17:20:03.972937 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 1024/1024
I1028 17:20:03.972942 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 205/614/819
I1028 17:20:03.973033 29475 inq_conv_layer.cu:62] fire3/expand1x1 (INQConvolution):  Shaping the bias...
I1028 17:20:03.973067 29475 inq_conv_layer.cpp:263] Max_power = -2
I1028 17:20:03.973076 29475 inq_conv_layer.cpp:264] Min_power = -8
I1028 17:20:03.973088 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.3125% -> 40.625%)
I1028 17:20:03.973099 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 64/64
I1028 17:20:03.973104 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 13/38/51
I1028 17:20:03.977185 29475 inq_conv_layer.cu:52] fire3/expand3x3 (INQConvolution):  Shaping the weights...
I1028 17:20:03.978365 29475 inq_conv_layer.cpp:263] Max_power = 0
I1028 17:20:03.978377 29475 inq_conv_layer.cpp:264] Min_power = -6
I1028 17:20:03.978446 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9978% -> 39.9957%)
I1028 17:20:03.978461 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 9216/9216
I1028 17:20:03.978466 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 1843/5530/7373
I1028 17:20:03.979338 29475 inq_conv_layer.cu:62] fire3/expand3x3 (INQConvolution):  Shaping the bias...
I1028 17:20:03.979379 29475 inq_conv_layer.cpp:263] Max_power = -3
I1028 17:20:03.979388 29475 inq_conv_layer.cpp:264] Min_power = -9
I1028 17:20:03.979398 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.3125% -> 40.625%)
I1028 17:20:03.979415 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 64/64
I1028 17:20:03.979423 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 13/38/51
I1028 17:20:03.992336 29475 inq_conv_layer.cu:52] fire4/squeeze1x1 (INQConvolution):  Shaping the weights...
I1028 17:20:03.994168 29475 inq_conv_layer.cpp:263] Max_power = 0
I1028 17:20:03.994180 29475 inq_conv_layer.cpp:264] Min_power = -6
I1028 17:20:03.994215 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9951% -> 39.9902%)
I1028 17:20:03.994232 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 4096/4096
I1028 17:20:03.994237 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 819/2458/3277
I1028 17:20:03.994628 29475 inq_conv_layer.cu:62] fire4/squeeze1x1 (INQConvolution):  Shaping the bias...
I1028 17:20:03.994670 29475 inq_conv_layer.cpp:263] Max_power = -3
I1028 17:20:03.994678 29475 inq_conv_layer.cpp:264] Min_power = -9
I1028 17:20:03.994686 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 18.75% -> 37.5%)
I1028 17:20:03.994698 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 33/32
I1028 17:20:03.994702 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 6/20/26
I1028 17:20:03.998196 29475 inq_conv_layer.cu:52] fire4/expand1x1 (INQConvolution):  Shaping the weights...
I1028 17:20:03.999397 29475 inq_conv_layer.cpp:263] Max_power = -1
I1028 17:20:03.999409 29475 inq_conv_layer.cpp:264] Min_power = -7
I1028 17:20:03.999444 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9951% -> 39.9902%)
I1028 17:20:03.999462 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 4096/4096
I1028 17:20:03.999469 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 819/2458/3277
I1028 17:20:03.999838 29475 inq_conv_layer.cu:62] fire4/expand1x1 (INQConvolution):  Shaping the bias...
I1028 17:20:03.999876 29475 inq_conv_layer.cpp:263] Max_power = -4
I1028 17:20:03.999883 29475 inq_conv_layer.cpp:264] Min_power = -10
I1028 17:20:03.999892 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.3125% -> 39.8438%)
I1028 17:20:03.999902 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 128/128
I1028 17:20:03.999907 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 25/77/102
I1028 17:20:04.003773 29475 inq_conv_layer.cu:52] fire4/expand3x3 (INQConvolution):  Shaping the weights...
I1028 17:20:04.004608 29475 inq_conv_layer.cpp:263] Max_power = -1
I1028 17:20:04.004621 29475 inq_conv_layer.cpp:264] Min_power = -7
I1028 17:20:04.004880 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0005% -> 40.0011%)
I1028 17:20:04.004899 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 36864/36864
I1028 17:20:04.004904 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 7373/22118/29491
I1028 17:20:04.008667 29475 inq_conv_layer.cu:62] fire4/expand3x3 (INQConvolution):  Shaping the bias...
I1028 17:20:04.008711 29475 inq_conv_layer.cpp:263] Max_power = -4
I1028 17:20:04.008720 29475 inq_conv_layer.cpp:264] Min_power = -10
I1028 17:20:04.008730 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.3125% -> 39.8438%)
I1028 17:20:04.008743 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 128/128
I1028 17:20:04.008746 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 25/77/102
I1028 17:20:04.015486 29475 inq_conv_layer.cu:52] fire5/squeeze1x1 (INQConvolution):  Shaping the weights...
I1028 17:20:04.017505 29475 inq_conv_layer.cpp:263] Max_power = -1
I1028 17:20:04.017518 29475 inq_conv_layer.cpp:264] Min_power = -7
I1028 17:20:04.017573 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9951% -> 39.9902%)
I1028 17:20:04.017590 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 8193/8192
I1028 17:20:04.017596 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 1638/4916/6554
I1028 17:20:04.018380 29475 inq_conv_layer.cu:62] fire5/squeeze1x1 (INQConvolution):  Shaping the bias...
I1028 17:20:04.018426 29475 inq_conv_layer.cpp:263] Max_power = -2
I1028 17:20:04.018445 29475 inq_conv_layer.cpp:264] Min_power = -8
I1028 17:20:04.018452 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 18.75% -> 37.5%)
I1028 17:20:04.018465 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 33/32
I1028 17:20:04.018470 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 6/20/26
I1028 17:20:04.023699 29475 inq_conv_layer.cu:52] fire5/expand1x1 (INQConvolution):  Shaping the weights...
I1028 17:20:04.025497 29475 inq_conv_layer.cpp:263] Max_power = -1
I1028 17:20:04.025509 29475 inq_conv_layer.cpp:264] Min_power = -7
I1028 17:20:04.025557 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9951% -> 39.9902%)
I1028 17:20:04.025571 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 4096/4096
I1028 17:20:04.025576 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 819/2458/3277
I1028 17:20:04.025951 29475 inq_conv_layer.cu:62] fire5/expand1x1 (INQConvolution):  Shaping the bias...
I1028 17:20:04.025990 29475 inq_conv_layer.cpp:263] Max_power = -3
I1028 17:20:04.026000 29475 inq_conv_layer.cpp:264] Min_power = -9
I1028 17:20:04.026008 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.3125% -> 39.8438%)
I1028 17:20:04.026020 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 128/128
I1028 17:20:04.026024 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 25/77/102
I1028 17:20:04.029886 29475 inq_conv_layer.cu:52] fire5/expand3x3 (INQConvolution):  Shaping the weights...
I1028 17:20:04.030733 29475 inq_conv_layer.cpp:263] Max_power = 0
I1028 17:20:04.030746 29475 inq_conv_layer.cpp:264] Min_power = -6
I1028 17:20:04.030968 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0005% -> 40.0011%)
I1028 17:20:04.030987 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 36864/36864
I1028 17:20:04.030992 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 7373/22118/29491
I1028 17:20:04.034759 29475 inq_conv_layer.cu:62] fire5/expand3x3 (INQConvolution):  Shaping the bias...
I1028 17:20:04.034802 29475 inq_conv_layer.cpp:263] Max_power = -5
I1028 17:20:04.034813 29475 inq_conv_layer.cpp:264] Min_power = -11
I1028 17:20:04.034823 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.3125% -> 39.8438%)
I1028 17:20:04.034837 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 128/128
I1028 17:20:04.034842 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 25/77/102
I1028 17:20:04.044849 29475 inq_conv_layer.cu:52] fire6/squeeze1x1 (INQConvolution):  Shaping the weights...
I1028 17:20:04.045832 29475 inq_conv_layer.cpp:263] Max_power = -1
I1028 17:20:04.045846 29475 inq_conv_layer.cpp:264] Min_power = -7
I1028 17:20:04.045924 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0033% -> 39.9984%)
I1028 17:20:04.045940 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 12288/12288
I1028 17:20:04.045945 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 2457/7373/9830
I1028 17:20:04.047132 29475 inq_conv_layer.cu:62] fire6/squeeze1x1 (INQConvolution):  Shaping the bias...
I1028 17:20:04.047173 29475 inq_conv_layer.cpp:263] Max_power = -3
I1028 17:20:04.047180 29475 inq_conv_layer.cpp:264] Min_power = -9
I1028 17:20:04.047189 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.8333% -> 39.5833%)
I1028 17:20:04.047202 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 48/48
I1028 17:20:04.047207 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 9/29/38
I1028 17:20:04.050947 29475 inq_conv_layer.cu:52] fire6/expand1x1 (INQConvolution):  Shaping the weights...
I1028 17:20:04.053257 29475 inq_conv_layer.cpp:263] Max_power = -1
I1028 17:20:04.053272 29475 inq_conv_layer.cpp:264] Min_power = -7
I1028 17:20:04.053338 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9978% -> 39.9957%)
I1028 17:20:04.053361 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 9216/9216
I1028 17:20:04.053369 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 1843/5530/7373
I1028 17:20:04.054250 29475 inq_conv_layer.cu:62] fire6/expand1x1 (INQConvolution):  Shaping the bias...
I1028 17:20:04.054289 29475 inq_conv_layer.cpp:263] Max_power = -5
I1028 17:20:04.054302 29475 inq_conv_layer.cpp:264] Min_power = -11
I1028 17:20:04.054314 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.7917% -> 39.5833%)
I1028 17:20:04.054327 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 193/192
I1028 17:20:04.054333 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 38/116/154
I1028 17:20:04.057991 29475 inq_conv_layer.cu:52] fire6/expand3x3 (INQConvolution):  Shaping the weights...
I1028 17:20:04.058893 29475 inq_conv_layer.cpp:263] Max_power = -1
I1028 17:20:04.058907 29475 inq_conv_layer.cpp:264] Min_power = -7
I1028 17:20:04.059536 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0002% -> 40.0005%)
I1028 17:20:04.059556 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 82944/82944
I1028 17:20:04.059561 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 16589/49766/66355
I1028 17:20:04.068513 29475 inq_conv_layer.cu:62] fire6/expand3x3 (INQConvolution):  Shaping the bias...
I1028 17:20:04.068557 29475 inq_conv_layer.cpp:263] Max_power = -5
I1028 17:20:04.068567 29475 inq_conv_layer.cpp:264] Min_power = -11
I1028 17:20:04.068578 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.7917% -> 39.5833%)
I1028 17:20:04.068591 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 193/192
I1028 17:20:04.068596 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 38/116/154
I1028 17:20:04.075040 29475 inq_conv_layer.cu:52] fire7/squeeze1x1 (INQConvolution):  Shaping the weights...
I1028 17:20:04.076988 29475 inq_conv_layer.cpp:263] Max_power = -1
I1028 17:20:04.077002 29475 inq_conv_layer.cpp:264] Min_power = -7
I1028 17:20:04.077111 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9978% -> 39.9957%)
I1028 17:20:04.077127 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 18433/18432
I1028 17:20:04.077133 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 3686/11060/14746
I1028 17:20:04.078963 29475 inq_conv_layer.cu:62] fire7/squeeze1x1 (INQConvolution):  Shaping the bias...
I1028 17:20:04.079005 29475 inq_conv_layer.cpp:263] Max_power = -2
I1028 17:20:04.079011 29475 inq_conv_layer.cpp:264] Min_power = -8
I1028 17:20:04.079020 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.8333% -> 39.5833%)
I1028 17:20:04.079032 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 48/48
I1028 17:20:04.079037 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 9/29/38
I1028 17:20:04.082653 29475 inq_conv_layer.cu:52] fire7/expand1x1 (INQConvolution):  Shaping the weights...
I1028 17:20:04.086177 29475 inq_conv_layer.cpp:263] Max_power = -1
I1028 17:20:04.086190 29475 inq_conv_layer.cpp:264] Min_power = -7
I1028 17:20:04.086251 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9978% -> 39.9957%)
I1028 17:20:04.086266 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 9216/9216
I1028 17:20:04.086272 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 1843/5530/7373
I1028 17:20:04.087147 29475 inq_conv_layer.cu:62] fire7/expand1x1 (INQConvolution):  Shaping the bias...
I1028 17:20:04.087188 29475 inq_conv_layer.cpp:263] Max_power = -2
I1028 17:20:04.087195 29475 inq_conv_layer.cpp:264] Min_power = -8
I1028 17:20:04.087205 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.7917% -> 39.5833%)
I1028 17:20:04.087218 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 193/192
I1028 17:20:04.087224 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 38/116/154
I1028 17:20:04.090873 29475 inq_conv_layer.cu:52] fire7/expand3x3 (INQConvolution):  Shaping the weights...
I1028 17:20:04.091759 29475 inq_conv_layer.cpp:263] Max_power = -1
I1028 17:20:04.091773 29475 inq_conv_layer.cpp:264] Min_power = -7
I1028 17:20:04.092263 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0002% -> 40.0005%)
I1028 17:20:04.092281 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 82944/82944
I1028 17:20:04.092286 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 16589/49766/66355
I1028 17:20:04.101176 29475 inq_conv_layer.cu:62] fire7/expand3x3 (INQConvolution):  Shaping the bias...
I1028 17:20:04.101220 29475 inq_conv_layer.cpp:263] Max_power = -4
I1028 17:20:04.101228 29475 inq_conv_layer.cpp:264] Min_power = -10
I1028 17:20:04.101239 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.7917% -> 39.5833%)
I1028 17:20:04.101266 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 193/192
I1028 17:20:04.101271 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 38/116/154
I1028 17:20:04.107745 29475 inq_conv_layer.cu:52] fire8/squeeze1x1 (INQConvolution):  Shaping the weights...
I1028 17:20:04.109680 29475 inq_conv_layer.cpp:263] Max_power = -1
I1028 17:20:04.109694 29475 inq_conv_layer.cpp:264] Min_power = -7
I1028 17:20:04.109839 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9992% -> 39.9984%)
I1028 17:20:04.109855 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 24576/24576
I1028 17:20:04.109861 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 4915/14746/19661
I1028 17:20:04.112349 29475 inq_conv_layer.cu:62] fire8/squeeze1x1 (INQConvolution):  Shaping the bias...
I1028 17:20:04.112391 29475 inq_conv_layer.cpp:263] Max_power = 3
I1028 17:20:04.112399 29475 inq_conv_layer.cpp:264] Min_power = -3
I1028 17:20:04.112408 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.3125% -> 40.625%)
I1028 17:20:04.112421 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 64/64
I1028 17:20:04.112426 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 13/38/51
I1028 17:20:04.116071 29475 inq_conv_layer.cu:52] fire8/expand1x1 (INQConvolution):  Shaping the weights...
I1028 17:20:04.119704 29475 inq_conv_layer.cpp:263] Max_power = -1
I1028 17:20:04.119717 29475 inq_conv_layer.cpp:264] Min_power = -7
I1028 17:20:04.119815 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0012% -> 40.0024%)
I1028 17:20:04.119832 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 16384/16384
I1028 17:20:04.119837 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 3277/9830/13107
I1028 17:20:04.121459 29475 inq_conv_layer.cu:62] fire8/expand1x1 (INQConvolution):  Shaping the bias...
I1028 17:20:04.121500 29475 inq_conv_layer.cpp:263] Max_power = -1
I1028 17:20:04.121510 29475 inq_conv_layer.cpp:264] Min_power = -7
I1028 17:20:04.121520 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9219% -> 39.8438%)
I1028 17:20:04.121533 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 256/256
I1028 17:20:04.121537 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 51/154/205
I1028 17:20:04.125239 29475 inq_conv_layer.cu:52] fire8/expand3x3 (INQConvolution):  Shaping the weights...
I1028 17:20:04.126687 29475 inq_conv_layer.cpp:263] Max_power = -1
I1028 17:20:04.126700 29475 inq_conv_layer.cpp:264] Min_power = -7
I1028 17:20:04.127553 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9999% -> 39.9997%)
I1028 17:20:04.127571 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 147456/147456
I1028 17:20:04.127576 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 29491/88474/117965
I1028 17:20:04.143880 29475 inq_conv_layer.cu:62] fire8/expand3x3 (INQConvolution):  Shaping the bias...
I1028 17:20:04.143927 29475 inq_conv_layer.cpp:263] Max_power = -1
I1028 17:20:04.143935 29475 inq_conv_layer.cpp:264] Min_power = -7
I1028 17:20:04.143949 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9219% -> 39.8438%)
I1028 17:20:04.143971 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 256/256
I1028 17:20:04.143977 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 51/154/205
I1028 17:20:04.151227 29475 inq_conv_layer.cu:52] fire9/squeeze1x1 (INQConvolution):  Shaping the weights...
I1028 17:20:04.154676 29475 inq_conv_layer.cpp:263] Max_power = -1
I1028 17:20:04.154690 29475 inq_conv_layer.cpp:264] Min_power = -7
I1028 17:20:04.154881 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0012% -> 39.9994%)
I1028 17:20:04.154899 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 32768/32768
I1028 17:20:04.154904 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 6553/19661/26214
I1028 17:20:04.158260 29475 inq_conv_layer.cu:62] fire9/squeeze1x1 (INQConvolution):  Shaping the bias...
I1028 17:20:04.158304 29475 inq_conv_layer.cpp:263] Max_power = 0
I1028 17:20:04.158316 29475 inq_conv_layer.cpp:264] Min_power = -6
I1028 17:20:04.158326 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.3125% -> 40.625%)
I1028 17:20:04.158339 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 64/64
I1028 17:20:04.158344 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 13/38/51
I1028 17:20:04.161998 29475 inq_conv_layer.cu:52] fire9/expand1x1 (INQConvolution):  Shaping the weights...
I1028 17:20:04.166852 29475 inq_conv_layer.cpp:263] Max_power = -1
I1028 17:20:04.166867 29475 inq_conv_layer.cpp:264] Min_power = -7
I1028 17:20:04.166967 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20.0012% -> 40.0024%)
I1028 17:20:04.166983 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 16384/16384
I1028 17:20:04.166988 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 3277/9830/13107
I1028 17:20:04.168599 29475 inq_conv_layer.cu:62] fire9/expand1x1 (INQConvolution):  Shaping the bias...
I1028 17:20:04.168642 29475 inq_conv_layer.cpp:263] Max_power = -4
I1028 17:20:04.168653 29475 inq_conv_layer.cpp:264] Min_power = -10
I1028 17:20:04.168661 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9219% -> 39.8438%)
I1028 17:20:04.168674 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 256/256
I1028 17:20:04.168687 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 51/154/205
I1028 17:20:04.172395 29475 inq_conv_layer.cu:52] fire9/expand3x3 (INQConvolution):  Shaping the weights...
I1028 17:20:04.173820 29475 inq_conv_layer.cpp:263] Max_power = -1
I1028 17:20:04.173833 29475 inq_conv_layer.cpp:264] Min_power = -7
I1028 17:20:04.174628 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9999% -> 39.9997%)
I1028 17:20:04.174645 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 147456/147456
I1028 17:20:04.174650 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 29491/88474/117965
I1028 17:20:04.190963 29475 inq_conv_layer.cu:62] fire9/expand3x3 (INQConvolution):  Shaping the bias...
I1028 17:20:04.191006 29475 inq_conv_layer.cpp:263] Max_power = -5
I1028 17:20:04.191016 29475 inq_conv_layer.cpp:264] Min_power = -11
I1028 17:20:04.191026 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 19.9219% -> 39.8438%)
I1028 17:20:04.191040 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 256/256
I1028 17:20:04.191045 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 51/154/205
I1028 17:20:04.205114 29475 inq_conv_layer.cu:52] conv10 (INQConvolution):  Shaping the weights...
I1028 17:20:04.208681 29475 inq_conv_layer.cpp:263] Max_power = -2
I1028 17:20:04.208695 29475 inq_conv_layer.cpp:264] Min_power = -8
I1028 17:20:04.212085 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20% -> 40%)
I1028 17:20:04.212103 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 512000/512000
I1028 17:20:04.212108 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 102400/307200/409600
I1028 17:20:04.272392 29475 inq_conv_layer.cu:62] conv10 (INQConvolution):  Shaping the bias...
I1028 17:20:04.272449 29475 inq_conv_layer.cpp:263] Max_power = -2
I1028 17:20:04.272460 29475 inq_conv_layer.cpp:264] Min_power = -8
I1028 17:20:04.272480 29475 inq_conv_layer.cpp:307] portions: 20% -> 40% (total: 20% -> 40%)
I1028 17:20:04.272490 29475 inq_conv_layer.cpp:313] init_not_quantized/total: 1000/1000
I1028 17:20:04.272495 29475 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 200/600/800
I1028 17:20:05.164672 29475 solver.cpp:222] Iteration 0 (-2.84572e-36 iter/s, 32.696s/40 iters), loss = 1.90886
I1028 17:20:05.164731 29475 solver.cpp:241]     Train net output #0: loss = 1.90886 (* 1 = 1.90886 loss)
I1028 17:20:05.164757 29475 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I1028 17:20:35.843086 29475 solver.cpp:222] Iteration 40 (1.3039 iter/s, 30.6772s/40 iters), loss = 2.22323
I1028 17:20:35.843380 29475 solver.cpp:241]     Train net output #0: loss = 2.22323 (* 1 = 2.22323 loss)
I1028 17:20:35.843400 29475 sgd_solver.cpp:105] Iteration 40, lr = 0.0099948
I1028 17:21:06.371816 29475 solver.cpp:222] Iteration 80 (1.3103 iter/s, 30.5273s/40 iters), loss = 2.06655
I1028 17:21:06.372005 29475 solver.cpp:241]     Train net output #0: loss = 2.06655 (* 1 = 2.06655 loss)
I1028 17:21:06.372025 29475 sgd_solver.cpp:105] Iteration 80, lr = 0.0099896
I1028 17:21:36.946573 29475 solver.cpp:222] Iteration 120 (1.30833 iter/s, 30.5734s/40 iters), loss = 1.89621
I1028 17:21:36.946789 29475 solver.cpp:241]     Train net output #0: loss = 1.89621 (* 1 = 1.89621 loss)
I1028 17:21:36.946805 29475 sgd_solver.cpp:105] Iteration 120, lr = 0.0099844
I1028 17:22:07.574618 29475 solver.cpp:222] Iteration 160 (1.30605 iter/s, 30.6267s/40 iters), loss = 1.6147
I1028 17:22:07.574815 29475 solver.cpp:241]     Train net output #0: loss = 1.6147 (* 1 = 1.6147 loss)
I1028 17:22:07.574831 29475 sgd_solver.cpp:105] Iteration 160, lr = 0.0099792
I1028 17:22:38.236213 29475 solver.cpp:222] Iteration 200 (1.30462 iter/s, 30.6602s/40 iters), loss = 1.95484
I1028 17:22:38.236402 29475 solver.cpp:241]     Train net output #0: loss = 1.95484 (* 1 = 1.95484 loss)
I1028 17:22:38.236418 29475 sgd_solver.cpp:105] Iteration 200, lr = 0.00997401
I1028 17:23:09.004952 29475 solver.cpp:222] Iteration 240 (1.30008 iter/s, 30.7674s/40 iters), loss = 1.79645
I1028 17:23:09.005151 29475 solver.cpp:241]     Train net output #0: loss = 1.79645 (* 1 = 1.79645 loss)
I1028 17:23:09.005168 29475 sgd_solver.cpp:105] Iteration 240, lr = 0.00996881
I1028 17:23:39.699877 29475 solver.cpp:222] Iteration 280 (1.3032 iter/s, 30.6936s/40 iters), loss = 1.62351
I1028 17:23:39.700048 29475 solver.cpp:241]     Train net output #0: loss = 1.62351 (* 1 = 1.62351 loss)
I1028 17:23:39.700064 29475 sgd_solver.cpp:105] Iteration 280, lr = 0.00996361
I1028 17:24:11.025806 29475 solver.cpp:222] Iteration 320 (1.27695 iter/s, 31.3246s/40 iters), loss = 1.80751
I1028 17:24:11.025995 29475 solver.cpp:241]     Train net output #0: loss = 1.80751 (* 1 = 1.80751 loss)
I1028 17:24:11.026011 29475 sgd_solver.cpp:105] Iteration 320, lr = 0.00995842
I1028 17:24:41.507889 29475 solver.cpp:222] Iteration 360 (1.3123 iter/s, 30.4807s/40 iters), loss = 1.74826
I1028 17:24:41.508067 29475 solver.cpp:241]     Train net output #0: loss = 1.74826 (* 1 = 1.74826 loss)
I1028 17:24:41.508085 29475 sgd_solver.cpp:105] Iteration 360, lr = 0.00995323
I1028 17:25:11.951784 29475 solver.cpp:222] Iteration 400 (1.31395 iter/s, 30.4426s/40 iters), loss = 1.84591
I1028 17:25:11.951972 29475 solver.cpp:241]     Train net output #0: loss = 1.84591 (* 1 = 1.84591 loss)
I1028 17:25:11.951989 29475 sgd_solver.cpp:105] Iteration 400, lr = 0.00994803
I1028 17:25:42.475459 29475 solver.cpp:222] Iteration 440 (1.31052 iter/s, 30.5223s/40 iters), loss = 1.75242
I1028 17:25:42.475638 29475 solver.cpp:241]     Train net output #0: loss = 1.75242 (* 1 = 1.75242 loss)
I1028 17:25:42.475656 29475 sgd_solver.cpp:105] Iteration 440, lr = 0.00994284
I1028 17:26:12.935457 29475 solver.cpp:222] Iteration 480 (1.31325 iter/s, 30.4587s/40 iters), loss = 1.66832
I1028 17:26:12.935686 29475 solver.cpp:241]     Train net output #0: loss = 1.66832 (* 1 = 1.66832 loss)
I1028 17:26:12.935720 29475 sgd_solver.cpp:105] Iteration 480, lr = 0.00993764
I1028 17:26:27.454730 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_500.caffemodel
I1028 17:26:27.551254 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_500.solverstate
I1028 17:26:27.573187 29475 solver.cpp:334] Iteration 500, Testing net (#0)
I1028 17:26:58.310797 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 17:26:58.515159 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.52536
I1028 17:26:58.515223 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77044
I1028 17:26:58.515236 29475 solver.cpp:401]     Test net output #2: loss = 2.08464 (* 1 = 2.08464 loss)
I1028 17:27:14.563360 29475 solver.cpp:222] Iteration 520 (0.649083 iter/s, 61.6254s/40 iters), loss = 1.77781
I1028 17:27:14.563427 29475 solver.cpp:241]     Train net output #0: loss = 1.77781 (* 1 = 1.77781 loss)
I1028 17:27:14.563443 29475 sgd_solver.cpp:105] Iteration 520, lr = 0.00993245
I1028 17:27:45.042382 29475 solver.cpp:222] Iteration 560 (1.31243 iter/s, 30.4778s/40 iters), loss = 2.06637
I1028 17:27:45.042563 29475 solver.cpp:241]     Train net output #0: loss = 2.06637 (* 1 = 2.06637 loss)
I1028 17:27:45.042580 29475 sgd_solver.cpp:105] Iteration 560, lr = 0.00992726
I1028 17:28:15.667248 29475 solver.cpp:222] Iteration 600 (1.30619 iter/s, 30.6235s/40 iters), loss = 1.74936
I1028 17:28:15.667428 29475 solver.cpp:241]     Train net output #0: loss = 1.74936 (* 1 = 1.74936 loss)
I1028 17:28:15.667446 29475 sgd_solver.cpp:105] Iteration 600, lr = 0.00992207
I1028 17:28:46.485478 29475 solver.cpp:222] Iteration 640 (1.29799 iter/s, 30.8169s/40 iters), loss = 1.61912
I1028 17:28:46.485671 29475 solver.cpp:241]     Train net output #0: loss = 1.61912 (* 1 = 1.61912 loss)
I1028 17:28:46.485688 29475 sgd_solver.cpp:105] Iteration 640, lr = 0.00991688
I1028 17:29:17.392101 29475 solver.cpp:222] Iteration 680 (1.29428 iter/s, 30.9053s/40 iters), loss = 1.76837
I1028 17:29:17.392295 29475 solver.cpp:241]     Train net output #0: loss = 1.76837 (* 1 = 1.76837 loss)
I1028 17:29:17.392316 29475 sgd_solver.cpp:105] Iteration 680, lr = 0.00991169
I1028 17:29:48.303010 29475 solver.cpp:222] Iteration 720 (1.2941 iter/s, 30.9095s/40 iters), loss = 1.80912
I1028 17:29:48.303196 29475 solver.cpp:241]     Train net output #0: loss = 1.80912 (* 1 = 1.80912 loss)
I1028 17:29:48.303215 29475 sgd_solver.cpp:105] Iteration 720, lr = 0.0099065
I1028 17:30:19.097364 29475 solver.cpp:222] Iteration 760 (1.299 iter/s, 30.793s/40 iters), loss = 1.93745
I1028 17:30:19.097544 29475 solver.cpp:241]     Train net output #0: loss = 1.93745 (* 1 = 1.93745 loss)
I1028 17:30:19.097561 29475 sgd_solver.cpp:105] Iteration 760, lr = 0.00990131
I1028 17:30:49.933202 29475 solver.cpp:222] Iteration 800 (1.29725 iter/s, 30.8345s/40 iters), loss = 1.75491
I1028 17:30:49.933388 29475 solver.cpp:241]     Train net output #0: loss = 1.75491 (* 1 = 1.75491 loss)
I1028 17:30:49.933406 29475 sgd_solver.cpp:105] Iteration 800, lr = 0.00989612
I1028 17:31:20.584564 29475 solver.cpp:222] Iteration 840 (1.30506 iter/s, 30.65s/40 iters), loss = 1.88961
I1028 17:31:20.584758 29475 solver.cpp:241]     Train net output #0: loss = 1.88961 (* 1 = 1.88961 loss)
I1028 17:31:20.584777 29475 sgd_solver.cpp:105] Iteration 840, lr = 0.00989094
I1028 17:31:51.130831 29475 solver.cpp:222] Iteration 880 (1.30955 iter/s, 30.5449s/40 iters), loss = 1.97072
I1028 17:31:51.130995 29475 solver.cpp:241]     Train net output #0: loss = 1.97072 (* 1 = 1.97072 loss)
I1028 17:31:51.131011 29475 sgd_solver.cpp:105] Iteration 880, lr = 0.00988575
I1028 17:32:21.667521 29475 solver.cpp:222] Iteration 920 (1.30996 iter/s, 30.5354s/40 iters), loss = 1.66507
I1028 17:32:21.667683 29475 solver.cpp:241]     Train net output #0: loss = 1.66507 (* 1 = 1.66507 loss)
I1028 17:32:21.667698 29475 sgd_solver.cpp:105] Iteration 920, lr = 0.00988057
I1028 17:32:52.231191 29475 solver.cpp:222] Iteration 960 (1.3088 iter/s, 30.5623s/40 iters), loss = 1.84502
I1028 17:32:52.231458 29475 solver.cpp:241]     Train net output #0: loss = 1.84502 (* 1 = 1.84502 loss)
I1028 17:32:52.231478 29475 sgd_solver.cpp:105] Iteration 960, lr = 0.00987538
I1028 17:33:22.312939 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_1000.caffemodel
I1028 17:33:22.355918 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_1000.solverstate
I1028 17:33:22.373106 29475 solver.cpp:334] Iteration 1000, Testing net (#0)
I1028 17:33:53.411159 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.52136
I1028 17:33:53.411396 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7652
I1028 17:33:53.411412 29475 solver.cpp:401]     Test net output #2: loss = 2.17552 (* 1 = 2.17552 loss)
I1028 17:33:54.182011 29475 solver.cpp:222] Iteration 1000 (0.6457 iter/s, 61.9482s/40 iters), loss = 1.10858
I1028 17:33:54.182057 29475 solver.cpp:241]     Train net output #0: loss = 1.10858 (* 1 = 1.10858 loss)
I1028 17:33:54.182071 29475 sgd_solver.cpp:105] Iteration 1000, lr = 0.0098702
I1028 17:34:25.007027 29475 solver.cpp:222] Iteration 1040 (1.2977 iter/s, 30.8237s/40 iters), loss = 2.09422
I1028 17:34:25.007239 29475 solver.cpp:241]     Train net output #0: loss = 2.09422 (* 1 = 2.09422 loss)
I1028 17:34:25.007257 29475 sgd_solver.cpp:105] Iteration 1040, lr = 0.00986501
I1028 17:34:55.710844 29475 solver.cpp:222] Iteration 1080 (1.30283 iter/s, 30.7024s/40 iters), loss = 1.99078
I1028 17:34:55.711021 29475 solver.cpp:241]     Train net output #0: loss = 1.99078 (* 1 = 1.99078 loss)
I1028 17:34:55.711037 29475 sgd_solver.cpp:105] Iteration 1080, lr = 0.00985983
I1028 17:35:26.910310 29475 solver.cpp:222] Iteration 1120 (1.28213 iter/s, 31.1981s/40 iters), loss = 1.75122
I1028 17:35:26.910501 29475 solver.cpp:241]     Train net output #0: loss = 1.75122 (* 1 = 1.75122 loss)
I1028 17:35:26.910523 29475 sgd_solver.cpp:105] Iteration 1120, lr = 0.00985464
I1028 17:35:57.874109 29475 solver.cpp:222] Iteration 1160 (1.29189 iter/s, 30.9624s/40 iters), loss = 1.69493
I1028 17:35:57.874308 29475 solver.cpp:241]     Train net output #0: loss = 1.69493 (* 1 = 1.69493 loss)
I1028 17:35:57.874326 29475 sgd_solver.cpp:105] Iteration 1160, lr = 0.00984946
I1028 17:36:28.765388 29475 solver.cpp:222] Iteration 1200 (1.29492 iter/s, 30.8899s/40 iters), loss = 1.47898
I1028 17:36:28.765604 29475 solver.cpp:241]     Train net output #0: loss = 1.47898 (* 1 = 1.47898 loss)
I1028 17:36:28.765621 29475 sgd_solver.cpp:105] Iteration 1200, lr = 0.00984428
I1028 17:36:59.729218 29475 solver.cpp:222] Iteration 1240 (1.29189 iter/s, 30.9624s/40 iters), loss = 1.71365
I1028 17:36:59.729434 29475 solver.cpp:241]     Train net output #0: loss = 1.71365 (* 1 = 1.71365 loss)
I1028 17:36:59.729451 29475 sgd_solver.cpp:105] Iteration 1240, lr = 0.0098391
I1028 17:37:31.204191 29475 solver.cpp:222] Iteration 1280 (1.27091 iter/s, 31.4736s/40 iters), loss = 1.72541
I1028 17:37:31.204367 29475 solver.cpp:241]     Train net output #0: loss = 1.72541 (* 1 = 1.72541 loss)
I1028 17:37:31.204383 29475 sgd_solver.cpp:105] Iteration 1280, lr = 0.00983392
I1028 17:38:01.942922 29475 solver.cpp:222] Iteration 1320 (1.30135 iter/s, 30.7374s/40 iters), loss = 1.99831
I1028 17:38:01.943115 29475 solver.cpp:241]     Train net output #0: loss = 1.99831 (* 1 = 1.99831 loss)
I1028 17:38:01.943131 29475 sgd_solver.cpp:105] Iteration 1320, lr = 0.00982874
I1028 17:38:32.745815 29475 solver.cpp:222] Iteration 1360 (1.29864 iter/s, 30.8015s/40 iters), loss = 1.92104
I1028 17:38:32.745980 29475 solver.cpp:241]     Train net output #0: loss = 1.92104 (* 1 = 1.92104 loss)
I1028 17:38:32.745995 29475 sgd_solver.cpp:105] Iteration 1360, lr = 0.00982356
I1028 17:39:03.585994 29475 solver.cpp:222] Iteration 1400 (1.29707 iter/s, 30.8388s/40 iters), loss = 1.72132
I1028 17:39:03.586232 29475 solver.cpp:241]     Train net output #0: loss = 1.72132 (* 1 = 1.72132 loss)
I1028 17:39:03.586266 29475 sgd_solver.cpp:105] Iteration 1400, lr = 0.00981838
I1028 17:39:34.487677 29475 solver.cpp:222] Iteration 1440 (1.29449 iter/s, 30.9003s/40 iters), loss = 1.85771
I1028 17:39:34.487881 29475 solver.cpp:241]     Train net output #0: loss = 1.85771 (* 1 = 1.85771 loss)
I1028 17:39:34.487906 29475 sgd_solver.cpp:105] Iteration 1440, lr = 0.00981321
I1028 17:40:05.357230 29475 solver.cpp:222] Iteration 1480 (1.29583 iter/s, 30.8682s/40 iters), loss = 1.91849
I1028 17:40:05.357434 29475 solver.cpp:241]     Train net output #0: loss = 1.91849 (* 1 = 1.91849 loss)
I1028 17:40:05.357456 29475 sgd_solver.cpp:105] Iteration 1480, lr = 0.00980803
I1028 17:40:20.341078 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_1500.caffemodel
I1028 17:40:20.400416 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_1500.solverstate
I1028 17:40:20.422437 29475 solver.cpp:334] Iteration 1500, Testing net (#0)
I1028 17:40:51.728473 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 17:40:51.942492 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53272
I1028 17:40:51.942555 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77368
I1028 17:40:51.942567 29475 solver.cpp:401]     Test net output #2: loss = 2.11037 (* 1 = 2.11037 loss)
I1028 17:41:08.345067 29475 solver.cpp:222] Iteration 1520 (0.635069 iter/s, 62.9852s/40 iters), loss = 2.06114
I1028 17:41:08.345175 29475 solver.cpp:241]     Train net output #0: loss = 2.06114 (* 1 = 2.06114 loss)
I1028 17:41:08.345201 29475 sgd_solver.cpp:105] Iteration 1520, lr = 0.00980285
I1028 17:41:40.355454 29475 solver.cpp:222] Iteration 1560 (1.24965 iter/s, 32.0091s/40 iters), loss = 1.91801
I1028 17:41:40.355690 29475 solver.cpp:241]     Train net output #0: loss = 1.91801 (* 1 = 1.91801 loss)
I1028 17:41:40.355711 29475 sgd_solver.cpp:105] Iteration 1560, lr = 0.00979768
I1028 17:42:11.296005 29475 solver.cpp:222] Iteration 1600 (1.29286 iter/s, 30.9391s/40 iters), loss = 1.96562
I1028 17:42:11.296221 29475 solver.cpp:241]     Train net output #0: loss = 1.96562 (* 1 = 1.96562 loss)
I1028 17:42:11.296238 29475 sgd_solver.cpp:105] Iteration 1600, lr = 0.0097925
I1028 17:42:43.006341 29475 solver.cpp:222] Iteration 1640 (1.26147 iter/s, 31.7089s/40 iters), loss = 1.79121
I1028 17:42:43.006548 29475 solver.cpp:241]     Train net output #0: loss = 1.79121 (* 1 = 1.79121 loss)
I1028 17:42:43.006566 29475 sgd_solver.cpp:105] Iteration 1640, lr = 0.00978733
I1028 17:43:14.108924 29475 solver.cpp:222] Iteration 1680 (1.28612 iter/s, 31.1012s/40 iters), loss = 1.72969
I1028 17:43:14.109124 29475 solver.cpp:241]     Train net output #0: loss = 1.72969 (* 1 = 1.72969 loss)
I1028 17:43:14.109140 29475 sgd_solver.cpp:105] Iteration 1680, lr = 0.00978215
I1028 17:43:45.112123 29475 solver.cpp:222] Iteration 1720 (1.29025 iter/s, 31.0018s/40 iters), loss = 1.57124
I1028 17:43:45.112326 29475 solver.cpp:241]     Train net output #0: loss = 1.57124 (* 1 = 1.57124 loss)
I1028 17:43:45.112344 29475 sgd_solver.cpp:105] Iteration 1720, lr = 0.00977698
I1028 17:44:15.918431 29475 solver.cpp:222] Iteration 1760 (1.2985 iter/s, 30.8049s/40 iters), loss = 1.74748
I1028 17:44:15.918647 29475 solver.cpp:241]     Train net output #0: loss = 1.74748 (* 1 = 1.74748 loss)
I1028 17:44:15.918665 29475 sgd_solver.cpp:105] Iteration 1760, lr = 0.00977181
I1028 17:44:47.022001 29475 solver.cpp:222] Iteration 1800 (1.28608 iter/s, 31.1022s/40 iters), loss = 2.08153
I1028 17:44:47.022210 29475 solver.cpp:241]     Train net output #0: loss = 2.08153 (* 1 = 2.08153 loss)
I1028 17:44:47.022228 29475 sgd_solver.cpp:105] Iteration 1800, lr = 0.00976663
I1028 17:45:18.185465 29475 solver.cpp:222] Iteration 1840 (1.28361 iter/s, 31.1621s/40 iters), loss = 1.78454
I1028 17:45:18.185703 29475 solver.cpp:241]     Train net output #0: loss = 1.78454 (* 1 = 1.78454 loss)
I1028 17:45:18.185731 29475 sgd_solver.cpp:105] Iteration 1840, lr = 0.00976146
I1028 17:45:48.984578 29475 solver.cpp:222] Iteration 1880 (1.2988 iter/s, 30.7977s/40 iters), loss = 1.76288
I1028 17:45:48.984836 29475 solver.cpp:241]     Train net output #0: loss = 1.76288 (* 1 = 1.76288 loss)
I1028 17:45:48.984853 29475 sgd_solver.cpp:105] Iteration 1880, lr = 0.00975629
I1028 17:46:19.666929 29475 solver.cpp:222] Iteration 1920 (1.30374 iter/s, 30.6809s/40 iters), loss = 2.02434
I1028 17:46:19.667110 29475 solver.cpp:241]     Train net output #0: loss = 2.02434 (* 1 = 2.02434 loss)
I1028 17:46:19.667126 29475 sgd_solver.cpp:105] Iteration 1920, lr = 0.00975112
I1028 17:46:50.426934 29475 solver.cpp:222] Iteration 1960 (1.30045 iter/s, 30.7587s/40 iters), loss = 1.68375
I1028 17:46:50.427094 29475 solver.cpp:241]     Train net output #0: loss = 1.68375 (* 1 = 1.68375 loss)
I1028 17:46:50.427110 29475 sgd_solver.cpp:105] Iteration 1960, lr = 0.00974595
I1028 17:47:20.778451 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_2000.caffemodel
I1028 17:47:20.814494 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_2000.solverstate
I1028 17:47:20.832603 29475 solver.cpp:334] Iteration 2000, Testing net (#0)
I1028 17:47:51.974073 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53532
I1028 17:47:51.974234 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77596
I1028 17:47:51.974249 29475 solver.cpp:401]     Test net output #2: loss = 2.06291 (* 1 = 2.06291 loss)
I1028 17:47:52.742805 29475 solver.cpp:222] Iteration 2000 (0.641917 iter/s, 62.3134s/40 iters), loss = 1.57635
I1028 17:47:52.742872 29475 solver.cpp:241]     Train net output #0: loss = 1.57635 (* 1 = 1.57635 loss)
I1028 17:47:52.742888 29475 sgd_solver.cpp:105] Iteration 2000, lr = 0.00974078
I1028 17:48:23.658303 29475 solver.cpp:222] Iteration 2040 (1.2939 iter/s, 30.9142s/40 iters), loss = 1.96682
I1028 17:48:23.658490 29475 solver.cpp:241]     Train net output #0: loss = 1.96682 (* 1 = 1.96682 loss)
I1028 17:48:23.658512 29475 sgd_solver.cpp:105] Iteration 2040, lr = 0.00973561
I1028 17:48:54.615772 29475 solver.cpp:222] Iteration 2080 (1.29215 iter/s, 30.9561s/40 iters), loss = 1.98187
I1028 17:48:54.615952 29475 solver.cpp:241]     Train net output #0: loss = 1.98187 (* 1 = 1.98187 loss)
I1028 17:48:54.615969 29475 sgd_solver.cpp:105] Iteration 2080, lr = 0.00973045
I1028 17:49:25.976500 29475 solver.cpp:222] Iteration 2120 (1.27554 iter/s, 31.3593s/40 iters), loss = 1.51536
I1028 17:49:25.976683 29475 solver.cpp:241]     Train net output #0: loss = 1.51536 (* 1 = 1.51536 loss)
I1028 17:49:25.976701 29475 sgd_solver.cpp:105] Iteration 2120, lr = 0.00972528
I1028 17:49:57.035992 29475 solver.cpp:222] Iteration 2160 (1.28791 iter/s, 31.0581s/40 iters), loss = 1.6683
I1028 17:49:57.036185 29475 solver.cpp:241]     Train net output #0: loss = 1.6683 (* 1 = 1.6683 loss)
I1028 17:49:57.036201 29475 sgd_solver.cpp:105] Iteration 2160, lr = 0.00972011
I1028 17:50:28.717968 29475 solver.cpp:222] Iteration 2200 (1.2626 iter/s, 31.6806s/40 iters), loss = 1.95708
I1028 17:50:28.718168 29475 solver.cpp:241]     Train net output #0: loss = 1.95708 (* 1 = 1.95708 loss)
I1028 17:50:28.718186 29475 sgd_solver.cpp:105] Iteration 2200, lr = 0.00971495
I1028 17:50:59.758370 29475 solver.cpp:222] Iteration 2240 (1.2887 iter/s, 31.039s/40 iters), loss = 1.83173
I1028 17:50:59.758570 29475 solver.cpp:241]     Train net output #0: loss = 1.83173 (* 1 = 1.83173 loss)
I1028 17:50:59.758589 29475 sgd_solver.cpp:105] Iteration 2240, lr = 0.00970978
I1028 17:51:31.556406 29475 solver.cpp:222] Iteration 2280 (1.258 iter/s, 31.7966s/40 iters), loss = 1.53988
I1028 17:51:31.556593 29475 solver.cpp:241]     Train net output #0: loss = 1.53988 (* 1 = 1.53988 loss)
I1028 17:51:31.556610 29475 sgd_solver.cpp:105] Iteration 2280, lr = 0.00970462
I1028 17:52:02.637871 29475 solver.cpp:222] Iteration 2320 (1.287 iter/s, 31.0801s/40 iters), loss = 1.79732
I1028 17:52:02.638099 29475 solver.cpp:241]     Train net output #0: loss = 1.79732 (* 1 = 1.79732 loss)
I1028 17:52:02.638128 29475 sgd_solver.cpp:105] Iteration 2320, lr = 0.00969946
I1028 17:52:33.449755 29475 solver.cpp:222] Iteration 2360 (1.29826 iter/s, 30.8105s/40 iters), loss = 1.64847
I1028 17:52:33.449959 29475 solver.cpp:241]     Train net output #0: loss = 1.64847 (* 1 = 1.64847 loss)
I1028 17:52:33.449976 29475 sgd_solver.cpp:105] Iteration 2360, lr = 0.00969429
I1028 17:53:04.063969 29475 solver.cpp:222] Iteration 2400 (1.30664 iter/s, 30.6128s/40 iters), loss = 1.6457
I1028 17:53:04.064143 29475 solver.cpp:241]     Train net output #0: loss = 1.6457 (* 1 = 1.6457 loss)
I1028 17:53:04.064162 29475 sgd_solver.cpp:105] Iteration 2400, lr = 0.00968913
I1028 17:53:34.972395 29475 solver.cpp:222] Iteration 2440 (1.2942 iter/s, 30.9071s/40 iters), loss = 2.15739
I1028 17:53:34.972599 29475 solver.cpp:241]     Train net output #0: loss = 2.15739 (* 1 = 2.15739 loss)
I1028 17:53:34.972615 29475 sgd_solver.cpp:105] Iteration 2440, lr = 0.00968397
I1028 17:54:05.827792 29475 solver.cpp:222] Iteration 2480 (1.29643 iter/s, 30.854s/40 iters), loss = 1.95688
I1028 17:54:05.827967 29475 solver.cpp:241]     Train net output #0: loss = 1.95688 (* 1 = 1.95688 loss)
I1028 17:54:05.827986 29475 sgd_solver.cpp:105] Iteration 2480, lr = 0.00967881
I1028 17:54:19.794258 29523 data_layer.cpp:73] Restarting data prefetching from start.
I1028 17:54:20.511354 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_2500.caffemodel
I1028 17:54:20.546923 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_2500.solverstate
I1028 17:54:20.564960 29475 solver.cpp:334] Iteration 2500, Testing net (#0)
I1028 17:54:51.428663 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 17:54:51.637842 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5308
I1028 17:54:51.637903 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.773559
I1028 17:54:51.637917 29475 solver.cpp:401]     Test net output #2: loss = 2.0898 (* 1 = 2.0898 loss)
I1028 17:55:07.801755 29475 solver.cpp:222] Iteration 2520 (0.645458 iter/s, 61.9715s/40 iters), loss = 1.98356
I1028 17:55:07.801827 29475 solver.cpp:241]     Train net output #0: loss = 1.98356 (* 1 = 1.98356 loss)
I1028 17:55:07.801843 29475 sgd_solver.cpp:105] Iteration 2520, lr = 0.00967365
I1028 17:55:38.603881 29475 solver.cpp:222] Iteration 2560 (1.29866 iter/s, 30.8009s/40 iters), loss = 1.57443
I1028 17:55:38.604065 29475 solver.cpp:241]     Train net output #0: loss = 1.57443 (* 1 = 1.57443 loss)
I1028 17:55:38.604081 29475 sgd_solver.cpp:105] Iteration 2560, lr = 0.00966849
I1028 17:56:09.259114 29475 solver.cpp:222] Iteration 2600 (1.30489 iter/s, 30.6539s/40 iters), loss = 1.92627
I1028 17:56:09.259280 29475 solver.cpp:241]     Train net output #0: loss = 1.92627 (* 1 = 1.92627 loss)
I1028 17:56:09.259305 29475 sgd_solver.cpp:105] Iteration 2600, lr = 0.00966333
I1028 17:56:39.916055 29475 solver.cpp:222] Iteration 2640 (1.30482 iter/s, 30.6556s/40 iters), loss = 2.01078
I1028 17:56:39.916240 29475 solver.cpp:241]     Train net output #0: loss = 2.01078 (* 1 = 2.01078 loss)
I1028 17:56:39.916257 29475 sgd_solver.cpp:105] Iteration 2640, lr = 0.00965817
I1028 17:57:10.621472 29475 solver.cpp:222] Iteration 2680 (1.30276 iter/s, 30.7041s/40 iters), loss = 1.55429
I1028 17:57:10.621628 29475 solver.cpp:241]     Train net output #0: loss = 1.55429 (* 1 = 1.55429 loss)
I1028 17:57:10.621644 29475 sgd_solver.cpp:105] Iteration 2680, lr = 0.00965301
I1028 17:57:41.340680 29475 solver.cpp:222] Iteration 2720 (1.30218 iter/s, 30.7178s/40 iters), loss = 1.59436
I1028 17:57:41.340862 29475 solver.cpp:241]     Train net output #0: loss = 1.59436 (* 1 = 1.59436 loss)
I1028 17:57:41.340881 29475 sgd_solver.cpp:105] Iteration 2720, lr = 0.00964785
I1028 17:58:12.487653 29475 solver.cpp:222] Iteration 2760 (1.28429 iter/s, 31.1456s/40 iters), loss = 1.90498
I1028 17:58:12.487902 29475 solver.cpp:241]     Train net output #0: loss = 1.90498 (* 1 = 1.90498 loss)
I1028 17:58:12.487928 29475 sgd_solver.cpp:105] Iteration 2760, lr = 0.0096427
I1028 17:58:43.293521 29475 solver.cpp:222] Iteration 2800 (1.29851 iter/s, 30.8045s/40 iters), loss = 1.62573
I1028 17:58:43.293689 29475 solver.cpp:241]     Train net output #0: loss = 1.62573 (* 1 = 1.62573 loss)
I1028 17:58:43.293706 29475 sgd_solver.cpp:105] Iteration 2800, lr = 0.00963754
I1028 17:59:14.241848 29475 solver.cpp:222] Iteration 2840 (1.29253 iter/s, 30.947s/40 iters), loss = 1.6541
I1028 17:59:14.242012 29475 solver.cpp:241]     Train net output #0: loss = 1.6541 (* 1 = 1.6541 loss)
I1028 17:59:14.242031 29475 sgd_solver.cpp:105] Iteration 2840, lr = 0.00963238
I1028 17:59:45.079650 29475 solver.cpp:222] Iteration 2880 (1.29717 iter/s, 30.8365s/40 iters), loss = 1.70078
I1028 17:59:45.079820 29475 solver.cpp:241]     Train net output #0: loss = 1.70078 (* 1 = 1.70078 loss)
I1028 17:59:45.079838 29475 sgd_solver.cpp:105] Iteration 2880, lr = 0.00962723
I1028 18:00:15.768100 29475 solver.cpp:222] Iteration 2920 (1.30348 iter/s, 30.6871s/40 iters), loss = 1.73447
I1028 18:00:15.768260 29475 solver.cpp:241]     Train net output #0: loss = 1.73447 (* 1 = 1.73447 loss)
I1028 18:00:15.768277 29475 sgd_solver.cpp:105] Iteration 2920, lr = 0.00962207
I1028 18:00:46.510272 29475 solver.cpp:222] Iteration 2960 (1.3012 iter/s, 30.7408s/40 iters), loss = 1.8941
I1028 18:00:46.510444 29475 solver.cpp:241]     Train net output #0: loss = 1.8941 (* 1 = 1.8941 loss)
I1028 18:00:46.510460 29475 sgd_solver.cpp:105] Iteration 2960, lr = 0.00961692
I1028 18:01:16.539221 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_3000.caffemodel
I1028 18:01:16.573676 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_3000.solverstate
I1028 18:01:16.590256 29475 solver.cpp:334] Iteration 3000, Testing net (#0)
I1028 18:01:47.694592 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53036
I1028 18:01:47.694778 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77392
I1028 18:01:47.694793 29475 solver.cpp:401]     Test net output #2: loss = 2.10649 (* 1 = 2.10649 loss)
I1028 18:01:48.464640 29475 solver.cpp:222] Iteration 3000 (0.645663 iter/s, 61.9519s/40 iters), loss = 2.15944
I1028 18:01:48.464712 29475 solver.cpp:241]     Train net output #0: loss = 2.15944 (* 1 = 2.15944 loss)
I1028 18:01:48.464728 29475 sgd_solver.cpp:105] Iteration 3000, lr = 0.00961177
I1028 18:02:19.134006 29475 solver.cpp:222] Iteration 3040 (1.30429 iter/s, 30.6681s/40 iters), loss = 1.7467
I1028 18:02:19.134210 29475 solver.cpp:241]     Train net output #0: loss = 1.7467 (* 1 = 1.7467 loss)
I1028 18:02:19.134228 29475 sgd_solver.cpp:105] Iteration 3040, lr = 0.00960661
I1028 18:02:50.129782 29475 solver.cpp:222] Iteration 3080 (1.29056 iter/s, 30.9944s/40 iters), loss = 1.69898
I1028 18:02:50.129968 29475 solver.cpp:241]     Train net output #0: loss = 1.69898 (* 1 = 1.69898 loss)
I1028 18:02:50.129987 29475 sgd_solver.cpp:105] Iteration 3080, lr = 0.00960146
I1028 18:03:21.570387 29475 solver.cpp:222] Iteration 3120 (1.2723 iter/s, 31.4392s/40 iters), loss = 1.76629
I1028 18:03:21.570559 29475 solver.cpp:241]     Train net output #0: loss = 1.76629 (* 1 = 1.76629 loss)
I1028 18:03:21.570576 29475 sgd_solver.cpp:105] Iteration 3120, lr = 0.00959631
I1028 18:03:52.244596 29475 solver.cpp:222] Iteration 3160 (1.30408 iter/s, 30.6729s/40 iters), loss = 1.87806
I1028 18:03:52.244787 29475 solver.cpp:241]     Train net output #0: loss = 1.87806 (* 1 = 1.87806 loss)
I1028 18:03:52.244803 29475 sgd_solver.cpp:105] Iteration 3160, lr = 0.00959116
I1028 18:04:23.273555 29475 solver.cpp:222] Iteration 3200 (1.28918 iter/s, 31.0276s/40 iters), loss = 1.77719
I1028 18:04:23.273756 29475 solver.cpp:241]     Train net output #0: loss = 1.77719 (* 1 = 1.77719 loss)
I1028 18:04:23.273773 29475 sgd_solver.cpp:105] Iteration 3200, lr = 0.00958601
I1028 18:04:54.589377 29475 solver.cpp:222] Iteration 3240 (1.27737 iter/s, 31.3144s/40 iters), loss = 2.08253
I1028 18:04:54.589617 29475 solver.cpp:241]     Train net output #0: loss = 2.08253 (* 1 = 2.08253 loss)
I1028 18:04:54.589634 29475 sgd_solver.cpp:105] Iteration 3240, lr = 0.00958086
I1028 18:05:25.654433 29475 solver.cpp:222] Iteration 3280 (1.28768 iter/s, 31.0636s/40 iters), loss = 2.01731
I1028 18:05:25.654630 29475 solver.cpp:241]     Train net output #0: loss = 2.01731 (* 1 = 2.01731 loss)
I1028 18:05:25.654649 29475 sgd_solver.cpp:105] Iteration 3280, lr = 0.00957571
I1028 18:05:56.901512 29475 solver.cpp:222] Iteration 3320 (1.28018 iter/s, 31.2457s/40 iters), loss = 1.91724
I1028 18:05:56.901793 29475 solver.cpp:241]     Train net output #0: loss = 1.91724 (* 1 = 1.91724 loss)
I1028 18:05:56.901821 29475 sgd_solver.cpp:105] Iteration 3320, lr = 0.00957057
I1028 18:06:28.255203 29475 solver.cpp:222] Iteration 3360 (1.27583 iter/s, 31.3522s/40 iters), loss = 1.82932
I1028 18:06:28.255393 29475 solver.cpp:241]     Train net output #0: loss = 1.82932 (* 1 = 1.82932 loss)
I1028 18:06:28.255409 29475 sgd_solver.cpp:105] Iteration 3360, lr = 0.00956542
I1028 18:06:59.764993 29475 solver.cpp:222] Iteration 3400 (1.26951 iter/s, 31.5083s/40 iters), loss = 1.74607
I1028 18:06:59.765198 29475 solver.cpp:241]     Train net output #0: loss = 1.74607 (* 1 = 1.74607 loss)
I1028 18:06:59.765226 29475 sgd_solver.cpp:105] Iteration 3400, lr = 0.00956027
I1028 18:07:31.226016 29475 solver.cpp:222] Iteration 3440 (1.27147 iter/s, 31.4596s/40 iters), loss = 1.72685
I1028 18:07:31.226212 29475 solver.cpp:241]     Train net output #0: loss = 1.72685 (* 1 = 1.72685 loss)
I1028 18:07:31.226230 29475 sgd_solver.cpp:105] Iteration 3440, lr = 0.00955513
I1028 18:08:02.473903 29475 solver.cpp:222] Iteration 3480 (1.28014 iter/s, 31.2465s/40 iters), loss = 1.65771
I1028 18:08:02.474103 29475 solver.cpp:241]     Train net output #0: loss = 1.65771 (* 1 = 1.65771 loss)
I1028 18:08:02.474120 29475 sgd_solver.cpp:105] Iteration 3480, lr = 0.00954998
I1028 18:08:17.354456 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_3500.caffemodel
I1028 18:08:17.396157 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_3500.solverstate
I1028 18:08:17.419289 29475 solver.cpp:334] Iteration 3500, Testing net (#0)
I1028 18:08:48.329111 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 18:08:48.536000 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53128
I1028 18:08:48.536064 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77456
I1028 18:08:48.536078 29475 solver.cpp:401]     Test net output #2: loss = 2.12951 (* 1 = 2.12951 loss)
I1028 18:09:04.911980 29475 solver.cpp:222] Iteration 3520 (0.640661 iter/s, 62.4355s/40 iters), loss = 1.74443
I1028 18:09:04.912048 29475 solver.cpp:241]     Train net output #0: loss = 1.74443 (* 1 = 1.74443 loss)
I1028 18:09:04.912063 29475 sgd_solver.cpp:105] Iteration 3520, lr = 0.00954484
I1028 18:09:35.886253 29475 solver.cpp:222] Iteration 3560 (1.29145 iter/s, 30.973s/40 iters), loss = 1.81546
I1028 18:09:35.886454 29475 solver.cpp:241]     Train net output #0: loss = 1.81546 (* 1 = 1.81546 loss)
I1028 18:09:35.886472 29475 sgd_solver.cpp:105] Iteration 3560, lr = 0.00953969
I1028 18:10:07.092622 29475 solver.cpp:222] Iteration 3600 (1.28185 iter/s, 31.205s/40 iters), loss = 2.12171
I1028 18:10:07.092809 29475 solver.cpp:241]     Train net output #0: loss = 2.12171 (* 1 = 2.12171 loss)
I1028 18:10:07.092828 29475 sgd_solver.cpp:105] Iteration 3600, lr = 0.00953455
I1028 18:10:38.183508 29475 solver.cpp:222] Iteration 3640 (1.28661 iter/s, 31.0895s/40 iters), loss = 1.91731
I1028 18:10:38.183693 29475 solver.cpp:241]     Train net output #0: loss = 1.91731 (* 1 = 1.91731 loss)
I1028 18:10:38.183712 29475 sgd_solver.cpp:105] Iteration 3640, lr = 0.00952941
I1028 18:11:09.436169 29475 solver.cpp:222] Iteration 3680 (1.27995 iter/s, 31.2512s/40 iters), loss = 1.40953
I1028 18:11:09.436430 29475 solver.cpp:241]     Train net output #0: loss = 1.40953 (* 1 = 1.40953 loss)
I1028 18:11:09.436461 29475 sgd_solver.cpp:105] Iteration 3680, lr = 0.00952426
I1028 18:11:40.438751 29475 solver.cpp:222] Iteration 3720 (1.29027 iter/s, 31.0011s/40 iters), loss = 1.79034
I1028 18:11:40.438948 29475 solver.cpp:241]     Train net output #0: loss = 1.79034 (* 1 = 1.79034 loss)
I1028 18:11:40.438964 29475 sgd_solver.cpp:105] Iteration 3720, lr = 0.00951912
I1028 18:12:12.076500 29475 solver.cpp:222] Iteration 3760 (1.26437 iter/s, 31.6364s/40 iters), loss = 1.52315
I1028 18:12:12.076726 29475 solver.cpp:241]     Train net output #0: loss = 1.52315 (* 1 = 1.52315 loss)
I1028 18:12:12.076743 29475 sgd_solver.cpp:105] Iteration 3760, lr = 0.00951398
I1028 18:12:43.031400 29475 solver.cpp:222] Iteration 3800 (1.29226 iter/s, 30.9535s/40 iters), loss = 1.53249
I1028 18:12:43.031649 29475 solver.cpp:241]     Train net output #0: loss = 1.53249 (* 1 = 1.53249 loss)
I1028 18:12:43.031677 29475 sgd_solver.cpp:105] Iteration 3800, lr = 0.00950884
I1028 18:13:14.666533 29475 solver.cpp:222] Iteration 3840 (1.26447 iter/s, 31.6337s/40 iters), loss = 1.56935
I1028 18:13:14.666719 29475 solver.cpp:241]     Train net output #0: loss = 1.56935 (* 1 = 1.56935 loss)
I1028 18:13:14.666736 29475 sgd_solver.cpp:105] Iteration 3840, lr = 0.0095037
I1028 18:13:46.524492 29475 solver.cpp:222] Iteration 3880 (1.25563 iter/s, 31.8566s/40 iters), loss = 1.99037
I1028 18:13:46.524672 29475 solver.cpp:241]     Train net output #0: loss = 1.99037 (* 1 = 1.99037 loss)
I1028 18:13:46.524688 29475 sgd_solver.cpp:105] Iteration 3880, lr = 0.00949856
I1028 18:14:19.276536 29475 solver.cpp:222] Iteration 3920 (1.22135 iter/s, 32.7506s/40 iters), loss = 1.72511
I1028 18:14:19.276698 29475 solver.cpp:241]     Train net output #0: loss = 1.72511 (* 1 = 1.72511 loss)
I1028 18:14:19.276716 29475 sgd_solver.cpp:105] Iteration 3920, lr = 0.00949342
I1028 18:14:31.924803 29526 blocking_queue.cpp:49] Waiting for data
I1028 18:14:51.461308 29475 solver.cpp:222] Iteration 3960 (1.24288 iter/s, 32.1834s/40 iters), loss = 1.75027
I1028 18:14:51.461547 29475 solver.cpp:241]     Train net output #0: loss = 1.75027 (* 1 = 1.75027 loss)
I1028 18:14:51.461575 29475 sgd_solver.cpp:105] Iteration 3960, lr = 0.00948829
I1028 18:15:28.695430 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_4000.caffemodel
I1028 18:15:28.728890 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_4000.solverstate
I1028 18:15:28.746407 29475 solver.cpp:334] Iteration 4000, Testing net (#0)
I1028 18:15:59.890811 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.52952
I1028 18:15:59.890988 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7706
I1028 18:15:59.891003 29475 solver.cpp:401]     Test net output #2: loss = 2.10893 (* 1 = 2.10893 loss)
I1028 18:16:00.656613 29475 solver.cpp:222] Iteration 4000 (0.578098 iter/s, 69.1924s/40 iters), loss = 1.57245
I1028 18:16:00.656682 29475 solver.cpp:241]     Train net output #0: loss = 1.57245 (* 1 = 1.57245 loss)
I1028 18:16:00.656698 29475 sgd_solver.cpp:105] Iteration 4000, lr = 0.00948315
I1028 18:16:33.678489 29475 solver.cpp:222] Iteration 4040 (1.21137 iter/s, 33.0205s/40 iters), loss = 1.73867
I1028 18:16:33.678728 29475 solver.cpp:241]     Train net output #0: loss = 1.73867 (* 1 = 1.73867 loss)
I1028 18:16:33.678757 29475 sgd_solver.cpp:105] Iteration 4040, lr = 0.00947801
I1028 18:17:10.143793 29475 solver.cpp:222] Iteration 4080 (1.09698 iter/s, 36.4637s/40 iters), loss = 1.85947
I1028 18:17:10.143999 29475 solver.cpp:241]     Train net output #0: loss = 1.85947 (* 1 = 1.85947 loss)
I1028 18:17:10.144017 29475 sgd_solver.cpp:105] Iteration 4080, lr = 0.00947288
I1028 18:17:41.040779 29475 solver.cpp:222] Iteration 4120 (1.29468 iter/s, 30.8956s/40 iters), loss = 1.72971
I1028 18:17:41.040976 29475 solver.cpp:241]     Train net output #0: loss = 1.72971 (* 1 = 1.72971 loss)
I1028 18:17:41.040992 29475 sgd_solver.cpp:105] Iteration 4120, lr = 0.00946774
I1028 18:18:12.066056 29475 solver.cpp:222] Iteration 4160 (1.28933 iter/s, 31.0239s/40 iters), loss = 1.8325
I1028 18:18:12.066313 29475 solver.cpp:241]     Train net output #0: loss = 1.8325 (* 1 = 1.8325 loss)
I1028 18:18:12.066331 29475 sgd_solver.cpp:105] Iteration 4160, lr = 0.00946261
I1028 18:18:43.764494 29475 solver.cpp:222] Iteration 4200 (1.26195 iter/s, 31.697s/40 iters), loss = 1.79541
I1028 18:18:43.764724 29475 solver.cpp:241]     Train net output #0: loss = 1.79541 (* 1 = 1.79541 loss)
I1028 18:18:43.764761 29475 sgd_solver.cpp:105] Iteration 4200, lr = 0.00945747
I1028 18:19:16.638139 29475 solver.cpp:222] Iteration 4240 (1.21683 iter/s, 32.8722s/40 iters), loss = 1.73297
I1028 18:19:16.638330 29475 solver.cpp:241]     Train net output #0: loss = 1.73297 (* 1 = 1.73297 loss)
I1028 18:19:16.638355 29475 sgd_solver.cpp:105] Iteration 4240, lr = 0.00945234
I1028 18:19:47.499138 29475 solver.cpp:222] Iteration 4280 (1.29619 iter/s, 30.8596s/40 iters), loss = 1.57633
I1028 18:19:47.499335 29475 solver.cpp:241]     Train net output #0: loss = 1.57633 (* 1 = 1.57633 loss)
I1028 18:19:47.499352 29475 sgd_solver.cpp:105] Iteration 4280, lr = 0.00944721
I1028 18:20:18.407409 29475 solver.cpp:222] Iteration 4320 (1.29421 iter/s, 30.9069s/40 iters), loss = 1.68479
I1028 18:20:18.407598 29475 solver.cpp:241]     Train net output #0: loss = 1.68479 (* 1 = 1.68479 loss)
I1028 18:20:18.407614 29475 sgd_solver.cpp:105] Iteration 4320, lr = 0.00944208
I1028 18:20:49.263355 29475 solver.cpp:222] Iteration 4360 (1.29641 iter/s, 30.8545s/40 iters), loss = 1.77133
I1028 18:20:49.263519 29475 solver.cpp:241]     Train net output #0: loss = 1.77133 (* 1 = 1.77133 loss)
I1028 18:20:49.263536 29475 sgd_solver.cpp:105] Iteration 4360, lr = 0.00943694
I1028 18:21:20.353649 29475 solver.cpp:222] Iteration 4400 (1.28663 iter/s, 31.089s/40 iters), loss = 1.88537
I1028 18:21:20.353843 29475 solver.cpp:241]     Train net output #0: loss = 1.88537 (* 1 = 1.88537 loss)
I1028 18:21:20.353860 29475 sgd_solver.cpp:105] Iteration 4400, lr = 0.00943181
I1028 18:21:52.404709 29475 solver.cpp:222] Iteration 4440 (1.24806 iter/s, 32.0497s/40 iters), loss = 1.58359
I1028 18:21:52.404924 29475 solver.cpp:241]     Train net output #0: loss = 1.58359 (* 1 = 1.58359 loss)
I1028 18:21:52.404947 29475 sgd_solver.cpp:105] Iteration 4440, lr = 0.00942669
I1028 18:22:23.332841 29475 solver.cpp:222] Iteration 4480 (1.29338 iter/s, 30.9267s/40 iters), loss = 1.30352
I1028 18:22:23.333050 29475 solver.cpp:241]     Train net output #0: loss = 1.30352 (* 1 = 1.30352 loss)
I1028 18:22:23.333066 29475 sgd_solver.cpp:105] Iteration 4480, lr = 0.00942156
I1028 18:22:38.114992 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_4500.caffemodel
I1028 18:22:38.150825 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_4500.solverstate
I1028 18:22:38.167582 29475 solver.cpp:334] Iteration 4500, Testing net (#0)
I1028 18:23:09.067533 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 18:23:09.274083 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54016
I1028 18:23:09.274147 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78068
I1028 18:23:09.274161 29475 solver.cpp:401]     Test net output #2: loss = 2.08378 (* 1 = 2.08378 loss)
I1028 18:23:26.282362 29475 solver.cpp:222] Iteration 4520 (0.635456 iter/s, 62.947s/40 iters), loss = 1.69117
I1028 18:23:26.282433 29475 solver.cpp:241]     Train net output #0: loss = 1.69117 (* 1 = 1.69117 loss)
I1028 18:23:26.282449 29475 sgd_solver.cpp:105] Iteration 4520, lr = 0.00941643
I1028 18:23:57.347515 29475 solver.cpp:222] Iteration 4560 (1.28767 iter/s, 31.0639s/40 iters), loss = 1.68247
I1028 18:23:57.347697 29475 solver.cpp:241]     Train net output #0: loss = 1.68247 (* 1 = 1.68247 loss)
I1028 18:23:57.347712 29475 sgd_solver.cpp:105] Iteration 4560, lr = 0.0094113
I1028 18:24:28.604755 29475 solver.cpp:222] Iteration 4600 (1.27976 iter/s, 31.2558s/40 iters), loss = 1.83237
I1028 18:24:28.605003 29475 solver.cpp:241]     Train net output #0: loss = 1.83237 (* 1 = 1.83237 loss)
I1028 18:24:28.605022 29475 sgd_solver.cpp:105] Iteration 4600, lr = 0.00940617
I1028 18:24:59.558351 29475 solver.cpp:222] Iteration 4640 (1.29232 iter/s, 30.9522s/40 iters), loss = 2.15029
I1028 18:24:59.558552 29475 solver.cpp:241]     Train net output #0: loss = 2.15029 (* 1 = 2.15029 loss)
I1028 18:24:59.558569 29475 sgd_solver.cpp:105] Iteration 4640, lr = 0.00940104
I1028 18:25:31.003217 29475 solver.cpp:222] Iteration 4680 (1.27212 iter/s, 31.4435s/40 iters), loss = 1.80682
I1028 18:25:31.003449 29475 solver.cpp:241]     Train net output #0: loss = 1.80682 (* 1 = 1.80682 loss)
I1028 18:25:31.003466 29475 sgd_solver.cpp:105] Iteration 4680, lr = 0.00939592
I1028 18:26:02.051252 29475 solver.cpp:222] Iteration 4720 (1.28838 iter/s, 31.0466s/40 iters), loss = 1.80778
I1028 18:26:02.051424 29475 solver.cpp:241]     Train net output #0: loss = 1.80778 (* 1 = 1.80778 loss)
I1028 18:26:02.051441 29475 sgd_solver.cpp:105] Iteration 4720, lr = 0.00939079
I1028 18:26:32.998602 29475 solver.cpp:222] Iteration 4760 (1.29257 iter/s, 30.946s/40 iters), loss = 1.43723
I1028 18:26:32.998793 29475 solver.cpp:241]     Train net output #0: loss = 1.43723 (* 1 = 1.43723 loss)
I1028 18:26:32.998811 29475 sgd_solver.cpp:105] Iteration 4760, lr = 0.00938567
I1028 18:27:03.728073 29475 solver.cpp:222] Iteration 4800 (1.30174 iter/s, 30.7281s/40 iters), loss = 1.86303
I1028 18:27:03.728257 29475 solver.cpp:241]     Train net output #0: loss = 1.86303 (* 1 = 1.86303 loss)
I1028 18:27:03.728273 29475 sgd_solver.cpp:105] Iteration 4800, lr = 0.00938054
I1028 18:27:34.670421 29475 solver.cpp:222] Iteration 4840 (1.29278 iter/s, 30.941s/40 iters), loss = 1.79384
I1028 18:27:34.670599 29475 solver.cpp:241]     Train net output #0: loss = 1.79384 (* 1 = 1.79384 loss)
I1028 18:27:34.670615 29475 sgd_solver.cpp:105] Iteration 4840, lr = 0.00937542
I1028 18:28:05.430783 29475 solver.cpp:222] Iteration 4880 (1.30044 iter/s, 30.7589s/40 iters), loss = 2.00441
I1028 18:28:05.430974 29475 solver.cpp:241]     Train net output #0: loss = 2.00441 (* 1 = 2.00441 loss)
I1028 18:28:05.430991 29475 sgd_solver.cpp:105] Iteration 4880, lr = 0.0093703
I1028 18:28:36.367280 29475 solver.cpp:222] Iteration 4920 (1.29303 iter/s, 30.9351s/40 iters), loss = 1.55114
I1028 18:28:36.367482 29475 solver.cpp:241]     Train net output #0: loss = 1.55114 (* 1 = 1.55114 loss)
I1028 18:28:36.367498 29475 sgd_solver.cpp:105] Iteration 4920, lr = 0.00936518
I1028 18:29:07.434388 29475 solver.cpp:222] Iteration 4960 (1.28759 iter/s, 31.0657s/40 iters), loss = 1.59442
I1028 18:29:07.434588 29475 solver.cpp:241]     Train net output #0: loss = 1.59442 (* 1 = 1.59442 loss)
I1028 18:29:07.434604 29475 sgd_solver.cpp:105] Iteration 4960, lr = 0.00936005
I1028 18:29:37.663230 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_5000.caffemodel
I1028 18:29:37.703361 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_5000.solverstate
I1028 18:29:37.726071 29475 solver.cpp:334] Iteration 5000, Testing net (#0)
I1028 18:30:08.821049 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5402
I1028 18:30:08.821238 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.779
I1028 18:30:08.821254 29475 solver.cpp:401]     Test net output #2: loss = 2.04771 (* 1 = 2.04771 loss)
I1028 18:30:09.588167 29475 solver.cpp:222] Iteration 5000 (0.643591 iter/s, 62.1512s/40 iters), loss = 2.19192
I1028 18:30:09.588244 29475 solver.cpp:241]     Train net output #0: loss = 2.19192 (* 1 = 2.19192 loss)
I1028 18:30:09.588260 29475 sgd_solver.cpp:105] Iteration 5000, lr = 0.00935493
I1028 18:30:09.674635 29523 data_layer.cpp:73] Restarting data prefetching from start.
I1028 18:30:40.707625 29475 solver.cpp:222] Iteration 5040 (1.28543 iter/s, 31.1181s/40 iters), loss = 1.79272
I1028 18:30:40.707904 29475 solver.cpp:241]     Train net output #0: loss = 1.79272 (* 1 = 1.79272 loss)
I1028 18:30:40.707934 29475 sgd_solver.cpp:105] Iteration 5040, lr = 0.00934981
I1028 18:31:11.871835 29475 solver.cpp:222] Iteration 5080 (1.28358 iter/s, 31.1627s/40 iters), loss = 1.84616
I1028 18:31:11.872043 29475 solver.cpp:241]     Train net output #0: loss = 1.84616 (* 1 = 1.84616 loss)
I1028 18:31:11.872064 29475 sgd_solver.cpp:105] Iteration 5080, lr = 0.00934469
I1028 18:31:43.385869 29475 solver.cpp:222] Iteration 5120 (1.26933 iter/s, 31.5126s/40 iters), loss = 1.89432
I1028 18:31:43.386088 29475 solver.cpp:241]     Train net output #0: loss = 1.89432 (* 1 = 1.89432 loss)
I1028 18:31:43.386106 29475 sgd_solver.cpp:105] Iteration 5120, lr = 0.00933957
I1028 18:32:14.761652 29475 solver.cpp:222] Iteration 5160 (1.27493 iter/s, 31.3743s/40 iters), loss = 2.01078
I1028 18:32:14.761924 29475 solver.cpp:241]     Train net output #0: loss = 2.01078 (* 1 = 2.01078 loss)
I1028 18:32:14.761946 29475 sgd_solver.cpp:105] Iteration 5160, lr = 0.00933446
I1028 18:32:47.106678 29475 solver.cpp:222] Iteration 5200 (1.23672 iter/s, 32.3435s/40 iters), loss = 1.87379
I1028 18:32:47.106900 29475 solver.cpp:241]     Train net output #0: loss = 1.87379 (* 1 = 1.87379 loss)
I1028 18:32:47.106920 29475 sgd_solver.cpp:105] Iteration 5200, lr = 0.00932934
I1028 18:33:18.570274 29475 solver.cpp:222] Iteration 5240 (1.27137 iter/s, 31.4622s/40 iters), loss = 1.68572
I1028 18:33:18.570499 29475 solver.cpp:241]     Train net output #0: loss = 1.68572 (* 1 = 1.68572 loss)
I1028 18:33:18.570520 29475 sgd_solver.cpp:105] Iteration 5240, lr = 0.00932422
I1028 18:33:49.696357 29475 solver.cpp:222] Iteration 5280 (1.28515 iter/s, 31.1247s/40 iters), loss = 2.13873
I1028 18:33:49.696579 29475 solver.cpp:241]     Train net output #0: loss = 2.13873 (* 1 = 2.13873 loss)
I1028 18:33:49.696597 29475 sgd_solver.cpp:105] Iteration 5280, lr = 0.0093191
I1028 18:34:20.799316 29475 solver.cpp:222] Iteration 5320 (1.28611 iter/s, 31.1015s/40 iters), loss = 1.72659
I1028 18:34:20.799509 29475 solver.cpp:241]     Train net output #0: loss = 1.72659 (* 1 = 1.72659 loss)
I1028 18:34:20.799525 29475 sgd_solver.cpp:105] Iteration 5320, lr = 0.00931399
I1028 18:34:52.187175 29475 solver.cpp:222] Iteration 5360 (1.27443 iter/s, 31.3865s/40 iters), loss = 1.92071
I1028 18:34:52.187435 29475 solver.cpp:241]     Train net output #0: loss = 1.92071 (* 1 = 1.92071 loss)
I1028 18:34:52.187454 29475 sgd_solver.cpp:105] Iteration 5360, lr = 0.00930887
I1028 18:35:23.496590 29475 solver.cpp:222] Iteration 5400 (1.27763 iter/s, 31.3079s/40 iters), loss = 1.88785
I1028 18:35:23.496829 29475 solver.cpp:241]     Train net output #0: loss = 1.88785 (* 1 = 1.88785 loss)
I1028 18:35:23.496850 29475 sgd_solver.cpp:105] Iteration 5400, lr = 0.00930376
I1028 18:35:54.523500 29475 solver.cpp:222] Iteration 5440 (1.28926 iter/s, 31.0255s/40 iters), loss = 1.83685
I1028 18:35:54.523736 29475 solver.cpp:241]     Train net output #0: loss = 1.83685 (* 1 = 1.83685 loss)
I1028 18:35:54.523753 29475 sgd_solver.cpp:105] Iteration 5440, lr = 0.00929864
I1028 18:36:25.616999 29475 solver.cpp:222] Iteration 5480 (1.2865 iter/s, 31.092s/40 iters), loss = 1.62215
I1028 18:36:25.617166 29475 solver.cpp:241]     Train net output #0: loss = 1.62215 (* 1 = 1.62215 loss)
I1028 18:36:25.617183 29475 sgd_solver.cpp:105] Iteration 5480, lr = 0.00929353
I1028 18:36:40.524085 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_5500.caffemodel
I1028 18:36:40.558168 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_5500.solverstate
I1028 18:36:40.577702 29475 solver.cpp:334] Iteration 5500, Testing net (#0)
I1028 18:37:11.473731 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 18:37:11.680914 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53236
I1028 18:37:11.680979 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77744
I1028 18:37:11.680992 29475 solver.cpp:401]     Test net output #2: loss = 2.10977 (* 1 = 2.10977 loss)
I1028 18:37:28.485811 29475 solver.cpp:222] Iteration 5520 (0.636271 iter/s, 62.8663s/40 iters), loss = 1.51299
I1028 18:37:28.485884 29475 solver.cpp:241]     Train net output #0: loss = 1.51299 (* 1 = 1.51299 loss)
I1028 18:37:28.485900 29475 sgd_solver.cpp:105] Iteration 5520, lr = 0.00928842
I1028 18:37:59.641250 29475 solver.cpp:222] Iteration 5560 (1.28394 iter/s, 31.1542s/40 iters), loss = 1.77498
I1028 18:37:59.641505 29475 solver.cpp:241]     Train net output #0: loss = 1.77498 (* 1 = 1.77498 loss)
I1028 18:37:59.641523 29475 sgd_solver.cpp:105] Iteration 5560, lr = 0.00928331
I1028 18:38:30.883926 29475 solver.cpp:222] Iteration 5600 (1.28036 iter/s, 31.2412s/40 iters), loss = 1.69588
I1028 18:38:30.884148 29475 solver.cpp:241]     Train net output #0: loss = 1.69588 (* 1 = 1.69588 loss)
I1028 18:38:30.884165 29475 sgd_solver.cpp:105] Iteration 5600, lr = 0.0092782
I1028 18:39:01.696673 29475 solver.cpp:222] Iteration 5640 (1.29823 iter/s, 30.8113s/40 iters), loss = 1.89051
I1028 18:39:01.696847 29475 solver.cpp:241]     Train net output #0: loss = 1.89051 (* 1 = 1.89051 loss)
I1028 18:39:01.696866 29475 sgd_solver.cpp:105] Iteration 5640, lr = 0.00927309
I1028 18:39:32.632501 29475 solver.cpp:222] Iteration 5680 (1.29306 iter/s, 30.9345s/40 iters), loss = 1.8113
I1028 18:39:32.632683 29475 solver.cpp:241]     Train net output #0: loss = 1.8113 (* 1 = 1.8113 loss)
I1028 18:39:32.632700 29475 sgd_solver.cpp:105] Iteration 5680, lr = 0.00926798
I1028 18:40:03.551357 29475 solver.cpp:222] Iteration 5720 (1.29377 iter/s, 30.9175s/40 iters), loss = 1.61905
I1028 18:40:03.551542 29475 solver.cpp:241]     Train net output #0: loss = 1.61905 (* 1 = 1.61905 loss)
I1028 18:40:03.551559 29475 sgd_solver.cpp:105] Iteration 5720, lr = 0.00926287
I1028 18:40:34.767971 29475 solver.cpp:222] Iteration 5760 (1.28143 iter/s, 31.2152s/40 iters), loss = 1.5524
I1028 18:40:34.768149 29475 solver.cpp:241]     Train net output #0: loss = 1.5524 (* 1 = 1.5524 loss)
I1028 18:40:34.768173 29475 sgd_solver.cpp:105] Iteration 5760, lr = 0.00925776
I1028 18:41:05.766059 29475 solver.cpp:222] Iteration 5800 (1.29046 iter/s, 30.9967s/40 iters), loss = 1.88861
I1028 18:41:05.766252 29475 solver.cpp:241]     Train net output #0: loss = 1.88861 (* 1 = 1.88861 loss)
I1028 18:41:05.766268 29475 sgd_solver.cpp:105] Iteration 5800, lr = 0.00925265
I1028 18:41:36.719589 29475 solver.cpp:222] Iteration 5840 (1.29232 iter/s, 30.9522s/40 iters), loss = 1.87035
I1028 18:41:36.719791 29475 solver.cpp:241]     Train net output #0: loss = 1.87035 (* 1 = 1.87035 loss)
I1028 18:41:36.719807 29475 sgd_solver.cpp:105] Iteration 5840, lr = 0.00924754
I1028 18:42:07.913790 29475 solver.cpp:222] Iteration 5880 (1.28235 iter/s, 31.1927s/40 iters), loss = 1.97114
I1028 18:42:07.913974 29475 solver.cpp:241]     Train net output #0: loss = 1.97114 (* 1 = 1.97114 loss)
I1028 18:42:07.913991 29475 sgd_solver.cpp:105] Iteration 5880, lr = 0.00924244
I1028 18:42:39.075225 29475 solver.cpp:222] Iteration 5920 (1.28369 iter/s, 31.1601s/40 iters), loss = 1.73947
I1028 18:42:39.075392 29475 solver.cpp:241]     Train net output #0: loss = 1.73947 (* 1 = 1.73947 loss)
I1028 18:42:39.075410 29475 sgd_solver.cpp:105] Iteration 5920, lr = 0.00923733
I1028 18:43:10.090721 29475 solver.cpp:222] Iteration 5960 (1.28974 iter/s, 31.0141s/40 iters), loss = 1.85691
I1028 18:43:10.090893 29475 solver.cpp:241]     Train net output #0: loss = 1.85691 (* 1 = 1.85691 loss)
I1028 18:43:10.090910 29475 sgd_solver.cpp:105] Iteration 5960, lr = 0.00923223
I1028 18:43:40.477337 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_6000.caffemodel
I1028 18:43:40.511657 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_6000.solverstate
I1028 18:43:40.528985 29475 solver.cpp:334] Iteration 6000, Testing net (#0)
I1028 18:44:11.687590 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.52952
I1028 18:44:11.687880 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77192
I1028 18:44:11.687943 29475 solver.cpp:401]     Test net output #2: loss = 2.07244 (* 1 = 2.07244 loss)
I1028 18:44:12.464891 29475 solver.cpp:222] Iteration 6000 (0.641317 iter/s, 62.3717s/40 iters), loss = 1.94017
I1028 18:44:12.464967 29475 solver.cpp:241]     Train net output #0: loss = 1.94017 (* 1 = 1.94017 loss)
I1028 18:44:12.464984 29475 sgd_solver.cpp:105] Iteration 6000, lr = 0.00922712
I1028 18:44:43.664613 29475 solver.cpp:222] Iteration 6040 (1.28211 iter/s, 31.1985s/40 iters), loss = 1.67405
I1028 18:44:43.664816 29475 solver.cpp:241]     Train net output #0: loss = 1.67405 (* 1 = 1.67405 loss)
I1028 18:44:43.664832 29475 sgd_solver.cpp:105] Iteration 6040, lr = 0.00922202
I1028 18:45:14.709687 29475 solver.cpp:222] Iteration 6080 (1.28851 iter/s, 31.0437s/40 iters), loss = 1.16999
I1028 18:45:14.709885 29475 solver.cpp:241]     Train net output #0: loss = 1.16999 (* 1 = 1.16999 loss)
I1028 18:45:14.709903 29475 sgd_solver.cpp:105] Iteration 6080, lr = 0.00921691
I1028 18:45:45.766290 29475 solver.cpp:222] Iteration 6120 (1.28803 iter/s, 31.0552s/40 iters), loss = 1.77998
I1028 18:45:45.766456 29475 solver.cpp:241]     Train net output #0: loss = 1.77998 (* 1 = 1.77998 loss)
I1028 18:45:45.766472 29475 sgd_solver.cpp:105] Iteration 6120, lr = 0.00921181
I1028 18:46:16.996461 29475 solver.cpp:222] Iteration 6160 (1.28087 iter/s, 31.2288s/40 iters), loss = 1.67434
I1028 18:46:16.996665 29475 solver.cpp:241]     Train net output #0: loss = 1.67434 (* 1 = 1.67434 loss)
I1028 18:46:16.996682 29475 sgd_solver.cpp:105] Iteration 6160, lr = 0.00920671
I1028 18:46:47.959571 29475 solver.cpp:222] Iteration 6200 (1.29192 iter/s, 30.9617s/40 iters), loss = 1.79362
I1028 18:46:47.959749 29475 solver.cpp:241]     Train net output #0: loss = 1.79362 (* 1 = 1.79362 loss)
I1028 18:46:47.959765 29475 sgd_solver.cpp:105] Iteration 6200, lr = 0.00920161
I1028 18:47:19.131121 29475 solver.cpp:222] Iteration 6240 (1.28328 iter/s, 31.1702s/40 iters), loss = 1.53592
I1028 18:47:19.131319 29475 solver.cpp:241]     Train net output #0: loss = 1.53592 (* 1 = 1.53592 loss)
I1028 18:47:19.131336 29475 sgd_solver.cpp:105] Iteration 6240, lr = 0.00919651
I1028 18:47:50.417098 29475 solver.cpp:222] Iteration 6280 (1.27858 iter/s, 31.2846s/40 iters), loss = 1.88074
I1028 18:47:50.417282 29475 solver.cpp:241]     Train net output #0: loss = 1.88074 (* 1 = 1.88074 loss)
I1028 18:47:50.417304 29475 sgd_solver.cpp:105] Iteration 6280, lr = 0.00919141
I1028 18:48:21.642710 29475 solver.cpp:222] Iteration 6320 (1.28106 iter/s, 31.2242s/40 iters), loss = 1.52374
I1028 18:48:21.642891 29475 solver.cpp:241]     Train net output #0: loss = 1.52374 (* 1 = 1.52374 loss)
I1028 18:48:21.642909 29475 sgd_solver.cpp:105] Iteration 6320, lr = 0.00918631
I1028 18:48:53.252645 29475 solver.cpp:222] Iteration 6360 (1.26548 iter/s, 31.6085s/40 iters), loss = 1.51216
I1028 18:48:53.252873 29475 solver.cpp:241]     Train net output #0: loss = 1.51216 (* 1 = 1.51216 loss)
I1028 18:48:53.252892 29475 sgd_solver.cpp:105] Iteration 6360, lr = 0.00918121
I1028 18:49:25.243702 29475 solver.cpp:222] Iteration 6400 (1.25041 iter/s, 31.9896s/40 iters), loss = 1.76816
I1028 18:49:25.243908 29475 solver.cpp:241]     Train net output #0: loss = 1.76816 (* 1 = 1.76816 loss)
I1028 18:49:25.243927 29475 sgd_solver.cpp:105] Iteration 6400, lr = 0.00917611
I1028 18:49:56.402127 29475 solver.cpp:222] Iteration 6440 (1.28382 iter/s, 31.1569s/40 iters), loss = 1.86842
I1028 18:49:56.402355 29475 solver.cpp:241]     Train net output #0: loss = 1.86842 (* 1 = 1.86842 loss)
I1028 18:49:56.402381 29475 sgd_solver.cpp:105] Iteration 6440, lr = 0.00917101
I1028 18:50:33.342200 29475 solver.cpp:222] Iteration 6480 (1.08288 iter/s, 36.9384s/40 iters), loss = 1.74287
I1028 18:50:33.342483 29475 solver.cpp:241]     Train net output #0: loss = 1.74287 (* 1 = 1.74287 loss)
I1028 18:50:33.342501 29475 sgd_solver.cpp:105] Iteration 6480, lr = 0.00916591
I1028 18:50:47.892233 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_6500.caffemodel
I1028 18:50:47.928514 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_6500.solverstate
I1028 18:50:47.947007 29475 solver.cpp:334] Iteration 6500, Testing net (#0)
I1028 18:51:18.847329 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 18:51:19.058248 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53212
I1028 18:51:19.058312 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7774
I1028 18:51:19.058327 29475 solver.cpp:401]     Test net output #2: loss = 2.0697 (* 1 = 2.0697 loss)
I1028 18:51:35.263820 29475 solver.cpp:222] Iteration 6520 (0.646005 iter/s, 61.919s/40 iters), loss = 1.81824
I1028 18:51:35.263895 29475 solver.cpp:241]     Train net output #0: loss = 1.81824 (* 1 = 1.81824 loss)
I1028 18:51:35.263913 29475 sgd_solver.cpp:105] Iteration 6520, lr = 0.00916082
I1028 18:52:06.370599 29475 solver.cpp:222] Iteration 6560 (1.28595 iter/s, 31.1055s/40 iters), loss = 1.91492
I1028 18:52:06.370787 29475 solver.cpp:241]     Train net output #0: loss = 1.91492 (* 1 = 1.91492 loss)
I1028 18:52:06.370803 29475 sgd_solver.cpp:105] Iteration 6560, lr = 0.00915572
I1028 18:52:37.247823 29475 solver.cpp:222] Iteration 6600 (1.29551 iter/s, 30.8759s/40 iters), loss = 1.87017
I1028 18:52:37.248020 29475 solver.cpp:241]     Train net output #0: loss = 1.87017 (* 1 = 1.87017 loss)
I1028 18:52:37.248044 29475 sgd_solver.cpp:105] Iteration 6600, lr = 0.00915063
I1028 18:53:08.662525 29475 solver.cpp:222] Iteration 6640 (1.27335 iter/s, 31.4132s/40 iters), loss = 1.78719
I1028 18:53:08.662719 29475 solver.cpp:241]     Train net output #0: loss = 1.78719 (* 1 = 1.78719 loss)
I1028 18:53:08.662737 29475 sgd_solver.cpp:105] Iteration 6640, lr = 0.00914553
I1028 18:53:39.629086 29475 solver.cpp:222] Iteration 6680 (1.29177 iter/s, 30.9652s/40 iters), loss = 1.74654
I1028 18:53:39.629312 29475 solver.cpp:241]     Train net output #0: loss = 1.74654 (* 1 = 1.74654 loss)
I1028 18:53:39.629338 29475 sgd_solver.cpp:105] Iteration 6680, lr = 0.00914044
I1028 18:54:10.617558 29475 solver.cpp:222] Iteration 6720 (1.29086 iter/s, 30.9871s/40 iters), loss = 1.65031
I1028 18:54:10.617754 29475 solver.cpp:241]     Train net output #0: loss = 1.65031 (* 1 = 1.65031 loss)
I1028 18:54:10.617771 29475 sgd_solver.cpp:105] Iteration 6720, lr = 0.00913535
I1028 18:54:41.989179 29475 solver.cpp:222] Iteration 6760 (1.27509 iter/s, 31.3702s/40 iters), loss = 1.7893
I1028 18:54:41.989400 29475 solver.cpp:241]     Train net output #0: loss = 1.7893 (* 1 = 1.7893 loss)
I1028 18:54:41.989416 29475 sgd_solver.cpp:105] Iteration 6760, lr = 0.00913026
I1028 18:55:12.940117 29475 solver.cpp:222] Iteration 6800 (1.29243 iter/s, 30.9495s/40 iters), loss = 1.75196
I1028 18:55:12.940327 29475 solver.cpp:241]     Train net output #0: loss = 1.75196 (* 1 = 1.75196 loss)
I1028 18:55:12.940346 29475 sgd_solver.cpp:105] Iteration 6800, lr = 0.00912516
I1028 18:55:43.955266 29475 solver.cpp:222] Iteration 6840 (1.28975 iter/s, 31.0138s/40 iters), loss = 1.83669
I1028 18:55:43.955461 29475 solver.cpp:241]     Train net output #0: loss = 1.83669 (* 1 = 1.83669 loss)
I1028 18:55:43.955478 29475 sgd_solver.cpp:105] Iteration 6840, lr = 0.00912007
I1028 18:56:15.419075 29475 solver.cpp:222] Iteration 6880 (1.27136 iter/s, 31.4624s/40 iters), loss = 1.85248
I1028 18:56:15.419275 29475 solver.cpp:241]     Train net output #0: loss = 1.85248 (* 1 = 1.85248 loss)
I1028 18:56:15.419292 29475 sgd_solver.cpp:105] Iteration 6880, lr = 0.00911498
I1028 18:56:46.915269 29475 solver.cpp:222] Iteration 6920 (1.27005 iter/s, 31.4948s/40 iters), loss = 1.60622
I1028 18:56:46.915479 29475 solver.cpp:241]     Train net output #0: loss = 1.60622 (* 1 = 1.60622 loss)
I1028 18:56:46.915499 29475 sgd_solver.cpp:105] Iteration 6920, lr = 0.00910989
I1028 18:57:18.223124 29475 solver.cpp:222] Iteration 6960 (1.27769 iter/s, 31.3064s/40 iters), loss = 1.58074
I1028 18:57:18.223613 29475 solver.cpp:241]     Train net output #0: loss = 1.58074 (* 1 = 1.58074 loss)
I1028 18:57:18.223641 29475 sgd_solver.cpp:105] Iteration 6960, lr = 0.0091048
I1028 18:57:48.140564 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_7000.caffemodel
I1028 18:57:48.174810 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_7000.solverstate
I1028 18:57:48.193253 29475 solver.cpp:334] Iteration 7000, Testing net (#0)
I1028 18:58:19.304827 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54056
I1028 18:58:19.305004 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77992
I1028 18:58:19.305021 29475 solver.cpp:401]     Test net output #2: loss = 2.04889 (* 1 = 2.04889 loss)
I1028 18:58:20.075387 29475 solver.cpp:222] Iteration 7000 (0.646732 iter/s, 61.8495s/40 iters), loss = 1.62926
I1028 18:58:20.075453 29475 solver.cpp:241]     Train net output #0: loss = 1.62926 (* 1 = 1.62926 loss)
I1028 18:58:20.075469 29475 sgd_solver.cpp:105] Iteration 7000, lr = 0.00909972
I1028 18:58:51.104426 29475 solver.cpp:222] Iteration 7040 (1.28917 iter/s, 31.0277s/40 iters), loss = 1.97171
I1028 18:58:51.104604 29475 solver.cpp:241]     Train net output #0: loss = 1.97171 (* 1 = 1.97171 loss)
I1028 18:58:51.104620 29475 sgd_solver.cpp:105] Iteration 7040, lr = 0.00909463
I1028 18:59:21.699487 29475 solver.cpp:222] Iteration 7080 (1.30746 iter/s, 30.5936s/40 iters), loss = 1.5339
I1028 18:59:21.699663 29475 solver.cpp:241]     Train net output #0: loss = 1.5339 (* 1 = 1.5339 loss)
I1028 18:59:21.699681 29475 sgd_solver.cpp:105] Iteration 7080, lr = 0.00908954
I1028 18:59:52.574007 29475 solver.cpp:222] Iteration 7120 (1.29562 iter/s, 30.8732s/40 iters), loss = 1.88864
I1028 18:59:52.574183 29475 solver.cpp:241]     Train net output #0: loss = 1.88864 (* 1 = 1.88864 loss)
I1028 18:59:52.574199 29475 sgd_solver.cpp:105] Iteration 7120, lr = 0.00908445
I1028 19:00:23.658962 29475 solver.cpp:222] Iteration 7160 (1.28686 iter/s, 31.0835s/40 iters), loss = 1.8937
I1028 19:00:23.659155 29475 solver.cpp:241]     Train net output #0: loss = 1.8937 (* 1 = 1.8937 loss)
I1028 19:00:23.659173 29475 sgd_solver.cpp:105] Iteration 7160, lr = 0.00907937
I1028 19:00:55.040118 29475 solver.cpp:222] Iteration 7200 (1.27471 iter/s, 31.3798s/40 iters), loss = 2.03494
I1028 19:00:55.040390 29475 solver.cpp:241]     Train net output #0: loss = 2.03494 (* 1 = 2.03494 loss)
I1028 19:00:55.040413 29475 sgd_solver.cpp:105] Iteration 7200, lr = 0.00907428
I1028 19:01:26.097805 29475 solver.cpp:222] Iteration 7240 (1.28799 iter/s, 31.0562s/40 iters), loss = 1.67826
I1028 19:01:26.098017 29475 solver.cpp:241]     Train net output #0: loss = 1.67826 (* 1 = 1.67826 loss)
I1028 19:01:26.098033 29475 sgd_solver.cpp:105] Iteration 7240, lr = 0.0090692
I1028 19:01:56.723345 29475 solver.cpp:222] Iteration 7280 (1.30616 iter/s, 30.6242s/40 iters), loss = 1.97037
I1028 19:01:56.723544 29475 solver.cpp:241]     Train net output #0: loss = 1.97037 (* 1 = 1.97037 loss)
I1028 19:01:56.723563 29475 sgd_solver.cpp:105] Iteration 7280, lr = 0.00906412
I1028 19:02:28.274551 29475 solver.cpp:222] Iteration 7320 (1.26784 iter/s, 31.5498s/40 iters), loss = 1.58294
I1028 19:02:28.274755 29475 solver.cpp:241]     Train net output #0: loss = 1.58294 (* 1 = 1.58294 loss)
I1028 19:02:28.274772 29475 sgd_solver.cpp:105] Iteration 7320, lr = 0.00905903
I1028 19:03:13.006645 29475 solver.cpp:222] Iteration 7360 (0.89425 iter/s, 44.7302s/40 iters), loss = 1.77489
I1028 19:03:13.006840 29475 solver.cpp:241]     Train net output #0: loss = 1.77489 (* 1 = 1.77489 loss)
I1028 19:03:13.006858 29475 sgd_solver.cpp:105] Iteration 7360, lr = 0.00905395
I1028 19:03:44.376374 29475 solver.cpp:222] Iteration 7400 (1.27517 iter/s, 31.3683s/40 iters), loss = 2.07995
I1028 19:03:44.376577 29475 solver.cpp:241]     Train net output #0: loss = 2.07995 (* 1 = 2.07995 loss)
I1028 19:03:44.376600 29475 sgd_solver.cpp:105] Iteration 7400, lr = 0.00904887
I1028 19:04:15.737154 29475 solver.cpp:222] Iteration 7440 (1.27553 iter/s, 31.3594s/40 iters), loss = 1.92756
I1028 19:04:15.737401 29475 solver.cpp:241]     Train net output #0: loss = 1.92756 (* 1 = 1.92756 loss)
I1028 19:04:15.737419 29475 sgd_solver.cpp:105] Iteration 7440, lr = 0.00904379
I1028 19:04:46.861467 29475 solver.cpp:222] Iteration 7480 (1.28523 iter/s, 31.1229s/40 iters), loss = 1.83264
I1028 19:04:46.861662 29475 solver.cpp:241]     Train net output #0: loss = 1.83264 (* 1 = 1.83264 loss)
I1028 19:04:46.861680 29475 sgd_solver.cpp:105] Iteration 7480, lr = 0.00903871
I1028 19:05:01.896739 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_7500.caffemodel
I1028 19:05:01.931331 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_7500.solverstate
I1028 19:05:01.949380 29475 solver.cpp:334] Iteration 7500, Testing net (#0)
I1028 19:05:32.757555 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 19:05:32.964150 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53144
I1028 19:05:32.964212 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77424
I1028 19:05:32.964226 29475 solver.cpp:401]     Test net output #2: loss = 2.07962 (* 1 = 2.07962 loss)
I1028 19:05:35.425438 29523 data_layer.cpp:73] Restarting data prefetching from start.
I1028 19:05:49.196058 29475 solver.cpp:222] Iteration 7520 (0.641724 iter/s, 62.3321s/40 iters), loss = 1.79841
I1028 19:05:49.196132 29475 solver.cpp:241]     Train net output #0: loss = 1.79841 (* 1 = 1.79841 loss)
I1028 19:05:49.196148 29475 sgd_solver.cpp:105] Iteration 7520, lr = 0.00903363
I1028 19:06:19.768435 29475 solver.cpp:222] Iteration 7560 (1.30842 iter/s, 30.5711s/40 iters), loss = 1.79081
I1028 19:06:19.768620 29475 solver.cpp:241]     Train net output #0: loss = 1.79081 (* 1 = 1.79081 loss)
I1028 19:06:19.768638 29475 sgd_solver.cpp:105] Iteration 7560, lr = 0.00902855
I1028 19:06:50.172960 29475 solver.cpp:222] Iteration 7600 (1.31565 iter/s, 30.4031s/40 iters), loss = 1.82387
I1028 19:06:50.173111 29475 solver.cpp:241]     Train net output #0: loss = 1.82387 (* 1 = 1.82387 loss)
I1028 19:06:50.173130 29475 sgd_solver.cpp:105] Iteration 7600, lr = 0.00902347
I1028 19:07:20.760933 29475 solver.cpp:222] Iteration 7640 (1.30776 iter/s, 30.5866s/40 iters), loss = 1.65407
I1028 19:07:20.761108 29475 solver.cpp:241]     Train net output #0: loss = 1.65407 (* 1 = 1.65407 loss)
I1028 19:07:20.761126 29475 sgd_solver.cpp:105] Iteration 7640, lr = 0.00901839
I1028 19:07:51.557889 29475 solver.cpp:222] Iteration 7680 (1.29889 iter/s, 30.7956s/40 iters), loss = 1.75187
I1028 19:07:51.558063 29475 solver.cpp:241]     Train net output #0: loss = 1.75187 (* 1 = 1.75187 loss)
I1028 19:07:51.558080 29475 sgd_solver.cpp:105] Iteration 7680, lr = 0.00901331
I1028 19:08:22.000028 29475 solver.cpp:222] Iteration 7720 (1.31403 iter/s, 30.4407s/40 iters), loss = 1.84332
I1028 19:08:22.000195 29475 solver.cpp:241]     Train net output #0: loss = 1.84332 (* 1 = 1.84332 loss)
I1028 19:08:22.000211 29475 sgd_solver.cpp:105] Iteration 7720, lr = 0.00900824
I1028 19:08:52.568667 29475 solver.cpp:222] Iteration 7760 (1.30859 iter/s, 30.5672s/40 iters), loss = 1.44011
I1028 19:08:52.568848 29475 solver.cpp:241]     Train net output #0: loss = 1.44011 (* 1 = 1.44011 loss)
I1028 19:08:52.568866 29475 sgd_solver.cpp:105] Iteration 7760, lr = 0.00900316
I1028 19:09:24.017442 29475 solver.cpp:222] Iteration 7800 (1.27197 iter/s, 31.4473s/40 iters), loss = 2.04338
I1028 19:09:24.017647 29475 solver.cpp:241]     Train net output #0: loss = 2.04338 (* 1 = 2.04338 loss)
I1028 19:09:24.017675 29475 sgd_solver.cpp:105] Iteration 7800, lr = 0.00899809
I1028 19:09:55.747246 29475 solver.cpp:222] Iteration 7840 (1.2607 iter/s, 31.7284s/40 iters), loss = 1.57865
I1028 19:09:55.747445 29475 solver.cpp:241]     Train net output #0: loss = 1.57865 (* 1 = 1.57865 loss)
I1028 19:09:55.747463 29475 sgd_solver.cpp:105] Iteration 7840, lr = 0.00899301
I1028 19:10:26.602437 29475 solver.cpp:222] Iteration 7880 (1.29644 iter/s, 30.8538s/40 iters), loss = 1.93638
I1028 19:10:26.602686 29475 solver.cpp:241]     Train net output #0: loss = 1.93638 (* 1 = 1.93638 loss)
I1028 19:10:26.602704 29475 sgd_solver.cpp:105] Iteration 7880, lr = 0.00898794
I1028 19:10:57.515794 29475 solver.cpp:222] Iteration 7920 (1.294 iter/s, 30.9119s/40 iters), loss = 1.77952
I1028 19:10:57.516037 29475 solver.cpp:241]     Train net output #0: loss = 1.77952 (* 1 = 1.77952 loss)
I1028 19:10:57.516062 29475 sgd_solver.cpp:105] Iteration 7920, lr = 0.00898287
I1028 19:11:29.646395 29475 solver.cpp:222] Iteration 7960 (1.24498 iter/s, 32.1291s/40 iters), loss = 1.77971
I1028 19:11:29.646639 29475 solver.cpp:241]     Train net output #0: loss = 1.77971 (* 1 = 1.77971 loss)
I1028 19:11:29.646662 29475 sgd_solver.cpp:105] Iteration 7960, lr = 0.00897779
I1028 19:12:04.099474 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_8000.caffemodel
I1028 19:12:04.134833 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_8000.solverstate
I1028 19:12:04.156980 29475 solver.cpp:334] Iteration 8000, Testing net (#0)
I1028 19:12:35.212819 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53684
I1028 19:12:35.212994 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77656
I1028 19:12:35.213011 29475 solver.cpp:401]     Test net output #2: loss = 2.0849 (* 1 = 2.0849 loss)
I1028 19:12:35.984174 29475 solver.cpp:222] Iteration 8000 (0.602999 iter/s, 66.3351s/40 iters), loss = 2.25166
I1028 19:12:35.984239 29475 solver.cpp:241]     Train net output #0: loss = 2.25166 (* 1 = 2.25166 loss)
I1028 19:12:35.984256 29475 sgd_solver.cpp:105] Iteration 8000, lr = 0.00897272
I1028 19:13:06.999410 29475 solver.cpp:222] Iteration 8040 (1.28974 iter/s, 31.014s/40 iters), loss = 1.79153
I1028 19:13:06.999598 29475 solver.cpp:241]     Train net output #0: loss = 1.79153 (* 1 = 1.79153 loss)
I1028 19:13:06.999619 29475 sgd_solver.cpp:105] Iteration 8040, lr = 0.00896765
I1028 19:13:37.923245 29475 solver.cpp:222] Iteration 8080 (1.29356 iter/s, 30.9225s/40 iters), loss = 1.82001
I1028 19:13:37.923426 29475 solver.cpp:241]     Train net output #0: loss = 1.82001 (* 1 = 1.82001 loss)
I1028 19:13:37.923442 29475 sgd_solver.cpp:105] Iteration 8080, lr = 0.00896258
I1028 19:14:09.150496 29475 solver.cpp:222] Iteration 8120 (1.28099 iter/s, 31.2259s/40 iters), loss = 1.59037
I1028 19:14:09.150693 29475 solver.cpp:241]     Train net output #0: loss = 1.59037 (* 1 = 1.59037 loss)
I1028 19:14:09.150712 29475 sgd_solver.cpp:105] Iteration 8120, lr = 0.00895751
I1028 19:14:40.455317 29475 solver.cpp:222] Iteration 8160 (1.27782 iter/s, 31.3033s/40 iters), loss = 1.84264
I1028 19:14:40.455482 29475 solver.cpp:241]     Train net output #0: loss = 1.84264 (* 1 = 1.84264 loss)
I1028 19:14:40.455499 29475 sgd_solver.cpp:105] Iteration 8160, lr = 0.00895244
I1028 19:15:11.542806 29475 solver.cpp:222] Iteration 8200 (1.28675 iter/s, 31.0861s/40 iters), loss = 1.8165
I1028 19:15:11.542995 29475 solver.cpp:241]     Train net output #0: loss = 1.8165 (* 1 = 1.8165 loss)
I1028 19:15:11.543011 29475 sgd_solver.cpp:105] Iteration 8200, lr = 0.00894737
I1028 19:15:44.270969 29475 solver.cpp:222] Iteration 8240 (1.22225 iter/s, 32.7266s/40 iters), loss = 1.61443
I1028 19:15:44.271220 29475 solver.cpp:241]     Train net output #0: loss = 1.61443 (* 1 = 1.61443 loss)
I1028 19:15:44.271353 29475 sgd_solver.cpp:105] Iteration 8240, lr = 0.0089423
I1028 19:16:16.243046 29475 solver.cpp:222] Iteration 8280 (1.25115 iter/s, 31.9706s/40 iters), loss = 1.66714
I1028 19:16:16.243223 29475 solver.cpp:241]     Train net output #0: loss = 1.66714 (* 1 = 1.66714 loss)
I1028 19:16:16.243239 29475 sgd_solver.cpp:105] Iteration 8280, lr = 0.00893724
I1028 19:16:46.933382 29475 solver.cpp:222] Iteration 8320 (1.3034 iter/s, 30.689s/40 iters), loss = 1.6914
I1028 19:16:46.933555 29475 solver.cpp:241]     Train net output #0: loss = 1.6914 (* 1 = 1.6914 loss)
I1028 19:16:46.933571 29475 sgd_solver.cpp:105] Iteration 8320, lr = 0.00893217
I1028 19:17:17.494637 29475 solver.cpp:222] Iteration 8360 (1.3089 iter/s, 30.5599s/40 iters), loss = 1.79131
I1028 19:17:17.494854 29475 solver.cpp:241]     Train net output #0: loss = 1.79131 (* 1 = 1.79131 loss)
I1028 19:17:17.494873 29475 sgd_solver.cpp:105] Iteration 8360, lr = 0.0089271
I1028 19:17:48.260145 29475 solver.cpp:222] Iteration 8400 (1.30022 iter/s, 30.7641s/40 iters), loss = 1.83952
I1028 19:17:48.260319 29475 solver.cpp:241]     Train net output #0: loss = 1.83952 (* 1 = 1.83952 loss)
I1028 19:17:48.260337 29475 sgd_solver.cpp:105] Iteration 8400, lr = 0.00892204
I1028 19:18:18.940811 29475 solver.cpp:222] Iteration 8440 (1.30381 iter/s, 30.6793s/40 iters), loss = 1.92667
I1028 19:18:18.940985 29475 solver.cpp:241]     Train net output #0: loss = 1.92667 (* 1 = 1.92667 loss)
I1028 19:18:18.941001 29475 sgd_solver.cpp:105] Iteration 8440, lr = 0.00891697
I1028 19:18:49.666447 29475 solver.cpp:222] Iteration 8480 (1.3019 iter/s, 30.7242s/40 iters), loss = 1.68069
I1028 19:18:49.666628 29475 solver.cpp:241]     Train net output #0: loss = 1.68069 (* 1 = 1.68069 loss)
I1028 19:18:49.666647 29475 sgd_solver.cpp:105] Iteration 8480, lr = 0.00891191
I1028 19:19:04.271903 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_8500.caffemodel
I1028 19:19:04.309314 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_8500.solverstate
I1028 19:19:04.330612 29475 solver.cpp:334] Iteration 8500, Testing net (#0)
I1028 19:19:35.190981 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 19:19:35.397848 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53288
I1028 19:19:35.397910 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7794
I1028 19:19:35.397924 29475 solver.cpp:401]     Test net output #2: loss = 2.06201 (* 1 = 2.06201 loss)
I1028 19:19:51.471336 29475 solver.cpp:222] Iteration 8520 (0.647224 iter/s, 61.8024s/40 iters), loss = 1.44121
I1028 19:19:51.471410 29475 solver.cpp:241]     Train net output #0: loss = 1.44121 (* 1 = 1.44121 loss)
I1028 19:19:51.471427 29475 sgd_solver.cpp:105] Iteration 8520, lr = 0.00890685
I1028 19:20:22.434414 29475 solver.cpp:222] Iteration 8560 (1.29191 iter/s, 30.9618s/40 iters), loss = 1.43104
I1028 19:20:22.434600 29475 solver.cpp:241]     Train net output #0: loss = 1.43104 (* 1 = 1.43104 loss)
I1028 19:20:22.434617 29475 sgd_solver.cpp:105] Iteration 8560, lr = 0.00890178
I1028 19:20:53.005877 29475 solver.cpp:222] Iteration 8600 (1.30847 iter/s, 30.5701s/40 iters), loss = 1.62595
I1028 19:20:53.006049 29475 solver.cpp:241]     Train net output #0: loss = 1.62595 (* 1 = 1.62595 loss)
I1028 19:20:53.006067 29475 sgd_solver.cpp:105] Iteration 8600, lr = 0.00889672
I1028 19:21:23.743216 29475 solver.cpp:222] Iteration 8640 (1.30141 iter/s, 30.736s/40 iters), loss = 1.77927
I1028 19:21:23.743486 29475 solver.cpp:241]     Train net output #0: loss = 1.77927 (* 1 = 1.77927 loss)
I1028 19:21:23.743515 29475 sgd_solver.cpp:105] Iteration 8640, lr = 0.00889166
I1028 19:21:54.704129 29475 solver.cpp:222] Iteration 8680 (1.29201 iter/s, 30.9595s/40 iters), loss = 1.69294
I1028 19:21:54.704332 29475 solver.cpp:241]     Train net output #0: loss = 1.69294 (* 1 = 1.69294 loss)
I1028 19:21:54.704351 29475 sgd_solver.cpp:105] Iteration 8680, lr = 0.0088866
I1028 19:22:25.546187 29475 solver.cpp:222] Iteration 8720 (1.29699 iter/s, 30.8407s/40 iters), loss = 1.72303
I1028 19:22:25.546370 29475 solver.cpp:241]     Train net output #0: loss = 1.72303 (* 1 = 1.72303 loss)
I1028 19:22:25.546386 29475 sgd_solver.cpp:105] Iteration 8720, lr = 0.00888154
I1028 19:22:56.434988 29475 solver.cpp:222] Iteration 8760 (1.29502 iter/s, 30.8874s/40 iters), loss = 1.56502
I1028 19:22:56.435160 29475 solver.cpp:241]     Train net output #0: loss = 1.56502 (* 1 = 1.56502 loss)
I1028 19:22:56.435176 29475 sgd_solver.cpp:105] Iteration 8760, lr = 0.00887648
I1028 19:23:28.087438 29475 solver.cpp:222] Iteration 8800 (1.26378 iter/s, 31.651s/40 iters), loss = 1.54241
I1028 19:23:28.087699 29475 solver.cpp:241]     Train net output #0: loss = 1.54241 (* 1 = 1.54241 loss)
I1028 19:23:28.087718 29475 sgd_solver.cpp:105] Iteration 8800, lr = 0.00887142
I1028 19:23:58.925482 29475 solver.cpp:222] Iteration 8840 (1.29716 iter/s, 30.8366s/40 iters), loss = 2.17766
I1028 19:23:58.925665 29475 solver.cpp:241]     Train net output #0: loss = 2.17766 (* 1 = 2.17766 loss)
I1028 19:23:58.925683 29475 sgd_solver.cpp:105] Iteration 8840, lr = 0.00886637
I1028 19:24:30.193308 29475 solver.cpp:222] Iteration 8880 (1.27933 iter/s, 31.2663s/40 iters), loss = 1.59683
I1028 19:24:30.193565 29475 solver.cpp:241]     Train net output #0: loss = 1.59683 (* 1 = 1.59683 loss)
I1028 19:24:30.193595 29475 sgd_solver.cpp:105] Iteration 8880, lr = 0.00886131
I1028 19:25:02.610314 29475 solver.cpp:222] Iteration 8920 (1.23398 iter/s, 32.4154s/40 iters), loss = 1.47767
I1028 19:25:02.610496 29475 solver.cpp:241]     Train net output #0: loss = 1.47767 (* 1 = 1.47767 loss)
I1028 19:25:02.610515 29475 sgd_solver.cpp:105] Iteration 8920, lr = 0.00885625
I1028 19:25:34.387001 29475 solver.cpp:222] Iteration 8960 (1.25884 iter/s, 31.7753s/40 iters), loss = 1.7809
I1028 19:25:34.387194 29475 solver.cpp:241]     Train net output #0: loss = 1.7809 (* 1 = 1.7809 loss)
I1028 19:25:34.387212 29475 sgd_solver.cpp:105] Iteration 8960, lr = 0.0088512
I1028 19:26:04.423823 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_9000.caffemodel
I1028 19:26:04.459219 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_9000.solverstate
I1028 19:26:04.477365 29475 solver.cpp:334] Iteration 9000, Testing net (#0)
I1028 19:26:35.493293 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53308
I1028 19:26:35.493485 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77536
I1028 19:26:35.493500 29475 solver.cpp:401]     Test net output #2: loss = 2.08836 (* 1 = 2.08836 loss)
I1028 19:26:36.264571 29475 solver.cpp:222] Iteration 9000 (0.646464 iter/s, 61.875s/40 iters), loss = 1.506
I1028 19:26:36.264652 29475 solver.cpp:241]     Train net output #0: loss = 1.506 (* 1 = 1.506 loss)
I1028 19:26:36.264670 29475 sgd_solver.cpp:105] Iteration 9000, lr = 0.00884614
I1028 19:27:07.470579 29475 solver.cpp:222] Iteration 9040 (1.28186 iter/s, 31.2047s/40 iters), loss = 2.10663
I1028 19:27:07.470794 29475 solver.cpp:241]     Train net output #0: loss = 2.10663 (* 1 = 2.10663 loss)
I1028 19:27:07.470813 29475 sgd_solver.cpp:105] Iteration 9040, lr = 0.00884109
I1028 19:27:39.060835 29475 solver.cpp:222] Iteration 9080 (1.26627 iter/s, 31.5888s/40 iters), loss = 1.7601
I1028 19:27:39.061038 29475 solver.cpp:241]     Train net output #0: loss = 1.7601 (* 1 = 1.7601 loss)
I1028 19:27:39.061058 29475 sgd_solver.cpp:105] Iteration 9080, lr = 0.00883603
I1028 19:28:11.519312 29475 solver.cpp:222] Iteration 9120 (1.2324 iter/s, 32.457s/40 iters), loss = 1.5811
I1028 19:28:11.519551 29475 solver.cpp:241]     Train net output #0: loss = 1.5811 (* 1 = 1.5811 loss)
I1028 19:28:11.519575 29475 sgd_solver.cpp:105] Iteration 9120, lr = 0.00883098
I1028 19:28:42.687088 29475 solver.cpp:222] Iteration 9160 (1.28343 iter/s, 31.1664s/40 iters), loss = 2.0503
I1028 19:28:42.687270 29475 solver.cpp:241]     Train net output #0: loss = 2.0503 (* 1 = 2.0503 loss)
I1028 19:28:42.687290 29475 sgd_solver.cpp:105] Iteration 9160, lr = 0.00882593
I1028 19:29:13.539060 29475 solver.cpp:222] Iteration 9200 (1.29657 iter/s, 30.8506s/40 iters), loss = 1.87061
I1028 19:29:13.539273 29475 solver.cpp:241]     Train net output #0: loss = 1.87061 (* 1 = 1.87061 loss)
I1028 19:29:13.539295 29475 sgd_solver.cpp:105] Iteration 9200, lr = 0.00882087
I1028 19:29:44.964696 29475 solver.cpp:222] Iteration 9240 (1.27291 iter/s, 31.4242s/40 iters), loss = 1.92595
I1028 19:29:44.964893 29475 solver.cpp:241]     Train net output #0: loss = 1.92595 (* 1 = 1.92595 loss)
I1028 19:29:44.964911 29475 sgd_solver.cpp:105] Iteration 9240, lr = 0.00881582
I1028 19:30:16.236209 29475 solver.cpp:222] Iteration 9280 (1.27918 iter/s, 31.2701s/40 iters), loss = 1.80136
I1028 19:30:16.236477 29475 solver.cpp:241]     Train net output #0: loss = 1.80136 (* 1 = 1.80136 loss)
I1028 19:30:16.236495 29475 sgd_solver.cpp:105] Iteration 9280, lr = 0.00881077
I1028 19:30:48.514598 29475 solver.cpp:222] Iteration 9320 (1.23928 iter/s, 32.2769s/40 iters), loss = 1.77164
I1028 19:30:48.514786 29475 solver.cpp:241]     Train net output #0: loss = 1.77164 (* 1 = 1.77164 loss)
I1028 19:30:48.514803 29475 sgd_solver.cpp:105] Iteration 9320, lr = 0.00880572
I1028 19:31:19.418280 29475 solver.cpp:222] Iteration 9360 (1.2944 iter/s, 30.9023s/40 iters), loss = 1.93902
I1028 19:31:19.418479 29475 solver.cpp:241]     Train net output #0: loss = 1.93902 (* 1 = 1.93902 loss)
I1028 19:31:19.418498 29475 sgd_solver.cpp:105] Iteration 9360, lr = 0.00880067
I1028 19:31:50.779769 29475 solver.cpp:222] Iteration 9400 (1.27551 iter/s, 31.3601s/40 iters), loss = 1.88454
I1028 19:31:50.779953 29475 solver.cpp:241]     Train net output #0: loss = 1.88454 (* 1 = 1.88454 loss)
I1028 19:31:50.779969 29475 sgd_solver.cpp:105] Iteration 9400, lr = 0.00879562
I1028 19:32:25.455921 29475 solver.cpp:222] Iteration 9440 (1.15358 iter/s, 34.6746s/40 iters), loss = 1.6747
I1028 19:32:25.456111 29475 solver.cpp:241]     Train net output #0: loss = 1.6747 (* 1 = 1.6747 loss)
I1028 19:32:25.456130 29475 sgd_solver.cpp:105] Iteration 9440, lr = 0.00879058
I1028 19:32:56.527396 29475 solver.cpp:222] Iteration 9480 (1.28741 iter/s, 31.0701s/40 iters), loss = 1.59313
I1028 19:32:56.527614 29475 solver.cpp:241]     Train net output #0: loss = 1.59313 (* 1 = 1.59313 loss)
I1028 19:32:56.527632 29475 sgd_solver.cpp:105] Iteration 9480, lr = 0.00878553
I1028 19:33:11.320482 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_9500.caffemodel
I1028 19:33:11.354449 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_9500.solverstate
I1028 19:33:11.371016 29475 solver.cpp:334] Iteration 9500, Testing net (#0)
I1028 19:33:42.333616 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 19:33:42.541261 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54004
I1028 19:33:42.541344 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78216
I1028 19:33:42.541365 29475 solver.cpp:401]     Test net output #2: loss = 2.0376 (* 1 = 2.0376 loss)
I1028 19:33:58.807008 29475 solver.cpp:222] Iteration 9520 (0.642291 iter/s, 62.2771s/40 iters), loss = 1.85579
I1028 19:33:58.807075 29475 solver.cpp:241]     Train net output #0: loss = 1.85579 (* 1 = 1.85579 loss)
I1028 19:33:58.807092 29475 sgd_solver.cpp:105] Iteration 9520, lr = 0.00878048
I1028 19:34:30.013034 29475 solver.cpp:222] Iteration 9560 (1.28186 iter/s, 31.2048s/40 iters), loss = 2.06466
I1028 19:34:30.013222 29475 solver.cpp:241]     Train net output #0: loss = 2.06466 (* 1 = 2.06466 loss)
I1028 19:34:30.013240 29475 sgd_solver.cpp:105] Iteration 9560, lr = 0.00877544
I1028 19:35:00.972254 29475 solver.cpp:222] Iteration 9600 (1.29208 iter/s, 30.9578s/40 iters), loss = 1.68315
I1028 19:35:00.972427 29475 solver.cpp:241]     Train net output #0: loss = 1.68315 (* 1 = 1.68315 loss)
I1028 19:35:00.972445 29475 sgd_solver.cpp:105] Iteration 9600, lr = 0.00877039
I1028 19:35:31.853197 29475 solver.cpp:222] Iteration 9640 (1.29535 iter/s, 30.8796s/40 iters), loss = 1.84095
I1028 19:35:31.853397 29475 solver.cpp:241]     Train net output #0: loss = 1.84095 (* 1 = 1.84095 loss)
I1028 19:35:31.853420 29475 sgd_solver.cpp:105] Iteration 9640, lr = 0.00876535
I1028 19:36:02.816879 29475 solver.cpp:222] Iteration 9680 (1.29189 iter/s, 30.9623s/40 iters), loss = 1.5335
I1028 19:36:02.817065 29475 solver.cpp:241]     Train net output #0: loss = 1.5335 (* 1 = 1.5335 loss)
I1028 19:36:02.817083 29475 sgd_solver.cpp:105] Iteration 9680, lr = 0.0087603
I1028 19:36:33.744465 29475 solver.cpp:222] Iteration 9720 (1.2934 iter/s, 30.9262s/40 iters), loss = 1.90136
I1028 19:36:33.744735 29475 solver.cpp:241]     Train net output #0: loss = 1.90136 (* 1 = 1.90136 loss)
I1028 19:36:33.744757 29475 sgd_solver.cpp:105] Iteration 9720, lr = 0.00875526
I1028 19:37:04.517832 29475 solver.cpp:222] Iteration 9760 (1.29989 iter/s, 30.7719s/40 iters), loss = 2.01148
I1028 19:37:04.518039 29475 solver.cpp:241]     Train net output #0: loss = 2.01148 (* 1 = 2.01148 loss)
I1028 19:37:04.518057 29475 sgd_solver.cpp:105] Iteration 9760, lr = 0.00875022
I1028 19:37:35.238488 29475 solver.cpp:222] Iteration 9800 (1.30211 iter/s, 30.7193s/40 iters), loss = 1.91887
I1028 19:37:35.238682 29475 solver.cpp:241]     Train net output #0: loss = 1.91887 (* 1 = 1.91887 loss)
I1028 19:37:35.238703 29475 sgd_solver.cpp:105] Iteration 9800, lr = 0.00874517
I1028 19:38:06.103044 29475 solver.cpp:222] Iteration 9840 (1.29604 iter/s, 30.8632s/40 iters), loss = 1.78323
I1028 19:38:06.103245 29475 solver.cpp:241]     Train net output #0: loss = 1.78323 (* 1 = 1.78323 loss)
I1028 19:38:06.103261 29475 sgd_solver.cpp:105] Iteration 9840, lr = 0.00874013
I1028 19:38:36.726004 29475 solver.cpp:222] Iteration 9880 (1.30627 iter/s, 30.6216s/40 iters), loss = 1.77129
I1028 19:38:36.726160 29475 solver.cpp:241]     Train net output #0: loss = 1.77129 (* 1 = 1.77129 loss)
I1028 19:38:36.726176 29475 sgd_solver.cpp:105] Iteration 9880, lr = 0.00873509
I1028 19:39:07.603929 29475 solver.cpp:222] Iteration 9920 (1.29548 iter/s, 30.8765s/40 iters), loss = 1.2963
I1028 19:39:07.604105 29475 solver.cpp:241]     Train net output #0: loss = 1.2963 (* 1 = 1.2963 loss)
I1028 19:39:07.604125 29475 sgd_solver.cpp:105] Iteration 9920, lr = 0.00873005
I1028 19:39:38.549005 29475 solver.cpp:222] Iteration 9960 (1.29267 iter/s, 30.9437s/40 iters), loss = 1.61617
I1028 19:39:38.549192 29475 solver.cpp:241]     Train net output #0: loss = 1.61617 (* 1 = 1.61617 loss)
I1028 19:39:38.549209 29475 sgd_solver.cpp:105] Iteration 9960, lr = 0.00872501
I1028 19:40:08.883502 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_10000.caffemodel
I1028 19:40:08.923265 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_10000.solverstate
I1028 19:40:08.945323 29475 solver.cpp:334] Iteration 10000, Testing net (#0)
I1028 19:40:40.096040 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54016
I1028 19:40:40.096199 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.777799
I1028 19:40:40.096215 29475 solver.cpp:401]     Test net output #2: loss = 2.04848 (* 1 = 2.04848 loss)
I1028 19:40:40.875411 29475 solver.cpp:222] Iteration 10000 (0.641808 iter/s, 62.3239s/40 iters), loss = 1.72577
I1028 19:40:40.875485 29475 solver.cpp:241]     Train net output #0: loss = 1.72577 (* 1 = 1.72577 loss)
I1028 19:40:40.875502 29475 sgd_solver.cpp:105] Iteration 10000, lr = 0.00871998
I1028 19:40:44.744024 29523 data_layer.cpp:73] Restarting data prefetching from start.
I1028 19:41:12.187484 29475 solver.cpp:222] Iteration 10040 (1.27752 iter/s, 31.3107s/40 iters), loss = 1.63818
I1028 19:41:12.187681 29475 solver.cpp:241]     Train net output #0: loss = 1.63818 (* 1 = 1.63818 loss)
I1028 19:41:12.187700 29475 sgd_solver.cpp:105] Iteration 10040, lr = 0.00871494
I1028 19:41:43.260993 29475 solver.cpp:222] Iteration 10080 (1.28733 iter/s, 31.0721s/40 iters), loss = 1.91286
I1028 19:41:43.261220 29475 solver.cpp:241]     Train net output #0: loss = 1.91286 (* 1 = 1.91286 loss)
I1028 19:41:43.261237 29475 sgd_solver.cpp:105] Iteration 10080, lr = 0.0087099
I1028 19:42:14.577574 29475 solver.cpp:222] Iteration 10120 (1.27734 iter/s, 31.3152s/40 iters), loss = 1.7392
I1028 19:42:14.577759 29475 solver.cpp:241]     Train net output #0: loss = 1.7392 (* 1 = 1.7392 loss)
I1028 19:42:14.577775 29475 sgd_solver.cpp:105] Iteration 10120, lr = 0.00870486
I1028 19:42:46.832264 29475 solver.cpp:222] Iteration 10160 (1.24018 iter/s, 32.2533s/40 iters), loss = 1.7808
I1028 19:42:46.832556 29475 solver.cpp:241]     Train net output #0: loss = 1.7808 (* 1 = 1.7808 loss)
I1028 19:42:46.832592 29475 sgd_solver.cpp:105] Iteration 10160, lr = 0.00869983
I1028 19:43:18.734030 29475 solver.cpp:222] Iteration 10200 (1.25391 iter/s, 31.9003s/40 iters), loss = 1.75597
I1028 19:43:18.734226 29475 solver.cpp:241]     Train net output #0: loss = 1.75597 (* 1 = 1.75597 loss)
I1028 19:43:18.734242 29475 sgd_solver.cpp:105] Iteration 10200, lr = 0.00869479
I1028 19:43:51.476862 29475 solver.cpp:222] Iteration 10240 (1.2217 iter/s, 32.7413s/40 iters), loss = 1.6978
I1028 19:43:51.477051 29475 solver.cpp:241]     Train net output #0: loss = 1.6978 (* 1 = 1.6978 loss)
I1028 19:43:51.477068 29475 sgd_solver.cpp:105] Iteration 10240, lr = 0.00868976
I1028 19:44:22.769685 29475 solver.cpp:222] Iteration 10280 (1.2783 iter/s, 31.2914s/40 iters), loss = 1.70625
I1028 19:44:22.769881 29475 solver.cpp:241]     Train net output #0: loss = 1.70625 (* 1 = 1.70625 loss)
I1028 19:44:22.769897 29475 sgd_solver.cpp:105] Iteration 10280, lr = 0.00868472
I1028 19:44:54.206104 29475 solver.cpp:222] Iteration 10320 (1.27247 iter/s, 31.435s/40 iters), loss = 1.60435
I1028 19:44:54.206306 29475 solver.cpp:241]     Train net output #0: loss = 1.60435 (* 1 = 1.60435 loss)
I1028 19:44:54.206324 29475 sgd_solver.cpp:105] Iteration 10320, lr = 0.00867969
I1028 19:45:26.256073 29475 solver.cpp:222] Iteration 10360 (1.24811 iter/s, 32.0486s/40 iters), loss = 1.98475
I1028 19:45:26.256253 29475 solver.cpp:241]     Train net output #0: loss = 1.98475 (* 1 = 1.98475 loss)
I1028 19:45:26.256270 29475 sgd_solver.cpp:105] Iteration 10360, lr = 0.00867466
I1028 19:45:57.910758 29475 solver.cpp:222] Iteration 10400 (1.26369 iter/s, 31.6533s/40 iters), loss = 1.86922
I1028 19:45:57.910979 29475 solver.cpp:241]     Train net output #0: loss = 1.86922 (* 1 = 1.86922 loss)
I1028 19:45:57.910997 29475 sgd_solver.cpp:105] Iteration 10400, lr = 0.00866963
I1028 19:46:29.370404 29475 solver.cpp:222] Iteration 10440 (1.27153 iter/s, 31.4582s/40 iters), loss = 1.89353
I1028 19:46:29.370616 29475 solver.cpp:241]     Train net output #0: loss = 1.89353 (* 1 = 1.89353 loss)
I1028 19:46:29.370633 29475 sgd_solver.cpp:105] Iteration 10440, lr = 0.0086646
I1028 19:47:00.306423 29475 solver.cpp:222] Iteration 10480 (1.29305 iter/s, 30.9346s/40 iters), loss = 1.88599
I1028 19:47:00.306591 29475 solver.cpp:241]     Train net output #0: loss = 1.88599 (* 1 = 1.88599 loss)
I1028 19:47:00.306617 29475 sgd_solver.cpp:105] Iteration 10480, lr = 0.00865957
I1028 19:47:14.963241 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_10500.caffemodel
I1028 19:47:15.006642 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_10500.solverstate
I1028 19:47:15.024153 29475 solver.cpp:334] Iteration 10500, Testing net (#0)
I1028 19:47:45.930974 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 19:47:46.137902 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53236
I1028 19:47:46.137966 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77928
I1028 19:47:46.137979 29475 solver.cpp:401]     Test net output #2: loss = 2.07377 (* 1 = 2.07377 loss)
I1028 19:48:02.449740 29475 solver.cpp:222] Iteration 10520 (0.643699 iter/s, 62.1408s/40 iters), loss = 1.68692
I1028 19:48:02.449815 29475 solver.cpp:241]     Train net output #0: loss = 1.68692 (* 1 = 1.68692 loss)
I1028 19:48:02.449831 29475 sgd_solver.cpp:105] Iteration 10520, lr = 0.00865454
I1028 19:48:33.613662 29475 solver.cpp:222] Iteration 10560 (1.28359 iter/s, 31.1626s/40 iters), loss = 1.58621
I1028 19:48:33.613859 29475 solver.cpp:241]     Train net output #0: loss = 1.58621 (* 1 = 1.58621 loss)
I1028 19:48:33.613878 29475 sgd_solver.cpp:105] Iteration 10560, lr = 0.00864951
I1028 19:49:04.977267 29475 solver.cpp:222] Iteration 10600 (1.27542 iter/s, 31.3622s/40 iters), loss = 1.55282
I1028 19:49:04.977512 29475 solver.cpp:241]     Train net output #0: loss = 1.55282 (* 1 = 1.55282 loss)
I1028 19:49:04.977541 29475 sgd_solver.cpp:105] Iteration 10600, lr = 0.00864448
I1028 19:49:36.687888 29475 solver.cpp:222] Iteration 10640 (1.26147 iter/s, 31.7091s/40 iters), loss = 1.9322
I1028 19:49:36.688071 29475 solver.cpp:241]     Train net output #0: loss = 1.9322 (* 1 = 1.9322 loss)
I1028 19:49:36.688089 29475 sgd_solver.cpp:105] Iteration 10640, lr = 0.00863945
I1028 19:50:08.386008 29475 solver.cpp:222] Iteration 10680 (1.26196 iter/s, 31.6967s/40 iters), loss = 1.65943
I1028 19:50:08.386205 29475 solver.cpp:241]     Train net output #0: loss = 1.65943 (* 1 = 1.65943 loss)
I1028 19:50:08.386224 29475 sgd_solver.cpp:105] Iteration 10680, lr = 0.00863442
I1028 19:50:39.419080 29475 solver.cpp:222] Iteration 10720 (1.289 iter/s, 31.0317s/40 iters), loss = 1.56303
I1028 19:50:39.419253 29475 solver.cpp:241]     Train net output #0: loss = 1.56303 (* 1 = 1.56303 loss)
I1028 19:50:39.419270 29475 sgd_solver.cpp:105] Iteration 10720, lr = 0.0086294
I1028 19:51:10.466853 29475 solver.cpp:222] Iteration 10760 (1.28839 iter/s, 31.0464s/40 iters), loss = 2.22826
I1028 19:51:10.467051 29475 solver.cpp:241]     Train net output #0: loss = 2.22826 (* 1 = 2.22826 loss)
I1028 19:51:10.467067 29475 sgd_solver.cpp:105] Iteration 10760, lr = 0.00862437
I1028 19:51:41.636345 29475 solver.cpp:222] Iteration 10800 (1.28336 iter/s, 31.1681s/40 iters), loss = 1.65565
I1028 19:51:41.636524 29475 solver.cpp:241]     Train net output #0: loss = 1.65565 (* 1 = 1.65565 loss)
I1028 19:51:41.636545 29475 sgd_solver.cpp:105] Iteration 10800, lr = 0.00861935
I1028 19:52:12.770934 29475 solver.cpp:222] Iteration 10840 (1.2848 iter/s, 31.1332s/40 iters), loss = 1.80375
I1028 19:52:12.771116 29475 solver.cpp:241]     Train net output #0: loss = 1.80375 (* 1 = 1.80375 loss)
I1028 19:52:12.771134 29475 sgd_solver.cpp:105] Iteration 10840, lr = 0.00861432
I1028 19:52:43.633194 29475 solver.cpp:222] Iteration 10880 (1.29614 iter/s, 30.8609s/40 iters), loss = 1.65881
I1028 19:52:43.633515 29475 solver.cpp:241]     Train net output #0: loss = 1.65881 (* 1 = 1.65881 loss)
I1028 19:52:43.633534 29475 sgd_solver.cpp:105] Iteration 10880, lr = 0.0086093
I1028 19:53:14.480305 29475 solver.cpp:222] Iteration 10920 (1.29678 iter/s, 30.8455s/40 iters), loss = 1.72655
I1028 19:53:14.480495 29475 solver.cpp:241]     Train net output #0: loss = 1.72655 (* 1 = 1.72655 loss)
I1028 19:53:14.480514 29475 sgd_solver.cpp:105] Iteration 10920, lr = 0.00860428
I1028 19:53:46.166740 29475 solver.cpp:222] Iteration 10960 (1.26243 iter/s, 31.685s/40 iters), loss = 1.56295
I1028 19:53:46.166957 29475 solver.cpp:241]     Train net output #0: loss = 1.56295 (* 1 = 1.56295 loss)
I1028 19:53:46.166976 29475 sgd_solver.cpp:105] Iteration 10960, lr = 0.00859925
I1028 19:54:17.494422 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_11000.caffemodel
I1028 19:54:17.528179 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_11000.solverstate
I1028 19:54:17.553673 29475 solver.cpp:334] Iteration 11000, Testing net (#0)
I1028 19:54:48.624218 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54256
I1028 19:54:48.624389 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78004
I1028 19:54:48.624404 29475 solver.cpp:401]     Test net output #2: loss = 2.04596 (* 1 = 2.04596 loss)
I1028 19:54:49.398663 29475 solver.cpp:222] Iteration 11000 (0.632618 iter/s, 63.2293s/40 iters), loss = 1.78588
I1028 19:54:49.398710 29475 solver.cpp:241]     Train net output #0: loss = 1.78588 (* 1 = 1.78588 loss)
I1028 19:54:49.398726 29475 sgd_solver.cpp:105] Iteration 11000, lr = 0.00859423
I1028 19:55:21.091869 29475 solver.cpp:222] Iteration 11040 (1.26215 iter/s, 31.692s/40 iters), loss = 1.43371
I1028 19:55:21.092057 29475 solver.cpp:241]     Train net output #0: loss = 1.43371 (* 1 = 1.43371 loss)
I1028 19:55:21.092075 29475 sgd_solver.cpp:105] Iteration 11040, lr = 0.00858921
I1028 19:55:52.242245 29475 solver.cpp:222] Iteration 11080 (1.28415 iter/s, 31.149s/40 iters), loss = 1.65987
I1028 19:55:52.242503 29475 solver.cpp:241]     Train net output #0: loss = 1.65987 (* 1 = 1.65987 loss)
I1028 19:55:52.242522 29475 sgd_solver.cpp:105] Iteration 11080, lr = 0.00858419
I1028 19:56:23.747474 29475 solver.cpp:222] Iteration 11120 (1.26969 iter/s, 31.5038s/40 iters), loss = 1.95518
I1028 19:56:23.747683 29475 solver.cpp:241]     Train net output #0: loss = 1.95518 (* 1 = 1.95518 loss)
I1028 19:56:23.747699 29475 sgd_solver.cpp:105] Iteration 11120, lr = 0.00857917
I1028 19:56:55.070847 29475 solver.cpp:222] Iteration 11160 (1.27706 iter/s, 31.322s/40 iters), loss = 1.6535
I1028 19:56:55.071024 29475 solver.cpp:241]     Train net output #0: loss = 1.6535 (* 1 = 1.6535 loss)
I1028 19:56:55.071043 29475 sgd_solver.cpp:105] Iteration 11160, lr = 0.00857415
I1028 19:57:26.124758 29475 solver.cpp:222] Iteration 11200 (1.28814 iter/s, 31.0526s/40 iters), loss = 1.89962
I1028 19:57:26.124969 29475 solver.cpp:241]     Train net output #0: loss = 1.89962 (* 1 = 1.89962 loss)
I1028 19:57:26.124989 29475 sgd_solver.cpp:105] Iteration 11200, lr = 0.00856913
I1028 19:57:56.821961 29475 solver.cpp:222] Iteration 11240 (1.30311 iter/s, 30.6958s/40 iters), loss = 1.57644
I1028 19:57:56.822156 29475 solver.cpp:241]     Train net output #0: loss = 1.57644 (* 1 = 1.57644 loss)
I1028 19:57:56.822172 29475 sgd_solver.cpp:105] Iteration 11240, lr = 0.00856411
I1028 19:58:27.348292 29475 solver.cpp:222] Iteration 11280 (1.3104 iter/s, 30.525s/40 iters), loss = 1.83578
I1028 19:58:27.348512 29475 solver.cpp:241]     Train net output #0: loss = 1.83578 (* 1 = 1.83578 loss)
I1028 19:58:27.348531 29475 sgd_solver.cpp:105] Iteration 11280, lr = 0.0085591
I1028 19:58:56.872454 29475 solver.cpp:222] Iteration 11320 (1.35489 iter/s, 29.5228s/40 iters), loss = 1.80273
I1028 19:58:56.872536 29475 solver.cpp:241]     Train net output #0: loss = 1.80273 (* 1 = 1.80273 loss)
I1028 19:58:56.872555 29475 sgd_solver.cpp:105] Iteration 11320, lr = 0.00855408
I1028 19:59:27.357586 29475 solver.cpp:222] Iteration 11360 (1.31217 iter/s, 30.4839s/40 iters), loss = 1.75574
I1028 19:59:27.357766 29475 solver.cpp:241]     Train net output #0: loss = 1.75574 (* 1 = 1.75574 loss)
I1028 19:59:27.357782 29475 sgd_solver.cpp:105] Iteration 11360, lr = 0.00854907
I1028 19:59:57.472101 29475 solver.cpp:222] Iteration 11400 (1.32832 iter/s, 30.1132s/40 iters), loss = 1.7024
I1028 19:59:57.472281 29475 solver.cpp:241]     Train net output #0: loss = 1.7024 (* 1 = 1.7024 loss)
I1028 19:59:57.472302 29475 sgd_solver.cpp:105] Iteration 11400, lr = 0.00854405
I1028 20:00:28.071749 29475 solver.cpp:222] Iteration 11440 (1.30726 iter/s, 30.5983s/40 iters), loss = 2.34775
I1028 20:00:28.071976 29475 solver.cpp:241]     Train net output #0: loss = 2.34775 (* 1 = 2.34775 loss)
I1028 20:00:28.071995 29475 sgd_solver.cpp:105] Iteration 11440, lr = 0.00853904
I1028 20:00:59.166927 29475 solver.cpp:222] Iteration 11480 (1.28643 iter/s, 31.0938s/40 iters), loss = 1.62722
I1028 20:00:59.167178 29475 solver.cpp:241]     Train net output #0: loss = 1.62722 (* 1 = 1.62722 loss)
I1028 20:00:59.167212 29475 sgd_solver.cpp:105] Iteration 11480, lr = 0.00853402
I1028 20:01:13.934975 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_11500.caffemodel
I1028 20:01:13.970182 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_11500.solverstate
I1028 20:01:13.987023 29475 solver.cpp:334] Iteration 11500, Testing net (#0)
I1028 20:01:44.912763 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 20:01:45.119724 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53132
I1028 20:01:45.119784 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7764
I1028 20:01:45.119797 29475 solver.cpp:401]     Test net output #2: loss = 2.10298 (* 1 = 2.10298 loss)
I1028 20:02:01.089304 29475 solver.cpp:222] Iteration 11520 (0.645998 iter/s, 61.9197s/40 iters), loss = 1.74037
I1028 20:02:01.089373 29475 solver.cpp:241]     Train net output #0: loss = 1.74037 (* 1 = 1.74037 loss)
I1028 20:02:01.089402 29475 sgd_solver.cpp:105] Iteration 11520, lr = 0.00852901
I1028 20:02:32.073351 29475 solver.cpp:222] Iteration 11560 (1.29104 iter/s, 30.9828s/40 iters), loss = 1.71463
I1028 20:02:32.073596 29475 solver.cpp:241]     Train net output #0: loss = 1.71463 (* 1 = 1.71463 loss)
I1028 20:02:32.073614 29475 sgd_solver.cpp:105] Iteration 11560, lr = 0.008524
I1028 20:03:03.337606 29475 solver.cpp:222] Iteration 11600 (1.27948 iter/s, 31.2628s/40 iters), loss = 1.82475
I1028 20:03:03.337888 29475 solver.cpp:241]     Train net output #0: loss = 1.82475 (* 1 = 1.82475 loss)
I1028 20:03:03.337920 29475 sgd_solver.cpp:105] Iteration 11600, lr = 0.00851899
I1028 20:03:35.437795 29475 solver.cpp:222] Iteration 11640 (1.24616 iter/s, 32.0987s/40 iters), loss = 1.7487
I1028 20:03:35.438001 29475 solver.cpp:241]     Train net output #0: loss = 1.7487 (* 1 = 1.7487 loss)
I1028 20:03:35.438020 29475 sgd_solver.cpp:105] Iteration 11640, lr = 0.00851398
I1028 20:04:07.273625 29475 solver.cpp:222] Iteration 11680 (1.2565 iter/s, 31.8344s/40 iters), loss = 1.73764
I1028 20:04:07.273823 29475 solver.cpp:241]     Train net output #0: loss = 1.73764 (* 1 = 1.73764 loss)
I1028 20:04:07.273839 29475 sgd_solver.cpp:105] Iteration 11680, lr = 0.00850897
I1028 20:04:39.402082 29475 solver.cpp:222] Iteration 11720 (1.24506 iter/s, 32.127s/40 iters), loss = 1.89946
I1028 20:04:39.402343 29475 solver.cpp:241]     Train net output #0: loss = 1.89946 (* 1 = 1.89946 loss)
I1028 20:04:39.402374 29475 sgd_solver.cpp:105] Iteration 11720, lr = 0.00850396
I1028 20:05:11.109036 29475 solver.cpp:222] Iteration 11760 (1.26161 iter/s, 31.7055s/40 iters), loss = 1.54108
I1028 20:05:11.109272 29475 solver.cpp:241]     Train net output #0: loss = 1.54108 (* 1 = 1.54108 loss)
I1028 20:05:11.109294 29475 sgd_solver.cpp:105] Iteration 11760, lr = 0.00849895
I1028 20:05:44.584594 29475 solver.cpp:222] Iteration 11800 (1.19496 iter/s, 33.4741s/40 iters), loss = 1.76965
I1028 20:05:44.584836 29475 solver.cpp:241]     Train net output #0: loss = 1.76965 (* 1 = 1.76965 loss)
I1028 20:05:44.584861 29475 sgd_solver.cpp:105] Iteration 11800, lr = 0.00849394
I1028 20:06:15.875406 29475 solver.cpp:222] Iteration 11840 (1.27839 iter/s, 31.2894s/40 iters), loss = 1.95343
I1028 20:06:15.875602 29475 solver.cpp:241]     Train net output #0: loss = 1.95343 (* 1 = 1.95343 loss)
I1028 20:06:15.875618 29475 sgd_solver.cpp:105] Iteration 11840, lr = 0.00848893
I1028 20:06:46.852596 29475 solver.cpp:222] Iteration 11880 (1.29133 iter/s, 30.9757s/40 iters), loss = 2.06128
I1028 20:06:46.852823 29475 solver.cpp:241]     Train net output #0: loss = 2.06128 (* 1 = 2.06128 loss)
I1028 20:06:46.852841 29475 sgd_solver.cpp:105] Iteration 11880, lr = 0.00848392
I1028 20:07:17.861353 29475 solver.cpp:222] Iteration 11920 (1.29002 iter/s, 31.0074s/40 iters), loss = 1.58742
I1028 20:07:17.861541 29475 solver.cpp:241]     Train net output #0: loss = 1.58742 (* 1 = 1.58742 loss)
I1028 20:07:17.861557 29475 sgd_solver.cpp:105] Iteration 11920, lr = 0.00847892
I1028 20:07:48.670388 29475 solver.cpp:222] Iteration 11960 (1.29838 iter/s, 30.8077s/40 iters), loss = 1.78138
I1028 20:07:48.670560 29475 solver.cpp:241]     Train net output #0: loss = 1.78138 (* 1 = 1.78138 loss)
I1028 20:07:48.670577 29475 sgd_solver.cpp:105] Iteration 11960, lr = 0.00847391
I1028 20:08:19.069281 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_12000.caffemodel
I1028 20:08:19.103639 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_12000.solverstate
I1028 20:08:19.120965 29475 solver.cpp:334] Iteration 12000, Testing net (#0)
I1028 20:08:50.186362 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5386
I1028 20:08:50.186532 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77616
I1028 20:08:50.186547 29475 solver.cpp:401]     Test net output #2: loss = 2.05013 (* 1 = 2.05013 loss)
I1028 20:08:50.962054 29475 solver.cpp:222] Iteration 12000 (0.642166 iter/s, 62.2892s/40 iters), loss = 2.08066
I1028 20:08:50.962146 29475 solver.cpp:241]     Train net output #0: loss = 2.08066 (* 1 = 2.08066 loss)
I1028 20:08:50.962163 29475 sgd_solver.cpp:105] Iteration 12000, lr = 0.00846891
I1028 20:09:22.107159 29475 solver.cpp:222] Iteration 12040 (1.28436 iter/s, 31.1438s/40 iters), loss = 1.82452
I1028 20:09:22.107437 29475 solver.cpp:241]     Train net output #0: loss = 1.82452 (* 1 = 1.82452 loss)
I1028 20:09:22.107465 29475 sgd_solver.cpp:105] Iteration 12040, lr = 0.00846391
I1028 20:09:53.677495 29475 solver.cpp:222] Iteration 12080 (1.26707 iter/s, 31.5689s/40 iters), loss = 1.76772
I1028 20:09:53.677700 29475 solver.cpp:241]     Train net output #0: loss = 1.76772 (* 1 = 1.76772 loss)
I1028 20:09:53.677717 29475 sgd_solver.cpp:105] Iteration 12080, lr = 0.0084589
I1028 20:10:24.985491 29475 solver.cpp:222] Iteration 12120 (1.27769 iter/s, 31.3065s/40 iters), loss = 1.91265
I1028 20:10:24.985702 29475 solver.cpp:241]     Train net output #0: loss = 1.91265 (* 1 = 1.91265 loss)
I1028 20:10:24.985720 29475 sgd_solver.cpp:105] Iteration 12120, lr = 0.0084539
I1028 20:10:56.292646 29475 solver.cpp:222] Iteration 12160 (1.27772 iter/s, 31.3057s/40 iters), loss = 1.90163
I1028 20:10:56.292840 29475 solver.cpp:241]     Train net output #0: loss = 1.90163 (* 1 = 1.90163 loss)
I1028 20:10:56.292856 29475 sgd_solver.cpp:105] Iteration 12160, lr = 0.0084489
I1028 20:11:27.807709 29475 solver.cpp:222] Iteration 12200 (1.26929 iter/s, 31.5137s/40 iters), loss = 1.61741
I1028 20:11:27.807919 29475 solver.cpp:241]     Train net output #0: loss = 1.61741 (* 1 = 1.61741 loss)
I1028 20:11:27.807940 29475 sgd_solver.cpp:105] Iteration 12200, lr = 0.0084439
I1028 20:12:01.072521 29475 solver.cpp:222] Iteration 12240 (1.20253 iter/s, 33.2633s/40 iters), loss = 1.88255
I1028 20:12:01.072721 29475 solver.cpp:241]     Train net output #0: loss = 1.88255 (* 1 = 1.88255 loss)
I1028 20:12:01.072738 29475 sgd_solver.cpp:105] Iteration 12240, lr = 0.0084389
I1028 20:12:36.508769 29475 solver.cpp:222] Iteration 12280 (1.12884 iter/s, 35.4346s/40 iters), loss = 2.25349
I1028 20:12:36.508934 29475 solver.cpp:241]     Train net output #0: loss = 2.25349 (* 1 = 2.25349 loss)
I1028 20:12:36.508955 29475 sgd_solver.cpp:105] Iteration 12280, lr = 0.0084339
I1028 20:13:14.552211 29475 solver.cpp:222] Iteration 12320 (1.05147 iter/s, 38.0419s/40 iters), loss = 1.73993
I1028 20:13:14.552404 29475 solver.cpp:241]     Train net output #0: loss = 1.73993 (* 1 = 1.73993 loss)
I1028 20:13:14.552428 29475 sgd_solver.cpp:105] Iteration 12320, lr = 0.0084289
I1028 20:13:45.831609 29475 solver.cpp:222] Iteration 12360 (1.27885 iter/s, 31.278s/40 iters), loss = 1.35943
I1028 20:13:45.831841 29475 solver.cpp:241]     Train net output #0: loss = 1.35943 (* 1 = 1.35943 loss)
I1028 20:13:45.831867 29475 sgd_solver.cpp:105] Iteration 12360, lr = 0.0084239
I1028 20:14:17.323086 29475 solver.cpp:222] Iteration 12400 (1.27024 iter/s, 31.49s/40 iters), loss = 1.77852
I1028 20:14:17.323271 29475 solver.cpp:241]     Train net output #0: loss = 1.77852 (* 1 = 1.77852 loss)
I1028 20:14:17.323287 29475 sgd_solver.cpp:105] Iteration 12400, lr = 0.0084189
I1028 20:14:48.332336 29475 solver.cpp:222] Iteration 12440 (1.28999 iter/s, 31.0079s/40 iters), loss = 1.88155
I1028 20:14:48.332554 29475 solver.cpp:241]     Train net output #0: loss = 1.88155 (* 1 = 1.88155 loss)
I1028 20:14:48.332571 29475 sgd_solver.cpp:105] Iteration 12440, lr = 0.0084139
I1028 20:15:19.574389 29475 solver.cpp:222] Iteration 12480 (1.28038 iter/s, 31.2407s/40 iters), loss = 1.51504
I1028 20:15:19.574597 29475 solver.cpp:241]     Train net output #0: loss = 1.51504 (* 1 = 1.51504 loss)
I1028 20:15:19.574618 29475 sgd_solver.cpp:105] Iteration 12480, lr = 0.00840891
I1028 20:15:34.401106 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_12500.caffemodel
I1028 20:15:34.437320 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_12500.solverstate
I1028 20:15:34.455484 29475 solver.cpp:334] Iteration 12500, Testing net (#0)
I1028 20:16:05.356792 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 20:16:05.566319 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.537
I1028 20:16:05.566380 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77868
I1028 20:16:05.566395 29475 solver.cpp:401]     Test net output #2: loss = 2.05287 (* 1 = 2.05287 loss)
I1028 20:16:11.958174 29523 data_layer.cpp:73] Restarting data prefetching from start.
I1028 20:16:21.764156 29475 solver.cpp:222] Iteration 12520 (0.643219 iter/s, 62.1872s/40 iters), loss = 1.7679
I1028 20:16:21.764230 29475 solver.cpp:241]     Train net output #0: loss = 1.7679 (* 1 = 1.7679 loss)
I1028 20:16:21.764250 29475 sgd_solver.cpp:105] Iteration 12520, lr = 0.00840391
I1028 20:16:52.722810 29475 solver.cpp:222] Iteration 12560 (1.2921 iter/s, 30.9574s/40 iters), loss = 1.97937
I1028 20:16:52.722985 29475 solver.cpp:241]     Train net output #0: loss = 1.97937 (* 1 = 1.97937 loss)
I1028 20:16:52.723000 29475 sgd_solver.cpp:105] Iteration 12560, lr = 0.00839892
I1028 20:17:24.016794 29475 solver.cpp:222] Iteration 12600 (1.27826 iter/s, 31.2926s/40 iters), loss = 1.75452
I1028 20:17:24.016970 29475 solver.cpp:241]     Train net output #0: loss = 1.75452 (* 1 = 1.75452 loss)
I1028 20:17:24.016986 29475 sgd_solver.cpp:105] Iteration 12600, lr = 0.00839392
I1028 20:17:54.918139 29475 solver.cpp:222] Iteration 12640 (1.2945 iter/s, 30.9s/40 iters), loss = 1.86095
I1028 20:17:54.918319 29475 solver.cpp:241]     Train net output #0: loss = 1.86095 (* 1 = 1.86095 loss)
I1028 20:17:54.918337 29475 sgd_solver.cpp:105] Iteration 12640, lr = 0.00838893
I1028 20:18:25.887536 29475 solver.cpp:222] Iteration 12680 (1.29165 iter/s, 30.968s/40 iters), loss = 1.61774
I1028 20:18:25.887706 29475 solver.cpp:241]     Train net output #0: loss = 1.61774 (* 1 = 1.61774 loss)
I1028 20:18:25.887724 29475 sgd_solver.cpp:105] Iteration 12680, lr = 0.00838393
I1028 20:18:57.068372 29475 solver.cpp:222] Iteration 12720 (1.28289 iter/s, 31.1795s/40 iters), loss = 1.87968
I1028 20:18:57.068563 29475 solver.cpp:241]     Train net output #0: loss = 1.87968 (* 1 = 1.87968 loss)
I1028 20:18:57.068580 29475 sgd_solver.cpp:105] Iteration 12720, lr = 0.00837894
I1028 20:19:28.145572 29475 solver.cpp:222] Iteration 12760 (1.28717 iter/s, 31.0758s/40 iters), loss = 1.5556
I1028 20:19:28.145766 29475 solver.cpp:241]     Train net output #0: loss = 1.5556 (* 1 = 1.5556 loss)
I1028 20:19:28.145786 29475 sgd_solver.cpp:105] Iteration 12760, lr = 0.00837395
I1028 20:19:59.055531 29475 solver.cpp:222] Iteration 12800 (1.29414 iter/s, 30.9086s/40 iters), loss = 1.96016
I1028 20:19:59.055703 29475 solver.cpp:241]     Train net output #0: loss = 1.96016 (* 1 = 1.96016 loss)
I1028 20:19:59.055721 29475 sgd_solver.cpp:105] Iteration 12800, lr = 0.00836896
I1028 20:20:30.608098 29475 solver.cpp:222] Iteration 12840 (1.26778 iter/s, 31.5512s/40 iters), loss = 1.66003
I1028 20:20:30.608317 29475 solver.cpp:241]     Train net output #0: loss = 1.66003 (* 1 = 1.66003 loss)
I1028 20:20:30.608335 29475 sgd_solver.cpp:105] Iteration 12840, lr = 0.00836397
I1028 20:21:01.967972 29475 solver.cpp:222] Iteration 12880 (1.27557 iter/s, 31.3585s/40 iters), loss = 1.88108
I1028 20:21:01.968152 29475 solver.cpp:241]     Train net output #0: loss = 1.88108 (* 1 = 1.88108 loss)
I1028 20:21:01.968168 29475 sgd_solver.cpp:105] Iteration 12880, lr = 0.00835898
I1028 20:21:32.962085 29475 solver.cpp:222] Iteration 12920 (1.29063 iter/s, 30.9927s/40 iters), loss = 1.45034
I1028 20:21:32.962275 29475 solver.cpp:241]     Train net output #0: loss = 1.45034 (* 1 = 1.45034 loss)
I1028 20:21:32.962293 29475 sgd_solver.cpp:105] Iteration 12920, lr = 0.00835399
I1028 20:22:03.890437 29475 solver.cpp:222] Iteration 12960 (1.29337 iter/s, 30.927s/40 iters), loss = 2.1966
I1028 20:22:03.890616 29475 solver.cpp:241]     Train net output #0: loss = 2.1966 (* 1 = 2.1966 loss)
I1028 20:22:03.890635 29475 sgd_solver.cpp:105] Iteration 12960, lr = 0.008349
I1028 20:22:34.069203 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_13000.caffemodel
I1028 20:22:34.104847 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_13000.solverstate
I1028 20:22:34.123670 29475 solver.cpp:334] Iteration 13000, Testing net (#0)
I1028 20:23:05.253716 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53376
I1028 20:23:05.253887 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7798
I1028 20:23:05.253907 29475 solver.cpp:401]     Test net output #2: loss = 2.09805 (* 1 = 2.09805 loss)
I1028 20:23:06.022929 29475 solver.cpp:222] Iteration 13000 (0.643812 iter/s, 62.13s/40 iters), loss = 1.33715
I1028 20:23:06.023011 29475 solver.cpp:241]     Train net output #0: loss = 1.33715 (* 1 = 1.33715 loss)
I1028 20:23:06.023035 29475 sgd_solver.cpp:105] Iteration 13000, lr = 0.00834401
I1028 20:23:36.613867 29475 solver.cpp:222] Iteration 13040 (1.30763 iter/s, 30.5897s/40 iters), loss = 1.81091
I1028 20:23:36.614051 29475 solver.cpp:241]     Train net output #0: loss = 1.81091 (* 1 = 1.81091 loss)
I1028 20:23:36.614070 29475 sgd_solver.cpp:105] Iteration 13040, lr = 0.00833903
I1028 20:24:07.360872 29475 solver.cpp:222] Iteration 13080 (1.301 iter/s, 30.7457s/40 iters), loss = 1.61624
I1028 20:24:07.361049 29475 solver.cpp:241]     Train net output #0: loss = 1.61624 (* 1 = 1.61624 loss)
I1028 20:24:07.361066 29475 sgd_solver.cpp:105] Iteration 13080, lr = 0.00833404
I1028 20:24:38.075656 29475 solver.cpp:222] Iteration 13120 (1.30236 iter/s, 30.7134s/40 iters), loss = 1.698
I1028 20:24:38.075837 29475 solver.cpp:241]     Train net output #0: loss = 1.698 (* 1 = 1.698 loss)
I1028 20:24:38.075853 29475 sgd_solver.cpp:105] Iteration 13120, lr = 0.00832906
I1028 20:25:09.201445 29475 solver.cpp:222] Iteration 13160 (1.28517 iter/s, 31.1244s/40 iters), loss = 1.85211
I1028 20:25:09.201628 29475 solver.cpp:241]     Train net output #0: loss = 1.85211 (* 1 = 1.85211 loss)
I1028 20:25:09.201647 29475 sgd_solver.cpp:105] Iteration 13160, lr = 0.00832407
I1028 20:25:40.041379 29475 solver.cpp:222] Iteration 13200 (1.29708 iter/s, 30.8386s/40 iters), loss = 1.58548
I1028 20:25:40.041601 29475 solver.cpp:241]     Train net output #0: loss = 1.58548 (* 1 = 1.58548 loss)
I1028 20:25:40.041630 29475 sgd_solver.cpp:105] Iteration 13200, lr = 0.00831909
I1028 20:26:10.927134 29475 solver.cpp:222] Iteration 13240 (1.29515 iter/s, 30.8844s/40 iters), loss = 1.90196
I1028 20:26:10.927325 29475 solver.cpp:241]     Train net output #0: loss = 1.90196 (* 1 = 1.90196 loss)
I1028 20:26:10.927345 29475 sgd_solver.cpp:105] Iteration 13240, lr = 0.0083141
I1028 20:26:42.112102 29475 solver.cpp:222] Iteration 13280 (1.28273 iter/s, 31.1836s/40 iters), loss = 1.82376
I1028 20:26:42.112288 29475 solver.cpp:241]     Train net output #0: loss = 1.82376 (* 1 = 1.82376 loss)
I1028 20:26:42.112313 29475 sgd_solver.cpp:105] Iteration 13280, lr = 0.00830912
I1028 20:27:13.171535 29475 solver.cpp:222] Iteration 13320 (1.28791 iter/s, 31.0581s/40 iters), loss = 1.72516
I1028 20:27:13.171722 29475 solver.cpp:241]     Train net output #0: loss = 1.72516 (* 1 = 1.72516 loss)
I1028 20:27:13.171738 29475 sgd_solver.cpp:105] Iteration 13320, lr = 0.00830414
I1028 20:27:44.362370 29475 solver.cpp:222] Iteration 13360 (1.28248 iter/s, 31.1895s/40 iters), loss = 1.56555
I1028 20:27:44.362540 29475 solver.cpp:241]     Train net output #0: loss = 1.56555 (* 1 = 1.56555 loss)
I1028 20:27:44.362556 29475 sgd_solver.cpp:105] Iteration 13360, lr = 0.00829916
I1028 20:28:15.396198 29475 solver.cpp:222] Iteration 13400 (1.28897 iter/s, 31.0325s/40 iters), loss = 1.59953
I1028 20:28:15.396421 29475 solver.cpp:241]     Train net output #0: loss = 1.59953 (* 1 = 1.59953 loss)
I1028 20:28:15.396443 29475 sgd_solver.cpp:105] Iteration 13400, lr = 0.00829418
I1028 20:28:46.833350 29475 solver.cpp:222] Iteration 13440 (1.27244 iter/s, 31.4357s/40 iters), loss = 1.8291
I1028 20:28:46.833632 29475 solver.cpp:241]     Train net output #0: loss = 1.8291 (* 1 = 1.8291 loss)
I1028 20:28:46.833667 29475 sgd_solver.cpp:105] Iteration 13440, lr = 0.0082892
I1028 20:29:18.523685 29475 solver.cpp:222] Iteration 13480 (1.26228 iter/s, 31.6888s/40 iters), loss = 1.5732
I1028 20:29:18.523855 29475 solver.cpp:241]     Train net output #0: loss = 1.5732 (* 1 = 1.5732 loss)
I1028 20:29:18.523874 29475 sgd_solver.cpp:105] Iteration 13480, lr = 0.00828422
I1028 20:29:33.551064 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_13500.caffemodel
I1028 20:29:33.595477 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_13500.solverstate
I1028 20:29:33.614142 29475 solver.cpp:334] Iteration 13500, Testing net (#0)
I1028 20:30:04.517886 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 20:30:04.726188 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54244
I1028 20:30:04.726253 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7824
I1028 20:30:04.726266 29475 solver.cpp:401]     Test net output #2: loss = 2.03362 (* 1 = 2.03362 loss)
I1028 20:30:21.027498 29475 solver.cpp:222] Iteration 13520 (0.639987 iter/s, 62.5013s/40 iters), loss = 1.8304
I1028 20:30:21.027565 29475 solver.cpp:241]     Train net output #0: loss = 1.8304 (* 1 = 1.8304 loss)
I1028 20:30:21.027580 29475 sgd_solver.cpp:105] Iteration 13520, lr = 0.00827924
I1028 20:30:52.118191 29475 solver.cpp:222] Iteration 13560 (1.28661 iter/s, 31.0894s/40 iters), loss = 1.32654
I1028 20:30:52.118697 29475 solver.cpp:241]     Train net output #0: loss = 1.32654 (* 1 = 1.32654 loss)
I1028 20:30:52.118715 29475 sgd_solver.cpp:105] Iteration 13560, lr = 0.00827426
I1028 20:31:24.571832 29475 solver.cpp:222] Iteration 13600 (1.23259 iter/s, 32.4519s/40 iters), loss = 2.03596
I1028 20:31:24.572075 29475 solver.cpp:241]     Train net output #0: loss = 2.03596 (* 1 = 2.03596 loss)
I1028 20:31:24.572099 29475 sgd_solver.cpp:105] Iteration 13600, lr = 0.00826928
I1028 20:31:56.542978 29475 solver.cpp:222] Iteration 13640 (1.25119 iter/s, 31.9696s/40 iters), loss = 1.8162
I1028 20:31:56.543180 29475 solver.cpp:241]     Train net output #0: loss = 1.8162 (* 1 = 1.8162 loss)
I1028 20:31:56.543197 29475 sgd_solver.cpp:105] Iteration 13640, lr = 0.00826431
I1028 20:32:28.221295 29475 solver.cpp:222] Iteration 13680 (1.26275 iter/s, 31.6769s/40 iters), loss = 1.52422
I1028 20:32:28.221458 29475 solver.cpp:241]     Train net output #0: loss = 1.52422 (* 1 = 1.52422 loss)
I1028 20:32:28.221475 29475 sgd_solver.cpp:105] Iteration 13680, lr = 0.00825933
I1028 20:33:00.179755 29475 solver.cpp:222] Iteration 13720 (1.25168 iter/s, 31.9571s/40 iters), loss = 1.61065
I1028 20:33:00.179947 29475 solver.cpp:241]     Train net output #0: loss = 1.61065 (* 1 = 1.61065 loss)
I1028 20:33:00.179963 29475 sgd_solver.cpp:105] Iteration 13720, lr = 0.00825436
I1028 20:33:31.799904 29475 solver.cpp:222] Iteration 13760 (1.26507 iter/s, 31.6188s/40 iters), loss = 2.00183
I1028 20:33:31.800114 29475 solver.cpp:241]     Train net output #0: loss = 2.00183 (* 1 = 2.00183 loss)
I1028 20:33:31.800130 29475 sgd_solver.cpp:105] Iteration 13760, lr = 0.00824938
I1028 20:34:02.927346 29475 solver.cpp:222] Iteration 13800 (1.2851 iter/s, 31.126s/40 iters), loss = 1.48161
I1028 20:34:02.927594 29475 solver.cpp:241]     Train net output #0: loss = 1.48161 (* 1 = 1.48161 loss)
I1028 20:34:02.927618 29475 sgd_solver.cpp:105] Iteration 13800, lr = 0.00824441
I1028 20:34:35.343026 29475 solver.cpp:222] Iteration 13840 (1.23403 iter/s, 32.4142s/40 iters), loss = 1.64638
I1028 20:34:35.343219 29475 solver.cpp:241]     Train net output #0: loss = 1.64638 (* 1 = 1.64638 loss)
I1028 20:34:35.343235 29475 sgd_solver.cpp:105] Iteration 13840, lr = 0.00823943
I1028 20:35:06.374541 29475 solver.cpp:222] Iteration 13880 (1.28907 iter/s, 31.03s/40 iters), loss = 1.93757
I1028 20:35:06.374763 29475 solver.cpp:241]     Train net output #0: loss = 1.93757 (* 1 = 1.93757 loss)
I1028 20:35:06.374795 29475 sgd_solver.cpp:105] Iteration 13880, lr = 0.00823446
I1028 20:35:38.396272 29475 solver.cpp:222] Iteration 13920 (1.24921 iter/s, 32.0203s/40 iters), loss = 1.60496
I1028 20:35:38.396489 29475 solver.cpp:241]     Train net output #0: loss = 1.60496 (* 1 = 1.60496 loss)
I1028 20:35:38.396512 29475 sgd_solver.cpp:105] Iteration 13920, lr = 0.00822949
I1028 20:36:10.106433 29475 solver.cpp:222] Iteration 13960 (1.26148 iter/s, 31.7087s/40 iters), loss = 1.98459
I1028 20:36:10.106618 29475 solver.cpp:241]     Train net output #0: loss = 1.98459 (* 1 = 1.98459 loss)
I1028 20:36:10.106634 29475 sgd_solver.cpp:105] Iteration 13960, lr = 0.00822452
I1028 20:36:41.385854 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_14000.caffemodel
I1028 20:36:41.421684 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_14000.solverstate
I1028 20:36:41.439733 29475 solver.cpp:334] Iteration 14000, Testing net (#0)
I1028 20:37:12.581728 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54084
I1028 20:37:12.581898 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.780359
I1028 20:37:12.581913 29475 solver.cpp:401]     Test net output #2: loss = 2.03299 (* 1 = 2.03299 loss)
I1028 20:37:13.352699 29475 solver.cpp:222] Iteration 14000 (0.632474 iter/s, 63.2437s/40 iters), loss = 1.75499
I1028 20:37:13.352776 29475 solver.cpp:241]     Train net output #0: loss = 1.75499 (* 1 = 1.75499 loss)
I1028 20:37:13.352790 29475 sgd_solver.cpp:105] Iteration 14000, lr = 0.00821955
I1028 20:37:44.845566 29475 solver.cpp:222] Iteration 14040 (1.27018 iter/s, 31.4916s/40 iters), loss = 1.67318
I1028 20:37:44.845788 29475 solver.cpp:241]     Train net output #0: loss = 1.67318 (* 1 = 1.67318 loss)
I1028 20:37:44.845810 29475 sgd_solver.cpp:105] Iteration 14040, lr = 0.00821458
I1028 20:38:16.874939 29475 solver.cpp:222] Iteration 14080 (1.24891 iter/s, 32.0279s/40 iters), loss = 1.67758
I1028 20:38:16.875131 29475 solver.cpp:241]     Train net output #0: loss = 1.67758 (* 1 = 1.67758 loss)
I1028 20:38:16.875151 29475 sgd_solver.cpp:105] Iteration 14080, lr = 0.00820961
I1028 20:38:47.929160 29475 solver.cpp:222] Iteration 14120 (1.28813 iter/s, 31.0528s/40 iters), loss = 1.597
I1028 20:38:47.929335 29475 solver.cpp:241]     Train net output #0: loss = 1.597 (* 1 = 1.597 loss)
I1028 20:38:47.929354 29475 sgd_solver.cpp:105] Iteration 14120, lr = 0.00820464
I1028 20:39:19.162446 29475 solver.cpp:222] Iteration 14160 (1.28074 iter/s, 31.2319s/40 iters), loss = 1.94027
I1028 20:39:19.162637 29475 solver.cpp:241]     Train net output #0: loss = 1.94027 (* 1 = 1.94027 loss)
I1028 20:39:19.162653 29475 sgd_solver.cpp:105] Iteration 14160, lr = 0.00819967
I1028 20:39:49.960113 29475 solver.cpp:222] Iteration 14200 (1.29886 iter/s, 30.7963s/40 iters), loss = 2.07853
I1028 20:39:49.960302 29475 solver.cpp:241]     Train net output #0: loss = 2.07853 (* 1 = 2.07853 loss)
I1028 20:39:49.960319 29475 sgd_solver.cpp:105] Iteration 14200, lr = 0.00819471
I1028 20:40:20.979591 29475 solver.cpp:222] Iteration 14240 (1.28957 iter/s, 31.018s/40 iters), loss = 2.06057
I1028 20:40:20.979789 29475 solver.cpp:241]     Train net output #0: loss = 2.06057 (* 1 = 2.06057 loss)
I1028 20:40:20.979807 29475 sgd_solver.cpp:105] Iteration 14240, lr = 0.00818974
I1028 20:40:51.972718 29475 solver.cpp:222] Iteration 14280 (1.29067 iter/s, 30.9918s/40 iters), loss = 1.66785
I1028 20:40:51.972925 29475 solver.cpp:241]     Train net output #0: loss = 1.66785 (* 1 = 1.66785 loss)
I1028 20:40:51.972944 29475 sgd_solver.cpp:105] Iteration 14280, lr = 0.00818478
I1028 20:41:22.813685 29475 solver.cpp:222] Iteration 14320 (1.29703 iter/s, 30.8396s/40 iters), loss = 1.65368
I1028 20:41:22.813895 29475 solver.cpp:241]     Train net output #0: loss = 1.65368 (* 1 = 1.65368 loss)
I1028 20:41:22.813913 29475 sgd_solver.cpp:105] Iteration 14320, lr = 0.00817981
I1028 20:42:04.081969 29475 solver.cpp:222] Iteration 14360 (0.969309 iter/s, 41.2665s/40 iters), loss = 1.7296
I1028 20:42:04.082355 29475 solver.cpp:241]     Train net output #0: loss = 1.7296 (* 1 = 1.7296 loss)
I1028 20:42:04.082432 29475 sgd_solver.cpp:105] Iteration 14360, lr = 0.00817485
I1028 20:42:34.914708 29475 solver.cpp:222] Iteration 14400 (1.29739 iter/s, 30.8312s/40 iters), loss = 1.60244
I1028 20:42:34.914925 29475 solver.cpp:241]     Train net output #0: loss = 1.60244 (* 1 = 1.60244 loss)
I1028 20:42:34.914942 29475 sgd_solver.cpp:105] Iteration 14400, lr = 0.00816988
I1028 20:43:09.060151 29475 solver.cpp:222] Iteration 14440 (1.17151 iter/s, 34.1439s/40 iters), loss = 1.94482
I1028 20:43:09.060389 29475 solver.cpp:241]     Train net output #0: loss = 1.94482 (* 1 = 1.94482 loss)
I1028 20:43:09.060415 29475 sgd_solver.cpp:105] Iteration 14440, lr = 0.00816492
I1028 20:43:40.170989 29475 solver.cpp:222] Iteration 14480 (1.28578 iter/s, 31.1094s/40 iters), loss = 1.6079
I1028 20:43:40.171167 29475 solver.cpp:241]     Train net output #0: loss = 1.6079 (* 1 = 1.6079 loss)
I1028 20:43:40.171185 29475 sgd_solver.cpp:105] Iteration 14480, lr = 0.00815996
I1028 20:43:55.123293 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_14500.caffemodel
I1028 20:43:55.158808 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_14500.solverstate
I1028 20:43:55.176880 29475 solver.cpp:334] Iteration 14500, Testing net (#0)
I1028 20:44:26.031317 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 20:44:26.238628 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53964
I1028 20:44:26.238688 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77984
I1028 20:44:26.238701 29475 solver.cpp:401]     Test net output #2: loss = 2.08387 (* 1 = 2.08387 loss)
I1028 20:44:42.681251 29475 solver.cpp:222] Iteration 14520 (0.639921 iter/s, 62.5077s/40 iters), loss = 1.76632
I1028 20:44:42.681334 29475 solver.cpp:241]     Train net output #0: loss = 1.76632 (* 1 = 1.76632 loss)
I1028 20:44:42.681351 29475 sgd_solver.cpp:105] Iteration 14520, lr = 0.008155
I1028 20:45:13.967983 29475 solver.cpp:222] Iteration 14560 (1.27855 iter/s, 31.2855s/40 iters), loss = 1.85793
I1028 20:45:13.968168 29475 solver.cpp:241]     Train net output #0: loss = 1.85793 (* 1 = 1.85793 loss)
I1028 20:45:13.968188 29475 sgd_solver.cpp:105] Iteration 14560, lr = 0.00815004
I1028 20:45:44.896919 29475 solver.cpp:222] Iteration 14600 (1.29334 iter/s, 30.9276s/40 iters), loss = 1.72686
I1028 20:45:44.897099 29475 solver.cpp:241]     Train net output #0: loss = 1.72686 (* 1 = 1.72686 loss)
I1028 20:45:44.897115 29475 sgd_solver.cpp:105] Iteration 14600, lr = 0.00814508
I1028 20:46:15.604609 29475 solver.cpp:222] Iteration 14640 (1.30266 iter/s, 30.7063s/40 iters), loss = 1.49989
I1028 20:46:15.604785 29475 solver.cpp:241]     Train net output #0: loss = 1.49989 (* 1 = 1.49989 loss)
I1028 20:46:15.604804 29475 sgd_solver.cpp:105] Iteration 14640, lr = 0.00814012
I1028 20:46:46.486116 29475 solver.cpp:222] Iteration 14680 (1.29533 iter/s, 30.8802s/40 iters), loss = 2.0415
I1028 20:46:46.486289 29475 solver.cpp:241]     Train net output #0: loss = 2.0415 (* 1 = 2.0415 loss)
I1028 20:46:46.486310 29475 sgd_solver.cpp:105] Iteration 14680, lr = 0.00813516
I1028 20:47:17.399314 29475 solver.cpp:222] Iteration 14720 (1.29401 iter/s, 30.9118s/40 iters), loss = 1.85092
I1028 20:47:17.399513 29475 solver.cpp:241]     Train net output #0: loss = 1.85092 (* 1 = 1.85092 loss)
I1028 20:47:17.399531 29475 sgd_solver.cpp:105] Iteration 14720, lr = 0.0081302
I1028 20:47:48.119606 29475 solver.cpp:222] Iteration 14760 (1.30213 iter/s, 30.7189s/40 iters), loss = 1.89913
I1028 20:47:48.119796 29475 solver.cpp:241]     Train net output #0: loss = 1.89913 (* 1 = 1.89913 loss)
I1028 20:47:48.119813 29475 sgd_solver.cpp:105] Iteration 14760, lr = 0.00812524
I1028 20:48:18.686527 29475 solver.cpp:222] Iteration 14800 (1.30866 iter/s, 30.5656s/40 iters), loss = 1.83539
I1028 20:48:18.686753 29475 solver.cpp:241]     Train net output #0: loss = 1.83539 (* 1 = 1.83539 loss)
I1028 20:48:18.686784 29475 sgd_solver.cpp:105] Iteration 14800, lr = 0.00812029
I1028 20:48:49.568974 29475 solver.cpp:222] Iteration 14840 (1.29529 iter/s, 30.8811s/40 iters), loss = 1.95565
I1028 20:48:49.569150 29475 solver.cpp:241]     Train net output #0: loss = 1.95565 (* 1 = 1.95565 loss)
I1028 20:48:49.569166 29475 sgd_solver.cpp:105] Iteration 14840, lr = 0.00811533
I1028 20:49:20.109769 29475 solver.cpp:222] Iteration 14880 (1.30978 iter/s, 30.5395s/40 iters), loss = 1.90626
I1028 20:49:20.109951 29475 solver.cpp:241]     Train net output #0: loss = 1.90626 (* 1 = 1.90626 loss)
I1028 20:49:20.109966 29475 sgd_solver.cpp:105] Iteration 14880, lr = 0.00811038
I1028 20:49:50.980820 29475 solver.cpp:222] Iteration 14920 (1.29577 iter/s, 30.8697s/40 iters), loss = 1.46734
I1028 20:49:50.981007 29475 solver.cpp:241]     Train net output #0: loss = 1.46734 (* 1 = 1.46734 loss)
I1028 20:49:50.981027 29475 sgd_solver.cpp:105] Iteration 14920, lr = 0.00810542
I1028 20:50:22.147589 29475 solver.cpp:222] Iteration 14960 (1.28347 iter/s, 31.1654s/40 iters), loss = 1.32683
I1028 20:50:22.147795 29475 solver.cpp:241]     Train net output #0: loss = 1.32683 (* 1 = 1.32683 loss)
I1028 20:50:22.147812 29475 sgd_solver.cpp:105] Iteration 14960, lr = 0.00810047
I1028 20:50:52.260345 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_15000.caffemodel
I1028 20:50:52.296573 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_15000.solverstate
I1028 20:50:52.315142 29475 solver.cpp:334] Iteration 15000, Testing net (#0)
I1028 20:51:23.422488 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53412
I1028 20:51:23.422677 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.775159
I1028 20:51:23.422693 29475 solver.cpp:401]     Test net output #2: loss = 2.06649 (* 1 = 2.06649 loss)
I1028 20:51:24.193550 29475 solver.cpp:222] Iteration 15000 (0.64471 iter/s, 62.0434s/40 iters), loss = 1.59945
I1028 20:51:24.193616 29475 solver.cpp:241]     Train net output #0: loss = 1.59945 (* 1 = 1.59945 loss)
I1028 20:51:24.193632 29475 sgd_solver.cpp:105] Iteration 15000, lr = 0.00809552
I1028 20:51:31.185987 29523 data_layer.cpp:73] Restarting data prefetching from start.
I1028 20:51:55.032821 29475 solver.cpp:222] Iteration 15040 (1.2971 iter/s, 30.838s/40 iters), loss = 1.48214
I1028 20:51:55.033010 29475 solver.cpp:241]     Train net output #0: loss = 1.48214 (* 1 = 1.48214 loss)
I1028 20:51:55.033026 29475 sgd_solver.cpp:105] Iteration 15040, lr = 0.00809056
I1028 20:52:25.779763 29475 solver.cpp:222] Iteration 15080 (1.301 iter/s, 30.7456s/40 iters), loss = 1.67833
I1028 20:52:25.779950 29475 solver.cpp:241]     Train net output #0: loss = 1.67833 (* 1 = 1.67833 loss)
I1028 20:52:25.779968 29475 sgd_solver.cpp:105] Iteration 15080, lr = 0.00808561
I1028 20:52:56.564594 29475 solver.cpp:222] Iteration 15120 (1.2994 iter/s, 30.7835s/40 iters), loss = 1.74153
I1028 20:52:56.564781 29475 solver.cpp:241]     Train net output #0: loss = 1.74153 (* 1 = 1.74153 loss)
I1028 20:52:56.564800 29475 sgd_solver.cpp:105] Iteration 15120, lr = 0.00808066
I1028 20:53:27.567517 29475 solver.cpp:222] Iteration 15160 (1.29026 iter/s, 31.0016s/40 iters), loss = 1.69495
I1028 20:53:27.567677 29475 solver.cpp:241]     Train net output #0: loss = 1.69495 (* 1 = 1.69495 loss)
I1028 20:53:27.567694 29475 sgd_solver.cpp:105] Iteration 15160, lr = 0.00807571
I1028 20:53:58.826990 29475 solver.cpp:222] Iteration 15200 (1.27967 iter/s, 31.2581s/40 iters), loss = 1.65749
I1028 20:53:58.827184 29475 solver.cpp:241]     Train net output #0: loss = 1.65749 (* 1 = 1.65749 loss)
I1028 20:53:58.827203 29475 sgd_solver.cpp:105] Iteration 15200, lr = 0.00807076
I1028 20:54:30.202782 29475 solver.cpp:222] Iteration 15240 (1.27492 iter/s, 31.3744s/40 iters), loss = 1.60388
I1028 20:54:30.203047 29475 solver.cpp:241]     Train net output #0: loss = 1.60388 (* 1 = 1.60388 loss)
I1028 20:54:30.203099 29475 sgd_solver.cpp:105] Iteration 15240, lr = 0.00806581
I1028 20:55:01.449601 29475 solver.cpp:222] Iteration 15280 (1.28019 iter/s, 31.2454s/40 iters), loss = 2.15844
I1028 20:55:01.449777 29475 solver.cpp:241]     Train net output #0: loss = 2.15844 (* 1 = 2.15844 loss)
I1028 20:55:01.449796 29475 sgd_solver.cpp:105] Iteration 15280, lr = 0.00806087
I1028 20:55:32.442797 29475 solver.cpp:222] Iteration 15320 (1.29066 iter/s, 30.9918s/40 iters), loss = 1.80097
I1028 20:55:32.442986 29475 solver.cpp:241]     Train net output #0: loss = 1.80097 (* 1 = 1.80097 loss)
I1028 20:55:32.443003 29475 sgd_solver.cpp:105] Iteration 15320, lr = 0.00805592
I1028 20:56:03.298615 29475 solver.cpp:222] Iteration 15360 (1.29641 iter/s, 30.8545s/40 iters), loss = 1.85
I1028 20:56:03.298804 29475 solver.cpp:241]     Train net output #0: loss = 1.85 (* 1 = 1.85 loss)
I1028 20:56:03.298821 29475 sgd_solver.cpp:105] Iteration 15360, lr = 0.00805097
I1028 20:56:34.775607 29475 solver.cpp:222] Iteration 15400 (1.27083 iter/s, 31.4756s/40 iters), loss = 1.59433
I1028 20:56:34.775794 29475 solver.cpp:241]     Train net output #0: loss = 1.59433 (* 1 = 1.59433 loss)
I1028 20:56:34.775815 29475 sgd_solver.cpp:105] Iteration 15400, lr = 0.00804603
I1028 20:57:05.859019 29475 solver.cpp:222] Iteration 15440 (1.28692 iter/s, 31.082s/40 iters), loss = 1.48522
I1028 20:57:05.859212 29475 solver.cpp:241]     Train net output #0: loss = 1.48522 (* 1 = 1.48522 loss)
I1028 20:57:05.859230 29475 sgd_solver.cpp:105] Iteration 15440, lr = 0.00804108
I1028 20:57:36.820997 29475 solver.cpp:222] Iteration 15480 (1.29196 iter/s, 30.9606s/40 iters), loss = 1.71717
I1028 20:57:36.821208 29475 solver.cpp:241]     Train net output #0: loss = 1.71717 (* 1 = 1.71717 loss)
I1028 20:57:36.821230 29475 sgd_solver.cpp:105] Iteration 15480, lr = 0.00803614
I1028 20:57:51.523964 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_15500.caffemodel
I1028 20:57:51.559689 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_15500.solverstate
I1028 20:57:51.577862 29475 solver.cpp:334] Iteration 15500, Testing net (#0)
I1028 20:58:22.776446 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 20:58:22.986413 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53612
I1028 20:58:22.986475 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.778399
I1028 20:58:22.986488 29475 solver.cpp:401]     Test net output #2: loss = 2.04722 (* 1 = 2.04722 loss)
I1028 20:58:39.322486 29475 solver.cpp:222] Iteration 15520 (0.640011 iter/s, 62.4989s/40 iters), loss = 1.6382
I1028 20:58:39.322556 29475 solver.cpp:241]     Train net output #0: loss = 1.6382 (* 1 = 1.6382 loss)
I1028 20:58:39.322572 29475 sgd_solver.cpp:105] Iteration 15520, lr = 0.00803119
I1028 20:59:10.701642 29475 solver.cpp:222] Iteration 15560 (1.27478 iter/s, 31.3779s/40 iters), loss = 1.71024
I1028 20:59:10.701843 29475 solver.cpp:241]     Train net output #0: loss = 1.71024 (* 1 = 1.71024 loss)
I1028 20:59:10.701860 29475 sgd_solver.cpp:105] Iteration 15560, lr = 0.00802625
I1028 20:59:42.449056 29475 solver.cpp:222] Iteration 15600 (1.26 iter/s, 31.7459s/40 iters), loss = 1.6376
I1028 20:59:42.449244 29475 solver.cpp:241]     Train net output #0: loss = 1.6376 (* 1 = 1.6376 loss)
I1028 20:59:42.449261 29475 sgd_solver.cpp:105] Iteration 15600, lr = 0.00802131
I1028 21:00:13.689411 29475 solver.cpp:222] Iteration 15640 (1.28045 iter/s, 31.239s/40 iters), loss = 1.99827
I1028 21:00:13.689596 29475 solver.cpp:241]     Train net output #0: loss = 1.99827 (* 1 = 1.99827 loss)
I1028 21:00:13.689613 29475 sgd_solver.cpp:105] Iteration 15640, lr = 0.00801637
I1028 21:00:44.981057 29475 solver.cpp:222] Iteration 15680 (1.27835 iter/s, 31.2903s/40 iters), loss = 1.73378
I1028 21:00:44.981245 29475 solver.cpp:241]     Train net output #0: loss = 1.73378 (* 1 = 1.73378 loss)
I1028 21:00:44.981261 29475 sgd_solver.cpp:105] Iteration 15680, lr = 0.00801142
I1028 21:01:16.188278 29475 solver.cpp:222] Iteration 15720 (1.28181 iter/s, 31.2058s/40 iters), loss = 1.86563
I1028 21:01:16.188597 29475 solver.cpp:241]     Train net output #0: loss = 1.86563 (* 1 = 1.86563 loss)
I1028 21:01:16.188633 29475 sgd_solver.cpp:105] Iteration 15720, lr = 0.00800649
I1028 21:01:47.391378 29475 solver.cpp:222] Iteration 15760 (1.28198 iter/s, 31.2016s/40 iters), loss = 1.73323
I1028 21:01:47.391582 29475 solver.cpp:241]     Train net output #0: loss = 1.73323 (* 1 = 1.73323 loss)
I1028 21:01:47.391602 29475 sgd_solver.cpp:105] Iteration 15760, lr = 0.00800155
I1028 21:02:18.495784 29475 solver.cpp:222] Iteration 15800 (1.28605 iter/s, 31.103s/40 iters), loss = 1.91458
I1028 21:02:18.496073 29475 solver.cpp:241]     Train net output #0: loss = 1.91458 (* 1 = 1.91458 loss)
I1028 21:02:18.496100 29475 sgd_solver.cpp:105] Iteration 15800, lr = 0.00799661
I1028 21:02:49.814540 29475 solver.cpp:222] Iteration 15840 (1.27725 iter/s, 31.3173s/40 iters), loss = 1.55066
I1028 21:02:49.814769 29475 solver.cpp:241]     Train net output #0: loss = 1.55066 (* 1 = 1.55066 loss)
I1028 21:02:49.814787 29475 sgd_solver.cpp:105] Iteration 15840, lr = 0.00799167
I1028 21:03:21.944005 29475 solver.cpp:222] Iteration 15880 (1.24502 iter/s, 32.128s/40 iters), loss = 1.61762
I1028 21:03:21.944243 29475 solver.cpp:241]     Train net output #0: loss = 1.61762 (* 1 = 1.61762 loss)
I1028 21:03:21.944267 29475 sgd_solver.cpp:105] Iteration 15880, lr = 0.00798673
I1028 21:04:18.635385 29475 solver.cpp:222] Iteration 15920 (0.705604 iter/s, 56.689s/40 iters), loss = 1.82735
I1028 21:04:18.635609 29475 solver.cpp:241]     Train net output #0: loss = 1.82735 (* 1 = 1.82735 loss)
I1028 21:04:18.635627 29475 sgd_solver.cpp:105] Iteration 15920, lr = 0.00798179
I1028 21:04:49.601713 29475 solver.cpp:222] Iteration 15960 (1.29178 iter/s, 30.9649s/40 iters), loss = 1.59066
I1028 21:04:49.601903 29475 solver.cpp:241]     Train net output #0: loss = 1.59066 (* 1 = 1.59066 loss)
I1028 21:04:49.601922 29475 sgd_solver.cpp:105] Iteration 15960, lr = 0.00797686
I1028 21:05:20.656069 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_16000.caffemodel
I1028 21:05:20.702225 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_16000.solverstate
I1028 21:05:20.725076 29475 solver.cpp:334] Iteration 16000, Testing net (#0)
I1028 21:05:52.001889 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54264
I1028 21:05:52.002068 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7794
I1028 21:05:52.002082 29475 solver.cpp:401]     Test net output #2: loss = 2.07103 (* 1 = 2.07103 loss)
I1028 21:05:52.778369 29475 solver.cpp:222] Iteration 16000 (0.633171 iter/s, 63.1741s/40 iters), loss = 1.73482
I1028 21:05:52.778445 29475 solver.cpp:241]     Train net output #0: loss = 1.73482 (* 1 = 1.73482 loss)
I1028 21:05:52.778462 29475 sgd_solver.cpp:105] Iteration 16000, lr = 0.00797192
I1028 21:06:24.126847 29475 solver.cpp:222] Iteration 16040 (1.27603 iter/s, 31.3471s/40 iters), loss = 1.90352
I1028 21:06:24.127048 29475 solver.cpp:241]     Train net output #0: loss = 1.90352 (* 1 = 1.90352 loss)
I1028 21:06:24.127074 29475 sgd_solver.cpp:105] Iteration 16040, lr = 0.00796699
I1028 21:06:55.238785 29475 solver.cpp:222] Iteration 16080 (1.28574 iter/s, 31.1106s/40 iters), loss = 1.66784
I1028 21:06:55.238972 29475 solver.cpp:241]     Train net output #0: loss = 1.66784 (* 1 = 1.66784 loss)
I1028 21:06:55.238989 29475 sgd_solver.cpp:105] Iteration 16080, lr = 0.00796205
I1028 21:07:26.435943 29475 solver.cpp:222] Iteration 16120 (1.28222 iter/s, 31.1958s/40 iters), loss = 1.83006
I1028 21:07:26.436146 29475 solver.cpp:241]     Train net output #0: loss = 1.83006 (* 1 = 1.83006 loss)
I1028 21:07:26.436166 29475 sgd_solver.cpp:105] Iteration 16120, lr = 0.00795712
I1028 21:07:57.860870 29475 solver.cpp:222] Iteration 16160 (1.27293 iter/s, 31.4235s/40 iters), loss = 1.62712
I1028 21:07:57.861120 29475 solver.cpp:241]     Train net output #0: loss = 1.62712 (* 1 = 1.62712 loss)
I1028 21:07:57.861152 29475 sgd_solver.cpp:105] Iteration 16160, lr = 0.00795219
I1028 21:08:28.832523 29475 solver.cpp:222] Iteration 16200 (1.29156 iter/s, 30.9702s/40 iters), loss = 1.63353
I1028 21:08:28.832726 29475 solver.cpp:241]     Train net output #0: loss = 1.63353 (* 1 = 1.63353 loss)
I1028 21:08:28.832743 29475 sgd_solver.cpp:105] Iteration 16200, lr = 0.00794726
I1028 21:09:00.008714 29475 solver.cpp:222] Iteration 16240 (1.28309 iter/s, 31.1748s/40 iters), loss = 1.59503
I1028 21:09:00.008909 29475 solver.cpp:241]     Train net output #0: loss = 1.59503 (* 1 = 1.59503 loss)
I1028 21:09:00.008926 29475 sgd_solver.cpp:105] Iteration 16240, lr = 0.00794233
I1028 21:09:31.426409 29475 solver.cpp:222] Iteration 16280 (1.27323 iter/s, 31.4162s/40 iters), loss = 1.70195
I1028 21:09:31.426592 29475 solver.cpp:241]     Train net output #0: loss = 1.70195 (* 1 = 1.70195 loss)
I1028 21:09:31.426610 29475 sgd_solver.cpp:105] Iteration 16280, lr = 0.0079374
I1028 21:10:02.728108 29475 solver.cpp:222] Iteration 16320 (1.27794 iter/s, 31.3003s/40 iters), loss = 1.65204
I1028 21:10:02.728312 29475 solver.cpp:241]     Train net output #0: loss = 1.65204 (* 1 = 1.65204 loss)
I1028 21:10:02.728330 29475 sgd_solver.cpp:105] Iteration 16320, lr = 0.00793246
I1028 21:10:33.805718 29475 solver.cpp:222] Iteration 16360 (1.28716 iter/s, 31.0762s/40 iters), loss = 1.80239
I1028 21:10:33.805896 29475 solver.cpp:241]     Train net output #0: loss = 1.80239 (* 1 = 1.80239 loss)
I1028 21:10:33.805915 29475 sgd_solver.cpp:105] Iteration 16360, lr = 0.00792754
I1028 21:11:05.316285 29475 solver.cpp:222] Iteration 16400 (1.26947 iter/s, 31.5092s/40 iters), loss = 1.7737
I1028 21:11:05.316501 29475 solver.cpp:241]     Train net output #0: loss = 1.7737 (* 1 = 1.7737 loss)
I1028 21:11:05.316519 29475 sgd_solver.cpp:105] Iteration 16400, lr = 0.00792261
I1028 21:11:36.147645 29475 solver.cpp:222] Iteration 16440 (1.29744 iter/s, 30.83s/40 iters), loss = 1.8186
I1028 21:11:36.147835 29475 solver.cpp:241]     Train net output #0: loss = 1.8186 (* 1 = 1.8186 loss)
I1028 21:11:36.147852 29475 sgd_solver.cpp:105] Iteration 16440, lr = 0.00791768
I1028 21:12:07.897505 29475 solver.cpp:222] Iteration 16480 (1.25991 iter/s, 31.7484s/40 iters), loss = 1.70465
I1028 21:12:07.897696 29475 solver.cpp:241]     Train net output #0: loss = 1.70465 (* 1 = 1.70465 loss)
I1028 21:12:07.897713 29475 sgd_solver.cpp:105] Iteration 16480, lr = 0.00791275
I1028 21:12:22.525187 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_16500.caffemodel
I1028 21:12:22.559970 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_16500.solverstate
I1028 21:12:22.578291 29475 solver.cpp:334] Iteration 16500, Testing net (#0)
I1028 21:12:53.503365 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 21:12:53.712739 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5374
I1028 21:12:53.712800 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77932
I1028 21:12:53.712815 29475 solver.cpp:401]     Test net output #2: loss = 2.0527 (* 1 = 2.0527 loss)
I1028 21:13:09.814275 29475 solver.cpp:222] Iteration 16520 (0.646055 iter/s, 61.9143s/40 iters), loss = 1.88149
I1028 21:13:09.814354 29475 solver.cpp:241]     Train net output #0: loss = 1.88149 (* 1 = 1.88149 loss)
I1028 21:13:09.814373 29475 sgd_solver.cpp:105] Iteration 16520, lr = 0.00790783
I1028 21:13:40.626147 29475 solver.cpp:222] Iteration 16560 (1.29825 iter/s, 30.8106s/40 iters), loss = 1.56503
I1028 21:13:40.626361 29475 solver.cpp:241]     Train net output #0: loss = 1.56503 (* 1 = 1.56503 loss)
I1028 21:13:40.626379 29475 sgd_solver.cpp:105] Iteration 16560, lr = 0.0079029
I1028 21:14:11.336592 29475 solver.cpp:222] Iteration 16600 (1.30255 iter/s, 30.7091s/40 iters), loss = 1.96445
I1028 21:14:11.336846 29475 solver.cpp:241]     Train net output #0: loss = 1.96445 (* 1 = 1.96445 loss)
I1028 21:14:11.336874 29475 sgd_solver.cpp:105] Iteration 16600, lr = 0.00789798
I1028 21:14:42.389402 29475 solver.cpp:222] Iteration 16640 (1.28819 iter/s, 31.0513s/40 iters), loss = 1.94709
I1028 21:14:42.389789 29475 solver.cpp:241]     Train net output #0: loss = 1.94709 (* 1 = 1.94709 loss)
I1028 21:14:42.391317 29475 sgd_solver.cpp:105] Iteration 16640, lr = 0.00789305
I1028 21:15:13.318756 29475 solver.cpp:222] Iteration 16680 (1.29334 iter/s, 30.9278s/40 iters), loss = 1.5975
I1028 21:15:13.318944 29475 solver.cpp:241]     Train net output #0: loss = 1.5975 (* 1 = 1.5975 loss)
I1028 21:15:13.318963 29475 sgd_solver.cpp:105] Iteration 16680, lr = 0.00788813
I1028 21:15:44.114930 29475 solver.cpp:222] Iteration 16720 (1.29892 iter/s, 30.7948s/40 iters), loss = 1.86848
I1028 21:15:44.115116 29475 solver.cpp:241]     Train net output #0: loss = 1.86848 (* 1 = 1.86848 loss)
I1028 21:15:44.115133 29475 sgd_solver.cpp:105] Iteration 16720, lr = 0.00788321
I1028 21:16:14.904834 29475 solver.cpp:222] Iteration 16760 (1.29919 iter/s, 30.7885s/40 iters), loss = 1.53074
I1028 21:16:14.905014 29475 solver.cpp:241]     Train net output #0: loss = 1.53074 (* 1 = 1.53074 loss)
I1028 21:16:14.905030 29475 sgd_solver.cpp:105] Iteration 16760, lr = 0.00787828
I1028 21:16:45.613458 29475 solver.cpp:222] Iteration 16800 (1.30263 iter/s, 30.7072s/40 iters), loss = 1.77847
I1028 21:16:45.613647 29475 solver.cpp:241]     Train net output #0: loss = 1.77847 (* 1 = 1.77847 loss)
I1028 21:16:45.613667 29475 sgd_solver.cpp:105] Iteration 16800, lr = 0.00787336
I1028 21:17:20.228154 29475 solver.cpp:222] Iteration 16840 (1.15563 iter/s, 34.6132s/40 iters), loss = 1.7117
I1028 21:17:20.228381 29475 solver.cpp:241]     Train net output #0: loss = 1.7117 (* 1 = 1.7117 loss)
I1028 21:17:20.228399 29475 sgd_solver.cpp:105] Iteration 16840, lr = 0.00786844
I1028 21:17:51.427729 29475 solver.cpp:222] Iteration 16880 (1.28213 iter/s, 31.198s/40 iters), loss = 1.51433
I1028 21:17:51.427949 29475 solver.cpp:241]     Train net output #0: loss = 1.51433 (* 1 = 1.51433 loss)
I1028 21:17:51.427978 29475 sgd_solver.cpp:105] Iteration 16880, lr = 0.00786352
I1028 21:18:22.924753 29475 solver.cpp:222] Iteration 16920 (1.27002 iter/s, 31.4955s/40 iters), loss = 1.89256
I1028 21:18:22.924957 29475 solver.cpp:241]     Train net output #0: loss = 1.89256 (* 1 = 1.89256 loss)
I1028 21:18:22.924974 29475 sgd_solver.cpp:105] Iteration 16920, lr = 0.0078586
I1028 21:18:54.358438 29475 solver.cpp:222] Iteration 16960 (1.27258 iter/s, 31.4321s/40 iters), loss = 1.75204
I1028 21:18:54.358681 29475 solver.cpp:241]     Train net output #0: loss = 1.75204 (* 1 = 1.75204 loss)
I1028 21:18:54.358711 29475 sgd_solver.cpp:105] Iteration 16960, lr = 0.00785369
I1028 21:19:24.342002 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_17000.caffemodel
I1028 21:19:24.376951 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_17000.solverstate
I1028 21:19:24.393741 29475 solver.cpp:334] Iteration 17000, Testing net (#0)
I1028 21:19:55.507314 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54372
I1028 21:19:55.507479 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78344
I1028 21:19:55.507495 29475 solver.cpp:401]     Test net output #2: loss = 2.01483 (* 1 = 2.01483 loss)
I1028 21:19:56.282964 29475 solver.cpp:222] Iteration 17000 (0.645974 iter/s, 61.922s/40 iters), loss = 1.77139
I1028 21:19:56.283035 29475 solver.cpp:241]     Train net output #0: loss = 1.77139 (* 1 = 1.77139 loss)
I1028 21:19:56.283051 29475 sgd_solver.cpp:105] Iteration 17000, lr = 0.00784877
I1028 21:20:27.304924 29475 solver.cpp:222] Iteration 17040 (1.28946 iter/s, 31.0207s/40 iters), loss = 1.94787
I1028 21:20:27.305120 29475 solver.cpp:241]     Train net output #0: loss = 1.94787 (* 1 = 1.94787 loss)
I1028 21:20:27.305138 29475 sgd_solver.cpp:105] Iteration 17040, lr = 0.00784385
I1028 21:20:58.046707 29475 solver.cpp:222] Iteration 17080 (1.30122 iter/s, 30.7403s/40 iters), loss = 1.80067
I1028 21:20:58.046942 29475 solver.cpp:241]     Train net output #0: loss = 1.80067 (* 1 = 1.80067 loss)
I1028 21:20:58.046962 29475 sgd_solver.cpp:105] Iteration 17080, lr = 0.00783894
I1028 21:21:28.913586 29475 solver.cpp:222] Iteration 17120 (1.29595 iter/s, 30.8655s/40 iters), loss = 1.79868
I1028 21:21:28.913789 29475 solver.cpp:241]     Train net output #0: loss = 1.79868 (* 1 = 1.79868 loss)
I1028 21:21:28.913805 29475 sgd_solver.cpp:105] Iteration 17120, lr = 0.00783402
I1028 21:22:00.209041 29475 solver.cpp:222] Iteration 17160 (1.2782 iter/s, 31.294s/40 iters), loss = 1.64081
I1028 21:22:00.209261 29475 solver.cpp:241]     Train net output #0: loss = 1.64081 (* 1 = 1.64081 loss)
I1028 21:22:00.209280 29475 sgd_solver.cpp:105] Iteration 17160, lr = 0.00782911
I1028 21:22:31.903631 29475 solver.cpp:222] Iteration 17200 (1.2621 iter/s, 31.6932s/40 iters), loss = 1.48378
I1028 21:22:31.903834 29475 solver.cpp:241]     Train net output #0: loss = 1.48378 (* 1 = 1.48378 loss)
I1028 21:22:31.903856 29475 sgd_solver.cpp:105] Iteration 17200, lr = 0.00782419
I1028 21:23:03.052237 29475 solver.cpp:222] Iteration 17240 (1.28422 iter/s, 31.1472s/40 iters), loss = 1.87301
I1028 21:23:03.052424 29475 solver.cpp:241]     Train net output #0: loss = 1.87301 (* 1 = 1.87301 loss)
I1028 21:23:03.052440 29475 sgd_solver.cpp:105] Iteration 17240, lr = 0.00781928
I1028 21:23:33.775805 29475 solver.cpp:222] Iteration 17280 (1.30199 iter/s, 30.7221s/40 iters), loss = 1.44756
I1028 21:23:33.775966 29475 solver.cpp:241]     Train net output #0: loss = 1.44756 (* 1 = 1.44756 loss)
I1028 21:23:33.775985 29475 sgd_solver.cpp:105] Iteration 17280, lr = 0.00781436
I1028 21:24:04.997480 29475 solver.cpp:222] Iteration 17320 (1.28122 iter/s, 31.2203s/40 iters), loss = 1.61156
I1028 21:24:04.997704 29475 solver.cpp:241]     Train net output #0: loss = 1.61156 (* 1 = 1.61156 loss)
I1028 21:24:04.997721 29475 sgd_solver.cpp:105] Iteration 17320, lr = 0.00780945
I1028 21:24:35.982667 29475 solver.cpp:222] Iteration 17360 (1.291 iter/s, 30.9837s/40 iters), loss = 1.62992
I1028 21:24:35.982846 29475 solver.cpp:241]     Train net output #0: loss = 1.62992 (* 1 = 1.62992 loss)
I1028 21:24:35.982864 29475 sgd_solver.cpp:105] Iteration 17360, lr = 0.00780454
I1028 21:25:07.776947 29475 solver.cpp:222] Iteration 17400 (1.25814 iter/s, 31.7929s/40 iters), loss = 1.83064
I1028 21:25:07.777132 29475 solver.cpp:241]     Train net output #0: loss = 1.83064 (* 1 = 1.83064 loss)
I1028 21:25:07.777149 29475 sgd_solver.cpp:105] Iteration 17400, lr = 0.00779963
I1028 21:25:40.475332 29475 solver.cpp:222] Iteration 17440 (1.22336 iter/s, 32.697s/40 iters), loss = 1.70333
I1028 21:25:40.475531 29475 solver.cpp:241]     Train net output #0: loss = 1.70333 (* 1 = 1.70333 loss)
I1028 21:25:40.475549 29475 sgd_solver.cpp:105] Iteration 17440, lr = 0.00779472
I1028 21:26:12.619487 29475 solver.cpp:222] Iteration 17480 (1.24445 iter/s, 32.1427s/40 iters), loss = 1.85466
I1028 21:26:12.619725 29475 solver.cpp:241]     Train net output #0: loss = 1.85466 (* 1 = 1.85466 loss)
I1028 21:26:12.619748 29475 sgd_solver.cpp:105] Iteration 17480, lr = 0.00778981
I1028 21:26:28.054488 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_17500.caffemodel
I1028 21:26:28.090324 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_17500.solverstate
I1028 21:26:28.108250 29475 solver.cpp:334] Iteration 17500, Testing net (#0)
I1028 21:26:59.020825 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 21:26:59.228019 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53672
I1028 21:26:59.228078 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.782
I1028 21:26:59.228091 29475 solver.cpp:401]     Test net output #2: loss = 2.04096 (* 1 = 2.04096 loss)
I1028 21:27:08.860002 29523 data_layer.cpp:73] Restarting data prefetching from start.
I1028 21:27:15.472990 29475 solver.cpp:222] Iteration 17520 (0.636427 iter/s, 62.8509s/40 iters), loss = 1.77129
I1028 21:27:15.473075 29475 solver.cpp:241]     Train net output #0: loss = 1.77129 (* 1 = 1.77129 loss)
I1028 21:27:15.473091 29475 sgd_solver.cpp:105] Iteration 17520, lr = 0.0077849
I1028 21:27:46.474186 29475 solver.cpp:222] Iteration 17560 (1.29033 iter/s, 30.9999s/40 iters), loss = 2.11695
I1028 21:27:46.474440 29475 solver.cpp:241]     Train net output #0: loss = 2.11695 (* 1 = 2.11695 loss)
I1028 21:27:46.474462 29475 sgd_solver.cpp:105] Iteration 17560, lr = 0.00778
I1028 21:28:18.292870 29475 solver.cpp:222] Iteration 17600 (1.25718 iter/s, 31.8172s/40 iters), loss = 1.55647
I1028 21:28:18.293085 29475 solver.cpp:241]     Train net output #0: loss = 1.55647 (* 1 = 1.55647 loss)
I1028 21:28:18.293104 29475 sgd_solver.cpp:105] Iteration 17600, lr = 0.00777509
I1028 21:28:49.573029 29475 solver.cpp:222] Iteration 17640 (1.27882 iter/s, 31.2787s/40 iters), loss = 1.72175
I1028 21:28:49.573274 29475 solver.cpp:241]     Train net output #0: loss = 1.72175 (* 1 = 1.72175 loss)
I1028 21:28:49.573307 29475 sgd_solver.cpp:105] Iteration 17640, lr = 0.00777018
I1028 21:29:20.966056 29475 solver.cpp:222] Iteration 17680 (1.27423 iter/s, 31.3916s/40 iters), loss = 1.97335
I1028 21:29:20.966264 29475 solver.cpp:241]     Train net output #0: loss = 1.97335 (* 1 = 1.97335 loss)
I1028 21:29:20.966281 29475 sgd_solver.cpp:105] Iteration 17680, lr = 0.00776528
I1028 21:29:52.071012 29475 solver.cpp:222] Iteration 17720 (1.28603 iter/s, 31.1036s/40 iters), loss = 1.65076
I1028 21:29:52.071202 29475 solver.cpp:241]     Train net output #0: loss = 1.65076 (* 1 = 1.65076 loss)
I1028 21:29:52.071219 29475 sgd_solver.cpp:105] Iteration 17720, lr = 0.00776037
I1028 21:30:22.912325 29475 solver.cpp:222] Iteration 17760 (1.29702 iter/s, 30.8399s/40 iters), loss = 2.15002
I1028 21:30:22.912513 29475 solver.cpp:241]     Train net output #0: loss = 2.15002 (* 1 = 2.15002 loss)
I1028 21:30:22.912536 29475 sgd_solver.cpp:105] Iteration 17760, lr = 0.00775547
I1028 21:30:54.362874 29475 solver.cpp:222] Iteration 17800 (1.27189 iter/s, 31.4492s/40 iters), loss = 1.36826
I1028 21:30:54.363051 29475 solver.cpp:241]     Train net output #0: loss = 1.36826 (* 1 = 1.36826 loss)
I1028 21:30:54.363068 29475 sgd_solver.cpp:105] Iteration 17800, lr = 0.00775057
I1028 21:31:25.231101 29475 solver.cpp:222] Iteration 17840 (1.29589 iter/s, 30.8669s/40 iters), loss = 1.80097
I1028 21:31:25.231319 29475 solver.cpp:241]     Train net output #0: loss = 1.80097 (* 1 = 1.80097 loss)
I1028 21:31:25.231338 29475 sgd_solver.cpp:105] Iteration 17840, lr = 0.00774566
I1028 21:31:56.088534 29475 solver.cpp:222] Iteration 17880 (1.29634 iter/s, 30.856s/40 iters), loss = 1.65825
I1028 21:31:56.088732 29475 solver.cpp:241]     Train net output #0: loss = 1.65825 (* 1 = 1.65825 loss)
I1028 21:31:56.088749 29475 sgd_solver.cpp:105] Iteration 17880, lr = 0.00774076
I1028 21:32:26.815387 29475 solver.cpp:222] Iteration 17920 (1.30185 iter/s, 30.7255s/40 iters), loss = 1.5037
I1028 21:32:26.815563 29475 solver.cpp:241]     Train net output #0: loss = 1.5037 (* 1 = 1.5037 loss)
I1028 21:32:26.815584 29475 sgd_solver.cpp:105] Iteration 17920, lr = 0.00773586
I1028 21:32:58.440277 29475 solver.cpp:222] Iteration 17960 (1.26488 iter/s, 31.6235s/40 iters), loss = 1.9687
I1028 21:32:58.440451 29475 solver.cpp:241]     Train net output #0: loss = 1.9687 (* 1 = 1.9687 loss)
I1028 21:32:58.440471 29475 sgd_solver.cpp:105] Iteration 17960, lr = 0.00773096
I1028 21:33:29.045424 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_18000.caffemodel
I1028 21:33:29.080042 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_18000.solverstate
I1028 21:33:29.096756 29475 solver.cpp:334] Iteration 18000, Testing net (#0)
I1028 21:34:00.211726 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54228
I1028 21:34:00.211962 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77976
I1028 21:34:00.211978 29475 solver.cpp:401]     Test net output #2: loss = 2.03166 (* 1 = 2.03166 loss)
I1028 21:34:00.985483 29475 solver.cpp:222] Iteration 18000 (0.639563 iter/s, 62.5427s/40 iters), loss = 1.71178
I1028 21:34:00.985549 29475 solver.cpp:241]     Train net output #0: loss = 1.71178 (* 1 = 1.71178 loss)
I1028 21:34:00.985564 29475 sgd_solver.cpp:105] Iteration 18000, lr = 0.00772606
I1028 21:34:32.086171 29475 solver.cpp:222] Iteration 18040 (1.2862 iter/s, 31.0994s/40 iters), loss = 1.40035
I1028 21:34:32.086393 29475 solver.cpp:241]     Train net output #0: loss = 1.40035 (* 1 = 1.40035 loss)
I1028 21:34:32.086410 29475 sgd_solver.cpp:105] Iteration 18040, lr = 0.00772116
I1028 21:35:02.936882 29475 solver.cpp:222] Iteration 18080 (1.29663 iter/s, 30.8493s/40 iters), loss = 1.74553
I1028 21:35:02.937062 29475 solver.cpp:241]     Train net output #0: loss = 1.74553 (* 1 = 1.74553 loss)
I1028 21:35:02.937078 29475 sgd_solver.cpp:105] Iteration 18080, lr = 0.00771626
I1028 21:35:33.736816 29475 solver.cpp:222] Iteration 18120 (1.29876 iter/s, 30.7986s/40 iters), loss = 1.51889
I1028 21:35:33.737004 29475 solver.cpp:241]     Train net output #0: loss = 1.51889 (* 1 = 1.51889 loss)
I1028 21:35:33.737020 29475 sgd_solver.cpp:105] Iteration 18120, lr = 0.00771136
I1028 21:36:04.782510 29475 solver.cpp:222] Iteration 18160 (1.28848 iter/s, 31.0443s/40 iters), loss = 1.82676
I1028 21:36:04.782699 29475 solver.cpp:241]     Train net output #0: loss = 1.82676 (* 1 = 1.82676 loss)
I1028 21:36:04.782716 29475 sgd_solver.cpp:105] Iteration 18160, lr = 0.00770647
I1028 21:36:35.530701 29475 solver.cpp:222] Iteration 18200 (1.30095 iter/s, 30.7468s/40 iters), loss = 1.53964
I1028 21:36:35.530877 29475 solver.cpp:241]     Train net output #0: loss = 1.53964 (* 1 = 1.53964 loss)
I1028 21:36:35.530894 29475 sgd_solver.cpp:105] Iteration 18200, lr = 0.00770157
I1028 21:37:06.429256 29475 solver.cpp:222] Iteration 18240 (1.29462 iter/s, 30.8972s/40 iters), loss = 1.57271
I1028 21:37:06.429420 29475 solver.cpp:241]     Train net output #0: loss = 1.57271 (* 1 = 1.57271 loss)
I1028 21:37:06.429440 29475 sgd_solver.cpp:105] Iteration 18240, lr = 0.00769668
I1028 21:37:38.594506 29475 solver.cpp:222] Iteration 18280 (1.24363 iter/s, 32.1638s/40 iters), loss = 2.03841
I1028 21:37:38.594786 29475 solver.cpp:241]     Train net output #0: loss = 2.03841 (* 1 = 2.03841 loss)
I1028 21:37:38.594815 29475 sgd_solver.cpp:105] Iteration 18280, lr = 0.00769178
I1028 21:38:10.383288 29475 solver.cpp:222] Iteration 18320 (1.25836 iter/s, 31.7873s/40 iters), loss = 1.80664
I1028 21:38:10.383499 29475 solver.cpp:241]     Train net output #0: loss = 1.80664 (* 1 = 1.80664 loss)
I1028 21:38:10.383532 29475 sgd_solver.cpp:105] Iteration 18320, lr = 0.00768689
I1028 21:38:42.016091 29475 solver.cpp:222] Iteration 18360 (1.26457 iter/s, 31.6312s/40 iters), loss = 1.95901
I1028 21:38:42.016376 29475 solver.cpp:241]     Train net output #0: loss = 1.95901 (* 1 = 1.95901 loss)
I1028 21:38:42.016409 29475 sgd_solver.cpp:105] Iteration 18360, lr = 0.00768199
I1028 21:39:13.329152 29475 solver.cpp:222] Iteration 18400 (1.27748 iter/s, 31.3116s/40 iters), loss = 1.77056
I1028 21:39:13.329401 29475 solver.cpp:241]     Train net output #0: loss = 1.77056 (* 1 = 1.77056 loss)
I1028 21:39:13.329426 29475 sgd_solver.cpp:105] Iteration 18400, lr = 0.0076771
I1028 21:39:45.535050 29475 solver.cpp:222] Iteration 18440 (1.24207 iter/s, 32.2044s/40 iters), loss = 1.51471
I1028 21:39:45.535269 29475 solver.cpp:241]     Train net output #0: loss = 1.51471 (* 1 = 1.51471 loss)
I1028 21:39:45.535286 29475 sgd_solver.cpp:105] Iteration 18440, lr = 0.00767221
I1028 21:40:16.576798 29475 solver.cpp:222] Iteration 18480 (1.28865 iter/s, 31.0403s/40 iters), loss = 1.92235
I1028 21:40:16.577028 29475 solver.cpp:241]     Train net output #0: loss = 1.92235 (* 1 = 1.92235 loss)
I1028 21:40:16.577049 29475 sgd_solver.cpp:105] Iteration 18480, lr = 0.00766732
I1028 21:40:31.310204 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_18500.caffemodel
I1028 21:40:31.347872 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_18500.solverstate
I1028 21:40:31.370643 29475 solver.cpp:334] Iteration 18500, Testing net (#0)
I1028 21:41:02.393400 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 21:41:02.606989 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54428
I1028 21:41:02.607053 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78084
I1028 21:41:02.607066 29475 solver.cpp:401]     Test net output #2: loss = 2.05946 (* 1 = 2.05946 loss)
I1028 21:41:18.933440 29475 solver.cpp:222] Iteration 18520 (0.641498 iter/s, 62.3541s/40 iters), loss = 1.78989
I1028 21:41:18.933512 29475 solver.cpp:241]     Train net output #0: loss = 1.78989 (* 1 = 1.78989 loss)
I1028 21:41:18.933527 29475 sgd_solver.cpp:105] Iteration 18520, lr = 0.00766243
I1028 21:41:49.967012 29475 solver.cpp:222] Iteration 18560 (1.28898 iter/s, 31.0323s/40 iters), loss = 1.67914
I1028 21:41:49.967223 29475 solver.cpp:241]     Train net output #0: loss = 1.67914 (* 1 = 1.67914 loss)
I1028 21:41:49.967241 29475 sgd_solver.cpp:105] Iteration 18560, lr = 0.00765754
I1028 21:42:21.246683 29475 solver.cpp:222] Iteration 18600 (1.27884 iter/s, 31.2783s/40 iters), loss = 1.86412
I1028 21:42:21.246891 29475 solver.cpp:241]     Train net output #0: loss = 1.86412 (* 1 = 1.86412 loss)
I1028 21:42:21.246915 29475 sgd_solver.cpp:105] Iteration 18600, lr = 0.00765265
I1028 21:42:52.374112 29475 solver.cpp:222] Iteration 18640 (1.2851 iter/s, 31.126s/40 iters), loss = 1.66063
I1028 21:42:52.374291 29475 solver.cpp:241]     Train net output #0: loss = 1.66063 (* 1 = 1.66063 loss)
I1028 21:42:52.374315 29475 sgd_solver.cpp:105] Iteration 18640, lr = 0.00764776
I1028 21:43:23.593689 29475 solver.cpp:222] Iteration 18680 (1.2813 iter/s, 31.2182s/40 iters), loss = 1.96991
I1028 21:43:23.593935 29475 solver.cpp:241]     Train net output #0: loss = 1.96991 (* 1 = 1.96991 loss)
I1028 21:43:23.593951 29475 sgd_solver.cpp:105] Iteration 18680, lr = 0.00764287
I1028 21:43:54.836918 29475 solver.cpp:222] Iteration 18720 (1.28034 iter/s, 31.2417s/40 iters), loss = 1.88165
I1028 21:43:54.837086 29475 solver.cpp:241]     Train net output #0: loss = 1.88165 (* 1 = 1.88165 loss)
I1028 21:43:54.837105 29475 sgd_solver.cpp:105] Iteration 18720, lr = 0.00763799
I1028 21:44:26.239537 29475 solver.cpp:222] Iteration 18760 (1.27384 iter/s, 31.4011s/40 iters), loss = 1.72375
I1028 21:44:26.239795 29475 solver.cpp:241]     Train net output #0: loss = 1.72375 (* 1 = 1.72375 loss)
I1028 21:44:26.239825 29475 sgd_solver.cpp:105] Iteration 18760, lr = 0.0076331
I1028 21:44:57.987035 29475 solver.cpp:222] Iteration 18800 (1.26 iter/s, 31.746s/40 iters), loss = 1.7798
I1028 21:44:57.987217 29475 solver.cpp:241]     Train net output #0: loss = 1.7798 (* 1 = 1.7798 loss)
I1028 21:44:57.987234 29475 sgd_solver.cpp:105] Iteration 18800, lr = 0.00762821
I1028 21:45:28.990600 29475 solver.cpp:222] Iteration 18840 (1.29023 iter/s, 31.0022s/40 iters), loss = 1.66262
I1028 21:45:28.990792 29475 solver.cpp:241]     Train net output #0: loss = 1.66262 (* 1 = 1.66262 loss)
I1028 21:45:28.990811 29475 sgd_solver.cpp:105] Iteration 18840, lr = 0.00762333
I1028 21:46:01.032793 29475 solver.cpp:222] Iteration 18880 (1.24841 iter/s, 32.0408s/40 iters), loss = 1.61843
I1028 21:46:01.032990 29475 solver.cpp:241]     Train net output #0: loss = 1.61843 (* 1 = 1.61843 loss)
I1028 21:46:01.033007 29475 sgd_solver.cpp:105] Iteration 18880, lr = 0.00761844
I1028 21:46:32.713138 29475 solver.cpp:222] Iteration 18920 (1.26267 iter/s, 31.6789s/40 iters), loss = 1.41424
I1028 21:46:32.713449 29475 solver.cpp:241]     Train net output #0: loss = 1.41424 (* 1 = 1.41424 loss)
I1028 21:46:32.713466 29475 sgd_solver.cpp:105] Iteration 18920, lr = 0.00761356
I1028 21:47:03.829597 29475 solver.cpp:222] Iteration 18960 (1.28556 iter/s, 31.1149s/40 iters), loss = 2.07465
I1028 21:47:03.829838 29475 solver.cpp:241]     Train net output #0: loss = 2.07465 (* 1 = 2.07465 loss)
I1028 21:47:03.829867 29475 sgd_solver.cpp:105] Iteration 18960, lr = 0.00760868
I1028 21:47:39.697557 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_19000.caffemodel
I1028 21:47:39.732307 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_19000.solverstate
I1028 21:47:39.749361 29475 solver.cpp:334] Iteration 19000, Testing net (#0)
I1028 21:48:10.930511 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53272
I1028 21:48:10.930699 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.773839
I1028 21:48:10.930714 29475 solver.cpp:401]     Test net output #2: loss = 2.1227 (* 1 = 2.1227 loss)
I1028 21:48:11.694206 29475 solver.cpp:222] Iteration 19000 (0.589433 iter/s, 67.8618s/40 iters), loss = 1.63004
I1028 21:48:11.694277 29475 solver.cpp:241]     Train net output #0: loss = 1.63004 (* 1 = 1.63004 loss)
I1028 21:48:11.694293 29475 sgd_solver.cpp:105] Iteration 19000, lr = 0.0076038
I1028 21:48:42.822295 29475 solver.cpp:222] Iteration 19040 (1.28507 iter/s, 31.1268s/40 iters), loss = 1.74286
I1028 21:48:42.822509 29475 solver.cpp:241]     Train net output #0: loss = 1.74286 (* 1 = 1.74286 loss)
I1028 21:48:42.822531 29475 sgd_solver.cpp:105] Iteration 19040, lr = 0.00759892
I1028 21:49:13.910827 29475 solver.cpp:222] Iteration 19080 (1.28671 iter/s, 31.0871s/40 iters), loss = 1.48245
I1028 21:49:13.911010 29475 solver.cpp:241]     Train net output #0: loss = 1.48245 (* 1 = 1.48245 loss)
I1028 21:49:13.911026 29475 sgd_solver.cpp:105] Iteration 19080, lr = 0.00759404
I1028 21:49:45.168284 29475 solver.cpp:222] Iteration 19120 (1.27975 iter/s, 31.2561s/40 iters), loss = 1.71207
I1028 21:49:45.168488 29475 solver.cpp:241]     Train net output #0: loss = 1.71207 (* 1 = 1.71207 loss)
I1028 21:49:45.168504 29475 sgd_solver.cpp:105] Iteration 19120, lr = 0.00758916
I1028 21:50:16.031512 29475 solver.cpp:222] Iteration 19160 (1.2961 iter/s, 30.8618s/40 iters), loss = 1.67102
I1028 21:50:16.031710 29475 solver.cpp:241]     Train net output #0: loss = 1.67102 (* 1 = 1.67102 loss)
I1028 21:50:16.031728 29475 sgd_solver.cpp:105] Iteration 19160, lr = 0.00758428
I1028 21:50:46.950356 29475 solver.cpp:222] Iteration 19200 (1.29377 iter/s, 30.9175s/40 iters), loss = 1.44993
I1028 21:50:46.950552 29475 solver.cpp:241]     Train net output #0: loss = 1.44993 (* 1 = 1.44993 loss)
I1028 21:50:46.950573 29475 sgd_solver.cpp:105] Iteration 19200, lr = 0.0075794
I1028 21:51:23.376821 29475 solver.cpp:222] Iteration 19240 (1.09815 iter/s, 36.4249s/40 iters), loss = 1.69427
I1028 21:51:23.377017 29475 solver.cpp:241]     Train net output #0: loss = 1.69427 (* 1 = 1.69427 loss)
I1028 21:51:23.377033 29475 sgd_solver.cpp:105] Iteration 19240, lr = 0.00757452
I1028 21:51:54.703979 29475 solver.cpp:222] Iteration 19280 (1.2769 iter/s, 31.3258s/40 iters), loss = 1.5152
I1028 21:51:54.704215 29475 solver.cpp:241]     Train net output #0: loss = 1.5152 (* 1 = 1.5152 loss)
I1028 21:51:54.704236 29475 sgd_solver.cpp:105] Iteration 19280, lr = 0.00756965
I1028 21:52:26.197922 29475 solver.cpp:222] Iteration 19320 (1.27014 iter/s, 31.4925s/40 iters), loss = 2.04014
I1028 21:52:26.198145 29475 solver.cpp:241]     Train net output #0: loss = 2.04014 (* 1 = 2.04014 loss)
I1028 21:52:26.198164 29475 sgd_solver.cpp:105] Iteration 19320, lr = 0.00756477
I1028 21:52:57.123667 29475 solver.cpp:222] Iteration 19360 (1.29348 iter/s, 30.9244s/40 iters), loss = 1.77774
I1028 21:52:57.123849 29475 solver.cpp:241]     Train net output #0: loss = 1.77774 (* 1 = 1.77774 loss)
I1028 21:52:57.123867 29475 sgd_solver.cpp:105] Iteration 19360, lr = 0.00755989
I1028 21:53:28.156129 29475 solver.cpp:222] Iteration 19400 (1.28903 iter/s, 31.0311s/40 iters), loss = 1.7663
I1028 21:53:28.156327 29475 solver.cpp:241]     Train net output #0: loss = 1.7663 (* 1 = 1.7663 loss)
I1028 21:53:28.156347 29475 sgd_solver.cpp:105] Iteration 19400, lr = 0.00755502
I1028 21:53:59.877640 29475 solver.cpp:222] Iteration 19440 (1.26103 iter/s, 31.7201s/40 iters), loss = 2.06869
I1028 21:53:59.877887 29475 solver.cpp:241]     Train net output #0: loss = 2.06869 (* 1 = 2.06869 loss)
I1028 21:53:59.877904 29475 sgd_solver.cpp:105] Iteration 19440, lr = 0.00755014
I1028 21:54:31.248175 29475 solver.cpp:222] Iteration 19480 (1.27514 iter/s, 31.3691s/40 iters), loss = 1.25865
I1028 21:54:31.248469 29475 solver.cpp:241]     Train net output #0: loss = 1.25865 (* 1 = 1.25865 loss)
I1028 21:54:31.248493 29475 sgd_solver.cpp:105] Iteration 19480, lr = 0.00754527
I1028 21:54:46.395591 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_19500.caffemodel
I1028 21:54:46.429369 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_19500.solverstate
I1028 21:54:46.446086 29475 solver.cpp:334] Iteration 19500, Testing net (#0)
I1028 21:55:17.313974 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 21:55:17.521536 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5466
I1028 21:55:17.521597 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78724
I1028 21:55:17.521611 29475 solver.cpp:401]     Test net output #2: loss = 2.01198 (* 1 = 2.01198 loss)
I1028 21:55:33.859342 29475 solver.cpp:222] Iteration 19520 (0.638891 iter/s, 62.6085s/40 iters), loss = 1.85287
I1028 21:55:33.859423 29475 solver.cpp:241]     Train net output #0: loss = 1.85287 (* 1 = 1.85287 loss)
I1028 21:55:33.859439 29475 sgd_solver.cpp:105] Iteration 19520, lr = 0.0075404
I1028 21:56:04.817828 29475 solver.cpp:222] Iteration 19560 (1.29211 iter/s, 30.9572s/40 iters), loss = 1.5067
I1028 21:56:04.818009 29475 solver.cpp:241]     Train net output #0: loss = 1.5067 (* 1 = 1.5067 loss)
I1028 21:56:04.818027 29475 sgd_solver.cpp:105] Iteration 19560, lr = 0.00753553
I1028 21:56:35.803192 29475 solver.cpp:222] Iteration 19600 (1.29099 iter/s, 30.984s/40 iters), loss = 1.69645
I1028 21:56:35.803381 29475 solver.cpp:241]     Train net output #0: loss = 1.69645 (* 1 = 1.69645 loss)
I1028 21:56:35.803397 29475 sgd_solver.cpp:105] Iteration 19600, lr = 0.00753066
I1028 21:57:06.840965 29475 solver.cpp:222] Iteration 19640 (1.28881 iter/s, 31.0364s/40 iters), loss = 1.99477
I1028 21:57:06.841156 29475 solver.cpp:241]     Train net output #0: loss = 1.99477 (* 1 = 1.99477 loss)
I1028 21:57:06.841173 29475 sgd_solver.cpp:105] Iteration 19640, lr = 0.00752579
I1028 21:57:37.727612 29475 solver.cpp:222] Iteration 19680 (1.29512 iter/s, 30.8853s/40 iters), loss = 1.7023
I1028 21:57:37.727857 29475 solver.cpp:241]     Train net output #0: loss = 1.7023 (* 1 = 1.7023 loss)
I1028 21:57:37.727885 29475 sgd_solver.cpp:105] Iteration 19680, lr = 0.00752092
I1028 21:58:08.693606 29475 solver.cpp:222] Iteration 19720 (1.2918 iter/s, 30.9646s/40 iters), loss = 1.97043
I1028 21:58:08.693804 29475 solver.cpp:241]     Train net output #0: loss = 1.97043 (* 1 = 1.97043 loss)
I1028 21:58:08.693821 29475 sgd_solver.cpp:105] Iteration 19720, lr = 0.00751605
I1028 21:58:39.615201 29475 solver.cpp:222] Iteration 19760 (1.29365 iter/s, 30.9202s/40 iters), loss = 1.55376
I1028 21:58:39.615517 29475 solver.cpp:241]     Train net output #0: loss = 1.55376 (* 1 = 1.55376 loss)
I1028 21:58:39.615535 29475 sgd_solver.cpp:105] Iteration 19760, lr = 0.00751118
I1028 21:59:10.302527 29475 solver.cpp:222] Iteration 19800 (1.30354 iter/s, 30.6858s/40 iters), loss = 1.90635
I1028 21:59:10.302706 29475 solver.cpp:241]     Train net output #0: loss = 1.90635 (* 1 = 1.90635 loss)
I1028 21:59:10.302723 29475 sgd_solver.cpp:105] Iteration 19800, lr = 0.00750631
I1028 21:59:41.142673 29475 solver.cpp:222] Iteration 19840 (1.29707 iter/s, 30.8388s/40 iters), loss = 1.70971
I1028 21:59:41.142845 29475 solver.cpp:241]     Train net output #0: loss = 1.70971 (* 1 = 1.70971 loss)
I1028 21:59:41.142863 29475 sgd_solver.cpp:105] Iteration 19840, lr = 0.00750145
I1028 22:00:11.914685 29475 solver.cpp:222] Iteration 19880 (1.29994 iter/s, 30.7707s/40 iters), loss = 1.78534
I1028 22:00:11.914970 29475 solver.cpp:241]     Train net output #0: loss = 1.78534 (* 1 = 1.78534 loss)
I1028 22:00:11.915021 29475 sgd_solver.cpp:105] Iteration 19880, lr = 0.00749658
I1028 22:00:42.964207 29475 solver.cpp:222] Iteration 19920 (1.28833 iter/s, 31.048s/40 iters), loss = 1.62734
I1028 22:00:42.964416 29475 solver.cpp:241]     Train net output #0: loss = 1.62734 (* 1 = 1.62734 loss)
I1028 22:00:42.964433 29475 sgd_solver.cpp:105] Iteration 19920, lr = 0.00749172
I1028 22:01:14.088380 29475 solver.cpp:222] Iteration 19960 (1.28523 iter/s, 31.1228s/40 iters), loss = 1.88065
I1028 22:01:14.088600 29475 solver.cpp:241]     Train net output #0: loss = 1.88065 (* 1 = 1.88065 loss)
I1028 22:01:14.088618 29475 sgd_solver.cpp:105] Iteration 19960, lr = 0.00748685
I1028 22:01:44.067560 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_20000.caffemodel
I1028 22:01:44.101735 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_20000.solverstate
I1028 22:01:44.118543 29475 solver.cpp:334] Iteration 20000, Testing net (#0)
I1028 22:02:15.197788 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53976
I1028 22:02:15.197969 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77824
I1028 22:02:15.197984 29475 solver.cpp:401]     Test net output #2: loss = 2.06404 (* 1 = 2.06404 loss)
I1028 22:02:15.970752 29475 solver.cpp:222] Iteration 20000 (0.646414 iter/s, 61.8798s/40 iters), loss = 2.39308
I1028 22:02:15.970819 29475 solver.cpp:241]     Train net output #0: loss = 2.39308 (* 1 = 2.39308 loss)
I1028 22:02:15.970835 29475 sgd_solver.cpp:105] Iteration 20000, lr = 0.00748199
I1028 22:02:26.823791 29523 data_layer.cpp:73] Restarting data prefetching from start.
I1028 22:02:46.921780 29475 solver.cpp:222] Iteration 20040 (1.29242 iter/s, 30.9498s/40 iters), loss = 1.58077
I1028 22:02:46.921989 29475 solver.cpp:241]     Train net output #0: loss = 1.58077 (* 1 = 1.58077 loss)
I1028 22:02:46.922008 29475 sgd_solver.cpp:105] Iteration 20040, lr = 0.00747712
I1028 22:03:18.110508 29475 solver.cpp:222] Iteration 20080 (1.28257 iter/s, 31.1873s/40 iters), loss = 1.75244
I1028 22:03:18.110694 29475 solver.cpp:241]     Train net output #0: loss = 1.75244 (* 1 = 1.75244 loss)
I1028 22:03:18.110713 29475 sgd_solver.cpp:105] Iteration 20080, lr = 0.00747226
I1028 22:03:48.986403 29475 solver.cpp:222] Iteration 20120 (1.29557 iter/s, 30.8745s/40 iters), loss = 1.79188
I1028 22:03:48.986598 29475 solver.cpp:241]     Train net output #0: loss = 1.79188 (* 1 = 1.79188 loss)
I1028 22:03:48.986616 29475 sgd_solver.cpp:105] Iteration 20120, lr = 0.0074674
I1028 22:04:19.889032 29475 solver.cpp:222] Iteration 20160 (1.29445 iter/s, 30.9013s/40 iters), loss = 1.53421
I1028 22:04:19.889225 29475 solver.cpp:241]     Train net output #0: loss = 1.53421 (* 1 = 1.53421 loss)
I1028 22:04:19.889242 29475 sgd_solver.cpp:105] Iteration 20160, lr = 0.00746254
I1028 22:04:50.775168 29475 solver.cpp:222] Iteration 20200 (1.29514 iter/s, 30.8848s/40 iters), loss = 1.69768
I1028 22:04:50.775382 29475 solver.cpp:241]     Train net output #0: loss = 1.69768 (* 1 = 1.69768 loss)
I1028 22:04:50.775398 29475 sgd_solver.cpp:105] Iteration 20200, lr = 0.00745768
I1028 22:05:21.802760 29475 solver.cpp:222] Iteration 20240 (1.28923 iter/s, 31.0262s/40 iters), loss = 1.63716
I1028 22:05:21.802951 29475 solver.cpp:241]     Train net output #0: loss = 1.63716 (* 1 = 1.63716 loss)
I1028 22:05:21.802970 29475 sgd_solver.cpp:105] Iteration 20240, lr = 0.00745282
I1028 22:05:52.608150 29475 solver.cpp:222] Iteration 20280 (1.29853 iter/s, 30.804s/40 iters), loss = 1.70877
I1028 22:05:52.608367 29475 solver.cpp:241]     Train net output #0: loss = 1.70877 (* 1 = 1.70877 loss)
I1028 22:05:52.608384 29475 sgd_solver.cpp:105] Iteration 20280, lr = 0.00744796
I1028 22:06:23.342527 29475 solver.cpp:222] Iteration 20320 (1.30153 iter/s, 30.733s/40 iters), loss = 1.67478
I1028 22:06:23.342793 29475 solver.cpp:241]     Train net output #0: loss = 1.67478 (* 1 = 1.67478 loss)
I1028 22:06:23.342811 29475 sgd_solver.cpp:105] Iteration 20320, lr = 0.0074431
I1028 22:06:54.257153 29475 solver.cpp:222] Iteration 20360 (1.29395 iter/s, 30.9131s/40 iters), loss = 1.55025
I1028 22:06:54.257315 29475 solver.cpp:241]     Train net output #0: loss = 1.55025 (* 1 = 1.55025 loss)
I1028 22:06:54.257338 29475 sgd_solver.cpp:105] Iteration 20360, lr = 0.00743825
I1028 22:07:25.009167 29475 solver.cpp:222] Iteration 20400 (1.30078 iter/s, 30.7507s/40 iters), loss = 1.80524
I1028 22:07:25.009373 29475 solver.cpp:241]     Train net output #0: loss = 1.80524 (* 1 = 1.80524 loss)
I1028 22:07:25.009392 29475 sgd_solver.cpp:105] Iteration 20400, lr = 0.00743339
I1028 22:07:55.531754 29475 solver.cpp:222] Iteration 20440 (1.31057 iter/s, 30.5211s/40 iters), loss = 1.39203
I1028 22:07:55.531910 29475 solver.cpp:241]     Train net output #0: loss = 1.39203 (* 1 = 1.39203 loss)
I1028 22:07:55.531929 29475 sgd_solver.cpp:105] Iteration 20440, lr = 0.00742854
I1028 22:08:26.037416 29475 solver.cpp:222] Iteration 20480 (1.31129 iter/s, 30.5043s/40 iters), loss = 1.69538
I1028 22:08:26.037569 29475 solver.cpp:241]     Train net output #0: loss = 1.69538 (* 1 = 1.69538 loss)
I1028 22:08:26.037586 29475 sgd_solver.cpp:105] Iteration 20480, lr = 0.00742368
I1028 22:08:40.520443 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_20500.caffemodel
I1028 22:08:40.556279 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_20500.solverstate
I1028 22:08:40.575496 29475 solver.cpp:334] Iteration 20500, Testing net (#0)
I1028 22:09:11.729626 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 22:09:11.940348 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5438
I1028 22:09:11.940412 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78144
I1028 22:09:11.940425 29475 solver.cpp:401]     Test net output #2: loss = 2.0615 (* 1 = 2.0615 loss)
I1028 22:09:28.190104 29475 solver.cpp:222] Iteration 20520 (0.643602 iter/s, 62.1502s/40 iters), loss = 1.89392
I1028 22:09:28.190184 29475 solver.cpp:241]     Train net output #0: loss = 1.89392 (* 1 = 1.89392 loss)
I1028 22:09:28.190201 29475 sgd_solver.cpp:105] Iteration 20520, lr = 0.00741883
I1028 22:09:59.146952 29475 solver.cpp:222] Iteration 20560 (1.29218 iter/s, 30.9555s/40 iters), loss = 1.37704
I1028 22:09:59.147142 29475 solver.cpp:241]     Train net output #0: loss = 1.37704 (* 1 = 1.37704 loss)
I1028 22:09:59.147161 29475 sgd_solver.cpp:105] Iteration 20560, lr = 0.00741397
I1028 22:10:30.387058 29475 solver.cpp:222] Iteration 20600 (1.28046 iter/s, 31.2387s/40 iters), loss = 1.51276
I1028 22:10:30.387248 29475 solver.cpp:241]     Train net output #0: loss = 1.51276 (* 1 = 1.51276 loss)
I1028 22:10:30.387264 29475 sgd_solver.cpp:105] Iteration 20600, lr = 0.00740912
I1028 22:11:02.186839 29475 solver.cpp:222] Iteration 20640 (1.25793 iter/s, 31.7983s/40 iters), loss = 1.62841
I1028 22:11:02.187042 29475 solver.cpp:241]     Train net output #0: loss = 1.62841 (* 1 = 1.62841 loss)
I1028 22:11:02.187059 29475 sgd_solver.cpp:105] Iteration 20640, lr = 0.00740427
I1028 22:11:33.900876 29475 solver.cpp:222] Iteration 20680 (1.26133 iter/s, 31.7126s/40 iters), loss = 2.20408
I1028 22:11:33.901093 29475 solver.cpp:241]     Train net output #0: loss = 2.20408 (* 1 = 2.20408 loss)
I1028 22:11:33.901110 29475 sgd_solver.cpp:105] Iteration 20680, lr = 0.00739942
I1028 22:12:04.760854 29475 solver.cpp:222] Iteration 20720 (1.29624 iter/s, 30.8586s/40 iters), loss = 1.15972
I1028 22:12:04.761088 29475 solver.cpp:241]     Train net output #0: loss = 1.15972 (* 1 = 1.15972 loss)
I1028 22:12:04.761109 29475 sgd_solver.cpp:105] Iteration 20720, lr = 0.00739457
I1028 22:12:35.370570 29475 solver.cpp:222] Iteration 20760 (1.30683 iter/s, 30.6083s/40 iters), loss = 1.61018
I1028 22:12:35.370759 29475 solver.cpp:241]     Train net output #0: loss = 1.61018 (* 1 = 1.61018 loss)
I1028 22:12:35.370779 29475 sgd_solver.cpp:105] Iteration 20760, lr = 0.00738972
I1028 22:13:06.085445 29475 solver.cpp:222] Iteration 20800 (1.30236 iter/s, 30.7135s/40 iters), loss = 1.65935
I1028 22:13:06.085750 29475 solver.cpp:241]     Train net output #0: loss = 1.65935 (* 1 = 1.65935 loss)
I1028 22:13:06.085794 29475 sgd_solver.cpp:105] Iteration 20800, lr = 0.00738487
I1028 22:13:36.776383 29475 solver.cpp:222] Iteration 20840 (1.30338 iter/s, 30.6895s/40 iters), loss = 1.63261
I1028 22:13:36.776536 29475 solver.cpp:241]     Train net output #0: loss = 1.63261 (* 1 = 1.63261 loss)
I1028 22:13:36.776553 29475 sgd_solver.cpp:105] Iteration 20840, lr = 0.00738002
I1028 22:14:07.440486 29475 solver.cpp:222] Iteration 20880 (1.30451 iter/s, 30.6628s/40 iters), loss = 1.73526
I1028 22:14:07.440647 29475 solver.cpp:241]     Train net output #0: loss = 1.73526 (* 1 = 1.73526 loss)
I1028 22:14:07.440668 29475 sgd_solver.cpp:105] Iteration 20880, lr = 0.00737517
I1028 22:14:38.249604 29475 solver.cpp:222] Iteration 20920 (1.29837 iter/s, 30.8078s/40 iters), loss = 1.48553
I1028 22:14:38.249874 29475 solver.cpp:241]     Train net output #0: loss = 1.48553 (* 1 = 1.48553 loss)
I1028 22:14:38.249904 29475 sgd_solver.cpp:105] Iteration 20920, lr = 0.00737032
I1028 22:15:49.861001 29475 solver.cpp:222] Iteration 20960 (0.558594 iter/s, 71.6084s/40 iters), loss = 1.53389
I1028 22:15:49.861243 29475 solver.cpp:241]     Train net output #0: loss = 1.53389 (* 1 = 1.53389 loss)
I1028 22:15:49.861266 29475 sgd_solver.cpp:105] Iteration 20960, lr = 0.00736548
I1028 22:16:20.389168 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_21000.caffemodel
I1028 22:16:20.433073 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_21000.solverstate
I1028 22:16:20.455621 29475 solver.cpp:334] Iteration 21000, Testing net (#0)
I1028 22:16:51.518146 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54624
I1028 22:16:51.518322 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.785279
I1028 22:16:51.518338 29475 solver.cpp:401]     Test net output #2: loss = 2.00797 (* 1 = 2.00797 loss)
I1028 22:16:52.288990 29475 solver.cpp:222] Iteration 21000 (0.640765 iter/s, 62.4254s/40 iters), loss = 1.88091
I1028 22:16:52.289055 29475 solver.cpp:241]     Train net output #0: loss = 1.88091 (* 1 = 1.88091 loss)
I1028 22:16:52.289072 29475 sgd_solver.cpp:105] Iteration 21000, lr = 0.00736063
I1028 22:17:24.208969 29475 solver.cpp:222] Iteration 21040 (1.25318 iter/s, 31.9187s/40 iters), loss = 1.7565
I1028 22:17:24.209249 29475 solver.cpp:241]     Train net output #0: loss = 1.7565 (* 1 = 1.7565 loss)
I1028 22:17:24.209273 29475 sgd_solver.cpp:105] Iteration 21040, lr = 0.00735579
I1028 22:18:31.422286 29475 solver.cpp:222] Iteration 21080 (0.595145 iter/s, 67.2105s/40 iters), loss = 1.81854
I1028 22:18:31.422564 29475 solver.cpp:241]     Train net output #0: loss = 1.81854 (* 1 = 1.81854 loss)
I1028 22:18:31.422591 29475 sgd_solver.cpp:105] Iteration 21080, lr = 0.00735095
I1028 22:19:02.224395 29475 solver.cpp:222] Iteration 21120 (1.29868 iter/s, 30.8006s/40 iters), loss = 1.56064
I1028 22:19:02.224627 29475 solver.cpp:241]     Train net output #0: loss = 1.56064 (* 1 = 1.56064 loss)
I1028 22:19:02.224644 29475 sgd_solver.cpp:105] Iteration 21120, lr = 0.0073461
I1028 22:19:33.247912 29475 solver.cpp:222] Iteration 21160 (1.2894 iter/s, 31.0221s/40 iters), loss = 1.64119
I1028 22:19:33.248101 29475 solver.cpp:241]     Train net output #0: loss = 1.64119 (* 1 = 1.64119 loss)
I1028 22:19:33.248119 29475 sgd_solver.cpp:105] Iteration 21160, lr = 0.00734126
I1028 22:20:04.571727 29475 solver.cpp:222] Iteration 21200 (1.27704 iter/s, 31.3224s/40 iters), loss = 1.70184
I1028 22:20:04.571936 29475 solver.cpp:241]     Train net output #0: loss = 1.70184 (* 1 = 1.70184 loss)
I1028 22:20:04.571955 29475 sgd_solver.cpp:105] Iteration 21200, lr = 0.00733642
I1028 22:20:35.481274 29475 solver.cpp:222] Iteration 21240 (1.29416 iter/s, 30.9082s/40 iters), loss = 1.55411
I1028 22:20:35.481545 29475 solver.cpp:241]     Train net output #0: loss = 1.55411 (* 1 = 1.55411 loss)
I1028 22:20:35.481576 29475 sgd_solver.cpp:105] Iteration 21240, lr = 0.00733158
I1028 22:21:07.348249 29475 solver.cpp:222] Iteration 21280 (1.25528 iter/s, 31.8654s/40 iters), loss = 1.85632
I1028 22:21:07.348480 29475 solver.cpp:241]     Train net output #0: loss = 1.85632 (* 1 = 1.85632 loss)
I1028 22:21:07.348498 29475 sgd_solver.cpp:105] Iteration 21280, lr = 0.00732674
I1028 22:21:38.386847 29475 solver.cpp:222] Iteration 21320 (1.28878 iter/s, 31.0372s/40 iters), loss = 1.86309
I1028 22:21:38.387058 29475 solver.cpp:241]     Train net output #0: loss = 1.86309 (* 1 = 1.86309 loss)
I1028 22:21:38.387075 29475 sgd_solver.cpp:105] Iteration 21320, lr = 0.0073219
I1028 22:22:09.275751 29475 solver.cpp:222] Iteration 21360 (1.29502 iter/s, 30.8875s/40 iters), loss = 1.90169
I1028 22:22:09.275962 29475 solver.cpp:241]     Train net output #0: loss = 1.90169 (* 1 = 1.90169 loss)
I1028 22:22:09.275979 29475 sgd_solver.cpp:105] Iteration 21360, lr = 0.00731706
I1028 22:22:40.342730 29475 solver.cpp:222] Iteration 21400 (1.2876 iter/s, 31.0656s/40 iters), loss = 1.717
I1028 22:22:40.342916 29475 solver.cpp:241]     Train net output #0: loss = 1.717 (* 1 = 1.717 loss)
I1028 22:22:40.342932 29475 sgd_solver.cpp:105] Iteration 21400, lr = 0.00731222
I1028 22:23:11.252449 29475 solver.cpp:222] Iteration 21440 (1.29415 iter/s, 30.9084s/40 iters), loss = 2.04501
I1028 22:23:11.252647 29475 solver.cpp:241]     Train net output #0: loss = 2.04501 (* 1 = 2.04501 loss)
I1028 22:23:11.252665 29475 sgd_solver.cpp:105] Iteration 21440, lr = 0.00730738
I1028 22:23:42.599943 29475 solver.cpp:222] Iteration 21480 (1.27608 iter/s, 31.3461s/40 iters), loss = 1.75756
I1028 22:23:42.600200 29475 solver.cpp:241]     Train net output #0: loss = 1.75756 (* 1 = 1.75756 loss)
I1028 22:23:42.600224 29475 sgd_solver.cpp:105] Iteration 21480, lr = 0.00730255
I1028 22:23:57.449918 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_21500.caffemodel
I1028 22:23:57.486896 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_21500.solverstate
I1028 22:23:57.511811 29475 solver.cpp:334] Iteration 21500, Testing net (#0)
I1028 22:24:28.319630 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 22:24:28.525041 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.546
I1028 22:24:28.525106 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78424
I1028 22:24:28.525120 29475 solver.cpp:401]     Test net output #2: loss = 2.01942 (* 1 = 2.01942 loss)
I1028 22:24:44.775079 29475 solver.cpp:222] Iteration 21520 (0.643371 iter/s, 62.1726s/40 iters), loss = 1.59357
I1028 22:24:44.775146 29475 solver.cpp:241]     Train net output #0: loss = 1.59357 (* 1 = 1.59357 loss)
I1028 22:24:44.775161 29475 sgd_solver.cpp:105] Iteration 21520, lr = 0.00729771
I1028 22:25:15.980451 29475 solver.cpp:222] Iteration 21560 (1.28188 iter/s, 31.2041s/40 iters), loss = 1.67959
I1028 22:25:15.980651 29475 solver.cpp:241]     Train net output #0: loss = 1.67959 (* 1 = 1.67959 loss)
I1028 22:25:15.980669 29475 sgd_solver.cpp:105] Iteration 21560, lr = 0.00729288
I1028 22:25:47.142544 29475 solver.cpp:222] Iteration 21600 (1.28367 iter/s, 31.1607s/40 iters), loss = 1.80714
I1028 22:25:47.142747 29475 solver.cpp:241]     Train net output #0: loss = 1.80714 (* 1 = 1.80714 loss)
I1028 22:25:47.142765 29475 sgd_solver.cpp:105] Iteration 21600, lr = 0.00728804
I1028 22:26:17.909366 29475 solver.cpp:222] Iteration 21640 (1.30016 iter/s, 30.7655s/40 iters), loss = 1.66969
I1028 22:26:17.909580 29475 solver.cpp:241]     Train net output #0: loss = 1.66969 (* 1 = 1.66969 loss)
I1028 22:26:17.909597 29475 sgd_solver.cpp:105] Iteration 21640, lr = 0.00728321
I1028 22:26:48.904752 29475 solver.cpp:222] Iteration 21680 (1.29057 iter/s, 30.994s/40 iters), loss = 1.55954
I1028 22:26:48.905007 29475 solver.cpp:241]     Train net output #0: loss = 1.55954 (* 1 = 1.55954 loss)
I1028 22:26:48.905035 29475 sgd_solver.cpp:105] Iteration 21680, lr = 0.00727838
I1028 22:27:19.757779 29475 solver.cpp:222] Iteration 21720 (1.29653 iter/s, 30.8515s/40 iters), loss = 1.67137
I1028 22:27:19.757973 29475 solver.cpp:241]     Train net output #0: loss = 1.67137 (* 1 = 1.67137 loss)
I1028 22:27:19.757992 29475 sgd_solver.cpp:105] Iteration 21720, lr = 0.00727354
I1028 22:27:50.475849 29475 solver.cpp:222] Iteration 21760 (1.30222 iter/s, 30.7167s/40 iters), loss = 1.56881
I1028 22:27:50.476028 29475 solver.cpp:241]     Train net output #0: loss = 1.56881 (* 1 = 1.56881 loss)
I1028 22:27:50.476047 29475 sgd_solver.cpp:105] Iteration 21760, lr = 0.00726871
I1028 22:28:21.010931 29475 solver.cpp:222] Iteration 21800 (1.31003 iter/s, 30.5337s/40 iters), loss = 1.65562
I1028 22:28:21.011111 29475 solver.cpp:241]     Train net output #0: loss = 1.65562 (* 1 = 1.65562 loss)
I1028 22:28:21.011129 29475 sgd_solver.cpp:105] Iteration 21800, lr = 0.00726388
I1028 22:28:51.994845 29475 solver.cpp:222] Iteration 21840 (1.29105 iter/s, 30.9826s/40 iters), loss = 1.707
I1028 22:28:51.995056 29475 solver.cpp:241]     Train net output #0: loss = 1.707 (* 1 = 1.707 loss)
I1028 22:28:51.995072 29475 sgd_solver.cpp:105] Iteration 21840, lr = 0.00725905
I1028 22:29:23.127189 29475 solver.cpp:222] Iteration 21880 (1.28489 iter/s, 31.131s/40 iters), loss = 1.84997
I1028 22:29:23.127440 29475 solver.cpp:241]     Train net output #0: loss = 1.84997 (* 1 = 1.84997 loss)
I1028 22:29:23.127457 29475 sgd_solver.cpp:105] Iteration 21880, lr = 0.00725422
I1028 22:29:55.248679 29475 solver.cpp:222] Iteration 21920 (1.24533 iter/s, 32.12s/40 iters), loss = 1.63711
I1028 22:29:55.248914 29475 solver.cpp:241]     Train net output #0: loss = 1.63711 (* 1 = 1.63711 loss)
I1028 22:29:55.248940 29475 sgd_solver.cpp:105] Iteration 21920, lr = 0.00724939
I1028 22:30:26.394834 29475 solver.cpp:222] Iteration 21960 (1.28433 iter/s, 31.1447s/40 iters), loss = 1.29612
I1028 22:30:26.395035 29475 solver.cpp:241]     Train net output #0: loss = 1.29612 (* 1 = 1.29612 loss)
I1028 22:30:26.395054 29475 sgd_solver.cpp:105] Iteration 21960, lr = 0.00724457
I1028 22:30:56.401923 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_22000.caffemodel
I1028 22:30:56.436395 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_22000.solverstate
I1028 22:30:56.453172 29475 solver.cpp:334] Iteration 22000, Testing net (#0)
I1028 22:31:27.491962 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54612
I1028 22:31:27.492159 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78084
I1028 22:31:27.492174 29475 solver.cpp:401]     Test net output #2: loss = 2.03911 (* 1 = 2.03911 loss)
I1028 22:31:28.262523 29475 solver.cpp:222] Iteration 22000 (0.646567 iter/s, 61.8652s/40 iters), loss = 1.40484
I1028 22:31:28.262589 29475 solver.cpp:241]     Train net output #0: loss = 1.40484 (* 1 = 1.40484 loss)
I1028 22:31:28.262604 29475 sgd_solver.cpp:105] Iteration 22000, lr = 0.00723974
I1028 22:31:59.529824 29475 solver.cpp:222] Iteration 22040 (1.27934 iter/s, 31.266s/40 iters), loss = 1.85528
I1028 22:31:59.530082 29475 solver.cpp:241]     Train net output #0: loss = 1.85528 (* 1 = 1.85528 loss)
I1028 22:31:59.530650 29475 sgd_solver.cpp:105] Iteration 22040, lr = 0.00723491
I1028 22:32:30.892431 29475 solver.cpp:222] Iteration 22080 (1.27546 iter/s, 31.3612s/40 iters), loss = 1.99663
I1028 22:32:30.892621 29475 solver.cpp:241]     Train net output #0: loss = 1.99663 (* 1 = 1.99663 loss)
I1028 22:32:30.892637 29475 sgd_solver.cpp:105] Iteration 22080, lr = 0.00723009
I1028 22:33:01.992238 29475 solver.cpp:222] Iteration 22120 (1.28624 iter/s, 31.0984s/40 iters), loss = 1.25338
I1028 22:33:01.992377 29475 solver.cpp:241]     Train net output #0: loss = 1.25338 (* 1 = 1.25338 loss)
I1028 22:33:01.992393 29475 sgd_solver.cpp:105] Iteration 22120, lr = 0.00722526
I1028 22:33:33.163820 29475 solver.cpp:222] Iteration 22160 (1.28327 iter/s, 31.1702s/40 iters), loss = 1.70754
I1028 22:33:33.164047 29475 solver.cpp:241]     Train net output #0: loss = 1.70754 (* 1 = 1.70754 loss)
I1028 22:33:33.164064 29475 sgd_solver.cpp:105] Iteration 22160, lr = 0.00722044
I1028 22:34:04.097754 29475 solver.cpp:222] Iteration 22200 (1.29314 iter/s, 30.9325s/40 iters), loss = 1.74776
I1028 22:34:04.097985 29475 solver.cpp:241]     Train net output #0: loss = 1.74776 (* 1 = 1.74776 loss)
I1028 22:34:04.098007 29475 sgd_solver.cpp:105] Iteration 22200, lr = 0.00721562
I1028 22:34:35.327538 29475 solver.cpp:222] Iteration 22240 (1.28089 iter/s, 31.2283s/40 iters), loss = 1.83095
I1028 22:34:35.327733 29475 solver.cpp:241]     Train net output #0: loss = 1.83095 (* 1 = 1.83095 loss)
I1028 22:34:35.327750 29475 sgd_solver.cpp:105] Iteration 22240, lr = 0.00721079
I1028 22:35:06.000721 29475 solver.cpp:222] Iteration 22280 (1.30413 iter/s, 30.6718s/40 iters), loss = 1.71984
I1028 22:35:06.000882 29475 solver.cpp:241]     Train net output #0: loss = 1.71984 (* 1 = 1.71984 loss)
I1028 22:35:06.000898 29475 sgd_solver.cpp:105] Iteration 22280, lr = 0.00720597
I1028 22:35:36.987121 29475 solver.cpp:222] Iteration 22320 (1.29094 iter/s, 30.9851s/40 iters), loss = 1.75634
I1028 22:35:36.987318 29475 solver.cpp:241]     Train net output #0: loss = 1.75634 (* 1 = 1.75634 loss)
I1028 22:35:36.987339 29475 sgd_solver.cpp:105] Iteration 22320, lr = 0.00720115
I1028 22:36:07.784382 29475 solver.cpp:222] Iteration 22360 (1.29887 iter/s, 30.7959s/40 iters), loss = 1.72779
I1028 22:36:07.784564 29475 solver.cpp:241]     Train net output #0: loss = 1.72779 (* 1 = 1.72779 loss)
I1028 22:36:07.784581 29475 sgd_solver.cpp:105] Iteration 22360, lr = 0.00719633
I1028 22:36:38.796692 29475 solver.cpp:222] Iteration 22400 (1.28987 iter/s, 31.011s/40 iters), loss = 2.17782
I1028 22:36:38.796900 29475 solver.cpp:241]     Train net output #0: loss = 2.17782 (* 1 = 2.17782 loss)
I1028 22:36:38.796917 29475 sgd_solver.cpp:105] Iteration 22400, lr = 0.00719151
I1028 22:37:09.706830 29475 solver.cpp:222] Iteration 22440 (1.29413 iter/s, 30.9088s/40 iters), loss = 1.69047
I1028 22:37:09.707020 29475 solver.cpp:241]     Train net output #0: loss = 1.69047 (* 1 = 1.69047 loss)
I1028 22:37:09.707037 29475 sgd_solver.cpp:105] Iteration 22440, lr = 0.00718669
I1028 22:37:40.871213 29475 solver.cpp:222] Iteration 22480 (1.28357 iter/s, 31.163s/40 iters), loss = 1.65987
I1028 22:37:40.871409 29475 solver.cpp:241]     Train net output #0: loss = 1.65987 (* 1 = 1.65987 loss)
I1028 22:37:40.871430 29475 sgd_solver.cpp:105] Iteration 22480, lr = 0.00718188
I1028 22:37:55.711210 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_22500.caffemodel
I1028 22:37:55.747195 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_22500.solverstate
I1028 22:37:55.765311 29475 solver.cpp:334] Iteration 22500, Testing net (#0)
I1028 22:38:26.576970 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 22:38:26.784478 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54344
I1028 22:38:26.784539 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78372
I1028 22:38:26.784552 29475 solver.cpp:401]     Test net output #2: loss = 2.02281 (* 1 = 2.02281 loss)
I1028 22:38:40.104398 29523 data_layer.cpp:73] Restarting data prefetching from start.
I1028 22:38:43.017292 29475 solver.cpp:222] Iteration 22520 (0.643671 iter/s, 62.1436s/40 iters), loss = 1.85784
I1028 22:38:43.017369 29475 solver.cpp:241]     Train net output #0: loss = 1.85784 (* 1 = 1.85784 loss)
I1028 22:38:43.017385 29475 sgd_solver.cpp:105] Iteration 22520, lr = 0.00717706
I1028 22:39:13.784788 29475 solver.cpp:222] Iteration 22560 (1.30013 iter/s, 30.7662s/40 iters), loss = 1.56653
I1028 22:39:13.784982 29475 solver.cpp:241]     Train net output #0: loss = 1.56653 (* 1 = 1.56653 loss)
I1028 22:39:13.784999 29475 sgd_solver.cpp:105] Iteration 22560, lr = 0.00717224
I1028 22:39:44.452330 29475 solver.cpp:222] Iteration 22600 (1.30437 iter/s, 30.6662s/40 iters), loss = 1.81283
I1028 22:39:44.452569 29475 solver.cpp:241]     Train net output #0: loss = 1.81283 (* 1 = 1.81283 loss)
I1028 22:39:44.452587 29475 sgd_solver.cpp:105] Iteration 22600, lr = 0.00716743
I1028 22:40:14.717221 29475 solver.cpp:222] Iteration 22640 (1.32172 iter/s, 30.2635s/40 iters), loss = 1.44853
I1028 22:40:14.717414 29475 solver.cpp:241]     Train net output #0: loss = 1.44853 (* 1 = 1.44853 loss)
I1028 22:40:14.717432 29475 sgd_solver.cpp:105] Iteration 22640, lr = 0.00716261
I1028 22:40:45.400197 29475 solver.cpp:222] Iteration 22680 (1.30371 iter/s, 30.6816s/40 iters), loss = 1.5065
I1028 22:40:45.400373 29475 solver.cpp:241]     Train net output #0: loss = 1.5065 (* 1 = 1.5065 loss)
I1028 22:40:45.400394 29475 sgd_solver.cpp:105] Iteration 22680, lr = 0.0071578
I1028 22:41:16.175278 29475 solver.cpp:222] Iteration 22720 (1.29981 iter/s, 30.7737s/40 iters), loss = 1.33931
I1028 22:41:16.175489 29475 solver.cpp:241]     Train net output #0: loss = 1.33931 (* 1 = 1.33931 loss)
I1028 22:41:16.175506 29475 sgd_solver.cpp:105] Iteration 22720, lr = 0.00715298
I1028 22:41:46.818684 29475 solver.cpp:222] Iteration 22760 (1.3054 iter/s, 30.642s/40 iters), loss = 1.37105
I1028 22:41:46.818864 29475 solver.cpp:241]     Train net output #0: loss = 1.37105 (* 1 = 1.37105 loss)
I1028 22:41:46.818881 29475 sgd_solver.cpp:105] Iteration 22760, lr = 0.00714817
I1028 22:42:17.610811 29475 solver.cpp:222] Iteration 22800 (1.29909 iter/s, 30.7908s/40 iters), loss = 1.70111
I1028 22:42:17.610975 29475 solver.cpp:241]     Train net output #0: loss = 1.70111 (* 1 = 1.70111 loss)
I1028 22:42:17.610991 29475 sgd_solver.cpp:105] Iteration 22800, lr = 0.00714336
I1028 22:42:48.047610 29475 solver.cpp:222] Iteration 22840 (1.31426 iter/s, 30.4355s/40 iters), loss = 1.64577
I1028 22:42:48.047775 29475 solver.cpp:241]     Train net output #0: loss = 1.64577 (* 1 = 1.64577 loss)
I1028 22:42:48.047793 29475 sgd_solver.cpp:105] Iteration 22840, lr = 0.00713855
I1028 22:43:18.643499 29475 solver.cpp:222] Iteration 22880 (1.30742 iter/s, 30.5946s/40 iters), loss = 1.73917
I1028 22:43:18.643652 29475 solver.cpp:241]     Train net output #0: loss = 1.73917 (* 1 = 1.73917 loss)
I1028 22:43:18.643668 29475 sgd_solver.cpp:105] Iteration 22880, lr = 0.00713374
I1028 22:43:49.559360 29475 solver.cpp:222] Iteration 22920 (1.29389 iter/s, 30.9145s/40 iters), loss = 1.47077
I1028 22:43:49.559554 29475 solver.cpp:241]     Train net output #0: loss = 1.47077 (* 1 = 1.47077 loss)
I1028 22:43:49.559572 29475 sgd_solver.cpp:105] Iteration 22920, lr = 0.00712893
I1028 22:44:21.900522 29475 solver.cpp:222] Iteration 22960 (1.23687 iter/s, 32.3397s/40 iters), loss = 1.56523
I1028 22:44:21.900738 29475 solver.cpp:241]     Train net output #0: loss = 1.56523 (* 1 = 1.56523 loss)
I1028 22:44:21.900756 29475 sgd_solver.cpp:105] Iteration 22960, lr = 0.00712412
I1028 22:44:53.008388 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_23000.caffemodel
I1028 22:44:53.042781 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_23000.solverstate
I1028 22:44:53.060114 29475 solver.cpp:334] Iteration 23000, Testing net (#0)
I1028 22:45:24.028067 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.544
I1028 22:45:24.028236 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78372
I1028 22:45:24.028251 29475 solver.cpp:401]     Test net output #2: loss = 2.00973 (* 1 = 2.00973 loss)
I1028 22:45:24.794209 29475 solver.cpp:222] Iteration 23000 (0.63602 iter/s, 62.8911s/40 iters), loss = 1.51563
I1028 22:45:24.794275 29475 solver.cpp:241]     Train net output #0: loss = 1.51563 (* 1 = 1.51563 loss)
I1028 22:45:24.794291 29475 sgd_solver.cpp:105] Iteration 23000, lr = 0.00711931
I1028 22:45:56.463217 29475 solver.cpp:222] Iteration 23040 (1.26312 iter/s, 31.6677s/40 iters), loss = 1.64965
I1028 22:45:56.463516 29475 solver.cpp:241]     Train net output #0: loss = 1.64965 (* 1 = 1.64965 loss)
I1028 22:45:56.463542 29475 sgd_solver.cpp:105] Iteration 23040, lr = 0.0071145
I1028 22:46:28.310926 29475 solver.cpp:222] Iteration 23080 (1.25604 iter/s, 31.8462s/40 iters), loss = 1.69295
I1028 22:46:28.311130 29475 solver.cpp:241]     Train net output #0: loss = 1.69295 (* 1 = 1.69295 loss)
I1028 22:46:28.311146 29475 sgd_solver.cpp:105] Iteration 23080, lr = 0.0071097
I1028 22:46:59.248179 29475 solver.cpp:222] Iteration 23120 (1.293 iter/s, 30.9359s/40 iters), loss = 1.3588
I1028 22:46:59.248389 29475 solver.cpp:241]     Train net output #0: loss = 1.3588 (* 1 = 1.3588 loss)
I1028 22:46:59.248409 29475 sgd_solver.cpp:105] Iteration 23120, lr = 0.00710489
I1028 22:47:30.401291 29475 solver.cpp:222] Iteration 23160 (1.28404 iter/s, 31.1517s/40 iters), loss = 1.57057
I1028 22:47:30.401473 29475 solver.cpp:241]     Train net output #0: loss = 1.57057 (* 1 = 1.57057 loss)
I1028 22:47:30.401489 29475 sgd_solver.cpp:105] Iteration 23160, lr = 0.00710009
I1028 22:48:01.543364 29475 solver.cpp:222] Iteration 23200 (1.28449 iter/s, 31.1407s/40 iters), loss = 1.52122
I1028 22:48:01.543540 29475 solver.cpp:241]     Train net output #0: loss = 1.52122 (* 1 = 1.52122 loss)
I1028 22:48:01.543556 29475 sgd_solver.cpp:105] Iteration 23200, lr = 0.00709528
I1028 22:48:32.778957 29475 solver.cpp:222] Iteration 23240 (1.28065 iter/s, 31.2342s/40 iters), loss = 1.61331
I1028 22:48:32.779162 29475 solver.cpp:241]     Train net output #0: loss = 1.61331 (* 1 = 1.61331 loss)
I1028 22:48:32.779181 29475 sgd_solver.cpp:105] Iteration 23240, lr = 0.00709048
I1028 22:49:03.896793 29475 solver.cpp:222] Iteration 23280 (1.28549 iter/s, 31.1164s/40 iters), loss = 1.71466
I1028 22:49:03.897027 29475 solver.cpp:241]     Train net output #0: loss = 1.71466 (* 1 = 1.71466 loss)
I1028 22:49:03.897047 29475 sgd_solver.cpp:105] Iteration 23280, lr = 0.00708567
I1028 22:49:35.220221 29475 solver.cpp:222] Iteration 23320 (1.27706 iter/s, 31.322s/40 iters), loss = 1.55591
I1028 22:49:35.220417 29475 solver.cpp:241]     Train net output #0: loss = 1.55591 (* 1 = 1.55591 loss)
I1028 22:49:35.220434 29475 sgd_solver.cpp:105] Iteration 23320, lr = 0.00708087
I1028 22:50:07.998565 29475 solver.cpp:222] Iteration 23360 (1.22037 iter/s, 32.7769s/40 iters), loss = 1.67796
I1028 22:50:07.998824 29475 solver.cpp:241]     Train net output #0: loss = 1.67796 (* 1 = 1.67796 loss)
I1028 22:50:07.998850 29475 sgd_solver.cpp:105] Iteration 23360, lr = 0.00707607
I1028 22:50:40.120784 29475 solver.cpp:222] Iteration 23400 (1.2453 iter/s, 32.1207s/40 iters), loss = 1.70914
I1028 22:50:40.121029 29475 solver.cpp:241]     Train net output #0: loss = 1.70914 (* 1 = 1.70914 loss)
I1028 22:50:40.121045 29475 sgd_solver.cpp:105] Iteration 23400, lr = 0.00707127
I1028 22:51:11.901996 29475 solver.cpp:222] Iteration 23440 (1.25866 iter/s, 31.7798s/40 iters), loss = 2.3867
I1028 22:51:11.902214 29475 solver.cpp:241]     Train net output #0: loss = 2.3867 (* 1 = 2.3867 loss)
I1028 22:51:11.902230 29475 sgd_solver.cpp:105] Iteration 23440, lr = 0.00706647
I1028 22:51:43.121950 29475 solver.cpp:222] Iteration 23480 (1.28129 iter/s, 31.2185s/40 iters), loss = 1.39463
I1028 22:51:43.122143 29475 solver.cpp:241]     Train net output #0: loss = 1.39463 (* 1 = 1.39463 loss)
I1028 22:51:43.122159 29475 sgd_solver.cpp:105] Iteration 23480, lr = 0.00706167
I1028 22:51:58.335634 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_23500.caffemodel
I1028 22:51:58.372226 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_23500.solverstate
I1028 22:51:58.393813 29475 solver.cpp:334] Iteration 23500, Testing net (#0)
I1028 22:52:29.240275 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 22:52:29.447108 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54076
I1028 22:52:29.447170 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.783
I1028 22:52:29.447185 29475 solver.cpp:401]     Test net output #2: loss = 2.03455 (* 1 = 2.03455 loss)
I1028 22:52:45.997215 29475 solver.cpp:222] Iteration 23520 (0.636206 iter/s, 62.8727s/40 iters), loss = 1.50366
I1028 22:52:45.997280 29475 solver.cpp:241]     Train net output #0: loss = 1.50366 (* 1 = 1.50366 loss)
I1028 22:52:45.997299 29475 sgd_solver.cpp:105] Iteration 23520, lr = 0.00705687
I1028 22:53:17.102886 29475 solver.cpp:222] Iteration 23560 (1.28599 iter/s, 31.1044s/40 iters), loss = 1.7552
I1028 22:53:17.103162 29475 solver.cpp:241]     Train net output #0: loss = 1.7552 (* 1 = 1.7552 loss)
I1028 22:53:17.103179 29475 sgd_solver.cpp:105] Iteration 23560, lr = 0.00705207
I1028 22:53:48.846547 29475 solver.cpp:222] Iteration 23600 (1.26015 iter/s, 31.7422s/40 iters), loss = 2.01286
I1028 22:53:48.846827 29475 solver.cpp:241]     Train net output #0: loss = 2.01286 (* 1 = 2.01286 loss)
I1028 22:53:48.846853 29475 sgd_solver.cpp:105] Iteration 23600, lr = 0.00704728
I1028 22:54:20.642103 29475 solver.cpp:222] Iteration 23640 (1.2581 iter/s, 31.794s/40 iters), loss = 1.57354
I1028 22:54:20.642325 29475 solver.cpp:241]     Train net output #0: loss = 1.57354 (* 1 = 1.57354 loss)
I1028 22:54:20.642346 29475 sgd_solver.cpp:105] Iteration 23640, lr = 0.00704248
I1028 22:54:52.070446 29475 solver.cpp:222] Iteration 23680 (1.27279 iter/s, 31.4269s/40 iters), loss = 1.80527
I1028 22:54:52.070650 29475 solver.cpp:241]     Train net output #0: loss = 1.80527 (* 1 = 1.80527 loss)
I1028 22:54:52.070667 29475 sgd_solver.cpp:105] Iteration 23680, lr = 0.00703769
I1028 22:55:23.350885 29475 solver.cpp:222] Iteration 23720 (1.27881 iter/s, 31.279s/40 iters), loss = 1.73778
I1028 22:55:23.351078 29475 solver.cpp:241]     Train net output #0: loss = 1.73778 (* 1 = 1.73778 loss)
I1028 22:55:23.351095 29475 sgd_solver.cpp:105] Iteration 23720, lr = 0.00703289
I1028 22:55:54.524188 29475 solver.cpp:222] Iteration 23760 (1.28321 iter/s, 31.1719s/40 iters), loss = 1.64504
I1028 22:55:54.524396 29475 solver.cpp:241]     Train net output #0: loss = 1.64504 (* 1 = 1.64504 loss)
I1028 22:55:54.524415 29475 sgd_solver.cpp:105] Iteration 23760, lr = 0.0070281
I1028 22:56:26.085223 29475 solver.cpp:222] Iteration 23800 (1.26744 iter/s, 31.5596s/40 iters), loss = 1.57251
I1028 22:56:26.085445 29475 solver.cpp:241]     Train net output #0: loss = 1.57251 (* 1 = 1.57251 loss)
I1028 22:56:26.085461 29475 sgd_solver.cpp:105] Iteration 23800, lr = 0.0070233
I1028 22:56:57.202921 29475 solver.cpp:222] Iteration 23840 (1.2855 iter/s, 31.1162s/40 iters), loss = 1.90381
I1028 22:56:57.203094 29475 solver.cpp:241]     Train net output #0: loss = 1.90381 (* 1 = 1.90381 loss)
I1028 22:56:57.203114 29475 sgd_solver.cpp:105] Iteration 23840, lr = 0.00701851
I1028 22:57:28.510725 29475 solver.cpp:222] Iteration 23880 (1.27769 iter/s, 31.3064s/40 iters), loss = 1.5181
I1028 22:57:28.510939 29475 solver.cpp:241]     Train net output #0: loss = 1.5181 (* 1 = 1.5181 loss)
I1028 22:57:28.510956 29475 sgd_solver.cpp:105] Iteration 23880, lr = 0.00701372
I1028 22:57:59.862679 29475 solver.cpp:222] Iteration 23920 (1.27589 iter/s, 31.3505s/40 iters), loss = 1.54786
I1028 22:57:59.862884 29475 solver.cpp:241]     Train net output #0: loss = 1.54786 (* 1 = 1.54786 loss)
I1028 22:57:59.862901 29475 sgd_solver.cpp:105] Iteration 23920, lr = 0.00700893
I1028 22:58:31.249864 29475 solver.cpp:222] Iteration 23960 (1.27446 iter/s, 31.3858s/40 iters), loss = 1.50444
I1028 22:58:31.250051 29475 solver.cpp:241]     Train net output #0: loss = 1.50444 (* 1 = 1.50444 loss)
I1028 22:58:31.250068 29475 sgd_solver.cpp:105] Iteration 23960, lr = 0.00700414
I1028 22:59:01.480582 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_24000.caffemodel
I1028 22:59:01.514590 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_24000.solverstate
I1028 22:59:01.532011 29475 solver.cpp:334] Iteration 24000, Testing net (#0)
I1028 22:59:32.529736 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54284
I1028 22:59:32.529969 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77948
I1028 22:59:32.529996 29475 solver.cpp:401]     Test net output #2: loss = 2.02766 (* 1 = 2.02766 loss)
I1028 22:59:33.302033 29475 solver.cpp:222] Iteration 24000 (0.644645 iter/s, 62.0497s/40 iters), loss = 2.11307
I1028 22:59:33.302099 29475 solver.cpp:241]     Train net output #0: loss = 2.11307 (* 1 = 2.11307 loss)
I1028 22:59:33.302115 29475 sgd_solver.cpp:105] Iteration 24000, lr = 0.00699935
I1028 23:00:04.441210 29475 solver.cpp:222] Iteration 24040 (1.28461 iter/s, 31.1379s/40 iters), loss = 1.68971
I1028 23:00:04.441406 29475 solver.cpp:241]     Train net output #0: loss = 1.68971 (* 1 = 1.68971 loss)
I1028 23:00:04.441421 29475 sgd_solver.cpp:105] Iteration 24040, lr = 0.00699456
I1028 23:00:35.754212 29475 solver.cpp:222] Iteration 24080 (1.27748 iter/s, 31.3116s/40 iters), loss = 1.99021
I1028 23:00:35.754426 29475 solver.cpp:241]     Train net output #0: loss = 1.99021 (* 1 = 1.99021 loss)
I1028 23:00:35.754446 29475 sgd_solver.cpp:105] Iteration 24080, lr = 0.00698977
I1028 23:01:06.735184 29475 solver.cpp:222] Iteration 24120 (1.29117 iter/s, 30.9796s/40 iters), loss = 1.68112
I1028 23:01:06.735368 29475 solver.cpp:241]     Train net output #0: loss = 1.68112 (* 1 = 1.68112 loss)
I1028 23:01:06.735384 29475 sgd_solver.cpp:105] Iteration 24120, lr = 0.00698499
I1028 23:01:38.138054 29475 solver.cpp:222] Iteration 24160 (1.27382 iter/s, 31.4015s/40 iters), loss = 1.43025
I1028 23:01:38.138252 29475 solver.cpp:241]     Train net output #0: loss = 1.43025 (* 1 = 1.43025 loss)
I1028 23:01:38.138272 29475 sgd_solver.cpp:105] Iteration 24160, lr = 0.0069802
I1028 23:02:09.343472 29475 solver.cpp:222] Iteration 24200 (1.28189 iter/s, 31.204s/40 iters), loss = 1.73509
I1028 23:02:09.343688 29475 solver.cpp:241]     Train net output #0: loss = 1.73509 (* 1 = 1.73509 loss)
I1028 23:02:09.343708 29475 sgd_solver.cpp:105] Iteration 24200, lr = 0.00697541
I1028 23:02:40.294836 29475 solver.cpp:222] Iteration 24240 (1.29241 iter/s, 30.95s/40 iters), loss = 1.85815
I1028 23:02:40.295060 29475 solver.cpp:241]     Train net output #0: loss = 1.85815 (* 1 = 1.85815 loss)
I1028 23:02:40.295076 29475 sgd_solver.cpp:105] Iteration 24240, lr = 0.00697063
I1028 23:03:11.602874 29475 solver.cpp:222] Iteration 24280 (1.27768 iter/s, 31.3066s/40 iters), loss = 1.96588
I1028 23:03:11.603046 29475 solver.cpp:241]     Train net output #0: loss = 1.96588 (* 1 = 1.96588 loss)
I1028 23:03:11.603065 29475 sgd_solver.cpp:105] Iteration 24280, lr = 0.00696584
I1028 23:03:42.981071 29475 solver.cpp:222] Iteration 24320 (1.27483 iter/s, 31.3768s/40 iters), loss = 1.86895
I1028 23:03:42.981238 29475 solver.cpp:241]     Train net output #0: loss = 1.86895 (* 1 = 1.86895 loss)
I1028 23:03:42.981256 29475 sgd_solver.cpp:105] Iteration 24320, lr = 0.00696106
I1028 23:04:14.398023 29475 solver.cpp:222] Iteration 24360 (1.27326 iter/s, 31.4155s/40 iters), loss = 1.82792
I1028 23:04:14.398234 29475 solver.cpp:241]     Train net output #0: loss = 1.82792 (* 1 = 1.82792 loss)
I1028 23:04:14.398252 29475 sgd_solver.cpp:105] Iteration 24360, lr = 0.00695628
I1028 23:04:45.417086 29475 solver.cpp:222] Iteration 24400 (1.28959 iter/s, 31.0177s/40 iters), loss = 1.61264
I1028 23:04:45.417284 29475 solver.cpp:241]     Train net output #0: loss = 1.61264 (* 1 = 1.61264 loss)
I1028 23:04:45.417306 29475 sgd_solver.cpp:105] Iteration 24400, lr = 0.0069515
I1028 23:05:16.624946 29475 solver.cpp:222] Iteration 24440 (1.28179 iter/s, 31.2065s/40 iters), loss = 2.01023
I1028 23:05:16.625171 29475 solver.cpp:241]     Train net output #0: loss = 2.01023 (* 1 = 2.01023 loss)
I1028 23:05:16.625195 29475 sgd_solver.cpp:105] Iteration 24440, lr = 0.00694672
I1028 23:05:47.928164 29475 solver.cpp:222] Iteration 24480 (1.27788 iter/s, 31.3017s/40 iters), loss = 1.61591
I1028 23:05:47.928365 29475 solver.cpp:241]     Train net output #0: loss = 1.61591 (* 1 = 1.61591 loss)
I1028 23:05:47.928382 29475 sgd_solver.cpp:105] Iteration 24480, lr = 0.00694194
I1028 23:06:02.764724 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_24500.caffemodel
I1028 23:06:02.798954 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_24500.solverstate
I1028 23:06:02.817178 29475 solver.cpp:334] Iteration 24500, Testing net (#0)
I1028 23:06:33.598373 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 23:06:33.805196 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54236
I1028 23:06:33.805259 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78132
I1028 23:06:33.805272 29475 solver.cpp:401]     Test net output #2: loss = 2.01972 (* 1 = 2.01972 loss)
I1028 23:06:50.072824 29475 solver.cpp:222] Iteration 24520 (0.643686 iter/s, 62.1421s/40 iters), loss = 1.92907
I1028 23:06:50.072896 29475 solver.cpp:241]     Train net output #0: loss = 1.92907 (* 1 = 1.92907 loss)
I1028 23:06:50.072911 29475 sgd_solver.cpp:105] Iteration 24520, lr = 0.00693716
I1028 23:07:21.167013 29475 solver.cpp:222] Iteration 24560 (1.28647 iter/s, 31.0929s/40 iters), loss = 1.54678
I1028 23:07:21.167254 29475 solver.cpp:241]     Train net output #0: loss = 1.54678 (* 1 = 1.54678 loss)
I1028 23:07:21.167276 29475 sgd_solver.cpp:105] Iteration 24560, lr = 0.00693238
I1028 23:07:52.521113 29475 solver.cpp:222] Iteration 24600 (1.27581 iter/s, 31.3526s/40 iters), loss = 1.67851
I1028 23:07:52.521293 29475 solver.cpp:241]     Train net output #0: loss = 1.67851 (* 1 = 1.67851 loss)
I1028 23:07:52.521317 29475 sgd_solver.cpp:105] Iteration 24600, lr = 0.0069276
I1028 23:08:23.294343 29475 solver.cpp:222] Iteration 24640 (1.29989 iter/s, 30.7719s/40 iters), loss = 1.78599
I1028 23:08:23.294559 29475 solver.cpp:241]     Train net output #0: loss = 1.78599 (* 1 = 1.78599 loss)
I1028 23:08:23.294576 29475 sgd_solver.cpp:105] Iteration 24640, lr = 0.00692282
I1028 23:08:54.191020 29475 solver.cpp:222] Iteration 24680 (1.2947 iter/s, 30.8953s/40 iters), loss = 1.49317
I1028 23:08:54.191203 29475 solver.cpp:241]     Train net output #0: loss = 1.49317 (* 1 = 1.49317 loss)
I1028 23:08:54.191220 29475 sgd_solver.cpp:105] Iteration 24680, lr = 0.00691805
I1028 23:09:24.918972 29475 solver.cpp:222] Iteration 24720 (1.3018 iter/s, 30.7266s/40 iters), loss = 1.8841
I1028 23:09:24.919152 29475 solver.cpp:241]     Train net output #0: loss = 1.8841 (* 1 = 1.8841 loss)
I1028 23:09:24.919168 29475 sgd_solver.cpp:105] Iteration 24720, lr = 0.00691327
I1028 23:09:55.381017 29475 solver.cpp:222] Iteration 24760 (1.31317 iter/s, 30.4607s/40 iters), loss = 1.78618
I1028 23:09:55.381178 29475 solver.cpp:241]     Train net output #0: loss = 1.78618 (* 1 = 1.78618 loss)
I1028 23:09:55.381196 29475 sgd_solver.cpp:105] Iteration 24760, lr = 0.00690849
I1028 23:10:25.877748 29475 solver.cpp:222] Iteration 24800 (1.31167 iter/s, 30.4954s/40 iters), loss = 1.9983
I1028 23:10:25.877931 29475 solver.cpp:241]     Train net output #0: loss = 1.9983 (* 1 = 1.9983 loss)
I1028 23:10:25.877948 29475 sgd_solver.cpp:105] Iteration 24800, lr = 0.00690372
I1028 23:10:56.533252 29475 solver.cpp:222] Iteration 24840 (1.30488 iter/s, 30.6541s/40 iters), loss = 1.67014
I1028 23:10:56.533443 29475 solver.cpp:241]     Train net output #0: loss = 1.67014 (* 1 = 1.67014 loss)
I1028 23:10:56.533460 29475 sgd_solver.cpp:105] Iteration 24840, lr = 0.00689895
I1028 23:11:28.035157 29475 solver.cpp:222] Iteration 24880 (1.26982 iter/s, 31.5005s/40 iters), loss = 1.89533
I1028 23:11:28.035392 29475 solver.cpp:241]     Train net output #0: loss = 1.89533 (* 1 = 1.89533 loss)
I1028 23:11:28.035408 29475 sgd_solver.cpp:105] Iteration 24880, lr = 0.00689417
I1028 23:11:59.057101 29475 solver.cpp:222] Iteration 24920 (1.28947 iter/s, 31.0205s/40 iters), loss = 1.55829
I1028 23:11:59.057302 29475 solver.cpp:241]     Train net output #0: loss = 1.55829 (* 1 = 1.55829 loss)
I1028 23:11:59.057320 29475 sgd_solver.cpp:105] Iteration 24920, lr = 0.0068894
I1028 23:12:29.827024 29475 solver.cpp:222] Iteration 24960 (1.30003 iter/s, 30.7685s/40 iters), loss = 1.73174
I1028 23:12:29.827260 29475 solver.cpp:241]     Train net output #0: loss = 1.73174 (* 1 = 1.73174 loss)
I1028 23:12:29.827289 29475 sgd_solver.cpp:105] Iteration 24960, lr = 0.00688463
I1028 23:12:59.603916 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_25000.caffemodel
I1028 23:12:59.641304 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_25000.solverstate
I1028 23:12:59.663136 29475 solver.cpp:334] Iteration 25000, Testing net (#0)
I1028 23:13:30.719445 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.538
I1028 23:13:30.719637 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77648
I1028 23:13:30.719653 29475 solver.cpp:401]     Test net output #2: loss = 2.08096 (* 1 = 2.08096 loss)
I1028 23:13:31.489553 29475 solver.cpp:222] Iteration 25000 (0.648719 iter/s, 61.66s/40 iters), loss = 1.76126
I1028 23:13:31.489626 29475 solver.cpp:241]     Train net output #0: loss = 1.76126 (* 1 = 1.76126 loss)
I1028 23:13:31.489644 29475 sgd_solver.cpp:105] Iteration 25000, lr = 0.00687986
I1028 23:13:45.400280 29523 data_layer.cpp:73] Restarting data prefetching from start.
I1028 23:14:02.019136 29475 solver.cpp:222] Iteration 25040 (1.31026 iter/s, 30.5283s/40 iters), loss = 1.75752
I1028 23:14:02.019326 29475 solver.cpp:241]     Train net output #0: loss = 1.75752 (* 1 = 1.75752 loss)
I1028 23:14:02.019347 29475 sgd_solver.cpp:105] Iteration 25040, lr = 0.00687509
I1028 23:14:33.771459 29475 solver.cpp:222] Iteration 25080 (1.25981 iter/s, 31.7509s/40 iters), loss = 1.85094
I1028 23:14:33.771710 29475 solver.cpp:241]     Train net output #0: loss = 1.85094 (* 1 = 1.85094 loss)
I1028 23:14:33.771735 29475 sgd_solver.cpp:105] Iteration 25080, lr = 0.00687032
I1028 23:15:06.490643 29475 solver.cpp:222] Iteration 25120 (1.22258 iter/s, 32.7177s/40 iters), loss = 1.28066
I1028 23:15:06.490851 29475 solver.cpp:241]     Train net output #0: loss = 1.28066 (* 1 = 1.28066 loss)
I1028 23:15:06.490873 29475 sgd_solver.cpp:105] Iteration 25120, lr = 0.00686555
I1028 23:15:44.384853 29475 solver.cpp:222] Iteration 25160 (1.05562 iter/s, 37.8926s/40 iters), loss = 1.4499
I1028 23:15:44.385048 29475 solver.cpp:241]     Train net output #0: loss = 1.4499 (* 1 = 1.4499 loss)
I1028 23:15:44.385066 29475 sgd_solver.cpp:105] Iteration 25160, lr = 0.00686079
I1028 23:16:15.212239 29475 solver.cpp:222] Iteration 25200 (1.2976 iter/s, 30.826s/40 iters), loss = 1.65212
I1028 23:16:15.212435 29475 solver.cpp:241]     Train net output #0: loss = 1.65212 (* 1 = 1.65212 loss)
I1028 23:16:15.212451 29475 sgd_solver.cpp:105] Iteration 25200, lr = 0.00685602
I1028 23:16:59.099809 29475 solver.cpp:222] Iteration 25240 (0.911458 iter/s, 43.8857s/40 iters), loss = 1.7723
I1028 23:16:59.100024 29475 solver.cpp:241]     Train net output #0: loss = 1.7723 (* 1 = 1.7723 loss)
I1028 23:16:59.100044 29475 sgd_solver.cpp:105] Iteration 25240, lr = 0.00685125
I1028 23:17:30.324921 29475 solver.cpp:222] Iteration 25280 (1.28108 iter/s, 31.2237s/40 iters), loss = 1.60608
I1028 23:17:30.325130 29475 solver.cpp:241]     Train net output #0: loss = 1.60608 (* 1 = 1.60608 loss)
I1028 23:17:30.325148 29475 sgd_solver.cpp:105] Iteration 25280, lr = 0.00684649
I1028 23:18:01.450342 29475 solver.cpp:222] Iteration 25320 (1.28518 iter/s, 31.124s/40 iters), loss = 1.72377
I1028 23:18:01.450543 29475 solver.cpp:241]     Train net output #0: loss = 1.72377 (* 1 = 1.72377 loss)
I1028 23:18:01.450562 29475 sgd_solver.cpp:105] Iteration 25320, lr = 0.00684172
I1028 23:18:32.759846 29475 solver.cpp:222] Iteration 25360 (1.27762 iter/s, 31.3081s/40 iters), loss = 1.71183
I1028 23:18:32.760054 29475 solver.cpp:241]     Train net output #0: loss = 1.71183 (* 1 = 1.71183 loss)
I1028 23:18:32.760071 29475 sgd_solver.cpp:105] Iteration 25360, lr = 0.00683696
I1028 23:19:03.952213 29475 solver.cpp:222] Iteration 25400 (1.28242 iter/s, 31.191s/40 iters), loss = 1.61077
I1028 23:19:03.952419 29475 solver.cpp:241]     Train net output #0: loss = 1.61077 (* 1 = 1.61077 loss)
I1028 23:19:03.952435 29475 sgd_solver.cpp:105] Iteration 25400, lr = 0.0068322
I1028 23:19:35.146199 29475 solver.cpp:222] Iteration 25440 (1.28236 iter/s, 31.1926s/40 iters), loss = 1.55275
I1028 23:19:35.146469 29475 solver.cpp:241]     Train net output #0: loss = 1.55275 (* 1 = 1.55275 loss)
I1028 23:19:35.146488 29475 sgd_solver.cpp:105] Iteration 25440, lr = 0.00682744
I1028 23:20:06.166715 29475 solver.cpp:222] Iteration 25480 (1.28953 iter/s, 31.0191s/40 iters), loss = 1.58761
I1028 23:20:06.166934 29475 solver.cpp:241]     Train net output #0: loss = 1.58761 (* 1 = 1.58761 loss)
I1028 23:20:06.166949 29475 sgd_solver.cpp:105] Iteration 25480, lr = 0.00682268
I1028 23:20:21.013733 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_25500.caffemodel
I1028 23:20:21.053977 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_25500.solverstate
I1028 23:20:21.078131 29475 solver.cpp:334] Iteration 25500, Testing net (#0)
I1028 23:20:51.908984 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 23:20:52.115500 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5492
I1028 23:20:52.115561 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7858
I1028 23:20:52.115576 29475 solver.cpp:401]     Test net output #2: loss = 2.02443 (* 1 = 2.02443 loss)
I1028 23:21:08.529532 29475 solver.cpp:222] Iteration 25520 (0.641434 iter/s, 62.3603s/40 iters), loss = 2.00261
I1028 23:21:08.529613 29475 solver.cpp:241]     Train net output #0: loss = 2.00261 (* 1 = 2.00261 loss)
I1028 23:21:08.529629 29475 sgd_solver.cpp:105] Iteration 25520, lr = 0.00681791
I1028 23:21:39.943302 29475 solver.cpp:222] Iteration 25560 (1.27338 iter/s, 31.4125s/40 iters), loss = 1.48218
I1028 23:21:39.943527 29475 solver.cpp:241]     Train net output #0: loss = 1.48218 (* 1 = 1.48218 loss)
I1028 23:21:39.943544 29475 sgd_solver.cpp:105] Iteration 25560, lr = 0.00681316
I1028 23:22:11.450332 29475 solver.cpp:222] Iteration 25600 (1.26962 iter/s, 31.5056s/40 iters), loss = 1.84447
I1028 23:22:11.450517 29475 solver.cpp:241]     Train net output #0: loss = 1.84447 (* 1 = 1.84447 loss)
I1028 23:22:11.450534 29475 sgd_solver.cpp:105] Iteration 25600, lr = 0.0068084
I1028 23:22:43.182494 29475 solver.cpp:222] Iteration 25640 (1.26061 iter/s, 31.7308s/40 iters), loss = 1.64168
I1028 23:22:43.182683 29475 solver.cpp:241]     Train net output #0: loss = 1.64168 (* 1 = 1.64168 loss)
I1028 23:22:43.182705 29475 sgd_solver.cpp:105] Iteration 25640, lr = 0.00680364
I1028 23:23:14.505615 29475 solver.cpp:222] Iteration 25680 (1.27707 iter/s, 31.3217s/40 iters), loss = 1.62398
I1028 23:23:14.505846 29475 solver.cpp:241]     Train net output #0: loss = 1.62398 (* 1 = 1.62398 loss)
I1028 23:23:14.505862 29475 sgd_solver.cpp:105] Iteration 25680, lr = 0.00679888
I1028 23:23:45.747752 29475 solver.cpp:222] Iteration 25720 (1.28038 iter/s, 31.2407s/40 iters), loss = 1.78139
I1028 23:23:45.747944 29475 solver.cpp:241]     Train net output #0: loss = 1.78139 (* 1 = 1.78139 loss)
I1028 23:23:45.747962 29475 sgd_solver.cpp:105] Iteration 25720, lr = 0.00679412
I1028 23:24:16.651813 29475 solver.cpp:222] Iteration 25760 (1.29439 iter/s, 30.9027s/40 iters), loss = 1.74563
I1028 23:24:16.652014 29475 solver.cpp:241]     Train net output #0: loss = 1.74563 (* 1 = 1.74563 loss)
I1028 23:24:16.652030 29475 sgd_solver.cpp:105] Iteration 25760, lr = 0.00678937
I1028 23:24:47.306607 29475 solver.cpp:222] Iteration 25800 (1.30491 iter/s, 30.6534s/40 iters), loss = 1.47651
I1028 23:24:47.306782 29475 solver.cpp:241]     Train net output #0: loss = 1.47651 (* 1 = 1.47651 loss)
I1028 23:24:47.306797 29475 sgd_solver.cpp:105] Iteration 25800, lr = 0.00678461
I1028 23:25:17.830085 29475 solver.cpp:222] Iteration 25840 (1.31052 iter/s, 30.5221s/40 iters), loss = 1.48216
I1028 23:25:17.830256 29475 solver.cpp:241]     Train net output #0: loss = 1.48216 (* 1 = 1.48216 loss)
I1028 23:25:17.830276 29475 sgd_solver.cpp:105] Iteration 25840, lr = 0.00677986
I1028 23:25:48.818198 29475 solver.cpp:222] Iteration 25880 (1.29087 iter/s, 30.9868s/40 iters), loss = 1.76199
I1028 23:25:48.818408 29475 solver.cpp:241]     Train net output #0: loss = 1.76199 (* 1 = 1.76199 loss)
I1028 23:25:48.818425 29475 sgd_solver.cpp:105] Iteration 25880, lr = 0.0067751
I1028 23:26:19.457855 29475 solver.cpp:222] Iteration 25920 (1.30556 iter/s, 30.6382s/40 iters), loss = 1.67249
I1028 23:26:19.458058 29475 solver.cpp:241]     Train net output #0: loss = 1.67249 (* 1 = 1.67249 loss)
I1028 23:26:19.458076 29475 sgd_solver.cpp:105] Iteration 25920, lr = 0.00677035
I1028 23:26:49.693336 29475 solver.cpp:222] Iteration 25960 (1.32301 iter/s, 30.2341s/40 iters), loss = 1.71806
I1028 23:26:49.693506 29475 solver.cpp:241]     Train net output #0: loss = 1.71806 (* 1 = 1.71806 loss)
I1028 23:26:49.693522 29475 sgd_solver.cpp:105] Iteration 25960, lr = 0.0067656
I1028 23:27:19.317436 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_26000.caffemodel
I1028 23:27:19.353111 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_26000.solverstate
I1028 23:27:19.374660 29475 solver.cpp:334] Iteration 26000, Testing net (#0)
I1028 23:27:51.169617 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54676
I1028 23:27:51.169790 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7864
I1028 23:27:51.169806 29475 solver.cpp:401]     Test net output #2: loss = 2.08786 (* 1 = 2.08786 loss)
I1028 23:27:51.937309 29475 solver.cpp:222] Iteration 26000 (0.642658 iter/s, 62.2415s/40 iters), loss = 1.90846
I1028 23:27:51.937386 29475 solver.cpp:241]     Train net output #0: loss = 1.90846 (* 1 = 1.90846 loss)
I1028 23:27:51.937403 29475 sgd_solver.cpp:105] Iteration 26000, lr = 0.00676085
I1028 23:28:22.804867 29475 solver.cpp:222] Iteration 26040 (1.29591 iter/s, 30.8663s/40 iters), loss = 1.64194
I1028 23:28:22.805063 29475 solver.cpp:241]     Train net output #0: loss = 1.64194 (* 1 = 1.64194 loss)
I1028 23:28:22.805081 29475 sgd_solver.cpp:105] Iteration 26040, lr = 0.0067561
I1028 23:28:53.994312 29475 solver.cpp:222] Iteration 26080 (1.28255 iter/s, 31.1879s/40 iters), loss = 1.91032
I1028 23:28:53.994560 29475 solver.cpp:241]     Train net output #0: loss = 1.91032 (* 1 = 1.91032 loss)
I1028 23:28:53.994592 29475 sgd_solver.cpp:105] Iteration 26080, lr = 0.00675135
I1028 23:29:26.840781 29475 solver.cpp:222] Iteration 26120 (1.21784 iter/s, 32.845s/40 iters), loss = 2.04393
I1028 23:29:26.840978 29475 solver.cpp:241]     Train net output #0: loss = 2.04393 (* 1 = 2.04393 loss)
I1028 23:29:26.840997 29475 sgd_solver.cpp:105] Iteration 26120, lr = 0.0067466
I1028 23:29:58.004524 29475 solver.cpp:222] Iteration 26160 (1.2836 iter/s, 31.1624s/40 iters), loss = 1.7356
I1028 23:29:58.004709 29475 solver.cpp:241]     Train net output #0: loss = 1.7356 (* 1 = 1.7356 loss)
I1028 23:29:58.004726 29475 sgd_solver.cpp:105] Iteration 26160, lr = 0.00674185
I1028 23:30:28.923246 29475 solver.cpp:222] Iteration 26200 (1.29377 iter/s, 30.9174s/40 iters), loss = 2.06712
I1028 23:30:28.923468 29475 solver.cpp:241]     Train net output #0: loss = 2.06712 (* 1 = 2.06712 loss)
I1028 23:30:28.923485 29475 sgd_solver.cpp:105] Iteration 26200, lr = 0.0067371
I1028 23:31:00.679327 29475 solver.cpp:222] Iteration 26240 (1.25966 iter/s, 31.7546s/40 iters), loss = 1.6824
I1028 23:31:00.679498 29475 solver.cpp:241]     Train net output #0: loss = 1.6824 (* 1 = 1.6824 loss)
I1028 23:31:00.679515 29475 sgd_solver.cpp:105] Iteration 26240, lr = 0.00673236
I1028 23:31:32.597395 29475 solver.cpp:222] Iteration 26280 (1.25326 iter/s, 31.9167s/40 iters), loss = 1.55023
I1028 23:31:32.597615 29475 solver.cpp:241]     Train net output #0: loss = 1.55023 (* 1 = 1.55023 loss)
I1028 23:31:32.597631 29475 sgd_solver.cpp:105] Iteration 26280, lr = 0.00672761
I1028 23:32:04.035606 29475 solver.cpp:222] Iteration 26320 (1.27239 iter/s, 31.4368s/40 iters), loss = 1.44996
I1028 23:32:04.035879 29475 solver.cpp:241]     Train net output #0: loss = 1.44996 (* 1 = 1.44996 loss)
I1028 23:32:04.035917 29475 sgd_solver.cpp:105] Iteration 26320, lr = 0.00672287
I1028 23:32:35.326728 29475 solver.cpp:222] Iteration 26360 (1.27838 iter/s, 31.2896s/40 iters), loss = 1.79741
I1028 23:32:35.326898 29475 solver.cpp:241]     Train net output #0: loss = 1.79741 (* 1 = 1.79741 loss)
I1028 23:32:35.326917 29475 sgd_solver.cpp:105] Iteration 26360, lr = 0.00671812
I1028 23:33:06.680147 29475 solver.cpp:222] Iteration 26400 (1.27583 iter/s, 31.3521s/40 iters), loss = 1.61238
I1028 23:33:06.680330 29475 solver.cpp:241]     Train net output #0: loss = 1.61238 (* 1 = 1.61238 loss)
I1028 23:33:06.680351 29475 sgd_solver.cpp:105] Iteration 26400, lr = 0.00671338
I1028 23:33:37.622092 29475 solver.cpp:222] Iteration 26440 (1.2928 iter/s, 30.9406s/40 iters), loss = 1.57293
I1028 23:33:37.622320 29475 solver.cpp:241]     Train net output #0: loss = 1.57293 (* 1 = 1.57293 loss)
I1028 23:33:37.622341 29475 sgd_solver.cpp:105] Iteration 26440, lr = 0.00670864
I1028 23:34:08.448675 29475 solver.cpp:222] Iteration 26480 (1.29764 iter/s, 30.8252s/40 iters), loss = 2.02999
I1028 23:34:08.448848 29475 solver.cpp:241]     Train net output #0: loss = 2.02999 (* 1 = 2.02999 loss)
I1028 23:34:08.448868 29475 sgd_solver.cpp:105] Iteration 26480, lr = 0.00670389
I1028 23:34:23.172015 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_26500.caffemodel
I1028 23:34:23.206542 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_26500.solverstate
I1028 23:34:23.223373 29475 solver.cpp:334] Iteration 26500, Testing net (#0)
I1028 23:34:54.091292 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 23:34:54.299916 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54756
I1028 23:34:54.299981 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78824
I1028 23:34:54.299995 29475 solver.cpp:401]     Test net output #2: loss = 2.05655 (* 1 = 2.05655 loss)
I1028 23:35:10.814165 29475 solver.cpp:222] Iteration 26520 (0.641406 iter/s, 62.363s/40 iters), loss = 1.68251
I1028 23:35:10.814247 29475 solver.cpp:241]     Train net output #0: loss = 1.68251 (* 1 = 1.68251 loss)
I1028 23:35:10.814265 29475 sgd_solver.cpp:105] Iteration 26520, lr = 0.00669915
I1028 23:35:41.689321 29475 solver.cpp:222] Iteration 26560 (1.29559 iter/s, 30.8739s/40 iters), loss = 1.53021
I1028 23:35:41.689522 29475 solver.cpp:241]     Train net output #0: loss = 1.53021 (* 1 = 1.53021 loss)
I1028 23:35:41.689538 29475 sgd_solver.cpp:105] Iteration 26560, lr = 0.00669441
I1028 23:36:12.819777 29475 solver.cpp:222] Iteration 26600 (1.28498 iter/s, 31.129s/40 iters), loss = 1.9845
I1028 23:36:12.819969 29475 solver.cpp:241]     Train net output #0: loss = 1.9845 (* 1 = 1.9845 loss)
I1028 23:36:12.819986 29475 sgd_solver.cpp:105] Iteration 26600, lr = 0.00668967
I1028 23:36:43.976670 29475 solver.cpp:222] Iteration 26640 (1.28388 iter/s, 31.1555s/40 iters), loss = 1.50446
I1028 23:36:43.976853 29475 solver.cpp:241]     Train net output #0: loss = 1.50446 (* 1 = 1.50446 loss)
I1028 23:36:43.976871 29475 sgd_solver.cpp:105] Iteration 26640, lr = 0.00668493
I1028 23:37:14.985981 29475 solver.cpp:222] Iteration 26680 (1.28999 iter/s, 31.008s/40 iters), loss = 1.90131
I1028 23:37:14.986207 29475 solver.cpp:241]     Train net output #0: loss = 1.90131 (* 1 = 1.90131 loss)
I1028 23:37:14.986224 29475 sgd_solver.cpp:105] Iteration 26680, lr = 0.0066802
I1028 23:37:45.585074 29475 solver.cpp:222] Iteration 26720 (1.30729 iter/s, 30.5977s/40 iters), loss = 1.67863
I1028 23:37:45.585247 29475 solver.cpp:241]     Train net output #0: loss = 1.67863 (* 1 = 1.67863 loss)
I1028 23:37:45.585264 29475 sgd_solver.cpp:105] Iteration 26720, lr = 0.00667546
I1028 23:38:16.520143 29475 solver.cpp:222] Iteration 26760 (1.29309 iter/s, 30.9337s/40 iters), loss = 1.4017
I1028 23:38:16.520380 29475 solver.cpp:241]     Train net output #0: loss = 1.4017 (* 1 = 1.4017 loss)
I1028 23:38:16.520396 29475 sgd_solver.cpp:105] Iteration 26760, lr = 0.00667072
I1028 23:38:47.754642 29475 solver.cpp:222] Iteration 26800 (1.28069 iter/s, 31.2331s/40 iters), loss = 1.83395
I1028 23:38:47.754901 29475 solver.cpp:241]     Train net output #0: loss = 1.83395 (* 1 = 1.83395 loss)
I1028 23:38:47.754926 29475 sgd_solver.cpp:105] Iteration 26800, lr = 0.00666599
I1028 23:39:18.726330 29475 solver.cpp:222] Iteration 26840 (1.29156 iter/s, 30.9702s/40 iters), loss = 1.5644
I1028 23:39:18.726505 29475 solver.cpp:241]     Train net output #0: loss = 1.5644 (* 1 = 1.5644 loss)
I1028 23:39:18.726521 29475 sgd_solver.cpp:105] Iteration 26840, lr = 0.00666125
I1028 23:39:49.624212 29475 solver.cpp:222] Iteration 26880 (1.29465 iter/s, 30.8965s/40 iters), loss = 1.65613
I1028 23:39:49.624387 29475 solver.cpp:241]     Train net output #0: loss = 1.65613 (* 1 = 1.65613 loss)
I1028 23:39:49.624405 29475 sgd_solver.cpp:105] Iteration 26880, lr = 0.00665652
I1028 23:40:20.225210 29475 solver.cpp:222] Iteration 26920 (1.3072 iter/s, 30.5997s/40 iters), loss = 1.49113
I1028 23:40:20.225412 29475 solver.cpp:241]     Train net output #0: loss = 1.49113 (* 1 = 1.49113 loss)
I1028 23:40:20.225428 29475 sgd_solver.cpp:105] Iteration 26920, lr = 0.00665178
I1028 23:40:51.106379 29475 solver.cpp:222] Iteration 26960 (1.29535 iter/s, 30.8797s/40 iters), loss = 1.6718
I1028 23:40:51.106590 29475 solver.cpp:241]     Train net output #0: loss = 1.6718 (* 1 = 1.6718 loss)
I1028 23:40:51.106613 29475 sgd_solver.cpp:105] Iteration 26960, lr = 0.00664705
I1028 23:41:23.992260 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_27000.caffemodel
I1028 23:41:24.038688 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_27000.solverstate
I1028 23:41:24.062357 29475 solver.cpp:334] Iteration 27000, Testing net (#0)
I1028 23:41:55.091995 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55308
I1028 23:41:55.092181 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7852
I1028 23:41:55.092196 29475 solver.cpp:401]     Test net output #2: loss = 2.00798 (* 1 = 2.00798 loss)
I1028 23:41:55.865547 29475 solver.cpp:222] Iteration 27000 (0.617698 iter/s, 64.7565s/40 iters), loss = 1.73597
I1028 23:41:55.865623 29475 solver.cpp:241]     Train net output #0: loss = 1.73597 (* 1 = 1.73597 loss)
I1028 23:41:55.865640 29475 sgd_solver.cpp:105] Iteration 27000, lr = 0.00664232
I1028 23:42:27.486971 29475 solver.cpp:222] Iteration 27040 (1.26502 iter/s, 31.6201s/40 iters), loss = 1.92421
I1028 23:42:27.487149 29475 solver.cpp:241]     Train net output #0: loss = 1.92421 (* 1 = 1.92421 loss)
I1028 23:42:27.487165 29475 sgd_solver.cpp:105] Iteration 27040, lr = 0.00663759
I1028 23:42:58.184551 29475 solver.cpp:222] Iteration 27080 (1.30309 iter/s, 30.6962s/40 iters), loss = 1.82957
I1028 23:42:58.184733 29475 solver.cpp:241]     Train net output #0: loss = 1.82957 (* 1 = 1.82957 loss)
I1028 23:42:58.184751 29475 sgd_solver.cpp:105] Iteration 27080, lr = 0.00663286
I1028 23:43:28.987831 29475 solver.cpp:222] Iteration 27120 (1.29862 iter/s, 30.8019s/40 iters), loss = 1.37413
I1028 23:43:28.987996 29475 solver.cpp:241]     Train net output #0: loss = 1.37413 (* 1 = 1.37413 loss)
I1028 23:43:28.988014 29475 sgd_solver.cpp:105] Iteration 27120, lr = 0.00662813
I1028 23:44:00.418226 29475 solver.cpp:222] Iteration 27160 (1.27271 iter/s, 31.429s/40 iters), loss = 1.54718
I1028 23:44:00.418417 29475 solver.cpp:241]     Train net output #0: loss = 1.54718 (* 1 = 1.54718 loss)
I1028 23:44:00.418433 29475 sgd_solver.cpp:105] Iteration 27160, lr = 0.0066234
I1028 23:44:31.534988 29475 solver.cpp:222] Iteration 27200 (1.28554 iter/s, 31.1154s/40 iters), loss = 1.7652
I1028 23:44:31.535154 29475 solver.cpp:241]     Train net output #0: loss = 1.7652 (* 1 = 1.7652 loss)
I1028 23:44:31.535171 29475 sgd_solver.cpp:105] Iteration 27200, lr = 0.00661867
I1028 23:45:02.989878 29475 solver.cpp:222] Iteration 27240 (1.27172 iter/s, 31.4535s/40 iters), loss = 1.74121
I1028 23:45:02.990140 29475 solver.cpp:241]     Train net output #0: loss = 1.74121 (* 1 = 1.74121 loss)
I1028 23:45:02.990173 29475 sgd_solver.cpp:105] Iteration 27240, lr = 0.00661394
I1028 23:45:33.750033 29475 solver.cpp:222] Iteration 27280 (1.30044 iter/s, 30.7587s/40 iters), loss = 1.54481
I1028 23:45:33.750211 29475 solver.cpp:241]     Train net output #0: loss = 1.54481 (* 1 = 1.54481 loss)
I1028 23:45:33.750226 29475 sgd_solver.cpp:105] Iteration 27280, lr = 0.00660922
I1028 23:46:05.254681 29475 solver.cpp:222] Iteration 27320 (1.26971 iter/s, 31.5032s/40 iters), loss = 1.62018
I1028 23:46:05.254946 29475 solver.cpp:241]     Train net output #0: loss = 1.62018 (* 1 = 1.62018 loss)
I1028 23:46:05.254976 29475 sgd_solver.cpp:105] Iteration 27320, lr = 0.00660449
I1028 23:46:37.408640 29475 solver.cpp:222] Iteration 27360 (1.24407 iter/s, 32.1525s/40 iters), loss = 1.78444
I1028 23:46:37.408823 29475 solver.cpp:241]     Train net output #0: loss = 1.78444 (* 1 = 1.78444 loss)
I1028 23:46:37.408840 29475 sgd_solver.cpp:105] Iteration 27360, lr = 0.00659977
I1028 23:47:08.296528 29475 solver.cpp:222] Iteration 27400 (1.29506 iter/s, 30.8865s/40 iters), loss = 1.61827
I1028 23:47:08.296707 29475 solver.cpp:241]     Train net output #0: loss = 1.61827 (* 1 = 1.61827 loss)
I1028 23:47:08.296723 29475 sgd_solver.cpp:105] Iteration 27400, lr = 0.00659504
I1028 23:47:39.515882 29475 solver.cpp:222] Iteration 27440 (1.28131 iter/s, 31.218s/40 iters), loss = 1.91772
I1028 23:47:39.516052 29475 solver.cpp:241]     Train net output #0: loss = 1.91772 (* 1 = 1.91772 loss)
I1028 23:47:39.516069 29475 sgd_solver.cpp:105] Iteration 27440, lr = 0.00659032
I1028 23:48:10.916498 29475 solver.cpp:222] Iteration 27480 (1.27392 iter/s, 31.3993s/40 iters), loss = 1.73381
I1028 23:48:10.916710 29475 solver.cpp:241]     Train net output #0: loss = 1.73381 (* 1 = 1.73381 loss)
I1028 23:48:10.916728 29475 sgd_solver.cpp:105] Iteration 27480, lr = 0.0065856
I1028 23:48:25.625478 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_27500.caffemodel
I1028 23:48:25.660764 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_27500.solverstate
I1028 23:48:25.678966 29475 solver.cpp:334] Iteration 27500, Testing net (#0)
I1028 23:48:56.458323 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1028 23:48:56.667050 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54476
I1028 23:48:56.667114 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7862
I1028 23:48:56.667126 29475 solver.cpp:401]     Test net output #2: loss = 2.0229 (* 1 = 2.0229 loss)
I1028 23:49:13.016450 29475 solver.cpp:222] Iteration 27520 (0.644149 iter/s, 62.0974s/40 iters), loss = 1.62442
I1028 23:49:13.016525 29475 solver.cpp:241]     Train net output #0: loss = 1.62442 (* 1 = 1.62442 loss)
I1028 23:49:13.016541 29475 sgd_solver.cpp:105] Iteration 27520, lr = 0.00658087
I1028 23:49:13.878996 29523 data_layer.cpp:73] Restarting data prefetching from start.
I1028 23:49:44.272475 29475 solver.cpp:222] Iteration 27560 (1.27981 iter/s, 31.2548s/40 iters), loss = 1.73255
I1028 23:49:44.272665 29475 solver.cpp:241]     Train net output #0: loss = 1.73255 (* 1 = 1.73255 loss)
I1028 23:49:44.272681 29475 sgd_solver.cpp:105] Iteration 27560, lr = 0.00657615
I1028 23:50:15.325996 29475 solver.cpp:222] Iteration 27600 (1.28816 iter/s, 31.0522s/40 iters), loss = 1.92181
I1028 23:50:15.326203 29475 solver.cpp:241]     Train net output #0: loss = 1.92181 (* 1 = 1.92181 loss)
I1028 23:50:15.326220 29475 sgd_solver.cpp:105] Iteration 27600, lr = 0.00657143
I1028 23:50:46.314170 29475 solver.cpp:222] Iteration 27640 (1.29087 iter/s, 30.9868s/40 iters), loss = 1.61695
I1028 23:50:46.314465 29475 solver.cpp:241]     Train net output #0: loss = 1.61695 (* 1 = 1.61695 loss)
I1028 23:50:46.314482 29475 sgd_solver.cpp:105] Iteration 27640, lr = 0.00656671
I1028 23:51:17.327467 29475 solver.cpp:222] Iteration 27680 (1.28983 iter/s, 31.0118s/40 iters), loss = 1.66357
I1028 23:51:17.327703 29475 solver.cpp:241]     Train net output #0: loss = 1.66357 (* 1 = 1.66357 loss)
I1028 23:51:17.327720 29475 sgd_solver.cpp:105] Iteration 27680, lr = 0.006562
I1028 23:51:48.309514 29475 solver.cpp:222] Iteration 27720 (1.29113 iter/s, 30.9806s/40 iters), loss = 1.43913
I1028 23:51:48.309720 29475 solver.cpp:241]     Train net output #0: loss = 1.43913 (* 1 = 1.43913 loss)
I1028 23:51:48.309737 29475 sgd_solver.cpp:105] Iteration 27720, lr = 0.00655728
I1028 23:52:18.933374 29475 solver.cpp:222] Iteration 27760 (1.30623 iter/s, 30.6225s/40 iters), loss = 1.47914
I1028 23:52:18.933539 29475 solver.cpp:241]     Train net output #0: loss = 1.47914 (* 1 = 1.47914 loss)
I1028 23:52:18.933558 29475 sgd_solver.cpp:105] Iteration 27760, lr = 0.00655256
I1028 23:52:49.471930 29475 solver.cpp:222] Iteration 27800 (1.30988 iter/s, 30.5372s/40 iters), loss = 1.74137
I1028 23:52:49.472088 29475 solver.cpp:241]     Train net output #0: loss = 1.74137 (* 1 = 1.74137 loss)
I1028 23:52:49.472105 29475 sgd_solver.cpp:105] Iteration 27800, lr = 0.00654784
I1028 23:53:20.125345 29475 solver.cpp:222] Iteration 27840 (1.30497 iter/s, 30.6521s/40 iters), loss = 1.77509
I1028 23:53:20.125562 29475 solver.cpp:241]     Train net output #0: loss = 1.77509 (* 1 = 1.77509 loss)
I1028 23:53:20.125581 29475 sgd_solver.cpp:105] Iteration 27840, lr = 0.00654313
I1028 23:53:51.115049 29475 solver.cpp:222] Iteration 27880 (1.29081 iter/s, 30.9883s/40 iters), loss = 1.94428
I1028 23:53:51.115211 29475 solver.cpp:241]     Train net output #0: loss = 1.94428 (* 1 = 1.94428 loss)
I1028 23:53:51.115228 29475 sgd_solver.cpp:105] Iteration 27880, lr = 0.00653841
I1028 23:54:22.541749 29475 solver.cpp:222] Iteration 27920 (1.27286 iter/s, 31.4253s/40 iters), loss = 1.88122
I1028 23:54:22.541944 29475 solver.cpp:241]     Train net output #0: loss = 1.88122 (* 1 = 1.88122 loss)
I1028 23:54:22.541961 29475 sgd_solver.cpp:105] Iteration 27920, lr = 0.0065337
I1028 23:54:53.171681 29475 solver.cpp:222] Iteration 27960 (1.30597 iter/s, 30.6286s/40 iters), loss = 1.60854
I1028 23:54:53.171878 29475 solver.cpp:241]     Train net output #0: loss = 1.60854 (* 1 = 1.60854 loss)
I1028 23:54:53.171896 29475 sgd_solver.cpp:105] Iteration 27960, lr = 0.00652899
I1028 23:55:22.937063 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_28000.caffemodel
I1028 23:55:22.971415 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_28000.solverstate
I1028 23:55:22.988171 29475 solver.cpp:334] Iteration 28000, Testing net (#0)
I1028 23:55:53.944021 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54636
I1028 23:55:53.944222 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7836
I1028 23:55:53.944236 29475 solver.cpp:401]     Test net output #2: loss = 2.03085 (* 1 = 2.03085 loss)
I1028 23:55:54.718807 29475 solver.cpp:222] Iteration 28000 (0.649935 iter/s, 61.5446s/40 iters), loss = 1.34745
I1028 23:55:54.718883 29475 solver.cpp:241]     Train net output #0: loss = 1.34745 (* 1 = 1.34745 loss)
I1028 23:55:54.718899 29475 sgd_solver.cpp:105] Iteration 28000, lr = 0.00652428
I1028 23:56:26.779845 29475 solver.cpp:222] Iteration 28040 (1.24767 iter/s, 32.0597s/40 iters), loss = 1.53511
I1028 23:56:26.780115 29475 solver.cpp:241]     Train net output #0: loss = 1.53511 (* 1 = 1.53511 loss)
I1028 23:56:26.780136 29475 sgd_solver.cpp:105] Iteration 28040, lr = 0.00651956
I1028 23:56:58.512892 29475 solver.cpp:222] Iteration 28080 (1.26057 iter/s, 31.7316s/40 iters), loss = 1.61166
I1028 23:56:58.513070 29475 solver.cpp:241]     Train net output #0: loss = 1.61166 (* 1 = 1.61166 loss)
I1028 23:56:58.513087 29475 sgd_solver.cpp:105] Iteration 28080, lr = 0.00651485
I1028 23:57:30.333781 29475 solver.cpp:222] Iteration 28120 (1.25709 iter/s, 31.8195s/40 iters), loss = 1.51478
I1028 23:57:30.333962 29475 solver.cpp:241]     Train net output #0: loss = 1.51478 (* 1 = 1.51478 loss)
I1028 23:57:30.333977 29475 sgd_solver.cpp:105] Iteration 28120, lr = 0.00651014
I1028 23:58:01.514989 29475 solver.cpp:222] Iteration 28160 (1.28288 iter/s, 31.1798s/40 iters), loss = 1.76688
I1028 23:58:01.515254 29475 solver.cpp:241]     Train net output #0: loss = 1.76688 (* 1 = 1.76688 loss)
I1028 23:58:01.515292 29475 sgd_solver.cpp:105] Iteration 28160, lr = 0.00650543
I1028 23:58:32.720676 29475 solver.cpp:222] Iteration 28200 (1.28188 iter/s, 31.2042s/40 iters), loss = 1.21976
I1028 23:58:32.720867 29475 solver.cpp:241]     Train net output #0: loss = 1.21976 (* 1 = 1.21976 loss)
I1028 23:58:32.720885 29475 sgd_solver.cpp:105] Iteration 28200, lr = 0.00650072
I1028 23:59:03.693648 29475 solver.cpp:222] Iteration 28240 (1.29151 iter/s, 30.9716s/40 iters), loss = 1.47518
I1028 23:59:03.693837 29475 solver.cpp:241]     Train net output #0: loss = 1.47518 (* 1 = 1.47518 loss)
I1028 23:59:03.693853 29475 sgd_solver.cpp:105] Iteration 28240, lr = 0.00649602
I1028 23:59:35.032124 29475 solver.cpp:222] Iteration 28280 (1.27644 iter/s, 31.3371s/40 iters), loss = 1.80287
I1028 23:59:35.032320 29475 solver.cpp:241]     Train net output #0: loss = 1.80287 (* 1 = 1.80287 loss)
I1028 23:59:35.032337 29475 sgd_solver.cpp:105] Iteration 28280, lr = 0.00649131
I1029 00:00:06.317404 29475 solver.cpp:222] Iteration 28320 (1.27862 iter/s, 31.2838s/40 iters), loss = 1.62627
I1029 00:00:06.317600 29475 solver.cpp:241]     Train net output #0: loss = 1.62627 (* 1 = 1.62627 loss)
I1029 00:00:06.317618 29475 sgd_solver.cpp:105] Iteration 28320, lr = 0.0064866
I1029 00:00:38.004362 29475 solver.cpp:222] Iteration 28360 (1.26241 iter/s, 31.6855s/40 iters), loss = 1.69716
I1029 00:00:38.004580 29475 solver.cpp:241]     Train net output #0: loss = 1.69716 (* 1 = 1.69716 loss)
I1029 00:00:38.004606 29475 sgd_solver.cpp:105] Iteration 28360, lr = 0.0064819
I1029 00:01:10.742537 29475 solver.cpp:222] Iteration 28400 (1.22187 iter/s, 32.7367s/40 iters), loss = 1.67953
I1029 00:01:10.742755 29475 solver.cpp:241]     Train net output #0: loss = 1.67953 (* 1 = 1.67953 loss)
I1029 00:01:10.742774 29475 sgd_solver.cpp:105] Iteration 28400, lr = 0.00647719
I1029 00:01:42.230849 29475 solver.cpp:222] Iteration 28440 (1.27037 iter/s, 31.4869s/40 iters), loss = 1.52952
I1029 00:01:42.231045 29475 solver.cpp:241]     Train net output #0: loss = 1.52952 (* 1 = 1.52952 loss)
I1029 00:01:42.231063 29475 sgd_solver.cpp:105] Iteration 28440, lr = 0.00647249
I1029 00:02:13.584626 29475 solver.cpp:222] Iteration 28480 (1.27582 iter/s, 31.3524s/40 iters), loss = 1.58683
I1029 00:02:13.584830 29475 solver.cpp:241]     Train net output #0: loss = 1.58683 (* 1 = 1.58683 loss)
I1029 00:02:13.584847 29475 sgd_solver.cpp:105] Iteration 28480, lr = 0.00646779
I1029 00:02:28.422688 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_28500.caffemodel
I1029 00:02:28.456537 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_28500.solverstate
I1029 00:02:28.478376 29475 solver.cpp:334] Iteration 28500, Testing net (#0)
I1029 00:02:59.258177 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 00:02:59.465221 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5466
I1029 00:02:59.465286 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.785639
I1029 00:02:59.465302 29475 solver.cpp:401]     Test net output #2: loss = 2.01403 (* 1 = 2.01403 loss)
I1029 00:03:15.626112 29475 solver.cpp:222] Iteration 28520 (0.644756 iter/s, 62.0389s/40 iters), loss = 1.85738
I1029 00:03:15.626194 29475 solver.cpp:241]     Train net output #0: loss = 1.85738 (* 1 = 1.85738 loss)
I1029 00:03:15.626210 29475 sgd_solver.cpp:105] Iteration 28520, lr = 0.00646309
I1029 00:03:46.559252 29475 solver.cpp:222] Iteration 28560 (1.29317 iter/s, 30.9318s/40 iters), loss = 1.45756
I1029 00:03:46.559453 29475 solver.cpp:241]     Train net output #0: loss = 1.45756 (* 1 = 1.45756 loss)
I1029 00:03:46.559470 29475 sgd_solver.cpp:105] Iteration 28560, lr = 0.00645838
I1029 00:04:17.960947 29475 solver.cpp:222] Iteration 28600 (1.27388 iter/s, 31.4002s/40 iters), loss = 2.05888
I1029 00:04:17.961197 29475 solver.cpp:241]     Train net output #0: loss = 2.05888 (* 1 = 2.05888 loss)
I1029 00:04:17.961216 29475 sgd_solver.cpp:105] Iteration 28600, lr = 0.00645368
I1029 00:04:49.028529 29475 solver.cpp:222] Iteration 28640 (1.28758 iter/s, 31.0662s/40 iters), loss = 2.02271
I1029 00:04:49.028712 29475 solver.cpp:241]     Train net output #0: loss = 2.02271 (* 1 = 2.02271 loss)
I1029 00:04:49.028729 29475 sgd_solver.cpp:105] Iteration 28640, lr = 0.00644898
I1029 00:05:19.801690 29475 solver.cpp:222] Iteration 28680 (1.29989 iter/s, 30.7718s/40 iters), loss = 1.27736
I1029 00:05:19.801864 29475 solver.cpp:241]     Train net output #0: loss = 1.27736 (* 1 = 1.27736 loss)
I1029 00:05:19.801882 29475 sgd_solver.cpp:105] Iteration 28680, lr = 0.00644428
I1029 00:05:50.574138 29475 solver.cpp:222] Iteration 28720 (1.29992 iter/s, 30.7711s/40 iters), loss = 1.87608
I1029 00:05:50.574322 29475 solver.cpp:241]     Train net output #0: loss = 1.87608 (* 1 = 1.87608 loss)
I1029 00:05:50.574340 29475 sgd_solver.cpp:105] Iteration 28720, lr = 0.00643959
I1029 00:06:21.349498 29475 solver.cpp:222] Iteration 28760 (1.2998 iter/s, 30.7739s/40 iters), loss = 1.52671
I1029 00:06:21.349673 29475 solver.cpp:241]     Train net output #0: loss = 1.52671 (* 1 = 1.52671 loss)
I1029 00:06:21.349690 29475 sgd_solver.cpp:105] Iteration 28760, lr = 0.00643489
I1029 00:06:52.144708 29475 solver.cpp:222] Iteration 28800 (1.29896 iter/s, 30.7939s/40 iters), loss = 1.83338
I1029 00:06:52.144928 29475 solver.cpp:241]     Train net output #0: loss = 1.83338 (* 1 = 1.83338 loss)
I1029 00:06:52.144948 29475 sgd_solver.cpp:105] Iteration 28800, lr = 0.00643019
I1029 00:07:23.706765 29475 solver.cpp:222] Iteration 28840 (1.2674 iter/s, 31.5606s/40 iters), loss = 1.645
I1029 00:07:23.706949 29475 solver.cpp:241]     Train net output #0: loss = 1.645 (* 1 = 1.645 loss)
I1029 00:07:23.706965 29475 sgd_solver.cpp:105] Iteration 28840, lr = 0.0064255
I1029 00:07:55.004629 29475 solver.cpp:222] Iteration 28880 (1.2781 iter/s, 31.2964s/40 iters), loss = 1.33788
I1029 00:07:55.004844 29475 solver.cpp:241]     Train net output #0: loss = 1.33788 (* 1 = 1.33788 loss)
I1029 00:07:55.004863 29475 sgd_solver.cpp:105] Iteration 28880, lr = 0.0064208
I1029 00:08:26.154561 29475 solver.cpp:222] Iteration 28920 (1.28417 iter/s, 31.1485s/40 iters), loss = 1.82068
I1029 00:08:26.154741 29475 solver.cpp:241]     Train net output #0: loss = 1.82068 (* 1 = 1.82068 loss)
I1029 00:08:26.154757 29475 sgd_solver.cpp:105] Iteration 28920, lr = 0.00641611
I1029 00:08:56.874251 29475 solver.cpp:222] Iteration 28960 (1.30215 iter/s, 30.7183s/40 iters), loss = 1.80076
I1029 00:08:56.874429 29475 solver.cpp:241]     Train net output #0: loss = 1.80076 (* 1 = 1.80076 loss)
I1029 00:08:56.874446 29475 sgd_solver.cpp:105] Iteration 28960, lr = 0.00641141
I1029 00:09:26.763586 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_29000.caffemodel
I1029 00:09:26.804392 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_29000.solverstate
I1029 00:09:26.827729 29475 solver.cpp:334] Iteration 29000, Testing net (#0)
I1029 00:09:57.868765 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.554
I1029 00:09:57.868964 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.787
I1029 00:09:57.868979 29475 solver.cpp:401]     Test net output #2: loss = 1.98063 (* 1 = 1.98063 loss)
I1029 00:09:58.645123 29475 solver.cpp:222] Iteration 29000 (0.647581 iter/s, 61.7684s/40 iters), loss = 1.7342
I1029 00:09:58.645196 29475 solver.cpp:241]     Train net output #0: loss = 1.7342 (* 1 = 1.7342 loss)
I1029 00:09:58.645212 29475 sgd_solver.cpp:105] Iteration 29000, lr = 0.00640672
I1029 00:10:29.151170 29475 solver.cpp:222] Iteration 29040 (1.31127 iter/s, 30.5047s/40 iters), loss = 1.77243
I1029 00:10:29.151414 29475 solver.cpp:241]     Train net output #0: loss = 1.77243 (* 1 = 1.77243 loss)
I1029 00:10:29.151444 29475 sgd_solver.cpp:105] Iteration 29040, lr = 0.00640203
I1029 00:11:00.586005 29475 solver.cpp:222] Iteration 29080 (1.27253 iter/s, 31.4333s/40 iters), loss = 1.54567
I1029 00:11:00.586168 29475 solver.cpp:241]     Train net output #0: loss = 1.54567 (* 1 = 1.54567 loss)
I1029 00:11:00.586185 29475 sgd_solver.cpp:105] Iteration 29080, lr = 0.00639734
I1029 00:11:31.765100 29475 solver.cpp:222] Iteration 29120 (1.28297 iter/s, 31.1777s/40 iters), loss = 1.44558
I1029 00:11:31.765347 29475 solver.cpp:241]     Train net output #0: loss = 1.44558 (* 1 = 1.44558 loss)
I1029 00:11:31.765374 29475 sgd_solver.cpp:105] Iteration 29120, lr = 0.00639265
I1029 00:12:03.402735 29475 solver.cpp:222] Iteration 29160 (1.26437 iter/s, 31.6362s/40 iters), loss = 1.6351
I1029 00:12:03.402926 29475 solver.cpp:241]     Train net output #0: loss = 1.6351 (* 1 = 1.6351 loss)
I1029 00:12:03.402942 29475 sgd_solver.cpp:105] Iteration 29160, lr = 0.00638796
I1029 00:12:34.708047 29475 solver.cpp:222] Iteration 29200 (1.27779 iter/s, 31.3039s/40 iters), loss = 1.37049
I1029 00:12:34.708235 29475 solver.cpp:241]     Train net output #0: loss = 1.37049 (* 1 = 1.37049 loss)
I1029 00:12:34.708253 29475 sgd_solver.cpp:105] Iteration 29200, lr = 0.00638327
I1029 00:13:06.398385 29475 solver.cpp:222] Iteration 29240 (1.26227 iter/s, 31.689s/40 iters), loss = 1.61202
I1029 00:13:06.398555 29475 solver.cpp:241]     Train net output #0: loss = 1.61202 (* 1 = 1.61202 loss)
I1029 00:13:06.398574 29475 sgd_solver.cpp:105] Iteration 29240, lr = 0.00637858
I1029 00:13:37.441545 29475 solver.cpp:222] Iteration 29280 (1.28858 iter/s, 31.0418s/40 iters), loss = 1.83171
I1029 00:13:37.441716 29475 solver.cpp:241]     Train net output #0: loss = 1.83171 (* 1 = 1.83171 loss)
I1029 00:13:37.441735 29475 sgd_solver.cpp:105] Iteration 29280, lr = 0.0063739
I1029 00:14:08.730495 29475 solver.cpp:222] Iteration 29320 (1.27847 iter/s, 31.2875s/40 iters), loss = 1.48175
I1029 00:14:08.730721 29475 solver.cpp:241]     Train net output #0: loss = 1.48175 (* 1 = 1.48175 loss)
I1029 00:14:08.730739 29475 sgd_solver.cpp:105] Iteration 29320, lr = 0.00636921
I1029 00:14:41.024427 29475 solver.cpp:222] Iteration 29360 (1.23868 iter/s, 32.2925s/40 iters), loss = 1.41308
I1029 00:14:41.024634 29475 solver.cpp:241]     Train net output #0: loss = 1.41308 (* 1 = 1.41308 loss)
I1029 00:14:41.024652 29475 sgd_solver.cpp:105] Iteration 29360, lr = 0.00636452
I1029 00:15:11.872598 29475 solver.cpp:222] Iteration 29400 (1.29673 iter/s, 30.8468s/40 iters), loss = 1.92627
I1029 00:15:11.872792 29475 solver.cpp:241]     Train net output #0: loss = 1.92627 (* 1 = 1.92627 loss)
I1029 00:15:11.872810 29475 sgd_solver.cpp:105] Iteration 29400, lr = 0.00635984
I1029 00:15:43.373085 29475 solver.cpp:222] Iteration 29440 (1.26988 iter/s, 31.4991s/40 iters), loss = 1.66061
I1029 00:15:43.373272 29475 solver.cpp:241]     Train net output #0: loss = 1.66061 (* 1 = 1.66061 loss)
I1029 00:15:43.373289 29475 sgd_solver.cpp:105] Iteration 29440, lr = 0.00635516
I1029 00:16:15.048023 29475 solver.cpp:222] Iteration 29480 (1.26288 iter/s, 31.6735s/40 iters), loss = 1.69497
I1029 00:16:15.048260 29475 solver.cpp:241]     Train net output #0: loss = 1.69497 (* 1 = 1.69497 loss)
I1029 00:16:15.048281 29475 sgd_solver.cpp:105] Iteration 29480, lr = 0.00635047
I1029 00:16:30.067770 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_29500.caffemodel
I1029 00:16:30.108080 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_29500.solverstate
I1029 00:16:30.131664 29475 solver.cpp:334] Iteration 29500, Testing net (#0)
I1029 00:17:00.943603 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 00:17:01.149791 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54768
I1029 00:17:01.149858 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.788799
I1029 00:17:01.149873 29475 solver.cpp:401]     Test net output #2: loss = 2.01741 (* 1 = 2.01741 loss)
I1029 00:17:17.438053 29475 solver.cpp:222] Iteration 29520 (0.641155 iter/s, 62.3874s/40 iters), loss = 1.4317
I1029 00:17:17.438124 29475 solver.cpp:241]     Train net output #0: loss = 1.4317 (* 1 = 1.4317 loss)
I1029 00:17:17.438141 29475 sgd_solver.cpp:105] Iteration 29520, lr = 0.00634579
I1029 00:17:48.294157 29475 solver.cpp:222] Iteration 29560 (1.29639 iter/s, 30.8549s/40 iters), loss = 1.94262
I1029 00:17:48.294405 29475 solver.cpp:241]     Train net output #0: loss = 1.94262 (* 1 = 1.94262 loss)
I1029 00:17:48.294425 29475 sgd_solver.cpp:105] Iteration 29560, lr = 0.00634111
I1029 00:18:19.427059 29475 solver.cpp:222] Iteration 29600 (1.28487 iter/s, 31.1315s/40 iters), loss = 1.63037
I1029 00:18:19.427253 29475 solver.cpp:241]     Train net output #0: loss = 1.63037 (* 1 = 1.63037 loss)
I1029 00:18:19.427270 29475 sgd_solver.cpp:105] Iteration 29600, lr = 0.00633643
I1029 00:18:50.517730 29475 solver.cpp:222] Iteration 29640 (1.28662 iter/s, 31.0893s/40 iters), loss = 1.70316
I1029 00:18:50.517948 29475 solver.cpp:241]     Train net output #0: loss = 1.70316 (* 1 = 1.70316 loss)
I1029 00:18:50.517971 29475 sgd_solver.cpp:105] Iteration 29640, lr = 0.00633175
I1029 00:19:21.377068 29475 solver.cpp:222] Iteration 29680 (1.29626 iter/s, 30.8579s/40 iters), loss = 1.52491
I1029 00:19:21.377240 29475 solver.cpp:241]     Train net output #0: loss = 1.52491 (* 1 = 1.52491 loss)
I1029 00:19:21.377259 29475 sgd_solver.cpp:105] Iteration 29680, lr = 0.00632707
I1029 00:19:52.420225 29475 solver.cpp:222] Iteration 29720 (1.28858 iter/s, 31.0418s/40 iters), loss = 1.75055
I1029 00:19:52.420449 29475 solver.cpp:241]     Train net output #0: loss = 1.75055 (* 1 = 1.75055 loss)
I1029 00:19:52.420467 29475 sgd_solver.cpp:105] Iteration 29720, lr = 0.00632239
I1029 00:20:24.368947 29475 solver.cpp:222] Iteration 29760 (1.25206 iter/s, 31.9473s/40 iters), loss = 1.66802
I1029 00:20:24.369199 29475 solver.cpp:241]     Train net output #0: loss = 1.66802 (* 1 = 1.66802 loss)
I1029 00:20:24.369223 29475 sgd_solver.cpp:105] Iteration 29760, lr = 0.00631771
I1029 00:20:55.480787 29475 solver.cpp:222] Iteration 29800 (1.28574 iter/s, 31.1104s/40 iters), loss = 1.94707
I1029 00:20:55.480962 29475 solver.cpp:241]     Train net output #0: loss = 1.94707 (* 1 = 1.94707 loss)
I1029 00:20:55.480978 29475 sgd_solver.cpp:105] Iteration 29800, lr = 0.00631304
I1029 00:21:26.511184 29475 solver.cpp:222] Iteration 29840 (1.28911 iter/s, 31.0291s/40 iters), loss = 1.59482
I1029 00:21:26.511387 29475 solver.cpp:241]     Train net output #0: loss = 1.59482 (* 1 = 1.59482 loss)
I1029 00:21:26.511404 29475 sgd_solver.cpp:105] Iteration 29840, lr = 0.00630836
I1029 00:21:57.269119 29475 solver.cpp:222] Iteration 29880 (1.30054 iter/s, 30.7566s/40 iters), loss = 1.70684
I1029 00:21:57.269291 29475 solver.cpp:241]     Train net output #0: loss = 1.70684 (* 1 = 1.70684 loss)
I1029 00:21:57.269314 29475 sgd_solver.cpp:105] Iteration 29880, lr = 0.00630368
I1029 00:22:27.812934 29475 solver.cpp:222] Iteration 29920 (1.30965 iter/s, 30.5425s/40 iters), loss = 1.62354
I1029 00:22:27.813093 29475 solver.cpp:241]     Train net output #0: loss = 1.62354 (* 1 = 1.62354 loss)
I1029 00:22:27.813110 29475 sgd_solver.cpp:105] Iteration 29920, lr = 0.00629901
I1029 00:22:58.464182 29475 solver.cpp:222] Iteration 29960 (1.30506 iter/s, 30.6499s/40 iters), loss = 1.53409
I1029 00:22:58.464368 29475 solver.cpp:241]     Train net output #0: loss = 1.53409 (* 1 = 1.53409 loss)
I1029 00:22:58.464385 29475 sgd_solver.cpp:105] Iteration 29960, lr = 0.00629434
I1029 00:23:28.814890 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_30000.caffemodel
I1029 00:23:28.858307 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_30000.solverstate
I1029 00:23:28.882272 29475 solver.cpp:334] Iteration 30000, Testing net (#0)
I1029 00:23:59.860774 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54628
I1029 00:23:59.861022 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78272
I1029 00:23:59.861049 29475 solver.cpp:401]     Test net output #2: loss = 2.0238 (* 1 = 2.0238 loss)
I1029 00:24:00.626739 29475 solver.cpp:222] Iteration 30000 (0.6435 iter/s, 62.16s/40 iters), loss = 1.69857
I1029 00:24:00.626812 29475 solver.cpp:241]     Train net output #0: loss = 1.69857 (* 1 = 1.69857 loss)
I1029 00:24:00.626827 29475 sgd_solver.cpp:105] Iteration 30000, lr = 0.00628966
I1029 00:24:19.510737 29523 data_layer.cpp:73] Restarting data prefetching from start.
I1029 00:24:32.396503 29475 solver.cpp:222] Iteration 30040 (1.25911 iter/s, 31.7685s/40 iters), loss = 1.47835
I1029 00:24:32.396703 29475 solver.cpp:241]     Train net output #0: loss = 1.47835 (* 1 = 1.47835 loss)
I1029 00:24:32.396720 29475 sgd_solver.cpp:105] Iteration 30040, lr = 0.00628499
I1029 00:25:03.263461 29475 solver.cpp:222] Iteration 30080 (1.29594 iter/s, 30.8656s/40 iters), loss = 1.6116
I1029 00:25:03.263680 29475 solver.cpp:241]     Train net output #0: loss = 1.6116 (* 1 = 1.6116 loss)
I1029 00:25:03.263700 29475 sgd_solver.cpp:105] Iteration 30080, lr = 0.00628032
I1029 00:25:34.262361 29475 solver.cpp:222] Iteration 30120 (1.29043 iter/s, 30.9975s/40 iters), loss = 1.53171
I1029 00:25:34.262552 29475 solver.cpp:241]     Train net output #0: loss = 1.53171 (* 1 = 1.53171 loss)
I1029 00:25:34.262567 29475 sgd_solver.cpp:105] Iteration 30120, lr = 0.00627565
I1029 00:26:05.105669 29475 solver.cpp:222] Iteration 30160 (1.29693 iter/s, 30.842s/40 iters), loss = 1.48613
I1029 00:26:05.105859 29475 solver.cpp:241]     Train net output #0: loss = 1.48613 (* 1 = 1.48613 loss)
I1029 00:26:05.105875 29475 sgd_solver.cpp:105] Iteration 30160, lr = 0.00627098
I1029 00:26:35.628592 29475 solver.cpp:222] Iteration 30200 (1.31055 iter/s, 30.5216s/40 iters), loss = 1.9024
I1029 00:26:35.628756 29475 solver.cpp:241]     Train net output #0: loss = 1.9024 (* 1 = 1.9024 loss)
I1029 00:26:35.628772 29475 sgd_solver.cpp:105] Iteration 30200, lr = 0.00626631
I1029 00:27:06.777822 29475 solver.cpp:222] Iteration 30240 (1.2842 iter/s, 31.1479s/40 iters), loss = 1.64073
I1029 00:27:06.777999 29475 solver.cpp:241]     Train net output #0: loss = 1.64073 (* 1 = 1.64073 loss)
I1029 00:27:06.778017 29475 sgd_solver.cpp:105] Iteration 30240, lr = 0.00626164
I1029 00:27:37.750365 29475 solver.cpp:222] Iteration 30280 (1.29152 iter/s, 30.9712s/40 iters), loss = 1.63469
I1029 00:27:37.750555 29475 solver.cpp:241]     Train net output #0: loss = 1.63469 (* 1 = 1.63469 loss)
I1029 00:27:37.750571 29475 sgd_solver.cpp:105] Iteration 30280, lr = 0.00625698
I1029 00:28:09.135476 29475 solver.cpp:222] Iteration 30320 (1.27455 iter/s, 31.3837s/40 iters), loss = 1.76056
I1029 00:28:09.135658 29475 solver.cpp:241]     Train net output #0: loss = 1.76056 (* 1 = 1.76056 loss)
I1029 00:28:09.135674 29475 sgd_solver.cpp:105] Iteration 30320, lr = 0.00625231
I1029 00:28:40.323705 29475 solver.cpp:222] Iteration 30360 (1.28259 iter/s, 31.1869s/40 iters), loss = 1.80647
I1029 00:28:40.323892 29475 solver.cpp:241]     Train net output #0: loss = 1.80647 (* 1 = 1.80647 loss)
I1029 00:28:40.323910 29475 sgd_solver.cpp:105] Iteration 30360, lr = 0.00624765
I1029 00:29:12.188570 29475 solver.cpp:222] Iteration 30400 (1.25536 iter/s, 31.8635s/40 iters), loss = 1.48508
I1029 00:29:12.188769 29475 solver.cpp:241]     Train net output #0: loss = 1.48508 (* 1 = 1.48508 loss)
I1029 00:29:12.188786 29475 sgd_solver.cpp:105] Iteration 30400, lr = 0.00624298
I1029 00:29:43.213117 29475 solver.cpp:222] Iteration 30440 (1.28936 iter/s, 31.0232s/40 iters), loss = 1.84703
I1029 00:29:43.213305 29475 solver.cpp:241]     Train net output #0: loss = 1.84703 (* 1 = 1.84703 loss)
I1029 00:29:43.213325 29475 sgd_solver.cpp:105] Iteration 30440, lr = 0.00623832
I1029 00:30:14.708253 29475 solver.cpp:222] Iteration 30480 (1.27009 iter/s, 31.4937s/40 iters), loss = 1.63976
I1029 00:30:14.708508 29475 solver.cpp:241]     Train net output #0: loss = 1.63976 (* 1 = 1.63976 loss)
I1029 00:30:14.708530 29475 sgd_solver.cpp:105] Iteration 30480, lr = 0.00623365
I1029 00:30:29.447032 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_30500.caffemodel
I1029 00:30:29.482106 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_30500.solverstate
I1029 00:30:29.498714 29475 solver.cpp:334] Iteration 30500, Testing net (#0)
I1029 00:31:00.340404 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 00:31:00.547472 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54396
I1029 00:31:00.547528 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78244
I1029 00:31:00.547539 29475 solver.cpp:401]     Test net output #2: loss = 2.03796 (* 1 = 2.03796 loss)
I1029 00:31:17.199302 29475 solver.cpp:222] Iteration 30520 (0.640118 iter/s, 62.4885s/40 iters), loss = 1.55874
I1029 00:31:17.199384 29475 solver.cpp:241]     Train net output #0: loss = 1.55874 (* 1 = 1.55874 loss)
I1029 00:31:17.199404 29475 sgd_solver.cpp:105] Iteration 30520, lr = 0.00622899
I1029 00:31:49.862788 29475 solver.cpp:222] Iteration 30560 (1.22466 iter/s, 32.6621s/40 iters), loss = 1.54715
I1029 00:31:49.863045 29475 solver.cpp:241]     Train net output #0: loss = 1.54715 (* 1 = 1.54715 loss)
I1029 00:31:49.863068 29475 sgd_solver.cpp:105] Iteration 30560, lr = 0.00622433
I1029 00:32:21.908202 29475 solver.cpp:222] Iteration 30600 (1.24829 iter/s, 32.0439s/40 iters), loss = 1.66624
I1029 00:32:21.908377 29475 solver.cpp:241]     Train net output #0: loss = 1.66624 (* 1 = 1.66624 loss)
I1029 00:32:21.908396 29475 sgd_solver.cpp:105] Iteration 30600, lr = 0.00621967
I1029 00:32:53.198712 29475 solver.cpp:222] Iteration 30640 (1.2784 iter/s, 31.2892s/40 iters), loss = 1.92755
I1029 00:32:53.198895 29475 solver.cpp:241]     Train net output #0: loss = 1.92755 (* 1 = 1.92755 loss)
I1029 00:32:53.198912 29475 sgd_solver.cpp:105] Iteration 30640, lr = 0.00621501
I1029 00:33:24.504400 29475 solver.cpp:222] Iteration 30680 (1.27778 iter/s, 31.3043s/40 iters), loss = 1.63953
I1029 00:33:24.504570 29475 solver.cpp:241]     Train net output #0: loss = 1.63953 (* 1 = 1.63953 loss)
I1029 00:33:24.504586 29475 sgd_solver.cpp:105] Iteration 30680, lr = 0.00621035
I1029 00:33:55.499243 29475 solver.cpp:222] Iteration 30720 (1.2906 iter/s, 30.9934s/40 iters), loss = 1.60332
I1029 00:33:55.499431 29475 solver.cpp:241]     Train net output #0: loss = 1.60332 (* 1 = 1.60332 loss)
I1029 00:33:55.499450 29475 sgd_solver.cpp:105] Iteration 30720, lr = 0.00620569
I1029 00:34:26.601282 29475 solver.cpp:222] Iteration 30760 (1.28615 iter/s, 31.1007s/40 iters), loss = 1.71932
I1029 00:34:26.601501 29475 solver.cpp:241]     Train net output #0: loss = 1.71932 (* 1 = 1.71932 loss)
I1029 00:34:26.601518 29475 sgd_solver.cpp:105] Iteration 30760, lr = 0.00620103
I1029 00:34:57.351994 29475 solver.cpp:222] Iteration 30800 (1.30084 iter/s, 30.7493s/40 iters), loss = 1.64449
I1029 00:34:57.352175 29475 solver.cpp:241]     Train net output #0: loss = 1.64449 (* 1 = 1.64449 loss)
I1029 00:34:57.352195 29475 sgd_solver.cpp:105] Iteration 30800, lr = 0.00619638
I1029 00:35:27.933202 29475 solver.cpp:222] Iteration 30840 (1.30805 iter/s, 30.5799s/40 iters), loss = 1.71455
I1029 00:35:27.933399 29475 solver.cpp:241]     Train net output #0: loss = 1.71455 (* 1 = 1.71455 loss)
I1029 00:35:27.933416 29475 sgd_solver.cpp:105] Iteration 30840, lr = 0.00619172
I1029 00:35:58.622475 29475 solver.cpp:222] Iteration 30880 (1.30344 iter/s, 30.6879s/40 iters), loss = 1.69932
I1029 00:35:58.622653 29475 solver.cpp:241]     Train net output #0: loss = 1.69932 (* 1 = 1.69932 loss)
I1029 00:35:58.622670 29475 sgd_solver.cpp:105] Iteration 30880, lr = 0.00618707
I1029 00:36:29.269490 29475 solver.cpp:222] Iteration 30920 (1.30524 iter/s, 30.6457s/40 iters), loss = 1.81893
I1029 00:36:29.269651 29475 solver.cpp:241]     Train net output #0: loss = 1.81893 (* 1 = 1.81893 loss)
I1029 00:36:29.269668 29475 sgd_solver.cpp:105] Iteration 30920, lr = 0.00618241
I1029 00:37:00.219142 29475 solver.cpp:222] Iteration 30960 (1.29248 iter/s, 30.9483s/40 iters), loss = 1.38868
I1029 00:37:00.219456 29475 solver.cpp:241]     Train net output #0: loss = 1.38868 (* 1 = 1.38868 loss)
I1029 00:37:00.219475 29475 sgd_solver.cpp:105] Iteration 30960, lr = 0.00617776
I1029 00:37:30.863075 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_31000.caffemodel
I1029 00:37:30.897464 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_31000.solverstate
I1029 00:37:30.915491 29475 solver.cpp:334] Iteration 31000, Testing net (#0)
I1029 00:38:01.958374 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55488
I1029 00:38:01.958549 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78952
I1029 00:38:01.958564 29475 solver.cpp:401]     Test net output #2: loss = 1.97339 (* 1 = 1.97339 loss)
I1029 00:38:02.726336 29475 solver.cpp:222] Iteration 31000 (0.639954 iter/s, 62.5045s/40 iters), loss = 1.18151
I1029 00:38:02.726406 29475 solver.cpp:241]     Train net output #0: loss = 1.18151 (* 1 = 1.18151 loss)
I1029 00:38:02.726423 29475 sgd_solver.cpp:105] Iteration 31000, lr = 0.00617311
I1029 00:38:33.703747 29475 solver.cpp:222] Iteration 31040 (1.29132 iter/s, 30.9762s/40 iters), loss = 1.51709
I1029 00:38:33.703909 29475 solver.cpp:241]     Train net output #0: loss = 1.51709 (* 1 = 1.51709 loss)
I1029 00:38:33.703927 29475 sgd_solver.cpp:105] Iteration 31040, lr = 0.00616846
I1029 00:39:04.731636 29475 solver.cpp:222] Iteration 31080 (1.28922 iter/s, 31.0266s/40 iters), loss = 1.39453
I1029 00:39:04.731829 29475 solver.cpp:241]     Train net output #0: loss = 1.39453 (* 1 = 1.39453 loss)
I1029 00:39:04.731848 29475 sgd_solver.cpp:105] Iteration 31080, lr = 0.0061638
I1029 00:39:35.947247 29475 solver.cpp:222] Iteration 31120 (1.28147 iter/s, 31.2142s/40 iters), loss = 1.45357
I1029 00:39:35.947427 29475 solver.cpp:241]     Train net output #0: loss = 1.45357 (* 1 = 1.45357 loss)
I1029 00:39:35.947445 29475 sgd_solver.cpp:105] Iteration 31120, lr = 0.00615915
I1029 00:40:06.781458 29475 solver.cpp:222] Iteration 31160 (1.29732 iter/s, 30.8328s/40 iters), loss = 1.74244
I1029 00:40:06.781647 29475 solver.cpp:241]     Train net output #0: loss = 1.74244 (* 1 = 1.74244 loss)
I1029 00:40:06.781666 29475 sgd_solver.cpp:105] Iteration 31160, lr = 0.00615451
I1029 00:40:37.796233 29475 solver.cpp:222] Iteration 31200 (1.28976 iter/s, 31.0134s/40 iters), loss = 1.77809
I1029 00:40:37.796407 29475 solver.cpp:241]     Train net output #0: loss = 1.77809 (* 1 = 1.77809 loss)
I1029 00:40:37.796425 29475 sgd_solver.cpp:105] Iteration 31200, lr = 0.00614986
I1029 00:41:10.828148 29475 solver.cpp:222] Iteration 31240 (1.211 iter/s, 33.0305s/40 iters), loss = 1.66081
I1029 00:41:10.828405 29475 solver.cpp:241]     Train net output #0: loss = 1.66081 (* 1 = 1.66081 loss)
I1029 00:41:10.828424 29475 sgd_solver.cpp:105] Iteration 31240, lr = 0.00614521
I1029 00:41:42.781375 29475 solver.cpp:222] Iteration 31280 (1.25189 iter/s, 31.9518s/40 iters), loss = 1.34239
I1029 00:41:42.781576 29475 solver.cpp:241]     Train net output #0: loss = 1.34239 (* 1 = 1.34239 loss)
I1029 00:41:42.781599 29475 sgd_solver.cpp:105] Iteration 31280, lr = 0.00614056
I1029 00:42:13.894070 29475 solver.cpp:222] Iteration 31320 (1.28571 iter/s, 31.1113s/40 iters), loss = 1.39172
I1029 00:42:13.894245 29475 solver.cpp:241]     Train net output #0: loss = 1.39172 (* 1 = 1.39172 loss)
I1029 00:42:13.894263 29475 sgd_solver.cpp:105] Iteration 31320, lr = 0.00613592
I1029 00:42:44.654022 29475 solver.cpp:222] Iteration 31360 (1.30045 iter/s, 30.7586s/40 iters), loss = 1.62271
I1029 00:42:44.654209 29475 solver.cpp:241]     Train net output #0: loss = 1.62271 (* 1 = 1.62271 loss)
I1029 00:42:44.654225 29475 sgd_solver.cpp:105] Iteration 31360, lr = 0.00613127
I1029 00:43:16.129333 29475 solver.cpp:222] Iteration 31400 (1.27089 iter/s, 31.4739s/40 iters), loss = 1.87563
I1029 00:43:16.129570 29475 solver.cpp:241]     Train net output #0: loss = 1.87563 (* 1 = 1.87563 loss)
I1029 00:43:16.129596 29475 sgd_solver.cpp:105] Iteration 31400, lr = 0.00612663
I1029 00:43:46.924535 29475 solver.cpp:222] Iteration 31440 (1.29896 iter/s, 30.7938s/40 iters), loss = 1.59706
I1029 00:43:46.924723 29475 solver.cpp:241]     Train net output #0: loss = 1.59706 (* 1 = 1.59706 loss)
I1029 00:43:46.924741 29475 sgd_solver.cpp:105] Iteration 31440, lr = 0.00612198
I1029 00:44:17.852458 29475 solver.cpp:222] Iteration 31480 (1.29339 iter/s, 30.9265s/40 iters), loss = 1.89615
I1029 00:44:17.852644 29475 solver.cpp:241]     Train net output #0: loss = 1.89615 (* 1 = 1.89615 loss)
I1029 00:44:17.852663 29475 sgd_solver.cpp:105] Iteration 31480, lr = 0.00611734
I1029 00:44:32.658990 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_31500.caffemodel
I1029 00:44:32.694902 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_31500.solverstate
I1029 00:44:32.713490 29475 solver.cpp:334] Iteration 31500, Testing net (#0)
I1029 00:45:03.519460 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 00:45:03.729285 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54892
I1029 00:45:03.729352 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78856
I1029 00:45:03.729365 29475 solver.cpp:401]     Test net output #2: loss = 1.97956 (* 1 = 1.97956 loss)
I1029 00:45:20.401202 29475 solver.cpp:222] Iteration 31520 (0.639527 iter/s, 62.5462s/40 iters), loss = 1.34022
I1029 00:45:20.401273 29475 solver.cpp:241]     Train net output #0: loss = 1.34022 (* 1 = 1.34022 loss)
I1029 00:45:20.401288 29475 sgd_solver.cpp:105] Iteration 31520, lr = 0.0061127
I1029 00:45:51.291581 29475 solver.cpp:222] Iteration 31560 (1.29495 iter/s, 30.8891s/40 iters), loss = 1.9638
I1029 00:45:51.291779 29475 solver.cpp:241]     Train net output #0: loss = 1.9638 (* 1 = 1.9638 loss)
I1029 00:45:51.291796 29475 sgd_solver.cpp:105] Iteration 31560, lr = 0.00610806
I1029 00:46:22.220556 29475 solver.cpp:222] Iteration 31600 (1.29334 iter/s, 30.9276s/40 iters), loss = 1.57047
I1029 00:46:22.220738 29475 solver.cpp:241]     Train net output #0: loss = 1.57047 (* 1 = 1.57047 loss)
I1029 00:46:22.220755 29475 sgd_solver.cpp:105] Iteration 31600, lr = 0.00610342
I1029 00:46:53.491994 29475 solver.cpp:222] Iteration 31640 (1.27918 iter/s, 31.2701s/40 iters), loss = 1.39108
I1029 00:46:53.492175 29475 solver.cpp:241]     Train net output #0: loss = 1.39108 (* 1 = 1.39108 loss)
I1029 00:46:53.492193 29475 sgd_solver.cpp:105] Iteration 31640, lr = 0.00609878
I1029 00:47:25.087504 29475 solver.cpp:222] Iteration 31680 (1.26606 iter/s, 31.5941s/40 iters), loss = 1.77792
I1029 00:47:25.087749 29475 solver.cpp:241]     Train net output #0: loss = 1.77792 (* 1 = 1.77792 loss)
I1029 00:47:25.087769 29475 sgd_solver.cpp:105] Iteration 31680, lr = 0.00609414
I1029 00:47:56.217833 29475 solver.cpp:222] Iteration 31720 (1.28498 iter/s, 31.1288s/40 iters), loss = 1.47705
I1029 00:47:56.218029 29475 solver.cpp:241]     Train net output #0: loss = 1.47705 (* 1 = 1.47705 loss)
I1029 00:47:56.218046 29475 sgd_solver.cpp:105] Iteration 31720, lr = 0.0060895
I1029 00:48:28.061445 29475 solver.cpp:222] Iteration 31760 (1.25619 iter/s, 31.8422s/40 iters), loss = 1.57021
I1029 00:48:28.061638 29475 solver.cpp:241]     Train net output #0: loss = 1.57021 (* 1 = 1.57021 loss)
I1029 00:48:28.061656 29475 sgd_solver.cpp:105] Iteration 31760, lr = 0.00608486
I1029 00:48:59.122568 29475 solver.cpp:222] Iteration 31800 (1.28784 iter/s, 31.0598s/40 iters), loss = 1.55656
I1029 00:48:59.122753 29475 solver.cpp:241]     Train net output #0: loss = 1.55656 (* 1 = 1.55656 loss)
I1029 00:48:59.122772 29475 sgd_solver.cpp:105] Iteration 31800, lr = 0.00608023
I1029 00:49:30.093252 29475 solver.cpp:222] Iteration 31840 (1.2916 iter/s, 30.9693s/40 iters), loss = 1.37018
I1029 00:49:30.093473 29475 solver.cpp:241]     Train net output #0: loss = 1.37018 (* 1 = 1.37018 loss)
I1029 00:49:30.093497 29475 sgd_solver.cpp:105] Iteration 31840, lr = 0.00607559
I1029 00:50:01.292495 29475 solver.cpp:222] Iteration 31880 (1.28214 iter/s, 31.1978s/40 iters), loss = 1.66671
I1029 00:50:01.292709 29475 solver.cpp:241]     Train net output #0: loss = 1.66671 (* 1 = 1.66671 loss)
I1029 00:50:01.292728 29475 sgd_solver.cpp:105] Iteration 31880, lr = 0.00607096
I1029 00:50:32.391083 29475 solver.cpp:222] Iteration 31920 (1.28629 iter/s, 31.0972s/40 iters), loss = 1.4906
I1029 00:50:32.391294 29475 solver.cpp:241]     Train net output #0: loss = 1.4906 (* 1 = 1.4906 loss)
I1029 00:50:32.391319 29475 sgd_solver.cpp:105] Iteration 31920, lr = 0.00606632
I1029 00:51:03.556533 29475 solver.cpp:222] Iteration 31960 (1.28353 iter/s, 31.164s/40 iters), loss = 1.55437
I1029 00:51:03.556721 29475 solver.cpp:241]     Train net output #0: loss = 1.55437 (* 1 = 1.55437 loss)
I1029 00:51:03.556740 29475 sgd_solver.cpp:105] Iteration 31960, lr = 0.00606169
I1029 00:51:36.472302 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_32000.caffemodel
I1029 00:51:36.509876 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_32000.solverstate
I1029 00:51:36.533648 29475 solver.cpp:334] Iteration 32000, Testing net (#0)
I1029 00:52:07.666729 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5504
I1029 00:52:07.666894 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78556
I1029 00:52:07.666909 29475 solver.cpp:401]     Test net output #2: loss = 1.99401 (* 1 = 1.99401 loss)
I1029 00:52:08.440436 29475 solver.cpp:222] Iteration 32000 (0.616511 iter/s, 64.8813s/40 iters), loss = 1.67474
I1029 00:52:08.440506 29475 solver.cpp:241]     Train net output #0: loss = 1.67474 (* 1 = 1.67474 loss)
I1029 00:52:08.440523 29475 sgd_solver.cpp:105] Iteration 32000, lr = 0.00605706
I1029 00:52:39.285272 29475 solver.cpp:222] Iteration 32040 (1.29687 iter/s, 30.8436s/40 iters), loss = 1.8612
I1029 00:52:39.285468 29475 solver.cpp:241]     Train net output #0: loss = 1.8612 (* 1 = 1.8612 loss)
I1029 00:52:39.285485 29475 sgd_solver.cpp:105] Iteration 32040, lr = 0.00605242
I1029 00:53:11.577145 29475 solver.cpp:222] Iteration 32080 (1.23876 iter/s, 32.2904s/40 iters), loss = 1.60499
I1029 00:53:11.577446 29475 solver.cpp:241]     Train net output #0: loss = 1.60499 (* 1 = 1.60499 loss)
I1029 00:53:11.577486 29475 sgd_solver.cpp:105] Iteration 32080, lr = 0.00604779
I1029 00:53:43.084527 29475 solver.cpp:222] Iteration 32120 (1.2696 iter/s, 31.5059s/40 iters), loss = 1.82486
I1029 00:53:43.084761 29475 solver.cpp:241]     Train net output #0: loss = 1.82486 (* 1 = 1.82486 loss)
I1029 00:53:43.084779 29475 sgd_solver.cpp:105] Iteration 32120, lr = 0.00604316
I1029 00:54:14.228425 29475 solver.cpp:222] Iteration 32160 (1.28442 iter/s, 31.1425s/40 iters), loss = 1.51096
I1029 00:54:14.228623 29475 solver.cpp:241]     Train net output #0: loss = 1.51096 (* 1 = 1.51096 loss)
I1029 00:54:14.228642 29475 sgd_solver.cpp:105] Iteration 32160, lr = 0.00603854
I1029 00:54:44.871522 29475 solver.cpp:222] Iteration 32200 (1.30541 iter/s, 30.6417s/40 iters), loss = 1.54464
I1029 00:54:44.871686 29475 solver.cpp:241]     Train net output #0: loss = 1.54464 (* 1 = 1.54464 loss)
I1029 00:54:44.871704 29475 sgd_solver.cpp:105] Iteration 32200, lr = 0.00603391
I1029 00:55:15.696126 29475 solver.cpp:222] Iteration 32240 (1.29772 iter/s, 30.8232s/40 iters), loss = 1.59365
I1029 00:55:15.696291 29475 solver.cpp:241]     Train net output #0: loss = 1.59365 (* 1 = 1.59365 loss)
I1029 00:55:15.696316 29475 sgd_solver.cpp:105] Iteration 32240, lr = 0.00602928
I1029 00:55:46.287840 29475 solver.cpp:222] Iteration 32280 (1.3076 iter/s, 30.5903s/40 iters), loss = 2.02635
I1029 00:55:46.287999 29475 solver.cpp:241]     Train net output #0: loss = 2.02635 (* 1 = 2.02635 loss)
I1029 00:55:46.288017 29475 sgd_solver.cpp:105] Iteration 32280, lr = 0.00602465
I1029 00:56:16.998095 29475 solver.cpp:222] Iteration 32320 (1.30255 iter/s, 30.7089s/40 iters), loss = 1.75849
I1029 00:56:16.998307 29475 solver.cpp:241]     Train net output #0: loss = 1.75849 (* 1 = 1.75849 loss)
I1029 00:56:16.998342 29475 sgd_solver.cpp:105] Iteration 32320, lr = 0.00602003
I1029 00:56:50.409116 29475 solver.cpp:222] Iteration 32360 (1.19726 iter/s, 33.4095s/40 iters), loss = 1.81412
I1029 00:56:50.409353 29475 solver.cpp:241]     Train net output #0: loss = 1.81412 (* 1 = 1.81412 loss)
I1029 00:56:50.409376 29475 sgd_solver.cpp:105] Iteration 32360, lr = 0.0060154
I1029 00:57:23.564600 29475 solver.cpp:222] Iteration 32400 (1.20649 iter/s, 33.154s/40 iters), loss = 1.55031
I1029 00:57:23.564805 29475 solver.cpp:241]     Train net output #0: loss = 1.55031 (* 1 = 1.55031 loss)
I1029 00:57:23.564823 29475 sgd_solver.cpp:105] Iteration 32400, lr = 0.00601078
I1029 00:57:54.585757 29475 solver.cpp:222] Iteration 32440 (1.2895 iter/s, 31.0198s/40 iters), loss = 1.68328
I1029 00:57:54.585953 29475 solver.cpp:241]     Train net output #0: loss = 1.68328 (* 1 = 1.68328 loss)
I1029 00:57:54.585970 29475 sgd_solver.cpp:105] Iteration 32440, lr = 0.00600615
I1029 00:58:25.813705 29475 solver.cpp:222] Iteration 32480 (1.28096 iter/s, 31.2266s/40 iters), loss = 1.66676
I1029 00:58:25.813894 29475 solver.cpp:241]     Train net output #0: loss = 1.66676 (* 1 = 1.66676 loss)
I1029 00:58:25.813913 29475 sgd_solver.cpp:105] Iteration 32480, lr = 0.00600153
I1029 00:58:40.482411 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_32500.caffemodel
I1029 00:58:40.518326 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_32500.solverstate
I1029 00:58:40.538336 29475 solver.cpp:334] Iteration 32500, Testing net (#0)
I1029 00:59:11.315958 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 00:59:11.524237 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5434
I1029 00:59:11.524304 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78264
I1029 00:59:11.524318 29475 solver.cpp:401]     Test net output #2: loss = 2.05334 (* 1 = 2.05334 loss)
I1029 00:59:28.128412 29475 solver.cpp:222] Iteration 32520 (0.64193 iter/s, 62.3121s/40 iters), loss = 1.46385
I1029 00:59:28.128489 29475 solver.cpp:241]     Train net output #0: loss = 1.46385 (* 1 = 1.46385 loss)
I1029 00:59:28.128505 29475 sgd_solver.cpp:105] Iteration 32520, lr = 0.00599691
I1029 00:59:32.200954 29523 data_layer.cpp:73] Restarting data prefetching from start.
I1029 00:59:59.188906 29475 solver.cpp:222] Iteration 32560 (1.28786 iter/s, 31.0592s/40 iters), loss = 1.63202
I1029 00:59:59.189119 29475 solver.cpp:241]     Train net output #0: loss = 1.63202 (* 1 = 1.63202 loss)
I1029 00:59:59.189137 29475 sgd_solver.cpp:105] Iteration 32560, lr = 0.00599229
I1029 01:00:30.085983 29475 solver.cpp:222] Iteration 32600 (1.29468 iter/s, 30.8957s/40 iters), loss = 1.66835
I1029 01:00:30.086185 29475 solver.cpp:241]     Train net output #0: loss = 1.66835 (* 1 = 1.66835 loss)
I1029 01:00:30.086201 29475 sgd_solver.cpp:105] Iteration 32600, lr = 0.00598767
I1029 01:01:00.889328 29475 solver.cpp:222] Iteration 32640 (1.29862 iter/s, 30.8019s/40 iters), loss = 1.62836
I1029 01:01:00.889516 29475 solver.cpp:241]     Train net output #0: loss = 1.62836 (* 1 = 1.62836 loss)
I1029 01:01:00.889533 29475 sgd_solver.cpp:105] Iteration 32640, lr = 0.00598305
I1029 01:01:31.478973 29475 solver.cpp:222] Iteration 32680 (1.30769 iter/s, 30.5882s/40 iters), loss = 1.56607
I1029 01:01:31.479185 29475 solver.cpp:241]     Train net output #0: loss = 1.56607 (* 1 = 1.56607 loss)
I1029 01:01:31.479203 29475 sgd_solver.cpp:105] Iteration 32680, lr = 0.00597843
I1029 01:02:02.297046 29475 solver.cpp:222] Iteration 32720 (1.298 iter/s, 30.8167s/40 iters), loss = 1.58584
I1029 01:02:02.297224 29475 solver.cpp:241]     Train net output #0: loss = 1.58584 (* 1 = 1.58584 loss)
I1029 01:02:02.297240 29475 sgd_solver.cpp:105] Iteration 32720, lr = 0.00597381
I1029 01:02:32.891897 29475 solver.cpp:222] Iteration 32760 (1.30747 iter/s, 30.5935s/40 iters), loss = 1.88561
I1029 01:02:32.892212 29475 solver.cpp:241]     Train net output #0: loss = 1.88561 (* 1 = 1.88561 loss)
I1029 01:02:32.892247 29475 sgd_solver.cpp:105] Iteration 32760, lr = 0.0059692
I1029 01:03:03.573525 29475 solver.cpp:222] Iteration 32800 (1.30377 iter/s, 30.6802s/40 iters), loss = 1.13712
I1029 01:03:03.573714 29475 solver.cpp:241]     Train net output #0: loss = 1.13712 (* 1 = 1.13712 loss)
I1029 01:03:03.573730 29475 sgd_solver.cpp:105] Iteration 32800, lr = 0.00596458
I1029 01:03:34.508514 29475 solver.cpp:222] Iteration 32840 (1.29309 iter/s, 30.9336s/40 iters), loss = 1.94535
I1029 01:03:34.508703 29475 solver.cpp:241]     Train net output #0: loss = 1.94535 (* 1 = 1.94535 loss)
I1029 01:03:34.508721 29475 sgd_solver.cpp:105] Iteration 32840, lr = 0.00595997
I1029 01:04:05.266217 29475 solver.cpp:222] Iteration 32880 (1.30054 iter/s, 30.7564s/40 iters), loss = 1.69792
I1029 01:04:05.266402 29475 solver.cpp:241]     Train net output #0: loss = 1.69792 (* 1 = 1.69792 loss)
I1029 01:04:05.266418 29475 sgd_solver.cpp:105] Iteration 32880, lr = 0.00595535
I1029 01:04:35.853235 29475 solver.cpp:222] Iteration 32920 (1.3078 iter/s, 30.5857s/40 iters), loss = 1.6369
I1029 01:04:35.853448 29475 solver.cpp:241]     Train net output #0: loss = 1.6369 (* 1 = 1.6369 loss)
I1029 01:04:35.853468 29475 sgd_solver.cpp:105] Iteration 32920, lr = 0.00595074
I1029 01:05:06.889783 29475 solver.cpp:222] Iteration 32960 (1.28886 iter/s, 31.0352s/40 iters), loss = 1.82934
I1029 01:05:06.889984 29475 solver.cpp:241]     Train net output #0: loss = 1.82934 (* 1 = 1.82934 loss)
I1029 01:05:06.890002 29475 sgd_solver.cpp:105] Iteration 32960, lr = 0.00594613
I1029 01:05:37.133659 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_33000.caffemodel
I1029 01:05:37.167374 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_33000.solverstate
I1029 01:05:37.184206 29475 solver.cpp:334] Iteration 33000, Testing net (#0)
I1029 01:06:08.207594 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55032
I1029 01:06:08.207763 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78764
I1029 01:06:08.207778 29475 solver.cpp:401]     Test net output #2: loss = 2.02062 (* 1 = 2.02062 loss)
I1029 01:06:08.997427 29475 solver.cpp:222] Iteration 33000 (0.644069 iter/s, 62.1051s/40 iters), loss = 1.63828
I1029 01:06:08.997491 29475 solver.cpp:241]     Train net output #0: loss = 1.63828 (* 1 = 1.63828 loss)
I1029 01:06:08.997506 29475 sgd_solver.cpp:105] Iteration 33000, lr = 0.00594152
I1029 01:06:40.380288 29475 solver.cpp:222] Iteration 33040 (1.27463 iter/s, 31.3816s/40 iters), loss = 1.56721
I1029 01:06:40.380461 29475 solver.cpp:241]     Train net output #0: loss = 1.56721 (* 1 = 1.56721 loss)
I1029 01:06:40.380478 29475 sgd_solver.cpp:105] Iteration 33040, lr = 0.0059369
I1029 01:07:11.884034 29475 solver.cpp:222] Iteration 33080 (1.26975 iter/s, 31.5024s/40 iters), loss = 1.63791
I1029 01:07:11.884222 29475 solver.cpp:241]     Train net output #0: loss = 1.63791 (* 1 = 1.63791 loss)
I1029 01:07:11.884238 29475 sgd_solver.cpp:105] Iteration 33080, lr = 0.00593229
I1029 01:07:43.127379 29475 solver.cpp:222] Iteration 33120 (1.28033 iter/s, 31.242s/40 iters), loss = 1.8004
I1029 01:07:43.127568 29475 solver.cpp:241]     Train net output #0: loss = 1.8004 (* 1 = 1.8004 loss)
I1029 01:07:43.127595 29475 sgd_solver.cpp:105] Iteration 33120, lr = 0.00592769
I1029 01:08:14.438287 29475 solver.cpp:222] Iteration 33160 (1.27757 iter/s, 31.3094s/40 iters), loss = 1.56563
I1029 01:08:14.438484 29475 solver.cpp:241]     Train net output #0: loss = 1.56563 (* 1 = 1.56563 loss)
I1029 01:08:14.438501 29475 sgd_solver.cpp:105] Iteration 33160, lr = 0.00592308
I1029 01:08:45.634507 29475 solver.cpp:222] Iteration 33200 (1.28226 iter/s, 31.1948s/40 iters), loss = 1.95051
I1029 01:08:45.634680 29475 solver.cpp:241]     Train net output #0: loss = 1.95051 (* 1 = 1.95051 loss)
I1029 01:08:45.634698 29475 sgd_solver.cpp:105] Iteration 33200, lr = 0.00591847
I1029 01:09:16.831629 29475 solver.cpp:222] Iteration 33240 (1.28223 iter/s, 31.1958s/40 iters), loss = 1.99145
I1029 01:09:16.831831 29475 solver.cpp:241]     Train net output #0: loss = 1.99145 (* 1 = 1.99145 loss)
I1029 01:09:16.831849 29475 sgd_solver.cpp:105] Iteration 33240, lr = 0.00591386
I1029 01:09:47.876744 29475 solver.cpp:222] Iteration 33280 (1.2885 iter/s, 31.0437s/40 iters), loss = 1.74691
I1029 01:09:47.876914 29475 solver.cpp:241]     Train net output #0: loss = 1.74691 (* 1 = 1.74691 loss)
I1029 01:09:47.876929 29475 sgd_solver.cpp:105] Iteration 33280, lr = 0.00590926
I1029 01:10:19.120896 29475 solver.cpp:222] Iteration 33320 (1.2803 iter/s, 31.2428s/40 iters), loss = 1.60788
I1029 01:10:19.121099 29475 solver.cpp:241]     Train net output #0: loss = 1.60788 (* 1 = 1.60788 loss)
I1029 01:10:19.121119 29475 sgd_solver.cpp:105] Iteration 33320, lr = 0.00590465
I1029 01:10:50.301234 29475 solver.cpp:222] Iteration 33360 (1.28292 iter/s, 31.179s/40 iters), loss = 1.47551
I1029 01:10:50.301410 29475 solver.cpp:241]     Train net output #0: loss = 1.47551 (* 1 = 1.47551 loss)
I1029 01:10:50.301429 29475 sgd_solver.cpp:105] Iteration 33360, lr = 0.00590005
I1029 01:11:21.293459 29475 solver.cpp:222] Iteration 33400 (1.2907 iter/s, 30.9909s/40 iters), loss = 1.7265
I1029 01:11:21.293668 29475 solver.cpp:241]     Train net output #0: loss = 1.7265 (* 1 = 1.7265 loss)
I1029 01:11:21.293684 29475 sgd_solver.cpp:105] Iteration 33400, lr = 0.00589544
I1029 01:11:52.200176 29475 solver.cpp:222] Iteration 33440 (1.29428 iter/s, 30.9053s/40 iters), loss = 1.36531
I1029 01:11:52.200422 29475 solver.cpp:241]     Train net output #0: loss = 1.36531 (* 1 = 1.36531 loss)
I1029 01:11:52.200439 29475 sgd_solver.cpp:105] Iteration 33440, lr = 0.00589084
I1029 01:12:22.973431 29475 solver.cpp:222] Iteration 33480 (1.29989 iter/s, 30.7719s/40 iters), loss = 1.91086
I1029 01:12:22.973624 29475 solver.cpp:241]     Train net output #0: loss = 1.91086 (* 1 = 1.91086 loss)
I1029 01:12:22.973642 29475 sgd_solver.cpp:105] Iteration 33480, lr = 0.00588624
I1029 01:12:37.808197 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_33500.caffemodel
I1029 01:12:37.848109 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_33500.solverstate
I1029 01:12:37.872009 29475 solver.cpp:334] Iteration 33500, Testing net (#0)
I1029 01:13:08.636741 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 01:13:08.843617 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55812
I1029 01:13:08.843680 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79072
I1029 01:13:08.843693 29475 solver.cpp:401]     Test net output #2: loss = 1.99726 (* 1 = 1.99726 loss)
I1029 01:13:25.121289 29475 solver.cpp:222] Iteration 33520 (0.643652 iter/s, 62.1453s/40 iters), loss = 1.51718
I1029 01:13:25.121392 29475 solver.cpp:241]     Train net output #0: loss = 1.51718 (* 1 = 1.51718 loss)
I1029 01:13:25.121414 29475 sgd_solver.cpp:105] Iteration 33520, lr = 0.00588164
I1029 01:13:57.423825 29475 solver.cpp:222] Iteration 33560 (1.23834 iter/s, 32.3012s/40 iters), loss = 1.91404
I1029 01:13:57.424070 29475 solver.cpp:241]     Train net output #0: loss = 1.91404 (* 1 = 1.91404 loss)
I1029 01:13:57.424096 29475 sgd_solver.cpp:105] Iteration 33560, lr = 0.00587704
I1029 01:14:29.752619 29475 solver.cpp:222] Iteration 33600 (1.23734 iter/s, 32.3273s/40 iters), loss = 1.96566
I1029 01:14:29.752810 29475 solver.cpp:241]     Train net output #0: loss = 1.96566 (* 1 = 1.96566 loss)
I1029 01:14:29.752826 29475 sgd_solver.cpp:105] Iteration 33600, lr = 0.00587244
I1029 01:15:01.555343 29475 solver.cpp:222] Iteration 33640 (1.25781 iter/s, 31.8013s/40 iters), loss = 1.54947
I1029 01:15:01.555511 29475 solver.cpp:241]     Train net output #0: loss = 1.54947 (* 1 = 1.54947 loss)
I1029 01:15:01.555531 29475 sgd_solver.cpp:105] Iteration 33640, lr = 0.00586784
I1029 01:15:32.533524 29475 solver.cpp:222] Iteration 33680 (1.29129 iter/s, 30.9768s/40 iters), loss = 1.67125
I1029 01:15:32.533793 29475 solver.cpp:241]     Train net output #0: loss = 1.67125 (* 1 = 1.67125 loss)
I1029 01:15:32.533810 29475 sgd_solver.cpp:105] Iteration 33680, lr = 0.00586324
I1029 01:16:03.624114 29475 solver.cpp:222] Iteration 33720 (1.28662 iter/s, 31.0891s/40 iters), loss = 1.70532
I1029 01:16:03.624316 29475 solver.cpp:241]     Train net output #0: loss = 1.70532 (* 1 = 1.70532 loss)
I1029 01:16:03.624335 29475 sgd_solver.cpp:105] Iteration 33720, lr = 0.00585865
I1029 01:16:34.677923 29475 solver.cpp:222] Iteration 33760 (1.28814 iter/s, 31.0524s/40 iters), loss = 1.27647
I1029 01:16:34.678122 29475 solver.cpp:241]     Train net output #0: loss = 1.27647 (* 1 = 1.27647 loss)
I1029 01:16:34.678140 29475 sgd_solver.cpp:105] Iteration 33760, lr = 0.00585405
I1029 01:17:05.292336 29475 solver.cpp:222] Iteration 33800 (1.30663 iter/s, 30.613s/40 iters), loss = 1.83966
I1029 01:17:05.292491 29475 solver.cpp:241]     Train net output #0: loss = 1.83966 (* 1 = 1.83966 loss)
I1029 01:17:05.292510 29475 sgd_solver.cpp:105] Iteration 33800, lr = 0.00584945
I1029 01:17:35.956432 29475 solver.cpp:222] Iteration 33840 (1.30451 iter/s, 30.6628s/40 iters), loss = 1.83584
I1029 01:17:35.956593 29475 solver.cpp:241]     Train net output #0: loss = 1.83584 (* 1 = 1.83584 loss)
I1029 01:17:35.956611 29475 sgd_solver.cpp:105] Iteration 33840, lr = 0.00584486
I1029 01:18:06.741353 29475 solver.cpp:222] Iteration 33880 (1.29939 iter/s, 30.7836s/40 iters), loss = 1.81218
I1029 01:18:06.741542 29475 solver.cpp:241]     Train net output #0: loss = 1.81218 (* 1 = 1.81218 loss)
I1029 01:18:06.741559 29475 sgd_solver.cpp:105] Iteration 33880, lr = 0.00584027
I1029 01:18:37.601888 29475 solver.cpp:222] Iteration 33920 (1.29621 iter/s, 30.8591s/40 iters), loss = 1.71509
I1029 01:18:37.602078 29475 solver.cpp:241]     Train net output #0: loss = 1.71509 (* 1 = 1.71509 loss)
I1029 01:18:37.602097 29475 sgd_solver.cpp:105] Iteration 33920, lr = 0.00583567
I1029 01:19:08.354050 29475 solver.cpp:222] Iteration 33960 (1.30078 iter/s, 30.7508s/40 iters), loss = 2.08609
I1029 01:19:08.354224 29475 solver.cpp:241]     Train net output #0: loss = 2.08609 (* 1 = 2.08609 loss)
I1029 01:19:08.354243 29475 sgd_solver.cpp:105] Iteration 33960, lr = 0.00583108
I1029 01:19:38.628707 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_34000.caffemodel
I1029 01:19:38.671624 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_34000.solverstate
I1029 01:19:38.693573 29475 solver.cpp:334] Iteration 34000, Testing net (#0)
I1029 01:20:09.746451 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54948
I1029 01:20:09.746639 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78784
I1029 01:20:09.746652 29475 solver.cpp:401]     Test net output #2: loss = 2.00193 (* 1 = 2.00193 loss)
I1029 01:20:10.520028 29475 solver.cpp:222] Iteration 34000 (0.643465 iter/s, 62.1635s/40 iters), loss = 1.75145
I1029 01:20:10.520097 29475 solver.cpp:241]     Train net output #0: loss = 1.75145 (* 1 = 1.75145 loss)
I1029 01:20:10.520112 29475 sgd_solver.cpp:105] Iteration 34000, lr = 0.00582649
I1029 01:20:41.492619 29475 solver.cpp:222] Iteration 34040 (1.29152 iter/s, 30.9713s/40 iters), loss = 1.60786
I1029 01:20:41.492805 29475 solver.cpp:241]     Train net output #0: loss = 1.60786 (* 1 = 1.60786 loss)
I1029 01:20:41.492825 29475 sgd_solver.cpp:105] Iteration 34040, lr = 0.0058219
I1029 01:21:13.155802 29475 solver.cpp:222] Iteration 34080 (1.26335 iter/s, 31.6618s/40 iters), loss = 1.68714
I1029 01:21:13.156016 29475 solver.cpp:241]     Train net output #0: loss = 1.68714 (* 1 = 1.68714 loss)
I1029 01:21:13.156034 29475 sgd_solver.cpp:105] Iteration 34080, lr = 0.00581731
I1029 01:21:44.900077 29475 solver.cpp:222] Iteration 34120 (1.26013 iter/s, 31.7429s/40 iters), loss = 1.65745
I1029 01:21:44.900318 29475 solver.cpp:241]     Train net output #0: loss = 1.65745 (* 1 = 1.65745 loss)
I1029 01:21:44.900346 29475 sgd_solver.cpp:105] Iteration 34120, lr = 0.00581272
I1029 01:22:16.801576 29475 solver.cpp:222] Iteration 34160 (1.25392 iter/s, 31.9s/40 iters), loss = 1.75967
I1029 01:22:16.801756 29475 solver.cpp:241]     Train net output #0: loss = 1.75967 (* 1 = 1.75967 loss)
I1029 01:22:16.801774 29475 sgd_solver.cpp:105] Iteration 34160, lr = 0.00580814
I1029 01:22:47.431882 29475 solver.cpp:222] Iteration 34200 (1.30596 iter/s, 30.6289s/40 iters), loss = 1.67347
I1029 01:22:47.432037 29475 solver.cpp:241]     Train net output #0: loss = 1.67347 (* 1 = 1.67347 loss)
I1029 01:22:47.432055 29475 sgd_solver.cpp:105] Iteration 34200, lr = 0.00580355
I1029 01:23:19.907307 29475 solver.cpp:222] Iteration 34240 (1.23175 iter/s, 32.474s/40 iters), loss = 1.82232
I1029 01:23:19.907485 29475 solver.cpp:241]     Train net output #0: loss = 1.82232 (* 1 = 1.82232 loss)
I1029 01:23:19.907503 29475 sgd_solver.cpp:105] Iteration 34240, lr = 0.00579896
I1029 01:23:50.625056 29475 solver.cpp:222] Iteration 34280 (1.30224 iter/s, 30.7164s/40 iters), loss = 1.49063
I1029 01:23:50.625223 29475 solver.cpp:241]     Train net output #0: loss = 1.49063 (* 1 = 1.49063 loss)
I1029 01:23:50.625243 29475 sgd_solver.cpp:105] Iteration 34280, lr = 0.00579438
I1029 01:24:21.579413 29475 solver.cpp:222] Iteration 34320 (1.29228 iter/s, 30.953s/40 iters), loss = 1.82193
I1029 01:24:21.579596 29475 solver.cpp:241]     Train net output #0: loss = 1.82193 (* 1 = 1.82193 loss)
I1029 01:24:21.579612 29475 sgd_solver.cpp:105] Iteration 34320, lr = 0.00578979
I1029 01:24:52.742609 29475 solver.cpp:222] Iteration 34360 (1.28362 iter/s, 31.1618s/40 iters), loss = 1.50708
I1029 01:24:52.742786 29475 solver.cpp:241]     Train net output #0: loss = 1.50708 (* 1 = 1.50708 loss)
I1029 01:24:52.742805 29475 sgd_solver.cpp:105] Iteration 34360, lr = 0.00578521
I1029 01:25:23.527226 29475 solver.cpp:222] Iteration 34400 (1.29941 iter/s, 30.7833s/40 iters), loss = 1.91021
I1029 01:25:23.527441 29475 solver.cpp:241]     Train net output #0: loss = 1.91021 (* 1 = 1.91021 loss)
I1029 01:25:23.527462 29475 sgd_solver.cpp:105] Iteration 34400, lr = 0.00578063
I1029 01:25:54.696733 29475 solver.cpp:222] Iteration 34440 (1.28336 iter/s, 31.1681s/40 iters), loss = 1.63024
I1029 01:25:54.696928 29475 solver.cpp:241]     Train net output #0: loss = 1.63024 (* 1 = 1.63024 loss)
I1029 01:25:54.696945 29475 sgd_solver.cpp:105] Iteration 34440, lr = 0.00577605
I1029 01:26:26.178542 29475 solver.cpp:222] Iteration 34480 (1.27063 iter/s, 31.4804s/40 iters), loss = 1.4199
I1029 01:26:26.178778 29475 solver.cpp:241]     Train net output #0: loss = 1.4199 (* 1 = 1.4199 loss)
I1029 01:26:26.178808 29475 sgd_solver.cpp:105] Iteration 34480, lr = 0.00577146
I1029 01:26:43.580013 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_34500.caffemodel
I1029 01:26:43.626986 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_34500.solverstate
I1029 01:26:43.653923 29475 solver.cpp:334] Iteration 34500, Testing net (#0)
I1029 01:27:16.035320 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 01:27:16.241256 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5488
I1029 01:27:16.241322 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.784079
I1029 01:27:16.241338 29475 solver.cpp:401]     Test net output #2: loss = 1.99319 (* 1 = 1.99319 loss)
I1029 01:27:35.856403 29475 solver.cpp:222] Iteration 34520 (0.574094 iter/s, 69.675s/40 iters), loss = 1.6782
I1029 01:27:35.856511 29475 solver.cpp:241]     Train net output #0: loss = 1.6782 (* 1 = 1.6782 loss)
I1029 01:27:35.856533 29475 sgd_solver.cpp:105] Iteration 34520, lr = 0.00576688
I1029 01:28:07.024618 29475 solver.cpp:222] Iteration 34560 (1.28341 iter/s, 31.1669s/40 iters), loss = 1.75215
I1029 01:28:07.024799 29475 solver.cpp:241]     Train net output #0: loss = 1.75215 (* 1 = 1.75215 loss)
I1029 01:28:07.024816 29475 sgd_solver.cpp:105] Iteration 34560, lr = 0.00576231
I1029 01:28:38.212132 29475 solver.cpp:222] Iteration 34600 (1.28262 iter/s, 31.1861s/40 iters), loss = 1.6383
I1029 01:28:38.212429 29475 solver.cpp:241]     Train net output #0: loss = 1.6383 (* 1 = 1.6383 loss)
I1029 01:28:38.212465 29475 sgd_solver.cpp:105] Iteration 34600, lr = 0.00575773
I1029 01:29:09.684496 29475 solver.cpp:222] Iteration 34640 (1.27102 iter/s, 31.4709s/40 iters), loss = 1.58833
I1029 01:29:09.684691 29475 solver.cpp:241]     Train net output #0: loss = 1.58833 (* 1 = 1.58833 loss)
I1029 01:29:09.684708 29475 sgd_solver.cpp:105] Iteration 34640, lr = 0.00575315
I1029 01:29:40.895094 29475 solver.cpp:222] Iteration 34680 (1.28167 iter/s, 31.2092s/40 iters), loss = 1.76428
I1029 01:29:40.895295 29475 solver.cpp:241]     Train net output #0: loss = 1.76428 (* 1 = 1.76428 loss)
I1029 01:29:40.895318 29475 sgd_solver.cpp:105] Iteration 34680, lr = 0.00574857
I1029 01:30:11.778460 29475 solver.cpp:222] Iteration 34720 (1.29525 iter/s, 30.882s/40 iters), loss = 1.74002
I1029 01:30:11.778668 29475 solver.cpp:241]     Train net output #0: loss = 1.74002 (* 1 = 1.74002 loss)
I1029 01:30:11.778687 29475 sgd_solver.cpp:105] Iteration 34720, lr = 0.005744
I1029 01:30:42.959817 29475 solver.cpp:222] Iteration 34760 (1.28288 iter/s, 31.1799s/40 iters), loss = 1.51991
I1029 01:30:42.960003 29475 solver.cpp:241]     Train net output #0: loss = 1.51991 (* 1 = 1.51991 loss)
I1029 01:30:42.960022 29475 sgd_solver.cpp:105] Iteration 34760, lr = 0.00573942
I1029 01:31:13.491993 29475 solver.cpp:222] Iteration 34800 (1.31015 iter/s, 30.5308s/40 iters), loss = 1.3697
I1029 01:31:13.492192 29475 solver.cpp:241]     Train net output #0: loss = 1.3697 (* 1 = 1.3697 loss)
I1029 01:31:13.492208 29475 sgd_solver.cpp:105] Iteration 34800, lr = 0.00573485
I1029 01:31:44.359511 29475 solver.cpp:222] Iteration 34840 (1.29592 iter/s, 30.8661s/40 iters), loss = 1.7614
I1029 01:31:44.359717 29475 solver.cpp:241]     Train net output #0: loss = 1.7614 (* 1 = 1.7614 loss)
I1029 01:31:44.359745 29475 sgd_solver.cpp:105] Iteration 34840, lr = 0.00573027
I1029 01:32:15.317145 29475 solver.cpp:222] Iteration 34880 (1.29215 iter/s, 30.9562s/40 iters), loss = 1.50647
I1029 01:32:15.317325 29475 solver.cpp:241]     Train net output #0: loss = 1.50647 (* 1 = 1.50647 loss)
I1029 01:32:15.317347 29475 sgd_solver.cpp:105] Iteration 34880, lr = 0.0057257
I1029 01:32:46.256978 29475 solver.cpp:222] Iteration 34920 (1.29289 iter/s, 30.9384s/40 iters), loss = 1.47468
I1029 01:32:46.257165 29475 solver.cpp:241]     Train net output #0: loss = 1.47468 (* 1 = 1.47468 loss)
I1029 01:32:46.257184 29475 sgd_solver.cpp:105] Iteration 34920, lr = 0.00572113
I1029 01:33:17.081872 29475 solver.cpp:222] Iteration 34960 (1.29771 iter/s, 30.8235s/40 iters), loss = 1.6119
I1029 01:33:17.082044 29475 solver.cpp:241]     Train net output #0: loss = 1.6119 (* 1 = 1.6119 loss)
I1029 01:33:17.082059 29475 sgd_solver.cpp:105] Iteration 34960, lr = 0.00571656
I1029 01:33:47.177179 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_35000.caffemodel
I1029 01:33:47.213327 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_35000.solverstate
I1029 01:33:47.231917 29475 solver.cpp:334] Iteration 35000, Testing net (#0)
I1029 01:34:18.215508 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55036
I1029 01:34:18.215680 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78528
I1029 01:34:18.215694 29475 solver.cpp:401]     Test net output #2: loss = 1.99634 (* 1 = 1.99634 loss)
I1029 01:34:18.992311 29475 solver.cpp:222] Iteration 35000 (0.646121 iter/s, 61.9079s/40 iters), loss = 1.6245
I1029 01:34:18.992377 29475 solver.cpp:241]     Train net output #0: loss = 1.6245 (* 1 = 1.6245 loss)
I1029 01:34:18.992393 29475 sgd_solver.cpp:105] Iteration 35000, lr = 0.00571199
I1029 01:34:39.866644 29523 data_layer.cpp:73] Restarting data prefetching from start.
I1029 01:34:49.657935 29475 solver.cpp:222] Iteration 35040 (1.30444 iter/s, 30.6644s/40 iters), loss = 1.71005
I1029 01:34:49.658216 29475 solver.cpp:241]     Train net output #0: loss = 1.71005 (* 1 = 1.71005 loss)
I1029 01:34:49.658242 29475 sgd_solver.cpp:105] Iteration 35040, lr = 0.00570742
I1029 01:35:20.497831 29475 solver.cpp:222] Iteration 35080 (1.29708 iter/s, 30.8385s/40 iters), loss = 1.16524
I1029 01:35:20.498018 29475 solver.cpp:241]     Train net output #0: loss = 1.16524 (* 1 = 1.16524 loss)
I1029 01:35:20.498039 29475 sgd_solver.cpp:105] Iteration 35080, lr = 0.00570285
I1029 01:35:51.473475 29475 solver.cpp:222] Iteration 35120 (1.29139 iter/s, 30.9743s/40 iters), loss = 1.44782
I1029 01:35:51.473644 29475 solver.cpp:241]     Train net output #0: loss = 1.44782 (* 1 = 1.44782 loss)
I1029 01:35:51.473660 29475 sgd_solver.cpp:105] Iteration 35120, lr = 0.00569828
I1029 01:36:22.691491 29475 solver.cpp:222] Iteration 35160 (1.28137 iter/s, 31.2166s/40 iters), loss = 1.5034
I1029 01:36:22.691668 29475 solver.cpp:241]     Train net output #0: loss = 1.5034 (* 1 = 1.5034 loss)
I1029 01:36:22.691685 29475 sgd_solver.cpp:105] Iteration 35160, lr = 0.00569372
I1029 01:36:53.700709 29475 solver.cpp:222] Iteration 35200 (1.29 iter/s, 31.0079s/40 iters), loss = 1.70337
I1029 01:36:53.700898 29475 solver.cpp:241]     Train net output #0: loss = 1.70337 (* 1 = 1.70337 loss)
I1029 01:36:53.700914 29475 sgd_solver.cpp:105] Iteration 35200, lr = 0.00568915
I1029 01:37:24.548895 29475 solver.cpp:222] Iteration 35240 (1.29673 iter/s, 30.8468s/40 iters), loss = 1.55387
I1029 01:37:24.549078 29475 solver.cpp:241]     Train net output #0: loss = 1.55387 (* 1 = 1.55387 loss)
I1029 01:37:24.549096 29475 sgd_solver.cpp:105] Iteration 35240, lr = 0.00568459
I1029 01:37:55.593890 29475 solver.cpp:222] Iteration 35280 (1.28851 iter/s, 31.0436s/40 iters), loss = 1.73911
I1029 01:37:55.594072 29475 solver.cpp:241]     Train net output #0: loss = 1.73911 (* 1 = 1.73911 loss)
I1029 01:37:55.594090 29475 sgd_solver.cpp:105] Iteration 35280, lr = 0.00568002
I1029 01:38:26.458426 29475 solver.cpp:222] Iteration 35320 (1.29604 iter/s, 30.8632s/40 iters), loss = 1.3798
I1029 01:38:26.458622 29475 solver.cpp:241]     Train net output #0: loss = 1.3798 (* 1 = 1.3798 loss)
I1029 01:38:26.458640 29475 sgd_solver.cpp:105] Iteration 35320, lr = 0.00567546
I1029 01:38:57.348011 29475 solver.cpp:222] Iteration 35360 (1.29499 iter/s, 30.8882s/40 iters), loss = 1.46263
I1029 01:38:57.348181 29475 solver.cpp:241]     Train net output #0: loss = 1.46263 (* 1 = 1.46263 loss)
I1029 01:38:57.348197 29475 sgd_solver.cpp:105] Iteration 35360, lr = 0.0056709
I1029 01:39:28.433609 29475 solver.cpp:222] Iteration 35400 (1.28683 iter/s, 31.0842s/40 iters), loss = 1.74935
I1029 01:39:28.433815 29475 solver.cpp:241]     Train net output #0: loss = 1.74935 (* 1 = 1.74935 loss)
I1029 01:39:28.433831 29475 sgd_solver.cpp:105] Iteration 35400, lr = 0.00566634
I1029 01:40:00.077391 29475 solver.cpp:222] Iteration 35440 (1.26413 iter/s, 31.6424s/40 iters), loss = 1.79144
I1029 01:40:00.077574 29475 solver.cpp:241]     Train net output #0: loss = 1.79144 (* 1 = 1.79144 loss)
I1029 01:40:00.077590 29475 sgd_solver.cpp:105] Iteration 35440, lr = 0.00566177
I1029 01:40:31.781118 29475 solver.cpp:222] Iteration 35480 (1.26174 iter/s, 31.7023s/40 iters), loss = 1.47702
I1029 01:40:31.781383 29475 solver.cpp:241]     Train net output #0: loss = 1.47702 (* 1 = 1.47702 loss)
I1029 01:40:31.781409 29475 sgd_solver.cpp:105] Iteration 35480, lr = 0.00565722
I1029 01:40:46.948926 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_35500.caffemodel
I1029 01:40:46.982671 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_35500.solverstate
I1029 01:40:46.999387 29475 solver.cpp:334] Iteration 35500, Testing net (#0)
I1029 01:41:17.797413 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 01:41:18.004618 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.549
I1029 01:41:18.004683 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78584
I1029 01:41:18.004710 29475 solver.cpp:401]     Test net output #2: loss = 1.99641 (* 1 = 1.99641 loss)
I1029 01:41:34.249713 29475 solver.cpp:222] Iteration 35520 (0.640348 iter/s, 62.466s/40 iters), loss = 1.73198
I1029 01:41:34.249799 29475 solver.cpp:241]     Train net output #0: loss = 1.73198 (* 1 = 1.73198 loss)
I1029 01:41:34.249815 29475 sgd_solver.cpp:105] Iteration 35520, lr = 0.00565266
I1029 01:42:05.766096 29475 solver.cpp:222] Iteration 35560 (1.26923 iter/s, 31.5151s/40 iters), loss = 1.39195
I1029 01:42:05.766347 29475 solver.cpp:241]     Train net output #0: loss = 1.39195 (* 1 = 1.39195 loss)
I1029 01:42:05.766366 29475 sgd_solver.cpp:105] Iteration 35560, lr = 0.0056481
I1029 01:42:36.709205 29475 solver.cpp:222] Iteration 35600 (1.29275 iter/s, 30.9417s/40 iters), loss = 1.71433
I1029 01:42:36.709414 29475 solver.cpp:241]     Train net output #0: loss = 1.71433 (* 1 = 1.71433 loss)
I1029 01:42:36.709430 29475 sgd_solver.cpp:105] Iteration 35600, lr = 0.00564354
I1029 01:43:07.432363 29475 solver.cpp:222] Iteration 35640 (1.30201 iter/s, 30.7217s/40 iters), loss = 1.80614
I1029 01:43:07.432554 29475 solver.cpp:241]     Train net output #0: loss = 1.80614 (* 1 = 1.80614 loss)
I1029 01:43:07.432570 29475 sgd_solver.cpp:105] Iteration 35640, lr = 0.00563898
I1029 01:43:38.248386 29475 solver.cpp:222] Iteration 35680 (1.29808 iter/s, 30.8147s/40 iters), loss = 1.50951
I1029 01:43:38.248565 29475 solver.cpp:241]     Train net output #0: loss = 1.50951 (* 1 = 1.50951 loss)
I1029 01:43:38.248584 29475 sgd_solver.cpp:105] Iteration 35680, lr = 0.00563443
I1029 01:44:09.066406 29475 solver.cpp:222] Iteration 35720 (1.298 iter/s, 30.8167s/40 iters), loss = 1.5298
I1029 01:44:09.066604 29475 solver.cpp:241]     Train net output #0: loss = 1.5298 (* 1 = 1.5298 loss)
I1029 01:44:09.066622 29475 sgd_solver.cpp:105] Iteration 35720, lr = 0.00562987
I1029 01:44:40.233028 29475 solver.cpp:222] Iteration 35760 (1.28348 iter/s, 31.1652s/40 iters), loss = 1.46717
I1029 01:44:40.233227 29475 solver.cpp:241]     Train net output #0: loss = 1.46717 (* 1 = 1.46717 loss)
I1029 01:44:40.233244 29475 sgd_solver.cpp:105] Iteration 35760, lr = 0.00562532
I1029 01:45:11.715931 29475 solver.cpp:222] Iteration 35800 (1.27059 iter/s, 31.4815s/40 iters), loss = 1.3571
I1029 01:45:11.716131 29475 solver.cpp:241]     Train net output #0: loss = 1.3571 (* 1 = 1.3571 loss)
I1029 01:45:11.716148 29475 sgd_solver.cpp:105] Iteration 35800, lr = 0.00562077
I1029 01:45:42.562176 29475 solver.cpp:222] Iteration 35840 (1.29681 iter/s, 30.8449s/40 iters), loss = 1.69527
I1029 01:45:42.562407 29475 solver.cpp:241]     Train net output #0: loss = 1.69527 (* 1 = 1.69527 loss)
I1029 01:45:42.562424 29475 sgd_solver.cpp:105] Iteration 35840, lr = 0.00561621
I1029 01:46:13.432318 29475 solver.cpp:222] Iteration 35880 (1.29581 iter/s, 30.8687s/40 iters), loss = 1.48101
I1029 01:46:13.432507 29475 solver.cpp:241]     Train net output #0: loss = 1.48101 (* 1 = 1.48101 loss)
I1029 01:46:13.432523 29475 sgd_solver.cpp:105] Iteration 35880, lr = 0.00561166
I1029 01:46:44.510169 29475 solver.cpp:222] Iteration 35920 (1.28715 iter/s, 31.0765s/40 iters), loss = 1.44822
I1029 01:46:44.510396 29475 solver.cpp:241]     Train net output #0: loss = 1.44822 (* 1 = 1.44822 loss)
I1029 01:46:44.510416 29475 sgd_solver.cpp:105] Iteration 35920, lr = 0.00560711
I1029 01:47:20.674010 29475 solver.cpp:222] Iteration 35960 (1.10613 iter/s, 36.1622s/40 iters), loss = 1.69854
I1029 01:47:20.674271 29475 solver.cpp:241]     Train net output #0: loss = 1.69854 (* 1 = 1.69854 loss)
I1029 01:47:20.674300 29475 sgd_solver.cpp:105] Iteration 35960, lr = 0.00560256
I1029 01:47:55.329440 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_36000.caffemodel
I1029 01:47:55.377411 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_36000.solverstate
I1029 01:47:55.402120 29475 solver.cpp:334] Iteration 36000, Testing net (#0)
I1029 01:48:26.607516 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55248
I1029 01:48:26.607764 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78928
I1029 01:48:26.607784 29475 solver.cpp:401]     Test net output #2: loss = 1.98058 (* 1 = 1.98058 loss)
I1029 01:48:27.377810 29475 solver.cpp:222] Iteration 36000 (0.599691 iter/s, 66.701s/40 iters), loss = 1.75955
I1029 01:48:27.377878 29475 solver.cpp:241]     Train net output #0: loss = 1.75955 (* 1 = 1.75955 loss)
I1029 01:48:27.377894 29475 sgd_solver.cpp:105] Iteration 36000, lr = 0.00559801
I1029 01:48:58.515195 29475 solver.cpp:222] Iteration 36040 (1.28468 iter/s, 31.1361s/40 iters), loss = 1.57851
I1029 01:48:58.515388 29475 solver.cpp:241]     Train net output #0: loss = 1.57851 (* 1 = 1.57851 loss)
I1029 01:48:58.515406 29475 sgd_solver.cpp:105] Iteration 36040, lr = 0.00559347
I1029 01:49:29.300513 29475 solver.cpp:222] Iteration 36080 (1.29938 iter/s, 30.7839s/40 iters), loss = 1.71109
I1029 01:49:29.300706 29475 solver.cpp:241]     Train net output #0: loss = 1.71109 (* 1 = 1.71109 loss)
I1029 01:49:29.300724 29475 sgd_solver.cpp:105] Iteration 36080, lr = 0.00558892
I1029 01:50:00.482719 29475 solver.cpp:222] Iteration 36120 (1.28284 iter/s, 31.1808s/40 iters), loss = 1.53881
I1029 01:50:00.482897 29475 solver.cpp:241]     Train net output #0: loss = 1.53881 (* 1 = 1.53881 loss)
I1029 01:50:00.482914 29475 sgd_solver.cpp:105] Iteration 36120, lr = 0.00558437
I1029 01:50:31.458739 29475 solver.cpp:222] Iteration 36160 (1.29138 iter/s, 30.9747s/40 iters), loss = 1.56089
I1029 01:50:31.458931 29475 solver.cpp:241]     Train net output #0: loss = 1.56089 (* 1 = 1.56089 loss)
I1029 01:50:31.458951 29475 sgd_solver.cpp:105] Iteration 36160, lr = 0.00557983
I1029 01:51:02.535966 29475 solver.cpp:222] Iteration 36200 (1.28717 iter/s, 31.0759s/40 iters), loss = 1.55485
I1029 01:51:02.536180 29475 solver.cpp:241]     Train net output #0: loss = 1.55485 (* 1 = 1.55485 loss)
I1029 01:51:02.536196 29475 sgd_solver.cpp:105] Iteration 36200, lr = 0.00557528
I1029 01:51:33.505712 29475 solver.cpp:222] Iteration 36240 (1.29164 iter/s, 30.9684s/40 iters), loss = 1.51604
I1029 01:51:33.505913 29475 solver.cpp:241]     Train net output #0: loss = 1.51604 (* 1 = 1.51604 loss)
I1029 01:51:33.505930 29475 sgd_solver.cpp:105] Iteration 36240, lr = 0.00557074
I1029 01:52:13.424360 29475 solver.cpp:222] Iteration 36280 (1.00208 iter/s, 39.9169s/40 iters), loss = 1.62633
I1029 01:52:13.424607 29475 solver.cpp:241]     Train net output #0: loss = 1.62633 (* 1 = 1.62633 loss)
I1029 01:52:13.424633 29475 sgd_solver.cpp:105] Iteration 36280, lr = 0.0055662
I1029 01:52:44.837378 29475 solver.cpp:222] Iteration 36320 (1.27342 iter/s, 31.4116s/40 iters), loss = 1.56673
I1029 01:52:44.837585 29475 solver.cpp:241]     Train net output #0: loss = 1.56673 (* 1 = 1.56673 loss)
I1029 01:52:44.837604 29475 sgd_solver.cpp:105] Iteration 36320, lr = 0.00556165
I1029 01:53:15.650465 29475 solver.cpp:222] Iteration 36360 (1.29821 iter/s, 30.8117s/40 iters), loss = 1.61518
I1029 01:53:15.650650 29475 solver.cpp:241]     Train net output #0: loss = 1.61518 (* 1 = 1.61518 loss)
I1029 01:53:15.650667 29475 sgd_solver.cpp:105] Iteration 36360, lr = 0.00555711
I1029 01:53:46.896059 29475 solver.cpp:222] Iteration 36400 (1.28024 iter/s, 31.2442s/40 iters), loss = 1.5375
I1029 01:53:46.896239 29475 solver.cpp:241]     Train net output #0: loss = 1.5375 (* 1 = 1.5375 loss)
I1029 01:53:46.896255 29475 sgd_solver.cpp:105] Iteration 36400, lr = 0.00555257
I1029 01:54:17.805124 29475 solver.cpp:222] Iteration 36440 (1.29418 iter/s, 30.9077s/40 iters), loss = 1.5068
I1029 01:54:17.805320 29475 solver.cpp:241]     Train net output #0: loss = 1.5068 (* 1 = 1.5068 loss)
I1029 01:54:17.805338 29475 sgd_solver.cpp:105] Iteration 36440, lr = 0.00554803
I1029 01:54:49.966625 29475 solver.cpp:222] Iteration 36480 (1.24378 iter/s, 32.1601s/40 iters), loss = 1.78107
I1029 01:54:49.966843 29475 solver.cpp:241]     Train net output #0: loss = 1.78107 (* 1 = 1.78107 loss)
I1029 01:54:49.966861 29475 sgd_solver.cpp:105] Iteration 36480, lr = 0.0055435
I1029 01:55:04.794886 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_36500.caffemodel
I1029 01:55:04.830690 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_36500.solverstate
I1029 01:55:04.850463 29475 solver.cpp:334] Iteration 36500, Testing net (#0)
I1029 01:55:35.702327 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 01:55:35.909186 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54208
I1029 01:55:35.909235 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.783159
I1029 01:55:35.909248 29475 solver.cpp:401]     Test net output #2: loss = 2.07519 (* 1 = 2.07519 loss)
I1029 01:55:52.507369 29475 solver.cpp:222] Iteration 36520 (0.639609 iter/s, 62.5382s/40 iters), loss = 1.81572
I1029 01:55:52.507444 29475 solver.cpp:241]     Train net output #0: loss = 1.81572 (* 1 = 1.81572 loss)
I1029 01:55:52.507460 29475 sgd_solver.cpp:105] Iteration 36520, lr = 0.00553896
I1029 01:56:23.666348 29475 solver.cpp:222] Iteration 36560 (1.28379 iter/s, 31.1577s/40 iters), loss = 1.66716
I1029 01:56:23.666533 29475 solver.cpp:241]     Train net output #0: loss = 1.66716 (* 1 = 1.66716 loss)
I1029 01:56:23.666551 29475 sgd_solver.cpp:105] Iteration 36560, lr = 0.00553442
I1029 01:56:54.489002 29475 solver.cpp:222] Iteration 36600 (1.2978 iter/s, 30.8213s/40 iters), loss = 1.65365
I1029 01:56:54.489194 29475 solver.cpp:241]     Train net output #0: loss = 1.65365 (* 1 = 1.65365 loss)
I1029 01:56:54.489212 29475 sgd_solver.cpp:105] Iteration 36600, lr = 0.00552988
I1029 01:57:25.491546 29475 solver.cpp:222] Iteration 36640 (1.29027 iter/s, 31.0012s/40 iters), loss = 1.47357
I1029 01:57:25.491727 29475 solver.cpp:241]     Train net output #0: loss = 1.47357 (* 1 = 1.47357 loss)
I1029 01:57:25.491746 29475 sgd_solver.cpp:105] Iteration 36640, lr = 0.00552535
I1029 01:57:56.887482 29475 solver.cpp:222] Iteration 36680 (1.27411 iter/s, 31.3946s/40 iters), loss = 1.73115
I1029 01:57:56.887687 29475 solver.cpp:241]     Train net output #0: loss = 1.73115 (* 1 = 1.73115 loss)
I1029 01:57:56.887712 29475 sgd_solver.cpp:105] Iteration 36680, lr = 0.00552081
I1029 01:58:27.819959 29475 solver.cpp:222] Iteration 36720 (1.2932 iter/s, 30.9311s/40 iters), loss = 1.86229
I1029 01:58:27.820142 29475 solver.cpp:241]     Train net output #0: loss = 1.86229 (* 1 = 1.86229 loss)
I1029 01:58:27.820158 29475 sgd_solver.cpp:105] Iteration 36720, lr = 0.00551628
I1029 01:58:58.924768 29475 solver.cpp:222] Iteration 36760 (1.28603 iter/s, 31.1034s/40 iters), loss = 1.90184
I1029 01:58:58.924957 29475 solver.cpp:241]     Train net output #0: loss = 1.90184 (* 1 = 1.90184 loss)
I1029 01:58:58.924973 29475 sgd_solver.cpp:105] Iteration 36760, lr = 0.00551175
I1029 01:59:29.962291 29475 solver.cpp:222] Iteration 36800 (1.28882 iter/s, 31.0361s/40 iters), loss = 1.80098
I1029 01:59:29.962471 29475 solver.cpp:241]     Train net output #0: loss = 1.80098 (* 1 = 1.80098 loss)
I1029 01:59:29.962489 29475 sgd_solver.cpp:105] Iteration 36800, lr = 0.00550722
I1029 02:00:02.075809 29475 solver.cpp:222] Iteration 36840 (1.24564 iter/s, 32.1121s/40 iters), loss = 1.954
I1029 02:00:02.076004 29475 solver.cpp:241]     Train net output #0: loss = 1.954 (* 1 = 1.954 loss)
I1029 02:00:02.076020 29475 sgd_solver.cpp:105] Iteration 36840, lr = 0.00550269
I1029 02:00:33.036288 29475 solver.cpp:222] Iteration 36880 (1.29203 iter/s, 30.959s/40 iters), loss = 1.65974
I1029 02:00:33.036483 29475 solver.cpp:241]     Train net output #0: loss = 1.65974 (* 1 = 1.65974 loss)
I1029 02:00:33.036501 29475 sgd_solver.cpp:105] Iteration 36880, lr = 0.00549816
I1029 02:01:04.792498 29475 solver.cpp:222] Iteration 36920 (1.25965 iter/s, 31.7548s/40 iters), loss = 1.88339
I1029 02:01:04.792704 29475 solver.cpp:241]     Train net output #0: loss = 1.88339 (* 1 = 1.88339 loss)
I1029 02:01:04.792721 29475 sgd_solver.cpp:105] Iteration 36920, lr = 0.00549363
I1029 02:01:36.121469 29475 solver.cpp:222] Iteration 36960 (1.27683 iter/s, 31.3276s/40 iters), loss = 1.67786
I1029 02:01:36.121729 29475 solver.cpp:241]     Train net output #0: loss = 1.67786 (* 1 = 1.67786 loss)
I1029 02:01:36.121748 29475 sgd_solver.cpp:105] Iteration 36960, lr = 0.0054891
I1029 02:02:06.427781 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_37000.caffemodel
I1029 02:02:06.461293 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_37000.solverstate
I1029 02:02:06.477738 29475 solver.cpp:334] Iteration 37000, Testing net (#0)
I1029 02:02:37.448257 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55604
I1029 02:02:37.448467 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.788519
I1029 02:02:37.448482 29475 solver.cpp:401]     Test net output #2: loss = 1.96983 (* 1 = 1.96983 loss)
I1029 02:02:38.215639 29475 solver.cpp:222] Iteration 37000 (0.64421 iter/s, 62.0916s/40 iters), loss = 1.46526
I1029 02:02:38.215713 29475 solver.cpp:241]     Train net output #0: loss = 1.46526 (* 1 = 1.46526 loss)
I1029 02:02:38.215728 29475 sgd_solver.cpp:105] Iteration 37000, lr = 0.00548457
I1029 02:03:09.121742 29475 solver.cpp:222] Iteration 37040 (1.29429 iter/s, 30.9049s/40 iters), loss = 1.89685
I1029 02:03:09.121929 29475 solver.cpp:241]     Train net output #0: loss = 1.89685 (* 1 = 1.89685 loss)
I1029 02:03:09.121948 29475 sgd_solver.cpp:105] Iteration 37040, lr = 0.00548004
I1029 02:03:40.080382 29475 solver.cpp:222] Iteration 37080 (1.2921 iter/s, 30.9573s/40 iters), loss = 1.55208
I1029 02:03:40.080554 29475 solver.cpp:241]     Train net output #0: loss = 1.55208 (* 1 = 1.55208 loss)
I1029 02:03:40.080572 29475 sgd_solver.cpp:105] Iteration 37080, lr = 0.00547552
I1029 02:04:11.008647 29475 solver.cpp:222] Iteration 37120 (1.29337 iter/s, 30.9269s/40 iters), loss = 1.85875
I1029 02:04:11.008828 29475 solver.cpp:241]     Train net output #0: loss = 1.85875 (* 1 = 1.85875 loss)
I1029 02:04:11.008846 29475 sgd_solver.cpp:105] Iteration 37120, lr = 0.00547099
I1029 02:04:41.851574 29475 solver.cpp:222] Iteration 37160 (1.29695 iter/s, 30.8416s/40 iters), loss = 1.9018
I1029 02:04:41.851775 29475 solver.cpp:241]     Train net output #0: loss = 1.9018 (* 1 = 1.9018 loss)
I1029 02:04:41.851795 29475 sgd_solver.cpp:105] Iteration 37160, lr = 0.00546647
I1029 02:05:13.083098 29475 solver.cpp:222] Iteration 37200 (1.28081 iter/s, 31.2301s/40 iters), loss = 1.59084
I1029 02:05:13.083302 29475 solver.cpp:241]     Train net output #0: loss = 1.59084 (* 1 = 1.59084 loss)
I1029 02:05:13.083320 29475 sgd_solver.cpp:105] Iteration 37200, lr = 0.00546195
I1029 02:05:44.230969 29475 solver.cpp:222] Iteration 37240 (1.28425 iter/s, 31.1465s/40 iters), loss = 1.52022
I1029 02:05:44.231195 29475 solver.cpp:241]     Train net output #0: loss = 1.52022 (* 1 = 1.52022 loss)
I1029 02:05:44.231212 29475 sgd_solver.cpp:105] Iteration 37240, lr = 0.00545743
I1029 02:06:14.962055 29475 solver.cpp:222] Iteration 37280 (1.30167 iter/s, 30.7297s/40 iters), loss = 1.66746
I1029 02:06:14.962239 29475 solver.cpp:241]     Train net output #0: loss = 1.66746 (* 1 = 1.66746 loss)
I1029 02:06:14.962257 29475 sgd_solver.cpp:105] Iteration 37280, lr = 0.0054529
I1029 02:06:45.606164 29475 solver.cpp:222] Iteration 37320 (1.30537 iter/s, 30.6428s/40 iters), loss = 1.44042
I1029 02:06:45.606369 29475 solver.cpp:241]     Train net output #0: loss = 1.44042 (* 1 = 1.44042 loss)
I1029 02:06:45.606389 29475 sgd_solver.cpp:105] Iteration 37320, lr = 0.00544838
I1029 02:07:17.003567 29475 solver.cpp:222] Iteration 37360 (1.27405 iter/s, 31.396s/40 iters), loss = 1.83317
I1029 02:07:17.003790 29475 solver.cpp:241]     Train net output #0: loss = 1.83317 (* 1 = 1.83317 loss)
I1029 02:07:17.003808 29475 sgd_solver.cpp:105] Iteration 37360, lr = 0.00544386
I1029 02:07:48.999619 29475 solver.cpp:222] Iteration 37400 (1.25021 iter/s, 31.9946s/40 iters), loss = 1.56684
I1029 02:07:48.999871 29475 solver.cpp:241]     Train net output #0: loss = 1.56684 (* 1 = 1.56684 loss)
I1029 02:07:48.999900 29475 sgd_solver.cpp:105] Iteration 37400, lr = 0.00543935
I1029 02:08:20.771137 29475 solver.cpp:222] Iteration 37440 (1.25905 iter/s, 31.77s/40 iters), loss = 1.67986
I1029 02:08:20.771313 29475 solver.cpp:241]     Train net output #0: loss = 1.67986 (* 1 = 1.67986 loss)
I1029 02:08:20.771332 29475 sgd_solver.cpp:105] Iteration 37440, lr = 0.00543483
I1029 02:08:52.556908 29475 solver.cpp:222] Iteration 37480 (1.25848 iter/s, 31.7844s/40 iters), loss = 1.68269
I1029 02:08:52.557099 29475 solver.cpp:241]     Train net output #0: loss = 1.68269 (* 1 = 1.68269 loss)
I1029 02:08:52.557116 29475 sgd_solver.cpp:105] Iteration 37480, lr = 0.00543031
I1029 02:09:07.296581 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_37500.caffemodel
I1029 02:09:07.331467 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_37500.solverstate
I1029 02:09:07.446856 29475 solver.cpp:334] Iteration 37500, Testing net (#0)
I1029 02:09:38.262038 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 02:09:38.468884 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55132
I1029 02:09:38.468947 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.792079
I1029 02:09:38.468961 29475 solver.cpp:401]     Test net output #2: loss = 1.99963 (* 1 = 1.99963 loss)
I1029 02:09:54.763365 29475 solver.cpp:222] Iteration 37520 (0.643047 iter/s, 62.2039s/40 iters), loss = 1.53006
I1029 02:09:54.763438 29475 solver.cpp:241]     Train net output #0: loss = 1.53006 (* 1 = 1.53006 loss)
I1029 02:09:54.763455 29475 sgd_solver.cpp:105] Iteration 37520, lr = 0.00542579
I1029 02:10:02.591889 29523 data_layer.cpp:73] Restarting data prefetching from start.
I1029 02:10:26.182607 29475 solver.cpp:222] Iteration 37560 (1.27316 iter/s, 31.4179s/40 iters), loss = 1.7407
I1029 02:10:26.182808 29475 solver.cpp:241]     Train net output #0: loss = 1.7407 (* 1 = 1.7407 loss)
I1029 02:10:26.182826 29475 sgd_solver.cpp:105] Iteration 37560, lr = 0.00542128
I1029 02:10:57.148825 29475 solver.cpp:222] Iteration 37600 (1.29179 iter/s, 30.9648s/40 iters), loss = 1.4775
I1029 02:10:57.149010 29475 solver.cpp:241]     Train net output #0: loss = 1.4775 (* 1 = 1.4775 loss)
I1029 02:10:57.149027 29475 sgd_solver.cpp:105] Iteration 37600, lr = 0.00541676
I1029 02:11:28.019512 29475 solver.cpp:222] Iteration 37640 (1.29578 iter/s, 30.8693s/40 iters), loss = 1.57103
I1029 02:11:28.019714 29475 solver.cpp:241]     Train net output #0: loss = 1.57103 (* 1 = 1.57103 loss)
I1029 02:11:28.019732 29475 sgd_solver.cpp:105] Iteration 37640, lr = 0.00541225
I1029 02:11:58.595252 29475 solver.cpp:222] Iteration 37680 (1.30829 iter/s, 30.5744s/40 iters), loss = 1.50304
I1029 02:11:58.595434 29475 solver.cpp:241]     Train net output #0: loss = 1.50304 (* 1 = 1.50304 loss)
I1029 02:11:58.595451 29475 sgd_solver.cpp:105] Iteration 37680, lr = 0.00540774
I1029 02:12:29.299348 29475 solver.cpp:222] Iteration 37720 (1.30281 iter/s, 30.7028s/40 iters), loss = 1.97606
I1029 02:12:29.299530 29475 solver.cpp:241]     Train net output #0: loss = 1.97606 (* 1 = 1.97606 loss)
I1029 02:12:29.299546 29475 sgd_solver.cpp:105] Iteration 37720, lr = 0.00540323
I1029 02:12:59.887922 29475 solver.cpp:222] Iteration 37760 (1.30774 iter/s, 30.5872s/40 iters), loss = 1.45182
I1029 02:12:59.888087 29475 solver.cpp:241]     Train net output #0: loss = 1.45182 (* 1 = 1.45182 loss)
I1029 02:12:59.888103 29475 sgd_solver.cpp:105] Iteration 37760, lr = 0.00539872
I1029 02:13:30.561712 29475 solver.cpp:222] Iteration 37800 (1.3041 iter/s, 30.6725s/40 iters), loss = 1.77125
I1029 02:13:30.561872 29475 solver.cpp:241]     Train net output #0: loss = 1.77125 (* 1 = 1.77125 loss)
I1029 02:13:30.561890 29475 sgd_solver.cpp:105] Iteration 37800, lr = 0.00539421
I1029 02:14:01.413434 29475 solver.cpp:222] Iteration 37840 (1.29658 iter/s, 30.8503s/40 iters), loss = 1.34292
I1029 02:14:01.413658 29475 solver.cpp:241]     Train net output #0: loss = 1.34292 (* 1 = 1.34292 loss)
I1029 02:14:01.413688 29475 sgd_solver.cpp:105] Iteration 37840, lr = 0.0053897
I1029 02:14:32.179178 29475 solver.cpp:222] Iteration 37880 (1.30021 iter/s, 30.7644s/40 iters), loss = 1.63727
I1029 02:14:32.179369 29475 solver.cpp:241]     Train net output #0: loss = 1.63727 (* 1 = 1.63727 loss)
I1029 02:14:32.179388 29475 sgd_solver.cpp:105] Iteration 37880, lr = 0.00538519
I1029 02:15:02.943001 29475 solver.cpp:222] Iteration 37920 (1.30029 iter/s, 30.7625s/40 iters), loss = 1.54863
I1029 02:15:02.943169 29475 solver.cpp:241]     Train net output #0: loss = 1.54863 (* 1 = 1.54863 loss)
I1029 02:15:02.943186 29475 sgd_solver.cpp:105] Iteration 37920, lr = 0.00538068
I1029 02:15:33.724967 29475 solver.cpp:222] Iteration 37960 (1.29952 iter/s, 30.7806s/40 iters), loss = 1.45519
I1029 02:15:33.725152 29475 solver.cpp:241]     Train net output #0: loss = 1.45519 (* 1 = 1.45519 loss)
I1029 02:15:33.725169 29475 sgd_solver.cpp:105] Iteration 37960, lr = 0.00537617
I1029 02:16:03.826683 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_38000.caffemodel
I1029 02:16:03.865932 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_38000.solverstate
I1029 02:16:03.888705 29475 solver.cpp:334] Iteration 38000, Testing net (#0)
I1029 02:16:34.911058 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54896
I1029 02:16:34.911218 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.788879
I1029 02:16:34.911233 29475 solver.cpp:401]     Test net output #2: loss = 2.01509 (* 1 = 2.01509 loss)
I1029 02:16:35.675581 29475 solver.cpp:222] Iteration 38000 (0.645703 iter/s, 61.948s/40 iters), loss = 1.64783
I1029 02:16:35.675652 29475 solver.cpp:241]     Train net output #0: loss = 1.64783 (* 1 = 1.64783 loss)
I1029 02:16:35.675668 29475 sgd_solver.cpp:105] Iteration 38000, lr = 0.00537167
I1029 02:17:06.628146 29475 solver.cpp:222] Iteration 38040 (1.29235 iter/s, 30.9513s/40 iters), loss = 1.63499
I1029 02:17:06.628336 29475 solver.cpp:241]     Train net output #0: loss = 1.63499 (* 1 = 1.63499 loss)
I1029 02:17:06.628353 29475 sgd_solver.cpp:105] Iteration 38040, lr = 0.00536716
I1029 02:17:37.422816 29475 solver.cpp:222] Iteration 38080 (1.29898 iter/s, 30.7933s/40 iters), loss = 1.50215
I1029 02:17:37.423009 29475 solver.cpp:241]     Train net output #0: loss = 1.50215 (* 1 = 1.50215 loss)
I1029 02:17:37.423028 29475 sgd_solver.cpp:105] Iteration 38080, lr = 0.00536266
I1029 02:18:08.334437 29475 solver.cpp:222] Iteration 38120 (1.29407 iter/s, 30.9102s/40 iters), loss = 1.78416
I1029 02:18:08.334625 29475 solver.cpp:241]     Train net output #0: loss = 1.78416 (* 1 = 1.78416 loss)
I1029 02:18:08.334643 29475 sgd_solver.cpp:105] Iteration 38120, lr = 0.00535816
I1029 02:18:39.170948 29475 solver.cpp:222] Iteration 38160 (1.29722 iter/s, 30.8352s/40 iters), loss = 1.69387
I1029 02:18:39.171120 29475 solver.cpp:241]     Train net output #0: loss = 1.69387 (* 1 = 1.69387 loss)
I1029 02:18:39.171139 29475 sgd_solver.cpp:105] Iteration 38160, lr = 0.00535365
I1029 02:19:10.105203 29475 solver.cpp:222] Iteration 38200 (1.29312 iter/s, 30.9329s/40 iters), loss = 1.46506
I1029 02:19:10.105393 29475 solver.cpp:241]     Train net output #0: loss = 1.46506 (* 1 = 1.46506 loss)
I1029 02:19:10.105419 29475 sgd_solver.cpp:105] Iteration 38200, lr = 0.00534915
I1029 02:19:40.855419 29475 solver.cpp:222] Iteration 38240 (1.30086 iter/s, 30.7489s/40 iters), loss = 1.58124
I1029 02:19:40.855608 29475 solver.cpp:241]     Train net output #0: loss = 1.58124 (* 1 = 1.58124 loss)
I1029 02:19:40.855624 29475 sgd_solver.cpp:105] Iteration 38240, lr = 0.00534465
I1029 02:20:11.776206 29475 solver.cpp:222] Iteration 38280 (1.29369 iter/s, 30.9194s/40 iters), loss = 1.59955
I1029 02:20:11.776408 29475 solver.cpp:241]     Train net output #0: loss = 1.59955 (* 1 = 1.59955 loss)
I1029 02:20:11.776427 29475 sgd_solver.cpp:105] Iteration 38280, lr = 0.00534015
I1029 02:20:42.724135 29475 solver.cpp:222] Iteration 38320 (1.29255 iter/s, 30.9466s/40 iters), loss = 1.49524
I1029 02:20:42.724421 29475 solver.cpp:241]     Train net output #0: loss = 1.49524 (* 1 = 1.49524 loss)
I1029 02:20:42.724455 29475 sgd_solver.cpp:105] Iteration 38320, lr = 0.00533565
I1029 02:21:13.332202 29475 solver.cpp:222] Iteration 38360 (1.30691 iter/s, 30.6066s/40 iters), loss = 1.98529
I1029 02:21:13.332427 29475 solver.cpp:241]     Train net output #0: loss = 1.98529 (* 1 = 1.98529 loss)
I1029 02:21:13.332444 29475 sgd_solver.cpp:105] Iteration 38360, lr = 0.00533116
I1029 02:21:44.258965 29475 solver.cpp:222] Iteration 38400 (1.29344 iter/s, 30.9254s/40 iters), loss = 1.86332
I1029 02:21:44.259146 29475 solver.cpp:241]     Train net output #0: loss = 1.86332 (* 1 = 1.86332 loss)
I1029 02:21:44.259162 29475 sgd_solver.cpp:105] Iteration 38400, lr = 0.00532666
I1029 02:22:24.678231 29475 solver.cpp:222] Iteration 38440 (0.989669 iter/s, 40.4175s/40 iters), loss = 1.67158
I1029 02:22:24.678519 29475 solver.cpp:241]     Train net output #0: loss = 1.67158 (* 1 = 1.67158 loss)
I1029 02:22:24.678547 29475 sgd_solver.cpp:105] Iteration 38440, lr = 0.00532216
I1029 02:22:57.241847 29475 solver.cpp:222] Iteration 38480 (1.22842 iter/s, 32.5621s/40 iters), loss = 1.76468
I1029 02:22:57.242085 29475 solver.cpp:241]     Train net output #0: loss = 1.76468 (* 1 = 1.76468 loss)
I1029 02:22:57.242105 29475 sgd_solver.cpp:105] Iteration 38480, lr = 0.00531767
I1029 02:23:12.150248 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_38500.caffemodel
I1029 02:23:12.184790 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_38500.solverstate
I1029 02:23:12.201488 29475 solver.cpp:334] Iteration 38500, Testing net (#0)
I1029 02:23:43.002449 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 02:23:43.209347 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.553
I1029 02:23:43.209408 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.788
I1029 02:23:43.209422 29475 solver.cpp:401]     Test net output #2: loss = 1.98514 (* 1 = 1.98514 loss)
I1029 02:23:59.650323 29475 solver.cpp:222] Iteration 38520 (0.640966 iter/s, 62.4058s/40 iters), loss = 1.66524
I1029 02:23:59.650405 29475 solver.cpp:241]     Train net output #0: loss = 1.66524 (* 1 = 1.66524 loss)
I1029 02:23:59.650424 29475 sgd_solver.cpp:105] Iteration 38520, lr = 0.00531317
I1029 02:24:30.838217 29475 solver.cpp:222] Iteration 38560 (1.2826 iter/s, 31.1866s/40 iters), loss = 1.81355
I1029 02:24:30.838418 29475 solver.cpp:241]     Train net output #0: loss = 1.81355 (* 1 = 1.81355 loss)
I1029 02:24:30.838438 29475 sgd_solver.cpp:105] Iteration 38560, lr = 0.00530868
I1029 02:25:02.171681 29475 solver.cpp:222] Iteration 38600 (1.27665 iter/s, 31.3321s/40 iters), loss = 1.62224
I1029 02:25:02.171866 29475 solver.cpp:241]     Train net output #0: loss = 1.62224 (* 1 = 1.62224 loss)
I1029 02:25:02.171882 29475 sgd_solver.cpp:105] Iteration 38600, lr = 0.00530419
I1029 02:25:32.852666 29475 solver.cpp:222] Iteration 38640 (1.3038 iter/s, 30.6796s/40 iters), loss = 1.56141
I1029 02:25:32.852836 29475 solver.cpp:241]     Train net output #0: loss = 1.56141 (* 1 = 1.56141 loss)
I1029 02:25:32.852852 29475 sgd_solver.cpp:105] Iteration 38640, lr = 0.0052997
I1029 02:26:03.507992 29475 solver.cpp:222] Iteration 38680 (1.30489 iter/s, 30.654s/40 iters), loss = 1.76303
I1029 02:26:03.508164 29475 solver.cpp:241]     Train net output #0: loss = 1.76303 (* 1 = 1.76303 loss)
I1029 02:26:03.508193 29475 sgd_solver.cpp:105] Iteration 38680, lr = 0.00529521
I1029 02:26:46.369175 29475 solver.cpp:222] Iteration 38720 (0.933284 iter/s, 42.8594s/40 iters), loss = 1.87807
I1029 02:26:46.369537 29475 solver.cpp:241]     Train net output #0: loss = 1.87807 (* 1 = 1.87807 loss)
I1029 02:26:46.369560 29475 sgd_solver.cpp:105] Iteration 38720, lr = 0.00529072
I1029 02:27:19.596465 29475 solver.cpp:222] Iteration 38760 (1.20389 iter/s, 33.2256s/40 iters), loss = 1.77569
I1029 02:27:19.596786 29475 solver.cpp:241]     Train net output #0: loss = 1.77569 (* 1 = 1.77569 loss)
I1029 02:27:19.596824 29475 sgd_solver.cpp:105] Iteration 38760, lr = 0.00528623
I1029 02:27:50.655539 29475 solver.cpp:222] Iteration 38800 (1.28793 iter/s, 31.0576s/40 iters), loss = 1.67216
I1029 02:27:50.655742 29475 solver.cpp:241]     Train net output #0: loss = 1.67216 (* 1 = 1.67216 loss)
I1029 02:27:50.655761 29475 sgd_solver.cpp:105] Iteration 38800, lr = 0.00528174
I1029 02:28:23.065692 29475 solver.cpp:222] Iteration 38840 (1.23424 iter/s, 32.4087s/40 iters), loss = 1.79696
I1029 02:28:23.065912 29475 solver.cpp:241]     Train net output #0: loss = 1.79696 (* 1 = 1.79696 loss)
I1029 02:28:23.065935 29475 sgd_solver.cpp:105] Iteration 38840, lr = 0.00527725
I1029 02:29:01.411342 29475 solver.cpp:222] Iteration 38880 (1.04319 iter/s, 38.344s/40 iters), loss = 1.37029
I1029 02:29:01.411589 29475 solver.cpp:241]     Train net output #0: loss = 1.37029 (* 1 = 1.37029 loss)
I1029 02:29:01.411618 29475 sgd_solver.cpp:105] Iteration 38880, lr = 0.00527276
I1029 02:29:38.587044 29475 solver.cpp:222] Iteration 38920 (1.07602 iter/s, 37.1741s/40 iters), loss = 1.88427
I1029 02:29:38.587262 29475 solver.cpp:241]     Train net output #0: loss = 1.88427 (* 1 = 1.88427 loss)
I1029 02:29:38.587280 29475 sgd_solver.cpp:105] Iteration 38920, lr = 0.00526828
I1029 02:30:09.801028 29475 solver.cpp:222] Iteration 38960 (1.28154 iter/s, 31.2125s/40 iters), loss = 1.36432
I1029 02:30:09.801213 29475 solver.cpp:241]     Train net output #0: loss = 1.36432 (* 1 = 1.36432 loss)
I1029 02:30:09.801229 29475 sgd_solver.cpp:105] Iteration 38960, lr = 0.00526379
I1029 02:30:39.790470 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_39000.caffemodel
I1029 02:30:39.833058 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_39000.solverstate
I1029 02:30:39.855990 29475 solver.cpp:334] Iteration 39000, Testing net (#0)
I1029 02:31:10.854964 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55456
I1029 02:31:10.855152 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7886
I1029 02:31:10.855170 29475 solver.cpp:401]     Test net output #2: loss = 2.02184 (* 1 = 2.02184 loss)
I1029 02:31:11.621075 29475 solver.cpp:222] Iteration 39000 (0.647065 iter/s, 61.8175s/40 iters), loss = 1.39623
I1029 02:31:11.621143 29475 solver.cpp:241]     Train net output #0: loss = 1.39623 (* 1 = 1.39623 loss)
I1029 02:31:11.621158 29475 sgd_solver.cpp:105] Iteration 39000, lr = 0.00525931
I1029 02:31:42.497998 29475 solver.cpp:222] Iteration 39040 (1.29552 iter/s, 30.8757s/40 iters), loss = 1.58127
I1029 02:31:42.498188 29475 solver.cpp:241]     Train net output #0: loss = 1.58127 (* 1 = 1.58127 loss)
I1029 02:31:42.498203 29475 sgd_solver.cpp:105] Iteration 39040, lr = 0.00525483
I1029 02:32:14.196712 29475 solver.cpp:222] Iteration 39080 (1.26194 iter/s, 31.6973s/40 iters), loss = 1.51057
I1029 02:32:14.196887 29475 solver.cpp:241]     Train net output #0: loss = 1.51057 (* 1 = 1.51057 loss)
I1029 02:32:14.196904 29475 sgd_solver.cpp:105] Iteration 39080, lr = 0.00525035
I1029 02:32:45.061280 29475 solver.cpp:222] Iteration 39120 (1.29604 iter/s, 30.8632s/40 iters), loss = 1.70148
I1029 02:32:45.061457 29475 solver.cpp:241]     Train net output #0: loss = 1.70148 (* 1 = 1.70148 loss)
I1029 02:32:45.061476 29475 sgd_solver.cpp:105] Iteration 39120, lr = 0.00524586
I1029 02:33:16.125049 29475 solver.cpp:222] Iteration 39160 (1.28773 iter/s, 31.0624s/40 iters), loss = 1.6035
I1029 02:33:16.125227 29475 solver.cpp:241]     Train net output #0: loss = 1.6035 (* 1 = 1.6035 loss)
I1029 02:33:16.125244 29475 sgd_solver.cpp:105] Iteration 39160, lr = 0.00524138
I1029 02:33:46.923174 29475 solver.cpp:222] Iteration 39200 (1.29884 iter/s, 30.7968s/40 iters), loss = 1.62326
I1029 02:33:46.923393 29475 solver.cpp:241]     Train net output #0: loss = 1.62326 (* 1 = 1.62326 loss)
I1029 02:33:46.923411 29475 sgd_solver.cpp:105] Iteration 39200, lr = 0.00523691
I1029 02:34:18.108074 29475 solver.cpp:222] Iteration 39240 (1.28273 iter/s, 31.1835s/40 iters), loss = 1.37079
I1029 02:34:18.108264 29475 solver.cpp:241]     Train net output #0: loss = 1.37079 (* 1 = 1.37079 loss)
I1029 02:34:18.108281 29475 sgd_solver.cpp:105] Iteration 39240, lr = 0.00523243
I1029 02:34:49.244822 29475 solver.cpp:222] Iteration 39280 (1.28471 iter/s, 31.1354s/40 iters), loss = 1.36308
I1029 02:34:49.245020 29475 solver.cpp:241]     Train net output #0: loss = 1.36308 (* 1 = 1.36308 loss)
I1029 02:34:49.245038 29475 sgd_solver.cpp:105] Iteration 39280, lr = 0.00522795
I1029 02:35:20.370028 29475 solver.cpp:222] Iteration 39320 (1.28519 iter/s, 31.1238s/40 iters), loss = 1.60413
I1029 02:35:20.370206 29475 solver.cpp:241]     Train net output #0: loss = 1.60413 (* 1 = 1.60413 loss)
I1029 02:35:20.370226 29475 sgd_solver.cpp:105] Iteration 39320, lr = 0.00522347
I1029 02:35:51.594975 29475 solver.cpp:222] Iteration 39360 (1.28108 iter/s, 31.2236s/40 iters), loss = 1.47539
I1029 02:35:51.595181 29475 solver.cpp:241]     Train net output #0: loss = 1.47539 (* 1 = 1.47539 loss)
I1029 02:35:51.595197 29475 sgd_solver.cpp:105] Iteration 39360, lr = 0.005219
I1029 02:36:22.769093 29475 solver.cpp:222] Iteration 39400 (1.28318 iter/s, 31.1726s/40 iters), loss = 1.63224
I1029 02:36:22.769261 29475 solver.cpp:241]     Train net output #0: loss = 1.63224 (* 1 = 1.63224 loss)
I1029 02:36:22.769281 29475 sgd_solver.cpp:105] Iteration 39400, lr = 0.00521452
I1029 02:36:53.766773 29475 solver.cpp:222] Iteration 39440 (1.29047 iter/s, 30.9963s/40 iters), loss = 1.84153
I1029 02:36:53.766950 29475 solver.cpp:241]     Train net output #0: loss = 1.84153 (* 1 = 1.84153 loss)
I1029 02:36:53.766969 29475 sgd_solver.cpp:105] Iteration 39440, lr = 0.00521005
I1029 02:37:24.901260 29475 solver.cpp:222] Iteration 39480 (1.28481 iter/s, 31.1331s/40 iters), loss = 1.62859
I1029 02:37:24.901440 29475 solver.cpp:241]     Train net output #0: loss = 1.62859 (* 1 = 1.62859 loss)
I1029 02:37:24.901459 29475 sgd_solver.cpp:105] Iteration 39480, lr = 0.00520557
I1029 02:37:39.593953 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_39500.caffemodel
I1029 02:37:39.628412 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_39500.solverstate
I1029 02:37:39.646540 29475 solver.cpp:334] Iteration 39500, Testing net (#0)
I1029 02:38:10.592325 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 02:38:10.802124 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54928
I1029 02:38:10.802186 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78748
I1029 02:38:10.802199 29475 solver.cpp:401]     Test net output #2: loss = 2.05526 (* 1 = 2.05526 loss)
I1029 02:38:27.103904 29475 solver.cpp:222] Iteration 39520 (0.643085 iter/s, 62.2001s/40 iters), loss = 1.76286
I1029 02:38:27.103976 29475 solver.cpp:241]     Train net output #0: loss = 1.76286 (* 1 = 1.76286 loss)
I1029 02:38:27.103991 29475 sgd_solver.cpp:105] Iteration 39520, lr = 0.0052011
I1029 02:38:57.862218 29475 solver.cpp:222] Iteration 39560 (1.30051 iter/s, 30.7571s/40 iters), loss = 1.69359
I1029 02:38:57.862434 29475 solver.cpp:241]     Train net output #0: loss = 1.69359 (* 1 = 1.69359 loss)
I1029 02:38:57.862450 29475 sgd_solver.cpp:105] Iteration 39560, lr = 0.00519663
I1029 02:39:28.471099 29475 solver.cpp:222] Iteration 39600 (1.30687 iter/s, 30.6074s/40 iters), loss = 1.38619
I1029 02:39:28.471256 29475 solver.cpp:241]     Train net output #0: loss = 1.38619 (* 1 = 1.38619 loss)
I1029 02:39:28.471274 29475 sgd_solver.cpp:105] Iteration 39600, lr = 0.00519216
I1029 02:39:59.663452 29475 solver.cpp:222] Iteration 39640 (1.28242 iter/s, 31.191s/40 iters), loss = 1.50749
I1029 02:39:59.663642 29475 solver.cpp:241]     Train net output #0: loss = 1.50749 (* 1 = 1.50749 loss)
I1029 02:39:59.663662 29475 sgd_solver.cpp:105] Iteration 39640, lr = 0.00518769
I1029 02:40:30.738399 29475 solver.cpp:222] Iteration 39680 (1.28727 iter/s, 31.0736s/40 iters), loss = 1.63101
I1029 02:40:30.738626 29475 solver.cpp:241]     Train net output #0: loss = 1.63101 (* 1 = 1.63101 loss)
I1029 02:40:30.738644 29475 sgd_solver.cpp:105] Iteration 39680, lr = 0.00518322
I1029 02:41:01.573166 29475 solver.cpp:222] Iteration 39720 (1.2973 iter/s, 30.8334s/40 iters), loss = 1.57233
I1029 02:41:01.573385 29475 solver.cpp:241]     Train net output #0: loss = 1.57233 (* 1 = 1.57233 loss)
I1029 02:41:01.573402 29475 sgd_solver.cpp:105] Iteration 39720, lr = 0.00517875
I1029 02:41:32.501564 29475 solver.cpp:222] Iteration 39760 (1.29337 iter/s, 30.927s/40 iters), loss = 1.68632
I1029 02:41:32.501761 29475 solver.cpp:241]     Train net output #0: loss = 1.68632 (* 1 = 1.68632 loss)
I1029 02:41:32.501778 29475 sgd_solver.cpp:105] Iteration 39760, lr = 0.00517429
I1029 02:42:03.971639 29475 solver.cpp:222] Iteration 39800 (1.2711 iter/s, 31.4687s/40 iters), loss = 1.88676
I1029 02:42:03.971827 29475 solver.cpp:241]     Train net output #0: loss = 1.88676 (* 1 = 1.88676 loss)
I1029 02:42:03.971843 29475 sgd_solver.cpp:105] Iteration 39800, lr = 0.00516982
I1029 02:42:34.788375 29475 solver.cpp:222] Iteration 39840 (1.29806 iter/s, 30.8153s/40 iters), loss = 1.4835
I1029 02:42:34.788553 29475 solver.cpp:241]     Train net output #0: loss = 1.4835 (* 1 = 1.4835 loss)
I1029 02:42:34.788570 29475 sgd_solver.cpp:105] Iteration 39840, lr = 0.00516535
I1029 02:43:05.605664 29475 solver.cpp:222] Iteration 39880 (1.29803 iter/s, 30.8159s/40 iters), loss = 1.80432
I1029 02:43:05.605857 29475 solver.cpp:241]     Train net output #0: loss = 1.80432 (* 1 = 1.80432 loss)
I1029 02:43:05.605875 29475 sgd_solver.cpp:105] Iteration 39880, lr = 0.00516089
I1029 02:43:36.551959 29475 solver.cpp:222] Iteration 39920 (1.29262 iter/s, 30.9449s/40 iters), loss = 1.4245
I1029 02:43:36.552145 29475 solver.cpp:241]     Train net output #0: loss = 1.4245 (* 1 = 1.4245 loss)
I1029 02:43:36.552163 29475 sgd_solver.cpp:105] Iteration 39920, lr = 0.00515643
I1029 02:44:07.188062 29475 solver.cpp:222] Iteration 39960 (1.30571 iter/s, 30.6348s/40 iters), loss = 1.5894
I1029 02:44:07.188231 29475 solver.cpp:241]     Train net output #0: loss = 1.5894 (* 1 = 1.5894 loss)
I1029 02:44:07.188251 29475 sgd_solver.cpp:105] Iteration 39960, lr = 0.00515196
I1029 02:44:37.179505 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_40000.caffemodel
I1029 02:44:37.213832 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_40000.solverstate
I1029 02:44:37.231537 29475 solver.cpp:334] Iteration 40000, Testing net (#0)
I1029 02:45:08.277539 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5542
I1029 02:45:08.277705 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7884
I1029 02:45:08.277721 29475 solver.cpp:401]     Test net output #2: loss = 1.97544 (* 1 = 1.97544 loss)
I1029 02:45:09.049648 29475 solver.cpp:222] Iteration 40000 (0.646631 iter/s, 61.8591s/40 iters), loss = 1.34785
I1029 02:45:09.049723 29475 solver.cpp:241]     Train net output #0: loss = 1.34785 (* 1 = 1.34785 loss)
I1029 02:45:09.049744 29475 sgd_solver.cpp:105] Iteration 40000, lr = 0.0051475
I1029 02:45:33.805974 29523 data_layer.cpp:73] Restarting data prefetching from start.
I1029 02:45:39.883339 29475 solver.cpp:222] Iteration 40040 (1.29733 iter/s, 30.8324s/40 iters), loss = 1.86116
I1029 02:45:39.883533 29475 solver.cpp:241]     Train net output #0: loss = 1.86116 (* 1 = 1.86116 loss)
I1029 02:45:39.883550 29475 sgd_solver.cpp:105] Iteration 40040, lr = 0.00514304
I1029 02:46:10.455339 29475 solver.cpp:222] Iteration 40080 (1.30844 iter/s, 30.5707s/40 iters), loss = 1.74605
I1029 02:46:10.455513 29475 solver.cpp:241]     Train net output #0: loss = 1.74605 (* 1 = 1.74605 loss)
I1029 02:46:10.455529 29475 sgd_solver.cpp:105] Iteration 40080, lr = 0.00513858
I1029 02:46:41.022696 29475 solver.cpp:222] Iteration 40120 (1.30864 iter/s, 30.566s/40 iters), loss = 1.87879
I1029 02:46:41.022907 29475 solver.cpp:241]     Train net output #0: loss = 1.87879 (* 1 = 1.87879 loss)
I1029 02:46:41.022922 29475 sgd_solver.cpp:105] Iteration 40120, lr = 0.00513412
I1029 02:47:11.579710 29475 solver.cpp:222] Iteration 40160 (1.30909 iter/s, 30.5556s/40 iters), loss = 1.45923
I1029 02:47:11.579897 29475 solver.cpp:241]     Train net output #0: loss = 1.45923 (* 1 = 1.45923 loss)
I1029 02:47:11.579916 29475 sgd_solver.cpp:105] Iteration 40160, lr = 0.00512967
I1029 02:47:42.341091 29475 solver.cpp:222] Iteration 40200 (1.30039 iter/s, 30.76s/40 iters), loss = 1.98799
I1029 02:47:42.341279 29475 solver.cpp:241]     Train net output #0: loss = 1.98799 (* 1 = 1.98799 loss)
I1029 02:47:42.341301 29475 sgd_solver.cpp:105] Iteration 40200, lr = 0.00512521
I1029 02:48:13.210767 29475 solver.cpp:222] Iteration 40240 (1.29583 iter/s, 30.8683s/40 iters), loss = 1.99543
I1029 02:48:13.210940 29475 solver.cpp:241]     Train net output #0: loss = 1.99543 (* 1 = 1.99543 loss)
I1029 02:48:13.210957 29475 sgd_solver.cpp:105] Iteration 40240, lr = 0.00512075
I1029 02:48:44.323128 29475 solver.cpp:222] Iteration 40280 (1.28572 iter/s, 31.111s/40 iters), loss = 1.49333
I1029 02:48:44.323489 29475 solver.cpp:241]     Train net output #0: loss = 1.49333 (* 1 = 1.49333 loss)
I1029 02:48:44.323508 29475 sgd_solver.cpp:105] Iteration 40280, lr = 0.0051163
I1029 02:49:15.416746 29475 solver.cpp:222] Iteration 40320 (1.2865 iter/s, 31.0921s/40 iters), loss = 1.75189
I1029 02:49:15.416932 29475 solver.cpp:241]     Train net output #0: loss = 1.75189 (* 1 = 1.75189 loss)
I1029 02:49:15.416951 29475 sgd_solver.cpp:105] Iteration 40320, lr = 0.00511184
I1029 02:49:46.397210 29475 solver.cpp:222] Iteration 40360 (1.29119 iter/s, 30.9791s/40 iters), loss = 1.53118
I1029 02:49:46.397387 29475 solver.cpp:241]     Train net output #0: loss = 1.53118 (* 1 = 1.53118 loss)
I1029 02:49:46.397404 29475 sgd_solver.cpp:105] Iteration 40360, lr = 0.00510739
I1029 02:50:16.854931 29475 solver.cpp:222] Iteration 40400 (1.31335 iter/s, 30.4564s/40 iters), loss = 1.24516
I1029 02:50:16.855087 29475 solver.cpp:241]     Train net output #0: loss = 1.24516 (* 1 = 1.24516 loss)
I1029 02:50:16.855104 29475 sgd_solver.cpp:105] Iteration 40400, lr = 0.00510294
I1029 02:50:47.451845 29475 solver.cpp:222] Iteration 40440 (1.30738 iter/s, 30.5956s/40 iters), loss = 1.60995
I1029 02:50:47.451964 29475 solver.cpp:241]     Train net output #0: loss = 1.60995 (* 1 = 1.60995 loss)
I1029 02:50:47.451982 29475 sgd_solver.cpp:105] Iteration 40440, lr = 0.00509848
I1029 02:51:18.634948 29475 solver.cpp:222] Iteration 40480 (1.2828 iter/s, 31.1818s/40 iters), loss = 1.79135
I1029 02:51:18.635149 29475 solver.cpp:241]     Train net output #0: loss = 1.79135 (* 1 = 1.79135 loss)
I1029 02:51:18.635167 29475 sgd_solver.cpp:105] Iteration 40480, lr = 0.00509403
I1029 02:51:33.727838 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_40500.caffemodel
I1029 02:51:33.761735 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_40500.solverstate
I1029 02:51:33.779134 29475 solver.cpp:334] Iteration 40500, Testing net (#0)
I1029 02:52:04.668871 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 02:52:04.876291 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55372
I1029 02:52:04.876353 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7904
I1029 02:52:04.876368 29475 solver.cpp:401]     Test net output #2: loss = 1.96683 (* 1 = 1.96683 loss)
I1029 02:52:21.468678 29475 solver.cpp:222] Iteration 40520 (0.636628 iter/s, 62.8311s/40 iters), loss = 1.93632
I1029 02:52:21.468778 29475 solver.cpp:241]     Train net output #0: loss = 1.93632 (* 1 = 1.93632 loss)
I1029 02:52:21.468801 29475 sgd_solver.cpp:105] Iteration 40520, lr = 0.00508958
I1029 02:52:52.649966 29475 solver.cpp:222] Iteration 40560 (1.28287 iter/s, 31.18s/40 iters), loss = 1.35243
I1029 02:52:52.650233 29475 solver.cpp:241]     Train net output #0: loss = 1.35243 (* 1 = 1.35243 loss)
I1029 02:52:52.650274 29475 sgd_solver.cpp:105] Iteration 40560, lr = 0.00508513
I1029 02:53:24.010900 29475 solver.cpp:222] Iteration 40600 (1.27553 iter/s, 31.3595s/40 iters), loss = 1.61556
I1029 02:53:24.011093 29475 solver.cpp:241]     Train net output #0: loss = 1.61556 (* 1 = 1.61556 loss)
I1029 02:53:24.011111 29475 sgd_solver.cpp:105] Iteration 40600, lr = 0.00508069
I1029 02:53:55.096200 29475 solver.cpp:222] Iteration 40640 (1.28684 iter/s, 31.0839s/40 iters), loss = 1.37214
I1029 02:53:55.096390 29475 solver.cpp:241]     Train net output #0: loss = 1.37214 (* 1 = 1.37214 loss)
I1029 02:53:55.096420 29475 sgd_solver.cpp:105] Iteration 40640, lr = 0.00507624
I1029 02:54:26.398382 29475 solver.cpp:222] Iteration 40680 (1.27792 iter/s, 31.3008s/40 iters), loss = 1.39931
I1029 02:54:26.398566 29475 solver.cpp:241]     Train net output #0: loss = 1.39931 (* 1 = 1.39931 loss)
I1029 02:54:26.398582 29475 sgd_solver.cpp:105] Iteration 40680, lr = 0.00507179
I1029 02:54:58.038931 29475 solver.cpp:222] Iteration 40720 (1.26426 iter/s, 31.6391s/40 iters), loss = 1.42176
I1029 02:54:58.039108 29475 solver.cpp:241]     Train net output #0: loss = 1.42176 (* 1 = 1.42176 loss)
I1029 02:54:58.039126 29475 sgd_solver.cpp:105] Iteration 40720, lr = 0.00506735
I1029 02:55:29.942318 29475 solver.cpp:222] Iteration 40760 (1.25384 iter/s, 31.902s/40 iters), loss = 1.61754
I1029 02:55:29.942523 29475 solver.cpp:241]     Train net output #0: loss = 1.61754 (* 1 = 1.61754 loss)
I1029 02:55:29.942540 29475 sgd_solver.cpp:105] Iteration 40760, lr = 0.0050629
I1029 02:56:02.164458 29475 solver.cpp:222] Iteration 40800 (1.24144 iter/s, 32.2207s/40 iters), loss = 2.02317
I1029 02:56:02.164672 29475 solver.cpp:241]     Train net output #0: loss = 2.02317 (* 1 = 2.02317 loss)
I1029 02:56:02.164691 29475 sgd_solver.cpp:105] Iteration 40800, lr = 0.00505846
I1029 02:56:33.697993 29475 solver.cpp:222] Iteration 40840 (1.26855 iter/s, 31.5321s/40 iters), loss = 1.76334
I1029 02:56:33.698247 29475 solver.cpp:241]     Train net output #0: loss = 1.76334 (* 1 = 1.76334 loss)
I1029 02:56:33.698276 29475 sgd_solver.cpp:105] Iteration 40840, lr = 0.00505402
I1029 02:57:05.577024 29475 solver.cpp:222] Iteration 40880 (1.2548 iter/s, 31.8775s/40 iters), loss = 1.16033
I1029 02:57:05.577262 29475 solver.cpp:241]     Train net output #0: loss = 1.16033 (* 1 = 1.16033 loss)
I1029 02:57:05.577286 29475 sgd_solver.cpp:105] Iteration 40880, lr = 0.00504957
I1029 02:57:36.991063 29475 solver.cpp:222] Iteration 40920 (1.27337 iter/s, 31.4126s/40 iters), loss = 1.6192
I1029 02:57:36.991295 29475 solver.cpp:241]     Train net output #0: loss = 1.6192 (* 1 = 1.6192 loss)
I1029 02:57:36.991328 29475 sgd_solver.cpp:105] Iteration 40920, lr = 0.00504513
I1029 02:58:09.082387 29475 solver.cpp:222] Iteration 40960 (1.2465 iter/s, 32.0899s/40 iters), loss = 1.75522
I1029 02:58:09.082592 29475 solver.cpp:241]     Train net output #0: loss = 1.75522 (* 1 = 1.75522 loss)
I1029 02:58:09.082618 29475 sgd_solver.cpp:105] Iteration 40960, lr = 0.00504069
I1029 02:58:39.828704 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_41000.caffemodel
I1029 02:58:39.863360 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_41000.solverstate
I1029 02:58:39.880110 29475 solver.cpp:334] Iteration 41000, Testing net (#0)
I1029 02:59:10.861755 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56012
I1029 02:59:10.861929 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.791799
I1029 02:59:10.861944 29475 solver.cpp:401]     Test net output #2: loss = 1.9473 (* 1 = 1.9473 loss)
I1029 02:59:11.626827 29475 solver.cpp:222] Iteration 41000 (0.639571 iter/s, 62.5419s/40 iters), loss = 1.64965
I1029 02:59:11.626901 29475 solver.cpp:241]     Train net output #0: loss = 1.64965 (* 1 = 1.64965 loss)
I1029 02:59:11.626919 29475 sgd_solver.cpp:105] Iteration 41000, lr = 0.00503625
I1029 02:59:42.599328 29475 solver.cpp:222] Iteration 41040 (1.29152 iter/s, 30.9712s/40 iters), loss = 1.54757
I1029 02:59:42.599635 29475 solver.cpp:241]     Train net output #0: loss = 1.54757 (* 1 = 1.54757 loss)
I1029 02:59:42.599670 29475 sgd_solver.cpp:105] Iteration 41040, lr = 0.00503182
I1029 03:00:13.296264 29475 solver.cpp:222] Iteration 41080 (1.30312 iter/s, 30.6955s/40 iters), loss = 1.62502
I1029 03:00:13.296463 29475 solver.cpp:241]     Train net output #0: loss = 1.62502 (* 1 = 1.62502 loss)
I1029 03:00:13.296479 29475 sgd_solver.cpp:105] Iteration 41080, lr = 0.00502738
I1029 03:00:44.532114 29475 solver.cpp:222] Iteration 41120 (1.28064 iter/s, 31.2344s/40 iters), loss = 1.61809
I1029 03:00:44.532366 29475 solver.cpp:241]     Train net output #0: loss = 1.61809 (* 1 = 1.61809 loss)
I1029 03:00:44.532392 29475 sgd_solver.cpp:105] Iteration 41120, lr = 0.00502294
I1029 03:01:16.066098 29475 solver.cpp:222] Iteration 41160 (1.26853 iter/s, 31.5325s/40 iters), loss = 1.47131
I1029 03:01:16.066287 29475 solver.cpp:241]     Train net output #0: loss = 1.47131 (* 1 = 1.47131 loss)
I1029 03:01:16.066309 29475 sgd_solver.cpp:105] Iteration 41160, lr = 0.00501851
I1029 03:01:55.475370 29475 solver.cpp:222] Iteration 41200 (1.01503 iter/s, 39.4076s/40 iters), loss = 1.58706
I1029 03:01:55.475632 29475 solver.cpp:241]     Train net output #0: loss = 1.58706 (* 1 = 1.58706 loss)
I1029 03:01:55.475657 29475 sgd_solver.cpp:105] Iteration 41200, lr = 0.00501407
I1029 03:02:27.258697 29475 solver.cpp:222] Iteration 41240 (1.25858 iter/s, 31.7818s/40 iters), loss = 1.33957
I1029 03:02:27.258922 29475 solver.cpp:241]     Train net output #0: loss = 1.33957 (* 1 = 1.33957 loss)
I1029 03:02:27.258940 29475 sgd_solver.cpp:105] Iteration 41240, lr = 0.00500964
I1029 03:02:59.833480 29475 solver.cpp:222] Iteration 41280 (1.228 iter/s, 32.5733s/40 iters), loss = 1.30865
I1029 03:02:59.833714 29475 solver.cpp:241]     Train net output #0: loss = 1.30865 (* 1 = 1.30865 loss)
I1029 03:02:59.833736 29475 sgd_solver.cpp:105] Iteration 41280, lr = 0.0050052
I1029 03:03:32.411383 29475 solver.cpp:222] Iteration 41320 (1.22788 iter/s, 32.5764s/40 iters), loss = 1.88835
I1029 03:03:32.411586 29475 solver.cpp:241]     Train net output #0: loss = 1.88835 (* 1 = 1.88835 loss)
I1029 03:03:32.411602 29475 sgd_solver.cpp:105] Iteration 41320, lr = 0.00500077
I1029 03:04:03.335012 29475 solver.cpp:222] Iteration 41360 (1.29357 iter/s, 30.9223s/40 iters), loss = 1.7715
I1029 03:04:03.335201 29475 solver.cpp:241]     Train net output #0: loss = 1.7715 (* 1 = 1.7715 loss)
I1029 03:04:03.335217 29475 sgd_solver.cpp:105] Iteration 41360, lr = 0.00499634
I1029 03:04:34.383103 29475 solver.cpp:222] Iteration 41400 (1.28838 iter/s, 31.0467s/40 iters), loss = 1.5661
I1029 03:04:34.383275 29475 solver.cpp:241]     Train net output #0: loss = 1.5661 (* 1 = 1.5661 loss)
I1029 03:04:34.383293 29475 sgd_solver.cpp:105] Iteration 41400, lr = 0.00499191
I1029 03:05:05.333422 29475 solver.cpp:222] Iteration 41440 (1.29245 iter/s, 30.949s/40 iters), loss = 1.55221
I1029 03:05:05.333590 29475 solver.cpp:241]     Train net output #0: loss = 1.55221 (* 1 = 1.55221 loss)
I1029 03:05:05.333606 29475 sgd_solver.cpp:105] Iteration 41440, lr = 0.00498748
I1029 03:05:36.268802 29475 solver.cpp:222] Iteration 41480 (1.29308 iter/s, 30.934s/40 iters), loss = 1.66699
I1029 03:05:36.268980 29475 solver.cpp:241]     Train net output #0: loss = 1.66699 (* 1 = 1.66699 loss)
I1029 03:05:36.268997 29475 sgd_solver.cpp:105] Iteration 41480, lr = 0.00498305
I1029 03:05:50.927492 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_41500.caffemodel
I1029 03:05:50.961807 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_41500.solverstate
I1029 03:05:50.978446 29475 solver.cpp:334] Iteration 41500, Testing net (#0)
I1029 03:06:21.759249 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 03:06:21.966258 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55072
I1029 03:06:21.966336 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.791359
I1029 03:06:21.966351 29475 solver.cpp:401]     Test net output #2: loss = 1.99204 (* 1 = 1.99204 loss)
I1029 03:06:38.142431 29475 solver.cpp:222] Iteration 41520 (0.646505 iter/s, 61.8711s/40 iters), loss = 1.57163
I1029 03:06:38.142501 29475 solver.cpp:241]     Train net output #0: loss = 1.57163 (* 1 = 1.57163 loss)
I1029 03:06:38.142518 29475 sgd_solver.cpp:105] Iteration 41520, lr = 0.00497863
I1029 03:07:08.963214 29475 solver.cpp:222] Iteration 41560 (1.29788 iter/s, 30.8195s/40 iters), loss = 1.68908
I1029 03:07:08.963390 29475 solver.cpp:241]     Train net output #0: loss = 1.68908 (* 1 = 1.68908 loss)
I1029 03:07:08.963407 29475 sgd_solver.cpp:105] Iteration 41560, lr = 0.0049742
I1029 03:07:39.956822 29475 solver.cpp:222] Iteration 41600 (1.29064 iter/s, 30.9923s/40 iters), loss = 1.67182
I1029 03:07:39.956965 29475 solver.cpp:241]     Train net output #0: loss = 1.67182 (* 1 = 1.67182 loss)
I1029 03:07:39.956981 29475 sgd_solver.cpp:105] Iteration 41600, lr = 0.00496977
I1029 03:08:11.172387 29475 solver.cpp:222] Iteration 41640 (1.28147 iter/s, 31.2142s/40 iters), loss = 1.72812
I1029 03:08:11.172557 29475 solver.cpp:241]     Train net output #0: loss = 1.72812 (* 1 = 1.72812 loss)
I1029 03:08:11.172574 29475 sgd_solver.cpp:105] Iteration 41640, lr = 0.00496535
I1029 03:08:42.272033 29475 solver.cpp:222] Iteration 41680 (1.28624 iter/s, 31.0983s/40 iters), loss = 1.52762
I1029 03:08:42.272218 29475 solver.cpp:241]     Train net output #0: loss = 1.52762 (* 1 = 1.52762 loss)
I1029 03:08:42.272236 29475 sgd_solver.cpp:105] Iteration 41680, lr = 0.00496093
I1029 03:09:13.265758 29475 solver.cpp:222] Iteration 41720 (1.29064 iter/s, 30.9924s/40 iters), loss = 1.56265
I1029 03:09:13.265928 29475 solver.cpp:241]     Train net output #0: loss = 1.56265 (* 1 = 1.56265 loss)
I1029 03:09:13.265945 29475 sgd_solver.cpp:105] Iteration 41720, lr = 0.0049565
I1029 03:09:44.096772 29475 solver.cpp:222] Iteration 41760 (1.29745 iter/s, 30.8297s/40 iters), loss = 1.63402
I1029 03:09:44.096966 29475 solver.cpp:241]     Train net output #0: loss = 1.63402 (* 1 = 1.63402 loss)
I1029 03:09:44.096987 29475 sgd_solver.cpp:105] Iteration 41760, lr = 0.00495208
I1029 03:10:14.663792 29475 solver.cpp:222] Iteration 41800 (1.30866 iter/s, 30.5657s/40 iters), loss = 1.93003
I1029 03:10:14.663987 29475 solver.cpp:241]     Train net output #0: loss = 1.93003 (* 1 = 1.93003 loss)
I1029 03:10:14.664011 29475 sgd_solver.cpp:105] Iteration 41800, lr = 0.00494766
I1029 03:10:45.709796 29475 solver.cpp:222] Iteration 41840 (1.28847 iter/s, 31.0446s/40 iters), loss = 1.29384
I1029 03:10:45.709969 29475 solver.cpp:241]     Train net output #0: loss = 1.29384 (* 1 = 1.29384 loss)
I1029 03:10:45.709990 29475 sgd_solver.cpp:105] Iteration 41840, lr = 0.00494324
I1029 03:11:16.942204 29475 solver.cpp:222] Iteration 41880 (1.28078 iter/s, 31.231s/40 iters), loss = 1.5942
I1029 03:11:16.942418 29475 solver.cpp:241]     Train net output #0: loss = 1.5942 (* 1 = 1.5942 loss)
I1029 03:11:16.942436 29475 sgd_solver.cpp:105] Iteration 41880, lr = 0.00493882
I1029 03:11:48.322612 29475 solver.cpp:222] Iteration 41920 (1.27474 iter/s, 31.379s/40 iters), loss = 1.15202
I1029 03:11:48.322794 29475 solver.cpp:241]     Train net output #0: loss = 1.15202 (* 1 = 1.15202 loss)
I1029 03:11:48.322811 29475 sgd_solver.cpp:105] Iteration 41920, lr = 0.0049344
I1029 03:12:19.000547 29475 solver.cpp:222] Iteration 41960 (1.30393 iter/s, 30.6765s/40 iters), loss = 1.56705
I1029 03:12:19.000723 29475 solver.cpp:241]     Train net output #0: loss = 1.56705 (* 1 = 1.56705 loss)
I1029 03:12:19.000741 29475 sgd_solver.cpp:105] Iteration 41960, lr = 0.00492999
I1029 03:12:48.800814 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_42000.caffemodel
I1029 03:12:48.836578 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_42000.solverstate
I1029 03:12:48.857458 29475 solver.cpp:334] Iteration 42000, Testing net (#0)
I1029 03:13:19.998419 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55732
I1029 03:13:19.998661 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.790639
I1029 03:13:19.998678 29475 solver.cpp:401]     Test net output #2: loss = 1.9644 (* 1 = 1.9644 loss)
I1029 03:13:20.770570 29475 solver.cpp:222] Iteration 42000 (0.647589 iter/s, 61.7675s/40 iters), loss = 1.56516
I1029 03:13:20.770644 29475 solver.cpp:241]     Train net output #0: loss = 1.56516 (* 1 = 1.56516 loss)
I1029 03:13:20.770661 29475 sgd_solver.cpp:105] Iteration 42000, lr = 0.00492557
I1029 03:13:51.455801 29475 solver.cpp:222] Iteration 42040 (1.30361 iter/s, 30.684s/40 iters), loss = 1.5989
I1029 03:13:51.455981 29475 solver.cpp:241]     Train net output #0: loss = 1.5989 (* 1 = 1.5989 loss)
I1029 03:13:51.455998 29475 sgd_solver.cpp:105] Iteration 42040, lr = 0.00492115
I1029 03:14:22.425849 29475 solver.cpp:222] Iteration 42080 (1.29163 iter/s, 30.9687s/40 iters), loss = 1.76008
I1029 03:14:22.426044 29475 solver.cpp:241]     Train net output #0: loss = 1.76008 (* 1 = 1.76008 loss)
I1029 03:14:22.426061 29475 sgd_solver.cpp:105] Iteration 42080, lr = 0.00491674
I1029 03:14:53.097985 29475 solver.cpp:222] Iteration 42120 (1.30417 iter/s, 30.6708s/40 iters), loss = 1.57397
I1029 03:14:53.098172 29475 solver.cpp:241]     Train net output #0: loss = 1.57397 (* 1 = 1.57397 loss)
I1029 03:14:53.098188 29475 sgd_solver.cpp:105] Iteration 42120, lr = 0.00491232
I1029 03:15:24.283488 29475 solver.cpp:222] Iteration 42160 (1.2827 iter/s, 31.1841s/40 iters), loss = 1.63988
I1029 03:15:24.283674 29475 solver.cpp:241]     Train net output #0: loss = 1.63988 (* 1 = 1.63988 loss)
I1029 03:15:24.283691 29475 sgd_solver.cpp:105] Iteration 42160, lr = 0.00490791
I1029 03:15:55.147261 29475 solver.cpp:222] Iteration 42200 (1.29607 iter/s, 30.8624s/40 iters), loss = 1.7263
I1029 03:15:55.147449 29475 solver.cpp:241]     Train net output #0: loss = 1.7263 (* 1 = 1.7263 loss)
I1029 03:15:55.147466 29475 sgd_solver.cpp:105] Iteration 42200, lr = 0.0049035
I1029 03:16:27.213121 29475 solver.cpp:222] Iteration 42240 (1.24749 iter/s, 32.0644s/40 iters), loss = 1.70245
I1029 03:16:27.213382 29475 solver.cpp:241]     Train net output #0: loss = 1.70245 (* 1 = 1.70245 loss)
I1029 03:16:27.213407 29475 sgd_solver.cpp:105] Iteration 42240, lr = 0.00489909
I1029 03:16:59.355303 29475 solver.cpp:222] Iteration 42280 (1.24453 iter/s, 32.1406s/40 iters), loss = 1.72748
I1029 03:16:59.355489 29475 solver.cpp:241]     Train net output #0: loss = 1.72748 (* 1 = 1.72748 loss)
I1029 03:16:59.355507 29475 sgd_solver.cpp:105] Iteration 42280, lr = 0.00489468
I1029 03:17:29.895354 29475 solver.cpp:222] Iteration 42320 (1.30982 iter/s, 30.5386s/40 iters), loss = 1.50014
I1029 03:17:29.895521 29475 solver.cpp:241]     Train net output #0: loss = 1.50014 (* 1 = 1.50014 loss)
I1029 03:17:29.895539 29475 sgd_solver.cpp:105] Iteration 42320, lr = 0.00489027
I1029 03:18:00.817700 29475 solver.cpp:222] Iteration 42360 (1.29362 iter/s, 30.921s/40 iters), loss = 1.65961
I1029 03:18:00.817880 29475 solver.cpp:241]     Train net output #0: loss = 1.65961 (* 1 = 1.65961 loss)
I1029 03:18:00.817896 29475 sgd_solver.cpp:105] Iteration 42360, lr = 0.00488586
I1029 03:18:31.701803 29475 solver.cpp:222] Iteration 42400 (1.29522 iter/s, 30.8828s/40 iters), loss = 1.5299
I1029 03:18:31.701984 29475 solver.cpp:241]     Train net output #0: loss = 1.5299 (* 1 = 1.5299 loss)
I1029 03:18:31.702002 29475 sgd_solver.cpp:105] Iteration 42400, lr = 0.00488145
I1029 03:19:04.181068 29475 solver.cpp:222] Iteration 42440 (1.23161 iter/s, 32.4778s/40 iters), loss = 1.56832
I1029 03:19:04.181253 29475 solver.cpp:241]     Train net output #0: loss = 1.56832 (* 1 = 1.56832 loss)
I1029 03:19:04.181272 29475 sgd_solver.cpp:105] Iteration 42440, lr = 0.00487705
I1029 03:19:35.504201 29475 solver.cpp:222] Iteration 42480 (1.27707 iter/s, 31.3218s/40 iters), loss = 1.53431
I1029 03:19:35.504439 29475 solver.cpp:241]     Train net output #0: loss = 1.53431 (* 1 = 1.53431 loss)
I1029 03:19:35.504467 29475 sgd_solver.cpp:105] Iteration 42480, lr = 0.00487264
I1029 03:19:50.149992 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_42500.caffemodel
I1029 03:19:50.184202 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_42500.solverstate
I1029 03:19:50.200973 29475 solver.cpp:334] Iteration 42500, Testing net (#0)
I1029 03:20:20.951532 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 03:20:21.158639 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55296
I1029 03:20:21.158705 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.790039
I1029 03:20:21.158720 29475 solver.cpp:401]     Test net output #2: loss = 1.99999 (* 1 = 1.99999 loss)
I1029 03:20:37.368114 29475 solver.cpp:222] Iteration 42520 (0.646607 iter/s, 61.8614s/40 iters), loss = 1.63296
I1029 03:20:37.368185 29475 solver.cpp:241]     Train net output #0: loss = 1.63296 (* 1 = 1.63296 loss)
I1029 03:20:37.368199 29475 sgd_solver.cpp:105] Iteration 42520, lr = 0.00486824
I1029 03:20:48.403682 29523 data_layer.cpp:73] Restarting data prefetching from start.
I1029 03:21:08.401736 29475 solver.cpp:222] Iteration 42560 (1.28898 iter/s, 31.0324s/40 iters), loss = 1.49818
I1029 03:21:08.401957 29475 solver.cpp:241]     Train net output #0: loss = 1.49818 (* 1 = 1.49818 loss)
I1029 03:21:08.401975 29475 sgd_solver.cpp:105] Iteration 42560, lr = 0.00486383
I1029 03:21:39.729375 29475 solver.cpp:222] Iteration 42600 (1.27689 iter/s, 31.3261s/40 iters), loss = 1.5077
I1029 03:21:39.729554 29475 solver.cpp:241]     Train net output #0: loss = 1.5077 (* 1 = 1.5077 loss)
I1029 03:21:39.729573 29475 sgd_solver.cpp:105] Iteration 42600, lr = 0.00485943
I1029 03:22:10.882961 29475 solver.cpp:222] Iteration 42640 (1.28402 iter/s, 31.1522s/40 iters), loss = 1.69507
I1029 03:22:10.883141 29475 solver.cpp:241]     Train net output #0: loss = 1.69507 (* 1 = 1.69507 loss)
I1029 03:22:10.883158 29475 sgd_solver.cpp:105] Iteration 42640, lr = 0.00485503
I1029 03:22:41.968005 29475 solver.cpp:222] Iteration 42680 (1.28685 iter/s, 31.0836s/40 iters), loss = 1.64454
I1029 03:22:41.968202 29475 solver.cpp:241]     Train net output #0: loss = 1.64454 (* 1 = 1.64454 loss)
I1029 03:22:41.968221 29475 sgd_solver.cpp:105] Iteration 42680, lr = 0.00485063
I1029 03:23:12.955966 29475 solver.cpp:222] Iteration 42720 (1.29088 iter/s, 30.9866s/40 iters), loss = 1.62032
I1029 03:23:12.956149 29475 solver.cpp:241]     Train net output #0: loss = 1.62032 (* 1 = 1.62032 loss)
I1029 03:23:12.956167 29475 sgd_solver.cpp:105] Iteration 42720, lr = 0.00484623
I1029 03:23:44.334844 29475 solver.cpp:222] Iteration 42760 (1.2748 iter/s, 31.3775s/40 iters), loss = 1.42565
I1029 03:23:44.335117 29475 solver.cpp:241]     Train net output #0: loss = 1.42565 (* 1 = 1.42565 loss)
I1029 03:23:44.335149 29475 sgd_solver.cpp:105] Iteration 42760, lr = 0.00484183
I1029 03:24:16.627882 29475 solver.cpp:222] Iteration 42800 (1.23871 iter/s, 32.2916s/40 iters), loss = 1.40654
I1029 03:24:16.628074 29475 solver.cpp:241]     Train net output #0: loss = 1.40654 (* 1 = 1.40654 loss)
I1029 03:24:16.628093 29475 sgd_solver.cpp:105] Iteration 42800, lr = 0.00483743
I1029 03:24:48.101763 29475 solver.cpp:222] Iteration 42840 (1.27095 iter/s, 31.4725s/40 iters), loss = 1.47472
I1029 03:24:48.101990 29475 solver.cpp:241]     Train net output #0: loss = 1.47472 (* 1 = 1.47472 loss)
I1029 03:24:48.102008 29475 sgd_solver.cpp:105] Iteration 42840, lr = 0.00483303
I1029 03:25:46.019598 29475 solver.cpp:222] Iteration 42880 (0.690662 iter/s, 57.9154s/40 iters), loss = 1.80655
I1029 03:25:46.019837 29475 solver.cpp:241]     Train net output #0: loss = 1.80655 (* 1 = 1.80655 loss)
I1029 03:25:46.019865 29475 sgd_solver.cpp:105] Iteration 42880, lr = 0.00482864
I1029 03:26:17.489459 29475 solver.cpp:222] Iteration 42920 (1.27111 iter/s, 31.4684s/40 iters), loss = 1.54127
I1029 03:26:17.489688 29475 solver.cpp:241]     Train net output #0: loss = 1.54127 (* 1 = 1.54127 loss)
I1029 03:26:17.489722 29475 sgd_solver.cpp:105] Iteration 42920, lr = 0.00482424
I1029 03:26:48.310585 29475 solver.cpp:222] Iteration 42960 (1.29787 iter/s, 30.8197s/40 iters), loss = 1.40536
I1029 03:26:48.310776 29475 solver.cpp:241]     Train net output #0: loss = 1.40536 (* 1 = 1.40536 loss)
I1029 03:26:48.310793 29475 sgd_solver.cpp:105] Iteration 42960, lr = 0.00481985
I1029 03:27:19.032256 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_43000.caffemodel
I1029 03:27:19.067360 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_43000.solverstate
I1029 03:27:19.086627 29475 solver.cpp:334] Iteration 43000, Testing net (#0)
I1029 03:27:50.097615 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55232
I1029 03:27:50.097777 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.787799
I1029 03:27:50.097793 29475 solver.cpp:401]     Test net output #2: loss = 1.98614 (* 1 = 1.98614 loss)
I1029 03:27:50.878545 29475 solver.cpp:222] Iteration 43000 (0.639331 iter/s, 62.5654s/40 iters), loss = 1.66151
I1029 03:27:50.878623 29475 solver.cpp:241]     Train net output #0: loss = 1.66151 (* 1 = 1.66151 loss)
I1029 03:27:50.878638 29475 sgd_solver.cpp:105] Iteration 43000, lr = 0.00481545
I1029 03:28:22.568840 29475 solver.cpp:222] Iteration 43040 (1.26227 iter/s, 31.689s/40 iters), loss = 1.56836
I1029 03:28:22.569119 29475 solver.cpp:241]     Train net output #0: loss = 1.56836 (* 1 = 1.56836 loss)
I1029 03:28:22.569146 29475 sgd_solver.cpp:105] Iteration 43040, lr = 0.00481106
I1029 03:28:53.902068 29475 solver.cpp:222] Iteration 43080 (1.27666 iter/s, 31.3318s/40 iters), loss = 1.89258
I1029 03:28:53.902264 29475 solver.cpp:241]     Train net output #0: loss = 1.89258 (* 1 = 1.89258 loss)
I1029 03:28:53.902281 29475 sgd_solver.cpp:105] Iteration 43080, lr = 0.00480667
I1029 03:29:25.257757 29475 solver.cpp:222] Iteration 43120 (1.27574 iter/s, 31.3543s/40 iters), loss = 1.33995
I1029 03:29:25.257959 29475 solver.cpp:241]     Train net output #0: loss = 1.33995 (* 1 = 1.33995 loss)
I1029 03:29:25.257977 29475 sgd_solver.cpp:105] Iteration 43120, lr = 0.00480228
I1029 03:29:56.968117 29475 solver.cpp:222] Iteration 43160 (1.26147 iter/s, 31.709s/40 iters), loss = 1.68098
I1029 03:29:56.968317 29475 solver.cpp:241]     Train net output #0: loss = 1.68098 (* 1 = 1.68098 loss)
I1029 03:29:56.968334 29475 sgd_solver.cpp:105] Iteration 43160, lr = 0.00479789
I1029 03:30:28.674485 29475 solver.cpp:222] Iteration 43200 (1.26163 iter/s, 31.705s/40 iters), loss = 1.78157
I1029 03:30:28.674722 29475 solver.cpp:241]     Train net output #0: loss = 1.78157 (* 1 = 1.78157 loss)
I1029 03:30:28.674748 29475 sgd_solver.cpp:105] Iteration 43200, lr = 0.0047935
I1029 03:31:00.534598 29475 solver.cpp:222] Iteration 43240 (1.25555 iter/s, 31.8587s/40 iters), loss = 1.93371
I1029 03:31:00.534804 29475 solver.cpp:241]     Train net output #0: loss = 1.93371 (* 1 = 1.93371 loss)
I1029 03:31:00.534829 29475 sgd_solver.cpp:105] Iteration 43240, lr = 0.00478911
I1029 03:31:32.654355 29475 solver.cpp:222] Iteration 43280 (1.2454 iter/s, 32.1183s/40 iters), loss = 1.52288
I1029 03:31:32.654546 29475 solver.cpp:241]     Train net output #0: loss = 1.52288 (* 1 = 1.52288 loss)
I1029 03:31:32.654577 29475 sgd_solver.cpp:105] Iteration 43280, lr = 0.00478473
I1029 03:32:04.595556 29475 solver.cpp:222] Iteration 43320 (1.25236 iter/s, 31.9398s/40 iters), loss = 1.69263
I1029 03:32:04.595793 29475 solver.cpp:241]     Train net output #0: loss = 1.69263 (* 1 = 1.69263 loss)
I1029 03:32:04.595815 29475 sgd_solver.cpp:105] Iteration 43320, lr = 0.00478034
I1029 03:32:35.990753 29475 solver.cpp:222] Iteration 43360 (1.27414 iter/s, 31.3938s/40 iters), loss = 1.79884
I1029 03:32:35.990948 29475 solver.cpp:241]     Train net output #0: loss = 1.79884 (* 1 = 1.79884 loss)
I1029 03:32:35.990970 29475 sgd_solver.cpp:105] Iteration 43360, lr = 0.00477595
I1029 03:33:07.189793 29475 solver.cpp:222] Iteration 43400 (1.28215 iter/s, 31.1976s/40 iters), loss = 1.45706
I1029 03:33:07.190074 29475 solver.cpp:241]     Train net output #0: loss = 1.45706 (* 1 = 1.45706 loss)
I1029 03:33:07.190096 29475 sgd_solver.cpp:105] Iteration 43400, lr = 0.00477157
I1029 03:33:38.769477 29475 solver.cpp:222] Iteration 43440 (1.2667 iter/s, 31.5781s/40 iters), loss = 1.71009
I1029 03:33:38.769676 29475 solver.cpp:241]     Train net output #0: loss = 1.71009 (* 1 = 1.71009 loss)
I1029 03:33:38.769695 29475 sgd_solver.cpp:105] Iteration 43440, lr = 0.00476719
I1029 03:34:09.600939 29475 solver.cpp:222] Iteration 43480 (1.29743 iter/s, 30.8301s/40 iters), loss = 1.76716
I1029 03:34:09.601130 29475 solver.cpp:241]     Train net output #0: loss = 1.76716 (* 1 = 1.76716 loss)
I1029 03:34:09.601146 29475 sgd_solver.cpp:105] Iteration 43480, lr = 0.0047628
I1029 03:34:24.168099 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_43500.caffemodel
I1029 03:34:24.204011 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_43500.solverstate
I1029 03:34:24.222122 29475 solver.cpp:334] Iteration 43500, Testing net (#0)
I1029 03:34:55.140476 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 03:34:55.348232 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55212
I1029 03:34:55.348300 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79252
I1029 03:34:55.348315 29475 solver.cpp:401]     Test net output #2: loss = 2.01354 (* 1 = 2.01354 loss)
I1029 03:35:11.633826 29475 solver.cpp:222] Iteration 43520 (0.644845 iter/s, 62.0304s/40 iters), loss = 1.90464
I1029 03:35:11.633909 29475 solver.cpp:241]     Train net output #0: loss = 1.90464 (* 1 = 1.90464 loss)
I1029 03:35:11.633934 29475 sgd_solver.cpp:105] Iteration 43520, lr = 0.00475842
I1029 03:35:42.917624 29475 solver.cpp:222] Iteration 43560 (1.27867 iter/s, 31.2825s/40 iters), loss = 1.45244
I1029 03:35:42.917807 29475 solver.cpp:241]     Train net output #0: loss = 1.45244 (* 1 = 1.45244 loss)
I1029 03:35:42.917824 29475 sgd_solver.cpp:105] Iteration 43560, lr = 0.00475404
I1029 03:36:14.127060 29475 solver.cpp:222] Iteration 43600 (1.28172 iter/s, 31.2081s/40 iters), loss = 1.50309
I1029 03:36:14.127233 29475 solver.cpp:241]     Train net output #0: loss = 1.50309 (* 1 = 1.50309 loss)
I1029 03:36:14.127252 29475 sgd_solver.cpp:105] Iteration 43600, lr = 0.00474966
I1029 03:36:45.501612 29475 solver.cpp:222] Iteration 43640 (1.27498 iter/s, 31.3731s/40 iters), loss = 1.52528
I1029 03:36:45.501788 29475 solver.cpp:241]     Train net output #0: loss = 1.52528 (* 1 = 1.52528 loss)
I1029 03:36:45.501807 29475 sgd_solver.cpp:105] Iteration 43640, lr = 0.00474529
I1029 03:37:16.950196 29475 solver.cpp:222] Iteration 43680 (1.27198 iter/s, 31.4471s/40 iters), loss = 1.49862
I1029 03:37:16.950382 29475 solver.cpp:241]     Train net output #0: loss = 1.49862 (* 1 = 1.49862 loss)
I1029 03:37:16.950400 29475 sgd_solver.cpp:105] Iteration 43680, lr = 0.00474091
I1029 03:37:47.924808 29475 solver.cpp:222] Iteration 43720 (1.29144 iter/s, 30.9732s/40 iters), loss = 1.58485
I1029 03:37:47.924989 29475 solver.cpp:241]     Train net output #0: loss = 1.58485 (* 1 = 1.58485 loss)
I1029 03:37:47.925006 29475 sgd_solver.cpp:105] Iteration 43720, lr = 0.00473653
I1029 03:38:18.648471 29475 solver.cpp:222] Iteration 43760 (1.30199 iter/s, 30.7223s/40 iters), loss = 1.4692
I1029 03:38:18.648655 29475 solver.cpp:241]     Train net output #0: loss = 1.4692 (* 1 = 1.4692 loss)
I1029 03:38:18.648672 29475 sgd_solver.cpp:105] Iteration 43760, lr = 0.00473215
I1029 03:38:49.365003 29475 solver.cpp:222] Iteration 43800 (1.30229 iter/s, 30.7152s/40 iters), loss = 1.72076
I1029 03:38:49.365185 29475 solver.cpp:241]     Train net output #0: loss = 1.72076 (* 1 = 1.72076 loss)
I1029 03:38:49.365200 29475 sgd_solver.cpp:105] Iteration 43800, lr = 0.00472778
I1029 03:39:20.042955 29475 solver.cpp:222] Iteration 43840 (1.30392 iter/s, 30.6766s/40 iters), loss = 1.73851
I1029 03:39:20.043128 29475 solver.cpp:241]     Train net output #0: loss = 1.73851 (* 1 = 1.73851 loss)
I1029 03:39:20.043145 29475 sgd_solver.cpp:105] Iteration 43840, lr = 0.0047234
I1029 03:39:50.605872 29475 solver.cpp:222] Iteration 43880 (1.30883 iter/s, 30.5616s/40 iters), loss = 1.73404
I1029 03:39:50.606030 29475 solver.cpp:241]     Train net output #0: loss = 1.73404 (* 1 = 1.73404 loss)
I1029 03:39:50.606047 29475 sgd_solver.cpp:105] Iteration 43880, lr = 0.00471903
I1029 03:40:21.169276 29475 solver.cpp:222] Iteration 43920 (1.30881 iter/s, 30.5621s/40 iters), loss = 1.78182
I1029 03:40:21.169464 29475 solver.cpp:241]     Train net output #0: loss = 1.78182 (* 1 = 1.78182 loss)
I1029 03:40:21.169481 29475 sgd_solver.cpp:105] Iteration 43920, lr = 0.00471466
I1029 03:40:52.256362 29475 solver.cpp:222] Iteration 43960 (1.28676 iter/s, 31.0857s/40 iters), loss = 1.47606
I1029 03:40:52.256574 29475 solver.cpp:241]     Train net output #0: loss = 1.47606 (* 1 = 1.47606 loss)
I1029 03:40:52.256593 29475 sgd_solver.cpp:105] Iteration 43960, lr = 0.00471029
I1029 03:41:22.232367 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_44000.caffemodel
I1029 03:41:22.266728 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_44000.solverstate
I1029 03:41:22.284900 29475 solver.cpp:334] Iteration 44000, Testing net (#0)
I1029 03:41:53.282827 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55272
I1029 03:41:53.282997 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78952
I1029 03:41:53.283012 29475 solver.cpp:401]     Test net output #2: loss = 1.9535 (* 1 = 1.9535 loss)
I1029 03:41:54.054586 29475 solver.cpp:222] Iteration 44000 (0.647294 iter/s, 61.7957s/40 iters), loss = 1.41967
I1029 03:41:54.054658 29475 solver.cpp:241]     Train net output #0: loss = 1.41967 (* 1 = 1.41967 loss)
I1029 03:41:54.054673 29475 sgd_solver.cpp:105] Iteration 44000, lr = 0.00470592
I1029 03:42:24.729604 29475 solver.cpp:222] Iteration 44040 (1.30405 iter/s, 30.6738s/40 iters), loss = 1.55992
I1029 03:42:24.729781 29475 solver.cpp:241]     Train net output #0: loss = 1.55992 (* 1 = 1.55992 loss)
I1029 03:42:24.729799 29475 sgd_solver.cpp:105] Iteration 44040, lr = 0.00470155
I1029 03:42:55.898980 29475 solver.cpp:222] Iteration 44080 (1.28337 iter/s, 31.168s/40 iters), loss = 1.32879
I1029 03:42:55.899199 29475 solver.cpp:241]     Train net output #0: loss = 1.32879 (* 1 = 1.32879 loss)
I1029 03:42:55.899219 29475 sgd_solver.cpp:105] Iteration 44080, lr = 0.00469718
I1029 03:43:26.719018 29475 solver.cpp:222] Iteration 44120 (1.29792 iter/s, 30.8187s/40 iters), loss = 1.4651
I1029 03:43:26.719198 29475 solver.cpp:241]     Train net output #0: loss = 1.4651 (* 1 = 1.4651 loss)
I1029 03:43:26.719218 29475 sgd_solver.cpp:105] Iteration 44120, lr = 0.00469281
I1029 03:43:58.285503 29475 solver.cpp:222] Iteration 44160 (1.26722 iter/s, 31.5651s/40 iters), loss = 1.43022
I1029 03:43:58.285702 29475 solver.cpp:241]     Train net output #0: loss = 1.43022 (* 1 = 1.43022 loss)
I1029 03:43:58.285720 29475 sgd_solver.cpp:105] Iteration 44160, lr = 0.00468845
I1029 03:44:29.238037 29475 solver.cpp:222] Iteration 44200 (1.29236 iter/s, 30.9512s/40 iters), loss = 1.66385
I1029 03:44:29.238229 29475 solver.cpp:241]     Train net output #0: loss = 1.66385 (* 1 = 1.66385 loss)
I1029 03:44:29.238246 29475 sgd_solver.cpp:105] Iteration 44200, lr = 0.00468408
I1029 03:45:00.482017 29475 solver.cpp:222] Iteration 44240 (1.2803 iter/s, 31.2426s/40 iters), loss = 1.66465
I1029 03:45:00.482211 29475 solver.cpp:241]     Train net output #0: loss = 1.66465 (* 1 = 1.66465 loss)
I1029 03:45:00.482230 29475 sgd_solver.cpp:105] Iteration 44240, lr = 0.00467972
I1029 03:45:31.409613 29475 solver.cpp:222] Iteration 44280 (1.2934 iter/s, 30.9261s/40 iters), loss = 1.29134
I1029 03:45:31.409802 29475 solver.cpp:241]     Train net output #0: loss = 1.29134 (* 1 = 1.29134 loss)
I1029 03:45:31.409821 29475 sgd_solver.cpp:105] Iteration 44280, lr = 0.00467535
I1029 03:46:02.285220 29475 solver.cpp:222] Iteration 44320 (1.29558 iter/s, 30.8742s/40 iters), loss = 1.63169
I1029 03:46:02.285437 29475 solver.cpp:241]     Train net output #0: loss = 1.63169 (* 1 = 1.63169 loss)
I1029 03:46:02.285456 29475 sgd_solver.cpp:105] Iteration 44320, lr = 0.00467099
I1029 03:46:33.311424 29475 solver.cpp:222] Iteration 44360 (1.28929 iter/s, 31.0248s/40 iters), loss = 1.50442
I1029 03:46:33.311609 29475 solver.cpp:241]     Train net output #0: loss = 1.50442 (* 1 = 1.50442 loss)
I1029 03:46:33.311625 29475 sgd_solver.cpp:105] Iteration 44360, lr = 0.00466663
I1029 03:47:05.171443 29475 solver.cpp:222] Iteration 44400 (1.25555 iter/s, 31.8586s/40 iters), loss = 1.89468
I1029 03:47:05.171656 29475 solver.cpp:241]     Train net output #0: loss = 1.89468 (* 1 = 1.89468 loss)
I1029 03:47:05.171674 29475 sgd_solver.cpp:105] Iteration 44400, lr = 0.00466227
I1029 03:47:36.712553 29475 solver.cpp:222] Iteration 44440 (1.26824 iter/s, 31.5397s/40 iters), loss = 1.90296
I1029 03:47:36.712734 29475 solver.cpp:241]     Train net output #0: loss = 1.90296 (* 1 = 1.90296 loss)
I1029 03:47:36.712752 29475 sgd_solver.cpp:105] Iteration 44440, lr = 0.00465791
I1029 03:48:08.359148 29475 solver.cpp:222] Iteration 44480 (1.26401 iter/s, 31.6452s/40 iters), loss = 1.44835
I1029 03:48:08.359344 29475 solver.cpp:241]     Train net output #0: loss = 1.44835 (* 1 = 1.44835 loss)
I1029 03:48:08.359365 29475 sgd_solver.cpp:105] Iteration 44480, lr = 0.00465355
I1029 03:48:23.239440 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_44500.caffemodel
I1029 03:48:23.276819 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_44500.solverstate
I1029 03:48:23.294883 29475 solver.cpp:334] Iteration 44500, Testing net (#0)
I1029 03:48:54.159685 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 03:48:54.367352 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5536
I1029 03:48:54.367415 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79284
I1029 03:48:54.367429 29475 solver.cpp:401]     Test net output #2: loss = 1.98053 (* 1 = 1.98053 loss)
I1029 03:49:10.667026 29475 solver.cpp:222] Iteration 44520 (0.642001 iter/s, 62.3052s/40 iters), loss = 1.47846
I1029 03:49:10.667101 29475 solver.cpp:241]     Train net output #0: loss = 1.47846 (* 1 = 1.47846 loss)
I1029 03:49:10.667119 29475 sgd_solver.cpp:105] Iteration 44520, lr = 0.00464919
I1029 03:49:42.109112 29475 solver.cpp:222] Iteration 44560 (1.27223 iter/s, 31.4407s/40 iters), loss = 1.61816
I1029 03:49:42.109294 29475 solver.cpp:241]     Train net output #0: loss = 1.61816 (* 1 = 1.61816 loss)
I1029 03:49:42.109318 29475 sgd_solver.cpp:105] Iteration 44560, lr = 0.00464483
I1029 03:50:13.157610 29475 solver.cpp:222] Iteration 44600 (1.28836 iter/s, 31.0471s/40 iters), loss = 1.51179
I1029 03:50:13.157812 29475 solver.cpp:241]     Train net output #0: loss = 1.51179 (* 1 = 1.51179 loss)
I1029 03:50:13.157832 29475 sgd_solver.cpp:105] Iteration 44600, lr = 0.00464048
I1029 03:50:44.285076 29475 solver.cpp:222] Iteration 44640 (1.2851 iter/s, 31.1259s/40 iters), loss = 1.51013
I1029 03:50:44.285308 29475 solver.cpp:241]     Train net output #0: loss = 1.51013 (* 1 = 1.51013 loss)
I1029 03:50:44.285336 29475 sgd_solver.cpp:105] Iteration 44640, lr = 0.00463612
I1029 03:51:16.884385 29475 solver.cpp:222] Iteration 44680 (1.22707 iter/s, 32.5978s/40 iters), loss = 1.46516
I1029 03:51:16.884598 29475 solver.cpp:241]     Train net output #0: loss = 1.46516 (* 1 = 1.46516 loss)
I1029 03:51:16.884618 29475 sgd_solver.cpp:105] Iteration 44680, lr = 0.00463177
I1029 03:51:50.280835 29475 solver.cpp:222] Iteration 44720 (1.19779 iter/s, 33.395s/40 iters), loss = 1.75116
I1029 03:51:50.281054 29475 solver.cpp:241]     Train net output #0: loss = 1.75116 (* 1 = 1.75116 loss)
I1029 03:51:50.281076 29475 sgd_solver.cpp:105] Iteration 44720, lr = 0.00462741
I1029 03:52:23.794840 29475 solver.cpp:222] Iteration 44760 (1.19358 iter/s, 33.5125s/40 iters), loss = 1.46068
I1029 03:52:23.795241 29475 solver.cpp:241]     Train net output #0: loss = 1.46068 (* 1 = 1.46068 loss)
I1029 03:52:23.795332 29475 sgd_solver.cpp:105] Iteration 44760, lr = 0.00462306
I1029 03:52:56.087610 29475 solver.cpp:222] Iteration 44800 (1.23873 iter/s, 32.2911s/40 iters), loss = 1.97967
I1029 03:52:56.087801 29475 solver.cpp:241]     Train net output #0: loss = 1.97967 (* 1 = 1.97967 loss)
I1029 03:52:56.087818 29475 sgd_solver.cpp:105] Iteration 44800, lr = 0.00461871
I1029 03:53:27.467278 29475 solver.cpp:222] Iteration 44840 (1.27477 iter/s, 31.3783s/40 iters), loss = 1.62011
I1029 03:53:27.467461 29475 solver.cpp:241]     Train net output #0: loss = 1.62011 (* 1 = 1.62011 loss)
I1029 03:53:27.467481 29475 sgd_solver.cpp:105] Iteration 44840, lr = 0.00461436
I1029 03:53:59.183864 29475 solver.cpp:222] Iteration 44880 (1.26122 iter/s, 31.7152s/40 iters), loss = 1.56635
I1029 03:53:59.184072 29475 solver.cpp:241]     Train net output #0: loss = 1.56635 (* 1 = 1.56635 loss)
I1029 03:53:59.184092 29475 sgd_solver.cpp:105] Iteration 44880, lr = 0.00461001
I1029 03:54:30.197096 29475 solver.cpp:222] Iteration 44920 (1.28983 iter/s, 31.0118s/40 iters), loss = 1.40712
I1029 03:54:30.197293 29475 solver.cpp:241]     Train net output #0: loss = 1.40712 (* 1 = 1.40712 loss)
I1029 03:54:30.197314 29475 sgd_solver.cpp:105] Iteration 44920, lr = 0.00460566
I1029 03:55:01.104022 29475 solver.cpp:222] Iteration 44960 (1.29427 iter/s, 30.9055s/40 iters), loss = 1.80524
I1029 03:55:01.104200 29475 solver.cpp:241]     Train net output #0: loss = 1.80524 (* 1 = 1.80524 loss)
I1029 03:55:01.104218 29475 sgd_solver.cpp:105] Iteration 44960, lr = 0.00460132
I1029 03:55:31.282941 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_45000.caffemodel
I1029 03:55:31.317601 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_45000.solverstate
I1029 03:55:31.334311 29475 solver.cpp:334] Iteration 45000, Testing net (#0)
I1029 03:56:02.320444 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55372
I1029 03:56:02.320618 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78716
I1029 03:56:02.320632 29475 solver.cpp:401]     Test net output #2: loss = 1.99644 (* 1 = 1.99644 loss)
I1029 03:56:03.121788 29475 solver.cpp:222] Iteration 45000 (0.645002 iter/s, 62.0153s/40 iters), loss = 1.65509
I1029 03:56:03.121862 29475 solver.cpp:241]     Train net output #0: loss = 1.65509 (* 1 = 1.65509 loss)
I1029 03:56:03.121877 29475 sgd_solver.cpp:105] Iteration 45000, lr = 0.00459697
I1029 03:56:31.762321 29523 data_layer.cpp:73] Restarting data prefetching from start.
I1029 03:56:34.057173 29475 solver.cpp:222] Iteration 45040 (1.29307 iter/s, 30.9341s/40 iters), loss = 1.98399
I1029 03:56:34.057368 29475 solver.cpp:241]     Train net output #0: loss = 1.98399 (* 1 = 1.98399 loss)
I1029 03:56:34.057384 29475 sgd_solver.cpp:105] Iteration 45040, lr = 0.00459262
I1029 03:57:04.973044 29475 solver.cpp:222] Iteration 45080 (1.29389 iter/s, 30.9145s/40 iters), loss = 1.75061
I1029 03:57:04.973244 29475 solver.cpp:241]     Train net output #0: loss = 1.75061 (* 1 = 1.75061 loss)
I1029 03:57:04.973263 29475 sgd_solver.cpp:105] Iteration 45080, lr = 0.00458828
I1029 03:57:36.748975 29475 solver.cpp:222] Iteration 45120 (1.25887 iter/s, 31.7745s/40 iters), loss = 1.7897
I1029 03:57:36.749169 29475 solver.cpp:241]     Train net output #0: loss = 1.7897 (* 1 = 1.7897 loss)
I1029 03:57:36.749186 29475 sgd_solver.cpp:105] Iteration 45120, lr = 0.00458393
I1029 03:58:07.936961 29475 solver.cpp:222] Iteration 45160 (1.28261 iter/s, 31.1865s/40 iters), loss = 1.79544
I1029 03:58:07.937155 29475 solver.cpp:241]     Train net output #0: loss = 1.79544 (* 1 = 1.79544 loss)
I1029 03:58:07.937173 29475 sgd_solver.cpp:105] Iteration 45160, lr = 0.00457959
I1029 03:58:39.206511 29475 solver.cpp:222] Iteration 45200 (1.27926 iter/s, 31.2682s/40 iters), loss = 1.47695
I1029 03:58:39.206737 29475 solver.cpp:241]     Train net output #0: loss = 1.47695 (* 1 = 1.47695 loss)
I1029 03:58:39.206753 29475 sgd_solver.cpp:105] Iteration 45200, lr = 0.00457525
I1029 03:59:10.756815 29475 solver.cpp:222] Iteration 45240 (1.26787 iter/s, 31.5489s/40 iters), loss = 1.48669
I1029 03:59:10.757011 29475 solver.cpp:241]     Train net output #0: loss = 1.48669 (* 1 = 1.48669 loss)
I1029 03:59:10.757030 29475 sgd_solver.cpp:105] Iteration 45240, lr = 0.00457091
I1029 03:59:42.332540 29475 solver.cpp:222] Iteration 45280 (1.26686 iter/s, 31.5742s/40 iters), loss = 1.61772
I1029 03:59:42.332797 29475 solver.cpp:241]     Train net output #0: loss = 1.61772 (* 1 = 1.61772 loss)
I1029 03:59:42.332826 29475 sgd_solver.cpp:105] Iteration 45280, lr = 0.00456657
I1029 04:00:20.346979 29475 solver.cpp:222] Iteration 45320 (1.05228 iter/s, 38.0127s/40 iters), loss = 1.69585
I1029 04:00:20.347235 29475 solver.cpp:241]     Train net output #0: loss = 1.69585 (* 1 = 1.69585 loss)
I1029 04:00:20.347261 29475 sgd_solver.cpp:105] Iteration 45320, lr = 0.00456223
I1029 04:00:51.976426 29475 solver.cpp:222] Iteration 45360 (1.2647 iter/s, 31.628s/40 iters), loss = 1.78161
I1029 04:00:51.976613 29475 solver.cpp:241]     Train net output #0: loss = 1.78161 (* 1 = 1.78161 loss)
I1029 04:00:51.976630 29475 sgd_solver.cpp:105] Iteration 45360, lr = 0.00455789
I1029 04:01:23.682180 29475 solver.cpp:222] Iteration 45400 (1.26166 iter/s, 31.7044s/40 iters), loss = 1.82284
I1029 04:01:23.682582 29475 solver.cpp:241]     Train net output #0: loss = 1.82284 (* 1 = 1.82284 loss)
I1029 04:01:23.682610 29475 sgd_solver.cpp:105] Iteration 45400, lr = 0.00455355
I1029 04:01:55.148234 29475 solver.cpp:222] Iteration 45440 (1.27128 iter/s, 31.4645s/40 iters), loss = 1.40652
I1029 04:01:55.148444 29475 solver.cpp:241]     Train net output #0: loss = 1.40652 (* 1 = 1.40652 loss)
I1029 04:01:55.148461 29475 sgd_solver.cpp:105] Iteration 45440, lr = 0.00454922
I1029 04:02:26.716884 29475 solver.cpp:222] Iteration 45480 (1.26714 iter/s, 31.5672s/40 iters), loss = 1.39676
I1029 04:02:26.717133 29475 solver.cpp:241]     Train net output #0: loss = 1.39676 (* 1 = 1.39676 loss)
I1029 04:02:26.717160 29475 sgd_solver.cpp:105] Iteration 45480, lr = 0.00454488
I1029 04:02:41.604632 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_45500.caffemodel
I1029 04:02:41.639536 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_45500.solverstate
I1029 04:02:41.656417 29475 solver.cpp:334] Iteration 45500, Testing net (#0)
I1029 04:03:12.407950 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 04:03:12.614887 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55928
I1029 04:03:12.614948 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.794319
I1029 04:03:12.614961 29475 solver.cpp:401]     Test net output #2: loss = 1.97725 (* 1 = 1.97725 loss)
I1029 04:03:28.843688 29475 solver.cpp:222] Iteration 45520 (0.643871 iter/s, 62.1242s/40 iters), loss = 1.37479
I1029 04:03:28.843771 29475 solver.cpp:241]     Train net output #0: loss = 1.37479 (* 1 = 1.37479 loss)
I1029 04:03:28.843791 29475 sgd_solver.cpp:105] Iteration 45520, lr = 0.00454055
I1029 04:03:59.724124 29475 solver.cpp:222] Iteration 45560 (1.29537 iter/s, 30.8792s/40 iters), loss = 1.76321
I1029 04:03:59.724331 29475 solver.cpp:241]     Train net output #0: loss = 1.76321 (* 1 = 1.76321 loss)
I1029 04:03:59.724349 29475 sgd_solver.cpp:105] Iteration 45560, lr = 0.00453621
I1029 04:04:30.387022 29475 solver.cpp:222] Iteration 45600 (1.30457 iter/s, 30.6615s/40 iters), loss = 1.44069
I1029 04:04:30.387192 29475 solver.cpp:241]     Train net output #0: loss = 1.44069 (* 1 = 1.44069 loss)
I1029 04:04:30.387208 29475 sgd_solver.cpp:105] Iteration 45600, lr = 0.00453188
I1029 04:05:01.058418 29475 solver.cpp:222] Iteration 45640 (1.3042 iter/s, 30.6701s/40 iters), loss = 1.55407
I1029 04:05:01.058604 29475 solver.cpp:241]     Train net output #0: loss = 1.55407 (* 1 = 1.55407 loss)
I1029 04:05:01.058635 29475 sgd_solver.cpp:105] Iteration 45640, lr = 0.00452755
I1029 04:05:31.668884 29475 solver.cpp:222] Iteration 45680 (1.3068 iter/s, 30.6091s/40 iters), loss = 1.49732
I1029 04:05:31.669049 29475 solver.cpp:241]     Train net output #0: loss = 1.49732 (* 1 = 1.49732 loss)
I1029 04:05:31.669070 29475 sgd_solver.cpp:105] Iteration 45680, lr = 0.00452322
I1029 04:06:02.234418 29475 solver.cpp:222] Iteration 45720 (1.30872 iter/s, 30.5642s/40 iters), loss = 1.43019
I1029 04:06:02.234572 29475 solver.cpp:241]     Train net output #0: loss = 1.43019 (* 1 = 1.43019 loss)
I1029 04:06:02.234588 29475 sgd_solver.cpp:105] Iteration 45720, lr = 0.00451889
I1029 04:06:32.829609 29475 solver.cpp:222] Iteration 45760 (1.30745 iter/s, 30.5939s/40 iters), loss = 1.6044
I1029 04:06:32.829753 29475 solver.cpp:241]     Train net output #0: loss = 1.6044 (* 1 = 1.6044 loss)
I1029 04:06:32.829771 29475 sgd_solver.cpp:105] Iteration 45760, lr = 0.00451456
I1029 04:07:03.469745 29475 solver.cpp:222] Iteration 45800 (1.30553 iter/s, 30.6388s/40 iters), loss = 1.49934
I1029 04:07:03.469921 29475 solver.cpp:241]     Train net output #0: loss = 1.49934 (* 1 = 1.49934 loss)
I1029 04:07:03.469938 29475 sgd_solver.cpp:105] Iteration 45800, lr = 0.00451023
I1029 04:07:34.967664 29475 solver.cpp:222] Iteration 45840 (1.26998 iter/s, 31.4966s/40 iters), loss = 1.70054
I1029 04:07:34.967881 29475 solver.cpp:241]     Train net output #0: loss = 1.70054 (* 1 = 1.70054 loss)
I1029 04:07:34.967916 29475 sgd_solver.cpp:105] Iteration 45840, lr = 0.00450591
I1029 04:08:05.616170 29475 solver.cpp:222] Iteration 45880 (1.30518 iter/s, 30.6471s/40 iters), loss = 1.51836
I1029 04:08:05.616334 29475 solver.cpp:241]     Train net output #0: loss = 1.51836 (* 1 = 1.51836 loss)
I1029 04:08:05.616351 29475 sgd_solver.cpp:105] Iteration 45880, lr = 0.00450158
I1029 04:08:36.617663 29475 solver.cpp:222] Iteration 45920 (1.29032 iter/s, 31.0002s/40 iters), loss = 1.3831
I1029 04:08:36.617853 29475 solver.cpp:241]     Train net output #0: loss = 1.3831 (* 1 = 1.3831 loss)
I1029 04:08:36.617869 29475 sgd_solver.cpp:105] Iteration 45920, lr = 0.00449726
I1029 04:09:07.408933 29475 solver.cpp:222] Iteration 45960 (1.29913 iter/s, 30.7899s/40 iters), loss = 1.63979
I1029 04:09:07.409090 29475 solver.cpp:241]     Train net output #0: loss = 1.63979 (* 1 = 1.63979 loss)
I1029 04:09:07.409107 29475 sgd_solver.cpp:105] Iteration 45960, lr = 0.00449293
I1029 04:09:37.174528 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_46000.caffemodel
I1029 04:09:37.214234 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_46000.solverstate
I1029 04:09:37.236435 29475 solver.cpp:334] Iteration 46000, Testing net (#0)
I1029 04:10:08.243403 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55428
I1029 04:10:08.243595 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7888
I1029 04:10:08.243609 29475 solver.cpp:401]     Test net output #2: loss = 1.96244 (* 1 = 1.96244 loss)
I1029 04:10:09.015439 29475 solver.cpp:222] Iteration 46000 (0.649308 iter/s, 61.604s/40 iters), loss = 1.61663
I1029 04:10:09.015513 29475 solver.cpp:241]     Train net output #0: loss = 1.61663 (* 1 = 1.61663 loss)
I1029 04:10:09.015533 29475 sgd_solver.cpp:105] Iteration 46000, lr = 0.00448861
I1029 04:10:39.697633 29475 solver.cpp:222] Iteration 46040 (1.30374 iter/s, 30.681s/40 iters), loss = 1.79209
I1029 04:10:39.697811 29475 solver.cpp:241]     Train net output #0: loss = 1.79209 (* 1 = 1.79209 loss)
I1029 04:10:39.697831 29475 sgd_solver.cpp:105] Iteration 46040, lr = 0.00448429
I1029 04:11:10.346657 29475 solver.cpp:222] Iteration 46080 (1.30516 iter/s, 30.6477s/40 iters), loss = 1.73608
I1029 04:11:10.346845 29475 solver.cpp:241]     Train net output #0: loss = 1.73608 (* 1 = 1.73608 loss)
I1029 04:11:10.346863 29475 sgd_solver.cpp:105] Iteration 46080, lr = 0.00447997
I1029 04:11:40.989312 29475 solver.cpp:222] Iteration 46120 (1.30543 iter/s, 30.6413s/40 iters), loss = 1.78211
I1029 04:11:40.989536 29475 solver.cpp:241]     Train net output #0: loss = 1.78211 (* 1 = 1.78211 loss)
I1029 04:11:40.989553 29475 sgd_solver.cpp:105] Iteration 46120, lr = 0.00447565
I1029 04:12:11.738037 29475 solver.cpp:222] Iteration 46160 (1.30093 iter/s, 30.7473s/40 iters), loss = 1.66462
I1029 04:12:11.738230 29475 solver.cpp:241]     Train net output #0: loss = 1.66462 (* 1 = 1.66462 loss)
I1029 04:12:11.738246 29475 sgd_solver.cpp:105] Iteration 46160, lr = 0.00447133
I1029 04:12:42.444128 29475 solver.cpp:222] Iteration 46200 (1.30274 iter/s, 30.7046s/40 iters), loss = 1.72802
I1029 04:12:42.444315 29475 solver.cpp:241]     Train net output #0: loss = 1.72802 (* 1 = 1.72802 loss)
I1029 04:12:42.444334 29475 sgd_solver.cpp:105] Iteration 46200, lr = 0.00446701
I1029 04:13:13.895388 29475 solver.cpp:222] Iteration 46240 (1.27187 iter/s, 31.4497s/40 iters), loss = 1.40828
I1029 04:13:13.895627 29475 solver.cpp:241]     Train net output #0: loss = 1.40828 (* 1 = 1.40828 loss)
I1029 04:13:13.895655 29475 sgd_solver.cpp:105] Iteration 46240, lr = 0.00446269
I1029 04:13:45.635887 29475 solver.cpp:222] Iteration 46280 (1.26028 iter/s, 31.7391s/40 iters), loss = 1.41443
I1029 04:13:45.636090 29475 solver.cpp:241]     Train net output #0: loss = 1.41443 (* 1 = 1.41443 loss)
I1029 04:13:45.636106 29475 sgd_solver.cpp:105] Iteration 46280, lr = 0.00445838
I1029 04:14:16.379058 29475 solver.cpp:222] Iteration 46320 (1.30116 iter/s, 30.7418s/40 iters), loss = 1.31817
I1029 04:14:16.379241 29475 solver.cpp:241]     Train net output #0: loss = 1.31817 (* 1 = 1.31817 loss)
I1029 04:14:16.379261 29475 sgd_solver.cpp:105] Iteration 46320, lr = 0.00445406
I1029 04:14:47.225558 29475 solver.cpp:222] Iteration 46360 (1.2968 iter/s, 30.8451s/40 iters), loss = 1.55102
I1029 04:14:47.225723 29475 solver.cpp:241]     Train net output #0: loss = 1.55102 (* 1 = 1.55102 loss)
I1029 04:14:47.225742 29475 sgd_solver.cpp:105] Iteration 46360, lr = 0.00444975
I1029 04:15:18.336004 29475 solver.cpp:222] Iteration 46400 (1.2858 iter/s, 31.1091s/40 iters), loss = 1.54202
I1029 04:15:18.336189 29475 solver.cpp:241]     Train net output #0: loss = 1.54202 (* 1 = 1.54202 loss)
I1029 04:15:18.336205 29475 sgd_solver.cpp:105] Iteration 46400, lr = 0.00444544
I1029 04:15:49.773717 29475 solver.cpp:222] Iteration 46440 (1.27241 iter/s, 31.4363s/40 iters), loss = 1.80687
I1029 04:15:49.773944 29475 solver.cpp:241]     Train net output #0: loss = 1.80687 (* 1 = 1.80687 loss)
I1029 04:15:49.773977 29475 sgd_solver.cpp:105] Iteration 46440, lr = 0.00444112
I1029 04:16:23.000327 29475 solver.cpp:222] Iteration 46480 (1.20391 iter/s, 33.225s/40 iters), loss = 1.40017
I1029 04:16:23.000542 29475 solver.cpp:241]     Train net output #0: loss = 1.40017 (* 1 = 1.40017 loss)
I1029 04:16:23.000562 29475 sgd_solver.cpp:105] Iteration 46480, lr = 0.00443681
I1029 04:17:04.629658 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_46500.caffemodel
I1029 04:17:04.680253 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_46500.solverstate
I1029 04:17:04.706290 29475 solver.cpp:334] Iteration 46500, Testing net (#0)
I1029 04:17:36.487650 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 04:17:36.693899 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55916
I1029 04:17:36.693971 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79576
I1029 04:17:36.693985 29475 solver.cpp:401]     Test net output #2: loss = 1.96048 (* 1 = 1.96048 loss)
I1029 04:17:52.787528 29475 solver.cpp:222] Iteration 46520 (0.445515 iter/s, 89.7836s/40 iters), loss = 1.82799
I1029 04:17:52.787601 29475 solver.cpp:241]     Train net output #0: loss = 1.82799 (* 1 = 1.82799 loss)
I1029 04:17:52.787617 29475 sgd_solver.cpp:105] Iteration 46520, lr = 0.0044325
I1029 04:18:23.671089 29475 solver.cpp:222] Iteration 46560 (1.29524 iter/s, 30.8822s/40 iters), loss = 1.63117
I1029 04:18:23.671373 29475 solver.cpp:241]     Train net output #0: loss = 1.63117 (* 1 = 1.63117 loss)
I1029 04:18:23.671392 29475 sgd_solver.cpp:105] Iteration 46560, lr = 0.00442819
I1029 04:18:57.485518 29475 solver.cpp:222] Iteration 46600 (1.18298 iter/s, 33.8128s/40 iters), loss = 1.39486
I1029 04:18:57.485735 29475 solver.cpp:241]     Train net output #0: loss = 1.39486 (* 1 = 1.39486 loss)
I1029 04:18:57.485759 29475 sgd_solver.cpp:105] Iteration 46600, lr = 0.00442388
I1029 04:19:30.667172 29475 solver.cpp:222] Iteration 46640 (1.20554 iter/s, 33.1802s/40 iters), loss = 1.6211
I1029 04:19:30.667366 29475 solver.cpp:241]     Train net output #0: loss = 1.6211 (* 1 = 1.6211 loss)
I1029 04:19:30.667393 29475 sgd_solver.cpp:105] Iteration 46640, lr = 0.00441958
I1029 04:20:01.748183 29475 solver.cpp:222] Iteration 46680 (1.28702 iter/s, 31.0796s/40 iters), loss = 2.02158
I1029 04:20:01.748420 29475 solver.cpp:241]     Train net output #0: loss = 2.02158 (* 1 = 2.02158 loss)
I1029 04:20:01.748443 29475 sgd_solver.cpp:105] Iteration 46680, lr = 0.00441527
I1029 04:20:33.280449 29475 solver.cpp:222] Iteration 46720 (1.2686 iter/s, 31.5308s/40 iters), loss = 1.16826
I1029 04:20:33.280694 29475 solver.cpp:241]     Train net output #0: loss = 1.16826 (* 1 = 1.16826 loss)
I1029 04:20:33.280719 29475 sgd_solver.cpp:105] Iteration 46720, lr = 0.00441096
I1029 04:21:05.038671 29475 solver.cpp:222] Iteration 46760 (1.25958 iter/s, 31.7567s/40 iters), loss = 1.41401
I1029 04:21:05.038872 29475 solver.cpp:241]     Train net output #0: loss = 1.41401 (* 1 = 1.41401 loss)
I1029 04:21:05.038889 29475 sgd_solver.cpp:105] Iteration 46760, lr = 0.00440666
I1029 04:21:36.345067 29475 solver.cpp:222] Iteration 46800 (1.27775 iter/s, 31.305s/40 iters), loss = 1.41512
I1029 04:21:36.345265 29475 solver.cpp:241]     Train net output #0: loss = 1.41512 (* 1 = 1.41512 loss)
I1029 04:21:36.345283 29475 sgd_solver.cpp:105] Iteration 46800, lr = 0.00440236
I1029 04:22:07.484757 29475 solver.cpp:222] Iteration 46840 (1.28459 iter/s, 31.1383s/40 iters), loss = 1.46653
I1029 04:22:07.484941 29475 solver.cpp:241]     Train net output #0: loss = 1.46653 (* 1 = 1.46653 loss)
I1029 04:22:07.484957 29475 sgd_solver.cpp:105] Iteration 46840, lr = 0.00439805
I1029 04:22:38.813117 29475 solver.cpp:222] Iteration 46880 (1.27685 iter/s, 31.327s/40 iters), loss = 1.5592
I1029 04:22:38.813328 29475 solver.cpp:241]     Train net output #0: loss = 1.5592 (* 1 = 1.5592 loss)
I1029 04:22:38.813359 29475 sgd_solver.cpp:105] Iteration 46880, lr = 0.00439375
I1029 04:23:10.942652 29475 solver.cpp:222] Iteration 46920 (1.24502 iter/s, 32.1281s/40 iters), loss = 1.50692
I1029 04:23:10.942849 29475 solver.cpp:241]     Train net output #0: loss = 1.50692 (* 1 = 1.50692 loss)
I1029 04:23:10.942868 29475 sgd_solver.cpp:105] Iteration 46920, lr = 0.00438945
I1029 04:23:41.998487 29475 solver.cpp:222] Iteration 46960 (1.28806 iter/s, 31.0545s/40 iters), loss = 1.57312
I1029 04:23:41.998687 29475 solver.cpp:241]     Train net output #0: loss = 1.57312 (* 1 = 1.57312 loss)
I1029 04:23:41.998704 29475 sgd_solver.cpp:105] Iteration 46960, lr = 0.00438515
I1029 04:24:12.208477 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_47000.caffemodel
I1029 04:24:12.246860 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_47000.solverstate
I1029 04:24:12.269532 29475 solver.cpp:334] Iteration 47000, Testing net (#0)
I1029 04:24:43.207087 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56272
I1029 04:24:43.207267 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79136
I1029 04:24:43.207281 29475 solver.cpp:401]     Test net output #2: loss = 1.9579 (* 1 = 1.9579 loss)
I1029 04:24:43.969460 29475 solver.cpp:222] Iteration 47000 (0.64549 iter/s, 61.9685s/40 iters), loss = 1.49391
I1029 04:24:43.969524 29475 solver.cpp:241]     Train net output #0: loss = 1.49391 (* 1 = 1.49391 loss)
I1029 04:24:43.969539 29475 sgd_solver.cpp:105] Iteration 47000, lr = 0.00438085
I1029 04:25:14.457393 29475 solver.cpp:222] Iteration 47040 (1.31205 iter/s, 30.4867s/40 iters), loss = 1.83302
I1029 04:25:14.457641 29475 solver.cpp:241]     Train net output #0: loss = 1.83302 (* 1 = 1.83302 loss)
I1029 04:25:14.457659 29475 sgd_solver.cpp:105] Iteration 47040, lr = 0.00437655
I1029 04:25:45.006104 29475 solver.cpp:222] Iteration 47080 (1.30944 iter/s, 30.5473s/40 iters), loss = 1.76657
I1029 04:25:45.006309 29475 solver.cpp:241]     Train net output #0: loss = 1.76657 (* 1 = 1.76657 loss)
I1029 04:25:45.006326 29475 sgd_solver.cpp:105] Iteration 47080, lr = 0.00437226
I1029 04:26:15.779595 29475 solver.cpp:222] Iteration 47120 (1.29988 iter/s, 30.7721s/40 iters), loss = 1.54138
I1029 04:26:15.779786 29475 solver.cpp:241]     Train net output #0: loss = 1.54138 (* 1 = 1.54138 loss)
I1029 04:26:15.779803 29475 sgd_solver.cpp:105] Iteration 47120, lr = 0.00436796
I1029 04:26:46.714057 29475 solver.cpp:222] Iteration 47160 (1.29312 iter/s, 30.933s/40 iters), loss = 1.83746
I1029 04:26:46.714257 29475 solver.cpp:241]     Train net output #0: loss = 1.83746 (* 1 = 1.83746 loss)
I1029 04:26:46.714277 29475 sgd_solver.cpp:105] Iteration 47160, lr = 0.00436367
I1029 04:27:17.922637 29475 solver.cpp:222] Iteration 47200 (1.28176 iter/s, 31.2072s/40 iters), loss = 1.69997
I1029 04:27:17.922798 29475 solver.cpp:241]     Train net output #0: loss = 1.69997 (* 1 = 1.69997 loss)
I1029 04:27:17.922816 29475 sgd_solver.cpp:105] Iteration 47200, lr = 0.00435937
I1029 04:27:49.034260 29475 solver.cpp:222] Iteration 47240 (1.28575 iter/s, 31.1103s/40 iters), loss = 1.62369
I1029 04:27:49.034433 29475 solver.cpp:241]     Train net output #0: loss = 1.62369 (* 1 = 1.62369 loss)
I1029 04:27:49.034451 29475 sgd_solver.cpp:105] Iteration 47240, lr = 0.00435508
I1029 04:28:19.808641 29475 solver.cpp:222] Iteration 47280 (1.29984 iter/s, 30.773s/40 iters), loss = 1.88767
I1029 04:28:19.808816 29475 solver.cpp:241]     Train net output #0: loss = 1.88767 (* 1 = 1.88767 loss)
I1029 04:28:19.808843 29475 sgd_solver.cpp:105] Iteration 47280, lr = 0.00435079
I1029 04:28:50.676754 29475 solver.cpp:222] Iteration 47320 (1.29589 iter/s, 30.8668s/40 iters), loss = 1.74194
I1029 04:28:50.676921 29475 solver.cpp:241]     Train net output #0: loss = 1.74194 (* 1 = 1.74194 loss)
I1029 04:28:50.676937 29475 sgd_solver.cpp:105] Iteration 47320, lr = 0.0043465
I1029 04:29:21.633510 29475 solver.cpp:222] Iteration 47360 (1.29218 iter/s, 30.9554s/40 iters), loss = 1.29361
I1029 04:29:21.633693 29475 solver.cpp:241]     Train net output #0: loss = 1.29361 (* 1 = 1.29361 loss)
I1029 04:29:21.633713 29475 sgd_solver.cpp:105] Iteration 47360, lr = 0.00434221
I1029 04:29:52.896692 29475 solver.cpp:222] Iteration 47400 (1.27952 iter/s, 31.2618s/40 iters), loss = 1.28798
I1029 04:29:52.896862 29475 solver.cpp:241]     Train net output #0: loss = 1.28798 (* 1 = 1.28798 loss)
I1029 04:29:52.896879 29475 sgd_solver.cpp:105] Iteration 47400, lr = 0.00433792
I1029 04:30:24.110914 29475 solver.cpp:222] Iteration 47440 (1.28152 iter/s, 31.2129s/40 iters), loss = 1.73561
I1029 04:30:24.111110 29475 solver.cpp:241]     Train net output #0: loss = 1.73561 (* 1 = 1.73561 loss)
I1029 04:30:24.111126 29475 sgd_solver.cpp:105] Iteration 47440, lr = 0.00433363
I1029 04:30:54.890698 29475 solver.cpp:222] Iteration 47480 (1.29961 iter/s, 30.7784s/40 iters), loss = 1.8521
I1029 04:30:54.890869 29475 solver.cpp:241]     Train net output #0: loss = 1.8521 (* 1 = 1.8521 loss)
I1029 04:30:54.890885 29475 sgd_solver.cpp:105] Iteration 47480, lr = 0.00432934
I1029 04:31:09.879029 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_47500.caffemodel
I1029 04:31:09.914824 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_47500.solverstate
I1029 04:31:09.935264 29475 solver.cpp:334] Iteration 47500, Testing net (#0)
I1029 04:31:40.756348 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 04:31:40.963201 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55388
I1029 04:31:40.963265 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7928
I1029 04:31:40.963279 29475 solver.cpp:401]     Test net output #2: loss = 1.98022 (* 1 = 1.98022 loss)
I1029 04:31:57.010567 29475 solver.cpp:222] Iteration 47520 (0.643942 iter/s, 62.1174s/40 iters), loss = 1.76885
I1029 04:31:57.010648 29475 solver.cpp:241]     Train net output #0: loss = 1.76885 (* 1 = 1.76885 loss)
I1029 04:31:57.010663 29475 sgd_solver.cpp:105] Iteration 47520, lr = 0.00432506
I1029 04:32:11.580565 29523 data_layer.cpp:73] Restarting data prefetching from start.
I1029 04:32:27.720533 29475 solver.cpp:222] Iteration 47560 (1.30256 iter/s, 30.7087s/40 iters), loss = 1.65501
I1029 04:32:27.720614 29475 solver.cpp:241]     Train net output #0: loss = 1.65501 (* 1 = 1.65501 loss)
I1029 04:32:27.720630 29475 sgd_solver.cpp:105] Iteration 47560, lr = 0.00432077
I1029 04:32:58.486740 29475 solver.cpp:222] Iteration 47600 (1.30018 iter/s, 30.765s/40 iters), loss = 1.53881
I1029 04:32:58.486913 29475 solver.cpp:241]     Train net output #0: loss = 1.53881 (* 1 = 1.53881 loss)
I1029 04:32:58.486929 29475 sgd_solver.cpp:105] Iteration 47600, lr = 0.00431649
I1029 04:33:29.211433 29475 solver.cpp:222] Iteration 47640 (1.30194 iter/s, 30.7234s/40 iters), loss = 1.28885
I1029 04:33:29.211593 29475 solver.cpp:241]     Train net output #0: loss = 1.28885 (* 1 = 1.28885 loss)
I1029 04:33:29.211609 29475 sgd_solver.cpp:105] Iteration 47640, lr = 0.00431221
I1029 04:34:00.228585 29475 solver.cpp:222] Iteration 47680 (1.28966 iter/s, 31.0158s/40 iters), loss = 1.43646
I1029 04:34:00.228773 29475 solver.cpp:241]     Train net output #0: loss = 1.43646 (* 1 = 1.43646 loss)
I1029 04:34:00.228791 29475 sgd_solver.cpp:105] Iteration 47680, lr = 0.00430792
I1029 04:34:31.103328 29475 solver.cpp:222] Iteration 47720 (1.29561 iter/s, 30.8734s/40 iters), loss = 1.38483
I1029 04:34:31.103490 29475 solver.cpp:241]     Train net output #0: loss = 1.38483 (* 1 = 1.38483 loss)
I1029 04:34:31.103507 29475 sgd_solver.cpp:105] Iteration 47720, lr = 0.00430364
I1029 04:35:02.014689 29475 solver.cpp:222] Iteration 47760 (1.29408 iter/s, 30.9099s/40 iters), loss = 1.64576
I1029 04:35:02.014863 29475 solver.cpp:241]     Train net output #0: loss = 1.64576 (* 1 = 1.64576 loss)
I1029 04:35:02.014880 29475 sgd_solver.cpp:105] Iteration 47760, lr = 0.00429936
I1029 04:35:32.775403 29475 solver.cpp:222] Iteration 47800 (1.30042 iter/s, 30.7594s/40 iters), loss = 1.78449
I1029 04:35:32.775581 29475 solver.cpp:241]     Train net output #0: loss = 1.78449 (* 1 = 1.78449 loss)
I1029 04:35:32.775599 29475 sgd_solver.cpp:105] Iteration 47800, lr = 0.00429508
I1029 04:36:03.630653 29475 solver.cpp:222] Iteration 47840 (1.29643 iter/s, 30.8539s/40 iters), loss = 1.7685
I1029 04:36:03.630830 29475 solver.cpp:241]     Train net output #0: loss = 1.7685 (* 1 = 1.7685 loss)
I1029 04:36:03.630846 29475 sgd_solver.cpp:105] Iteration 47840, lr = 0.00429081
I1029 04:36:34.305820 29475 solver.cpp:222] Iteration 47880 (1.30404 iter/s, 30.6738s/40 iters), loss = 1.55257
I1029 04:36:34.305994 29475 solver.cpp:241]     Train net output #0: loss = 1.55257 (* 1 = 1.55257 loss)
I1029 04:36:34.306010 29475 sgd_solver.cpp:105] Iteration 47880, lr = 0.00428653
I1029 04:37:05.113982 29475 solver.cpp:222] Iteration 47920 (1.29841 iter/s, 30.8068s/40 iters), loss = 1.54458
I1029 04:37:05.114097 29475 solver.cpp:241]     Train net output #0: loss = 1.54458 (* 1 = 1.54458 loss)
I1029 04:37:05.114116 29475 sgd_solver.cpp:105] Iteration 47920, lr = 0.00428225
I1029 04:37:36.007769 29475 solver.cpp:222] Iteration 47960 (1.29482 iter/s, 30.8924s/40 iters), loss = 1.42309
I1029 04:37:36.007930 29475 solver.cpp:241]     Train net output #0: loss = 1.42309 (* 1 = 1.42309 loss)
I1029 04:37:36.007946 29475 sgd_solver.cpp:105] Iteration 47960, lr = 0.00427798
I1029 04:38:06.029645 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_48000.caffemodel
I1029 04:38:06.064626 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_48000.solverstate
I1029 04:38:06.086174 29475 solver.cpp:334] Iteration 48000, Testing net (#0)
I1029 04:38:37.079879 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55792
I1029 04:38:37.080049 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78988
I1029 04:38:37.080063 29475 solver.cpp:401]     Test net output #2: loss = 1.94581 (* 1 = 1.94581 loss)
I1029 04:38:37.849179 29475 solver.cpp:222] Iteration 48000 (0.646842 iter/s, 61.8389s/40 iters), loss = 1.82282
I1029 04:38:37.849247 29475 solver.cpp:241]     Train net output #0: loss = 1.82282 (* 1 = 1.82282 loss)
I1029 04:38:37.849263 29475 sgd_solver.cpp:105] Iteration 48000, lr = 0.0042737
I1029 04:39:08.626788 29475 solver.cpp:222] Iteration 48040 (1.2997 iter/s, 30.7764s/40 iters), loss = 1.32542
I1029 04:39:08.626957 29475 solver.cpp:241]     Train net output #0: loss = 1.32542 (* 1 = 1.32542 loss)
I1029 04:39:08.626974 29475 sgd_solver.cpp:105] Iteration 48040, lr = 0.00426943
I1029 04:39:39.442946 29475 solver.cpp:222] Iteration 48080 (1.29808 iter/s, 30.8148s/40 iters), loss = 1.57562
I1029 04:39:39.443141 29475 solver.cpp:241]     Train net output #0: loss = 1.57562 (* 1 = 1.57562 loss)
I1029 04:39:39.443158 29475 sgd_solver.cpp:105] Iteration 48080, lr = 0.00426516
I1029 04:40:10.280668 29475 solver.cpp:222] Iteration 48120 (1.29717 iter/s, 30.8363s/40 iters), loss = 1.48195
I1029 04:40:10.280838 29475 solver.cpp:241]     Train net output #0: loss = 1.48195 (* 1 = 1.48195 loss)
I1029 04:40:10.280855 29475 sgd_solver.cpp:105] Iteration 48120, lr = 0.00426089
I1029 04:40:41.341225 29475 solver.cpp:222] Iteration 48160 (1.28786 iter/s, 31.0592s/40 iters), loss = 1.88445
I1029 04:40:41.341408 29475 solver.cpp:241]     Train net output #0: loss = 1.88445 (* 1 = 1.88445 loss)
I1029 04:40:41.341424 29475 sgd_solver.cpp:105] Iteration 48160, lr = 0.00425662
I1029 04:41:12.159857 29475 solver.cpp:222] Iteration 48200 (1.29797 iter/s, 30.8173s/40 iters), loss = 1.63989
I1029 04:41:12.160068 29475 solver.cpp:241]     Train net output #0: loss = 1.63989 (* 1 = 1.63989 loss)
I1029 04:41:12.160086 29475 sgd_solver.cpp:105] Iteration 48200, lr = 0.00425235
I1029 04:41:42.991055 29475 solver.cpp:222] Iteration 48240 (1.29745 iter/s, 30.8298s/40 iters), loss = 1.44183
I1029 04:41:42.991245 29475 solver.cpp:241]     Train net output #0: loss = 1.44183 (* 1 = 1.44183 loss)
I1029 04:41:42.991262 29475 sgd_solver.cpp:105] Iteration 48240, lr = 0.00424808
I1029 04:42:13.942224 29475 solver.cpp:222] Iteration 48280 (1.29242 iter/s, 30.9498s/40 iters), loss = 1.61011
I1029 04:42:13.942409 29475 solver.cpp:241]     Train net output #0: loss = 1.61011 (* 1 = 1.61011 loss)
I1029 04:42:13.942427 29475 sgd_solver.cpp:105] Iteration 48280, lr = 0.00424381
I1029 04:42:45.602792 29475 solver.cpp:222] Iteration 48320 (1.26346 iter/s, 31.6592s/40 iters), loss = 1.77114
I1029 04:42:45.603011 29475 solver.cpp:241]     Train net output #0: loss = 1.77114 (* 1 = 1.77114 loss)
I1029 04:42:45.603029 29475 sgd_solver.cpp:105] Iteration 48320, lr = 0.00423954
I1029 04:43:16.760381 29475 solver.cpp:222] Iteration 48360 (1.28386 iter/s, 31.1561s/40 iters), loss = 2.0494
I1029 04:43:16.760577 29475 solver.cpp:241]     Train net output #0: loss = 2.0494 (* 1 = 2.0494 loss)
I1029 04:43:16.760596 29475 sgd_solver.cpp:105] Iteration 48360, lr = 0.00423528
I1029 04:43:47.945535 29475 solver.cpp:222] Iteration 48400 (1.28272 iter/s, 31.1838s/40 iters), loss = 1.63216
I1029 04:43:47.945729 29475 solver.cpp:241]     Train net output #0: loss = 1.63216 (* 1 = 1.63216 loss)
I1029 04:43:47.945746 29475 sgd_solver.cpp:105] Iteration 48400, lr = 0.00423102
I1029 04:44:18.953405 29475 solver.cpp:222] Iteration 48440 (1.29005 iter/s, 31.0065s/40 iters), loss = 1.69803
I1029 04:44:18.953608 29475 solver.cpp:241]     Train net output #0: loss = 1.69803 (* 1 = 1.69803 loss)
I1029 04:44:18.953625 29475 sgd_solver.cpp:105] Iteration 48440, lr = 0.00422675
I1029 04:44:50.709365 29475 solver.cpp:222] Iteration 48480 (1.25966 iter/s, 31.7546s/40 iters), loss = 1.7958
I1029 04:44:50.709679 29475 solver.cpp:241]     Train net output #0: loss = 1.7958 (* 1 = 1.7958 loss)
I1029 04:44:50.709702 29475 sgd_solver.cpp:105] Iteration 48480, lr = 0.00422249
I1029 04:45:05.237666 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_48500.caffemodel
I1029 04:45:05.280632 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_48500.solverstate
I1029 04:45:05.298636 29475 solver.cpp:334] Iteration 48500, Testing net (#0)
I1029 04:45:36.084796 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 04:45:36.291954 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55572
I1029 04:45:36.292016 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79216
I1029 04:45:36.292031 29475 solver.cpp:401]     Test net output #2: loss = 1.96106 (* 1 = 1.96106 loss)
I1029 04:45:52.414700 29475 solver.cpp:222] Iteration 48520 (0.64827 iter/s, 61.7027s/40 iters), loss = 1.35978
I1029 04:45:52.414813 29475 solver.cpp:241]     Train net output #0: loss = 1.35978 (* 1 = 1.35978 loss)
I1029 04:45:52.414835 29475 sgd_solver.cpp:105] Iteration 48520, lr = 0.00421823
I1029 04:46:23.501683 29475 solver.cpp:222] Iteration 48560 (1.28677 iter/s, 31.0857s/40 iters), loss = 1.62068
I1029 04:46:23.501878 29475 solver.cpp:241]     Train net output #0: loss = 1.62068 (* 1 = 1.62068 loss)
I1029 04:46:23.501895 29475 sgd_solver.cpp:105] Iteration 48560, lr = 0.00421397
I1029 04:46:54.945997 29475 solver.cpp:222] Iteration 48600 (1.27215 iter/s, 31.4428s/40 iters), loss = 1.47565
I1029 04:46:54.946187 29475 solver.cpp:241]     Train net output #0: loss = 1.47565 (* 1 = 1.47565 loss)
I1029 04:46:54.946205 29475 sgd_solver.cpp:105] Iteration 48600, lr = 0.00420971
I1029 04:47:27.252564 29475 solver.cpp:222] Iteration 48640 (1.2382 iter/s, 32.3051s/40 iters), loss = 1.17601
I1029 04:47:27.252750 29475 solver.cpp:241]     Train net output #0: loss = 1.17601 (* 1 = 1.17601 loss)
I1029 04:47:27.252768 29475 sgd_solver.cpp:105] Iteration 48640, lr = 0.00420545
I1029 04:47:59.602694 29475 solver.cpp:222] Iteration 48680 (1.23653 iter/s, 32.3487s/40 iters), loss = 1.46946
I1029 04:47:59.602870 29475 solver.cpp:241]     Train net output #0: loss = 1.46946 (* 1 = 1.46946 loss)
I1029 04:47:59.602887 29475 sgd_solver.cpp:105] Iteration 48680, lr = 0.00420119
I1029 04:49:44.625797 29475 solver.cpp:222] Iteration 48720 (0.380884 iter/s, 105.019s/40 iters), loss = 1.74878
I1029 04:49:44.626082 29475 solver.cpp:241]     Train net output #0: loss = 1.74878 (* 1 = 1.74878 loss)
I1029 04:49:44.626118 29475 sgd_solver.cpp:105] Iteration 48720, lr = 0.00419694
I1029 04:50:40.538223 29475 solver.cpp:222] Iteration 48760 (0.715435 iter/s, 55.9101s/40 iters), loss = 1.55136
I1029 04:50:40.538465 29475 solver.cpp:241]     Train net output #0: loss = 1.55136 (* 1 = 1.55136 loss)
I1029 04:50:40.538482 29475 sgd_solver.cpp:105] Iteration 48760, lr = 0.00419268
I1029 04:51:11.765910 29475 solver.cpp:222] Iteration 48800 (1.28097 iter/s, 31.2263s/40 iters), loss = 1.59287
I1029 04:51:11.766163 29475 solver.cpp:241]     Train net output #0: loss = 1.59287 (* 1 = 1.59287 loss)
I1029 04:51:11.766191 29475 sgd_solver.cpp:105] Iteration 48800, lr = 0.00418843
I1029 04:51:42.961078 29475 solver.cpp:222] Iteration 48840 (1.28231 iter/s, 31.1937s/40 iters), loss = 1.36592
I1029 04:51:42.961267 29475 solver.cpp:241]     Train net output #0: loss = 1.36592 (* 1 = 1.36592 loss)
I1029 04:51:42.961284 29475 sgd_solver.cpp:105] Iteration 48840, lr = 0.00418417
I1029 04:52:14.172943 29475 solver.cpp:222] Iteration 48880 (1.28162 iter/s, 31.2105s/40 iters), loss = 1.65892
I1029 04:52:14.173116 29475 solver.cpp:241]     Train net output #0: loss = 1.65892 (* 1 = 1.65892 loss)
I1029 04:52:14.173135 29475 sgd_solver.cpp:105] Iteration 48880, lr = 0.00417992
I1029 04:52:45.134639 29475 solver.cpp:222] Iteration 48920 (1.29197 iter/s, 30.9604s/40 iters), loss = 1.48196
I1029 04:52:45.134871 29475 solver.cpp:241]     Train net output #0: loss = 1.48196 (* 1 = 1.48196 loss)
I1029 04:52:45.134888 29475 sgd_solver.cpp:105] Iteration 48920, lr = 0.00417567
I1029 04:53:16.453769 29475 solver.cpp:222] Iteration 48960 (1.27723 iter/s, 31.3177s/40 iters), loss = 1.98109
I1029 04:53:16.453945 29475 solver.cpp:241]     Train net output #0: loss = 1.98109 (* 1 = 1.98109 loss)
I1029 04:53:16.453963 29475 sgd_solver.cpp:105] Iteration 48960, lr = 0.00417142
I1029 04:53:46.592519 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_49000.caffemodel
I1029 04:53:46.627760 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_49000.solverstate
I1029 04:53:46.644783 29475 solver.cpp:334] Iteration 49000, Testing net (#0)
I1029 04:54:17.600980 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55384
I1029 04:54:17.601147 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7878
I1029 04:54:17.601162 29475 solver.cpp:401]     Test net output #2: loss = 2.00226 (* 1 = 2.00226 loss)
I1029 04:54:18.366750 29475 solver.cpp:222] Iteration 49000 (0.646094 iter/s, 61.9105s/40 iters), loss = 1.56129
I1029 04:54:18.366816 29475 solver.cpp:241]     Train net output #0: loss = 1.56129 (* 1 = 1.56129 loss)
I1029 04:54:18.366830 29475 sgd_solver.cpp:105] Iteration 49000, lr = 0.00416717
I1029 04:54:49.134830 29475 solver.cpp:222] Iteration 49040 (1.3001 iter/s, 30.7668s/40 iters), loss = 1.81435
I1029 04:54:49.135004 29475 solver.cpp:241]     Train net output #0: loss = 1.81435 (* 1 = 1.81435 loss)
I1029 04:54:49.135021 29475 sgd_solver.cpp:105] Iteration 49040, lr = 0.00416292
I1029 04:55:19.934859 29475 solver.cpp:222] Iteration 49080 (1.29876 iter/s, 30.7987s/40 iters), loss = 1.63538
I1029 04:55:19.935115 29475 solver.cpp:241]     Train net output #0: loss = 1.63538 (* 1 = 1.63538 loss)
I1029 04:55:19.935133 29475 sgd_solver.cpp:105] Iteration 49080, lr = 0.00415867
I1029 04:55:50.619253 29475 solver.cpp:222] Iteration 49120 (1.30365 iter/s, 30.683s/40 iters), loss = 1.75133
I1029 04:55:50.619488 29475 solver.cpp:241]     Train net output #0: loss = 1.75133 (* 1 = 1.75133 loss)
I1029 04:55:50.619506 29475 sgd_solver.cpp:105] Iteration 49120, lr = 0.00415443
I1029 04:56:21.250099 29475 solver.cpp:222] Iteration 49160 (1.30593 iter/s, 30.6294s/40 iters), loss = 1.15555
I1029 04:56:21.250286 29475 solver.cpp:241]     Train net output #0: loss = 1.15555 (* 1 = 1.15555 loss)
I1029 04:56:21.250309 29475 sgd_solver.cpp:105] Iteration 49160, lr = 0.00415018
I1029 04:56:51.812258 29475 solver.cpp:222] Iteration 49200 (1.30887 iter/s, 30.5608s/40 iters), loss = 1.62684
I1029 04:56:51.812443 29475 solver.cpp:241]     Train net output #0: loss = 1.62684 (* 1 = 1.62684 loss)
I1029 04:56:51.812460 29475 sgd_solver.cpp:105] Iteration 49200, lr = 0.00414594
I1029 04:57:22.656159 29475 solver.cpp:222] Iteration 49240 (1.29691 iter/s, 30.8425s/40 iters), loss = 1.68119
I1029 04:57:22.656344 29475 solver.cpp:241]     Train net output #0: loss = 1.68119 (* 1 = 1.68119 loss)
I1029 04:57:22.656363 29475 sgd_solver.cpp:105] Iteration 49240, lr = 0.00414169
I1029 04:57:53.313730 29475 solver.cpp:222] Iteration 49280 (1.30479 iter/s, 30.6562s/40 iters), loss = 1.6371
I1029 04:57:53.313889 29475 solver.cpp:241]     Train net output #0: loss = 1.6371 (* 1 = 1.6371 loss)
I1029 04:57:53.313905 29475 sgd_solver.cpp:105] Iteration 49280, lr = 0.00413745
I1029 04:58:23.853408 29475 solver.cpp:222] Iteration 49320 (1.30983 iter/s, 30.5384s/40 iters), loss = 1.99255
I1029 04:58:23.853579 29475 solver.cpp:241]     Train net output #0: loss = 1.99255 (* 1 = 1.99255 loss)
I1029 04:58:23.853595 29475 sgd_solver.cpp:105] Iteration 49320, lr = 0.00413321
I1029 04:58:54.472470 29475 solver.cpp:222] Iteration 49360 (1.30643 iter/s, 30.6177s/40 iters), loss = 1.57821
I1029 04:58:54.472633 29475 solver.cpp:241]     Train net output #0: loss = 1.57821 (* 1 = 1.57821 loss)
I1029 04:58:54.472651 29475 sgd_solver.cpp:105] Iteration 49360, lr = 0.00412897
I1029 04:59:25.241199 29475 solver.cpp:222] Iteration 49400 (1.30008 iter/s, 30.7674s/40 iters), loss = 1.73431
I1029 04:59:25.241441 29475 solver.cpp:241]     Train net output #0: loss = 1.73431 (* 1 = 1.73431 loss)
I1029 04:59:25.241457 29475 sgd_solver.cpp:105] Iteration 49400, lr = 0.00412473
I1029 04:59:55.767230 29475 solver.cpp:222] Iteration 49440 (1.31042 iter/s, 30.5246s/40 iters), loss = 1.82745
I1029 04:59:55.767415 29475 solver.cpp:241]     Train net output #0: loss = 1.82745 (* 1 = 1.82745 loss)
I1029 04:59:55.767432 29475 sgd_solver.cpp:105] Iteration 49440, lr = 0.00412049
I1029 05:00:26.509738 29475 solver.cpp:222] Iteration 49480 (1.30119 iter/s, 30.7412s/40 iters), loss = 1.35979
I1029 05:00:26.509943 29475 solver.cpp:241]     Train net output #0: loss = 1.35979 (* 1 = 1.35979 loss)
I1029 05:00:26.509961 29475 sgd_solver.cpp:105] Iteration 49480, lr = 0.00411626
I1029 05:00:41.104569 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_49500.caffemodel
I1029 05:00:41.140550 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_49500.solverstate
I1029 05:00:41.158746 29475 solver.cpp:334] Iteration 49500, Testing net (#0)
I1029 05:01:12.066535 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 05:01:12.272963 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56168
I1029 05:01:12.273011 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.798439
I1029 05:01:12.273025 29475 solver.cpp:401]     Test net output #2: loss = 1.93838 (* 1 = 1.93838 loss)
I1029 05:01:28.543941 29475 solver.cpp:222] Iteration 49520 (0.644832 iter/s, 62.0317s/40 iters), loss = 1.46782
I1029 05:01:28.544016 29475 solver.cpp:241]     Train net output #0: loss = 1.46782 (* 1 = 1.46782 loss)
I1029 05:01:28.544033 29475 sgd_solver.cpp:105] Iteration 49520, lr = 0.00411202
I1029 05:01:59.233580 29475 solver.cpp:222] Iteration 49560 (1.30342 iter/s, 30.6884s/40 iters), loss = 1.66067
I1029 05:01:59.233800 29475 solver.cpp:241]     Train net output #0: loss = 1.66067 (* 1 = 1.66067 loss)
I1029 05:01:59.233819 29475 sgd_solver.cpp:105] Iteration 49560, lr = 0.00410778
I1029 05:02:29.987903 29475 solver.cpp:222] Iteration 49600 (1.30069 iter/s, 30.7529s/40 iters), loss = 1.45927
I1029 05:02:29.988102 29475 solver.cpp:241]     Train net output #0: loss = 1.45927 (* 1 = 1.45927 loss)
I1029 05:02:29.988121 29475 sgd_solver.cpp:105] Iteration 49600, lr = 0.00410355
I1029 05:03:00.657095 29475 solver.cpp:222] Iteration 49640 (1.3043 iter/s, 30.6678s/40 iters), loss = 1.58385
I1029 05:03:00.657246 29475 solver.cpp:241]     Train net output #0: loss = 1.58385 (* 1 = 1.58385 loss)
I1029 05:03:00.657263 29475 sgd_solver.cpp:105] Iteration 49640, lr = 0.00409932
I1029 05:03:31.656139 29475 solver.cpp:222] Iteration 49680 (1.29042 iter/s, 30.9977s/40 iters), loss = 1.6262
I1029 05:03:31.656342 29475 solver.cpp:241]     Train net output #0: loss = 1.6262 (* 1 = 1.6262 loss)
I1029 05:03:31.656361 29475 sgd_solver.cpp:105] Iteration 49680, lr = 0.00409508
I1029 05:04:02.571573 29475 solver.cpp:222] Iteration 49720 (1.29391 iter/s, 30.914s/40 iters), loss = 1.6466
I1029 05:04:02.571764 29475 solver.cpp:241]     Train net output #0: loss = 1.6466 (* 1 = 1.6466 loss)
I1029 05:04:02.571782 29475 sgd_solver.cpp:105] Iteration 49720, lr = 0.00409085
I1029 05:04:33.251569 29475 solver.cpp:222] Iteration 49760 (1.30384 iter/s, 30.6786s/40 iters), loss = 1.37232
I1029 05:04:33.251765 29475 solver.cpp:241]     Train net output #0: loss = 1.37232 (* 1 = 1.37232 loss)
I1029 05:04:33.251780 29475 sgd_solver.cpp:105] Iteration 49760, lr = 0.00408662
I1029 05:05:03.693570 29475 solver.cpp:222] Iteration 49800 (1.31403 iter/s, 30.4407s/40 iters), loss = 1.544
I1029 05:05:03.693756 29475 solver.cpp:241]     Train net output #0: loss = 1.544 (* 1 = 1.544 loss)
I1029 05:05:03.693774 29475 sgd_solver.cpp:105] Iteration 49800, lr = 0.00408239
I1029 05:05:34.655848 29475 solver.cpp:222] Iteration 49840 (1.29195 iter/s, 30.9609s/40 iters), loss = 1.28969
I1029 05:05:34.656102 29475 solver.cpp:241]     Train net output #0: loss = 1.28969 (* 1 = 1.28969 loss)
I1029 05:05:34.656119 29475 sgd_solver.cpp:105] Iteration 49840, lr = 0.00407817
I1029 05:06:05.594013 29475 solver.cpp:222] Iteration 49880 (1.29296 iter/s, 30.9367s/40 iters), loss = 1.72135
I1029 05:06:05.594204 29475 solver.cpp:241]     Train net output #0: loss = 1.72135 (* 1 = 1.72135 loss)
I1029 05:06:05.594223 29475 sgd_solver.cpp:105] Iteration 49880, lr = 0.00407394
I1029 05:06:36.267434 29475 solver.cpp:222] Iteration 49920 (1.30412 iter/s, 30.6721s/40 iters), loss = 1.77766
I1029 05:06:36.267614 29475 solver.cpp:241]     Train net output #0: loss = 1.77766 (* 1 = 1.77766 loss)
I1029 05:06:36.267632 29475 sgd_solver.cpp:105] Iteration 49920, lr = 0.00406971
I1029 05:07:06.871969 29475 solver.cpp:222] Iteration 49960 (1.30705 iter/s, 30.6032s/40 iters), loss = 1.9008
I1029 05:07:06.872143 29475 solver.cpp:241]     Train net output #0: loss = 1.9008 (* 1 = 1.9008 loss)
I1029 05:07:06.872159 29475 sgd_solver.cpp:105] Iteration 49960, lr = 0.00406549
I1029 05:07:36.691020 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_50000.caffemodel
I1029 05:07:36.726881 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_50000.solverstate
I1029 05:07:36.745134 29475 solver.cpp:334] Iteration 50000, Testing net (#0)
I1029 05:08:07.697346 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5634
I1029 05:08:07.697542 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.795399
I1029 05:08:07.697557 29475 solver.cpp:401]     Test net output #2: loss = 1.95006 (* 1 = 1.95006 loss)
I1029 05:08:08.467975 29475 solver.cpp:222] Iteration 50000 (0.649419 iter/s, 61.5935s/40 iters), loss = 1.35504
I1029 05:08:08.468042 29475 solver.cpp:241]     Train net output #0: loss = 1.35504 (* 1 = 1.35504 loss)
I1029 05:08:08.468058 29475 sgd_solver.cpp:105] Iteration 50000, lr = 0.00406126
I1029 05:08:38.894515 29475 solver.cpp:222] Iteration 50040 (1.3147 iter/s, 30.4252s/40 iters), loss = 1.8008
I1029 05:08:38.894672 29475 solver.cpp:241]     Train net output #0: loss = 1.8008 (* 1 = 1.8008 loss)
I1029 05:08:38.894690 29475 sgd_solver.cpp:105] Iteration 50040, lr = 0.00405704
I1029 05:08:39.735810 29523 data_layer.cpp:73] Restarting data prefetching from start.
I1029 05:09:09.371814 29475 solver.cpp:222] Iteration 50080 (1.31251 iter/s, 30.4759s/40 iters), loss = 1.6048
I1029 05:09:09.371974 29475 solver.cpp:241]     Train net output #0: loss = 1.6048 (* 1 = 1.6048 loss)
I1029 05:09:09.371992 29475 sgd_solver.cpp:105] Iteration 50080, lr = 0.00405282
I1029 05:09:40.470248 29475 solver.cpp:222] Iteration 50120 (1.28629 iter/s, 31.0971s/40 iters), loss = 1.71019
I1029 05:09:40.470445 29475 solver.cpp:241]     Train net output #0: loss = 1.71019 (* 1 = 1.71019 loss)
I1029 05:09:40.470463 29475 sgd_solver.cpp:105] Iteration 50120, lr = 0.0040486
I1029 05:10:11.698530 29475 solver.cpp:222] Iteration 50160 (1.28095 iter/s, 31.2269s/40 iters), loss = 1.49815
I1029 05:10:11.698743 29475 solver.cpp:241]     Train net output #0: loss = 1.49815 (* 1 = 1.49815 loss)
I1029 05:10:11.698763 29475 sgd_solver.cpp:105] Iteration 50160, lr = 0.00404437
I1029 05:10:42.783848 29475 solver.cpp:222] Iteration 50200 (1.28684 iter/s, 31.0839s/40 iters), loss = 1.50233
I1029 05:10:42.784072 29475 solver.cpp:241]     Train net output #0: loss = 1.50233 (* 1 = 1.50233 loss)
I1029 05:10:42.784090 29475 sgd_solver.cpp:105] Iteration 50200, lr = 0.00404016
I1029 05:11:13.966286 29475 solver.cpp:222] Iteration 50240 (1.28283 iter/s, 31.181s/40 iters), loss = 1.38214
I1029 05:11:13.966498 29475 solver.cpp:241]     Train net output #0: loss = 1.38214 (* 1 = 1.38214 loss)
I1029 05:11:13.966516 29475 sgd_solver.cpp:105] Iteration 50240, lr = 0.00403594
I1029 05:11:45.739487 29475 solver.cpp:222] Iteration 50280 (1.25898 iter/s, 31.7718s/40 iters), loss = 1.59635
I1029 05:11:45.739758 29475 solver.cpp:241]     Train net output #0: loss = 1.59635 (* 1 = 1.59635 loss)
I1029 05:11:45.739775 29475 sgd_solver.cpp:105] Iteration 50280, lr = 0.00403172
I1029 05:12:16.925773 29475 solver.cpp:222] Iteration 50320 (1.28267 iter/s, 31.1848s/40 iters), loss = 1.49912
I1029 05:12:16.925969 29475 solver.cpp:241]     Train net output #0: loss = 1.49912 (* 1 = 1.49912 loss)
I1029 05:12:16.925988 29475 sgd_solver.cpp:105] Iteration 50320, lr = 0.0040275
I1029 05:12:48.443061 29475 solver.cpp:222] Iteration 50360 (1.2692 iter/s, 31.5159s/40 iters), loss = 1.65193
I1029 05:12:48.443249 29475 solver.cpp:241]     Train net output #0: loss = 1.65193 (* 1 = 1.65193 loss)
I1029 05:12:48.443269 29475 sgd_solver.cpp:105] Iteration 50360, lr = 0.00402329
I1029 05:13:19.962467 29475 solver.cpp:222] Iteration 50400 (1.26911 iter/s, 31.518s/40 iters), loss = 1.50605
I1029 05:13:19.962649 29475 solver.cpp:241]     Train net output #0: loss = 1.50605 (* 1 = 1.50605 loss)
I1029 05:13:19.962666 29475 sgd_solver.cpp:105] Iteration 50400, lr = 0.00401908
I1029 05:13:51.909076 29475 solver.cpp:222] Iteration 50440 (1.25214 iter/s, 31.9452s/40 iters), loss = 1.54666
I1029 05:13:51.909251 29475 solver.cpp:241]     Train net output #0: loss = 1.54666 (* 1 = 1.54666 loss)
I1029 05:13:51.909267 29475 sgd_solver.cpp:105] Iteration 50440, lr = 0.00401486
I1029 05:14:26.621989 29475 solver.cpp:222] Iteration 50480 (1.15236 iter/s, 34.7114s/40 iters), loss = 1.64777
I1029 05:14:26.622177 29475 solver.cpp:241]     Train net output #0: loss = 1.64777 (* 1 = 1.64777 loss)
I1029 05:14:26.622195 29475 sgd_solver.cpp:105] Iteration 50480, lr = 0.00401065
I1029 05:14:42.001440 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_50500.caffemodel
I1029 05:14:42.037811 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_50500.solverstate
I1029 05:14:42.064560 29475 solver.cpp:334] Iteration 50500, Testing net (#0)
I1029 05:15:12.832828 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 05:15:13.039909 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55992
I1029 05:15:13.039976 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79236
I1029 05:15:13.039990 29475 solver.cpp:401]     Test net output #2: loss = 1.95614 (* 1 = 1.95614 loss)
I1029 05:15:29.933655 29475 solver.cpp:222] Iteration 50520 (0.631821 iter/s, 63.3091s/40 iters), loss = 1.73277
I1029 05:15:29.933753 29475 solver.cpp:241]     Train net output #0: loss = 1.73277 (* 1 = 1.73277 loss)
I1029 05:15:29.933774 29475 sgd_solver.cpp:105] Iteration 50520, lr = 0.00400644
I1029 05:16:01.528038 29475 solver.cpp:222] Iteration 50560 (1.2661 iter/s, 31.5931s/40 iters), loss = 1.40617
I1029 05:16:01.528240 29475 solver.cpp:241]     Train net output #0: loss = 1.40617 (* 1 = 1.40617 loss)
I1029 05:16:01.528259 29475 sgd_solver.cpp:105] Iteration 50560, lr = 0.00400223
I1029 05:16:32.822115 29475 solver.cpp:222] Iteration 50600 (1.27825 iter/s, 31.2927s/40 iters), loss = 1.75437
I1029 05:16:32.822321 29475 solver.cpp:241]     Train net output #0: loss = 1.75437 (* 1 = 1.75437 loss)
I1029 05:16:32.822338 29475 sgd_solver.cpp:105] Iteration 50600, lr = 0.00399802
I1029 05:17:04.067390 29475 solver.cpp:222] Iteration 50640 (1.28025 iter/s, 31.2439s/40 iters), loss = 1.92858
I1029 05:17:04.067589 29475 solver.cpp:241]     Train net output #0: loss = 1.92858 (* 1 = 1.92858 loss)
I1029 05:17:04.067608 29475 sgd_solver.cpp:105] Iteration 50640, lr = 0.00399381
I1029 05:17:36.334388 29475 solver.cpp:222] Iteration 50680 (1.23972 iter/s, 32.2654s/40 iters), loss = 1.2827
I1029 05:17:36.334655 29475 solver.cpp:241]     Train net output #0: loss = 1.2827 (* 1 = 1.2827 loss)
I1029 05:17:36.334683 29475 sgd_solver.cpp:105] Iteration 50680, lr = 0.00398961
I1029 05:18:07.790392 29475 solver.cpp:222] Iteration 50720 (1.27168 iter/s, 31.4545s/40 iters), loss = 1.31209
I1029 05:18:07.790673 29475 solver.cpp:241]     Train net output #0: loss = 1.31209 (* 1 = 1.31209 loss)
I1029 05:18:07.790725 29475 sgd_solver.cpp:105] Iteration 50720, lr = 0.0039854
I1029 05:18:39.364240 29475 solver.cpp:222] Iteration 50760 (1.26693 iter/s, 31.5723s/40 iters), loss = 2.10057
I1029 05:18:39.364446 29475 solver.cpp:241]     Train net output #0: loss = 2.10057 (* 1 = 2.10057 loss)
I1029 05:18:39.364465 29475 sgd_solver.cpp:105] Iteration 50760, lr = 0.00398119
I1029 05:19:11.686451 29475 solver.cpp:222] Iteration 50800 (1.2376 iter/s, 32.3207s/40 iters), loss = 1.41109
I1029 05:19:11.686663 29475 solver.cpp:241]     Train net output #0: loss = 1.41109 (* 1 = 1.41109 loss)
I1029 05:19:11.686682 29475 sgd_solver.cpp:105] Iteration 50800, lr = 0.00397699
I1029 05:19:43.893468 29475 solver.cpp:222] Iteration 50840 (1.24202 iter/s, 32.2056s/40 iters), loss = 1.6221
I1029 05:19:43.893642 29475 solver.cpp:241]     Train net output #0: loss = 1.6221 (* 1 = 1.6221 loss)
I1029 05:19:43.893658 29475 sgd_solver.cpp:105] Iteration 50840, lr = 0.00397279
I1029 05:20:15.506050 29475 solver.cpp:222] Iteration 50880 (1.26537 iter/s, 31.6112s/40 iters), loss = 1.61141
I1029 05:20:15.506268 29475 solver.cpp:241]     Train net output #0: loss = 1.61141 (* 1 = 1.61141 loss)
I1029 05:20:15.506286 29475 sgd_solver.cpp:105] Iteration 50880, lr = 0.00396859
I1029 05:20:49.275185 29475 solver.cpp:222] Iteration 50920 (1.18457 iter/s, 33.7676s/40 iters), loss = 1.5993
I1029 05:20:49.275441 29475 solver.cpp:241]     Train net output #0: loss = 1.5993 (* 1 = 1.5993 loss)
I1029 05:20:49.275467 29475 sgd_solver.cpp:105] Iteration 50920, lr = 0.00396439
I1029 05:21:28.347966 29475 solver.cpp:222] Iteration 50960 (1.02378 iter/s, 39.071s/40 iters), loss = 1.57724
I1029 05:21:28.348208 29475 solver.cpp:241]     Train net output #0: loss = 1.57724 (* 1 = 1.57724 loss)
I1029 05:21:28.348232 29475 sgd_solver.cpp:105] Iteration 50960, lr = 0.00396019
I1029 05:22:05.383970 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_51000.caffemodel
I1029 05:22:05.431594 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_51000.solverstate
I1029 05:22:05.455049 29475 solver.cpp:334] Iteration 51000, Testing net (#0)
I1029 05:22:36.490247 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5654
I1029 05:22:36.490403 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79468
I1029 05:22:36.490418 29475 solver.cpp:401]     Test net output #2: loss = 1.92462 (* 1 = 1.92462 loss)
I1029 05:22:37.267906 29475 solver.cpp:222] Iteration 51000 (0.580407 iter/s, 68.9171s/40 iters), loss = 1.40934
I1029 05:22:37.267972 29475 solver.cpp:241]     Train net output #0: loss = 1.40934 (* 1 = 1.40934 loss)
I1029 05:22:37.267987 29475 sgd_solver.cpp:105] Iteration 51000, lr = 0.00395599
I1029 05:23:08.193162 29475 solver.cpp:222] Iteration 51040 (1.2935 iter/s, 30.9239s/40 iters), loss = 1.70886
I1029 05:23:08.193351 29475 solver.cpp:241]     Train net output #0: loss = 1.70886 (* 1 = 1.70886 loss)
I1029 05:23:08.193368 29475 sgd_solver.cpp:105] Iteration 51040, lr = 0.00395179
I1029 05:23:39.408994 29475 solver.cpp:222] Iteration 51080 (1.28146 iter/s, 31.2145s/40 iters), loss = 1.87827
I1029 05:23:39.409162 29475 solver.cpp:241]     Train net output #0: loss = 1.87827 (* 1 = 1.87827 loss)
I1029 05:23:39.409178 29475 sgd_solver.cpp:105] Iteration 51080, lr = 0.00394759
I1029 05:24:10.247467 29475 solver.cpp:222] Iteration 51120 (1.29714 iter/s, 30.837s/40 iters), loss = 1.86945
I1029 05:24:10.247630 29475 solver.cpp:241]     Train net output #0: loss = 1.86945 (* 1 = 1.86945 loss)
I1029 05:24:10.247648 29475 sgd_solver.cpp:105] Iteration 51120, lr = 0.0039434
I1029 05:24:41.388933 29475 solver.cpp:222] Iteration 51160 (1.28452 iter/s, 31.1401s/40 iters), loss = 1.13838
I1029 05:24:41.389101 29475 solver.cpp:241]     Train net output #0: loss = 1.13838 (* 1 = 1.13838 loss)
I1029 05:24:41.389117 29475 sgd_solver.cpp:105] Iteration 51160, lr = 0.0039392
I1029 05:25:12.545712 29475 solver.cpp:222] Iteration 51200 (1.28388 iter/s, 31.1554s/40 iters), loss = 1.68004
I1029 05:25:12.545958 29475 solver.cpp:241]     Train net output #0: loss = 1.68004 (* 1 = 1.68004 loss)
I1029 05:25:12.545984 29475 sgd_solver.cpp:105] Iteration 51200, lr = 0.00393501
I1029 05:25:43.362058 29475 solver.cpp:222] Iteration 51240 (1.29807 iter/s, 30.8149s/40 iters), loss = 1.49428
I1029 05:25:43.362257 29475 solver.cpp:241]     Train net output #0: loss = 1.49428 (* 1 = 1.49428 loss)
I1029 05:25:43.362272 29475 sgd_solver.cpp:105] Iteration 51240, lr = 0.00393082
I1029 05:26:14.080564 29475 solver.cpp:222] Iteration 51280 (1.3022 iter/s, 30.7171s/40 iters), loss = 1.38748
I1029 05:26:14.080744 29475 solver.cpp:241]     Train net output #0: loss = 1.38748 (* 1 = 1.38748 loss)
I1029 05:26:14.080760 29475 sgd_solver.cpp:105] Iteration 51280, lr = 0.00392663
I1029 05:26:45.015404 29475 solver.cpp:222] Iteration 51320 (1.2931 iter/s, 30.9334s/40 iters), loss = 1.41485
I1029 05:26:45.015635 29475 solver.cpp:241]     Train net output #0: loss = 1.41485 (* 1 = 1.41485 loss)
I1029 05:26:45.015666 29475 sgd_solver.cpp:105] Iteration 51320, lr = 0.00392243
I1029 05:27:16.066537 29475 solver.cpp:222] Iteration 51360 (1.28826 iter/s, 31.0497s/40 iters), loss = 1.55546
I1029 05:27:16.066735 29475 solver.cpp:241]     Train net output #0: loss = 1.55546 (* 1 = 1.55546 loss)
I1029 05:27:16.066751 29475 sgd_solver.cpp:105] Iteration 51360, lr = 0.00391825
I1029 05:27:47.351506 29475 solver.cpp:222] Iteration 51400 (1.27863 iter/s, 31.2836s/40 iters), loss = 1.71761
I1029 05:27:47.351691 29475 solver.cpp:241]     Train net output #0: loss = 1.71761 (* 1 = 1.71761 loss)
I1029 05:27:47.351709 29475 sgd_solver.cpp:105] Iteration 51400, lr = 0.00391406
I1029 05:28:18.591024 29475 solver.cpp:222] Iteration 51440 (1.28049 iter/s, 31.2381s/40 iters), loss = 1.59024
I1029 05:28:18.591222 29475 solver.cpp:241]     Train net output #0: loss = 1.59024 (* 1 = 1.59024 loss)
I1029 05:28:18.591239 29475 sgd_solver.cpp:105] Iteration 51440, lr = 0.00390987
I1029 05:28:49.740475 29475 solver.cpp:222] Iteration 51480 (1.28419 iter/s, 31.1481s/40 iters), loss = 1.48622
I1029 05:28:49.740679 29475 solver.cpp:241]     Train net output #0: loss = 1.48622 (* 1 = 1.48622 loss)
I1029 05:28:49.740696 29475 sgd_solver.cpp:105] Iteration 51480, lr = 0.00390568
I1029 05:29:04.567518 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_51500.caffemodel
I1029 05:29:04.603384 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_51500.solverstate
I1029 05:29:04.621532 29475 solver.cpp:334] Iteration 51500, Testing net (#0)
I1029 05:29:35.445998 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 05:29:35.656149 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55916
I1029 05:29:35.656211 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.795719
I1029 05:29:35.656225 29475 solver.cpp:401]     Test net output #2: loss = 1.94787 (* 1 = 1.94787 loss)
I1029 05:29:51.846144 29475 solver.cpp:222] Iteration 51520 (0.64409 iter/s, 62.1031s/40 iters), loss = 1.55532
I1029 05:29:51.846222 29475 solver.cpp:241]     Train net output #0: loss = 1.55532 (* 1 = 1.55532 loss)
I1029 05:29:51.846240 29475 sgd_solver.cpp:105] Iteration 51520, lr = 0.0039015
I1029 05:30:22.680943 29475 solver.cpp:222] Iteration 51560 (1.29729 iter/s, 30.8335s/40 iters), loss = 1.7058
I1029 05:30:22.681185 29475 solver.cpp:241]     Train net output #0: loss = 1.7058 (* 1 = 1.7058 loss)
I1029 05:30:22.681201 29475 sgd_solver.cpp:105] Iteration 51560, lr = 0.00389731
I1029 05:30:53.196676 29475 solver.cpp:222] Iteration 51600 (1.31086 iter/s, 30.5143s/40 iters), loss = 1.37128
I1029 05:30:53.196849 29475 solver.cpp:241]     Train net output #0: loss = 1.37128 (* 1 = 1.37128 loss)
I1029 05:30:53.196868 29475 sgd_solver.cpp:105] Iteration 51600, lr = 0.00389313
I1029 05:31:23.827347 29475 solver.cpp:222] Iteration 51640 (1.30594 iter/s, 30.6293s/40 iters), loss = 1.33748
I1029 05:31:23.827621 29475 solver.cpp:241]     Train net output #0: loss = 1.33748 (* 1 = 1.33748 loss)
I1029 05:31:23.827639 29475 sgd_solver.cpp:105] Iteration 51640, lr = 0.00388895
I1029 05:31:54.843431 29475 solver.cpp:222] Iteration 51680 (1.28971 iter/s, 31.0146s/40 iters), loss = 1.80739
I1029 05:31:54.843606 29475 solver.cpp:241]     Train net output #0: loss = 1.80739 (* 1 = 1.80739 loss)
I1029 05:31:54.843623 29475 sgd_solver.cpp:105] Iteration 51680, lr = 0.00388477
I1029 05:32:26.260408 29475 solver.cpp:222] Iteration 51720 (1.27325 iter/s, 31.4156s/40 iters), loss = 1.78055
I1029 05:32:26.260596 29475 solver.cpp:241]     Train net output #0: loss = 1.78055 (* 1 = 1.78055 loss)
I1029 05:32:26.260613 29475 sgd_solver.cpp:105] Iteration 51720, lr = 0.00388059
I1029 05:32:57.280047 29475 solver.cpp:222] Iteration 51760 (1.28956 iter/s, 31.0183s/40 iters), loss = 1.64753
I1029 05:32:57.280246 29475 solver.cpp:241]     Train net output #0: loss = 1.64753 (* 1 = 1.64753 loss)
I1029 05:32:57.280263 29475 sgd_solver.cpp:105] Iteration 51760, lr = 0.00387641
I1029 05:33:28.235913 29475 solver.cpp:222] Iteration 51800 (1.29222 iter/s, 30.9545s/40 iters), loss = 1.24711
I1029 05:33:28.236114 29475 solver.cpp:241]     Train net output #0: loss = 1.24711 (* 1 = 1.24711 loss)
I1029 05:33:28.236130 29475 sgd_solver.cpp:105] Iteration 51800, lr = 0.00387223
I1029 05:33:59.885896 29475 solver.cpp:222] Iteration 51840 (1.26388 iter/s, 31.6486s/40 iters), loss = 1.40954
I1029 05:33:59.886109 29475 solver.cpp:241]     Train net output #0: loss = 1.40954 (* 1 = 1.40954 loss)
I1029 05:33:59.886134 29475 sgd_solver.cpp:105] Iteration 51840, lr = 0.00386805
I1029 05:34:31.219897 29475 solver.cpp:222] Iteration 51880 (1.27663 iter/s, 31.3326s/40 iters), loss = 1.32267
I1029 05:34:31.220065 29475 solver.cpp:241]     Train net output #0: loss = 1.32267 (* 1 = 1.32267 loss)
I1029 05:34:31.220082 29475 sgd_solver.cpp:105] Iteration 51880, lr = 0.00386388
I1029 05:35:02.851780 29475 solver.cpp:222] Iteration 51920 (1.2646 iter/s, 31.6305s/40 iters), loss = 1.37012
I1029 05:35:02.851938 29475 solver.cpp:241]     Train net output #0: loss = 1.37012 (* 1 = 1.37012 loss)
I1029 05:35:02.851956 29475 sgd_solver.cpp:105] Iteration 51920, lr = 0.0038597
I1029 05:35:33.651371 29475 solver.cpp:222] Iteration 51960 (1.29878 iter/s, 30.7982s/40 iters), loss = 1.77667
I1029 05:35:33.651548 29475 solver.cpp:241]     Train net output #0: loss = 1.77667 (* 1 = 1.77667 loss)
I1029 05:35:33.651567 29475 sgd_solver.cpp:105] Iteration 51960, lr = 0.00385553
I1029 05:36:03.656484 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_52000.caffemodel
I1029 05:36:03.690805 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_52000.solverstate
I1029 05:36:03.707307 29475 solver.cpp:334] Iteration 52000, Testing net (#0)
I1029 05:36:34.746650 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56248
I1029 05:36:34.746820 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7954
I1029 05:36:34.746835 29475 solver.cpp:401]     Test net output #2: loss = 1.93746 (* 1 = 1.93746 loss)
I1029 05:36:35.507134 29475 solver.cpp:222] Iteration 52000 (0.646692 iter/s, 61.8533s/40 iters), loss = 1.71903
I1029 05:36:35.507203 29475 solver.cpp:241]     Train net output #0: loss = 1.71903 (* 1 = 1.71903 loss)
I1029 05:36:35.507220 29475 sgd_solver.cpp:105] Iteration 52000, lr = 0.00385136
I1029 05:37:06.625059 29475 solver.cpp:222] Iteration 52040 (1.28548 iter/s, 31.1167s/40 iters), loss = 1.75731
I1029 05:37:06.625249 29475 solver.cpp:241]     Train net output #0: loss = 1.75731 (* 1 = 1.75731 loss)
I1029 05:37:06.625267 29475 sgd_solver.cpp:105] Iteration 52040, lr = 0.00384718
I1029 05:37:37.577723 29475 solver.cpp:222] Iteration 52080 (1.29235 iter/s, 30.9513s/40 iters), loss = 1.14497
I1029 05:37:37.577913 29475 solver.cpp:241]     Train net output #0: loss = 1.14497 (* 1 = 1.14497 loss)
I1029 05:37:37.577934 29475 sgd_solver.cpp:105] Iteration 52080, lr = 0.00384301
I1029 05:38:08.586606 29475 solver.cpp:222] Iteration 52120 (1.29001 iter/s, 31.0075s/40 iters), loss = 1.4412
I1029 05:38:08.586838 29475 solver.cpp:241]     Train net output #0: loss = 1.4412 (* 1 = 1.4412 loss)
I1029 05:38:08.586855 29475 sgd_solver.cpp:105] Iteration 52120, lr = 0.00383884
I1029 05:38:39.396669 29475 solver.cpp:222] Iteration 52160 (1.29834 iter/s, 30.8087s/40 iters), loss = 1.43427
I1029 05:38:39.396832 29475 solver.cpp:241]     Train net output #0: loss = 1.43427 (* 1 = 1.43427 loss)
I1029 05:38:39.396849 29475 sgd_solver.cpp:105] Iteration 52160, lr = 0.00383467
I1029 05:39:10.520015 29475 solver.cpp:222] Iteration 52200 (1.28526 iter/s, 31.122s/40 iters), loss = 1.83312
I1029 05:39:10.520205 29475 solver.cpp:241]     Train net output #0: loss = 1.83312 (* 1 = 1.83312 loss)
I1029 05:39:10.520223 29475 sgd_solver.cpp:105] Iteration 52200, lr = 0.00383051
I1029 05:39:41.737735 29475 solver.cpp:222] Iteration 52240 (1.28138 iter/s, 31.2163s/40 iters), loss = 1.97213
I1029 05:39:41.737934 29475 solver.cpp:241]     Train net output #0: loss = 1.97213 (* 1 = 1.97213 loss)
I1029 05:39:41.737953 29475 sgd_solver.cpp:105] Iteration 52240, lr = 0.00382634
I1029 05:40:13.662060 29475 solver.cpp:222] Iteration 52280 (1.25302 iter/s, 31.9229s/40 iters), loss = 1.59833
I1029 05:40:13.662277 29475 solver.cpp:241]     Train net output #0: loss = 1.59833 (* 1 = 1.59833 loss)
I1029 05:40:13.662304 29475 sgd_solver.cpp:105] Iteration 52280, lr = 0.00382217
I1029 05:40:44.369089 29475 solver.cpp:222] Iteration 52320 (1.30269 iter/s, 30.7057s/40 iters), loss = 1.6302
I1029 05:40:44.369307 29475 solver.cpp:241]     Train net output #0: loss = 1.6302 (* 1 = 1.6302 loss)
I1029 05:40:44.369324 29475 sgd_solver.cpp:105] Iteration 52320, lr = 0.00381801
I1029 05:41:15.230412 29475 solver.cpp:222] Iteration 52360 (1.29618 iter/s, 30.8599s/40 iters), loss = 1.49604
I1029 05:41:15.230609 29475 solver.cpp:241]     Train net output #0: loss = 1.49604 (* 1 = 1.49604 loss)
I1029 05:41:15.230628 29475 sgd_solver.cpp:105] Iteration 52360, lr = 0.00381385
I1029 05:41:46.475819 29475 solver.cpp:222] Iteration 52400 (1.28024 iter/s, 31.244s/40 iters), loss = 1.87124
I1029 05:41:46.476068 29475 solver.cpp:241]     Train net output #0: loss = 1.87124 (* 1 = 1.87124 loss)
I1029 05:41:46.476091 29475 sgd_solver.cpp:105] Iteration 52400, lr = 0.00380968
I1029 05:42:18.724751 29475 solver.cpp:222] Iteration 52440 (1.24041 iter/s, 32.2475s/40 iters), loss = 1.53064
I1029 05:42:18.725010 29475 solver.cpp:241]     Train net output #0: loss = 1.53064 (* 1 = 1.53064 loss)
I1029 05:42:18.725037 29475 sgd_solver.cpp:105] Iteration 52440, lr = 0.00380552
I1029 05:42:51.355327 29475 solver.cpp:222] Iteration 52480 (1.2259 iter/s, 32.6291s/40 iters), loss = 1.51157
I1029 05:42:51.355516 29475 solver.cpp:241]     Train net output #0: loss = 1.51157 (* 1 = 1.51157 loss)
I1029 05:42:51.355535 29475 sgd_solver.cpp:105] Iteration 52480, lr = 0.00380136
I1029 05:43:06.335255 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_52500.caffemodel
I1029 05:43:06.371006 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_52500.solverstate
I1029 05:43:06.391939 29475 solver.cpp:334] Iteration 52500, Testing net (#0)
I1029 05:43:37.177707 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 05:43:37.385484 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56212
I1029 05:43:37.385546 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79844
I1029 05:43:37.385560 29475 solver.cpp:401]     Test net output #2: loss = 1.9519 (* 1 = 1.9519 loss)
I1029 05:43:54.043804 29475 solver.cpp:222] Iteration 52520 (0.638103 iter/s, 62.6858s/40 iters), loss = 1.61282
I1029 05:43:54.043877 29475 solver.cpp:241]     Train net output #0: loss = 1.61282 (* 1 = 1.61282 loss)
I1029 05:43:54.043895 29475 sgd_solver.cpp:105] Iteration 52520, lr = 0.0037972
I1029 05:44:12.481190 29523 data_layer.cpp:73] Restarting data prefetching from start.
I1029 05:44:25.488765 29475 solver.cpp:222] Iteration 52560 (1.27212 iter/s, 31.4436s/40 iters), loss = 1.36474
I1029 05:44:25.488837 29475 solver.cpp:241]     Train net output #0: loss = 1.36474 (* 1 = 1.36474 loss)
I1029 05:44:25.488853 29475 sgd_solver.cpp:105] Iteration 52560, lr = 0.00379305
I1029 05:44:56.969638 29475 solver.cpp:222] Iteration 52600 (1.27066 iter/s, 31.4796s/40 iters), loss = 1.4367
I1029 05:44:56.969842 29475 solver.cpp:241]     Train net output #0: loss = 1.4367 (* 1 = 1.4367 loss)
I1029 05:44:56.969859 29475 sgd_solver.cpp:105] Iteration 52600, lr = 0.00378889
I1029 05:45:28.142084 29475 solver.cpp:222] Iteration 52640 (1.28324 iter/s, 31.1711s/40 iters), loss = 1.59072
I1029 05:45:28.142321 29475 solver.cpp:241]     Train net output #0: loss = 1.59072 (* 1 = 1.59072 loss)
I1029 05:45:28.142339 29475 sgd_solver.cpp:105] Iteration 52640, lr = 0.00378473
I1029 05:45:59.793685 29475 solver.cpp:222] Iteration 52680 (1.26382 iter/s, 31.6502s/40 iters), loss = 1.73752
I1029 05:45:59.793881 29475 solver.cpp:241]     Train net output #0: loss = 1.73752 (* 1 = 1.73752 loss)
I1029 05:45:59.793898 29475 sgd_solver.cpp:105] Iteration 52680, lr = 0.00378058
I1029 05:46:31.538624 29475 solver.cpp:222] Iteration 52720 (1.2601 iter/s, 31.7435s/40 iters), loss = 1.4602
I1029 05:46:31.538786 29475 solver.cpp:241]     Train net output #0: loss = 1.4602 (* 1 = 1.4602 loss)
I1029 05:46:31.538805 29475 sgd_solver.cpp:105] Iteration 52720, lr = 0.00377642
I1029 05:47:02.524274 29475 solver.cpp:222] Iteration 52760 (1.29098 iter/s, 30.9843s/40 iters), loss = 1.79125
I1029 05:47:02.524492 29475 solver.cpp:241]     Train net output #0: loss = 1.79125 (* 1 = 1.79125 loss)
I1029 05:47:02.524509 29475 sgd_solver.cpp:105] Iteration 52760, lr = 0.00377227
I1029 05:47:33.513228 29475 solver.cpp:222] Iteration 52800 (1.29084 iter/s, 30.9876s/40 iters), loss = 1.40454
I1029 05:47:33.513420 29475 solver.cpp:241]     Train net output #0: loss = 1.40454 (* 1 = 1.40454 loss)
I1029 05:47:33.513438 29475 sgd_solver.cpp:105] Iteration 52800, lr = 0.00376812
I1029 05:48:04.258932 29475 solver.cpp:222] Iteration 52840 (1.30106 iter/s, 30.7443s/40 iters), loss = 1.69516
I1029 05:48:04.259121 29475 solver.cpp:241]     Train net output #0: loss = 1.69516 (* 1 = 1.69516 loss)
I1029 05:48:04.259138 29475 sgd_solver.cpp:105] Iteration 52840, lr = 0.00376397
I1029 05:48:35.477900 29475 solver.cpp:222] Iteration 52880 (1.28133 iter/s, 31.2176s/40 iters), loss = 1.35939
I1029 05:48:35.478101 29475 solver.cpp:241]     Train net output #0: loss = 1.35939 (* 1 = 1.35939 loss)
I1029 05:48:35.478118 29475 sgd_solver.cpp:105] Iteration 52880, lr = 0.00375982
I1029 05:49:06.550457 29475 solver.cpp:222] Iteration 52920 (1.28737 iter/s, 31.0712s/40 iters), loss = 1.42722
I1029 05:49:06.550642 29475 solver.cpp:241]     Train net output #0: loss = 1.42722 (* 1 = 1.42722 loss)
I1029 05:49:06.550662 29475 sgd_solver.cpp:105] Iteration 52920, lr = 0.00375567
I1029 05:49:37.852226 29475 solver.cpp:222] Iteration 52960 (1.27794 iter/s, 31.3003s/40 iters), loss = 1.5279
I1029 05:49:37.852473 29475 solver.cpp:241]     Train net output #0: loss = 1.5279 (* 1 = 1.5279 loss)
I1029 05:49:37.852491 29475 sgd_solver.cpp:105] Iteration 52960, lr = 0.00375152
I1029 05:50:08.575186 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_53000.caffemodel
I1029 05:50:08.638231 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_53000.solverstate
I1029 05:50:10.139943 29475 solver.cpp:334] Iteration 53000, Testing net (#0)
I1029 05:50:42.265003 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56148
I1029 05:50:42.265183 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79348
I1029 05:50:42.265197 29475 solver.cpp:401]     Test net output #2: loss = 1.96149 (* 1 = 1.96149 loss)
I1029 05:50:43.031097 29475 solver.cpp:222] Iteration 53000 (0.613721 iter/s, 65.1762s/40 iters), loss = 1.63192
I1029 05:50:43.031188 29475 solver.cpp:241]     Train net output #0: loss = 1.63192 (* 1 = 1.63192 loss)
I1029 05:50:43.031203 29475 sgd_solver.cpp:105] Iteration 53000, lr = 0.00374738
I1029 05:51:18.428997 29475 solver.cpp:222] Iteration 53040 (1.13006 iter/s, 35.3965s/40 iters), loss = 1.65111
I1029 05:51:18.429235 29475 solver.cpp:241]     Train net output #0: loss = 1.65111 (* 1 = 1.65111 loss)
I1029 05:51:18.429253 29475 sgd_solver.cpp:105] Iteration 53040, lr = 0.00374323
I1029 05:51:51.261826 29475 solver.cpp:222] Iteration 53080 (1.21835 iter/s, 32.8313s/40 iters), loss = 1.32902
I1029 05:51:51.262087 29475 solver.cpp:241]     Train net output #0: loss = 1.32902 (* 1 = 1.32902 loss)
I1029 05:51:51.262115 29475 sgd_solver.cpp:105] Iteration 53080, lr = 0.00373909
I1029 05:52:22.812021 29475 solver.cpp:222] Iteration 53120 (1.26788 iter/s, 31.5487s/40 iters), loss = 1.86252
I1029 05:52:22.812209 29475 solver.cpp:241]     Train net output #0: loss = 1.86252 (* 1 = 1.86252 loss)
I1029 05:52:22.812227 29475 sgd_solver.cpp:105] Iteration 53120, lr = 0.00373494
I1029 05:52:53.806026 29475 solver.cpp:222] Iteration 53160 (1.29063 iter/s, 30.9926s/40 iters), loss = 1.55784
I1029 05:52:53.806185 29475 solver.cpp:241]     Train net output #0: loss = 1.55784 (* 1 = 1.55784 loss)
I1029 05:52:53.806202 29475 sgd_solver.cpp:105] Iteration 53160, lr = 0.0037308
I1029 05:53:24.728997 29475 solver.cpp:222] Iteration 53200 (1.29359 iter/s, 30.9216s/40 iters), loss = 1.42599
I1029 05:53:24.729184 29475 solver.cpp:241]     Train net output #0: loss = 1.42599 (* 1 = 1.42599 loss)
I1029 05:53:24.729202 29475 sgd_solver.cpp:105] Iteration 53200, lr = 0.00372666
I1029 05:53:56.160616 29475 solver.cpp:222] Iteration 53240 (1.27266 iter/s, 31.4302s/40 iters), loss = 1.35308
I1029 05:53:56.160811 29475 solver.cpp:241]     Train net output #0: loss = 1.35308 (* 1 = 1.35308 loss)
I1029 05:53:56.160830 29475 sgd_solver.cpp:105] Iteration 53240, lr = 0.00372252
I1029 05:54:27.072878 29475 solver.cpp:222] Iteration 53280 (1.29404 iter/s, 30.9109s/40 iters), loss = 1.79517
I1029 05:54:27.073074 29475 solver.cpp:241]     Train net output #0: loss = 1.79517 (* 1 = 1.79517 loss)
I1029 05:54:27.073093 29475 sgd_solver.cpp:105] Iteration 53280, lr = 0.00371838
I1029 05:54:58.022580 29475 solver.cpp:222] Iteration 53320 (1.29248 iter/s, 30.9483s/40 iters), loss = 1.44731
I1029 05:54:58.022765 29475 solver.cpp:241]     Train net output #0: loss = 1.44731 (* 1 = 1.44731 loss)
I1029 05:54:58.022781 29475 sgd_solver.cpp:105] Iteration 53320, lr = 0.00371424
I1029 05:55:28.806200 29475 solver.cpp:222] Iteration 53360 (1.29945 iter/s, 30.7822s/40 iters), loss = 1.65987
I1029 05:55:28.806380 29475 solver.cpp:241]     Train net output #0: loss = 1.65987 (* 1 = 1.65987 loss)
I1029 05:55:28.806396 29475 sgd_solver.cpp:105] Iteration 53360, lr = 0.0037101
I1029 05:55:59.584841 29475 solver.cpp:222] Iteration 53400 (1.29966 iter/s, 30.7773s/40 iters), loss = 1.52553
I1029 05:55:59.585027 29475 solver.cpp:241]     Train net output #0: loss = 1.52553 (* 1 = 1.52553 loss)
I1029 05:55:59.585047 29475 sgd_solver.cpp:105] Iteration 53400, lr = 0.00370597
I1029 05:56:30.279754 29475 solver.cpp:222] Iteration 53440 (1.30321 iter/s, 30.6936s/40 iters), loss = 1.91009
I1029 05:56:30.279937 29475 solver.cpp:241]     Train net output #0: loss = 1.91009 (* 1 = 1.91009 loss)
I1029 05:56:30.279956 29475 sgd_solver.cpp:105] Iteration 53440, lr = 0.00370183
I1029 05:57:01.027166 29475 solver.cpp:222] Iteration 53480 (1.30098 iter/s, 30.7461s/40 iters), loss = 1.5319
I1029 05:57:01.027369 29475 solver.cpp:241]     Train net output #0: loss = 1.5319 (* 1 = 1.5319 loss)
I1029 05:57:01.027386 29475 sgd_solver.cpp:105] Iteration 53480, lr = 0.0036977
I1029 05:57:15.566275 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_53500.caffemodel
I1029 05:57:15.602293 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_53500.solverstate
I1029 05:57:15.618923 29475 solver.cpp:334] Iteration 53500, Testing net (#0)
I1029 05:57:46.413892 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 05:57:46.620645 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.560119
I1029 05:57:46.620712 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.797039
I1029 05:57:46.620725 29475 solver.cpp:401]     Test net output #2: loss = 1.94219 (* 1 = 1.94219 loss)
I1029 05:58:02.889968 29475 solver.cpp:222] Iteration 53520 (0.646618 iter/s, 61.8603s/40 iters), loss = 1.93994
I1029 05:58:02.890036 29475 solver.cpp:241]     Train net output #0: loss = 1.93994 (* 1 = 1.93994 loss)
I1029 05:58:02.890051 29475 sgd_solver.cpp:105] Iteration 53520, lr = 0.00369357
I1029 05:58:33.881403 29475 solver.cpp:222] Iteration 53560 (1.29073 iter/s, 30.9902s/40 iters), loss = 1.31866
I1029 05:58:33.881629 29475 solver.cpp:241]     Train net output #0: loss = 1.31866 (* 1 = 1.31866 loss)
I1029 05:58:33.881649 29475 sgd_solver.cpp:105] Iteration 53560, lr = 0.00368944
I1029 05:59:04.859530 29475 solver.cpp:222] Iteration 53600 (1.29129 iter/s, 30.9767s/40 iters), loss = 1.89006
I1029 05:59:04.859701 29475 solver.cpp:241]     Train net output #0: loss = 1.89006 (* 1 = 1.89006 loss)
I1029 05:59:04.859717 29475 sgd_solver.cpp:105] Iteration 53600, lr = 0.0036853
I1029 05:59:35.738095 29475 solver.cpp:222] Iteration 53640 (1.29546 iter/s, 30.8771s/40 iters), loss = 1.31657
I1029 05:59:35.738274 29475 solver.cpp:241]     Train net output #0: loss = 1.31657 (* 1 = 1.31657 loss)
I1029 05:59:35.738292 29475 sgd_solver.cpp:105] Iteration 53640, lr = 0.00368117
I1029 06:00:06.523448 29475 solver.cpp:222] Iteration 53680 (1.29938 iter/s, 30.784s/40 iters), loss = 1.56922
I1029 06:00:06.523645 29475 solver.cpp:241]     Train net output #0: loss = 1.56922 (* 1 = 1.56922 loss)
I1029 06:00:06.523663 29475 sgd_solver.cpp:105] Iteration 53680, lr = 0.00367705
I1029 06:00:36.996171 29475 solver.cpp:222] Iteration 53720 (1.31271 iter/s, 30.4713s/40 iters), loss = 1.73259
I1029 06:00:36.996353 29475 solver.cpp:241]     Train net output #0: loss = 1.73259 (* 1 = 1.73259 loss)
I1029 06:00:36.996371 29475 sgd_solver.cpp:105] Iteration 53720, lr = 0.00367292
I1029 06:01:07.662549 29475 solver.cpp:222] Iteration 53760 (1.30442 iter/s, 30.665s/40 iters), loss = 1.55773
I1029 06:01:07.662763 29475 solver.cpp:241]     Train net output #0: loss = 1.55773 (* 1 = 1.55773 loss)
I1029 06:01:07.662781 29475 sgd_solver.cpp:105] Iteration 53760, lr = 0.00366879
I1029 06:01:38.903316 29475 solver.cpp:222] Iteration 53800 (1.28044 iter/s, 31.2394s/40 iters), loss = 1.51571
I1029 06:01:38.903513 29475 solver.cpp:241]     Train net output #0: loss = 1.51571 (* 1 = 1.51571 loss)
I1029 06:01:38.903530 29475 sgd_solver.cpp:105] Iteration 53800, lr = 0.00366467
I1029 06:02:11.644670 29475 solver.cpp:222] Iteration 53840 (1.22175 iter/s, 32.7399s/40 iters), loss = 1.78151
I1029 06:02:11.644878 29475 solver.cpp:241]     Train net output #0: loss = 1.78151 (* 1 = 1.78151 loss)
I1029 06:02:11.644897 29475 sgd_solver.cpp:105] Iteration 53840, lr = 0.00366054
I1029 06:02:43.188607 29475 solver.cpp:222] Iteration 53880 (1.26813 iter/s, 31.5425s/40 iters), loss = 1.49976
I1029 06:02:43.188858 29475 solver.cpp:241]     Train net output #0: loss = 1.49976 (* 1 = 1.49976 loss)
I1029 06:02:43.188881 29475 sgd_solver.cpp:105] Iteration 53880, lr = 0.00365642
I1029 06:03:18.770714 29475 solver.cpp:222] Iteration 53920 (1.12421 iter/s, 35.5805s/40 iters), loss = 1.43174
I1029 06:03:18.770913 29475 solver.cpp:241]     Train net output #0: loss = 1.43174 (* 1 = 1.43174 loss)
I1029 06:03:18.770931 29475 sgd_solver.cpp:105] Iteration 53920, lr = 0.0036523
I1029 06:03:50.689750 29475 solver.cpp:222] Iteration 53960 (1.25323 iter/s, 31.9176s/40 iters), loss = 1.7551
I1029 06:03:50.689934 29475 solver.cpp:241]     Train net output #0: loss = 1.7551 (* 1 = 1.7551 loss)
I1029 06:03:50.689954 29475 sgd_solver.cpp:105] Iteration 53960, lr = 0.00364818
I1029 06:04:20.915349 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_54000.caffemodel
I1029 06:04:20.967098 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_54000.solverstate
I1029 06:04:20.989605 29475 solver.cpp:334] Iteration 54000, Testing net (#0)
I1029 06:04:51.958269 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56568
I1029 06:04:51.958461 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.797999
I1029 06:04:51.958477 29475 solver.cpp:401]     Test net output #2: loss = 1.91494 (* 1 = 1.91494 loss)
I1029 06:04:52.734853 29475 solver.cpp:222] Iteration 54000 (0.644718 iter/s, 62.0426s/40 iters), loss = 1.6771
I1029 06:04:52.734927 29475 solver.cpp:241]     Train net output #0: loss = 1.6771 (* 1 = 1.6771 loss)
I1029 06:04:52.734944 29475 sgd_solver.cpp:105] Iteration 54000, lr = 0.00364406
I1029 06:05:23.591972 29475 solver.cpp:222] Iteration 54040 (1.29635 iter/s, 30.8559s/40 iters), loss = 1.88771
I1029 06:05:23.592170 29475 solver.cpp:241]     Train net output #0: loss = 1.88771 (* 1 = 1.88771 loss)
I1029 06:05:23.592186 29475 sgd_solver.cpp:105] Iteration 54040, lr = 0.00363994
I1029 06:05:58.128245 29475 solver.cpp:222] Iteration 54080 (1.15825 iter/s, 34.5347s/40 iters), loss = 1.51147
I1029 06:05:58.128484 29475 solver.cpp:241]     Train net output #0: loss = 1.51147 (* 1 = 1.51147 loss)
I1029 06:05:58.134222 29475 sgd_solver.cpp:105] Iteration 54080, lr = 0.00363582
I1029 06:06:29.278977 29475 solver.cpp:222] Iteration 54120 (1.28414 iter/s, 31.1493s/40 iters), loss = 1.42163
I1029 06:06:29.279183 29475 solver.cpp:241]     Train net output #0: loss = 1.42163 (* 1 = 1.42163 loss)
I1029 06:06:29.279201 29475 sgd_solver.cpp:105] Iteration 54120, lr = 0.0036317
I1029 06:07:00.220602 29475 solver.cpp:222] Iteration 54160 (1.29281 iter/s, 30.9402s/40 iters), loss = 2.01337
I1029 06:07:00.220788 29475 solver.cpp:241]     Train net output #0: loss = 2.01337 (* 1 = 2.01337 loss)
I1029 06:07:00.220808 29475 sgd_solver.cpp:105] Iteration 54160, lr = 0.00362759
I1029 06:07:31.526435 29475 solver.cpp:222] Iteration 54200 (1.27777 iter/s, 31.3045s/40 iters), loss = 1.22675
I1029 06:07:31.526597 29475 solver.cpp:241]     Train net output #0: loss = 1.22675 (* 1 = 1.22675 loss)
I1029 06:07:31.526617 29475 sgd_solver.cpp:105] Iteration 54200, lr = 0.00362347
I1029 06:08:02.545169 29475 solver.cpp:222] Iteration 54240 (1.2896 iter/s, 31.0174s/40 iters), loss = 1.8333
I1029 06:08:02.545413 29475 solver.cpp:241]     Train net output #0: loss = 1.8333 (* 1 = 1.8333 loss)
I1029 06:08:02.545437 29475 sgd_solver.cpp:105] Iteration 54240, lr = 0.00361936
I1029 06:08:33.924345 29475 solver.cpp:222] Iteration 54280 (1.27479 iter/s, 31.3777s/40 iters), loss = 1.57502
I1029 06:08:33.924537 29475 solver.cpp:241]     Train net output #0: loss = 1.57502 (* 1 = 1.57502 loss)
I1029 06:08:33.924554 29475 sgd_solver.cpp:105] Iteration 54280, lr = 0.00361525
I1029 06:09:05.355217 29475 solver.cpp:222] Iteration 54320 (1.27269 iter/s, 31.4295s/40 iters), loss = 1.33519
I1029 06:09:05.355409 29475 solver.cpp:241]     Train net output #0: loss = 1.33519 (* 1 = 1.33519 loss)
I1029 06:09:05.355427 29475 sgd_solver.cpp:105] Iteration 54320, lr = 0.00361114
I1029 06:09:36.642952 29475 solver.cpp:222] Iteration 54360 (1.27851 iter/s, 31.2864s/40 iters), loss = 1.55846
I1029 06:09:36.643126 29475 solver.cpp:241]     Train net output #0: loss = 1.55846 (* 1 = 1.55846 loss)
I1029 06:09:36.643142 29475 sgd_solver.cpp:105] Iteration 54360, lr = 0.00360703
I1029 06:10:07.828773 29475 solver.cpp:222] Iteration 54400 (1.28269 iter/s, 31.1844s/40 iters), loss = 1.65159
I1029 06:10:07.828984 29475 solver.cpp:241]     Train net output #0: loss = 1.65159 (* 1 = 1.65159 loss)
I1029 06:10:07.829005 29475 sgd_solver.cpp:105] Iteration 54400, lr = 0.00360292
I1029 06:10:38.860550 29475 solver.cpp:222] Iteration 54440 (1.28906 iter/s, 31.0304s/40 iters), loss = 1.73106
I1029 06:10:38.860747 29475 solver.cpp:241]     Train net output #0: loss = 1.73106 (* 1 = 1.73106 loss)
I1029 06:10:38.860764 29475 sgd_solver.cpp:105] Iteration 54440, lr = 0.00359881
I1029 06:11:10.064028 29475 solver.cpp:222] Iteration 54480 (1.28197 iter/s, 31.2021s/40 iters), loss = 1.49918
I1029 06:11:10.064273 29475 solver.cpp:241]     Train net output #0: loss = 1.49918 (* 1 = 1.49918 loss)
I1029 06:11:10.064293 29475 sgd_solver.cpp:105] Iteration 54480, lr = 0.0035947
I1029 06:11:24.980123 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_54500.caffemodel
I1029 06:11:25.014248 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_54500.solverstate
I1029 06:11:25.030838 29475 solver.cpp:334] Iteration 54500, Testing net (#0)
I1029 06:11:55.799388 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 06:11:56.007223 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56188
I1029 06:11:56.007290 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79676
I1029 06:11:56.007308 29475 solver.cpp:401]     Test net output #2: loss = 1.93756 (* 1 = 1.93756 loss)
I1029 06:12:12.253851 29475 solver.cpp:222] Iteration 54520 (0.643219 iter/s, 62.1873s/40 iters), loss = 1.33471
I1029 06:12:12.253921 29475 solver.cpp:241]     Train net output #0: loss = 1.33471 (* 1 = 1.33471 loss)
I1029 06:12:12.253937 29475 sgd_solver.cpp:105] Iteration 54520, lr = 0.0035906
I1029 06:12:43.614192 29475 solver.cpp:222] Iteration 54560 (1.27555 iter/s, 31.3591s/40 iters), loss = 1.27401
I1029 06:12:43.614529 29475 solver.cpp:241]     Train net output #0: loss = 1.27401 (* 1 = 1.27401 loss)
I1029 06:12:43.614545 29475 sgd_solver.cpp:105] Iteration 54560, lr = 0.00358649
I1029 06:13:14.602263 29475 solver.cpp:222] Iteration 54600 (1.29089 iter/s, 30.9865s/40 iters), loss = 1.30239
I1029 06:13:14.602464 29475 solver.cpp:241]     Train net output #0: loss = 1.30239 (* 1 = 1.30239 loss)
I1029 06:13:14.602491 29475 sgd_solver.cpp:105] Iteration 54600, lr = 0.00358239
I1029 06:13:45.596107 29475 solver.cpp:222] Iteration 54640 (1.29064 iter/s, 30.9925s/40 iters), loss = 1.38113
I1029 06:13:45.596313 29475 solver.cpp:241]     Train net output #0: loss = 1.38113 (* 1 = 1.38113 loss)
I1029 06:13:45.596331 29475 sgd_solver.cpp:105] Iteration 54640, lr = 0.00357829
I1029 06:14:17.256547 29475 solver.cpp:222] Iteration 54680 (1.26346 iter/s, 31.659s/40 iters), loss = 1.91593
I1029 06:14:17.256839 29475 solver.cpp:241]     Train net output #0: loss = 1.91593 (* 1 = 1.91593 loss)
I1029 06:14:17.256868 29475 sgd_solver.cpp:105] Iteration 54680, lr = 0.00357418
I1029 06:14:48.819664 29475 solver.cpp:222] Iteration 54720 (1.26736 iter/s, 31.5616s/40 iters), loss = 1.42655
I1029 06:14:48.819910 29475 solver.cpp:241]     Train net output #0: loss = 1.42655 (* 1 = 1.42655 loss)
I1029 06:14:48.819933 29475 sgd_solver.cpp:105] Iteration 54720, lr = 0.00357008
I1029 06:15:20.359320 29475 solver.cpp:222] Iteration 54760 (1.2683 iter/s, 31.5382s/40 iters), loss = 1.57258
I1029 06:15:20.359503 29475 solver.cpp:241]     Train net output #0: loss = 1.57258 (* 1 = 1.57258 loss)
I1029 06:15:20.359519 29475 sgd_solver.cpp:105] Iteration 54760, lr = 0.00356598
I1029 06:15:51.339537 29475 solver.cpp:222] Iteration 54800 (1.2912 iter/s, 30.9789s/40 iters), loss = 1.79246
I1029 06:15:51.339731 29475 solver.cpp:241]     Train net output #0: loss = 1.79246 (* 1 = 1.79246 loss)
I1029 06:15:51.339749 29475 sgd_solver.cpp:105] Iteration 54800, lr = 0.00356189
I1029 06:16:22.047446 29475 solver.cpp:222] Iteration 54840 (1.30265 iter/s, 30.7065s/40 iters), loss = 1.57483
I1029 06:16:22.047618 29475 solver.cpp:241]     Train net output #0: loss = 1.57483 (* 1 = 1.57483 loss)
I1029 06:16:22.047636 29475 sgd_solver.cpp:105] Iteration 54840, lr = 0.00355779
I1029 06:16:55.121758 29475 solver.cpp:222] Iteration 54880 (1.20945 iter/s, 33.0729s/40 iters), loss = 1.48043
I1029 06:16:55.121954 29475 solver.cpp:241]     Train net output #0: loss = 1.48043 (* 1 = 1.48043 loss)
I1029 06:16:55.121974 29475 sgd_solver.cpp:105] Iteration 54880, lr = 0.00355369
I1029 06:17:26.041052 29475 solver.cpp:222] Iteration 54920 (1.29375 iter/s, 30.9178s/40 iters), loss = 1.46342
I1029 06:17:26.041276 29475 solver.cpp:241]     Train net output #0: loss = 1.46342 (* 1 = 1.46342 loss)
I1029 06:17:26.041307 29475 sgd_solver.cpp:105] Iteration 54920, lr = 0.0035496
I1029 06:17:57.631031 29475 solver.cpp:222] Iteration 54960 (1.26628 iter/s, 31.5886s/40 iters), loss = 1.52834
I1029 06:17:57.631227 29475 solver.cpp:241]     Train net output #0: loss = 1.52834 (* 1 = 1.52834 loss)
I1029 06:17:57.631244 29475 sgd_solver.cpp:105] Iteration 54960, lr = 0.0035455
I1029 06:18:29.592070 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_55000.caffemodel
I1029 06:18:29.626576 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_55000.solverstate
I1029 06:18:29.643314 29475 solver.cpp:334] Iteration 55000, Testing net (#0)
I1029 06:19:00.826706 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56444
I1029 06:19:00.826853 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79516
I1029 06:19:00.826869 29475 solver.cpp:401]     Test net output #2: loss = 1.93828 (* 1 = 1.93828 loss)
I1029 06:19:01.595235 29475 solver.cpp:222] Iteration 55000 (0.625375 iter/s, 63.9616s/40 iters), loss = 1.58076
I1029 06:19:01.595314 29475 solver.cpp:241]     Train net output #0: loss = 1.58076 (* 1 = 1.58076 loss)
I1029 06:19:01.595331 29475 sgd_solver.cpp:105] Iteration 55000, lr = 0.00354141
I1029 06:19:32.665088 29475 solver.cpp:222] Iteration 55040 (1.28748 iter/s, 31.0685s/40 iters), loss = 1.93581
I1029 06:19:32.665271 29475 solver.cpp:241]     Train net output #0: loss = 1.93581 (* 1 = 1.93581 loss)
I1029 06:19:32.665290 29475 sgd_solver.cpp:105] Iteration 55040, lr = 0.00353732
I1029 06:19:37.423640 29523 data_layer.cpp:73] Restarting data prefetching from start.
I1029 06:20:03.801290 29475 solver.cpp:222] Iteration 55080 (1.28473 iter/s, 31.1348s/40 iters), loss = 1.52217
I1029 06:20:03.801471 29475 solver.cpp:241]     Train net output #0: loss = 1.52217 (* 1 = 1.52217 loss)
I1029 06:20:03.801492 29475 sgd_solver.cpp:105] Iteration 55080, lr = 0.00353323
I1029 06:20:34.874482 29475 solver.cpp:222] Iteration 55120 (1.28734 iter/s, 31.0718s/40 iters), loss = 1.74875
I1029 06:20:34.874680 29475 solver.cpp:241]     Train net output #0: loss = 1.74875 (* 1 = 1.74875 loss)
I1029 06:20:34.874698 29475 sgd_solver.cpp:105] Iteration 55120, lr = 0.00352914
I1029 06:21:06.205029 29475 solver.cpp:222] Iteration 55160 (1.27677 iter/s, 31.3291s/40 iters), loss = 1.15457
I1029 06:21:06.205220 29475 solver.cpp:241]     Train net output #0: loss = 1.15457 (* 1 = 1.15457 loss)
I1029 06:21:06.205240 29475 sgd_solver.cpp:105] Iteration 55160, lr = 0.00352505
I1029 06:21:38.587390 29475 solver.cpp:222] Iteration 55200 (1.2353 iter/s, 32.3809s/40 iters), loss = 1.58349
I1029 06:21:38.587596 29475 solver.cpp:241]     Train net output #0: loss = 1.58349 (* 1 = 1.58349 loss)
I1029 06:21:38.587615 29475 sgd_solver.cpp:105] Iteration 55200, lr = 0.00352096
I1029 06:22:10.188119 29475 solver.cpp:222] Iteration 55240 (1.26586 iter/s, 31.5992s/40 iters), loss = 1.00195
I1029 06:22:10.188395 29475 solver.cpp:241]     Train net output #0: loss = 1.00195 (* 1 = 1.00195 loss)
I1029 06:22:10.188421 29475 sgd_solver.cpp:105] Iteration 55240, lr = 0.00351688
I1029 06:22:41.517784 29475 solver.cpp:222] Iteration 55280 (1.2768 iter/s, 31.3282s/40 iters), loss = 1.4552
I1029 06:22:41.517969 29475 solver.cpp:241]     Train net output #0: loss = 1.4552 (* 1 = 1.4552 loss)
I1029 06:22:41.517985 29475 sgd_solver.cpp:105] Iteration 55280, lr = 0.00351279
I1029 06:23:12.788731 29475 solver.cpp:222] Iteration 55320 (1.2792 iter/s, 31.2696s/40 iters), loss = 1.69435
I1029 06:23:12.788908 29475 solver.cpp:241]     Train net output #0: loss = 1.69435 (* 1 = 1.69435 loss)
I1029 06:23:12.788926 29475 sgd_solver.cpp:105] Iteration 55320, lr = 0.00350871
I1029 06:23:44.071126 29475 solver.cpp:222] Iteration 55360 (1.27873 iter/s, 31.281s/40 iters), loss = 1.71007
I1029 06:23:44.071411 29475 solver.cpp:241]     Train net output #0: loss = 1.71007 (* 1 = 1.71007 loss)
I1029 06:23:44.071446 29475 sgd_solver.cpp:105] Iteration 55360, lr = 0.00350462
I1029 06:24:15.004880 29475 solver.cpp:222] Iteration 55400 (1.29315 iter/s, 30.9323s/40 iters), loss = 1.67212
I1029 06:24:15.005069 29475 solver.cpp:241]     Train net output #0: loss = 1.67212 (* 1 = 1.67212 loss)
I1029 06:24:15.005085 29475 sgd_solver.cpp:105] Iteration 55400, lr = 0.00350054
I1029 06:24:45.839633 29475 solver.cpp:222] Iteration 55440 (1.2973 iter/s, 30.8333s/40 iters), loss = 1.78164
I1029 06:24:45.839802 29475 solver.cpp:241]     Train net output #0: loss = 1.78164 (* 1 = 1.78164 loss)
I1029 06:24:45.839818 29475 sgd_solver.cpp:105] Iteration 55440, lr = 0.00349646
I1029 06:25:16.519093 29475 solver.cpp:222] Iteration 55480 (1.30386 iter/s, 30.6781s/40 iters), loss = 1.48603
I1029 06:25:16.519273 29475 solver.cpp:241]     Train net output #0: loss = 1.48603 (* 1 = 1.48603 loss)
I1029 06:25:16.519290 29475 sgd_solver.cpp:105] Iteration 55480, lr = 0.00349238
I1029 06:25:31.120817 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_55500.caffemodel
I1029 06:25:31.161959 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_55500.solverstate
I1029 06:25:31.184667 29475 solver.cpp:334] Iteration 55500, Testing net (#0)
I1029 06:26:02.057219 29524 data_layer.cpp:73] Restarting data prefetching from start.
I1029 06:26:02.263528 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56108
I1029 06:26:02.263581 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79776
I1029 06:26:02.263593 29475 solver.cpp:401]     Test net output #2: loss = 1.94082 (* 1 = 1.94082 loss)
I1029 06:26:18.444725 29475 solver.cpp:222] Iteration 55520 (0.645962 iter/s, 61.9231s/40 iters), loss = 1.52938
I1029 06:26:18.444803 29475 solver.cpp:241]     Train net output #0: loss = 1.52938 (* 1 = 1.52938 loss)
I1029 06:26:18.444818 29475 sgd_solver.cpp:105] Iteration 55520, lr = 0.0034883
I1029 06:26:49.411239 29475 solver.cpp:222] Iteration 55560 (1.29177 iter/s, 30.9653s/40 iters), loss = 1.56515
I1029 06:26:49.411415 29475 solver.cpp:241]     Train net output #0: loss = 1.56515 (* 1 = 1.56515 loss)
I1029 06:26:49.411432 29475 sgd_solver.cpp:105] Iteration 55560, lr = 0.00348423
I1029 06:27:20.178321 29475 solver.cpp:222] Iteration 55600 (1.30015 iter/s, 30.7656s/40 iters), loss = 1.87075
I1029 06:27:20.178480 29475 solver.cpp:241]     Train net output #0: loss = 1.87075 (* 1 = 1.87075 loss)
I1029 06:27:20.178498 29475 sgd_solver.cpp:105] Iteration 55600, lr = 0.00348015
I1029 06:27:50.705785 29475 solver.cpp:222] Iteration 55640 (1.31035 iter/s, 30.5261s/40 iters), loss = 1.45127
I1029 06:27:50.705953 29475 solver.cpp:241]     Train net output #0: loss = 1.45127 (* 1 = 1.45127 loss)
I1029 06:27:50.705971 29475 sgd_solver.cpp:105] Iteration 55640, lr = 0.00347607
I1029 06:28:21.299392 29475 solver.cpp:222] Iteration 55680 (1.30752 iter/s, 30.5922s/40 iters), loss = 1.40802
I1029 06:28:21.299557 29475 solver.cpp:241]     Train net output #0: loss = 1.40802 (* 1 = 1.40802 loss)
I1029 06:28:21.299576 29475 sgd_solver.cpp:105] Iteration 55680, lr = 0.003472
I1029 06:28:51.840795 29475 solver.cpp:222] Iteration 55720 (1.30976 iter/s, 30.54s/40 iters), loss = 1.55251
I1029 06:28:51.840955 29475 solver.cpp:241]     Train net output #0: loss = 1.55251 (* 1 = 1.55251 loss)
I1029 06:28:51.840971 29475 sgd_solver.cpp:105] Iteration 55720, lr = 0.00346793
I1029 06:29:22.436290 29475 solver.cpp:222] Iteration 55760 (1.30744 iter/s, 30.5942s/40 iters), loss = 1.70954
I1029 06:29:22.436449 29475 solver.cpp:241]     Train net output #0: loss = 1.70954 (* 1 = 1.70954 loss)
I1029 06:29:22.436465 29475 sgd_solver.cpp:105] Iteration 55760, lr = 0.00346385
I1029 06:29:53.063133 29475 solver.cpp:222] Iteration 55800 (1.3061 iter/s, 30.6255s/40 iters), loss = 1.73558
I1029 06:29:53.063395 29475 solver.cpp:241]     Train net output #0: loss = 1.73558 (* 1 = 1.73558 loss)
I1029 06:29:53.063462 29475 sgd_solver.cpp:105] Iteration 55800, lr = 0.00345978
I1029 06:30:23.625005 29475 solver.cpp:222] Iteration 55840 (1.30888 iter/s, 30.5605s/40 iters), loss = 1.56483
I1029 06:30:23.625190 29475 solver.cpp:241]     Train net output #0: loss = 1.56483 (* 1 = 1.56483 loss)
I1029 06:30:23.625206 29475 sgd_solver.cpp:105] Iteration 55840, lr = 0.00345571
I1029 06:30:54.675015 29475 solver.cpp:222] Iteration 55880 (1.2883 iter/s, 31.0486s/40 iters), loss = 1.51793
I1029 06:30:54.675243 29475 solver.cpp:241]     Train net output #0: loss = 1.51793 (* 1 = 1.51793 loss)
I1029 06:30:54.675259 29475 sgd_solver.cpp:105] Iteration 55880, lr = 0.00345165
I1029 06:31:25.831550 29475 solver.cpp:222] Iteration 55920 (1.2839 iter/s, 31.155s/40 iters), loss = 1.62573
I1029 06:31:25.831737 29475 solver.cpp:241]     Train net output #0: loss = 1.62573 (* 1 = 1.62573 loss)
I1029 06:31:25.831754 29475 sgd_solver.cpp:105] Iteration 55920, lr = 0.00344758
I1029 06:31:58.592527 29475 solver.cpp:222] Iteration 55960 (1.22102 iter/s, 32.7596s/40 iters), loss = 1.17849
I1029 06:31:58.592747 29475 solver.cpp:241]     Train net output #0: loss = 1.17849 (* 1 = 1.17849 loss)
I1029 06:31:58.592767 29475 sgd_solver.cpp:105] Iteration 55960, lr = 0.00344351
I1029 06:32:35.950788 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_56000.caffemodel
I1029 06:32:35.985417 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_56000.solverstate
I1029 06:32:36.002229 29475 solver.cpp:334] Iteration 56000, Testing net (#0)
I1029 06:33:07.155396 29475 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56628
I1029 06:33:07.155561 29475 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79764
I1029 06:33:07.155576 29475 solver.cpp:401]     Test net output #2: loss = 1.93156 (* 1 = 1.93156 loss)
I1029 06:33:07.923118 29475 solver.cpp:222] Iteration 56000 (0.576969 iter/s, 69.3278s/40 iters), loss = 2.06378
I1029 06:33:07.923188 29475 solver.cpp:241]     Train net output #0: loss = 2.06378 (* 1 = 2.06378 loss)
I1029 06:33:07.923207 29475 sgd_solver.cpp:105] Iteration 56000, lr = 0.00343945
I1029 06:33:38.800247 29475 solver.cpp:222] Iteration 56040 (1.29551 iter/s, 30.8759s/40 iters), loss = 1.71539
I1029 06:33:38.800449 29475 solver.cpp:241]     Train net output #0: loss = 1.71539 (* 1 = 1.71539 loss)
I1029 06:33:38.800467 29475 sgd_solver.cpp:105] Iteration 56040, lr = 0.00343538
I1029 06:34:10.135606 29475 solver.cpp:222] Iteration 56080 (1.27657 iter/s, 31.334s/40 iters), loss = 1.52164
I1029 06:34:10.135808 29475 solver.cpp:241]     Train net output #0: loss = 1.52164 (* 1 = 1.52164 loss)
I1029 06:34:10.135825 29475 sgd_solver.cpp:105] Iteration 56080, lr = 0.00343132
I1029 06:34:40.980608 29475 solver.cpp:222] Iteration 56120 (1.29686 iter/s, 30.8436s/40 iters), loss = 1.62351
I1029 06:34:40.980803 29475 solver.cpp:241]     Train net output #0: loss = 1.62351 (* 1 = 1.62351 loss)
I1029 06:34:40.980819 29475 sgd_solver.cpp:105] Iteration 56120, lr = 0.00342726
I1029 06:35:12.617542 29475 solver.cpp:222] Iteration 56160 (1.2644 iter/s, 31.6355s/40 iters), loss = 1.54787
I1029 06:35:12.617764 29475 solver.cpp:241]     Train net output #0: loss = 1.54787 (* 1 = 1.54787 loss)
I1029 06:35:12.617789 29475 sgd_solver.cpp:105] Iteration 56160, lr = 0.0034232
I1029 06:36:19.047699 29475 solver.cpp:222] Iteration 56200 (0.602161 iter/s, 66.4275s/40 iters), loss = 1.76074
I1029 06:36:19.047897 29475 solver.cpp:241]     Train net output #0: loss = 1.76074 (* 1 = 1.76074 loss)
I1029 06:36:19.047914 29475 sgd_solver.cpp:105] Iteration 56200, lr = 0.00341914
I1029 06:36:47.500424 29475 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_56238.caffemodel
I1029 06:36:47.536077 29475 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_40_iter_56238.solverstate
I1029 06:36:47.555580 29475 solver.cpp:298] Optimization stopped early.
*** Aborted at 1509273436 (unix time) try "date -d @1509273436" if you are using GNU date ***
PC: @     0x7fe553c21705 __pthread_cond_wait
*** SIGTERM (@0x3ed000072cf) received by PID 29475 (TID 0x7fe566ca0740) from PID 29391; stack trace: ***
    @     0x7fe553c25130 (unknown)
    @     0x7fe553c21705 __pthread_cond_wait
    @     0x7fe565f7b804 boost::condition_variable::wait()
    @     0x7fe55c4eb8d4 boost::thread::join_noexcept()
    @     0x7fe565f66b8a caffe::InternalThread::StopInternalThread()
    @     0x7fe565f7f302 caffe::NCCL<>::Run()
    @           0x40adef train()
    @           0x4082ec main
    @     0x7fe553876af5 __libc_start_main
    @           0x408bf5 (unknown)
