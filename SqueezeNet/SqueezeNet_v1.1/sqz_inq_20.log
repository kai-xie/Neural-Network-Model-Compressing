nohup: ignoring input
I1026 15:43:28.201793 37958 caffe.cpp:218] Using GPUs 0, 1, 2, 3
I1026 15:43:28.202627 37958 caffe.cpp:223] GPU 0: Tesla P40
I1026 15:43:28.203040 37958 caffe.cpp:223] GPU 1: Tesla P40
I1026 15:43:28.203433 37958 caffe.cpp:223] GPU 2: Tesla P40
I1026 15:43:28.203817 37958 caffe.cpp:223] GPU 3: Tesla P40
I1026 15:43:28.839128 37958 solver.cpp:44] Initializing solver from parameters: 
test_iter: 500
test_interval: 500
base_lr: 0.01
display: 40
max_iter: 170000
lr_policy: "poly"
power: 1
momentum: 0.9
weight_decay: 0.0002
snapshot: 500
snapshot_prefix: "SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20"
solver_mode: GPU
device_id: 0
random_seed: 42
net: "SqueezeNet/SqueezeNet_v1.1/train_val_inq_20.prototxt"
train_state {
  level: 0
  stage: ""
}
I1026 15:43:28.839519 37958 solver.cpp:87] Creating training net from net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_20.prototxt
I1026 15:43:28.841346 37958 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1026 15:43:28.841410 37958 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top1
I1026 15:43:28.841420 37958 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top5
I1026 15:43:28.842113 37958 net.cpp:51] Initializing net from parameters: 
name: "SqueezeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/data/caffe-imagenet/ilsvrc12_train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "INQConvolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "fire3/concat"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire4/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool3"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "fire5/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire4/concat"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "fire5/concat"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire6/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool5"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "fire9/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire8/concat"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "INQConvolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "pool10"
  bottom: "label"
  top: "loss"
}
I1026 15:43:28.842542 37958 layer_factory.hpp:77] Creating layer data
I1026 15:43:28.842742 37958 db_lmdb.cpp:35] Opened lmdb /home/data/caffe-imagenet/ilsvrc12_train_lmdb
I1026 15:43:28.842792 37958 net.cpp:84] Creating Layer data
I1026 15:43:28.842805 37958 net.cpp:387] data -> data
I1026 15:43:28.842834 37958 net.cpp:387] data -> label
I1026 15:43:28.844622 37958 data_layer.cpp:45] output data size: 128,3,227,227
I1026 15:43:29.048271 37958 net.cpp:127] Setting up data
I1026 15:43:29.048329 37958 net.cpp:136] Top shape: 128 3 227 227 (19787136)
I1026 15:43:29.048341 37958 net.cpp:136] Top shape: 128 (128)
I1026 15:43:29.048346 37958 net.cpp:144] Memory required for data: 79149056
I1026 15:43:29.048359 37958 layer_factory.hpp:77] Creating layer conv1
I1026 15:43:29.048389 37958 net.cpp:84] Creating Layer conv1
I1026 15:43:29.048413 37958 net.cpp:413] conv1 <- data
I1026 15:43:29.048435 37958 net.cpp:387] conv1 -> conv1
I1026 15:43:29.051635 37958 net.cpp:127] Setting up conv1
I1026 15:43:29.051656 37958 net.cpp:136] Top shape: 128 64 113 113 (104603648)
I1026 15:43:29.051662 37958 net.cpp:144] Memory required for data: 497563648
I1026 15:43:29.051681 37958 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1026 15:43:29.051695 37958 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1026 15:43:29.051707 37958 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1026 15:43:29.051715 37958 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1026 15:43:29.051722 37958 layer_factory.hpp:77] Creating layer relu_conv1
I1026 15:43:29.051738 37958 net.cpp:84] Creating Layer relu_conv1
I1026 15:43:29.051745 37958 net.cpp:413] relu_conv1 <- conv1
I1026 15:43:29.051753 37958 net.cpp:374] relu_conv1 -> conv1 (in-place)
I1026 15:43:29.418511 37958 net.cpp:127] Setting up relu_conv1
I1026 15:43:29.418560 37958 net.cpp:136] Top shape: 128 64 113 113 (104603648)
I1026 15:43:29.418567 37958 net.cpp:144] Memory required for data: 915978240
I1026 15:43:29.418576 37958 layer_factory.hpp:77] Creating layer pool1
I1026 15:43:29.418593 37958 net.cpp:84] Creating Layer pool1
I1026 15:43:29.418599 37958 net.cpp:413] pool1 <- conv1
I1026 15:43:29.418612 37958 net.cpp:387] pool1 -> pool1
I1026 15:43:29.418695 37958 net.cpp:127] Setting up pool1
I1026 15:43:29.418720 37958 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1026 15:43:29.418756 37958 net.cpp:144] Memory required for data: 1018738688
I1026 15:43:29.418763 37958 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I1026 15:43:29.418781 37958 net.cpp:84] Creating Layer fire2/squeeze1x1
I1026 15:43:29.418789 37958 net.cpp:413] fire2/squeeze1x1 <- pool1
I1026 15:43:29.418797 37958 net.cpp:387] fire2/squeeze1x1 -> fire2/squeeze1x1
I1026 15:43:29.420557 37958 net.cpp:127] Setting up fire2/squeeze1x1
I1026 15:43:29.420577 37958 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1026 15:43:29.420583 37958 net.cpp:144] Memory required for data: 1044428800
I1026 15:43:29.420593 37958 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1026 15:43:29.420603 37958 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1026 15:43:29.420610 37958 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1026 15:43:29.420617 37958 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1026 15:43:29.420625 37958 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I1026 15:43:29.420635 37958 net.cpp:84] Creating Layer fire2/relu_squeeze1x1
I1026 15:43:29.420640 37958 net.cpp:413] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I1026 15:43:29.420648 37958 net.cpp:374] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I1026 15:43:29.421972 37958 net.cpp:127] Setting up fire2/relu_squeeze1x1
I1026 15:43:29.421991 37958 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1026 15:43:29.421998 37958 net.cpp:144] Memory required for data: 1070118912
I1026 15:43:29.422003 37958 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1026 15:43:29.422014 37958 net.cpp:84] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1026 15:43:29.422019 37958 net.cpp:413] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I1026 15:43:29.422029 37958 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1026 15:43:29.422039 37958 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1026 15:43:29.422091 37958 net.cpp:127] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1026 15:43:29.422099 37958 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1026 15:43:29.422106 37958 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1026 15:43:29.422112 37958 net.cpp:144] Memory required for data: 1121499136
I1026 15:43:29.422117 37958 layer_factory.hpp:77] Creating layer fire2/expand1x1
I1026 15:43:29.422129 37958 net.cpp:84] Creating Layer fire2/expand1x1
I1026 15:43:29.422137 37958 net.cpp:413] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1026 15:43:29.422145 37958 net.cpp:387] fire2/expand1x1 -> fire2/expand1x1
I1026 15:43:29.422463 37958 net.cpp:127] Setting up fire2/expand1x1
I1026 15:43:29.422477 37958 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1026 15:43:29.422482 37958 net.cpp:144] Memory required for data: 1224259584
I1026 15:43:29.422493 37958 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1026 15:43:29.422503 37958 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1026 15:43:29.422510 37958 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1026 15:43:29.422518 37958 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1026 15:43:29.422526 37958 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I1026 15:43:29.422535 37958 net.cpp:84] Creating Layer fire2/relu_expand1x1
I1026 15:43:29.422541 37958 net.cpp:413] fire2/relu_expand1x1 <- fire2/expand1x1
I1026 15:43:29.422547 37958 net.cpp:374] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I1026 15:43:29.422734 37958 net.cpp:127] Setting up fire2/relu_expand1x1
I1026 15:43:29.422745 37958 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1026 15:43:29.422760 37958 net.cpp:144] Memory required for data: 1327020032
I1026 15:43:29.422768 37958 layer_factory.hpp:77] Creating layer fire2/expand3x3
I1026 15:43:29.422793 37958 net.cpp:84] Creating Layer fire2/expand3x3
I1026 15:43:29.422799 37958 net.cpp:413] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1026 15:43:29.422807 37958 net.cpp:387] fire2/expand3x3 -> fire2/expand3x3
I1026 15:43:29.423207 37958 net.cpp:127] Setting up fire2/expand3x3
I1026 15:43:29.423219 37958 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1026 15:43:29.423224 37958 net.cpp:144] Memory required for data: 1429780480
I1026 15:43:29.423231 37958 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1026 15:43:29.423238 37958 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1026 15:43:29.423243 37958 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1026 15:43:29.423249 37958 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1026 15:43:29.423254 37958 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I1026 15:43:29.423264 37958 net.cpp:84] Creating Layer fire2/relu_expand3x3
I1026 15:43:29.423271 37958 net.cpp:413] fire2/relu_expand3x3 <- fire2/expand3x3
I1026 15:43:29.423279 37958 net.cpp:374] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I1026 15:43:29.423497 37958 net.cpp:127] Setting up fire2/relu_expand3x3
I1026 15:43:29.423511 37958 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1026 15:43:29.423516 37958 net.cpp:144] Memory required for data: 1532540928
I1026 15:43:29.423522 37958 layer_factory.hpp:77] Creating layer fire2/concat
I1026 15:43:29.423533 37958 net.cpp:84] Creating Layer fire2/concat
I1026 15:43:29.423540 37958 net.cpp:413] fire2/concat <- fire2/expand1x1
I1026 15:43:29.423547 37958 net.cpp:413] fire2/concat <- fire2/expand3x3
I1026 15:43:29.423557 37958 net.cpp:387] fire2/concat -> fire2/concat
I1026 15:43:29.423588 37958 net.cpp:127] Setting up fire2/concat
I1026 15:43:29.423597 37958 net.cpp:136] Top shape: 128 128 56 56 (51380224)
I1026 15:43:29.423602 37958 net.cpp:144] Memory required for data: 1738061824
I1026 15:43:29.423607 37958 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I1026 15:43:29.423624 37958 net.cpp:84] Creating Layer fire3/squeeze1x1
I1026 15:43:29.423629 37958 net.cpp:413] fire3/squeeze1x1 <- fire2/concat
I1026 15:43:29.423637 37958 net.cpp:387] fire3/squeeze1x1 -> fire3/squeeze1x1
I1026 15:43:29.423976 37958 net.cpp:127] Setting up fire3/squeeze1x1
I1026 15:43:29.423987 37958 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1026 15:43:29.423992 37958 net.cpp:144] Memory required for data: 1763751936
I1026 15:43:29.424001 37958 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1026 15:43:29.424011 37958 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1026 15:43:29.424017 37958 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1026 15:43:29.424023 37958 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1026 15:43:29.424029 37958 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I1026 15:43:29.424037 37958 net.cpp:84] Creating Layer fire3/relu_squeeze1x1
I1026 15:43:29.424042 37958 net.cpp:413] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I1026 15:43:29.424051 37958 net.cpp:374] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I1026 15:43:29.425392 37958 net.cpp:127] Setting up fire3/relu_squeeze1x1
I1026 15:43:29.425410 37958 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1026 15:43:29.425416 37958 net.cpp:144] Memory required for data: 1789442048
I1026 15:43:29.425422 37958 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1026 15:43:29.425431 37958 net.cpp:84] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1026 15:43:29.425436 37958 net.cpp:413] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I1026 15:43:29.425444 37958 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1026 15:43:29.425473 37958 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1026 15:43:29.425523 37958 net.cpp:127] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1026 15:43:29.425534 37958 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1026 15:43:29.425539 37958 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1026 15:43:29.425544 37958 net.cpp:144] Memory required for data: 1840822272
I1026 15:43:29.425549 37958 layer_factory.hpp:77] Creating layer fire3/expand1x1
I1026 15:43:29.425565 37958 net.cpp:84] Creating Layer fire3/expand1x1
I1026 15:43:29.425573 37958 net.cpp:413] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1026 15:43:29.425580 37958 net.cpp:387] fire3/expand1x1 -> fire3/expand1x1
I1026 15:43:29.425900 37958 net.cpp:127] Setting up fire3/expand1x1
I1026 15:43:29.425911 37958 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1026 15:43:29.425916 37958 net.cpp:144] Memory required for data: 1943582720
I1026 15:43:29.425923 37958 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1026 15:43:29.425930 37958 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1026 15:43:29.425935 37958 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1026 15:43:29.425940 37958 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1026 15:43:29.425946 37958 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I1026 15:43:29.425957 37958 net.cpp:84] Creating Layer fire3/relu_expand1x1
I1026 15:43:29.425966 37958 net.cpp:413] fire3/relu_expand1x1 <- fire3/expand1x1
I1026 15:43:29.425972 37958 net.cpp:374] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I1026 15:43:29.426182 37958 net.cpp:127] Setting up fire3/relu_expand1x1
I1026 15:43:29.426193 37958 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1026 15:43:29.426198 37958 net.cpp:144] Memory required for data: 2046343168
I1026 15:43:29.426204 37958 layer_factory.hpp:77] Creating layer fire3/expand3x3
I1026 15:43:29.426218 37958 net.cpp:84] Creating Layer fire3/expand3x3
I1026 15:43:29.426226 37958 net.cpp:413] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1026 15:43:29.426234 37958 net.cpp:387] fire3/expand3x3 -> fire3/expand3x3
I1026 15:43:29.426643 37958 net.cpp:127] Setting up fire3/expand3x3
I1026 15:43:29.426656 37958 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1026 15:43:29.426661 37958 net.cpp:144] Memory required for data: 2149103616
I1026 15:43:29.426672 37958 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1026 15:43:29.426681 37958 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1026 15:43:29.426687 37958 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1026 15:43:29.426693 37958 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1026 15:43:29.426699 37958 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I1026 15:43:29.426708 37958 net.cpp:84] Creating Layer fire3/relu_expand3x3
I1026 15:43:29.426715 37958 net.cpp:413] fire3/relu_expand3x3 <- fire3/expand3x3
I1026 15:43:29.426724 37958 net.cpp:374] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I1026 15:43:29.426929 37958 net.cpp:127] Setting up fire3/relu_expand3x3
I1026 15:43:29.426941 37958 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1026 15:43:29.426946 37958 net.cpp:144] Memory required for data: 2251864064
I1026 15:43:29.426952 37958 layer_factory.hpp:77] Creating layer fire3/concat
I1026 15:43:29.426962 37958 net.cpp:84] Creating Layer fire3/concat
I1026 15:43:29.426970 37958 net.cpp:413] fire3/concat <- fire3/expand1x1
I1026 15:43:29.426976 37958 net.cpp:413] fire3/concat <- fire3/expand3x3
I1026 15:43:29.426985 37958 net.cpp:387] fire3/concat -> fire3/concat
I1026 15:43:29.427017 37958 net.cpp:127] Setting up fire3/concat
I1026 15:43:29.427032 37958 net.cpp:136] Top shape: 128 128 56 56 (51380224)
I1026 15:43:29.427047 37958 net.cpp:144] Memory required for data: 2457384960
I1026 15:43:29.427052 37958 layer_factory.hpp:77] Creating layer pool3
I1026 15:43:29.427060 37958 net.cpp:84] Creating Layer pool3
I1026 15:43:29.427065 37958 net.cpp:413] pool3 <- fire3/concat
I1026 15:43:29.427074 37958 net.cpp:387] pool3 -> pool3
I1026 15:43:29.427121 37958 net.cpp:127] Setting up pool3
I1026 15:43:29.427131 37958 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1026 15:43:29.427139 37958 net.cpp:144] Memory required for data: 2508765184
I1026 15:43:29.427145 37958 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I1026 15:43:29.427168 37958 net.cpp:84] Creating Layer fire4/squeeze1x1
I1026 15:43:29.427176 37958 net.cpp:413] fire4/squeeze1x1 <- pool3
I1026 15:43:29.427184 37958 net.cpp:387] fire4/squeeze1x1 -> fire4/squeeze1x1
I1026 15:43:29.427544 37958 net.cpp:127] Setting up fire4/squeeze1x1
I1026 15:43:29.427556 37958 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1026 15:43:29.427561 37958 net.cpp:144] Memory required for data: 2521610240
I1026 15:43:29.427568 37958 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1026 15:43:29.427575 37958 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1026 15:43:29.427580 37958 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1026 15:43:29.427587 37958 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1026 15:43:29.427593 37958 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I1026 15:43:29.427604 37958 net.cpp:84] Creating Layer fire4/relu_squeeze1x1
I1026 15:43:29.427610 37958 net.cpp:413] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I1026 15:43:29.427618 37958 net.cpp:374] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I1026 15:43:29.427829 37958 net.cpp:127] Setting up fire4/relu_squeeze1x1
I1026 15:43:29.427844 37958 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1026 15:43:29.427850 37958 net.cpp:144] Memory required for data: 2534455296
I1026 15:43:29.427856 37958 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1026 15:43:29.427865 37958 net.cpp:84] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1026 15:43:29.427870 37958 net.cpp:413] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I1026 15:43:29.427878 37958 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1026 15:43:29.427889 37958 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1026 15:43:29.427938 37958 net.cpp:127] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1026 15:43:29.427947 37958 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1026 15:43:29.427954 37958 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1026 15:43:29.427959 37958 net.cpp:144] Memory required for data: 2560145408
I1026 15:43:29.427965 37958 layer_factory.hpp:77] Creating layer fire4/expand1x1
I1026 15:43:29.427979 37958 net.cpp:84] Creating Layer fire4/expand1x1
I1026 15:43:29.427984 37958 net.cpp:413] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1026 15:43:29.427994 37958 net.cpp:387] fire4/expand1x1 -> fire4/expand1x1
I1026 15:43:29.428338 37958 net.cpp:127] Setting up fire4/expand1x1
I1026 15:43:29.428349 37958 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1026 15:43:29.428354 37958 net.cpp:144] Memory required for data: 2611525632
I1026 15:43:29.428367 37958 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1026 15:43:29.428376 37958 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1026 15:43:29.428382 37958 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1026 15:43:29.428388 37958 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1026 15:43:29.428393 37958 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I1026 15:43:29.428411 37958 net.cpp:84] Creating Layer fire4/relu_expand1x1
I1026 15:43:29.428428 37958 net.cpp:413] fire4/relu_expand1x1 <- fire4/expand1x1
I1026 15:43:29.428437 37958 net.cpp:374] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I1026 15:43:29.429786 37958 net.cpp:127] Setting up fire4/relu_expand1x1
I1026 15:43:29.429805 37958 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1026 15:43:29.429811 37958 net.cpp:144] Memory required for data: 2662905856
I1026 15:43:29.429816 37958 layer_factory.hpp:77] Creating layer fire4/expand3x3
I1026 15:43:29.429831 37958 net.cpp:84] Creating Layer fire4/expand3x3
I1026 15:43:29.429837 37958 net.cpp:413] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1026 15:43:29.429850 37958 net.cpp:387] fire4/expand3x3 -> fire4/expand3x3
I1026 15:43:29.431815 37958 net.cpp:127] Setting up fire4/expand3x3
I1026 15:43:29.431834 37958 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1026 15:43:29.431840 37958 net.cpp:144] Memory required for data: 2714286080
I1026 15:43:29.431848 37958 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1026 15:43:29.431854 37958 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1026 15:43:29.431859 37958 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1026 15:43:29.431864 37958 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1026 15:43:29.431869 37958 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I1026 15:43:29.431879 37958 net.cpp:84] Creating Layer fire4/relu_expand3x3
I1026 15:43:29.431885 37958 net.cpp:413] fire4/relu_expand3x3 <- fire4/expand3x3
I1026 15:43:29.431892 37958 net.cpp:374] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I1026 15:43:29.432109 37958 net.cpp:127] Setting up fire4/relu_expand3x3
I1026 15:43:29.432121 37958 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1026 15:43:29.432127 37958 net.cpp:144] Memory required for data: 2765666304
I1026 15:43:29.432134 37958 layer_factory.hpp:77] Creating layer fire4/concat
I1026 15:43:29.432144 37958 net.cpp:84] Creating Layer fire4/concat
I1026 15:43:29.432149 37958 net.cpp:413] fire4/concat <- fire4/expand1x1
I1026 15:43:29.432155 37958 net.cpp:413] fire4/concat <- fire4/expand3x3
I1026 15:43:29.432163 37958 net.cpp:387] fire4/concat -> fire4/concat
I1026 15:43:29.432194 37958 net.cpp:127] Setting up fire4/concat
I1026 15:43:29.432204 37958 net.cpp:136] Top shape: 128 256 28 28 (25690112)
I1026 15:43:29.432209 37958 net.cpp:144] Memory required for data: 2868426752
I1026 15:43:29.432214 37958 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I1026 15:43:29.432227 37958 net.cpp:84] Creating Layer fire5/squeeze1x1
I1026 15:43:29.432235 37958 net.cpp:413] fire5/squeeze1x1 <- fire4/concat
I1026 15:43:29.432242 37958 net.cpp:387] fire5/squeeze1x1 -> fire5/squeeze1x1
I1026 15:43:29.432639 37958 net.cpp:127] Setting up fire5/squeeze1x1
I1026 15:43:29.432651 37958 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1026 15:43:29.432657 37958 net.cpp:144] Memory required for data: 2881271808
I1026 15:43:29.432663 37958 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1026 15:43:29.432669 37958 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1026 15:43:29.432675 37958 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1026 15:43:29.432680 37958 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1026 15:43:29.432687 37958 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I1026 15:43:29.432695 37958 net.cpp:84] Creating Layer fire5/relu_squeeze1x1
I1026 15:43:29.432704 37958 net.cpp:413] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I1026 15:43:29.432714 37958 net.cpp:374] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I1026 15:43:29.432947 37958 net.cpp:127] Setting up fire5/relu_squeeze1x1
I1026 15:43:29.432960 37958 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1026 15:43:29.432978 37958 net.cpp:144] Memory required for data: 2894116864
I1026 15:43:29.432998 37958 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1026 15:43:29.433012 37958 net.cpp:84] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1026 15:43:29.433018 37958 net.cpp:413] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I1026 15:43:29.433027 37958 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1026 15:43:29.433035 37958 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1026 15:43:29.433087 37958 net.cpp:127] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1026 15:43:29.433097 37958 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1026 15:43:29.433104 37958 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1026 15:43:29.433110 37958 net.cpp:144] Memory required for data: 2919806976
I1026 15:43:29.433115 37958 layer_factory.hpp:77] Creating layer fire5/expand1x1
I1026 15:43:29.433130 37958 net.cpp:84] Creating Layer fire5/expand1x1
I1026 15:43:29.433138 37958 net.cpp:413] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1026 15:43:29.433148 37958 net.cpp:387] fire5/expand1x1 -> fire5/expand1x1
I1026 15:43:29.433507 37958 net.cpp:127] Setting up fire5/expand1x1
I1026 15:43:29.433521 37958 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1026 15:43:29.433526 37958 net.cpp:144] Memory required for data: 2971187200
I1026 15:43:29.433532 37958 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1026 15:43:29.433539 37958 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1026 15:43:29.433544 37958 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1026 15:43:29.433549 37958 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1026 15:43:29.433554 37958 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I1026 15:43:29.433563 37958 net.cpp:84] Creating Layer fire5/relu_expand1x1
I1026 15:43:29.433568 37958 net.cpp:413] fire5/relu_expand1x1 <- fire5/expand1x1
I1026 15:43:29.433578 37958 net.cpp:374] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I1026 15:43:29.433794 37958 net.cpp:127] Setting up fire5/relu_expand1x1
I1026 15:43:29.433806 37958 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1026 15:43:29.433814 37958 net.cpp:144] Memory required for data: 3022567424
I1026 15:43:29.433820 37958 layer_factory.hpp:77] Creating layer fire5/expand3x3
I1026 15:43:29.433832 37958 net.cpp:84] Creating Layer fire5/expand3x3
I1026 15:43:29.433840 37958 net.cpp:413] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1026 15:43:29.433851 37958 net.cpp:387] fire5/expand3x3 -> fire5/expand3x3
I1026 15:43:29.434473 37958 net.cpp:127] Setting up fire5/expand3x3
I1026 15:43:29.434485 37958 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1026 15:43:29.434490 37958 net.cpp:144] Memory required for data: 3073947648
I1026 15:43:29.434496 37958 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1026 15:43:29.434502 37958 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1026 15:43:29.434509 37958 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1026 15:43:29.434514 37958 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1026 15:43:29.434520 37958 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I1026 15:43:29.434531 37958 net.cpp:84] Creating Layer fire5/relu_expand3x3
I1026 15:43:29.434537 37958 net.cpp:413] fire5/relu_expand3x3 <- fire5/expand3x3
I1026 15:43:29.434545 37958 net.cpp:374] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I1026 15:43:29.437345 37958 net.cpp:127] Setting up fire5/relu_expand3x3
I1026 15:43:29.437366 37958 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1026 15:43:29.437371 37958 net.cpp:144] Memory required for data: 3125327872
I1026 15:43:29.437381 37958 layer_factory.hpp:77] Creating layer fire5/concat
I1026 15:43:29.437404 37958 net.cpp:84] Creating Layer fire5/concat
I1026 15:43:29.437412 37958 net.cpp:413] fire5/concat <- fire5/expand1x1
I1026 15:43:29.437422 37958 net.cpp:413] fire5/concat <- fire5/expand3x3
I1026 15:43:29.437428 37958 net.cpp:387] fire5/concat -> fire5/concat
I1026 15:43:29.437465 37958 net.cpp:127] Setting up fire5/concat
I1026 15:43:29.437474 37958 net.cpp:136] Top shape: 128 256 28 28 (25690112)
I1026 15:43:29.437479 37958 net.cpp:144] Memory required for data: 3228088320
I1026 15:43:29.437485 37958 layer_factory.hpp:77] Creating layer pool5
I1026 15:43:29.437497 37958 net.cpp:84] Creating Layer pool5
I1026 15:43:29.437503 37958 net.cpp:413] pool5 <- fire5/concat
I1026 15:43:29.437510 37958 net.cpp:387] pool5 -> pool5
I1026 15:43:29.437554 37958 net.cpp:127] Setting up pool5
I1026 15:43:29.437563 37958 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1026 15:43:29.437569 37958 net.cpp:144] Memory required for data: 3253778432
I1026 15:43:29.437574 37958 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I1026 15:43:29.437588 37958 net.cpp:84] Creating Layer fire6/squeeze1x1
I1026 15:43:29.437594 37958 net.cpp:413] fire6/squeeze1x1 <- pool5
I1026 15:43:29.437603 37958 net.cpp:387] fire6/squeeze1x1 -> fire6/squeeze1x1
I1026 15:43:29.438036 37958 net.cpp:127] Setting up fire6/squeeze1x1
I1026 15:43:29.438050 37958 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1026 15:43:29.438055 37958 net.cpp:144] Memory required for data: 3258595328
I1026 15:43:29.438061 37958 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1026 15:43:29.438067 37958 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1026 15:43:29.438073 37958 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1026 15:43:29.438078 37958 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1026 15:43:29.438084 37958 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I1026 15:43:29.438092 37958 net.cpp:84] Creating Layer fire6/relu_squeeze1x1
I1026 15:43:29.438097 37958 net.cpp:413] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I1026 15:43:29.438103 37958 net.cpp:374] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I1026 15:43:29.438321 37958 net.cpp:127] Setting up fire6/relu_squeeze1x1
I1026 15:43:29.438338 37958 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1026 15:43:29.438345 37958 net.cpp:144] Memory required for data: 3263412224
I1026 15:43:29.438352 37958 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1026 15:43:29.438360 37958 net.cpp:84] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1026 15:43:29.438366 37958 net.cpp:413] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I1026 15:43:29.438374 37958 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1026 15:43:29.438383 37958 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1026 15:43:29.438444 37958 net.cpp:127] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1026 15:43:29.438454 37958 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1026 15:43:29.438462 37958 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1026 15:43:29.438465 37958 net.cpp:144] Memory required for data: 3273046016
I1026 15:43:29.438470 37958 layer_factory.hpp:77] Creating layer fire6/expand1x1
I1026 15:43:29.438484 37958 net.cpp:84] Creating Layer fire6/expand1x1
I1026 15:43:29.438491 37958 net.cpp:413] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1026 15:43:29.438498 37958 net.cpp:387] fire6/expand1x1 -> fire6/expand1x1
I1026 15:43:29.438896 37958 net.cpp:127] Setting up fire6/expand1x1
I1026 15:43:29.438907 37958 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1026 15:43:29.438912 37958 net.cpp:144] Memory required for data: 3292313600
I1026 15:43:29.438925 37958 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1026 15:43:29.438942 37958 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1026 15:43:29.438951 37958 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1026 15:43:29.438957 37958 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1026 15:43:29.438962 37958 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I1026 15:43:29.438971 37958 net.cpp:84] Creating Layer fire6/relu_expand1x1
I1026 15:43:29.438976 37958 net.cpp:413] fire6/relu_expand1x1 <- fire6/expand1x1
I1026 15:43:29.438987 37958 net.cpp:374] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I1026 15:43:29.439196 37958 net.cpp:127] Setting up fire6/relu_expand1x1
I1026 15:43:29.439208 37958 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1026 15:43:29.439213 37958 net.cpp:144] Memory required for data: 3311581184
I1026 15:43:29.439219 37958 layer_factory.hpp:77] Creating layer fire6/expand3x3
I1026 15:43:29.439231 37958 net.cpp:84] Creating Layer fire6/expand3x3
I1026 15:43:29.439237 37958 net.cpp:413] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1026 15:43:29.439249 37958 net.cpp:387] fire6/expand3x3 -> fire6/expand3x3
I1026 15:43:29.447301 37958 net.cpp:127] Setting up fire6/expand3x3
I1026 15:43:29.447325 37958 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1026 15:43:29.447331 37958 net.cpp:144] Memory required for data: 3330848768
I1026 15:43:29.447338 37958 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1026 15:43:29.447345 37958 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1026 15:43:29.447351 37958 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1026 15:43:29.447356 37958 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1026 15:43:29.447361 37958 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I1026 15:43:29.447373 37958 net.cpp:84] Creating Layer fire6/relu_expand3x3
I1026 15:43:29.447381 37958 net.cpp:413] fire6/relu_expand3x3 <- fire6/expand3x3
I1026 15:43:29.447388 37958 net.cpp:374] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I1026 15:43:29.447618 37958 net.cpp:127] Setting up fire6/relu_expand3x3
I1026 15:43:29.447633 37958 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1026 15:43:29.447638 37958 net.cpp:144] Memory required for data: 3350116352
I1026 15:43:29.447644 37958 layer_factory.hpp:77] Creating layer fire6/concat
I1026 15:43:29.447654 37958 net.cpp:84] Creating Layer fire6/concat
I1026 15:43:29.447659 37958 net.cpp:413] fire6/concat <- fire6/expand1x1
I1026 15:43:29.447667 37958 net.cpp:413] fire6/concat <- fire6/expand3x3
I1026 15:43:29.447677 37958 net.cpp:387] fire6/concat -> fire6/concat
I1026 15:43:29.447720 37958 net.cpp:127] Setting up fire6/concat
I1026 15:43:29.447727 37958 net.cpp:136] Top shape: 128 384 14 14 (9633792)
I1026 15:43:29.447732 37958 net.cpp:144] Memory required for data: 3388651520
I1026 15:43:29.447737 37958 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I1026 15:43:29.447749 37958 net.cpp:84] Creating Layer fire7/squeeze1x1
I1026 15:43:29.447754 37958 net.cpp:413] fire7/squeeze1x1 <- fire6/concat
I1026 15:43:29.447763 37958 net.cpp:387] fire7/squeeze1x1 -> fire7/squeeze1x1
I1026 15:43:29.448242 37958 net.cpp:127] Setting up fire7/squeeze1x1
I1026 15:43:29.448253 37958 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1026 15:43:29.448258 37958 net.cpp:144] Memory required for data: 3393468416
I1026 15:43:29.448273 37958 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1026 15:43:29.448285 37958 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1026 15:43:29.448292 37958 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1026 15:43:29.448303 37958 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1026 15:43:29.448318 37958 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I1026 15:43:29.448341 37958 net.cpp:84] Creating Layer fire7/relu_squeeze1x1
I1026 15:43:29.448346 37958 net.cpp:413] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I1026 15:43:29.448355 37958 net.cpp:374] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I1026 15:43:29.449724 37958 net.cpp:127] Setting up fire7/relu_squeeze1x1
I1026 15:43:29.449743 37958 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1026 15:43:29.449748 37958 net.cpp:144] Memory required for data: 3398285312
I1026 15:43:29.449754 37958 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1026 15:43:29.449762 37958 net.cpp:84] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1026 15:43:29.449767 37958 net.cpp:413] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I1026 15:43:29.449774 37958 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1026 15:43:29.449786 37958 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1026 15:43:29.449841 37958 net.cpp:127] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1026 15:43:29.449848 37958 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1026 15:43:29.449854 37958 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1026 15:43:29.449858 37958 net.cpp:144] Memory required for data: 3407919104
I1026 15:43:29.449863 37958 layer_factory.hpp:77] Creating layer fire7/expand1x1
I1026 15:43:29.449877 37958 net.cpp:84] Creating Layer fire7/expand1x1
I1026 15:43:29.449883 37958 net.cpp:413] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1026 15:43:29.449892 37958 net.cpp:387] fire7/expand1x1 -> fire7/expand1x1
I1026 15:43:29.450302 37958 net.cpp:127] Setting up fire7/expand1x1
I1026 15:43:29.450315 37958 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1026 15:43:29.450320 37958 net.cpp:144] Memory required for data: 3427186688
I1026 15:43:29.450327 37958 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1026 15:43:29.450335 37958 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1026 15:43:29.450340 37958 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1026 15:43:29.450345 37958 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1026 15:43:29.450350 37958 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I1026 15:43:29.450358 37958 net.cpp:84] Creating Layer fire7/relu_expand1x1
I1026 15:43:29.450369 37958 net.cpp:413] fire7/relu_expand1x1 <- fire7/expand1x1
I1026 15:43:29.450378 37958 net.cpp:374] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I1026 15:43:29.450582 37958 net.cpp:127] Setting up fire7/relu_expand1x1
I1026 15:43:29.450593 37958 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1026 15:43:29.450599 37958 net.cpp:144] Memory required for data: 3446454272
I1026 15:43:29.450605 37958 layer_factory.hpp:77] Creating layer fire7/expand3x3
I1026 15:43:29.450616 37958 net.cpp:84] Creating Layer fire7/expand3x3
I1026 15:43:29.450621 37958 net.cpp:413] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1026 15:43:29.450633 37958 net.cpp:387] fire7/expand3x3 -> fire7/expand3x3
I1026 15:43:29.451634 37958 net.cpp:127] Setting up fire7/expand3x3
I1026 15:43:29.451647 37958 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1026 15:43:29.451652 37958 net.cpp:144] Memory required for data: 3465721856
I1026 15:43:29.451658 37958 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1026 15:43:29.451664 37958 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1026 15:43:29.451669 37958 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1026 15:43:29.451675 37958 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1026 15:43:29.451683 37958 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I1026 15:43:29.451700 37958 net.cpp:84] Creating Layer fire7/relu_expand3x3
I1026 15:43:29.451719 37958 net.cpp:413] fire7/relu_expand3x3 <- fire7/expand3x3
I1026 15:43:29.451728 37958 net.cpp:374] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I1026 15:43:29.451942 37958 net.cpp:127] Setting up fire7/relu_expand3x3
I1026 15:43:29.451953 37958 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1026 15:43:29.451959 37958 net.cpp:144] Memory required for data: 3484989440
I1026 15:43:29.451966 37958 layer_factory.hpp:77] Creating layer fire7/concat
I1026 15:43:29.451972 37958 net.cpp:84] Creating Layer fire7/concat
I1026 15:43:29.451977 37958 net.cpp:413] fire7/concat <- fire7/expand1x1
I1026 15:43:29.451984 37958 net.cpp:413] fire7/concat <- fire7/expand3x3
I1026 15:43:29.451993 37958 net.cpp:387] fire7/concat -> fire7/concat
I1026 15:43:29.452024 37958 net.cpp:127] Setting up fire7/concat
I1026 15:43:29.452035 37958 net.cpp:136] Top shape: 128 384 14 14 (9633792)
I1026 15:43:29.452041 37958 net.cpp:144] Memory required for data: 3523524608
I1026 15:43:29.452046 37958 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I1026 15:43:29.452055 37958 net.cpp:84] Creating Layer fire8/squeeze1x1
I1026 15:43:29.452061 37958 net.cpp:413] fire8/squeeze1x1 <- fire7/concat
I1026 15:43:29.452070 37958 net.cpp:387] fire8/squeeze1x1 -> fire8/squeeze1x1
I1026 15:43:29.452600 37958 net.cpp:127] Setting up fire8/squeeze1x1
I1026 15:43:29.452611 37958 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1026 15:43:29.452616 37958 net.cpp:144] Memory required for data: 3529947136
I1026 15:43:29.452623 37958 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1026 15:43:29.452630 37958 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1026 15:43:29.452636 37958 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1026 15:43:29.452641 37958 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1026 15:43:29.452644 37958 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I1026 15:43:29.452654 37958 net.cpp:84] Creating Layer fire8/relu_squeeze1x1
I1026 15:43:29.452663 37958 net.cpp:413] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I1026 15:43:29.452672 37958 net.cpp:374] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I1026 15:43:29.454047 37958 net.cpp:127] Setting up fire8/relu_squeeze1x1
I1026 15:43:29.454066 37958 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1026 15:43:29.454071 37958 net.cpp:144] Memory required for data: 3536369664
I1026 15:43:29.454077 37958 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1026 15:43:29.454087 37958 net.cpp:84] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1026 15:43:29.454092 37958 net.cpp:413] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I1026 15:43:29.454099 37958 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1026 15:43:29.454109 37958 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1026 15:43:29.454165 37958 net.cpp:127] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1026 15:43:29.454172 37958 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1026 15:43:29.454179 37958 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1026 15:43:29.454183 37958 net.cpp:144] Memory required for data: 3549214720
I1026 15:43:29.454188 37958 layer_factory.hpp:77] Creating layer fire8/expand1x1
I1026 15:43:29.454200 37958 net.cpp:84] Creating Layer fire8/expand1x1
I1026 15:43:29.454205 37958 net.cpp:413] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1026 15:43:29.454216 37958 net.cpp:387] fire8/expand1x1 -> fire8/expand1x1
I1026 15:43:29.454677 37958 net.cpp:127] Setting up fire8/expand1x1
I1026 15:43:29.454690 37958 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1026 15:43:29.454695 37958 net.cpp:144] Memory required for data: 3574904832
I1026 15:43:29.454708 37958 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1026 15:43:29.454727 37958 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1026 15:43:29.454733 37958 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1026 15:43:29.454741 37958 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1026 15:43:29.454746 37958 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I1026 15:43:29.454754 37958 net.cpp:84] Creating Layer fire8/relu_expand1x1
I1026 15:43:29.454759 37958 net.cpp:413] fire8/relu_expand1x1 <- fire8/expand1x1
I1026 15:43:29.454768 37958 net.cpp:374] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I1026 15:43:29.454974 37958 net.cpp:127] Setting up fire8/relu_expand1x1
I1026 15:43:29.454987 37958 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1026 15:43:29.454993 37958 net.cpp:144] Memory required for data: 3600594944
I1026 15:43:29.454998 37958 layer_factory.hpp:77] Creating layer fire8/expand3x3
I1026 15:43:29.455008 37958 net.cpp:84] Creating Layer fire8/expand3x3
I1026 15:43:29.455014 37958 net.cpp:413] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1026 15:43:29.455025 37958 net.cpp:387] fire8/expand3x3 -> fire8/expand3x3
I1026 15:43:29.457890 37958 net.cpp:127] Setting up fire8/expand3x3
I1026 15:43:29.457909 37958 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1026 15:43:29.457916 37958 net.cpp:144] Memory required for data: 3626285056
I1026 15:43:29.457922 37958 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1026 15:43:29.457929 37958 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1026 15:43:29.457934 37958 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1026 15:43:29.457939 37958 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1026 15:43:29.457945 37958 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I1026 15:43:29.457957 37958 net.cpp:84] Creating Layer fire8/relu_expand3x3
I1026 15:43:29.457964 37958 net.cpp:413] fire8/relu_expand3x3 <- fire8/expand3x3
I1026 15:43:29.457972 37958 net.cpp:374] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I1026 15:43:29.458190 37958 net.cpp:127] Setting up fire8/relu_expand3x3
I1026 15:43:29.458202 37958 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1026 15:43:29.458209 37958 net.cpp:144] Memory required for data: 3651975168
I1026 15:43:29.458214 37958 layer_factory.hpp:77] Creating layer fire8/concat
I1026 15:43:29.458223 37958 net.cpp:84] Creating Layer fire8/concat
I1026 15:43:29.458228 37958 net.cpp:413] fire8/concat <- fire8/expand1x1
I1026 15:43:29.458235 37958 net.cpp:413] fire8/concat <- fire8/expand3x3
I1026 15:43:29.458243 37958 net.cpp:387] fire8/concat -> fire8/concat
I1026 15:43:29.458276 37958 net.cpp:127] Setting up fire8/concat
I1026 15:43:29.458284 37958 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1026 15:43:29.458290 37958 net.cpp:144] Memory required for data: 3703355392
I1026 15:43:29.458295 37958 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I1026 15:43:29.458314 37958 net.cpp:84] Creating Layer fire9/squeeze1x1
I1026 15:43:29.458320 37958 net.cpp:413] fire9/squeeze1x1 <- fire8/concat
I1026 15:43:29.458333 37958 net.cpp:387] fire9/squeeze1x1 -> fire9/squeeze1x1
I1026 15:43:29.458925 37958 net.cpp:127] Setting up fire9/squeeze1x1
I1026 15:43:29.458936 37958 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1026 15:43:29.458941 37958 net.cpp:144] Memory required for data: 3709777920
I1026 15:43:29.458948 37958 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1026 15:43:29.458955 37958 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1026 15:43:29.458959 37958 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1026 15:43:29.458966 37958 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1026 15:43:29.458976 37958 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I1026 15:43:29.458997 37958 net.cpp:84] Creating Layer fire9/relu_squeeze1x1
I1026 15:43:29.459003 37958 net.cpp:413] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I1026 15:43:29.459017 37958 net.cpp:374] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I1026 15:43:29.459229 37958 net.cpp:127] Setting up fire9/relu_squeeze1x1
I1026 15:43:29.459240 37958 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1026 15:43:29.459246 37958 net.cpp:144] Memory required for data: 3716200448
I1026 15:43:29.459252 37958 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1026 15:43:29.459270 37958 net.cpp:84] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1026 15:43:29.459275 37958 net.cpp:413] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I1026 15:43:29.459285 37958 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1026 15:43:29.459295 37958 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1026 15:43:29.459352 37958 net.cpp:127] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1026 15:43:29.459362 37958 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1026 15:43:29.459369 37958 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1026 15:43:29.459375 37958 net.cpp:144] Memory required for data: 3729045504
I1026 15:43:29.459380 37958 layer_factory.hpp:77] Creating layer fire9/expand1x1
I1026 15:43:29.459393 37958 net.cpp:84] Creating Layer fire9/expand1x1
I1026 15:43:29.459398 37958 net.cpp:413] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1026 15:43:29.459406 37958 net.cpp:387] fire9/expand1x1 -> fire9/expand1x1
I1026 15:43:29.459853 37958 net.cpp:127] Setting up fire9/expand1x1
I1026 15:43:29.459863 37958 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1026 15:43:29.459868 37958 net.cpp:144] Memory required for data: 3754735616
I1026 15:43:29.459875 37958 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1026 15:43:29.459882 37958 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1026 15:43:29.459887 37958 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1026 15:43:29.459893 37958 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1026 15:43:29.459897 37958 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I1026 15:43:29.459908 37958 net.cpp:84] Creating Layer fire9/relu_expand1x1
I1026 15:43:29.459913 37958 net.cpp:413] fire9/relu_expand1x1 <- fire9/expand1x1
I1026 15:43:29.459920 37958 net.cpp:374] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I1026 15:43:29.461284 37958 net.cpp:127] Setting up fire9/relu_expand1x1
I1026 15:43:29.461309 37958 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1026 15:43:29.461316 37958 net.cpp:144] Memory required for data: 3780425728
I1026 15:43:29.461321 37958 layer_factory.hpp:77] Creating layer fire9/expand3x3
I1026 15:43:29.461334 37958 net.cpp:84] Creating Layer fire9/expand3x3
I1026 15:43:29.461341 37958 net.cpp:413] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1026 15:43:29.461350 37958 net.cpp:387] fire9/expand3x3 -> fire9/expand3x3
I1026 15:43:29.462855 37958 net.cpp:127] Setting up fire9/expand3x3
I1026 15:43:29.462869 37958 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1026 15:43:29.462874 37958 net.cpp:144] Memory required for data: 3806115840
I1026 15:43:29.462882 37958 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1026 15:43:29.462888 37958 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1026 15:43:29.462893 37958 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1026 15:43:29.462899 37958 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1026 15:43:29.462905 37958 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I1026 15:43:29.462924 37958 net.cpp:84] Creating Layer fire9/relu_expand3x3
I1026 15:43:29.462942 37958 net.cpp:413] fire9/relu_expand3x3 <- fire9/expand3x3
I1026 15:43:29.462951 37958 net.cpp:374] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I1026 15:43:29.463156 37958 net.cpp:127] Setting up fire9/relu_expand3x3
I1026 15:43:29.463168 37958 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1026 15:43:29.463173 37958 net.cpp:144] Memory required for data: 3831805952
I1026 15:43:29.463179 37958 layer_factory.hpp:77] Creating layer fire9/concat
I1026 15:43:29.463186 37958 net.cpp:84] Creating Layer fire9/concat
I1026 15:43:29.463191 37958 net.cpp:413] fire9/concat <- fire9/expand1x1
I1026 15:43:29.463197 37958 net.cpp:413] fire9/concat <- fire9/expand3x3
I1026 15:43:29.463207 37958 net.cpp:387] fire9/concat -> fire9/concat
I1026 15:43:29.463238 37958 net.cpp:127] Setting up fire9/concat
I1026 15:43:29.463246 37958 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1026 15:43:29.463251 37958 net.cpp:144] Memory required for data: 3883186176
I1026 15:43:29.463255 37958 layer_factory.hpp:77] Creating layer drop9
I1026 15:43:29.463268 37958 net.cpp:84] Creating Layer drop9
I1026 15:43:29.463274 37958 net.cpp:413] drop9 <- fire9/concat
I1026 15:43:29.463280 37958 net.cpp:374] drop9 -> fire9/concat (in-place)
I1026 15:43:29.463322 37958 net.cpp:127] Setting up drop9
I1026 15:43:29.463341 37958 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1026 15:43:29.463346 37958 net.cpp:144] Memory required for data: 3934566400
I1026 15:43:29.463351 37958 layer_factory.hpp:77] Creating layer conv10
I1026 15:43:29.463363 37958 net.cpp:84] Creating Layer conv10
I1026 15:43:29.463368 37958 net.cpp:413] conv10 <- fire9/concat
I1026 15:43:29.463378 37958 net.cpp:387] conv10 -> conv10
I1026 15:43:29.472939 37958 net.cpp:127] Setting up conv10
I1026 15:43:29.472959 37958 net.cpp:136] Top shape: 128 1000 14 14 (25088000)
I1026 15:43:29.472965 37958 net.cpp:144] Memory required for data: 4034918400
I1026 15:43:29.472972 37958 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1026 15:43:29.472980 37958 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1026 15:43:29.472985 37958 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1026 15:43:29.472990 37958 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1026 15:43:29.472996 37958 layer_factory.hpp:77] Creating layer relu_conv10
I1026 15:43:29.473006 37958 net.cpp:84] Creating Layer relu_conv10
I1026 15:43:29.473014 37958 net.cpp:413] relu_conv10 <- conv10
I1026 15:43:29.473023 37958 net.cpp:374] relu_conv10 -> conv10 (in-place)
I1026 15:43:29.473251 37958 net.cpp:127] Setting up relu_conv10
I1026 15:43:29.473264 37958 net.cpp:136] Top shape: 128 1000 14 14 (25088000)
I1026 15:43:29.473269 37958 net.cpp:144] Memory required for data: 4135270400
I1026 15:43:29.473276 37958 layer_factory.hpp:77] Creating layer pool10
I1026 15:43:29.473289 37958 net.cpp:84] Creating Layer pool10
I1026 15:43:29.473294 37958 net.cpp:413] pool10 <- conv10
I1026 15:43:29.473306 37958 net.cpp:387] pool10 -> pool10
I1026 15:43:29.473553 37958 net.cpp:127] Setting up pool10
I1026 15:43:29.473570 37958 net.cpp:136] Top shape: 128 1000 1 1 (128000)
I1026 15:43:29.473577 37958 net.cpp:144] Memory required for data: 4135782400
I1026 15:43:29.473582 37958 layer_factory.hpp:77] Creating layer loss
I1026 15:43:29.473592 37958 net.cpp:84] Creating Layer loss
I1026 15:43:29.473598 37958 net.cpp:413] loss <- pool10
I1026 15:43:29.473603 37958 net.cpp:413] loss <- label
I1026 15:43:29.473611 37958 net.cpp:387] loss -> loss
I1026 15:43:29.473624 37958 layer_factory.hpp:77] Creating layer loss
I1026 15:43:29.476555 37958 net.cpp:127] Setting up loss
I1026 15:43:29.476574 37958 net.cpp:136] Top shape: (1)
I1026 15:43:29.476579 37958 net.cpp:139]     with loss weight 1
I1026 15:43:29.476604 37958 net.cpp:144] Memory required for data: 4135782404
I1026 15:43:29.476613 37958 net.cpp:205] loss needs backward computation.
I1026 15:43:29.476629 37958 net.cpp:205] pool10 needs backward computation.
I1026 15:43:29.476647 37958 net.cpp:205] relu_conv10 needs backward computation.
I1026 15:43:29.476652 37958 net.cpp:205] conv10 needs backward computation.
I1026 15:43:29.476657 37958 net.cpp:205] drop9 needs backward computation.
I1026 15:43:29.476661 37958 net.cpp:205] fire9/concat needs backward computation.
I1026 15:43:29.476666 37958 net.cpp:205] fire9/relu_expand3x3 needs backward computation.
I1026 15:43:29.476671 37958 net.cpp:205] fire9/expand3x3 needs backward computation.
I1026 15:43:29.476676 37958 net.cpp:205] fire9/relu_expand1x1 needs backward computation.
I1026 15:43:29.476680 37958 net.cpp:205] fire9/expand1x1 needs backward computation.
I1026 15:43:29.476686 37958 net.cpp:205] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I1026 15:43:29.476691 37958 net.cpp:205] fire9/relu_squeeze1x1 needs backward computation.
I1026 15:43:29.476696 37958 net.cpp:205] fire9/squeeze1x1 needs backward computation.
I1026 15:43:29.476701 37958 net.cpp:205] fire8/concat needs backward computation.
I1026 15:43:29.476706 37958 net.cpp:205] fire8/relu_expand3x3 needs backward computation.
I1026 15:43:29.476709 37958 net.cpp:205] fire8/expand3x3 needs backward computation.
I1026 15:43:29.476714 37958 net.cpp:205] fire8/relu_expand1x1 needs backward computation.
I1026 15:43:29.476718 37958 net.cpp:205] fire8/expand1x1 needs backward computation.
I1026 15:43:29.476723 37958 net.cpp:205] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I1026 15:43:29.476727 37958 net.cpp:205] fire8/relu_squeeze1x1 needs backward computation.
I1026 15:43:29.476732 37958 net.cpp:205] fire8/squeeze1x1 needs backward computation.
I1026 15:43:29.476737 37958 net.cpp:205] fire7/concat needs backward computation.
I1026 15:43:29.476742 37958 net.cpp:205] fire7/relu_expand3x3 needs backward computation.
I1026 15:43:29.476747 37958 net.cpp:205] fire7/expand3x3 needs backward computation.
I1026 15:43:29.476750 37958 net.cpp:205] fire7/relu_expand1x1 needs backward computation.
I1026 15:43:29.476755 37958 net.cpp:205] fire7/expand1x1 needs backward computation.
I1026 15:43:29.476759 37958 net.cpp:205] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I1026 15:43:29.476764 37958 net.cpp:205] fire7/relu_squeeze1x1 needs backward computation.
I1026 15:43:29.476768 37958 net.cpp:205] fire7/squeeze1x1 needs backward computation.
I1026 15:43:29.476773 37958 net.cpp:205] fire6/concat needs backward computation.
I1026 15:43:29.476778 37958 net.cpp:205] fire6/relu_expand3x3 needs backward computation.
I1026 15:43:29.476783 37958 net.cpp:205] fire6/expand3x3 needs backward computation.
I1026 15:43:29.476786 37958 net.cpp:205] fire6/relu_expand1x1 needs backward computation.
I1026 15:43:29.476791 37958 net.cpp:205] fire6/expand1x1 needs backward computation.
I1026 15:43:29.476795 37958 net.cpp:205] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I1026 15:43:29.476800 37958 net.cpp:205] fire6/relu_squeeze1x1 needs backward computation.
I1026 15:43:29.476804 37958 net.cpp:205] fire6/squeeze1x1 needs backward computation.
I1026 15:43:29.476809 37958 net.cpp:205] pool5 needs backward computation.
I1026 15:43:29.476814 37958 net.cpp:205] fire5/concat needs backward computation.
I1026 15:43:29.476819 37958 net.cpp:205] fire5/relu_expand3x3 needs backward computation.
I1026 15:43:29.476824 37958 net.cpp:205] fire5/expand3x3 needs backward computation.
I1026 15:43:29.476827 37958 net.cpp:205] fire5/relu_expand1x1 needs backward computation.
I1026 15:43:29.476831 37958 net.cpp:205] fire5/expand1x1 needs backward computation.
I1026 15:43:29.476836 37958 net.cpp:205] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I1026 15:43:29.476840 37958 net.cpp:205] fire5/relu_squeeze1x1 needs backward computation.
I1026 15:43:29.476845 37958 net.cpp:205] fire5/squeeze1x1 needs backward computation.
I1026 15:43:29.476850 37958 net.cpp:205] fire4/concat needs backward computation.
I1026 15:43:29.476860 37958 net.cpp:205] fire4/relu_expand3x3 needs backward computation.
I1026 15:43:29.476871 37958 net.cpp:205] fire4/expand3x3 needs backward computation.
I1026 15:43:29.476874 37958 net.cpp:205] fire4/relu_expand1x1 needs backward computation.
I1026 15:43:29.476879 37958 net.cpp:205] fire4/expand1x1 needs backward computation.
I1026 15:43:29.476883 37958 net.cpp:205] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I1026 15:43:29.476888 37958 net.cpp:205] fire4/relu_squeeze1x1 needs backward computation.
I1026 15:43:29.476892 37958 net.cpp:205] fire4/squeeze1x1 needs backward computation.
I1026 15:43:29.476897 37958 net.cpp:205] pool3 needs backward computation.
I1026 15:43:29.476902 37958 net.cpp:205] fire3/concat needs backward computation.
I1026 15:43:29.476907 37958 net.cpp:205] fire3/relu_expand3x3 needs backward computation.
I1026 15:43:29.476912 37958 net.cpp:205] fire3/expand3x3 needs backward computation.
I1026 15:43:29.476915 37958 net.cpp:205] fire3/relu_expand1x1 needs backward computation.
I1026 15:43:29.476920 37958 net.cpp:205] fire3/expand1x1 needs backward computation.
I1026 15:43:29.476924 37958 net.cpp:205] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I1026 15:43:29.476929 37958 net.cpp:205] fire3/relu_squeeze1x1 needs backward computation.
I1026 15:43:29.476933 37958 net.cpp:205] fire3/squeeze1x1 needs backward computation.
I1026 15:43:29.476938 37958 net.cpp:205] fire2/concat needs backward computation.
I1026 15:43:29.476945 37958 net.cpp:205] fire2/relu_expand3x3 needs backward computation.
I1026 15:43:29.476950 37958 net.cpp:205] fire2/expand3x3 needs backward computation.
I1026 15:43:29.476954 37958 net.cpp:205] fire2/relu_expand1x1 needs backward computation.
I1026 15:43:29.476958 37958 net.cpp:205] fire2/expand1x1 needs backward computation.
I1026 15:43:29.476963 37958 net.cpp:205] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I1026 15:43:29.476969 37958 net.cpp:205] fire2/relu_squeeze1x1 needs backward computation.
I1026 15:43:29.476972 37958 net.cpp:205] fire2/squeeze1x1 needs backward computation.
I1026 15:43:29.476977 37958 net.cpp:205] pool1 needs backward computation.
I1026 15:43:29.476982 37958 net.cpp:205] relu_conv1 needs backward computation.
I1026 15:43:29.476987 37958 net.cpp:205] conv1 needs backward computation.
I1026 15:43:29.476992 37958 net.cpp:207] data does not need backward computation.
I1026 15:43:29.476997 37958 net.cpp:249] This network produces output loss
I1026 15:43:29.477051 37958 net.cpp:262] Network initialization done.
I1026 15:43:29.478840 37958 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_20.prototxt
I1026 15:43:29.478943 37958 net.cpp:301] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1026 15:43:29.479681 37958 net.cpp:51] Initializing net from parameters: 
name: "SqueezeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/data/caffe-imagenet/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "INQConvolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "fire3/concat"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire4/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool3"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "fire5/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire4/concat"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "fire5/concat"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire6/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool5"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "fire9/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire8/concat"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "INQConvolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0.2
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "pool10"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy_top1"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy_top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy_top5"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy_top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I1026 15:43:29.480067 37958 layer_factory.hpp:77] Creating layer data
I1026 15:43:29.480147 37958 db_lmdb.cpp:35] Opened lmdb /home/data/caffe-imagenet/ilsvrc12_val_lmdb
I1026 15:43:29.480170 37958 net.cpp:84] Creating Layer data
I1026 15:43:29.480178 37958 net.cpp:387] data -> data
I1026 15:43:29.480191 37958 net.cpp:387] data -> label
I1026 15:43:29.480706 37958 data_layer.cpp:45] output data size: 50,3,227,227
I1026 15:43:29.569011 37958 net.cpp:127] Setting up data
I1026 15:43:29.569061 37958 net.cpp:136] Top shape: 50 3 227 227 (7729350)
I1026 15:43:29.569097 37958 net.cpp:136] Top shape: 50 (50)
I1026 15:43:29.569104 37958 net.cpp:144] Memory required for data: 30917600
I1026 15:43:29.569114 37958 layer_factory.hpp:77] Creating layer label_data_1_split
I1026 15:43:29.569134 37958 net.cpp:84] Creating Layer label_data_1_split
I1026 15:43:29.569140 37958 net.cpp:413] label_data_1_split <- label
I1026 15:43:29.569150 37958 net.cpp:387] label_data_1_split -> label_data_1_split_0
I1026 15:43:29.569164 37958 net.cpp:387] label_data_1_split -> label_data_1_split_1
I1026 15:43:29.569173 37958 net.cpp:387] label_data_1_split -> label_data_1_split_2
I1026 15:43:29.569283 37958 net.cpp:127] Setting up label_data_1_split
I1026 15:43:29.569293 37958 net.cpp:136] Top shape: 50 (50)
I1026 15:43:29.569308 37958 net.cpp:136] Top shape: 50 (50)
I1026 15:43:29.569320 37958 net.cpp:136] Top shape: 50 (50)
I1026 15:43:29.569324 37958 net.cpp:144] Memory required for data: 30918200
I1026 15:43:29.569329 37958 layer_factory.hpp:77] Creating layer conv1
I1026 15:43:29.569350 37958 net.cpp:84] Creating Layer conv1
I1026 15:43:29.569355 37958 net.cpp:413] conv1 <- data
I1026 15:43:29.569365 37958 net.cpp:387] conv1 -> conv1
I1026 15:43:29.569772 37958 net.cpp:127] Setting up conv1
I1026 15:43:29.569784 37958 net.cpp:136] Top shape: 50 64 113 113 (40860800)
I1026 15:43:29.569789 37958 net.cpp:144] Memory required for data: 194361400
I1026 15:43:29.569798 37958 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1026 15:43:29.569808 37958 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1026 15:43:29.569816 37958 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1026 15:43:29.569823 37958 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1026 15:43:29.569831 37958 layer_factory.hpp:77] Creating layer relu_conv1
I1026 15:43:29.569841 37958 net.cpp:84] Creating Layer relu_conv1
I1026 15:43:29.569846 37958 net.cpp:413] relu_conv1 <- conv1
I1026 15:43:29.569854 37958 net.cpp:374] relu_conv1 -> conv1 (in-place)
I1026 15:43:29.570111 37958 net.cpp:127] Setting up relu_conv1
I1026 15:43:29.570123 37958 net.cpp:136] Top shape: 50 64 113 113 (40860800)
I1026 15:43:29.570128 37958 net.cpp:144] Memory required for data: 357804600
I1026 15:43:29.570134 37958 layer_factory.hpp:77] Creating layer pool1
I1026 15:43:29.570147 37958 net.cpp:84] Creating Layer pool1
I1026 15:43:29.570152 37958 net.cpp:413] pool1 <- conv1
I1026 15:43:29.570160 37958 net.cpp:387] pool1 -> pool1
I1026 15:43:29.570231 37958 net.cpp:127] Setting up pool1
I1026 15:43:29.570241 37958 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1026 15:43:29.570247 37958 net.cpp:144] Memory required for data: 397945400
I1026 15:43:29.570252 37958 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I1026 15:43:29.570263 37958 net.cpp:84] Creating Layer fire2/squeeze1x1
I1026 15:43:29.570268 37958 net.cpp:413] fire2/squeeze1x1 <- pool1
I1026 15:43:29.570277 37958 net.cpp:387] fire2/squeeze1x1 -> fire2/squeeze1x1
I1026 15:43:29.573071 37958 net.cpp:127] Setting up fire2/squeeze1x1
I1026 15:43:29.573083 37958 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1026 15:43:29.573088 37958 net.cpp:144] Memory required for data: 407980600
I1026 15:43:29.573097 37958 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1026 15:43:29.573106 37958 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1026 15:43:29.573112 37958 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1026 15:43:29.573119 37958 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1026 15:43:29.573125 37958 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I1026 15:43:29.573137 37958 net.cpp:84] Creating Layer fire2/relu_squeeze1x1
I1026 15:43:29.573143 37958 net.cpp:413] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I1026 15:43:29.573150 37958 net.cpp:374] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I1026 15:43:29.573397 37958 net.cpp:127] Setting up fire2/relu_squeeze1x1
I1026 15:43:29.573422 37958 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1026 15:43:29.573427 37958 net.cpp:144] Memory required for data: 418015800
I1026 15:43:29.573434 37958 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1026 15:43:29.573443 37958 net.cpp:84] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1026 15:43:29.573448 37958 net.cpp:413] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I1026 15:43:29.573456 37958 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1026 15:43:29.573467 37958 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1026 15:43:29.573518 37958 net.cpp:127] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1026 15:43:29.573527 37958 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1026 15:43:29.573534 37958 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1026 15:43:29.573539 37958 net.cpp:144] Memory required for data: 438086200
I1026 15:43:29.573544 37958 layer_factory.hpp:77] Creating layer fire2/expand1x1
I1026 15:43:29.573554 37958 net.cpp:84] Creating Layer fire2/expand1x1
I1026 15:43:29.573559 37958 net.cpp:413] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1026 15:43:29.573568 37958 net.cpp:387] fire2/expand1x1 -> fire2/expand1x1
I1026 15:43:29.573957 37958 net.cpp:127] Setting up fire2/expand1x1
I1026 15:43:29.573968 37958 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1026 15:43:29.573973 37958 net.cpp:144] Memory required for data: 478227000
I1026 15:43:29.573983 37958 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1026 15:43:29.573992 37958 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1026 15:43:29.573997 37958 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1026 15:43:29.574004 37958 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1026 15:43:29.574010 37958 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I1026 15:43:29.574018 37958 net.cpp:84] Creating Layer fire2/relu_expand1x1
I1026 15:43:29.574024 37958 net.cpp:413] fire2/relu_expand1x1 <- fire2/expand1x1
I1026 15:43:29.574031 37958 net.cpp:374] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I1026 15:43:29.575448 37958 net.cpp:127] Setting up fire2/relu_expand1x1
I1026 15:43:29.575469 37958 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1026 15:43:29.575474 37958 net.cpp:144] Memory required for data: 518367800
I1026 15:43:29.575479 37958 layer_factory.hpp:77] Creating layer fire2/expand3x3
I1026 15:43:29.575490 37958 net.cpp:84] Creating Layer fire2/expand3x3
I1026 15:43:29.575496 37958 net.cpp:413] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1026 15:43:29.575507 37958 net.cpp:387] fire2/expand3x3 -> fire2/expand3x3
I1026 15:43:29.575955 37958 net.cpp:127] Setting up fire2/expand3x3
I1026 15:43:29.575968 37958 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1026 15:43:29.575973 37958 net.cpp:144] Memory required for data: 558508600
I1026 15:43:29.575979 37958 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1026 15:43:29.575985 37958 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1026 15:43:29.575991 37958 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1026 15:43:29.575996 37958 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1026 15:43:29.576001 37958 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I1026 15:43:29.576009 37958 net.cpp:84] Creating Layer fire2/relu_expand3x3
I1026 15:43:29.576016 37958 net.cpp:413] fire2/relu_expand3x3 <- fire2/expand3x3
I1026 15:43:29.576025 37958 net.cpp:374] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I1026 15:43:29.576247 37958 net.cpp:127] Setting up fire2/relu_expand3x3
I1026 15:43:29.576261 37958 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1026 15:43:29.576277 37958 net.cpp:144] Memory required for data: 598649400
I1026 15:43:29.576284 37958 layer_factory.hpp:77] Creating layer fire2/concat
I1026 15:43:29.576294 37958 net.cpp:84] Creating Layer fire2/concat
I1026 15:43:29.576308 37958 net.cpp:413] fire2/concat <- fire2/expand1x1
I1026 15:43:29.576314 37958 net.cpp:413] fire2/concat <- fire2/expand3x3
I1026 15:43:29.576325 37958 net.cpp:387] fire2/concat -> fire2/concat
I1026 15:43:29.576364 37958 net.cpp:127] Setting up fire2/concat
I1026 15:43:29.576378 37958 net.cpp:136] Top shape: 50 128 56 56 (20070400)
I1026 15:43:29.576383 37958 net.cpp:144] Memory required for data: 678931000
I1026 15:43:29.576388 37958 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I1026 15:43:29.576400 37958 net.cpp:84] Creating Layer fire3/squeeze1x1
I1026 15:43:29.576405 37958 net.cpp:413] fire3/squeeze1x1 <- fire2/concat
I1026 15:43:29.576413 37958 net.cpp:387] fire3/squeeze1x1 -> fire3/squeeze1x1
I1026 15:43:29.576786 37958 net.cpp:127] Setting up fire3/squeeze1x1
I1026 15:43:29.576797 37958 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1026 15:43:29.576800 37958 net.cpp:144] Memory required for data: 688966200
I1026 15:43:29.576809 37958 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1026 15:43:29.576817 37958 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1026 15:43:29.576823 37958 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1026 15:43:29.576829 37958 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1026 15:43:29.576833 37958 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I1026 15:43:29.576843 37958 net.cpp:84] Creating Layer fire3/relu_squeeze1x1
I1026 15:43:29.576848 37958 net.cpp:413] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I1026 15:43:29.576858 37958 net.cpp:374] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I1026 15:43:29.577069 37958 net.cpp:127] Setting up fire3/relu_squeeze1x1
I1026 15:43:29.577081 37958 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1026 15:43:29.577086 37958 net.cpp:144] Memory required for data: 699001400
I1026 15:43:29.577092 37958 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1026 15:43:29.577100 37958 net.cpp:84] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1026 15:43:29.577105 37958 net.cpp:413] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I1026 15:43:29.577114 37958 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1026 15:43:29.577123 37958 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1026 15:43:29.577177 37958 net.cpp:127] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1026 15:43:29.577188 37958 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1026 15:43:29.577195 37958 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1026 15:43:29.577200 37958 net.cpp:144] Memory required for data: 719071800
I1026 15:43:29.577205 37958 layer_factory.hpp:77] Creating layer fire3/expand1x1
I1026 15:43:29.577219 37958 net.cpp:84] Creating Layer fire3/expand1x1
I1026 15:43:29.577224 37958 net.cpp:413] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1026 15:43:29.577234 37958 net.cpp:387] fire3/expand1x1 -> fire3/expand1x1
I1026 15:43:29.577605 37958 net.cpp:127] Setting up fire3/expand1x1
I1026 15:43:29.577617 37958 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1026 15:43:29.577623 37958 net.cpp:144] Memory required for data: 759212600
I1026 15:43:29.577630 37958 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1026 15:43:29.577636 37958 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1026 15:43:29.577641 37958 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1026 15:43:29.577654 37958 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1026 15:43:29.577673 37958 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I1026 15:43:29.577682 37958 net.cpp:84] Creating Layer fire3/relu_expand1x1
I1026 15:43:29.577687 37958 net.cpp:413] fire3/relu_expand1x1 <- fire3/expand1x1
I1026 15:43:29.577694 37958 net.cpp:374] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I1026 15:43:29.577908 37958 net.cpp:127] Setting up fire3/relu_expand1x1
I1026 15:43:29.577920 37958 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1026 15:43:29.577925 37958 net.cpp:144] Memory required for data: 799353400
I1026 15:43:29.577931 37958 layer_factory.hpp:77] Creating layer fire3/expand3x3
I1026 15:43:29.577941 37958 net.cpp:84] Creating Layer fire3/expand3x3
I1026 15:43:29.577947 37958 net.cpp:413] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1026 15:43:29.577957 37958 net.cpp:387] fire3/expand3x3 -> fire3/expand3x3
I1026 15:43:29.578402 37958 net.cpp:127] Setting up fire3/expand3x3
I1026 15:43:29.578414 37958 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1026 15:43:29.578419 37958 net.cpp:144] Memory required for data: 839494200
I1026 15:43:29.578425 37958 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1026 15:43:29.578433 37958 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1026 15:43:29.578438 37958 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1026 15:43:29.578443 37958 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1026 15:43:29.578446 37958 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I1026 15:43:29.578460 37958 net.cpp:84] Creating Layer fire3/relu_expand3x3
I1026 15:43:29.578469 37958 net.cpp:413] fire3/relu_expand3x3 <- fire3/expand3x3
I1026 15:43:29.578477 37958 net.cpp:374] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I1026 15:43:29.579869 37958 net.cpp:127] Setting up fire3/relu_expand3x3
I1026 15:43:29.579887 37958 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1026 15:43:29.579893 37958 net.cpp:144] Memory required for data: 879635000
I1026 15:43:29.579898 37958 layer_factory.hpp:77] Creating layer fire3/concat
I1026 15:43:29.579906 37958 net.cpp:84] Creating Layer fire3/concat
I1026 15:43:29.579912 37958 net.cpp:413] fire3/concat <- fire3/expand1x1
I1026 15:43:29.579919 37958 net.cpp:413] fire3/concat <- fire3/expand3x3
I1026 15:43:29.579926 37958 net.cpp:387] fire3/concat -> fire3/concat
I1026 15:43:29.579965 37958 net.cpp:127] Setting up fire3/concat
I1026 15:43:29.579974 37958 net.cpp:136] Top shape: 50 128 56 56 (20070400)
I1026 15:43:29.579978 37958 net.cpp:144] Memory required for data: 959916600
I1026 15:43:29.579983 37958 layer_factory.hpp:77] Creating layer pool3
I1026 15:43:29.579993 37958 net.cpp:84] Creating Layer pool3
I1026 15:43:29.579998 37958 net.cpp:413] pool3 <- fire3/concat
I1026 15:43:29.580004 37958 net.cpp:387] pool3 -> pool3
I1026 15:43:29.580054 37958 net.cpp:127] Setting up pool3
I1026 15:43:29.580061 37958 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1026 15:43:29.580066 37958 net.cpp:144] Memory required for data: 979987000
I1026 15:43:29.580070 37958 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I1026 15:43:29.580082 37958 net.cpp:84] Creating Layer fire4/squeeze1x1
I1026 15:43:29.580088 37958 net.cpp:413] fire4/squeeze1x1 <- pool3
I1026 15:43:29.580097 37958 net.cpp:387] fire4/squeeze1x1 -> fire4/squeeze1x1
I1026 15:43:29.580498 37958 net.cpp:127] Setting up fire4/squeeze1x1
I1026 15:43:29.580513 37958 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1026 15:43:29.580519 37958 net.cpp:144] Memory required for data: 985004600
I1026 15:43:29.580526 37958 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1026 15:43:29.580533 37958 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1026 15:43:29.580539 37958 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1026 15:43:29.580551 37958 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1026 15:43:29.580569 37958 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I1026 15:43:29.580577 37958 net.cpp:84] Creating Layer fire4/relu_squeeze1x1
I1026 15:43:29.580582 37958 net.cpp:413] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I1026 15:43:29.580590 37958 net.cpp:374] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I1026 15:43:29.580807 37958 net.cpp:127] Setting up fire4/relu_squeeze1x1
I1026 15:43:29.580819 37958 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1026 15:43:29.580826 37958 net.cpp:144] Memory required for data: 990022200
I1026 15:43:29.580832 37958 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1026 15:43:29.580838 37958 net.cpp:84] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1026 15:43:29.580843 37958 net.cpp:413] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I1026 15:43:29.580850 37958 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1026 15:43:29.580860 37958 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1026 15:43:29.580911 37958 net.cpp:127] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1026 15:43:29.580921 37958 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1026 15:43:29.580927 37958 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1026 15:43:29.580932 37958 net.cpp:144] Memory required for data: 1000057400
I1026 15:43:29.580937 37958 layer_factory.hpp:77] Creating layer fire4/expand1x1
I1026 15:43:29.580948 37958 net.cpp:84] Creating Layer fire4/expand1x1
I1026 15:43:29.580955 37958 net.cpp:413] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1026 15:43:29.580963 37958 net.cpp:387] fire4/expand1x1 -> fire4/expand1x1
I1026 15:43:29.581341 37958 net.cpp:127] Setting up fire4/expand1x1
I1026 15:43:29.581356 37958 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1026 15:43:29.581360 37958 net.cpp:144] Memory required for data: 1020127800
I1026 15:43:29.581370 37958 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1026 15:43:29.581380 37958 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1026 15:43:29.581387 37958 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1026 15:43:29.581393 37958 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1026 15:43:29.581400 37958 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I1026 15:43:29.581411 37958 net.cpp:84] Creating Layer fire4/relu_expand1x1
I1026 15:43:29.581416 37958 net.cpp:413] fire4/relu_expand1x1 <- fire4/expand1x1
I1026 15:43:29.581423 37958 net.cpp:374] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I1026 15:43:29.581635 37958 net.cpp:127] Setting up fire4/relu_expand1x1
I1026 15:43:29.581647 37958 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1026 15:43:29.581653 37958 net.cpp:144] Memory required for data: 1040198200
I1026 15:43:29.581658 37958 layer_factory.hpp:77] Creating layer fire4/expand3x3
I1026 15:43:29.581672 37958 net.cpp:84] Creating Layer fire4/expand3x3
I1026 15:43:29.581677 37958 net.cpp:413] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1026 15:43:29.581686 37958 net.cpp:387] fire4/expand3x3 -> fire4/expand3x3
I1026 15:43:29.582365 37958 net.cpp:127] Setting up fire4/expand3x3
I1026 15:43:29.582377 37958 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1026 15:43:29.582382 37958 net.cpp:144] Memory required for data: 1060268600
I1026 15:43:29.582388 37958 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1026 15:43:29.582396 37958 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1026 15:43:29.582401 37958 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1026 15:43:29.582412 37958 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1026 15:43:29.582428 37958 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I1026 15:43:29.582438 37958 net.cpp:84] Creating Layer fire4/relu_expand3x3
I1026 15:43:29.582443 37958 net.cpp:413] fire4/relu_expand3x3 <- fire4/expand3x3
I1026 15:43:29.582449 37958 net.cpp:374] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I1026 15:43:29.582662 37958 net.cpp:127] Setting up fire4/relu_expand3x3
I1026 15:43:29.582674 37958 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1026 15:43:29.582679 37958 net.cpp:144] Memory required for data: 1080339000
I1026 15:43:29.582684 37958 layer_factory.hpp:77] Creating layer fire4/concat
I1026 15:43:29.582692 37958 net.cpp:84] Creating Layer fire4/concat
I1026 15:43:29.582697 37958 net.cpp:413] fire4/concat <- fire4/expand1x1
I1026 15:43:29.582702 37958 net.cpp:413] fire4/concat <- fire4/expand3x3
I1026 15:43:29.582710 37958 net.cpp:387] fire4/concat -> fire4/concat
I1026 15:43:29.582743 37958 net.cpp:127] Setting up fire4/concat
I1026 15:43:29.582751 37958 net.cpp:136] Top shape: 50 256 28 28 (10035200)
I1026 15:43:29.582756 37958 net.cpp:144] Memory required for data: 1120479800
I1026 15:43:29.582762 37958 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I1026 15:43:29.582773 37958 net.cpp:84] Creating Layer fire5/squeeze1x1
I1026 15:43:29.582779 37958 net.cpp:413] fire5/squeeze1x1 <- fire4/concat
I1026 15:43:29.582790 37958 net.cpp:387] fire5/squeeze1x1 -> fire5/squeeze1x1
I1026 15:43:29.583212 37958 net.cpp:127] Setting up fire5/squeeze1x1
I1026 15:43:29.583225 37958 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1026 15:43:29.583230 37958 net.cpp:144] Memory required for data: 1125497400
I1026 15:43:29.583235 37958 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1026 15:43:29.583242 37958 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1026 15:43:29.583247 37958 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1026 15:43:29.583252 37958 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1026 15:43:29.583258 37958 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I1026 15:43:29.583267 37958 net.cpp:84] Creating Layer fire5/relu_squeeze1x1
I1026 15:43:29.583273 37958 net.cpp:413] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I1026 15:43:29.583281 37958 net.cpp:374] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I1026 15:43:29.584710 37958 net.cpp:127] Setting up fire5/relu_squeeze1x1
I1026 15:43:29.584728 37958 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1026 15:43:29.584734 37958 net.cpp:144] Memory required for data: 1130515000
I1026 15:43:29.584740 37958 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1026 15:43:29.584753 37958 net.cpp:84] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1026 15:43:29.584758 37958 net.cpp:413] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I1026 15:43:29.584767 37958 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1026 15:43:29.584779 37958 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1026 15:43:29.584836 37958 net.cpp:127] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1026 15:43:29.584844 37958 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1026 15:43:29.584851 37958 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1026 15:43:29.584856 37958 net.cpp:144] Memory required for data: 1140550200
I1026 15:43:29.584859 37958 layer_factory.hpp:77] Creating layer fire5/expand1x1
I1026 15:43:29.584872 37958 net.cpp:84] Creating Layer fire5/expand1x1
I1026 15:43:29.584877 37958 net.cpp:413] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1026 15:43:29.584887 37958 net.cpp:387] fire5/expand1x1 -> fire5/expand1x1
I1026 15:43:29.585260 37958 net.cpp:127] Setting up fire5/expand1x1
I1026 15:43:29.585278 37958 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1026 15:43:29.585294 37958 net.cpp:144] Memory required for data: 1160620600
I1026 15:43:29.585306 37958 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1026 15:43:29.585314 37958 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1026 15:43:29.585321 37958 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1026 15:43:29.585330 37958 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1026 15:43:29.585335 37958 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I1026 15:43:29.585342 37958 net.cpp:84] Creating Layer fire5/relu_expand1x1
I1026 15:43:29.585347 37958 net.cpp:413] fire5/relu_expand1x1 <- fire5/expand1x1
I1026 15:43:29.585356 37958 net.cpp:374] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I1026 15:43:29.585567 37958 net.cpp:127] Setting up fire5/relu_expand1x1
I1026 15:43:29.585578 37958 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1026 15:43:29.585584 37958 net.cpp:144] Memory required for data: 1180691000
I1026 15:43:29.585590 37958 layer_factory.hpp:77] Creating layer fire5/expand3x3
I1026 15:43:29.585602 37958 net.cpp:84] Creating Layer fire5/expand3x3
I1026 15:43:29.585608 37958 net.cpp:413] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1026 15:43:29.585618 37958 net.cpp:387] fire5/expand3x3 -> fire5/expand3x3
I1026 15:43:29.586277 37958 net.cpp:127] Setting up fire5/expand3x3
I1026 15:43:29.586292 37958 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1026 15:43:29.586302 37958 net.cpp:144] Memory required for data: 1200761400
I1026 15:43:29.586309 37958 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1026 15:43:29.586316 37958 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1026 15:43:29.586321 37958 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1026 15:43:29.586328 37958 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1026 15:43:29.586334 37958 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I1026 15:43:29.586345 37958 net.cpp:84] Creating Layer fire5/relu_expand3x3
I1026 15:43:29.586350 37958 net.cpp:413] fire5/relu_expand3x3 <- fire5/expand3x3
I1026 15:43:29.586357 37958 net.cpp:374] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I1026 15:43:29.586568 37958 net.cpp:127] Setting up fire5/relu_expand3x3
I1026 15:43:29.586582 37958 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1026 15:43:29.586589 37958 net.cpp:144] Memory required for data: 1220831800
I1026 15:43:29.586594 37958 layer_factory.hpp:77] Creating layer fire5/concat
I1026 15:43:29.586601 37958 net.cpp:84] Creating Layer fire5/concat
I1026 15:43:29.586607 37958 net.cpp:413] fire5/concat <- fire5/expand1x1
I1026 15:43:29.586613 37958 net.cpp:413] fire5/concat <- fire5/expand3x3
I1026 15:43:29.586619 37958 net.cpp:387] fire5/concat -> fire5/concat
I1026 15:43:29.586654 37958 net.cpp:127] Setting up fire5/concat
I1026 15:43:29.586661 37958 net.cpp:136] Top shape: 50 256 28 28 (10035200)
I1026 15:43:29.586666 37958 net.cpp:144] Memory required for data: 1260972600
I1026 15:43:29.586670 37958 layer_factory.hpp:77] Creating layer pool5
I1026 15:43:29.586681 37958 net.cpp:84] Creating Layer pool5
I1026 15:43:29.586686 37958 net.cpp:413] pool5 <- fire5/concat
I1026 15:43:29.586694 37958 net.cpp:387] pool5 -> pool5
I1026 15:43:29.586745 37958 net.cpp:127] Setting up pool5
I1026 15:43:29.586755 37958 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1026 15:43:29.586760 37958 net.cpp:144] Memory required for data: 1271007800
I1026 15:43:29.586766 37958 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I1026 15:43:29.586776 37958 net.cpp:84] Creating Layer fire6/squeeze1x1
I1026 15:43:29.586783 37958 net.cpp:413] fire6/squeeze1x1 <- pool5
I1026 15:43:29.586792 37958 net.cpp:387] fire6/squeeze1x1 -> fire6/squeeze1x1
I1026 15:43:29.587242 37958 net.cpp:127] Setting up fire6/squeeze1x1
I1026 15:43:29.587258 37958 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1026 15:43:29.587273 37958 net.cpp:144] Memory required for data: 1272889400
I1026 15:43:29.587280 37958 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1026 15:43:29.587286 37958 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1026 15:43:29.587292 37958 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1026 15:43:29.587302 37958 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1026 15:43:29.587309 37958 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I1026 15:43:29.587318 37958 net.cpp:84] Creating Layer fire6/relu_squeeze1x1
I1026 15:43:29.587326 37958 net.cpp:413] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I1026 15:43:29.587334 37958 net.cpp:374] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I1026 15:43:29.587553 37958 net.cpp:127] Setting up fire6/relu_squeeze1x1
I1026 15:43:29.587564 37958 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1026 15:43:29.587569 37958 net.cpp:144] Memory required for data: 1274771000
I1026 15:43:29.587575 37958 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1026 15:43:29.587582 37958 net.cpp:84] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1026 15:43:29.587587 37958 net.cpp:413] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I1026 15:43:29.587599 37958 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1026 15:43:29.587606 37958 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1026 15:43:29.587663 37958 net.cpp:127] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1026 15:43:29.587672 37958 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1026 15:43:29.587678 37958 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1026 15:43:29.587683 37958 net.cpp:144] Memory required for data: 1278534200
I1026 15:43:29.587688 37958 layer_factory.hpp:77] Creating layer fire6/expand1x1
I1026 15:43:29.587702 37958 net.cpp:84] Creating Layer fire6/expand1x1
I1026 15:43:29.587707 37958 net.cpp:413] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1026 15:43:29.587714 37958 net.cpp:387] fire6/expand1x1 -> fire6/expand1x1
I1026 15:43:29.588135 37958 net.cpp:127] Setting up fire6/expand1x1
I1026 15:43:29.588145 37958 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1026 15:43:29.588150 37958 net.cpp:144] Memory required for data: 1286060600
I1026 15:43:29.588156 37958 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1026 15:43:29.588163 37958 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1026 15:43:29.588171 37958 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1026 15:43:29.588176 37958 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1026 15:43:29.588181 37958 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I1026 15:43:29.588188 37958 net.cpp:84] Creating Layer fire6/relu_expand1x1
I1026 15:43:29.588193 37958 net.cpp:413] fire6/relu_expand1x1 <- fire6/expand1x1
I1026 15:43:29.588204 37958 net.cpp:374] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I1026 15:43:29.589593 37958 net.cpp:127] Setting up fire6/relu_expand1x1
I1026 15:43:29.589612 37958 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1026 15:43:29.589617 37958 net.cpp:144] Memory required for data: 1293587000
I1026 15:43:29.589623 37958 layer_factory.hpp:77] Creating layer fire6/expand3x3
I1026 15:43:29.589637 37958 net.cpp:84] Creating Layer fire6/expand3x3
I1026 15:43:29.589645 37958 net.cpp:413] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1026 15:43:29.589655 37958 net.cpp:387] fire6/expand3x3 -> fire6/expand3x3
I1026 15:43:29.593120 37958 net.cpp:127] Setting up fire6/expand3x3
I1026 15:43:29.593137 37958 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1026 15:43:29.593152 37958 net.cpp:144] Memory required for data: 1301113400
I1026 15:43:29.593178 37958 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1026 15:43:29.593190 37958 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1026 15:43:29.593197 37958 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1026 15:43:29.593202 37958 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1026 15:43:29.593209 37958 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I1026 15:43:29.593221 37958 net.cpp:84] Creating Layer fire6/relu_expand3x3
I1026 15:43:29.593227 37958 net.cpp:413] fire6/relu_expand3x3 <- fire6/expand3x3
I1026 15:43:29.593236 37958 net.cpp:374] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I1026 15:43:29.593627 37958 net.cpp:127] Setting up fire6/relu_expand3x3
I1026 15:43:29.593643 37958 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1026 15:43:29.593649 37958 net.cpp:144] Memory required for data: 1308639800
I1026 15:43:29.593657 37958 layer_factory.hpp:77] Creating layer fire6/concat
I1026 15:43:29.593667 37958 net.cpp:84] Creating Layer fire6/concat
I1026 15:43:29.593672 37958 net.cpp:413] fire6/concat <- fire6/expand1x1
I1026 15:43:29.593677 37958 net.cpp:413] fire6/concat <- fire6/expand3x3
I1026 15:43:29.593684 37958 net.cpp:387] fire6/concat -> fire6/concat
I1026 15:43:29.593734 37958 net.cpp:127] Setting up fire6/concat
I1026 15:43:29.593752 37958 net.cpp:136] Top shape: 50 384 14 14 (3763200)
I1026 15:43:29.593756 37958 net.cpp:144] Memory required for data: 1323692600
I1026 15:43:29.593762 37958 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I1026 15:43:29.593780 37958 net.cpp:84] Creating Layer fire7/squeeze1x1
I1026 15:43:29.593787 37958 net.cpp:413] fire7/squeeze1x1 <- fire6/concat
I1026 15:43:29.593794 37958 net.cpp:387] fire7/squeeze1x1 -> fire7/squeeze1x1
I1026 15:43:29.594324 37958 net.cpp:127] Setting up fire7/squeeze1x1
I1026 15:43:29.594338 37958 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1026 15:43:29.594344 37958 net.cpp:144] Memory required for data: 1325574200
I1026 15:43:29.594362 37958 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1026 15:43:29.594372 37958 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1026 15:43:29.594379 37958 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1026 15:43:29.594384 37958 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1026 15:43:29.594390 37958 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I1026 15:43:29.594399 37958 net.cpp:84] Creating Layer fire7/relu_squeeze1x1
I1026 15:43:29.594405 37958 net.cpp:413] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I1026 15:43:29.594413 37958 net.cpp:374] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I1026 15:43:29.594624 37958 net.cpp:127] Setting up fire7/relu_squeeze1x1
I1026 15:43:29.594636 37958 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1026 15:43:29.594641 37958 net.cpp:144] Memory required for data: 1327455800
I1026 15:43:29.594648 37958 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1026 15:43:29.594663 37958 net.cpp:84] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1026 15:43:29.594669 37958 net.cpp:413] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I1026 15:43:29.594676 37958 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1026 15:43:29.594686 37958 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1026 15:43:29.594736 37958 net.cpp:127] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1026 15:43:29.594746 37958 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1026 15:43:29.594753 37958 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1026 15:43:29.594758 37958 net.cpp:144] Memory required for data: 1331219000
I1026 15:43:29.594769 37958 layer_factory.hpp:77] Creating layer fire7/expand1x1
I1026 15:43:29.594792 37958 net.cpp:84] Creating Layer fire7/expand1x1
I1026 15:43:29.594799 37958 net.cpp:413] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1026 15:43:29.594808 37958 net.cpp:387] fire7/expand1x1 -> fire7/expand1x1
I1026 15:43:29.595237 37958 net.cpp:127] Setting up fire7/expand1x1
I1026 15:43:29.595249 37958 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1026 15:43:29.595254 37958 net.cpp:144] Memory required for data: 1338745400
I1026 15:43:29.595260 37958 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1026 15:43:29.595268 37958 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1026 15:43:29.595273 37958 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1026 15:43:29.595279 37958 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1026 15:43:29.595283 37958 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I1026 15:43:29.595290 37958 net.cpp:84] Creating Layer fire7/relu_expand1x1
I1026 15:43:29.595295 37958 net.cpp:413] fire7/relu_expand1x1 <- fire7/expand1x1
I1026 15:43:29.595309 37958 net.cpp:374] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I1026 15:43:29.596784 37958 net.cpp:127] Setting up fire7/relu_expand1x1
I1026 15:43:29.596803 37958 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1026 15:43:29.596812 37958 net.cpp:144] Memory required for data: 1346271800
I1026 15:43:29.596819 37958 layer_factory.hpp:77] Creating layer fire7/expand3x3
I1026 15:43:29.596834 37958 net.cpp:84] Creating Layer fire7/expand3x3
I1026 15:43:29.596840 37958 net.cpp:413] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1026 15:43:29.596851 37958 net.cpp:387] fire7/expand3x3 -> fire7/expand3x3
I1026 15:43:29.597931 37958 net.cpp:127] Setting up fire7/expand3x3
I1026 15:43:29.597949 37958 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1026 15:43:29.597954 37958 net.cpp:144] Memory required for data: 1353798200
I1026 15:43:29.597960 37958 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1026 15:43:29.597967 37958 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1026 15:43:29.597976 37958 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1026 15:43:29.597981 37958 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1026 15:43:29.597986 37958 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I1026 15:43:29.597995 37958 net.cpp:84] Creating Layer fire7/relu_expand3x3
I1026 15:43:29.598001 37958 net.cpp:413] fire7/relu_expand3x3 <- fire7/expand3x3
I1026 15:43:29.598006 37958 net.cpp:374] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I1026 15:43:29.598222 37958 net.cpp:127] Setting up fire7/relu_expand3x3
I1026 15:43:29.598235 37958 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1026 15:43:29.598242 37958 net.cpp:144] Memory required for data: 1361324600
I1026 15:43:29.598248 37958 layer_factory.hpp:77] Creating layer fire7/concat
I1026 15:43:29.598255 37958 net.cpp:84] Creating Layer fire7/concat
I1026 15:43:29.598260 37958 net.cpp:413] fire7/concat <- fire7/expand1x1
I1026 15:43:29.598268 37958 net.cpp:413] fire7/concat <- fire7/expand3x3
I1026 15:43:29.598274 37958 net.cpp:387] fire7/concat -> fire7/concat
I1026 15:43:29.598315 37958 net.cpp:127] Setting up fire7/concat
I1026 15:43:29.598328 37958 net.cpp:136] Top shape: 50 384 14 14 (3763200)
I1026 15:43:29.598335 37958 net.cpp:144] Memory required for data: 1376377400
I1026 15:43:29.598340 37958 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I1026 15:43:29.598353 37958 net.cpp:84] Creating Layer fire8/squeeze1x1
I1026 15:43:29.598358 37958 net.cpp:413] fire8/squeeze1x1 <- fire7/concat
I1026 15:43:29.598368 37958 net.cpp:387] fire8/squeeze1x1 -> fire8/squeeze1x1
I1026 15:43:29.600330 37958 net.cpp:127] Setting up fire8/squeeze1x1
I1026 15:43:29.600356 37958 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1026 15:43:29.600368 37958 net.cpp:144] Memory required for data: 1378886200
I1026 15:43:29.600388 37958 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1026 15:43:29.600395 37958 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1026 15:43:29.600400 37958 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1026 15:43:29.600406 37958 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1026 15:43:29.600410 37958 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I1026 15:43:29.600420 37958 net.cpp:84] Creating Layer fire8/relu_squeeze1x1
I1026 15:43:29.600426 37958 net.cpp:413] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I1026 15:43:29.600435 37958 net.cpp:374] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I1026 15:43:29.600664 37958 net.cpp:127] Setting up fire8/relu_squeeze1x1
I1026 15:43:29.600677 37958 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1026 15:43:29.600682 37958 net.cpp:144] Memory required for data: 1381395000
I1026 15:43:29.600688 37958 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1026 15:43:29.600695 37958 net.cpp:84] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1026 15:43:29.600702 37958 net.cpp:413] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I1026 15:43:29.600710 37958 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1026 15:43:29.600719 37958 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1026 15:43:29.600776 37958 net.cpp:127] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1026 15:43:29.600785 37958 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1026 15:43:29.600792 37958 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1026 15:43:29.600797 37958 net.cpp:144] Memory required for data: 1386412600
I1026 15:43:29.600802 37958 layer_factory.hpp:77] Creating layer fire8/expand1x1
I1026 15:43:29.600814 37958 net.cpp:84] Creating Layer fire8/expand1x1
I1026 15:43:29.600821 37958 net.cpp:413] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1026 15:43:29.600828 37958 net.cpp:387] fire8/expand1x1 -> fire8/expand1x1
I1026 15:43:29.601325 37958 net.cpp:127] Setting up fire8/expand1x1
I1026 15:43:29.601338 37958 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1026 15:43:29.601343 37958 net.cpp:144] Memory required for data: 1396447800
I1026 15:43:29.601349 37958 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1026 15:43:29.601356 37958 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1026 15:43:29.601363 37958 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1026 15:43:29.601371 37958 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1026 15:43:29.601374 37958 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I1026 15:43:29.601382 37958 net.cpp:84] Creating Layer fire8/relu_expand1x1
I1026 15:43:29.601388 37958 net.cpp:413] fire8/relu_expand1x1 <- fire8/expand1x1
I1026 15:43:29.601397 37958 net.cpp:374] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I1026 15:43:29.601614 37958 net.cpp:127] Setting up fire8/relu_expand1x1
I1026 15:43:29.601625 37958 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1026 15:43:29.601631 37958 net.cpp:144] Memory required for data: 1406483000
I1026 15:43:29.601637 37958 layer_factory.hpp:77] Creating layer fire8/expand3x3
I1026 15:43:29.601650 37958 net.cpp:84] Creating Layer fire8/expand3x3
I1026 15:43:29.601656 37958 net.cpp:413] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1026 15:43:29.601666 37958 net.cpp:387] fire8/expand3x3 -> fire8/expand3x3
I1026 15:43:29.604552 37958 net.cpp:127] Setting up fire8/expand3x3
I1026 15:43:29.604571 37958 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1026 15:43:29.604583 37958 net.cpp:144] Memory required for data: 1416518200
I1026 15:43:29.604602 37958 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1026 15:43:29.604610 37958 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1026 15:43:29.604616 37958 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1026 15:43:29.604622 37958 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1026 15:43:29.604626 37958 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I1026 15:43:29.604638 37958 net.cpp:84] Creating Layer fire8/relu_expand3x3
I1026 15:43:29.604645 37958 net.cpp:413] fire8/relu_expand3x3 <- fire8/expand3x3
I1026 15:43:29.604651 37958 net.cpp:374] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I1026 15:43:29.606056 37958 net.cpp:127] Setting up fire8/relu_expand3x3
I1026 15:43:29.606077 37958 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1026 15:43:29.606083 37958 net.cpp:144] Memory required for data: 1426553400
I1026 15:43:29.606089 37958 layer_factory.hpp:77] Creating layer fire8/concat
I1026 15:43:29.606097 37958 net.cpp:84] Creating Layer fire8/concat
I1026 15:43:29.606113 37958 net.cpp:413] fire8/concat <- fire8/expand1x1
I1026 15:43:29.606119 37958 net.cpp:413] fire8/concat <- fire8/expand3x3
I1026 15:43:29.606127 37958 net.cpp:387] fire8/concat -> fire8/concat
I1026 15:43:29.606166 37958 net.cpp:127] Setting up fire8/concat
I1026 15:43:29.606176 37958 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1026 15:43:29.606181 37958 net.cpp:144] Memory required for data: 1446623800
I1026 15:43:29.606186 37958 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I1026 15:43:29.606201 37958 net.cpp:84] Creating Layer fire9/squeeze1x1
I1026 15:43:29.606207 37958 net.cpp:413] fire9/squeeze1x1 <- fire8/concat
I1026 15:43:29.606216 37958 net.cpp:387] fire9/squeeze1x1 -> fire9/squeeze1x1
I1026 15:43:29.606848 37958 net.cpp:127] Setting up fire9/squeeze1x1
I1026 15:43:29.606860 37958 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1026 15:43:29.606865 37958 net.cpp:144] Memory required for data: 1449132600
I1026 15:43:29.606873 37958 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1026 15:43:29.606879 37958 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1026 15:43:29.606885 37958 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1026 15:43:29.606892 37958 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1026 15:43:29.606897 37958 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I1026 15:43:29.606916 37958 net.cpp:84] Creating Layer fire9/relu_squeeze1x1
I1026 15:43:29.606922 37958 net.cpp:413] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I1026 15:43:29.606930 37958 net.cpp:374] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I1026 15:43:29.607148 37958 net.cpp:127] Setting up fire9/relu_squeeze1x1
I1026 15:43:29.607161 37958 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1026 15:43:29.607167 37958 net.cpp:144] Memory required for data: 1451641400
I1026 15:43:29.607172 37958 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1026 15:43:29.607180 37958 net.cpp:84] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1026 15:43:29.607185 37958 net.cpp:413] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I1026 15:43:29.607192 37958 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1026 15:43:29.607200 37958 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1026 15:43:29.607254 37958 net.cpp:127] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1026 15:43:29.607265 37958 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1026 15:43:29.607273 37958 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1026 15:43:29.607280 37958 net.cpp:144] Memory required for data: 1456659000
I1026 15:43:29.607292 37958 layer_factory.hpp:77] Creating layer fire9/expand1x1
I1026 15:43:29.607326 37958 net.cpp:84] Creating Layer fire9/expand1x1
I1026 15:43:29.607333 37958 net.cpp:413] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1026 15:43:29.607344 37958 net.cpp:387] fire9/expand1x1 -> fire9/expand1x1
I1026 15:43:29.607832 37958 net.cpp:127] Setting up fire9/expand1x1
I1026 15:43:29.607847 37958 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1026 15:43:29.607853 37958 net.cpp:144] Memory required for data: 1466694200
I1026 15:43:29.607861 37958 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1026 15:43:29.607867 37958 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1026 15:43:29.607872 37958 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1026 15:43:29.607878 37958 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1026 15:43:29.607883 37958 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I1026 15:43:29.607892 37958 net.cpp:84] Creating Layer fire9/relu_expand1x1
I1026 15:43:29.607897 37958 net.cpp:413] fire9/relu_expand1x1 <- fire9/expand1x1
I1026 15:43:29.607903 37958 net.cpp:374] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I1026 15:43:29.608119 37958 net.cpp:127] Setting up fire9/relu_expand1x1
I1026 15:43:29.608131 37958 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1026 15:43:29.608137 37958 net.cpp:144] Memory required for data: 1476729400
I1026 15:43:29.608144 37958 layer_factory.hpp:77] Creating layer fire9/expand3x3
I1026 15:43:29.608155 37958 net.cpp:84] Creating Layer fire9/expand3x3
I1026 15:43:29.608160 37958 net.cpp:413] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1026 15:43:29.608170 37958 net.cpp:387] fire9/expand3x3 -> fire9/expand3x3
I1026 15:43:29.611071 37958 net.cpp:127] Setting up fire9/expand3x3
I1026 15:43:29.611090 37958 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1026 15:43:29.611095 37958 net.cpp:144] Memory required for data: 1486764600
I1026 15:43:29.611104 37958 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1026 15:43:29.611110 37958 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1026 15:43:29.611119 37958 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1026 15:43:29.611124 37958 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1026 15:43:29.611129 37958 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I1026 15:43:29.611137 37958 net.cpp:84] Creating Layer fire9/relu_expand3x3
I1026 15:43:29.611142 37958 net.cpp:413] fire9/relu_expand3x3 <- fire9/expand3x3
I1026 15:43:29.611151 37958 net.cpp:374] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I1026 15:43:29.611402 37958 net.cpp:127] Setting up fire9/relu_expand3x3
I1026 15:43:29.611415 37958 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1026 15:43:29.611421 37958 net.cpp:144] Memory required for data: 1496799800
I1026 15:43:29.611428 37958 layer_factory.hpp:77] Creating layer fire9/concat
I1026 15:43:29.611438 37958 net.cpp:84] Creating Layer fire9/concat
I1026 15:43:29.611443 37958 net.cpp:413] fire9/concat <- fire9/expand1x1
I1026 15:43:29.611449 37958 net.cpp:413] fire9/concat <- fire9/expand3x3
I1026 15:43:29.611459 37958 net.cpp:387] fire9/concat -> fire9/concat
I1026 15:43:29.611493 37958 net.cpp:127] Setting up fire9/concat
I1026 15:43:29.611505 37958 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1026 15:43:29.611510 37958 net.cpp:144] Memory required for data: 1516870200
I1026 15:43:29.611515 37958 layer_factory.hpp:77] Creating layer drop9
I1026 15:43:29.611524 37958 net.cpp:84] Creating Layer drop9
I1026 15:43:29.611529 37958 net.cpp:413] drop9 <- fire9/concat
I1026 15:43:29.611536 37958 net.cpp:374] drop9 -> fire9/concat (in-place)
I1026 15:43:29.611567 37958 net.cpp:127] Setting up drop9
I1026 15:43:29.611574 37958 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1026 15:43:29.611588 37958 net.cpp:144] Memory required for data: 1536940600
I1026 15:43:29.611611 37958 layer_factory.hpp:77] Creating layer conv10
I1026 15:43:29.611624 37958 net.cpp:84] Creating Layer conv10
I1026 15:43:29.611630 37958 net.cpp:413] conv10 <- fire9/concat
I1026 15:43:29.611640 37958 net.cpp:387] conv10 -> conv10
I1026 15:43:29.621688 37958 net.cpp:127] Setting up conv10
I1026 15:43:29.621712 37958 net.cpp:136] Top shape: 50 1000 14 14 (9800000)
I1026 15:43:29.621718 37958 net.cpp:144] Memory required for data: 1576140600
I1026 15:43:29.621726 37958 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1026 15:43:29.621732 37958 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1026 15:43:29.621740 37958 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1026 15:43:29.621752 37958 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1026 15:43:29.621757 37958 layer_factory.hpp:77] Creating layer relu_conv10
I1026 15:43:29.621767 37958 net.cpp:84] Creating Layer relu_conv10
I1026 15:43:29.621773 37958 net.cpp:413] relu_conv10 <- conv10
I1026 15:43:29.621779 37958 net.cpp:374] relu_conv10 -> conv10 (in-place)
I1026 15:43:29.623188 37958 net.cpp:127] Setting up relu_conv10
I1026 15:43:29.623206 37958 net.cpp:136] Top shape: 50 1000 14 14 (9800000)
I1026 15:43:29.623212 37958 net.cpp:144] Memory required for data: 1615340600
I1026 15:43:29.623217 37958 layer_factory.hpp:77] Creating layer pool10
I1026 15:43:29.623230 37958 net.cpp:84] Creating Layer pool10
I1026 15:43:29.623236 37958 net.cpp:413] pool10 <- conv10
I1026 15:43:29.623245 37958 net.cpp:387] pool10 -> pool10
I1026 15:43:29.623492 37958 net.cpp:127] Setting up pool10
I1026 15:43:29.623507 37958 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1026 15:43:29.623513 37958 net.cpp:144] Memory required for data: 1615540600
I1026 15:43:29.623518 37958 layer_factory.hpp:77] Creating layer pool10_pool10_0_split
I1026 15:43:29.623527 37958 net.cpp:84] Creating Layer pool10_pool10_0_split
I1026 15:43:29.623531 37958 net.cpp:413] pool10_pool10_0_split <- pool10
I1026 15:43:29.623538 37958 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_0
I1026 15:43:29.623549 37958 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_1
I1026 15:43:29.623558 37958 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_2
I1026 15:43:29.623625 37958 net.cpp:127] Setting up pool10_pool10_0_split
I1026 15:43:29.623636 37958 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1026 15:43:29.623641 37958 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1026 15:43:29.623647 37958 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1026 15:43:29.623652 37958 net.cpp:144] Memory required for data: 1616140600
I1026 15:43:29.623656 37958 layer_factory.hpp:77] Creating layer loss
I1026 15:43:29.623667 37958 net.cpp:84] Creating Layer loss
I1026 15:43:29.623672 37958 net.cpp:413] loss <- pool10_pool10_0_split_0
I1026 15:43:29.623678 37958 net.cpp:413] loss <- label_data_1_split_0
I1026 15:43:29.623685 37958 net.cpp:387] loss -> loss
I1026 15:43:29.623695 37958 layer_factory.hpp:77] Creating layer loss
I1026 15:43:29.624049 37958 net.cpp:127] Setting up loss
I1026 15:43:29.624061 37958 net.cpp:136] Top shape: (1)
I1026 15:43:29.624068 37958 net.cpp:139]     with loss weight 1
I1026 15:43:29.624081 37958 net.cpp:144] Memory required for data: 1616140604
I1026 15:43:29.624086 37958 layer_factory.hpp:77] Creating layer accuracy_top1
I1026 15:43:29.624100 37958 net.cpp:84] Creating Layer accuracy_top1
I1026 15:43:29.624106 37958 net.cpp:413] accuracy_top1 <- pool10_pool10_0_split_1
I1026 15:43:29.624114 37958 net.cpp:413] accuracy_top1 <- label_data_1_split_1
I1026 15:43:29.624121 37958 net.cpp:387] accuracy_top1 -> accuracy_top1
I1026 15:43:29.624136 37958 net.cpp:127] Setting up accuracy_top1
I1026 15:43:29.624145 37958 net.cpp:136] Top shape: (1)
I1026 15:43:29.624150 37958 net.cpp:144] Memory required for data: 1616140608
I1026 15:43:29.624155 37958 layer_factory.hpp:77] Creating layer accuracy_top5
I1026 15:43:29.624183 37958 net.cpp:84] Creating Layer accuracy_top5
I1026 15:43:29.624189 37958 net.cpp:413] accuracy_top5 <- pool10_pool10_0_split_2
I1026 15:43:29.624207 37958 net.cpp:413] accuracy_top5 <- label_data_1_split_2
I1026 15:43:29.624218 37958 net.cpp:387] accuracy_top5 -> accuracy_top5
I1026 15:43:29.624238 37958 net.cpp:127] Setting up accuracy_top5
I1026 15:43:29.624244 37958 net.cpp:136] Top shape: (1)
I1026 15:43:29.624249 37958 net.cpp:144] Memory required for data: 1616140612
I1026 15:43:29.624254 37958 net.cpp:207] accuracy_top5 does not need backward computation.
I1026 15:43:29.624259 37958 net.cpp:207] accuracy_top1 does not need backward computation.
I1026 15:43:29.624264 37958 net.cpp:205] loss needs backward computation.
I1026 15:43:29.624270 37958 net.cpp:205] pool10_pool10_0_split needs backward computation.
I1026 15:43:29.624275 37958 net.cpp:205] pool10 needs backward computation.
I1026 15:43:29.624280 37958 net.cpp:205] relu_conv10 needs backward computation.
I1026 15:43:29.624284 37958 net.cpp:205] conv10 needs backward computation.
I1026 15:43:29.624289 37958 net.cpp:205] drop9 needs backward computation.
I1026 15:43:29.624294 37958 net.cpp:205] fire9/concat needs backward computation.
I1026 15:43:29.624305 37958 net.cpp:205] fire9/relu_expand3x3 needs backward computation.
I1026 15:43:29.624310 37958 net.cpp:205] fire9/expand3x3 needs backward computation.
I1026 15:43:29.624315 37958 net.cpp:205] fire9/relu_expand1x1 needs backward computation.
I1026 15:43:29.624320 37958 net.cpp:205] fire9/expand1x1 needs backward computation.
I1026 15:43:29.624325 37958 net.cpp:205] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I1026 15:43:29.624330 37958 net.cpp:205] fire9/relu_squeeze1x1 needs backward computation.
I1026 15:43:29.624336 37958 net.cpp:205] fire9/squeeze1x1 needs backward computation.
I1026 15:43:29.624341 37958 net.cpp:205] fire8/concat needs backward computation.
I1026 15:43:29.624348 37958 net.cpp:205] fire8/relu_expand3x3 needs backward computation.
I1026 15:43:29.624353 37958 net.cpp:205] fire8/expand3x3 needs backward computation.
I1026 15:43:29.624358 37958 net.cpp:205] fire8/relu_expand1x1 needs backward computation.
I1026 15:43:29.624362 37958 net.cpp:205] fire8/expand1x1 needs backward computation.
I1026 15:43:29.624367 37958 net.cpp:205] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I1026 15:43:29.624372 37958 net.cpp:205] fire8/relu_squeeze1x1 needs backward computation.
I1026 15:43:29.624377 37958 net.cpp:205] fire8/squeeze1x1 needs backward computation.
I1026 15:43:29.624382 37958 net.cpp:205] fire7/concat needs backward computation.
I1026 15:43:29.624387 37958 net.cpp:205] fire7/relu_expand3x3 needs backward computation.
I1026 15:43:29.624392 37958 net.cpp:205] fire7/expand3x3 needs backward computation.
I1026 15:43:29.624397 37958 net.cpp:205] fire7/relu_expand1x1 needs backward computation.
I1026 15:43:29.624400 37958 net.cpp:205] fire7/expand1x1 needs backward computation.
I1026 15:43:29.624405 37958 net.cpp:205] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I1026 15:43:29.624409 37958 net.cpp:205] fire7/relu_squeeze1x1 needs backward computation.
I1026 15:43:29.624414 37958 net.cpp:205] fire7/squeeze1x1 needs backward computation.
I1026 15:43:29.624418 37958 net.cpp:205] fire6/concat needs backward computation.
I1026 15:43:29.624423 37958 net.cpp:205] fire6/relu_expand3x3 needs backward computation.
I1026 15:43:29.624428 37958 net.cpp:205] fire6/expand3x3 needs backward computation.
I1026 15:43:29.624433 37958 net.cpp:205] fire6/relu_expand1x1 needs backward computation.
I1026 15:43:29.624438 37958 net.cpp:205] fire6/expand1x1 needs backward computation.
I1026 15:43:29.624442 37958 net.cpp:205] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I1026 15:43:29.624447 37958 net.cpp:205] fire6/relu_squeeze1x1 needs backward computation.
I1026 15:43:29.624451 37958 net.cpp:205] fire6/squeeze1x1 needs backward computation.
I1026 15:43:29.624456 37958 net.cpp:205] pool5 needs backward computation.
I1026 15:43:29.624466 37958 net.cpp:205] fire5/concat needs backward computation.
I1026 15:43:29.624480 37958 net.cpp:205] fire5/relu_expand3x3 needs backward computation.
I1026 15:43:29.624483 37958 net.cpp:205] fire5/expand3x3 needs backward computation.
I1026 15:43:29.624488 37958 net.cpp:205] fire5/relu_expand1x1 needs backward computation.
I1026 15:43:29.624492 37958 net.cpp:205] fire5/expand1x1 needs backward computation.
I1026 15:43:29.624497 37958 net.cpp:205] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I1026 15:43:29.624502 37958 net.cpp:205] fire5/relu_squeeze1x1 needs backward computation.
I1026 15:43:29.624506 37958 net.cpp:205] fire5/squeeze1x1 needs backward computation.
I1026 15:43:29.624511 37958 net.cpp:205] fire4/concat needs backward computation.
I1026 15:43:29.624518 37958 net.cpp:205] fire4/relu_expand3x3 needs backward computation.
I1026 15:43:29.624522 37958 net.cpp:205] fire4/expand3x3 needs backward computation.
I1026 15:43:29.624527 37958 net.cpp:205] fire4/relu_expand1x1 needs backward computation.
I1026 15:43:29.624531 37958 net.cpp:205] fire4/expand1x1 needs backward computation.
I1026 15:43:29.624536 37958 net.cpp:205] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I1026 15:43:29.624541 37958 net.cpp:205] fire4/relu_squeeze1x1 needs backward computation.
I1026 15:43:29.624545 37958 net.cpp:205] fire4/squeeze1x1 needs backward computation.
I1026 15:43:29.624549 37958 net.cpp:205] pool3 needs backward computation.
I1026 15:43:29.624554 37958 net.cpp:205] fire3/concat needs backward computation.
I1026 15:43:29.624559 37958 net.cpp:205] fire3/relu_expand3x3 needs backward computation.
I1026 15:43:29.624563 37958 net.cpp:205] fire3/expand3x3 needs backward computation.
I1026 15:43:29.624568 37958 net.cpp:205] fire3/relu_expand1x1 needs backward computation.
I1026 15:43:29.624572 37958 net.cpp:205] fire3/expand1x1 needs backward computation.
I1026 15:43:29.624577 37958 net.cpp:205] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I1026 15:43:29.624583 37958 net.cpp:205] fire3/relu_squeeze1x1 needs backward computation.
I1026 15:43:29.624586 37958 net.cpp:205] fire3/squeeze1x1 needs backward computation.
I1026 15:43:29.624591 37958 net.cpp:205] fire2/concat needs backward computation.
I1026 15:43:29.624595 37958 net.cpp:205] fire2/relu_expand3x3 needs backward computation.
I1026 15:43:29.624600 37958 net.cpp:205] fire2/expand3x3 needs backward computation.
I1026 15:43:29.624604 37958 net.cpp:205] fire2/relu_expand1x1 needs backward computation.
I1026 15:43:29.624609 37958 net.cpp:205] fire2/expand1x1 needs backward computation.
I1026 15:43:29.624614 37958 net.cpp:205] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I1026 15:43:29.624619 37958 net.cpp:205] fire2/relu_squeeze1x1 needs backward computation.
I1026 15:43:29.624622 37958 net.cpp:205] fire2/squeeze1x1 needs backward computation.
I1026 15:43:29.624627 37958 net.cpp:205] pool1 needs backward computation.
I1026 15:43:29.624632 37958 net.cpp:205] relu_conv1 needs backward computation.
I1026 15:43:29.624636 37958 net.cpp:205] conv1 needs backward computation.
I1026 15:43:29.624642 37958 net.cpp:207] label_data_1_split does not need backward computation.
I1026 15:43:29.624649 37958 net.cpp:207] data does not need backward computation.
I1026 15:43:29.624652 37958 net.cpp:249] This network produces output accuracy_top1
I1026 15:43:29.624657 37958 net.cpp:249] This network produces output accuracy_top5
I1026 15:43:29.624662 37958 net.cpp:249] This network produces output loss
I1026 15:43:29.624723 37958 net.cpp:262] Network initialization done.
I1026 15:43:29.625022 37958 solver.cpp:56] Solver scaffolding done.
I1026 15:43:29.629631 37958 caffe.cpp:155] Finetuning from SqueezeNet/SqueezeNet_v1.1/sqz_inq_raw.caffemodel
I1026 15:43:29.639803 37958 net.cpp:778] Ignoring source layer label_data_1_split
I1026 15:43:29.641782 37958 net.cpp:778] Ignoring source layer pool10_pool10_0_split
I1026 15:43:29.641798 37958 net.cpp:778] Ignoring source layer accuracy_top1
I1026 15:43:29.641813 37958 net.cpp:778] Ignoring source layer accuracy_top5
I1026 15:43:29.648079 37958 caffe.cpp:248] Starting Optimization
I1026 15:43:33.268290 38013 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_20.prototxt
I1026 15:43:33.275192 38012 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_20.prototxt
I1026 15:43:33.407704 38011 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_20.prototxt
I1026 15:43:34.105056 37958 solver.cpp:275] Solving SqueezeNet
I1026 15:43:34.105118 37958 solver.cpp:276] Learning Rate Policy: poly
I1026 15:43:34.105628 37958 solver.cpp:333] Iteration 0, Testing net (#0)
I1026 15:44:05.279274 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.58488
I1026 15:44:05.279503 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.80788
I1026 15:44:05.279518 37958 solver.cpp:400]     Test net output #2: loss = 1.83354 (* 1 = 1.83354 loss)
I1026 15:44:05.279788 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.279850 37958 inq_conv_layer.cpp:260] Max_power = 0
I1026 15:44:05.279857 37958 inq_conv_layer.cpp:261] Min_power = -6
I1026 15:44:05.279881 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.0231%)
I1026 15:44:05.279894 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 1728/1728
I1026 15:44:05.279901 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 346/1382/1728
I1026 15:44:05.280063 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.280102 37958 inq_conv_layer.cpp:260] Max_power = -2
I1026 15:44:05.280112 37958 inq_conv_layer.cpp:261] Min_power = -8
I1026 15:44:05.280119 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.3125%)
I1026 15:44:05.280129 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 64/64
I1026 15:44:05.280134 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 13/51/64
I1026 15:44:05.293231 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.310842 37958 inq_conv_layer.cpp:260] Max_power = 0
I1026 15:44:05.310853 37958 inq_conv_layer.cpp:261] Min_power = -6
I1026 15:44:05.310883 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.0195%)
I1026 15:44:05.310899 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 1024/1024
I1026 15:44:05.310904 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 205/819/1024
I1026 15:44:05.310999 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.311031 37958 inq_conv_layer.cpp:260] Max_power = -2
I1026 15:44:05.311043 37958 inq_conv_layer.cpp:261] Min_power = -8
I1026 15:44:05.311050 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 18.75%)
I1026 15:44:05.311060 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 16/16
I1026 15:44:05.311065 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 3/13/16
I1026 15:44:05.314498 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.314846 37958 inq_conv_layer.cpp:260] Max_power = 0
I1026 15:44:05.314854 37958 inq_conv_layer.cpp:261] Min_power = -6
I1026 15:44:05.314877 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.0195%)
I1026 15:44:05.314890 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 1024/1024
I1026 15:44:05.314895 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 205/819/1024
I1026 15:44:05.314993 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.315023 37958 inq_conv_layer.cpp:260] Max_power = -3
I1026 15:44:05.315030 37958 inq_conv_layer.cpp:261] Min_power = -9
I1026 15:44:05.315038 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.3125%)
I1026 15:44:05.315048 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 64/64
I1026 15:44:05.315068 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 13/51/64
I1026 15:44:05.319116 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.320309 37958 inq_conv_layer.cpp:260] Max_power = -1
I1026 15:44:05.320319 37958 inq_conv_layer.cpp:261] Min_power = -7
I1026 15:44:05.320461 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 19.9978%)
I1026 15:44:05.320477 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 9216/9216
I1026 15:44:05.320482 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 1843/7373/9216
I1026 15:44:05.321472 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.321529 37958 inq_conv_layer.cpp:260] Max_power = -4
I1026 15:44:05.321537 37958 inq_conv_layer.cpp:261] Min_power = -10
I1026 15:44:05.321545 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.3125%)
I1026 15:44:05.321570 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 64/64
I1026 15:44:05.321575 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 13/51/64
I1026 15:44:05.330648 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.334166 37958 inq_conv_layer.cpp:260] Max_power = 0
I1026 15:44:05.334175 37958 inq_conv_layer.cpp:261] Min_power = -6
I1026 15:44:05.334192 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.0195%)
I1026 15:44:05.334204 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 2048/2048
I1026 15:44:05.334210 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 410/1638/2048
I1026 15:44:05.334414 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.334453 37958 inq_conv_layer.cpp:260] Max_power = -2
I1026 15:44:05.334463 37958 inq_conv_layer.cpp:261] Min_power = -8
I1026 15:44:05.334470 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 18.75%)
I1026 15:44:05.334481 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 16/16
I1026 15:44:05.334484 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 3/13/16
I1026 15:44:05.337838 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.338675 37958 inq_conv_layer.cpp:260] Max_power = 0
I1026 15:44:05.338685 37958 inq_conv_layer.cpp:261] Min_power = -6
I1026 15:44:05.338698 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.0195%)
I1026 15:44:05.338711 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 1024/1024
I1026 15:44:05.338716 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 205/819/1024
I1026 15:44:05.338811 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.338841 37958 inq_conv_layer.cpp:260] Max_power = -2
I1026 15:44:05.338847 37958 inq_conv_layer.cpp:261] Min_power = -8
I1026 15:44:05.338855 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.3125%)
I1026 15:44:05.338865 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 64/64
I1026 15:44:05.338868 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 13/51/64
I1026 15:44:05.342859 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.344066 37958 inq_conv_layer.cpp:260] Max_power = 0
I1026 15:44:05.344076 37958 inq_conv_layer.cpp:261] Min_power = -6
I1026 15:44:05.344158 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 19.9978%)
I1026 15:44:05.344173 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 9216/9216
I1026 15:44:05.344178 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 1843/7373/9216
I1026 15:44:05.345160 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.345196 37958 inq_conv_layer.cpp:260] Max_power = -3
I1026 15:44:05.345202 37958 inq_conv_layer.cpp:261] Min_power = -9
I1026 15:44:05.345211 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.3125%)
I1026 15:44:05.345221 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 64/64
I1026 15:44:05.345232 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 13/51/64
I1026 15:44:05.357564 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.359989 37958 inq_conv_layer.cpp:260] Max_power = 0
I1026 15:44:05.359999 37958 inq_conv_layer.cpp:261] Min_power = -6
I1026 15:44:05.360024 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 19.9951%)
I1026 15:44:05.360038 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 4096/4096
I1026 15:44:05.360043 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 819/3277/4096
I1026 15:44:05.360466 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.360504 37958 inq_conv_layer.cpp:260] Max_power = -3
I1026 15:44:05.360518 37958 inq_conv_layer.cpp:261] Min_power = -9
I1026 15:44:05.360525 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 18.75%)
I1026 15:44:05.360548 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 32/32
I1026 15:44:05.360553 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 6/26/32
I1026 15:44:05.364056 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.365227 37958 inq_conv_layer.cpp:260] Max_power = -1
I1026 15:44:05.365237 37958 inq_conv_layer.cpp:261] Min_power = -7
I1026 15:44:05.365262 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 19.9951%)
I1026 15:44:05.365275 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 4096/4096
I1026 15:44:05.365279 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 819/3277/4096
I1026 15:44:05.365703 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.365736 37958 inq_conv_layer.cpp:260] Max_power = -4
I1026 15:44:05.365743 37958 inq_conv_layer.cpp:261] Min_power = -10
I1026 15:44:05.365751 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.3125%)
I1026 15:44:05.365761 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 128/128
I1026 15:44:05.365766 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 26/102/128
I1026 15:44:05.369514 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.370321 37958 inq_conv_layer.cpp:260] Max_power = -1
I1026 15:44:05.370332 37958 inq_conv_layer.cpp:261] Min_power = -7
I1026 15:44:05.370856 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.0005%)
I1026 15:44:05.370870 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 36864/36864
I1026 15:44:05.370875 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 7373/29491/36864
I1026 15:44:05.375183 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.375231 37958 inq_conv_layer.cpp:260] Max_power = -4
I1026 15:44:05.375241 37958 inq_conv_layer.cpp:261] Min_power = -10
I1026 15:44:05.375248 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.3125%)
I1026 15:44:05.375259 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 128/128
I1026 15:44:05.375264 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 26/102/128
I1026 15:44:05.381705 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.383978 37958 inq_conv_layer.cpp:260] Max_power = -1
I1026 15:44:05.383988 37958 inq_conv_layer.cpp:261] Min_power = -7
I1026 15:44:05.384028 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 19.9951%)
I1026 15:44:05.384043 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 8192/8192
I1026 15:44:05.384048 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 1638/6554/8192
I1026 15:44:05.384932 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.384966 37958 inq_conv_layer.cpp:260] Max_power = -2
I1026 15:44:05.384974 37958 inq_conv_layer.cpp:261] Min_power = -8
I1026 15:44:05.384981 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 18.75%)
I1026 15:44:05.384990 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 32/32
I1026 15:44:05.385010 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 6/26/32
I1026 15:44:05.389958 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.391937 37958 inq_conv_layer.cpp:260] Max_power = -1
I1026 15:44:05.391947 37958 inq_conv_layer.cpp:261] Min_power = -7
I1026 15:44:05.391971 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 19.9951%)
I1026 15:44:05.391985 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 4096/4096
I1026 15:44:05.391990 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 819/3277/4096
I1026 15:44:05.392407 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.392447 37958 inq_conv_layer.cpp:260] Max_power = -3
I1026 15:44:05.392457 37958 inq_conv_layer.cpp:261] Min_power = -9
I1026 15:44:05.392465 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.3125%)
I1026 15:44:05.392489 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 128/128
I1026 15:44:05.392494 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 26/102/128
I1026 15:44:05.396229 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.397063 37958 inq_conv_layer.cpp:260] Max_power = 0
I1026 15:44:05.397073 37958 inq_conv_layer.cpp:261] Min_power = -6
I1026 15:44:05.397276 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.0005%)
I1026 15:44:05.397291 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 36864/36864
I1026 15:44:05.397300 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 7373/29491/36864
I1026 15:44:05.401599 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.401646 37958 inq_conv_layer.cpp:260] Max_power = -5
I1026 15:44:05.401655 37958 inq_conv_layer.cpp:261] Min_power = -11
I1026 15:44:05.401664 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.3125%)
I1026 15:44:05.401674 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 128/128
I1026 15:44:05.401679 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 26/102/128
I1026 15:44:05.411479 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.412400 37958 inq_conv_layer.cpp:260] Max_power = -1
I1026 15:44:05.412410 37958 inq_conv_layer.cpp:261] Min_power = -7
I1026 15:44:05.412464 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.0033%)
I1026 15:44:05.412479 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 12288/12288
I1026 15:44:05.412485 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 2458/9830/12288
I1026 15:44:05.413830 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.413866 37958 inq_conv_layer.cpp:260] Max_power = -3
I1026 15:44:05.413873 37958 inq_conv_layer.cpp:261] Min_power = -9
I1026 15:44:05.413880 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.8333%)
I1026 15:44:05.413892 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 48/48
I1026 15:44:05.413895 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 10/38/48
I1026 15:44:05.417531 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.419912 37958 inq_conv_layer.cpp:260] Max_power = -1
I1026 15:44:05.419922 37958 inq_conv_layer.cpp:261] Min_power = -7
I1026 15:44:05.419966 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 19.9978%)
I1026 15:44:05.419981 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 9216/9216
I1026 15:44:05.419986 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 1843/7373/9216
I1026 15:44:05.420967 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.421002 37958 inq_conv_layer.cpp:260] Max_power = -5
I1026 15:44:05.421010 37958 inq_conv_layer.cpp:261] Min_power = -11
I1026 15:44:05.421018 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 19.7917%)
I1026 15:44:05.421030 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 192/192
I1026 15:44:05.421041 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 38/154/192
I1026 15:44:05.424574 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.425285 37958 inq_conv_layer.cpp:260] Max_power = -1
I1026 15:44:05.425294 37958 inq_conv_layer.cpp:261] Min_power = -7
I1026 15:44:05.426116 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.0002%)
I1026 15:44:05.426132 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 82944/82944
I1026 15:44:05.426137 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 16589/66355/82944
I1026 15:44:05.436250 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.436301 37958 inq_conv_layer.cpp:260] Max_power = -5
I1026 15:44:05.436314 37958 inq_conv_layer.cpp:261] Min_power = -11
I1026 15:44:05.436323 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 19.7917%)
I1026 15:44:05.436347 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 192/192
I1026 15:44:05.436352 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 38/154/192
I1026 15:44:05.442584 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.444658 37958 inq_conv_layer.cpp:260] Max_power = -1
I1026 15:44:05.444669 37958 inq_conv_layer.cpp:261] Min_power = -7
I1026 15:44:05.444748 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 19.9978%)
I1026 15:44:05.444764 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 18432/18432
I1026 15:44:05.444769 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 3686/14746/18432
I1026 15:44:05.446851 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.446885 37958 inq_conv_layer.cpp:260] Max_power = -2
I1026 15:44:05.446892 37958 inq_conv_layer.cpp:261] Min_power = -8
I1026 15:44:05.446900 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.8333%)
I1026 15:44:05.446910 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 48/48
I1026 15:44:05.446915 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 10/38/48
I1026 15:44:05.450438 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.454016 37958 inq_conv_layer.cpp:260] Max_power = -1
I1026 15:44:05.454026 37958 inq_conv_layer.cpp:261] Min_power = -7
I1026 15:44:05.454072 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 19.9978%)
I1026 15:44:05.454087 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 9216/9216
I1026 15:44:05.454092 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 1843/7373/9216
I1026 15:44:05.455082 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.455116 37958 inq_conv_layer.cpp:260] Max_power = -2
I1026 15:44:05.455123 37958 inq_conv_layer.cpp:261] Min_power = -8
I1026 15:44:05.455132 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 19.7917%)
I1026 15:44:05.455142 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 192/192
I1026 15:44:05.455147 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 38/154/192
I1026 15:44:05.458655 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.459388 37958 inq_conv_layer.cpp:260] Max_power = -1
I1026 15:44:05.459398 37958 inq_conv_layer.cpp:261] Min_power = -7
I1026 15:44:05.459769 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.0002%)
I1026 15:44:05.459784 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 82944/82944
I1026 15:44:05.459789 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 16589/66355/82944
I1026 15:44:05.469883 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.469941 37958 inq_conv_layer.cpp:260] Max_power = -4
I1026 15:44:05.469951 37958 inq_conv_layer.cpp:261] Min_power = -10
I1026 15:44:05.469959 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 19.7917%)
I1026 15:44:05.469977 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 192/192
I1026 15:44:05.469981 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 38/154/192
I1026 15:44:05.476176 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.478293 37958 inq_conv_layer.cpp:260] Max_power = -1
I1026 15:44:05.478307 37958 inq_conv_layer.cpp:261] Min_power = -7
I1026 15:44:05.478406 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 19.9992%)
I1026 15:44:05.478421 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 24576/24576
I1026 15:44:05.478426 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 4915/19661/24576
I1026 15:44:05.481221 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.481256 37958 inq_conv_layer.cpp:260] Max_power = 3
I1026 15:44:05.481263 37958 inq_conv_layer.cpp:261] Min_power = -3
I1026 15:44:05.481284 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.3125%)
I1026 15:44:05.481303 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 64/64
I1026 15:44:05.481310 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 13/51/64
I1026 15:44:05.484833 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.488507 37958 inq_conv_layer.cpp:260] Max_power = -1
I1026 15:44:05.488517 37958 inq_conv_layer.cpp:261] Min_power = -7
I1026 15:44:05.488585 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.0012%)
I1026 15:44:05.488600 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 16384/16384
I1026 15:44:05.488605 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 3277/13107/16384
I1026 15:44:05.490434 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.490469 37958 inq_conv_layer.cpp:260] Max_power = -1
I1026 15:44:05.490478 37958 inq_conv_layer.cpp:261] Min_power = -7
I1026 15:44:05.490485 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 19.9219%)
I1026 15:44:05.490496 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 256/256
I1026 15:44:05.490500 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 51/205/256
I1026 15:44:05.494050 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.495172 37958 inq_conv_layer.cpp:260] Max_power = -1
I1026 15:44:05.495183 37958 inq_conv_layer.cpp:261] Min_power = -7
I1026 15:44:05.496592 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 19.9999%)
I1026 15:44:05.496608 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 147456/147456
I1026 15:44:05.496613 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 29491/117965/147456
I1026 15:44:05.515354 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.515393 37958 inq_conv_layer.cpp:260] Max_power = -1
I1026 15:44:05.515400 37958 inq_conv_layer.cpp:261] Min_power = -7
I1026 15:44:05.515409 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 19.9219%)
I1026 15:44:05.515420 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 256/256
I1026 15:44:05.515424 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 51/205/256
I1026 15:44:05.522325 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.526037 37958 inq_conv_layer.cpp:260] Max_power = -1
I1026 15:44:05.526047 37958 inq_conv_layer.cpp:261] Min_power = -7
I1026 15:44:05.526175 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.0012%)
I1026 15:44:05.526190 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 32768/32768
I1026 15:44:05.526196 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 6554/26214/32768
I1026 15:44:05.529965 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.530000 37958 inq_conv_layer.cpp:260] Max_power = 0
I1026 15:44:05.530009 37958 inq_conv_layer.cpp:261] Min_power = -6
I1026 15:44:05.530016 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.3125%)
I1026 15:44:05.530033 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 64/64
I1026 15:44:05.530038 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 13/51/64
I1026 15:44:05.533552 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.538455 37958 inq_conv_layer.cpp:260] Max_power = -1
I1026 15:44:05.538467 37958 inq_conv_layer.cpp:261] Min_power = -7
I1026 15:44:05.538537 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20.0012%)
I1026 15:44:05.538552 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 16384/16384
I1026 15:44:05.538558 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 3277/13107/16384
I1026 15:44:05.540377 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.540421 37958 inq_conv_layer.cpp:260] Max_power = -4
I1026 15:44:05.540442 37958 inq_conv_layer.cpp:261] Min_power = -10
I1026 15:44:05.540452 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 19.9219%)
I1026 15:44:05.540463 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 256/256
I1026 15:44:05.540467 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 51/205/256
I1026 15:44:05.544045 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.545135 37958 inq_conv_layer.cpp:260] Max_power = -1
I1026 15:44:05.545145 37958 inq_conv_layer.cpp:261] Min_power = -7
I1026 15:44:05.545776 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 19.9999%)
I1026 15:44:05.545792 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 147456/147456
I1026 15:44:05.545797 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 29491/117965/147456
I1026 15:44:05.564477 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.564517 37958 inq_conv_layer.cpp:260] Max_power = -5
I1026 15:44:05.564523 37958 inq_conv_layer.cpp:261] Min_power = -11
I1026 15:44:05.564532 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 19.9219%)
I1026 15:44:05.564543 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 256/256
I1026 15:44:05.564548 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 51/205/256
I1026 15:44:05.578660 37958 inq_conv_layer.cu:52] INQConvolution Shaping the weights...
I1026 15:44:05.580618 37958 inq_conv_layer.cpp:260] Max_power = -2
I1026 15:44:05.580629 37958 inq_conv_layer.cpp:261] Min_power = -8
I1026 15:44:05.585085 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20%)
I1026 15:44:05.585103 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 512000/512000
I1026 15:44:05.585108 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 102400/409600/512000
I1026 15:44:05.655128 37958 inq_conv_layer.cu:60] INQConvolution Shaping the bias...
I1026 15:44:05.655175 37958 inq_conv_layer.cpp:260] Max_power = -2
I1026 15:44:05.655182 37958 inq_conv_layer.cpp:261] Min_power = -8
I1026 15:44:05.655197 37958 inq_conv_layer.cpp:304] portions: 0% -> 20% (total: 0% -> 20%)
I1026 15:44:05.655207 37958 inq_conv_layer.cpp:310] init_not_quantized/total: 1000/1000
I1026 15:44:05.655212 37958 inq_conv_layer.cpp:313] to_update/not_tobe_quantized/not_yet_quantized: 200/800/1000
I1026 15:44:06.509019 37958 solver.cpp:221] Iteration 0 (0 iter/s, 32.4017s/40 iters), loss = 4.5812
I1026 15:44:06.509063 37958 solver.cpp:240]     Train net output #0: loss = 4.5812 (* 1 = 4.5812 loss)
I1026 15:44:06.509076 37958 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I1026 15:44:36.049767 37958 solver.cpp:221] Iteration 40 (1.35411 iter/s, 29.5396s/40 iters), loss = 2.53099
I1026 15:44:36.049993 37958 solver.cpp:240]     Train net output #0: loss = 2.53099 (* 1 = 2.53099 loss)
I1026 15:44:36.050012 37958 sgd_solver.cpp:105] Iteration 40, lr = 0.00999765
I1026 15:45:06.899174 37958 solver.cpp:221] Iteration 80 (1.29668 iter/s, 30.848s/40 iters), loss = 2.32818
I1026 15:45:06.899441 37958 solver.cpp:240]     Train net output #0: loss = 2.32818 (* 1 = 2.32818 loss)
I1026 15:45:06.899474 37958 sgd_solver.cpp:105] Iteration 80, lr = 0.00999529
I1026 15:45:37.517259 37958 solver.cpp:221] Iteration 120 (1.30648 iter/s, 30.6167s/40 iters), loss = 2.23136
I1026 15:45:37.517443 37958 solver.cpp:240]     Train net output #0: loss = 2.23136 (* 1 = 2.23136 loss)
I1026 15:45:37.517462 37958 sgd_solver.cpp:105] Iteration 120, lr = 0.00999294
I1026 15:46:08.206727 37958 solver.cpp:221] Iteration 160 (1.30344 iter/s, 30.6881s/40 iters), loss = 1.85002
I1026 15:46:08.206899 37958 solver.cpp:240]     Train net output #0: loss = 1.85002 (* 1 = 1.85002 loss)
I1026 15:46:08.206918 37958 sgd_solver.cpp:105] Iteration 160, lr = 0.00999059
I1026 15:46:38.907925 37958 solver.cpp:221] Iteration 200 (1.30294 iter/s, 30.6999s/40 iters), loss = 1.97863
I1026 15:46:38.908114 37958 solver.cpp:240]     Train net output #0: loss = 1.97863 (* 1 = 1.97863 loss)
I1026 15:46:38.908138 37958 sgd_solver.cpp:105] Iteration 200, lr = 0.00998824
I1026 15:47:09.630698 37958 solver.cpp:221] Iteration 240 (1.30202 iter/s, 30.7214s/40 iters), loss = 1.86286
I1026 15:47:09.630890 37958 solver.cpp:240]     Train net output #0: loss = 1.86286 (* 1 = 1.86286 loss)
I1026 15:47:09.630908 37958 sgd_solver.cpp:105] Iteration 240, lr = 0.00998588
I1026 15:47:40.523964 37958 solver.cpp:221] Iteration 280 (1.29484 iter/s, 30.8919s/40 iters), loss = 1.93
I1026 15:47:40.524155 37958 solver.cpp:240]     Train net output #0: loss = 1.93 (* 1 = 1.93 loss)
I1026 15:47:40.524171 37958 sgd_solver.cpp:105] Iteration 280, lr = 0.00998353
I1026 15:48:11.139632 37958 solver.cpp:221] Iteration 320 (1.30658 iter/s, 30.6143s/40 iters), loss = 2.12225
I1026 15:48:11.139818 37958 solver.cpp:240]     Train net output #0: loss = 2.12225 (* 1 = 2.12225 loss)
I1026 15:48:11.139834 37958 sgd_solver.cpp:105] Iteration 320, lr = 0.00998118
I1026 15:48:41.727114 37958 solver.cpp:221] Iteration 360 (1.30778 iter/s, 30.5861s/40 iters), loss = 1.85719
I1026 15:48:41.727283 37958 solver.cpp:240]     Train net output #0: loss = 1.85719 (* 1 = 1.85719 loss)
I1026 15:48:41.727303 37958 sgd_solver.cpp:105] Iteration 360, lr = 0.00997882
I1026 15:49:12.271253 37958 solver.cpp:221] Iteration 400 (1.30964 iter/s, 30.5428s/40 iters), loss = 2.0165
I1026 15:49:12.271425 37958 solver.cpp:240]     Train net output #0: loss = 2.0165 (* 1 = 2.0165 loss)
I1026 15:49:12.271440 37958 sgd_solver.cpp:105] Iteration 400, lr = 0.00997647
I1026 15:49:42.748914 37958 solver.cpp:221] Iteration 440 (1.31249 iter/s, 30.4763s/40 iters), loss = 1.93256
I1026 15:49:42.749127 37958 solver.cpp:240]     Train net output #0: loss = 1.93256 (* 1 = 1.93256 loss)
I1026 15:49:42.749143 37958 sgd_solver.cpp:105] Iteration 440, lr = 0.00997412
I1026 15:50:13.389503 37958 solver.cpp:221] Iteration 480 (1.30552 iter/s, 30.6392s/40 iters), loss = 1.80341
I1026 15:50:13.389708 37958 solver.cpp:240]     Train net output #0: loss = 1.80341 (* 1 = 1.80341 loss)
I1026 15:50:13.389724 37958 sgd_solver.cpp:105] Iteration 480, lr = 0.00997176
I1026 15:50:28.040223 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_500.caffemodel
I1026 15:50:28.118726 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_500.solverstate
I1026 15:50:28.136857 37958 solver.cpp:333] Iteration 500, Testing net (#0)
I1026 15:50:58.883054 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 15:50:59.061000 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.49332
I1026 15:50:59.061048 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.7468
I1026 15:50:59.061060 37958 solver.cpp:400]     Test net output #2: loss = 2.25443 (* 1 = 2.25443 loss)
I1026 15:51:14.969326 37958 solver.cpp:221] Iteration 520 (0.64959 iter/s, 61.5773s/40 iters), loss = 1.96816
I1026 15:51:14.969388 37958 solver.cpp:240]     Train net output #0: loss = 1.96816 (* 1 = 1.96816 loss)
I1026 15:51:14.969403 37958 sgd_solver.cpp:105] Iteration 520, lr = 0.00996941
I1026 15:51:45.655043 37958 solver.cpp:221] Iteration 560 (1.30359 iter/s, 30.6845s/40 iters), loss = 2.35766
I1026 15:51:45.655319 37958 solver.cpp:240]     Train net output #0: loss = 2.35766 (* 1 = 2.35766 loss)
I1026 15:51:45.655338 37958 sgd_solver.cpp:105] Iteration 560, lr = 0.00996706
I1026 15:52:16.226013 37958 solver.cpp:221] Iteration 600 (1.30849 iter/s, 30.5695s/40 iters), loss = 1.93493
I1026 15:52:16.226207 37958 solver.cpp:240]     Train net output #0: loss = 1.93493 (* 1 = 1.93493 loss)
I1026 15:52:16.226222 37958 sgd_solver.cpp:105] Iteration 600, lr = 0.00996471
I1026 15:52:46.836805 37958 solver.cpp:221] Iteration 640 (1.30679 iter/s, 30.6094s/40 iters), loss = 1.7655
I1026 15:52:46.836995 37958 solver.cpp:240]     Train net output #0: loss = 1.7655 (* 1 = 1.7655 loss)
I1026 15:52:46.837013 37958 sgd_solver.cpp:105] Iteration 640, lr = 0.00996235
I1026 15:53:17.398380 37958 solver.cpp:221] Iteration 680 (1.30889 iter/s, 30.5602s/40 iters), loss = 2.1118
I1026 15:53:17.398591 37958 solver.cpp:240]     Train net output #0: loss = 2.1118 (* 1 = 2.1118 loss)
I1026 15:53:17.398608 37958 sgd_solver.cpp:105] Iteration 680, lr = 0.00996
I1026 15:53:48.016762 37958 solver.cpp:221] Iteration 720 (1.30646 iter/s, 30.617s/40 iters), loss = 2.13215
I1026 15:53:48.016957 37958 solver.cpp:240]     Train net output #0: loss = 2.13215 (* 1 = 2.13215 loss)
I1026 15:53:48.016975 37958 sgd_solver.cpp:105] Iteration 720, lr = 0.00995765
I1026 15:54:18.556988 37958 solver.cpp:221] Iteration 760 (1.30981 iter/s, 30.5389s/40 iters), loss = 2.03061
I1026 15:54:18.557191 37958 solver.cpp:240]     Train net output #0: loss = 2.03061 (* 1 = 2.03061 loss)
I1026 15:54:18.557207 37958 sgd_solver.cpp:105] Iteration 760, lr = 0.00995529
I1026 15:54:49.208242 37958 solver.cpp:221] Iteration 800 (1.30506 iter/s, 30.6499s/40 iters), loss = 1.85165
I1026 15:54:49.208452 37958 solver.cpp:240]     Train net output #0: loss = 1.85165 (* 1 = 1.85165 loss)
I1026 15:54:49.208469 37958 sgd_solver.cpp:105] Iteration 800, lr = 0.00995294
I1026 15:55:19.957634 37958 solver.cpp:221] Iteration 840 (1.3009 iter/s, 30.748s/40 iters), loss = 2.03425
I1026 15:55:19.957845 37958 solver.cpp:240]     Train net output #0: loss = 2.03425 (* 1 = 2.03425 loss)
I1026 15:55:19.957862 37958 sgd_solver.cpp:105] Iteration 840, lr = 0.00995059
I1026 15:55:50.653478 37958 solver.cpp:221] Iteration 880 (1.30317 iter/s, 30.6945s/40 iters), loss = 2.07552
I1026 15:55:50.653677 37958 solver.cpp:240]     Train net output #0: loss = 2.07552 (* 1 = 2.07552 loss)
I1026 15:55:50.653694 37958 sgd_solver.cpp:105] Iteration 880, lr = 0.00994824
I1026 15:56:21.517051 37958 solver.cpp:221] Iteration 920 (1.29608 iter/s, 30.8622s/40 iters), loss = 1.7973
I1026 15:56:21.517238 37958 solver.cpp:240]     Train net output #0: loss = 1.7973 (* 1 = 1.7973 loss)
I1026 15:56:21.517256 37958 sgd_solver.cpp:105] Iteration 920, lr = 0.00994588
I1026 15:56:51.793166 37958 solver.cpp:221] Iteration 960 (1.32123 iter/s, 30.2748s/40 iters), loss = 1.94142
I1026 15:56:51.793368 37958 solver.cpp:240]     Train net output #0: loss = 1.94142 (* 1 = 1.94142 loss)
I1026 15:56:51.793385 37958 sgd_solver.cpp:105] Iteration 960, lr = 0.00994353
I1026 15:57:21.277966 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_1000.caffemodel
I1026 15:57:21.310950 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_1000.solverstate
I1026 15:57:21.328631 37958 solver.cpp:333] Iteration 1000, Testing net (#0)
I1026 15:57:52.525831 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.51088
I1026 15:57:52.526027 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.7552
I1026 15:57:52.526042 37958 solver.cpp:400]     Test net output #2: loss = 2.21895 (* 1 = 2.21895 loss)
I1026 15:57:53.287088 37958 solver.cpp:221] Iteration 1000 (0.650497 iter/s, 61.4914s/40 iters), loss = 1.32417
I1026 15:57:53.287153 37958 solver.cpp:240]     Train net output #0: loss = 1.32417 (* 1 = 1.32417 loss)
I1026 15:57:53.287179 37958 sgd_solver.cpp:105] Iteration 1000, lr = 0.00994118
I1026 15:58:24.573256 37958 solver.cpp:221] Iteration 1040 (1.27857 iter/s, 31.2849s/40 iters), loss = 2.26695
I1026 15:58:24.573468 37958 solver.cpp:240]     Train net output #0: loss = 2.26695 (* 1 = 2.26695 loss)
I1026 15:58:24.573487 37958 sgd_solver.cpp:105] Iteration 1040, lr = 0.00993882
I1026 15:58:55.043067 37958 solver.cpp:221] Iteration 1080 (1.31283 iter/s, 30.4684s/40 iters), loss = 2.11223
I1026 15:58:55.043274 37958 solver.cpp:240]     Train net output #0: loss = 2.11223 (* 1 = 2.11223 loss)
I1026 15:58:55.043292 37958 sgd_solver.cpp:105] Iteration 1080, lr = 0.00993647
I1026 15:59:25.423408 37958 solver.cpp:221] Iteration 1120 (1.3167 iter/s, 30.379s/40 iters), loss = 1.95882
I1026 15:59:25.423599 37958 solver.cpp:240]     Train net output #0: loss = 1.95882 (* 1 = 1.95882 loss)
I1026 15:59:25.423614 37958 sgd_solver.cpp:105] Iteration 1120, lr = 0.00993412
I1026 15:59:55.898561 37958 solver.cpp:221] Iteration 1160 (1.3126 iter/s, 30.4738s/40 iters), loss = 1.82797
I1026 15:59:55.898748 37958 solver.cpp:240]     Train net output #0: loss = 1.82797 (* 1 = 1.82797 loss)
I1026 15:59:55.898766 37958 sgd_solver.cpp:105] Iteration 1160, lr = 0.00993176
I1026 16:00:26.802945 37958 solver.cpp:221] Iteration 1200 (1.29437 iter/s, 30.903s/40 iters), loss = 1.64805
I1026 16:00:26.803140 37958 solver.cpp:240]     Train net output #0: loss = 1.64805 (* 1 = 1.64805 loss)
I1026 16:00:26.803158 37958 sgd_solver.cpp:105] Iteration 1200, lr = 0.00992941
I1026 16:00:57.311976 37958 solver.cpp:221] Iteration 1240 (1.31115 iter/s, 30.5077s/40 iters), loss = 1.8219
I1026 16:00:57.312186 37958 solver.cpp:240]     Train net output #0: loss = 1.8219 (* 1 = 1.8219 loss)
I1026 16:00:57.312208 37958 sgd_solver.cpp:105] Iteration 1240, lr = 0.00992706
I1026 16:01:27.860867 37958 solver.cpp:221] Iteration 1280 (1.30943 iter/s, 30.5475s/40 iters), loss = 1.86082
I1026 16:01:27.861068 37958 solver.cpp:240]     Train net output #0: loss = 1.86082 (* 1 = 1.86082 loss)
I1026 16:01:27.861083 37958 sgd_solver.cpp:105] Iteration 1280, lr = 0.00992471
I1026 16:01:58.373706 37958 solver.cpp:221] Iteration 1320 (1.31098 iter/s, 30.5115s/40 iters), loss = 1.987
I1026 16:01:58.373908 37958 solver.cpp:240]     Train net output #0: loss = 1.987 (* 1 = 1.987 loss)
I1026 16:01:58.373925 37958 sgd_solver.cpp:105] Iteration 1320, lr = 0.00992235
I1026 16:02:29.403461 37958 solver.cpp:221] Iteration 1360 (1.28914 iter/s, 31.0284s/40 iters), loss = 2.0862
I1026 16:02:29.403636 37958 solver.cpp:240]     Train net output #0: loss = 2.0862 (* 1 = 2.0862 loss)
I1026 16:02:29.403653 37958 sgd_solver.cpp:105] Iteration 1360, lr = 0.00992
I1026 16:03:00.096892 37958 solver.cpp:221] Iteration 1400 (1.30327 iter/s, 30.6921s/40 iters), loss = 1.89238
I1026 16:03:00.097086 37958 solver.cpp:240]     Train net output #0: loss = 1.89238 (* 1 = 1.89238 loss)
I1026 16:03:00.097103 37958 sgd_solver.cpp:105] Iteration 1400, lr = 0.00991765
I1026 16:03:30.755998 37958 solver.cpp:221] Iteration 1440 (1.30473 iter/s, 30.6578s/40 iters), loss = 1.94203
I1026 16:03:30.756188 37958 solver.cpp:240]     Train net output #0: loss = 1.94203 (* 1 = 1.94203 loss)
I1026 16:03:30.756206 37958 sgd_solver.cpp:105] Iteration 1440, lr = 0.00991529
I1026 16:04:01.371171 37958 solver.cpp:221] Iteration 1480 (1.3066 iter/s, 30.6138s/40 iters), loss = 2.14099
I1026 16:04:01.371381 37958 solver.cpp:240]     Train net output #0: loss = 2.14099 (* 1 = 2.14099 loss)
I1026 16:04:01.371397 37958 sgd_solver.cpp:105] Iteration 1480, lr = 0.00991294
I1026 16:04:16.035199 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_1500.caffemodel
I1026 16:04:16.068696 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_1500.solverstate
I1026 16:04:16.086557 37958 solver.cpp:333] Iteration 1500, Testing net (#0)
I1026 16:04:46.832733 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 16:04:47.039090 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.50964
I1026 16:04:47.039147 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.75648
I1026 16:04:47.039160 37958 solver.cpp:400]     Test net output #2: loss = 2.20321 (* 1 = 2.20321 loss)
I1026 16:05:03.170898 37958 solver.cpp:221] Iteration 1520 (0.647278 iter/s, 61.7972s/40 iters), loss = 2.1872
I1026 16:05:03.170964 37958 solver.cpp:240]     Train net output #0: loss = 2.1872 (* 1 = 2.1872 loss)
I1026 16:05:03.170979 37958 sgd_solver.cpp:105] Iteration 1520, lr = 0.00991059
I1026 16:05:34.323174 37958 solver.cpp:221] Iteration 1560 (1.28407 iter/s, 31.151s/40 iters), loss = 1.98521
I1026 16:05:34.323632 37958 solver.cpp:240]     Train net output #0: loss = 1.98521 (* 1 = 1.98521 loss)
I1026 16:05:34.323649 37958 sgd_solver.cpp:105] Iteration 1560, lr = 0.00990823
I1026 16:06:04.862694 37958 solver.cpp:221] Iteration 1600 (1.30985 iter/s, 30.5379s/40 iters), loss = 2.06912
I1026 16:06:04.862864 37958 solver.cpp:240]     Train net output #0: loss = 2.06912 (* 1 = 2.06912 loss)
I1026 16:06:04.862881 37958 sgd_solver.cpp:105] Iteration 1600, lr = 0.00990588
I1026 16:06:35.759958 37958 solver.cpp:221] Iteration 1640 (1.29467 iter/s, 30.8959s/40 iters), loss = 1.82941
I1026 16:06:35.760129 37958 solver.cpp:240]     Train net output #0: loss = 1.82941 (* 1 = 1.82941 loss)
I1026 16:06:35.760145 37958 sgd_solver.cpp:105] Iteration 1640, lr = 0.00990353
I1026 16:06:54.291240 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_1665.caffemodel
I1026 16:06:54.325137 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_1665.solverstate
I1026 16:07:06.711135 37958 solver.cpp:221] Iteration 1680 (1.29241 iter/s, 30.9498s/40 iters), loss = 1.81056
I1026 16:07:06.711307 37958 solver.cpp:240]     Train net output #0: loss = 1.81056 (* 1 = 1.81056 loss)
I1026 16:07:06.711323 37958 sgd_solver.cpp:105] Iteration 1680, lr = 0.00990118
I1026 16:07:37.214805 37958 solver.cpp:221] Iteration 1720 (1.31137 iter/s, 30.5023s/40 iters), loss = 1.79994
I1026 16:07:37.214973 37958 solver.cpp:240]     Train net output #0: loss = 1.79994 (* 1 = 1.79994 loss)
I1026 16:07:37.214987 37958 sgd_solver.cpp:105] Iteration 1720, lr = 0.00989882
I1026 16:08:08.269284 37958 solver.cpp:221] Iteration 1760 (1.28812 iter/s, 31.0531s/40 iters), loss = 2.00508
I1026 16:08:08.269517 37958 solver.cpp:240]     Train net output #0: loss = 2.00508 (* 1 = 2.00508 loss)
I1026 16:08:08.269538 37958 sgd_solver.cpp:105] Iteration 1760, lr = 0.00989647
I1026 16:08:40.161906 37958 solver.cpp:221] Iteration 1800 (1.25427 iter/s, 31.8912s/40 iters), loss = 2.30898
I1026 16:08:40.162125 37958 solver.cpp:240]     Train net output #0: loss = 2.30898 (* 1 = 2.30898 loss)
I1026 16:08:40.162144 37958 sgd_solver.cpp:105] Iteration 1800, lr = 0.00989412
I1026 16:09:10.600139 37958 solver.cpp:221] Iteration 1840 (1.3142 iter/s, 30.4369s/40 iters), loss = 1.84181
I1026 16:09:10.600325 37958 solver.cpp:240]     Train net output #0: loss = 1.84181 (* 1 = 1.84181 loss)
I1026 16:09:10.600342 37958 sgd_solver.cpp:105] Iteration 1840, lr = 0.00989176
I1026 16:09:41.122341 37958 solver.cpp:221] Iteration 1880 (1.31058 iter/s, 30.5209s/40 iters), loss = 1.94041
I1026 16:09:41.122530 37958 solver.cpp:240]     Train net output #0: loss = 1.94041 (* 1 = 1.94041 loss)
I1026 16:09:41.122545 37958 sgd_solver.cpp:105] Iteration 1880, lr = 0.00988941
I1026 16:10:11.941180 37958 solver.cpp:221] Iteration 1920 (1.29797 iter/s, 30.8175s/40 iters), loss = 2.0806
I1026 16:10:11.941383 37958 solver.cpp:240]     Train net output #0: loss = 2.0806 (* 1 = 2.0806 loss)
I1026 16:10:11.941398 37958 sgd_solver.cpp:105] Iteration 1920, lr = 0.00988706
I1026 16:10:42.633740 37958 solver.cpp:221] Iteration 1960 (1.30331 iter/s, 30.6912s/40 iters), loss = 1.92267
I1026 16:10:42.633942 37958 solver.cpp:240]     Train net output #0: loss = 1.92267 (* 1 = 1.92267 loss)
I1026 16:10:42.633957 37958 sgd_solver.cpp:105] Iteration 1960, lr = 0.00988471
I1026 16:11:12.347584 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_2000.caffemodel
I1026 16:11:12.380091 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_2000.solverstate
I1026 16:11:12.398573 37958 solver.cpp:333] Iteration 2000, Testing net (#0)
I1026 16:11:43.330621 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.51472
I1026 16:11:43.330834 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.75988
I1026 16:11:43.330849 37958 solver.cpp:400]     Test net output #2: loss = 2.16356 (* 1 = 2.16356 loss)
I1026 16:11:44.091063 37958 solver.cpp:221] Iteration 2000 (0.650885 iter/s, 61.4548s/40 iters), loss = 1.65692
I1026 16:11:44.091110 37958 solver.cpp:240]     Train net output #0: loss = 1.65692 (* 1 = 1.65692 loss)
I1026 16:11:44.091123 37958 sgd_solver.cpp:105] Iteration 2000, lr = 0.00988235
I1026 16:12:14.617096 37958 solver.cpp:221] Iteration 2040 (1.31041 iter/s, 30.5248s/40 iters), loss = 2.1473
I1026 16:12:14.617311 37958 solver.cpp:240]     Train net output #0: loss = 2.1473 (* 1 = 2.1473 loss)
I1026 16:12:14.617328 37958 sgd_solver.cpp:105] Iteration 2040, lr = 0.00988
I1026 16:12:45.166121 37958 solver.cpp:221] Iteration 2080 (1.30943 iter/s, 30.5476s/40 iters), loss = 2.0926
I1026 16:12:45.166311 37958 solver.cpp:240]     Train net output #0: loss = 2.0926 (* 1 = 2.0926 loss)
I1026 16:12:45.166328 37958 sgd_solver.cpp:105] Iteration 2080, lr = 0.00987765
I1026 16:13:15.862617 37958 solver.cpp:221] Iteration 2120 (1.30314 iter/s, 30.6951s/40 iters), loss = 1.58461
I1026 16:13:15.862778 37958 solver.cpp:240]     Train net output #0: loss = 1.58461 (* 1 = 1.58461 loss)
I1026 16:13:15.862793 37958 sgd_solver.cpp:105] Iteration 2120, lr = 0.00987529
I1026 16:13:46.564440 37958 solver.cpp:221] Iteration 2160 (1.30291 iter/s, 30.7005s/40 iters), loss = 1.68592
I1026 16:13:46.564638 37958 solver.cpp:240]     Train net output #0: loss = 1.68592 (* 1 = 1.68592 loss)
I1026 16:13:46.564653 37958 sgd_solver.cpp:105] Iteration 2160, lr = 0.00987294
I1026 16:14:16.913398 37958 solver.cpp:221] Iteration 2200 (1.31806 iter/s, 30.3476s/40 iters), loss = 2.05572
I1026 16:14:16.913595 37958 solver.cpp:240]     Train net output #0: loss = 2.05572 (* 1 = 2.05572 loss)
I1026 16:14:16.913610 37958 sgd_solver.cpp:105] Iteration 2200, lr = 0.00987059
I1026 16:14:47.244352 37958 solver.cpp:221] Iteration 2240 (1.31884 iter/s, 30.3296s/40 iters), loss = 1.98382
I1026 16:14:47.244518 37958 solver.cpp:240]     Train net output #0: loss = 1.98382 (* 1 = 1.98382 loss)
I1026 16:14:47.244532 37958 sgd_solver.cpp:105] Iteration 2240, lr = 0.00986824
I1026 16:15:18.085639 37958 solver.cpp:221] Iteration 2280 (1.29702 iter/s, 30.84s/40 iters), loss = 1.70013
I1026 16:15:18.085814 37958 solver.cpp:240]     Train net output #0: loss = 1.70013 (* 1 = 1.70013 loss)
I1026 16:15:18.085829 37958 sgd_solver.cpp:105] Iteration 2280, lr = 0.00986588
I1026 16:15:48.890967 37958 solver.cpp:221] Iteration 2320 (1.29853 iter/s, 30.804s/40 iters), loss = 2.02104
I1026 16:15:48.891163 37958 solver.cpp:240]     Train net output #0: loss = 2.02104 (* 1 = 2.02104 loss)
I1026 16:15:48.891178 37958 sgd_solver.cpp:105] Iteration 2320, lr = 0.00986353
I1026 16:16:19.523007 37958 solver.cpp:221] Iteration 2360 (1.30588 iter/s, 30.6307s/40 iters), loss = 1.77471
I1026 16:16:19.523206 37958 solver.cpp:240]     Train net output #0: loss = 1.77471 (* 1 = 1.77471 loss)
I1026 16:16:19.523221 37958 sgd_solver.cpp:105] Iteration 2360, lr = 0.00986118
I1026 16:16:49.985700 37958 solver.cpp:221] Iteration 2400 (1.31314 iter/s, 30.4613s/40 iters), loss = 1.78863
I1026 16:16:49.985894 37958 solver.cpp:240]     Train net output #0: loss = 1.78863 (* 1 = 1.78863 loss)
I1026 16:16:49.985909 37958 sgd_solver.cpp:105] Iteration 2400, lr = 0.00985882
I1026 16:17:20.460191 37958 solver.cpp:221] Iteration 2440 (1.31263 iter/s, 30.4731s/40 iters), loss = 2.41058
I1026 16:17:20.460430 37958 solver.cpp:240]     Train net output #0: loss = 2.41058 (* 1 = 2.41058 loss)
I1026 16:17:20.460458 37958 sgd_solver.cpp:105] Iteration 2440, lr = 0.00985647
I1026 16:17:51.117549 37958 solver.cpp:221] Iteration 2480 (1.3048 iter/s, 30.656s/40 iters), loss = 2.08182
I1026 16:17:51.117739 37958 solver.cpp:240]     Train net output #0: loss = 2.08182 (* 1 = 2.08182 loss)
I1026 16:17:51.117753 37958 sgd_solver.cpp:105] Iteration 2480, lr = 0.00985412
I1026 16:18:05.004691 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1026 16:18:05.640547 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_2500.caffemodel
I1026 16:18:05.674940 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_2500.solverstate
I1026 16:18:05.694535 37958 solver.cpp:333] Iteration 2500, Testing net (#0)
I1026 16:18:36.456075 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 16:18:36.662916 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52104
I1026 16:18:36.662966 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.7638
I1026 16:18:36.662978 37958 solver.cpp:400]     Test net output #2: loss = 2.14113 (* 1 = 2.14113 loss)
I1026 16:18:52.781069 37958 solver.cpp:221] Iteration 2520 (0.648708 iter/s, 61.661s/40 iters), loss = 2.26313
I1026 16:18:52.781141 37958 solver.cpp:240]     Train net output #0: loss = 2.26313 (* 1 = 2.26313 loss)
I1026 16:18:52.781154 37958 sgd_solver.cpp:105] Iteration 2520, lr = 0.00985176
I1026 16:19:23.098125 37958 solver.cpp:221] Iteration 2560 (1.31944 iter/s, 30.3158s/40 iters), loss = 1.66807
I1026 16:19:23.098386 37958 solver.cpp:240]     Train net output #0: loss = 1.66807 (* 1 = 1.66807 loss)
I1026 16:19:23.098400 37958 sgd_solver.cpp:105] Iteration 2560, lr = 0.00984941
I1026 16:19:54.100595 37958 solver.cpp:221] Iteration 2600 (1.29028 iter/s, 31.001s/40 iters), loss = 1.96064
I1026 16:19:54.100762 37958 solver.cpp:240]     Train net output #0: loss = 1.96064 (* 1 = 1.96064 loss)
I1026 16:19:54.100776 37958 sgd_solver.cpp:105] Iteration 2600, lr = 0.00984706
I1026 16:20:24.728375 37958 solver.cpp:221] Iteration 2640 (1.30606 iter/s, 30.6265s/40 iters), loss = 2.05696
I1026 16:20:24.728565 37958 solver.cpp:240]     Train net output #0: loss = 2.05696 (* 1 = 2.05696 loss)
I1026 16:20:24.728580 37958 sgd_solver.cpp:105] Iteration 2640, lr = 0.00984471
I1026 16:20:56.482789 37958 solver.cpp:221] Iteration 2680 (1.25972 iter/s, 31.753s/40 iters), loss = 1.71049
I1026 16:20:56.482977 37958 solver.cpp:240]     Train net output #0: loss = 1.71049 (* 1 = 1.71049 loss)
I1026 16:20:56.482992 37958 sgd_solver.cpp:105] Iteration 2680, lr = 0.00984235
I1026 16:21:27.992563 37958 solver.cpp:221] Iteration 2720 (1.2695 iter/s, 31.5084s/40 iters), loss = 1.66445
I1026 16:21:27.992835 37958 solver.cpp:240]     Train net output #0: loss = 1.66445 (* 1 = 1.66445 loss)
I1026 16:21:27.992854 37958 sgd_solver.cpp:105] Iteration 2720, lr = 0.00984
I1026 16:22:01.185124 37958 solver.cpp:221] Iteration 2760 (1.20514 iter/s, 33.191s/40 iters), loss = 2.10308
I1026 16:22:01.185312 37958 solver.cpp:240]     Train net output #0: loss = 2.10308 (* 1 = 2.10308 loss)
I1026 16:22:01.185328 37958 sgd_solver.cpp:105] Iteration 2760, lr = 0.00983765
I1026 16:22:32.024404 37958 solver.cpp:221] Iteration 2800 (1.2971 iter/s, 30.8379s/40 iters), loss = 1.82733
I1026 16:22:32.024597 37958 solver.cpp:240]     Train net output #0: loss = 1.82733 (* 1 = 1.82733 loss)
I1026 16:22:32.024612 37958 sgd_solver.cpp:105] Iteration 2800, lr = 0.00983529
I1026 16:23:03.123760 37958 solver.cpp:221] Iteration 2840 (1.28626 iter/s, 31.098s/40 iters), loss = 1.7895
I1026 16:23:03.123961 37958 solver.cpp:240]     Train net output #0: loss = 1.7895 (* 1 = 1.7895 loss)
I1026 16:23:03.123975 37958 sgd_solver.cpp:105] Iteration 2840, lr = 0.00983294
I1026 16:23:34.231814 37958 solver.cpp:221] Iteration 2880 (1.2859 iter/s, 31.1067s/40 iters), loss = 1.84441
I1026 16:23:34.232045 37958 solver.cpp:240]     Train net output #0: loss = 1.84441 (* 1 = 1.84441 loss)
I1026 16:23:34.232091 37958 sgd_solver.cpp:105] Iteration 2880, lr = 0.00983059
I1026 16:24:05.771113 37958 solver.cpp:221] Iteration 2920 (1.26832 iter/s, 31.5379s/40 iters), loss = 1.85559
I1026 16:24:05.771306 37958 solver.cpp:240]     Train net output #0: loss = 1.85559 (* 1 = 1.85559 loss)
I1026 16:24:05.771323 37958 sgd_solver.cpp:105] Iteration 2920, lr = 0.00982824
I1026 16:24:37.083180 37958 solver.cpp:221] Iteration 2960 (1.27752 iter/s, 31.3107s/40 iters), loss = 2.08656
I1026 16:24:37.083458 37958 solver.cpp:240]     Train net output #0: loss = 2.08656 (* 1 = 2.08656 loss)
I1026 16:24:37.083474 37958 sgd_solver.cpp:105] Iteration 2960, lr = 0.00982588
I1026 16:25:07.640362 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_3000.caffemodel
I1026 16:25:07.673184 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_3000.solverstate
I1026 16:25:07.691061 37958 solver.cpp:333] Iteration 3000, Testing net (#0)
I1026 16:25:38.580159 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.51568
I1026 16:25:38.580293 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.7624
I1026 16:25:38.580312 37958 solver.cpp:400]     Test net output #2: loss = 2.17252 (* 1 = 2.17252 loss)
I1026 16:25:39.348812 37958 solver.cpp:221] Iteration 3000 (0.642436 iter/s, 62.263s/40 iters), loss = 2.27011
I1026 16:25:39.348865 37958 solver.cpp:240]     Train net output #0: loss = 2.27011 (* 1 = 2.27011 loss)
I1026 16:25:39.348879 37958 sgd_solver.cpp:105] Iteration 3000, lr = 0.00982353
I1026 16:26:10.000809 37958 solver.cpp:221] Iteration 3040 (1.30502 iter/s, 30.6508s/40 iters), loss = 1.8701
I1026 16:26:10.000996 37958 solver.cpp:240]     Train net output #0: loss = 1.8701 (* 1 = 1.8701 loss)
I1026 16:26:10.001011 37958 sgd_solver.cpp:105] Iteration 3040, lr = 0.00982118
I1026 16:26:40.735512 37958 solver.cpp:221] Iteration 3080 (1.30152 iter/s, 30.7333s/40 iters), loss = 1.91933
I1026 16:26:40.735718 37958 solver.cpp:240]     Train net output #0: loss = 1.91933 (* 1 = 1.91933 loss)
I1026 16:26:40.735734 37958 sgd_solver.cpp:105] Iteration 3080, lr = 0.00981882
I1026 16:27:11.406539 37958 solver.cpp:221] Iteration 3120 (1.30422 iter/s, 30.6697s/40 iters), loss = 2.06833
I1026 16:27:11.406730 37958 solver.cpp:240]     Train net output #0: loss = 2.06833 (* 1 = 2.06833 loss)
I1026 16:27:11.406745 37958 sgd_solver.cpp:105] Iteration 3120, lr = 0.00981647
I1026 16:27:41.826416 37958 solver.cpp:221] Iteration 3160 (1.31499 iter/s, 30.4185s/40 iters), loss = 2.06414
I1026 16:27:41.826611 37958 solver.cpp:240]     Train net output #0: loss = 2.06414 (* 1 = 2.06414 loss)
I1026 16:27:41.826624 37958 sgd_solver.cpp:105] Iteration 3160, lr = 0.00981412
I1026 16:28:12.098577 37958 solver.cpp:221] Iteration 3200 (1.3214 iter/s, 30.2708s/40 iters), loss = 1.99428
I1026 16:28:12.098762 37958 solver.cpp:240]     Train net output #0: loss = 1.99428 (* 1 = 1.99428 loss)
I1026 16:28:12.098775 37958 sgd_solver.cpp:105] Iteration 3200, lr = 0.00981176
I1026 16:28:42.615931 37958 solver.cpp:221] Iteration 3240 (1.31079 iter/s, 30.516s/40 iters), loss = 2.16548
I1026 16:28:42.616103 37958 solver.cpp:240]     Train net output #0: loss = 2.16548 (* 1 = 2.16548 loss)
I1026 16:28:42.616118 37958 sgd_solver.cpp:105] Iteration 3240, lr = 0.00980941
I1026 16:29:13.081522 37958 solver.cpp:221] Iteration 3280 (1.31301 iter/s, 30.4643s/40 iters), loss = 2.10337
I1026 16:29:13.081691 37958 solver.cpp:240]     Train net output #0: loss = 2.10337 (* 1 = 2.10337 loss)
I1026 16:29:13.081706 37958 sgd_solver.cpp:105] Iteration 3280, lr = 0.00980706
I1026 16:29:43.574897 37958 solver.cpp:221] Iteration 3320 (1.31182 iter/s, 30.4921s/40 iters), loss = 2.09072
I1026 16:29:43.575075 37958 solver.cpp:240]     Train net output #0: loss = 2.09072 (* 1 = 2.09072 loss)
I1026 16:29:43.575089 37958 sgd_solver.cpp:105] Iteration 3320, lr = 0.00980471
I1026 16:30:14.044790 37958 solver.cpp:221] Iteration 3360 (1.31283 iter/s, 30.4686s/40 iters), loss = 1.9667
I1026 16:30:14.044996 37958 solver.cpp:240]     Train net output #0: loss = 1.9667 (* 1 = 1.9667 loss)
I1026 16:30:14.045011 37958 sgd_solver.cpp:105] Iteration 3360, lr = 0.00980235
I1026 16:30:44.559424 37958 solver.cpp:221] Iteration 3400 (1.3109 iter/s, 30.5133s/40 iters), loss = 1.80297
I1026 16:30:44.559610 37958 solver.cpp:240]     Train net output #0: loss = 1.80297 (* 1 = 1.80297 loss)
I1026 16:30:44.559625 37958 sgd_solver.cpp:105] Iteration 3400, lr = 0.0098
I1026 16:31:15.133491 37958 solver.cpp:221] Iteration 3440 (1.30836 iter/s, 30.5727s/40 iters), loss = 1.78373
I1026 16:31:15.133677 37958 solver.cpp:240]     Train net output #0: loss = 1.78373 (* 1 = 1.78373 loss)
I1026 16:31:15.133692 37958 sgd_solver.cpp:105] Iteration 3440, lr = 0.00979765
I1026 16:31:45.701012 37958 solver.cpp:221] Iteration 3480 (1.30864 iter/s, 30.5662s/40 iters), loss = 1.76517
I1026 16:31:45.701244 37958 solver.cpp:240]     Train net output #0: loss = 1.76517 (* 1 = 1.76517 loss)
I1026 16:31:45.701259 37958 sgd_solver.cpp:105] Iteration 3480, lr = 0.00979529
I1026 16:32:00.359935 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_3500.caffemodel
I1026 16:32:00.394661 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_3500.solverstate
I1026 16:32:00.413805 37958 solver.cpp:333] Iteration 3500, Testing net (#0)
I1026 16:32:31.102128 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 16:32:31.308475 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.51732
I1026 16:32:31.308518 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76268
I1026 16:32:31.308531 37958 solver.cpp:400]     Test net output #2: loss = 2.18754 (* 1 = 2.18754 loss)
I1026 16:32:47.324048 37958 solver.cpp:221] Iteration 3520 (0.649135 iter/s, 61.6205s/40 iters), loss = 1.95696
I1026 16:32:47.324110 37958 solver.cpp:240]     Train net output #0: loss = 1.95696 (* 1 = 1.95696 loss)
I1026 16:32:47.324124 37958 sgd_solver.cpp:105] Iteration 3520, lr = 0.00979294
I1026 16:33:17.745064 37958 solver.cpp:221] Iteration 3560 (1.31493 iter/s, 30.4198s/40 iters), loss = 1.91839
I1026 16:33:17.745281 37958 solver.cpp:240]     Train net output #0: loss = 1.91839 (* 1 = 1.91839 loss)
I1026 16:33:17.745299 37958 sgd_solver.cpp:105] Iteration 3560, lr = 0.00979059
I1026 16:33:47.608438 37958 solver.cpp:221] Iteration 3600 (1.33949 iter/s, 29.862s/40 iters), loss = 2.16624
I1026 16:33:47.608501 37958 solver.cpp:240]     Train net output #0: loss = 2.16624 (* 1 = 2.16624 loss)
I1026 16:33:47.608515 37958 sgd_solver.cpp:105] Iteration 3600, lr = 0.00978824
I1026 16:34:17.156466 37958 solver.cpp:221] Iteration 3640 (1.35378 iter/s, 29.5468s/40 iters), loss = 1.97563
I1026 16:34:17.156677 37958 solver.cpp:240]     Train net output #0: loss = 1.97563 (* 1 = 1.97563 loss)
I1026 16:34:17.156690 37958 sgd_solver.cpp:105] Iteration 3640, lr = 0.00978588
I1026 16:34:47.885067 37958 solver.cpp:221] Iteration 3680 (1.30178 iter/s, 30.7272s/40 iters), loss = 1.57823
I1026 16:34:47.885259 37958 solver.cpp:240]     Train net output #0: loss = 1.57823 (* 1 = 1.57823 loss)
I1026 16:34:47.885278 37958 sgd_solver.cpp:105] Iteration 3680, lr = 0.00978353
I1026 16:35:18.840935 37958 solver.cpp:221] Iteration 3720 (1.29222 iter/s, 30.9545s/40 iters), loss = 1.94618
I1026 16:35:18.841152 37958 solver.cpp:240]     Train net output #0: loss = 1.94618 (* 1 = 1.94618 loss)
I1026 16:35:18.841176 37958 sgd_solver.cpp:105] Iteration 3720, lr = 0.00978118
I1026 16:35:49.541404 37958 solver.cpp:221] Iteration 3760 (1.30297 iter/s, 30.6991s/40 iters), loss = 1.55235
I1026 16:35:49.541602 37958 solver.cpp:240]     Train net output #0: loss = 1.55235 (* 1 = 1.55235 loss)
I1026 16:35:49.541617 37958 sgd_solver.cpp:105] Iteration 3760, lr = 0.00977882
I1026 16:36:20.457334 37958 solver.cpp:221] Iteration 3800 (1.29389 iter/s, 30.9146s/40 iters), loss = 1.64474
I1026 16:36:20.457588 37958 solver.cpp:240]     Train net output #0: loss = 1.64474 (* 1 = 1.64474 loss)
I1026 16:36:20.457615 37958 sgd_solver.cpp:105] Iteration 3800, lr = 0.00977647
I1026 16:36:51.246810 37958 solver.cpp:221] Iteration 3840 (1.29921 iter/s, 30.788s/40 iters), loss = 1.60661
I1026 16:36:51.247046 37958 solver.cpp:240]     Train net output #0: loss = 1.60661 (* 1 = 1.60661 loss)
I1026 16:36:51.247067 37958 sgd_solver.cpp:105] Iteration 3840, lr = 0.00977412
I1026 16:37:21.805958 37958 solver.cpp:221] Iteration 3880 (1.309 iter/s, 30.5578s/40 iters), loss = 2.22067
I1026 16:37:21.806143 37958 solver.cpp:240]     Train net output #0: loss = 2.22067 (* 1 = 2.22067 loss)
I1026 16:37:21.806157 37958 sgd_solver.cpp:105] Iteration 3880, lr = 0.00977176
I1026 16:37:52.342998 37958 solver.cpp:221] Iteration 3920 (1.30994 iter/s, 30.5357s/40 iters), loss = 1.87708
I1026 16:37:52.343189 37958 solver.cpp:240]     Train net output #0: loss = 1.87708 (* 1 = 1.87708 loss)
I1026 16:37:52.343204 37958 sgd_solver.cpp:105] Iteration 3920, lr = 0.00976941
I1026 16:38:23.025876 37958 solver.cpp:221] Iteration 3960 (1.30372 iter/s, 30.6815s/40 iters), loss = 1.81925
I1026 16:38:23.026048 37958 solver.cpp:240]     Train net output #0: loss = 1.81925 (* 1 = 1.81925 loss)
I1026 16:38:23.026062 37958 sgd_solver.cpp:105] Iteration 3960, lr = 0.00976706
I1026 16:38:52.921514 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_4000.caffemodel
I1026 16:38:52.954222 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_4000.solverstate
I1026 16:38:52.971860 37958 solver.cpp:333] Iteration 4000, Testing net (#0)
I1026 16:39:24.023108 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.51808
I1026 16:39:24.023269 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76296
I1026 16:39:24.023283 37958 solver.cpp:400]     Test net output #2: loss = 2.16613 (* 1 = 2.16613 loss)
I1026 16:39:24.781354 37958 solver.cpp:221] Iteration 4000 (0.647742 iter/s, 61.753s/40 iters), loss = 1.59364
I1026 16:39:24.781400 37958 solver.cpp:240]     Train net output #0: loss = 1.59364 (* 1 = 1.59364 loss)
I1026 16:39:24.781414 37958 sgd_solver.cpp:105] Iteration 4000, lr = 0.00976471
I1026 16:39:55.395323 37958 solver.cpp:221] Iteration 4040 (1.30664 iter/s, 30.6128s/40 iters), loss = 1.96582
I1026 16:39:55.395512 37958 solver.cpp:240]     Train net output #0: loss = 1.96582 (* 1 = 1.96582 loss)
I1026 16:39:55.395526 37958 sgd_solver.cpp:105] Iteration 4040, lr = 0.00976235
I1026 16:40:26.133324 37958 solver.cpp:221] Iteration 4080 (1.30138 iter/s, 30.7367s/40 iters), loss = 2.02292
I1026 16:40:26.133528 37958 solver.cpp:240]     Train net output #0: loss = 2.02292 (* 1 = 2.02292 loss)
I1026 16:40:26.133543 37958 sgd_solver.cpp:105] Iteration 4080, lr = 0.00976
I1026 16:40:57.906185 37958 solver.cpp:221] Iteration 4120 (1.25899 iter/s, 31.7714s/40 iters), loss = 1.8659
I1026 16:40:57.906432 37958 solver.cpp:240]     Train net output #0: loss = 1.8659 (* 1 = 1.8659 loss)
I1026 16:40:57.906453 37958 sgd_solver.cpp:105] Iteration 4120, lr = 0.00975765
I1026 16:41:29.862681 37958 solver.cpp:221] Iteration 4160 (1.25176 iter/s, 31.955s/40 iters), loss = 2.01245
I1026 16:41:29.862901 37958 solver.cpp:240]     Train net output #0: loss = 2.01245 (* 1 = 2.01245 loss)
I1026 16:41:29.862920 37958 sgd_solver.cpp:105] Iteration 4160, lr = 0.00975529
I1026 16:42:00.627749 37958 solver.cpp:221] Iteration 4200 (1.30023 iter/s, 30.7637s/40 iters), loss = 1.87457
I1026 16:42:00.627956 37958 solver.cpp:240]     Train net output #0: loss = 1.87457 (* 1 = 1.87457 loss)
I1026 16:42:00.627972 37958 sgd_solver.cpp:105] Iteration 4200, lr = 0.00975294
I1026 16:42:31.411100 37958 solver.cpp:221] Iteration 4240 (1.29946 iter/s, 30.782s/40 iters), loss = 1.8208
I1026 16:42:31.411293 37958 solver.cpp:240]     Train net output #0: loss = 1.8208 (* 1 = 1.8208 loss)
I1026 16:42:31.411312 37958 sgd_solver.cpp:105] Iteration 4240, lr = 0.00975059
I1026 16:43:02.137802 37958 solver.cpp:221] Iteration 4280 (1.30186 iter/s, 30.7253s/40 iters), loss = 1.73468
I1026 16:43:02.138062 37958 solver.cpp:240]     Train net output #0: loss = 1.73468 (* 1 = 1.73468 loss)
I1026 16:43:02.138078 37958 sgd_solver.cpp:105] Iteration 4280, lr = 0.00974824
I1026 16:43:32.965387 37958 solver.cpp:221] Iteration 4320 (1.2976 iter/s, 30.8262s/40 iters), loss = 1.851
I1026 16:43:32.965608 37958 solver.cpp:240]     Train net output #0: loss = 1.851 (* 1 = 1.851 loss)
I1026 16:43:32.965623 37958 sgd_solver.cpp:105] Iteration 4320, lr = 0.00974588
I1026 16:44:03.622136 37958 solver.cpp:221] Iteration 4360 (1.30483 iter/s, 30.6554s/40 iters), loss = 1.84966
I1026 16:44:03.622836 37958 solver.cpp:240]     Train net output #0: loss = 1.84966 (* 1 = 1.84966 loss)
I1026 16:44:03.622853 37958 sgd_solver.cpp:105] Iteration 4360, lr = 0.00974353
I1026 16:44:34.586942 37958 solver.cpp:221] Iteration 4400 (1.29187 iter/s, 30.9629s/40 iters), loss = 1.98662
I1026 16:44:34.587216 37958 solver.cpp:240]     Train net output #0: loss = 1.98662 (* 1 = 1.98662 loss)
I1026 16:44:34.587237 37958 sgd_solver.cpp:105] Iteration 4400, lr = 0.00974118
I1026 16:45:04.773579 37958 solver.cpp:221] Iteration 4440 (1.32515 iter/s, 30.1852s/40 iters), loss = 1.76187
I1026 16:45:04.773758 37958 solver.cpp:240]     Train net output #0: loss = 1.76187 (* 1 = 1.76187 loss)
I1026 16:45:04.773772 37958 sgd_solver.cpp:105] Iteration 4440, lr = 0.00973882
I1026 16:45:36.138496 37958 solver.cpp:221] Iteration 4480 (1.27537 iter/s, 31.3635s/40 iters), loss = 1.39296
I1026 16:45:36.138728 37958 solver.cpp:240]     Train net output #0: loss = 1.39296 (* 1 = 1.39296 loss)
I1026 16:45:36.138751 37958 sgd_solver.cpp:105] Iteration 4480, lr = 0.00973647
I1026 16:45:50.558758 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_4500.caffemodel
I1026 16:45:50.595621 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_4500.solverstate
I1026 16:45:50.616183 37958 solver.cpp:333] Iteration 4500, Testing net (#0)
I1026 16:46:21.397117 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 16:46:21.607993 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.5202
I1026 16:46:21.608045 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76196
I1026 16:46:21.608057 37958 solver.cpp:400]     Test net output #2: loss = 2.16102 (* 1 = 2.16102 loss)
I1026 16:46:37.860239 37958 solver.cpp:221] Iteration 4520 (0.648097 iter/s, 61.7192s/40 iters), loss = 1.76854
I1026 16:46:37.860307 37958 solver.cpp:240]     Train net output #0: loss = 1.76854 (* 1 = 1.76854 loss)
I1026 16:46:37.860323 37958 sgd_solver.cpp:105] Iteration 4520, lr = 0.00973412
I1026 16:47:08.718075 37958 solver.cpp:221] Iteration 4560 (1.29632 iter/s, 30.8566s/40 iters), loss = 1.90647
I1026 16:47:08.718300 37958 solver.cpp:240]     Train net output #0: loss = 1.90647 (* 1 = 1.90647 loss)
I1026 16:47:08.718317 37958 sgd_solver.cpp:105] Iteration 4560, lr = 0.00973176
I1026 16:47:39.550753 37958 solver.cpp:221] Iteration 4600 (1.29738 iter/s, 30.8313s/40 iters), loss = 2.04219
I1026 16:47:39.550945 37958 solver.cpp:240]     Train net output #0: loss = 2.04219 (* 1 = 2.04219 loss)
I1026 16:47:39.550959 37958 sgd_solver.cpp:105] Iteration 4600, lr = 0.00972941
I1026 16:48:10.061724 37958 solver.cpp:221] Iteration 4640 (1.31106 iter/s, 30.5096s/40 iters), loss = 2.17819
I1026 16:48:10.061877 37958 solver.cpp:240]     Train net output #0: loss = 2.17819 (* 1 = 2.17819 loss)
I1026 16:48:10.061892 37958 sgd_solver.cpp:105] Iteration 4640, lr = 0.00972706
I1026 16:48:40.822082 37958 solver.cpp:221] Iteration 4680 (1.30043 iter/s, 30.759s/40 iters), loss = 1.98107
I1026 16:48:40.822311 37958 solver.cpp:240]     Train net output #0: loss = 1.98107 (* 1 = 1.98107 loss)
I1026 16:48:40.822331 37958 sgd_solver.cpp:105] Iteration 4680, lr = 0.00972471
I1026 16:49:11.916796 37958 solver.cpp:221] Iteration 4720 (1.28645 iter/s, 31.0933s/40 iters), loss = 1.91075
I1026 16:49:11.917037 37958 solver.cpp:240]     Train net output #0: loss = 1.91075 (* 1 = 1.91075 loss)
I1026 16:49:11.917062 37958 sgd_solver.cpp:105] Iteration 4720, lr = 0.00972235
I1026 16:49:42.603927 37958 solver.cpp:221] Iteration 4760 (1.30354 iter/s, 30.6857s/40 iters), loss = 1.58951
I1026 16:49:42.604130 37958 solver.cpp:240]     Train net output #0: loss = 1.58951 (* 1 = 1.58951 loss)
I1026 16:49:42.604146 37958 sgd_solver.cpp:105] Iteration 4760, lr = 0.00972
I1026 16:50:13.260586 37958 solver.cpp:221] Iteration 4800 (1.30483 iter/s, 30.6553s/40 iters), loss = 2.04745
I1026 16:50:13.260794 37958 solver.cpp:240]     Train net output #0: loss = 2.04745 (* 1 = 2.04745 loss)
I1026 16:50:13.260809 37958 sgd_solver.cpp:105] Iteration 4800, lr = 0.00971765
I1026 16:50:43.436594 37958 solver.cpp:221] Iteration 4840 (1.32562 iter/s, 30.1747s/40 iters), loss = 1.866
I1026 16:50:43.436796 37958 solver.cpp:240]     Train net output #0: loss = 1.866 (* 1 = 1.866 loss)
I1026 16:50:43.436810 37958 sgd_solver.cpp:105] Iteration 4840, lr = 0.00971529
I1026 16:51:13.989954 37958 solver.cpp:221] Iteration 4880 (1.30924 iter/s, 30.552s/40 iters), loss = 2.04487
I1026 16:51:13.990145 37958 solver.cpp:240]     Train net output #0: loss = 2.04487 (* 1 = 2.04487 loss)
I1026 16:51:13.990160 37958 sgd_solver.cpp:105] Iteration 4880, lr = 0.00971294
I1026 16:51:44.606005 37958 solver.cpp:221] Iteration 4920 (1.30656 iter/s, 30.6147s/40 iters), loss = 1.57015
I1026 16:51:44.606210 37958 solver.cpp:240]     Train net output #0: loss = 1.57015 (* 1 = 1.57015 loss)
I1026 16:51:44.606225 37958 sgd_solver.cpp:105] Iteration 4920, lr = 0.00971059
I1026 16:52:15.189808 37958 solver.cpp:221] Iteration 4960 (1.30794 iter/s, 30.5824s/40 iters), loss = 1.8309
I1026 16:52:15.189988 37958 solver.cpp:240]     Train net output #0: loss = 1.8309 (* 1 = 1.8309 loss)
I1026 16:52:15.190002 37958 sgd_solver.cpp:105] Iteration 4960, lr = 0.00970824
I1026 16:52:44.645717 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_5000.caffemodel
I1026 16:52:44.680675 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_5000.solverstate
I1026 16:52:44.700798 37958 solver.cpp:333] Iteration 5000, Testing net (#0)
I1026 16:53:15.824738 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.5202
I1026 16:53:15.824921 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.7676
I1026 16:53:15.824937 37958 solver.cpp:400]     Test net output #2: loss = 2.12538 (* 1 = 2.12538 loss)
I1026 16:53:16.586319 37958 solver.cpp:221] Iteration 5000 (0.651529 iter/s, 61.394s/40 iters), loss = 2.32298
I1026 16:53:16.586382 37958 solver.cpp:240]     Train net output #0: loss = 2.32298 (* 1 = 2.32298 loss)
I1026 16:53:16.586395 37958 sgd_solver.cpp:105] Iteration 5000, lr = 0.00970588
I1026 16:53:16.658859 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1026 16:53:50.209816 37958 solver.cpp:221] Iteration 5040 (1.18969 iter/s, 33.6221s/40 iters), loss = 1.88544
I1026 16:53:50.210086 37958 solver.cpp:240]     Train net output #0: loss = 1.88544 (* 1 = 1.88544 loss)
I1026 16:53:50.210108 37958 sgd_solver.cpp:105] Iteration 5040, lr = 0.00970353
I1026 16:54:20.153132 37958 solver.cpp:221] Iteration 5080 (1.33592 iter/s, 29.9419s/40 iters), loss = 2.08548
I1026 16:54:20.153203 37958 solver.cpp:240]     Train net output #0: loss = 2.08548 (* 1 = 2.08548 loss)
I1026 16:54:20.153216 37958 sgd_solver.cpp:105] Iteration 5080, lr = 0.00970118
I1026 16:54:50.486048 37958 solver.cpp:221] Iteration 5120 (1.31875 iter/s, 30.3317s/40 iters), loss = 2.03142
I1026 16:54:50.486261 37958 solver.cpp:240]     Train net output #0: loss = 2.03142 (* 1 = 2.03142 loss)
I1026 16:54:50.486276 37958 sgd_solver.cpp:105] Iteration 5120, lr = 0.00969882
I1026 16:55:20.532912 37958 solver.cpp:221] Iteration 5160 (1.33131 iter/s, 30.0455s/40 iters), loss = 2.04957
I1026 16:55:20.533114 37958 solver.cpp:240]     Train net output #0: loss = 2.04957 (* 1 = 2.04957 loss)
I1026 16:55:20.533128 37958 sgd_solver.cpp:105] Iteration 5160, lr = 0.00969647
I1026 16:55:52.518373 37958 solver.cpp:221] Iteration 5200 (1.25062 iter/s, 31.984s/40 iters), loss = 2.12584
I1026 16:55:52.518590 37958 solver.cpp:240]     Train net output #0: loss = 2.12584 (* 1 = 2.12584 loss)
I1026 16:55:52.518606 37958 sgd_solver.cpp:105] Iteration 5200, lr = 0.00969412
I1026 16:56:23.376001 37958 solver.cpp:221] Iteration 5240 (1.29633 iter/s, 30.8562s/40 iters), loss = 1.91962
I1026 16:56:23.376215 37958 solver.cpp:240]     Train net output #0: loss = 1.91962 (* 1 = 1.91962 loss)
I1026 16:56:23.376233 37958 sgd_solver.cpp:105] Iteration 5240, lr = 0.00969176
I1026 16:56:54.376179 37958 solver.cpp:221] Iteration 5280 (1.29037 iter/s, 30.9988s/40 iters), loss = 2.34611
I1026 16:56:54.376418 37958 solver.cpp:240]     Train net output #0: loss = 2.34611 (* 1 = 2.34611 loss)
I1026 16:56:54.376432 37958 sgd_solver.cpp:105] Iteration 5280, lr = 0.00968941
I1026 16:57:25.278954 37958 solver.cpp:221] Iteration 5320 (1.29444 iter/s, 30.9014s/40 iters), loss = 1.81324
I1026 16:57:25.279161 37958 solver.cpp:240]     Train net output #0: loss = 1.81324 (* 1 = 1.81324 loss)
I1026 16:57:25.279175 37958 sgd_solver.cpp:105] Iteration 5320, lr = 0.00968706
I1026 16:57:55.834892 37958 solver.cpp:221] Iteration 5360 (1.30913 iter/s, 30.5546s/40 iters), loss = 2.07439
I1026 16:57:55.835096 37958 solver.cpp:240]     Train net output #0: loss = 2.07439 (* 1 = 2.07439 loss)
I1026 16:57:55.835110 37958 sgd_solver.cpp:105] Iteration 5360, lr = 0.00968471
I1026 16:58:26.717248 37958 solver.cpp:221] Iteration 5400 (1.2953 iter/s, 30.881s/40 iters), loss = 2.07836
I1026 16:58:26.717452 37958 solver.cpp:240]     Train net output #0: loss = 2.07836 (* 1 = 2.07836 loss)
I1026 16:58:26.717465 37958 sgd_solver.cpp:105] Iteration 5400, lr = 0.00968235
I1026 16:58:57.175945 37958 solver.cpp:221] Iteration 5440 (1.31331 iter/s, 30.4573s/40 iters), loss = 1.9251
I1026 16:58:57.176115 37958 solver.cpp:240]     Train net output #0: loss = 1.9251 (* 1 = 1.9251 loss)
I1026 16:58:57.176128 37958 sgd_solver.cpp:105] Iteration 5440, lr = 0.00968
I1026 16:59:26.894352 37958 solver.cpp:221] Iteration 5480 (1.34603 iter/s, 29.7171s/40 iters), loss = 1.90184
I1026 16:59:26.894418 37958 solver.cpp:240]     Train net output #0: loss = 1.90184 (* 1 = 1.90184 loss)
I1026 16:59:26.894430 37958 sgd_solver.cpp:105] Iteration 5480, lr = 0.00967765
I1026 16:59:41.109885 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_5500.caffemodel
I1026 16:59:41.144882 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_5500.solverstate
I1026 16:59:41.164441 37958 solver.cpp:333] Iteration 5500, Testing net (#0)
I1026 17:00:11.867269 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 17:00:12.073551 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.5148
I1026 17:00:12.073596 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.7646
I1026 17:00:12.073606 37958 solver.cpp:400]     Test net output #2: loss = 2.15258 (* 1 = 2.15258 loss)
I1026 17:00:28.096186 37958 solver.cpp:221] Iteration 5520 (0.6536 iter/s, 61.1995s/40 iters), loss = 1.5992
I1026 17:00:28.096251 37958 solver.cpp:240]     Train net output #0: loss = 1.5992 (* 1 = 1.5992 loss)
I1026 17:00:28.096264 37958 sgd_solver.cpp:105] Iteration 5520, lr = 0.00967529
I1026 17:00:58.572492 37958 solver.cpp:221] Iteration 5560 (1.31255 iter/s, 30.4751s/40 iters), loss = 1.78997
I1026 17:00:58.572684 37958 solver.cpp:240]     Train net output #0: loss = 1.78997 (* 1 = 1.78997 loss)
I1026 17:00:58.572698 37958 sgd_solver.cpp:105] Iteration 5560, lr = 0.00967294
I1026 17:01:29.509001 37958 solver.cpp:221] Iteration 5600 (1.29303 iter/s, 30.9351s/40 iters), loss = 1.79508
I1026 17:01:29.509233 37958 solver.cpp:240]     Train net output #0: loss = 1.79508 (* 1 = 1.79508 loss)
I1026 17:01:29.509249 37958 sgd_solver.cpp:105] Iteration 5600, lr = 0.00967059
I1026 17:02:00.068058 37958 solver.cpp:221] Iteration 5640 (1.309 iter/s, 30.5577s/40 iters), loss = 2.06269
I1026 17:02:00.068274 37958 solver.cpp:240]     Train net output #0: loss = 2.06269 (* 1 = 2.06269 loss)
I1026 17:02:00.068289 37958 sgd_solver.cpp:105] Iteration 5640, lr = 0.00966823
I1026 17:02:30.313607 37958 solver.cpp:221] Iteration 5680 (1.32257 iter/s, 30.2442s/40 iters), loss = 1.98751
I1026 17:02:30.313789 37958 solver.cpp:240]     Train net output #0: loss = 1.98751 (* 1 = 1.98751 loss)
I1026 17:02:30.313804 37958 sgd_solver.cpp:105] Iteration 5680, lr = 0.00966588
I1026 17:03:00.627769 37958 solver.cpp:221] Iteration 5720 (1.31957 iter/s, 30.3128s/40 iters), loss = 1.74171
I1026 17:03:00.627928 37958 solver.cpp:240]     Train net output #0: loss = 1.74171 (* 1 = 1.74171 loss)
I1026 17:03:00.627943 37958 sgd_solver.cpp:105] Iteration 5720, lr = 0.00966353
I1026 17:03:31.249596 37958 solver.cpp:221] Iteration 5760 (1.30631 iter/s, 30.6205s/40 iters), loss = 1.60584
I1026 17:03:31.249827 37958 solver.cpp:240]     Train net output #0: loss = 1.60584 (* 1 = 1.60584 loss)
I1026 17:03:31.249850 37958 sgd_solver.cpp:105] Iteration 5760, lr = 0.00966118
I1026 17:04:01.980567 37958 solver.cpp:221] Iteration 5800 (1.30168 iter/s, 30.7296s/40 iters), loss = 2.10531
I1026 17:04:01.980746 37958 solver.cpp:240]     Train net output #0: loss = 2.10531 (* 1 = 2.10531 loss)
I1026 17:04:01.980762 37958 sgd_solver.cpp:105] Iteration 5800, lr = 0.00965882
I1026 17:04:32.959651 37958 solver.cpp:221] Iteration 5840 (1.29125 iter/s, 30.9777s/40 iters), loss = 1.9724
I1026 17:04:32.959853 37958 solver.cpp:240]     Train net output #0: loss = 1.9724 (* 1 = 1.9724 loss)
I1026 17:04:32.959878 37958 sgd_solver.cpp:105] Iteration 5840, lr = 0.00965647
I1026 17:05:03.985915 37958 solver.cpp:221] Iteration 5880 (1.28929 iter/s, 31.0249s/40 iters), loss = 2.28468
I1026 17:05:03.986104 37958 solver.cpp:240]     Train net output #0: loss = 2.28468 (* 1 = 2.28468 loss)
I1026 17:05:03.986120 37958 sgd_solver.cpp:105] Iteration 5880, lr = 0.00965412
I1026 17:05:35.215509 37958 solver.cpp:221] Iteration 5920 (1.28089 iter/s, 31.2282s/40 iters), loss = 1.91276
I1026 17:05:35.215713 37958 solver.cpp:240]     Train net output #0: loss = 1.91276 (* 1 = 1.91276 loss)
I1026 17:05:35.215728 37958 sgd_solver.cpp:105] Iteration 5920, lr = 0.00965176
I1026 17:06:06.479949 37958 solver.cpp:221] Iteration 5960 (1.27947 iter/s, 31.2631s/40 iters), loss = 1.99915
I1026 17:06:06.480161 37958 solver.cpp:240]     Train net output #0: loss = 1.99915 (* 1 = 1.99915 loss)
I1026 17:06:06.480176 37958 sgd_solver.cpp:105] Iteration 5960, lr = 0.00964941
I1026 17:06:36.294905 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_6000.caffemodel
I1026 17:06:36.330147 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_6000.solverstate
I1026 17:06:36.350075 37958 solver.cpp:333] Iteration 6000, Testing net (#0)
I1026 17:07:07.299028 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52012
I1026 17:07:07.299218 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76304
I1026 17:07:07.299233 37958 solver.cpp:400]     Test net output #2: loss = 2.13187 (* 1 = 2.13187 loss)
I1026 17:07:08.063220 37958 solver.cpp:221] Iteration 6000 (0.649554 iter/s, 61.5807s/40 iters), loss = 1.99355
I1026 17:07:08.063274 37958 solver.cpp:240]     Train net output #0: loss = 1.99355 (* 1 = 1.99355 loss)
I1026 17:07:08.063288 37958 sgd_solver.cpp:105] Iteration 6000, lr = 0.00964706
I1026 17:07:39.346007 37958 solver.cpp:221] Iteration 6040 (1.27871 iter/s, 31.2815s/40 iters), loss = 1.77338
I1026 17:07:39.346220 37958 solver.cpp:240]     Train net output #0: loss = 1.77338 (* 1 = 1.77338 loss)
I1026 17:07:39.346238 37958 sgd_solver.cpp:105] Iteration 6040, lr = 0.00964471
I1026 17:08:10.672600 37958 solver.cpp:221] Iteration 6080 (1.27693 iter/s, 31.3252s/40 iters), loss = 1.31938
I1026 17:08:10.672790 37958 solver.cpp:240]     Train net output #0: loss = 1.31938 (* 1 = 1.31938 loss)
I1026 17:08:10.672804 37958 sgd_solver.cpp:105] Iteration 6080, lr = 0.00964235
I1026 17:08:41.612113 37958 solver.cpp:221] Iteration 6120 (1.2929 iter/s, 30.9382s/40 iters), loss = 1.90819
I1026 17:08:41.612416 37958 solver.cpp:240]     Train net output #0: loss = 1.90819 (* 1 = 1.90819 loss)
I1026 17:08:41.612448 37958 sgd_solver.cpp:105] Iteration 6120, lr = 0.00964
I1026 17:09:21.211014 38011 blocking_queue.cpp:49] Waiting for data
I1026 17:09:44.849349 37958 solver.cpp:221] Iteration 6160 (0.632565 iter/s, 63.2346s/40 iters), loss = 1.89051
I1026 17:09:44.849412 37958 solver.cpp:240]     Train net output #0: loss = 1.89051 (* 1 = 1.89051 loss)
I1026 17:09:44.849426 37958 sgd_solver.cpp:105] Iteration 6160, lr = 0.00963765
I1026 17:10:15.648905 37958 solver.cpp:221] Iteration 6200 (1.29877 iter/s, 30.7983s/40 iters), loss = 2.03207
I1026 17:10:15.649094 37958 solver.cpp:240]     Train net output #0: loss = 2.03207 (* 1 = 2.03207 loss)
I1026 17:10:15.649109 37958 sgd_solver.cpp:105] Iteration 6200, lr = 0.00963529
I1026 17:10:46.460805 37958 solver.cpp:221] Iteration 6240 (1.29826 iter/s, 30.8106s/40 iters), loss = 1.72911
I1026 17:10:46.460973 37958 solver.cpp:240]     Train net output #0: loss = 1.72911 (* 1 = 1.72911 loss)
I1026 17:10:46.460988 37958 sgd_solver.cpp:105] Iteration 6240, lr = 0.00963294
I1026 17:11:17.528558 37958 solver.cpp:221] Iteration 6280 (1.28756 iter/s, 31.0664s/40 iters), loss = 1.92581
I1026 17:11:17.528751 37958 solver.cpp:240]     Train net output #0: loss = 1.92581 (* 1 = 1.92581 loss)
I1026 17:11:17.528766 37958 sgd_solver.cpp:105] Iteration 6280, lr = 0.00963059
I1026 17:11:49.968943 37958 solver.cpp:221] Iteration 6320 (1.23308 iter/s, 32.439s/40 iters), loss = 1.69534
I1026 17:11:49.969125 37958 solver.cpp:240]     Train net output #0: loss = 1.69534 (* 1 = 1.69534 loss)
I1026 17:11:49.969139 37958 sgd_solver.cpp:105] Iteration 6320, lr = 0.00962823
I1026 17:12:21.066107 37958 solver.cpp:221] Iteration 6360 (1.28635 iter/s, 31.0958s/40 iters), loss = 1.73239
I1026 17:12:21.066325 37958 solver.cpp:240]     Train net output #0: loss = 1.73239 (* 1 = 1.73239 loss)
I1026 17:12:21.066341 37958 sgd_solver.cpp:105] Iteration 6360, lr = 0.00962588
I1026 17:12:52.039275 37958 solver.cpp:221] Iteration 6400 (1.2915 iter/s, 30.9718s/40 iters), loss = 1.93631
I1026 17:12:52.039468 37958 solver.cpp:240]     Train net output #0: loss = 1.93631 (* 1 = 1.93631 loss)
I1026 17:12:52.039482 37958 sgd_solver.cpp:105] Iteration 6400, lr = 0.00962353
I1026 17:13:22.860873 37958 solver.cpp:221] Iteration 6440 (1.29785 iter/s, 30.8202s/40 iters), loss = 1.98685
I1026 17:13:22.861101 37958 solver.cpp:240]     Train net output #0: loss = 1.98685 (* 1 = 1.98685 loss)
I1026 17:13:22.861122 37958 sgd_solver.cpp:105] Iteration 6440, lr = 0.00962118
I1026 17:13:53.716404 37958 solver.cpp:221] Iteration 6480 (1.29642 iter/s, 30.8541s/40 iters), loss = 1.84596
I1026 17:13:53.716583 37958 solver.cpp:240]     Train net output #0: loss = 1.84596 (* 1 = 1.84596 loss)
I1026 17:13:53.716598 37958 sgd_solver.cpp:105] Iteration 6480, lr = 0.00961882
I1026 17:14:08.517771 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_6500.caffemodel
I1026 17:14:08.562535 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_6500.solverstate
I1026 17:14:08.588093 37958 solver.cpp:333] Iteration 6500, Testing net (#0)
I1026 17:14:39.344513 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 17:14:39.554941 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.51828
I1026 17:14:39.554993 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76512
I1026 17:14:39.555004 37958 solver.cpp:400]     Test net output #2: loss = 2.13914 (* 1 = 2.13914 loss)
I1026 17:14:55.794797 37958 solver.cpp:221] Iteration 6520 (0.644373 iter/s, 62.0759s/40 iters), loss = 1.90811
I1026 17:14:55.794864 37958 solver.cpp:240]     Train net output #0: loss = 1.90811 (* 1 = 1.90811 loss)
I1026 17:14:55.794878 37958 sgd_solver.cpp:105] Iteration 6520, lr = 0.00961647
I1026 17:15:27.677438 37958 solver.cpp:221] Iteration 6560 (1.25465 iter/s, 31.8813s/40 iters), loss = 1.91507
I1026 17:15:27.677705 37958 solver.cpp:240]     Train net output #0: loss = 1.91507 (* 1 = 1.91507 loss)
I1026 17:15:27.677726 37958 sgd_solver.cpp:105] Iteration 6560, lr = 0.00961412
I1026 17:15:58.554477 37958 solver.cpp:221] Iteration 6600 (1.29552 iter/s, 30.8756s/40 iters), loss = 2.06747
I1026 17:15:58.554663 37958 solver.cpp:240]     Train net output #0: loss = 2.06747 (* 1 = 2.06747 loss)
I1026 17:15:58.554677 37958 sgd_solver.cpp:105] Iteration 6600, lr = 0.00961176
I1026 17:16:28.988976 37958 solver.cpp:221] Iteration 6640 (1.31436 iter/s, 30.4332s/40 iters), loss = 1.99718
I1026 17:16:28.989169 37958 solver.cpp:240]     Train net output #0: loss = 1.99718 (* 1 = 1.99718 loss)
I1026 17:16:28.989183 37958 sgd_solver.cpp:105] Iteration 6640, lr = 0.00960941
I1026 17:16:59.294512 37958 solver.cpp:221] Iteration 6680 (1.31995 iter/s, 30.3042s/40 iters), loss = 1.96689
I1026 17:16:59.294690 37958 solver.cpp:240]     Train net output #0: loss = 1.96689 (* 1 = 1.96689 loss)
I1026 17:16:59.294705 37958 sgd_solver.cpp:105] Iteration 6680, lr = 0.00960706
I1026 17:17:30.192553 37958 solver.cpp:221] Iteration 6720 (1.29464 iter/s, 30.8967s/40 iters), loss = 1.79744
I1026 17:17:30.192725 37958 solver.cpp:240]     Train net output #0: loss = 1.79744 (* 1 = 1.79744 loss)
I1026 17:17:30.192740 37958 sgd_solver.cpp:105] Iteration 6720, lr = 0.00960471
I1026 17:18:01.253752 37958 solver.cpp:221] Iteration 6760 (1.28784 iter/s, 31.0599s/40 iters), loss = 1.98119
I1026 17:18:01.253967 37958 solver.cpp:240]     Train net output #0: loss = 1.98119 (* 1 = 1.98119 loss)
I1026 17:18:01.253980 37958 sgd_solver.cpp:105] Iteration 6760, lr = 0.00960235
I1026 17:18:31.940275 37958 solver.cpp:221] Iteration 6800 (1.30356 iter/s, 30.6852s/40 iters), loss = 2.01316
I1026 17:18:31.940454 37958 solver.cpp:240]     Train net output #0: loss = 2.01316 (* 1 = 2.01316 loss)
I1026 17:18:31.940469 37958 sgd_solver.cpp:105] Iteration 6800, lr = 0.0096
I1026 17:19:02.467450 37958 solver.cpp:221] Iteration 6840 (1.31036 iter/s, 30.5258s/40 iters), loss = 1.84038
I1026 17:19:02.467615 37958 solver.cpp:240]     Train net output #0: loss = 1.84038 (* 1 = 1.84038 loss)
I1026 17:19:02.467630 37958 sgd_solver.cpp:105] Iteration 6840, lr = 0.00959765
I1026 17:19:32.967120 37958 solver.cpp:221] Iteration 6880 (1.31155 iter/s, 30.4984s/40 iters), loss = 1.97185
I1026 17:19:32.967289 37958 solver.cpp:240]     Train net output #0: loss = 1.97185 (* 1 = 1.97185 loss)
I1026 17:19:32.967310 37958 sgd_solver.cpp:105] Iteration 6880, lr = 0.00959529
I1026 17:20:03.445420 37958 solver.cpp:221] Iteration 6920 (1.31247 iter/s, 30.477s/40 iters), loss = 1.66471
I1026 17:20:03.445595 37958 solver.cpp:240]     Train net output #0: loss = 1.66471 (* 1 = 1.66471 loss)
I1026 17:20:03.445611 37958 sgd_solver.cpp:105] Iteration 6920, lr = 0.00959294
I1026 17:20:33.674448 37958 solver.cpp:221] Iteration 6960 (1.32329 iter/s, 30.2277s/40 iters), loss = 1.85017
I1026 17:20:33.674619 37958 solver.cpp:240]     Train net output #0: loss = 1.85017 (* 1 = 1.85017 loss)
I1026 17:20:33.674634 37958 sgd_solver.cpp:105] Iteration 6960, lr = 0.00959059
I1026 17:21:03.160225 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_7000.caffemodel
I1026 17:21:03.193439 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_7000.solverstate
I1026 17:21:03.212045 37958 solver.cpp:333] Iteration 7000, Testing net (#0)
I1026 17:21:34.241369 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.5196
I1026 17:21:34.241593 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.7644
I1026 17:21:34.241607 37958 solver.cpp:400]     Test net output #2: loss = 2.14544 (* 1 = 2.14544 loss)
I1026 17:21:35.007320 37958 solver.cpp:221] Iteration 7000 (0.652205 iter/s, 61.3304s/40 iters), loss = 1.84038
I1026 17:21:35.007357 37958 solver.cpp:240]     Train net output #0: loss = 1.84038 (* 1 = 1.84038 loss)
I1026 17:21:35.007387 37958 sgd_solver.cpp:105] Iteration 7000, lr = 0.00958824
I1026 17:22:05.545727 37958 solver.cpp:221] Iteration 7040 (1.30988 iter/s, 30.5372s/40 iters), loss = 2.08594
I1026 17:22:05.545995 37958 solver.cpp:240]     Train net output #0: loss = 2.08594 (* 1 = 2.08594 loss)
I1026 17:22:05.546026 37958 sgd_solver.cpp:105] Iteration 7040, lr = 0.00958588
I1026 17:22:35.831552 37958 solver.cpp:221] Iteration 7080 (1.32081 iter/s, 30.2844s/40 iters), loss = 1.54573
I1026 17:22:35.831738 37958 solver.cpp:240]     Train net output #0: loss = 1.54573 (* 1 = 1.54573 loss)
I1026 17:22:35.831753 37958 sgd_solver.cpp:105] Iteration 7080, lr = 0.00958353
I1026 17:23:06.139333 37958 solver.cpp:221] Iteration 7120 (1.31985 iter/s, 30.3064s/40 iters), loss = 2.02136
I1026 17:23:06.139484 37958 solver.cpp:240]     Train net output #0: loss = 2.02136 (* 1 = 2.02136 loss)
I1026 17:23:06.139499 37958 sgd_solver.cpp:105] Iteration 7120, lr = 0.00958118
I1026 17:23:36.479856 37958 solver.cpp:221] Iteration 7160 (1.31843 iter/s, 30.3392s/40 iters), loss = 2.01807
I1026 17:23:36.480047 37958 solver.cpp:240]     Train net output #0: loss = 2.01807 (* 1 = 2.01807 loss)
I1026 17:23:36.480062 37958 sgd_solver.cpp:105] Iteration 7160, lr = 0.00957882
I1026 17:24:06.745098 37958 solver.cpp:221] Iteration 7200 (1.32171 iter/s, 30.2639s/40 iters), loss = 2.1445
I1026 17:24:06.745281 37958 solver.cpp:240]     Train net output #0: loss = 2.1445 (* 1 = 2.1445 loss)
I1026 17:24:06.745301 37958 sgd_solver.cpp:105] Iteration 7200, lr = 0.00957647
I1026 17:24:37.732861 37958 solver.cpp:221] Iteration 7240 (1.29089 iter/s, 30.9864s/40 iters), loss = 1.91623
I1026 17:24:37.733050 37958 solver.cpp:240]     Train net output #0: loss = 1.91623 (* 1 = 1.91623 loss)
I1026 17:24:37.733064 37958 sgd_solver.cpp:105] Iteration 7240, lr = 0.00957412
I1026 17:25:09.411308 37958 solver.cpp:221] Iteration 7280 (1.26274 iter/s, 31.677s/40 iters), loss = 2.12449
I1026 17:25:09.411510 37958 solver.cpp:240]     Train net output #0: loss = 2.12449 (* 1 = 2.12449 loss)
I1026 17:25:09.411525 37958 sgd_solver.cpp:105] Iteration 7280, lr = 0.00957176
I1026 17:25:41.520658 37958 solver.cpp:221] Iteration 7320 (1.2458 iter/s, 32.1079s/40 iters), loss = 1.65414
I1026 17:25:41.520917 37958 solver.cpp:240]     Train net output #0: loss = 1.65414 (* 1 = 1.65414 loss)
I1026 17:25:41.520941 37958 sgd_solver.cpp:105] Iteration 7320, lr = 0.00956941
I1026 17:26:12.799094 37958 solver.cpp:221] Iteration 7360 (1.2789 iter/s, 31.277s/40 iters), loss = 1.89441
I1026 17:26:12.799294 37958 solver.cpp:240]     Train net output #0: loss = 1.89441 (* 1 = 1.89441 loss)
I1026 17:26:12.799314 37958 sgd_solver.cpp:105] Iteration 7360, lr = 0.00956706
I1026 17:26:43.545714 37958 solver.cpp:221] Iteration 7400 (1.30101 iter/s, 30.7453s/40 iters), loss = 2.21686
I1026 17:26:43.545887 37958 solver.cpp:240]     Train net output #0: loss = 2.21686 (* 1 = 2.21686 loss)
I1026 17:26:43.545902 37958 sgd_solver.cpp:105] Iteration 7400, lr = 0.00956471
I1026 17:27:13.818328 37958 solver.cpp:221] Iteration 7440 (1.32138 iter/s, 30.2713s/40 iters), loss = 2.13725
I1026 17:27:13.818522 37958 solver.cpp:240]     Train net output #0: loss = 2.13725 (* 1 = 2.13725 loss)
I1026 17:27:13.818537 37958 sgd_solver.cpp:105] Iteration 7440, lr = 0.00956235
I1026 17:27:45.006841 37958 solver.cpp:221] Iteration 7480 (1.28258 iter/s, 31.1871s/40 iters), loss = 2.05236
I1026 17:27:45.007079 37958 solver.cpp:240]     Train net output #0: loss = 2.05236 (* 1 = 2.05236 loss)
I1026 17:27:45.007099 37958 sgd_solver.cpp:105] Iteration 7480, lr = 0.00956
I1026 17:27:59.941608 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_7500.caffemodel
I1026 17:27:59.985241 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_7500.solverstate
I1026 17:28:00.008460 37958 solver.cpp:333] Iteration 7500, Testing net (#0)
I1026 17:28:32.516340 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 17:28:32.722996 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52008
I1026 17:28:32.723052 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.767
I1026 17:28:32.723063 37958 solver.cpp:400]     Test net output #2: loss = 2.13858 (* 1 = 2.13858 loss)
I1026 17:28:35.352717 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1026 17:28:48.616004 37958 solver.cpp:221] Iteration 7520 (0.628866 iter/s, 63.6065s/40 iters), loss = 1.91328
I1026 17:28:48.616056 37958 solver.cpp:240]     Train net output #0: loss = 1.91328 (* 1 = 1.91328 loss)
I1026 17:28:48.616070 37958 sgd_solver.cpp:105] Iteration 7520, lr = 0.00955765
I1026 17:29:18.893769 37958 solver.cpp:221] Iteration 7560 (1.32115 iter/s, 30.2766s/40 iters), loss = 1.99573
I1026 17:29:18.893949 37958 solver.cpp:240]     Train net output #0: loss = 1.99573 (* 1 = 1.99573 loss)
I1026 17:29:18.893965 37958 sgd_solver.cpp:105] Iteration 7560, lr = 0.00955529
I1026 17:29:49.375177 37958 solver.cpp:221] Iteration 7600 (1.31233 iter/s, 30.4801s/40 iters), loss = 1.99965
I1026 17:29:49.375365 37958 solver.cpp:240]     Train net output #0: loss = 1.99965 (* 1 = 1.99965 loss)
I1026 17:29:49.375380 37958 sgd_solver.cpp:105] Iteration 7600, lr = 0.00955294
I1026 17:30:19.793292 37958 solver.cpp:221] Iteration 7640 (1.31506 iter/s, 30.4168s/40 iters), loss = 1.82327
I1026 17:30:19.793481 37958 solver.cpp:240]     Train net output #0: loss = 1.82327 (* 1 = 1.82327 loss)
I1026 17:30:19.793495 37958 sgd_solver.cpp:105] Iteration 7640, lr = 0.00955059
I1026 17:30:50.506206 37958 solver.cpp:221] Iteration 7680 (1.30244 iter/s, 30.7116s/40 iters), loss = 2.00443
I1026 17:30:50.506386 37958 solver.cpp:240]     Train net output #0: loss = 2.00443 (* 1 = 2.00443 loss)
I1026 17:30:50.506402 37958 sgd_solver.cpp:105] Iteration 7680, lr = 0.00954824
I1026 17:31:21.429569 37958 solver.cpp:221] Iteration 7720 (1.29358 iter/s, 30.922s/40 iters), loss = 1.97111
I1026 17:31:21.429781 37958 solver.cpp:240]     Train net output #0: loss = 1.97111 (* 1 = 1.97111 loss)
I1026 17:31:21.429796 37958 sgd_solver.cpp:105] Iteration 7720, lr = 0.00954588
I1026 17:31:52.174949 37958 solver.cpp:221] Iteration 7760 (1.30107 iter/s, 30.744s/40 iters), loss = 1.5693
I1026 17:31:52.175159 37958 solver.cpp:240]     Train net output #0: loss = 1.5693 (* 1 = 1.5693 loss)
I1026 17:31:52.175174 37958 sgd_solver.cpp:105] Iteration 7760, lr = 0.00954353
I1026 17:32:23.078368 37958 solver.cpp:221] Iteration 7800 (1.29441 iter/s, 30.902s/40 iters), loss = 2.06653
I1026 17:32:23.078522 37958 solver.cpp:240]     Train net output #0: loss = 2.06653 (* 1 = 2.06653 loss)
I1026 17:32:23.078538 37958 sgd_solver.cpp:105] Iteration 7800, lr = 0.00954118
I1026 17:32:53.521663 37958 solver.cpp:221] Iteration 7840 (1.31397 iter/s, 30.442s/40 iters), loss = 1.68943
I1026 17:32:53.521855 37958 solver.cpp:240]     Train net output #0: loss = 1.68943 (* 1 = 1.68943 loss)
I1026 17:32:53.521870 37958 sgd_solver.cpp:105] Iteration 7840, lr = 0.00953882
I1026 17:33:23.880168 37958 solver.cpp:221] Iteration 7880 (1.31765 iter/s, 30.3572s/40 iters), loss = 2.07423
I1026 17:33:23.880491 37958 solver.cpp:240]     Train net output #0: loss = 2.07423 (* 1 = 2.07423 loss)
I1026 17:33:23.880506 37958 sgd_solver.cpp:105] Iteration 7880, lr = 0.00953647
I1026 17:33:56.715631 37958 solver.cpp:221] Iteration 7920 (1.21825 iter/s, 32.8339s/40 iters), loss = 1.90634
I1026 17:33:56.715910 37958 solver.cpp:240]     Train net output #0: loss = 1.90634 (* 1 = 1.90634 loss)
I1026 17:33:56.715934 37958 sgd_solver.cpp:105] Iteration 7920, lr = 0.00953412
I1026 17:34:33.191198 37958 solver.cpp:221] Iteration 7960 (1.09667 iter/s, 36.4739s/40 iters), loss = 1.80735
I1026 17:34:33.191448 37958 solver.cpp:240]     Train net output #0: loss = 1.80735 (* 1 = 1.80735 loss)
I1026 17:34:33.191469 37958 sgd_solver.cpp:105] Iteration 7960, lr = 0.00953176
I1026 17:35:03.796550 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_8000.caffemodel
I1026 17:35:03.831382 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_8000.solverstate
I1026 17:35:03.850812 37958 solver.cpp:333] Iteration 8000, Testing net (#0)
I1026 17:35:34.760728 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.5214
I1026 17:35:34.760887 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76712
I1026 17:35:34.760900 37958 solver.cpp:400]     Test net output #2: loss = 2.15127 (* 1 = 2.15127 loss)
I1026 17:35:35.526407 37958 solver.cpp:221] Iteration 8000 (0.641719 iter/s, 62.3326s/40 iters), loss = 2.33187
I1026 17:35:35.526463 37958 solver.cpp:240]     Train net output #0: loss = 2.33187 (* 1 = 2.33187 loss)
I1026 17:35:35.526477 37958 sgd_solver.cpp:105] Iteration 8000, lr = 0.00952941
I1026 17:36:06.446085 37958 solver.cpp:221] Iteration 8040 (1.29373 iter/s, 30.9185s/40 iters), loss = 2.02344
I1026 17:36:06.446285 37958 solver.cpp:240]     Train net output #0: loss = 2.02344 (* 1 = 2.02344 loss)
I1026 17:36:06.446303 37958 sgd_solver.cpp:105] Iteration 8040, lr = 0.00952706
I1026 17:36:37.279695 37958 solver.cpp:221] Iteration 8080 (1.29734 iter/s, 30.8322s/40 iters), loss = 1.95104
I1026 17:36:37.279934 37958 solver.cpp:240]     Train net output #0: loss = 1.95104 (* 1 = 1.95104 loss)
I1026 17:36:37.279956 37958 sgd_solver.cpp:105] Iteration 8080, lr = 0.00952471
I1026 17:37:08.191184 37958 solver.cpp:221] Iteration 8120 (1.29408 iter/s, 30.9101s/40 iters), loss = 1.70773
I1026 17:37:08.191382 37958 solver.cpp:240]     Train net output #0: loss = 1.70773 (* 1 = 1.70773 loss)
I1026 17:37:08.191397 37958 sgd_solver.cpp:105] Iteration 8120, lr = 0.00952235
I1026 17:37:39.039818 37958 solver.cpp:221] Iteration 8160 (1.29671 iter/s, 30.8473s/40 iters), loss = 2.01228
I1026 17:37:39.040001 37958 solver.cpp:240]     Train net output #0: loss = 2.01228 (* 1 = 2.01228 loss)
I1026 17:37:39.040016 37958 sgd_solver.cpp:105] Iteration 8160, lr = 0.00952
I1026 17:38:09.743623 37958 solver.cpp:221] Iteration 8200 (1.30283 iter/s, 30.7025s/40 iters), loss = 1.90319
I1026 17:38:09.743800 37958 solver.cpp:240]     Train net output #0: loss = 1.90319 (* 1 = 1.90319 loss)
I1026 17:38:09.743815 37958 sgd_solver.cpp:105] Iteration 8200, lr = 0.00951765
I1026 17:38:40.498634 37958 solver.cpp:221] Iteration 8240 (1.30066 iter/s, 30.7537s/40 iters), loss = 1.71045
I1026 17:38:40.498862 37958 solver.cpp:240]     Train net output #0: loss = 1.71045 (* 1 = 1.71045 loss)
I1026 17:38:40.498881 37958 sgd_solver.cpp:105] Iteration 8240, lr = 0.00951529
I1026 17:39:11.235707 37958 solver.cpp:221] Iteration 8280 (1.30142 iter/s, 30.7357s/40 iters), loss = 1.82406
I1026 17:39:11.235901 37958 solver.cpp:240]     Train net output #0: loss = 1.82406 (* 1 = 1.82406 loss)
I1026 17:39:11.235918 37958 sgd_solver.cpp:105] Iteration 8280, lr = 0.00951294
I1026 17:39:41.635468 37958 solver.cpp:221] Iteration 8320 (1.31586 iter/s, 30.3984s/40 iters), loss = 1.81131
I1026 17:39:41.635648 37958 solver.cpp:240]     Train net output #0: loss = 1.81131 (* 1 = 1.81131 loss)
I1026 17:39:41.635663 37958 sgd_solver.cpp:105] Iteration 8320, lr = 0.00951059
I1026 17:40:12.424839 37958 solver.cpp:221] Iteration 8360 (1.29921 iter/s, 30.788s/40 iters), loss = 1.94856
I1026 17:40:12.425019 37958 solver.cpp:240]     Train net output #0: loss = 1.94856 (* 1 = 1.94856 loss)
I1026 17:40:12.425034 37958 sgd_solver.cpp:105] Iteration 8360, lr = 0.00950824
I1026 17:40:42.607082 37958 solver.cpp:221] Iteration 8400 (1.32534 iter/s, 30.1809s/40 iters), loss = 1.92069
I1026 17:40:42.607273 37958 solver.cpp:240]     Train net output #0: loss = 1.92069 (* 1 = 1.92069 loss)
I1026 17:40:42.607288 37958 sgd_solver.cpp:105] Iteration 8400, lr = 0.00950588
I1026 17:41:14.069365 37958 solver.cpp:221] Iteration 8440 (1.27142 iter/s, 31.4609s/40 iters), loss = 1.94345
I1026 17:41:14.069617 37958 solver.cpp:240]     Train net output #0: loss = 1.94345 (* 1 = 1.94345 loss)
I1026 17:41:14.069639 37958 sgd_solver.cpp:105] Iteration 8440, lr = 0.00950353
I1026 17:41:45.129463 37958 solver.cpp:221] Iteration 8480 (1.28789 iter/s, 31.0587s/40 iters), loss = 1.89348
I1026 17:41:45.129724 37958 solver.cpp:240]     Train net output #0: loss = 1.89348 (* 1 = 1.89348 loss)
I1026 17:41:45.129739 37958 sgd_solver.cpp:105] Iteration 8480, lr = 0.00950118
I1026 17:41:59.551403 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_8500.caffemodel
I1026 17:41:59.584633 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_8500.solverstate
I1026 17:41:59.602365 37958 solver.cpp:333] Iteration 8500, Testing net (#0)
I1026 17:42:30.320117 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 17:42:30.525497 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.51332
I1026 17:42:30.525540 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.75932
I1026 17:42:30.525552 37958 solver.cpp:400]     Test net output #2: loss = 2.17697 (* 1 = 2.17697 loss)
I1026 17:42:46.746037 37958 solver.cpp:221] Iteration 8520 (0.649203 iter/s, 61.614s/40 iters), loss = 1.55428
I1026 17:42:46.746131 37958 solver.cpp:240]     Train net output #0: loss = 1.55428 (* 1 = 1.55428 loss)
I1026 17:42:46.746150 37958 sgd_solver.cpp:105] Iteration 8520, lr = 0.00949882
I1026 17:43:17.265909 37958 solver.cpp:221] Iteration 8560 (1.31068 iter/s, 30.5186s/40 iters), loss = 1.50193
I1026 17:43:17.266104 37958 solver.cpp:240]     Train net output #0: loss = 1.50193 (* 1 = 1.50193 loss)
I1026 17:43:17.266119 37958 sgd_solver.cpp:105] Iteration 8560, lr = 0.00949647
I1026 17:43:48.108638 37958 solver.cpp:221] Iteration 8600 (1.29696 iter/s, 30.8414s/40 iters), loss = 1.68104
I1026 17:43:48.108846 37958 solver.cpp:240]     Train net output #0: loss = 1.68104 (* 1 = 1.68104 loss)
I1026 17:43:48.108861 37958 sgd_solver.cpp:105] Iteration 8600, lr = 0.00949412
I1026 17:44:18.808878 37958 solver.cpp:221] Iteration 8640 (1.30298 iter/s, 30.6989s/40 iters), loss = 1.86497
I1026 17:44:18.809065 37958 solver.cpp:240]     Train net output #0: loss = 1.86497 (* 1 = 1.86497 loss)
I1026 17:44:18.809082 37958 sgd_solver.cpp:105] Iteration 8640, lr = 0.00949176
I1026 17:44:49.710908 37958 solver.cpp:221] Iteration 8680 (1.29447 iter/s, 30.9007s/40 iters), loss = 1.78268
I1026 17:44:49.711112 37958 solver.cpp:240]     Train net output #0: loss = 1.78268 (* 1 = 1.78268 loss)
I1026 17:44:49.711127 37958 sgd_solver.cpp:105] Iteration 8680, lr = 0.00948941
I1026 17:45:20.430526 37958 solver.cpp:221] Iteration 8720 (1.30216 iter/s, 30.7182s/40 iters), loss = 1.92269
I1026 17:45:20.430776 37958 solver.cpp:240]     Train net output #0: loss = 1.92269 (* 1 = 1.92269 loss)
I1026 17:45:20.430797 37958 sgd_solver.cpp:105] Iteration 8720, lr = 0.00948706
I1026 17:45:52.775557 37958 solver.cpp:221] Iteration 8760 (1.23672 iter/s, 32.3436s/40 iters), loss = 1.71975
I1026 17:45:52.775790 37958 solver.cpp:240]     Train net output #0: loss = 1.71975 (* 1 = 1.71975 loss)
I1026 17:45:52.775809 37958 sgd_solver.cpp:105] Iteration 8760, lr = 0.00948471
I1026 17:46:23.930153 37958 solver.cpp:221] Iteration 8800 (1.28398 iter/s, 31.1532s/40 iters), loss = 1.61895
I1026 17:46:23.930375 37958 solver.cpp:240]     Train net output #0: loss = 1.61895 (* 1 = 1.61895 loss)
I1026 17:46:23.930390 37958 sgd_solver.cpp:105] Iteration 8800, lr = 0.00948235
I1026 17:46:54.433270 37958 solver.cpp:221] Iteration 8840 (1.3114 iter/s, 30.5017s/40 iters), loss = 2.27487
I1026 17:46:54.433492 37958 solver.cpp:240]     Train net output #0: loss = 2.27487 (* 1 = 2.27487 loss)
I1026 17:46:54.433507 37958 sgd_solver.cpp:105] Iteration 8840, lr = 0.00948
I1026 17:47:25.131785 37958 solver.cpp:221] Iteration 8880 (1.30305 iter/s, 30.6971s/40 iters), loss = 1.7777
I1026 17:47:25.132028 37958 solver.cpp:240]     Train net output #0: loss = 1.7777 (* 1 = 1.7777 loss)
I1026 17:47:25.132052 37958 sgd_solver.cpp:105] Iteration 8880, lr = 0.00947765
I1026 17:47:55.750949 37958 solver.cpp:221] Iteration 8920 (1.30643 iter/s, 30.6178s/40 iters), loss = 1.6819
I1026 17:47:55.751204 37958 solver.cpp:240]     Train net output #0: loss = 1.6819 (* 1 = 1.6819 loss)
I1026 17:47:55.751219 37958 sgd_solver.cpp:105] Iteration 8920, lr = 0.00947529
I1026 17:48:26.305480 37958 solver.cpp:221] Iteration 8960 (1.30919 iter/s, 30.5531s/40 iters), loss = 2.02873
I1026 17:48:26.305666 37958 solver.cpp:240]     Train net output #0: loss = 2.02873 (* 1 = 2.02873 loss)
I1026 17:48:26.305680 37958 sgd_solver.cpp:105] Iteration 8960, lr = 0.00947294
I1026 17:48:56.147853 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_9000.caffemodel
I1026 17:48:56.180506 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_9000.solverstate
I1026 17:48:56.198145 37958 solver.cpp:333] Iteration 9000, Testing net (#0)
I1026 17:49:27.133213 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.524
I1026 17:49:27.133397 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76796
I1026 17:49:27.133410 37958 solver.cpp:400]     Test net output #2: loss = 2.139 (* 1 = 2.139 loss)
I1026 17:49:27.892433 37958 solver.cpp:221] Iteration 9000 (0.649514 iter/s, 61.5845s/40 iters), loss = 1.48173
I1026 17:49:27.892477 37958 solver.cpp:240]     Train net output #0: loss = 1.48173 (* 1 = 1.48173 loss)
I1026 17:49:27.892490 37958 sgd_solver.cpp:105] Iteration 9000, lr = 0.00947059
I1026 17:49:58.596845 37958 solver.cpp:221] Iteration 9040 (1.3028 iter/s, 30.7032s/40 iters), loss = 2.28394
I1026 17:49:58.597030 37958 solver.cpp:240]     Train net output #0: loss = 2.28394 (* 1 = 2.28394 loss)
I1026 17:49:58.597045 37958 sgd_solver.cpp:105] Iteration 9040, lr = 0.00946824
I1026 17:50:29.346665 37958 solver.cpp:221] Iteration 9080 (1.30088 iter/s, 30.7485s/40 iters), loss = 1.68666
I1026 17:50:29.346859 37958 solver.cpp:240]     Train net output #0: loss = 1.68666 (* 1 = 1.68666 loss)
I1026 17:50:29.346874 37958 sgd_solver.cpp:105] Iteration 9080, lr = 0.00946588
I1026 17:51:00.260511 37958 solver.cpp:221] Iteration 9120 (1.29398 iter/s, 30.9125s/40 iters), loss = 1.7022
I1026 17:51:00.260684 37958 solver.cpp:240]     Train net output #0: loss = 1.7022 (* 1 = 1.7022 loss)
I1026 17:51:00.260699 37958 sgd_solver.cpp:105] Iteration 9120, lr = 0.00946353
I1026 17:51:31.246309 37958 solver.cpp:221] Iteration 9160 (1.29097 iter/s, 30.9844s/40 iters), loss = 2.10627
I1026 17:51:31.246522 37958 solver.cpp:240]     Train net output #0: loss = 2.10627 (* 1 = 2.10627 loss)
I1026 17:51:31.246536 37958 sgd_solver.cpp:105] Iteration 9160, lr = 0.00946118
I1026 17:52:02.181254 37958 solver.cpp:221] Iteration 9200 (1.29309 iter/s, 30.9336s/40 iters), loss = 1.98374
I1026 17:52:02.181459 37958 solver.cpp:240]     Train net output #0: loss = 1.98374 (* 1 = 1.98374 loss)
I1026 17:52:02.181475 37958 sgd_solver.cpp:105] Iteration 9200, lr = 0.00945882
I1026 17:52:33.632055 37958 solver.cpp:221] Iteration 9240 (1.27188 iter/s, 31.4494s/40 iters), loss = 1.89201
I1026 17:52:33.632306 37958 solver.cpp:240]     Train net output #0: loss = 1.89201 (* 1 = 1.89201 loss)
I1026 17:52:33.632334 37958 sgd_solver.cpp:105] Iteration 9240, lr = 0.00945647
I1026 17:53:04.753942 37958 solver.cpp:221] Iteration 9280 (1.28533 iter/s, 31.1205s/40 iters), loss = 1.9569
I1026 17:53:04.754159 37958 solver.cpp:240]     Train net output #0: loss = 1.9569 (* 1 = 1.9569 loss)
I1026 17:53:04.754174 37958 sgd_solver.cpp:105] Iteration 9280, lr = 0.00945412
I1026 17:53:35.671963 37958 solver.cpp:221] Iteration 9320 (1.2938 iter/s, 30.9166s/40 iters), loss = 1.803
I1026 17:53:35.672173 37958 solver.cpp:240]     Train net output #0: loss = 1.803 (* 1 = 1.803 loss)
I1026 17:53:35.672188 37958 sgd_solver.cpp:105] Iteration 9320, lr = 0.00945176
I1026 17:54:06.143064 37958 solver.cpp:221] Iteration 9360 (1.31278 iter/s, 30.4697s/40 iters), loss = 1.95387
I1026 17:54:06.143270 37958 solver.cpp:240]     Train net output #0: loss = 1.95387 (* 1 = 1.95387 loss)
I1026 17:54:06.143285 37958 sgd_solver.cpp:105] Iteration 9360, lr = 0.00944941
I1026 17:54:36.790824 37958 solver.cpp:221] Iteration 9400 (1.30521 iter/s, 30.6464s/40 iters), loss = 1.89756
I1026 17:54:36.791067 37958 solver.cpp:240]     Train net output #0: loss = 1.89756 (* 1 = 1.89756 loss)
I1026 17:54:36.791082 37958 sgd_solver.cpp:105] Iteration 9400, lr = 0.00944706
I1026 17:55:07.444717 37958 solver.cpp:221] Iteration 9440 (1.30495 iter/s, 30.6525s/40 iters), loss = 1.6969
I1026 17:55:07.444939 37958 solver.cpp:240]     Train net output #0: loss = 1.6969 (* 1 = 1.6969 loss)
I1026 17:55:07.444954 37958 sgd_solver.cpp:105] Iteration 9440, lr = 0.00944471
I1026 17:55:38.304133 37958 solver.cpp:221] Iteration 9480 (1.29626 iter/s, 30.858s/40 iters), loss = 1.62594
I1026 17:55:38.304406 37958 solver.cpp:240]     Train net output #0: loss = 1.62594 (* 1 = 1.62594 loss)
I1026 17:55:38.304420 37958 sgd_solver.cpp:105] Iteration 9480, lr = 0.00944235
I1026 17:55:53.126543 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_9500.caffemodel
I1026 17:55:53.159252 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_9500.solverstate
I1026 17:55:53.176800 37958 solver.cpp:333] Iteration 9500, Testing net (#0)
I1026 17:56:23.899984 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 17:56:24.106263 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52824
I1026 17:56:24.106323 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77124
I1026 17:56:24.106334 37958 solver.cpp:400]     Test net output #2: loss = 2.09549 (* 1 = 2.09549 loss)
I1026 17:56:40.255740 37958 solver.cpp:221] Iteration 9520 (0.645692 iter/s, 61.949s/40 iters), loss = 2.07944
I1026 17:56:40.255816 37958 solver.cpp:240]     Train net output #0: loss = 2.07944 (* 1 = 2.07944 loss)
I1026 17:56:40.255831 37958 sgd_solver.cpp:105] Iteration 9520, lr = 0.00944
I1026 17:57:11.110891 37958 solver.cpp:221] Iteration 9560 (1.29643 iter/s, 30.8539s/40 iters), loss = 2.13473
I1026 17:57:11.111119 37958 solver.cpp:240]     Train net output #0: loss = 2.13473 (* 1 = 2.13473 loss)
I1026 17:57:11.111133 37958 sgd_solver.cpp:105] Iteration 9560, lr = 0.00943765
I1026 17:57:41.686189 37958 solver.cpp:221] Iteration 9600 (1.30831 iter/s, 30.5739s/40 iters), loss = 1.80343
I1026 17:57:41.686370 37958 solver.cpp:240]     Train net output #0: loss = 1.80343 (* 1 = 1.80343 loss)
I1026 17:57:41.686384 37958 sgd_solver.cpp:105] Iteration 9600, lr = 0.00943529
I1026 17:58:12.609131 37958 solver.cpp:221] Iteration 9640 (1.29359 iter/s, 30.9216s/40 iters), loss = 1.88986
I1026 17:58:12.609333 37958 solver.cpp:240]     Train net output #0: loss = 1.88986 (* 1 = 1.88986 loss)
I1026 17:58:12.609349 37958 sgd_solver.cpp:105] Iteration 9640, lr = 0.00943294
I1026 17:58:43.286051 37958 solver.cpp:221] Iteration 9680 (1.30397 iter/s, 30.6755s/40 iters), loss = 1.70567
I1026 17:58:43.286252 37958 solver.cpp:240]     Train net output #0: loss = 1.70567 (* 1 = 1.70567 loss)
I1026 17:58:43.286267 37958 sgd_solver.cpp:105] Iteration 9680, lr = 0.00943059
I1026 17:59:14.244243 37958 solver.cpp:221] Iteration 9720 (1.29212 iter/s, 30.9568s/40 iters), loss = 2.09278
I1026 17:59:14.244424 37958 solver.cpp:240]     Train net output #0: loss = 2.09278 (* 1 = 2.09278 loss)
I1026 17:59:14.244439 37958 sgd_solver.cpp:105] Iteration 9720, lr = 0.00942823
I1026 17:59:44.872319 37958 solver.cpp:221] Iteration 9760 (1.30605 iter/s, 30.6267s/40 iters), loss = 2.21283
I1026 17:59:44.872489 37958 solver.cpp:240]     Train net output #0: loss = 2.21283 (* 1 = 2.21283 loss)
I1026 17:59:44.872503 37958 sgd_solver.cpp:105] Iteration 9760, lr = 0.00942588
I1026 18:00:17.189196 37958 solver.cpp:221] Iteration 9800 (1.2378 iter/s, 32.3155s/40 iters), loss = 2.08331
I1026 18:00:17.189452 37958 solver.cpp:240]     Train net output #0: loss = 2.08331 (* 1 = 2.08331 loss)
I1026 18:00:17.189468 37958 sgd_solver.cpp:105] Iteration 9800, lr = 0.00942353
I1026 18:00:48.180187 37958 solver.cpp:221] Iteration 9840 (1.29076 iter/s, 30.9896s/40 iters), loss = 1.84965
I1026 18:00:48.180496 37958 solver.cpp:240]     Train net output #0: loss = 1.84965 (* 1 = 1.84965 loss)
I1026 18:00:48.180518 37958 sgd_solver.cpp:105] Iteration 9840, lr = 0.00942118
I1026 18:01:19.112951 37958 solver.cpp:221] Iteration 9880 (1.29319 iter/s, 30.9313s/40 iters), loss = 2.05356
I1026 18:01:19.113134 37958 solver.cpp:240]     Train net output #0: loss = 2.05356 (* 1 = 2.05356 loss)
I1026 18:01:19.113149 37958 sgd_solver.cpp:105] Iteration 9880, lr = 0.00941882
I1026 18:01:49.811172 37958 solver.cpp:221] Iteration 9920 (1.30306 iter/s, 30.6969s/40 iters), loss = 1.40595
I1026 18:01:49.811446 37958 solver.cpp:240]     Train net output #0: loss = 1.40595 (* 1 = 1.40595 loss)
I1026 18:01:49.811460 37958 sgd_solver.cpp:105] Iteration 9920, lr = 0.00941647
I1026 18:02:20.380987 37958 solver.cpp:221] Iteration 9960 (1.30854 iter/s, 30.5684s/40 iters), loss = 1.81562
I1026 18:02:20.381196 37958 solver.cpp:240]     Train net output #0: loss = 1.81562 (* 1 = 1.81562 loss)
I1026 18:02:20.381209 37958 sgd_solver.cpp:105] Iteration 9960, lr = 0.00941412
I1026 18:02:50.491607 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_10000.caffemodel
I1026 18:02:50.526069 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_10000.solverstate
I1026 18:02:50.545518 37958 solver.cpp:333] Iteration 10000, Testing net (#0)
I1026 18:03:21.499260 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52144
I1026 18:03:21.499418 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.7678
I1026 18:03:21.499431 37958 solver.cpp:400]     Test net output #2: loss = 2.13931 (* 1 = 2.13931 loss)
I1026 18:03:22.271937 37958 solver.cpp:221] Iteration 10000 (0.646325 iter/s, 61.8884s/40 iters), loss = 1.88111
I1026 18:03:22.272001 37958 solver.cpp:240]     Train net output #0: loss = 1.88111 (* 1 = 1.88111 loss)
I1026 18:03:22.272014 37958 sgd_solver.cpp:105] Iteration 10000, lr = 0.00941176
I1026 18:03:26.148772 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1026 18:03:52.952002 37958 solver.cpp:221] Iteration 10040 (1.30383 iter/s, 30.6788s/40 iters), loss = 1.77487
I1026 18:03:52.952216 37958 solver.cpp:240]     Train net output #0: loss = 1.77487 (* 1 = 1.77487 loss)
I1026 18:03:52.952231 37958 sgd_solver.cpp:105] Iteration 10040, lr = 0.00940941
I1026 18:04:23.487169 37958 solver.cpp:221] Iteration 10080 (1.31002 iter/s, 30.5338s/40 iters), loss = 1.95647
I1026 18:04:23.487357 37958 solver.cpp:240]     Train net output #0: loss = 1.95647 (* 1 = 1.95647 loss)
I1026 18:04:23.487372 37958 sgd_solver.cpp:105] Iteration 10080, lr = 0.00940706
I1026 18:04:54.231161 37958 solver.cpp:221] Iteration 10120 (1.30112 iter/s, 30.7426s/40 iters), loss = 1.92914
I1026 18:04:54.231397 37958 solver.cpp:240]     Train net output #0: loss = 1.92914 (* 1 = 1.92914 loss)
I1026 18:04:54.231412 37958 sgd_solver.cpp:105] Iteration 10120, lr = 0.00940471
I1026 18:05:24.518452 37958 solver.cpp:221] Iteration 10160 (1.32075 iter/s, 30.2859s/40 iters), loss = 1.85276
I1026 18:05:24.518632 37958 solver.cpp:240]     Train net output #0: loss = 1.85276 (* 1 = 1.85276 loss)
I1026 18:05:24.518647 37958 sgd_solver.cpp:105] Iteration 10160, lr = 0.00940235
I1026 18:05:55.049978 37958 solver.cpp:221] Iteration 10200 (1.31018 iter/s, 30.5302s/40 iters), loss = 1.90224
I1026 18:05:55.050177 37958 solver.cpp:240]     Train net output #0: loss = 1.90224 (* 1 = 1.90224 loss)
I1026 18:05:55.050192 37958 sgd_solver.cpp:105] Iteration 10200, lr = 0.0094
I1026 18:06:26.109733 37958 solver.cpp:221] Iteration 10240 (1.2879 iter/s, 31.0584s/40 iters), loss = 1.90421
I1026 18:06:26.109917 37958 solver.cpp:240]     Train net output #0: loss = 1.90421 (* 1 = 1.90421 loss)
I1026 18:06:26.109932 37958 sgd_solver.cpp:105] Iteration 10240, lr = 0.00939765
I1026 18:06:56.778174 37958 solver.cpp:221] Iteration 10280 (1.30433 iter/s, 30.6671s/40 iters), loss = 1.89758
I1026 18:06:56.778461 37958 solver.cpp:240]     Train net output #0: loss = 1.89758 (* 1 = 1.89758 loss)
I1026 18:06:56.778487 37958 sgd_solver.cpp:105] Iteration 10280, lr = 0.00939529
I1026 18:07:27.715935 37958 solver.cpp:221] Iteration 10320 (1.29298 iter/s, 30.9363s/40 iters), loss = 1.80765
I1026 18:07:27.716118 37958 solver.cpp:240]     Train net output #0: loss = 1.80765 (* 1 = 1.80765 loss)
I1026 18:07:27.716133 37958 sgd_solver.cpp:105] Iteration 10320, lr = 0.00939294
I1026 18:08:00.513195 37958 solver.cpp:221] Iteration 10360 (1.21967 iter/s, 32.7958s/40 iters), loss = 2.09
I1026 18:08:00.513440 37958 solver.cpp:240]     Train net output #0: loss = 2.09 (* 1 = 2.09 loss)
I1026 18:08:00.513461 37958 sgd_solver.cpp:105] Iteration 10360, lr = 0.00939059
I1026 18:08:32.333248 37958 solver.cpp:221] Iteration 10400 (1.25713 iter/s, 31.8186s/40 iters), loss = 2.09144
I1026 18:08:32.333447 37958 solver.cpp:240]     Train net output #0: loss = 2.09144 (* 1 = 2.09144 loss)
I1026 18:08:32.333463 37958 sgd_solver.cpp:105] Iteration 10400, lr = 0.00938824
I1026 18:09:03.586628 37958 solver.cpp:221] Iteration 10440 (1.27992 iter/s, 31.252s/40 iters), loss = 1.89891
I1026 18:09:03.586838 37958 solver.cpp:240]     Train net output #0: loss = 1.89891 (* 1 = 1.89891 loss)
I1026 18:09:03.586853 37958 sgd_solver.cpp:105] Iteration 10440, lr = 0.00938588
I1026 18:09:34.302345 37958 solver.cpp:221] Iteration 10480 (1.30232 iter/s, 30.7143s/40 iters), loss = 2.04491
I1026 18:09:34.302510 37958 solver.cpp:240]     Train net output #0: loss = 2.04491 (* 1 = 2.04491 loss)
I1026 18:09:34.302525 37958 sgd_solver.cpp:105] Iteration 10480, lr = 0.00938353
I1026 18:09:48.743301 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_10500.caffemodel
I1026 18:09:48.778883 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_10500.solverstate
I1026 18:09:48.798414 37958 solver.cpp:333] Iteration 10500, Testing net (#0)
I1026 18:10:19.509333 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 18:10:19.715582 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.51876
I1026 18:10:19.715634 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.765039
I1026 18:10:19.715646 37958 solver.cpp:400]     Test net output #2: loss = 2.16812 (* 1 = 2.16812 loss)
I1026 18:10:35.659869 37958 solver.cpp:221] Iteration 10520 (0.651943 iter/s, 61.355s/40 iters), loss = 1.83996
I1026 18:10:35.659931 37958 solver.cpp:240]     Train net output #0: loss = 1.83996 (* 1 = 1.83996 loss)
I1026 18:10:35.659945 37958 sgd_solver.cpp:105] Iteration 10520, lr = 0.00938118
I1026 18:11:07.110635 37958 solver.cpp:221] Iteration 10560 (1.27188 iter/s, 31.4495s/40 iters), loss = 1.63935
I1026 18:11:07.110831 37958 solver.cpp:240]     Train net output #0: loss = 1.63935 (* 1 = 1.63935 loss)
I1026 18:11:07.110846 37958 sgd_solver.cpp:105] Iteration 10560, lr = 0.00937882
I1026 18:11:37.245575 37958 solver.cpp:221] Iteration 10600 (1.32742 iter/s, 30.1336s/40 iters), loss = 1.77981
I1026 18:11:37.245760 37958 solver.cpp:240]     Train net output #0: loss = 1.77981 (* 1 = 1.77981 loss)
I1026 18:11:37.245775 37958 sgd_solver.cpp:105] Iteration 10600, lr = 0.00937647
I1026 18:12:07.456032 37958 solver.cpp:221] Iteration 10640 (1.3241 iter/s, 30.2091s/40 iters), loss = 2.18029
I1026 18:12:07.456200 37958 solver.cpp:240]     Train net output #0: loss = 2.18029 (* 1 = 2.18029 loss)
I1026 18:12:07.456215 37958 sgd_solver.cpp:105] Iteration 10640, lr = 0.00937412
I1026 18:12:37.791966 37958 solver.cpp:221] Iteration 10680 (1.31863 iter/s, 30.3346s/40 iters), loss = 1.75737
I1026 18:12:37.792114 37958 solver.cpp:240]     Train net output #0: loss = 1.75737 (* 1 = 1.75737 loss)
I1026 18:12:37.792129 37958 sgd_solver.cpp:105] Iteration 10680, lr = 0.00937176
I1026 18:13:08.216881 37958 solver.cpp:221] Iteration 10720 (1.31477 iter/s, 30.4236s/40 iters), loss = 1.74479
I1026 18:13:08.217039 37958 solver.cpp:240]     Train net output #0: loss = 1.74479 (* 1 = 1.74479 loss)
I1026 18:13:08.217054 37958 sgd_solver.cpp:105] Iteration 10720, lr = 0.00936941
I1026 18:13:38.671317 37958 solver.cpp:221] Iteration 10760 (1.31349 iter/s, 30.4531s/40 iters), loss = 2.331
I1026 18:13:38.671562 37958 solver.cpp:240]     Train net output #0: loss = 2.331 (* 1 = 2.331 loss)
I1026 18:13:38.671577 37958 sgd_solver.cpp:105] Iteration 10760, lr = 0.00936706
I1026 18:14:09.072152 37958 solver.cpp:221] Iteration 10800 (1.31581 iter/s, 30.3994s/40 iters), loss = 1.71844
I1026 18:14:09.072319 37958 solver.cpp:240]     Train net output #0: loss = 1.71844 (* 1 = 1.71844 loss)
I1026 18:14:09.072335 37958 sgd_solver.cpp:105] Iteration 10800, lr = 0.00936471
I1026 18:14:49.376565 37958 solver.cpp:221] Iteration 10840 (0.992489 iter/s, 40.3027s/40 iters), loss = 1.85574
I1026 18:14:49.376802 37958 solver.cpp:240]     Train net output #0: loss = 1.85574 (* 1 = 1.85574 loss)
I1026 18:14:49.376823 37958 sgd_solver.cpp:105] Iteration 10840, lr = 0.00936235
I1026 18:15:21.496657 37958 solver.cpp:221] Iteration 10880 (1.24538 iter/s, 32.1186s/40 iters), loss = 1.80403
I1026 18:15:21.496891 37958 solver.cpp:240]     Train net output #0: loss = 1.80403 (* 1 = 1.80403 loss)
I1026 18:15:21.496913 37958 sgd_solver.cpp:105] Iteration 10880, lr = 0.00936
I1026 18:15:53.739017 37958 solver.cpp:221] Iteration 10920 (1.24066 iter/s, 32.2409s/40 iters), loss = 1.83642
I1026 18:15:53.739214 37958 solver.cpp:240]     Train net output #0: loss = 1.83642 (* 1 = 1.83642 loss)
I1026 18:15:53.739229 37958 sgd_solver.cpp:105] Iteration 10920, lr = 0.00935765
I1026 18:16:24.784272 37958 solver.cpp:221] Iteration 10960 (1.2885 iter/s, 31.0439s/40 iters), loss = 1.64075
I1026 18:16:24.784458 37958 solver.cpp:240]     Train net output #0: loss = 1.64075 (* 1 = 1.64075 loss)
I1026 18:16:24.784474 37958 sgd_solver.cpp:105] Iteration 10960, lr = 0.00935529
I1026 18:16:55.094924 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_11000.caffemodel
I1026 18:16:55.127677 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_11000.solverstate
I1026 18:16:55.145409 37958 solver.cpp:333] Iteration 11000, Testing net (#0)
I1026 18:17:26.157829 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52452
I1026 18:17:26.157987 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76744
I1026 18:17:26.158001 37958 solver.cpp:400]     Test net output #2: loss = 2.12564 (* 1 = 2.12564 loss)
I1026 18:17:26.929371 37958 solver.cpp:221] Iteration 11000 (0.643681 iter/s, 62.1426s/40 iters), loss = 1.84556
I1026 18:17:26.929452 37958 solver.cpp:240]     Train net output #0: loss = 1.84556 (* 1 = 1.84556 loss)
I1026 18:17:26.929469 37958 sgd_solver.cpp:105] Iteration 11000, lr = 0.00935294
I1026 18:17:57.708520 37958 solver.cpp:221] Iteration 11040 (1.29963 iter/s, 30.7779s/40 iters), loss = 1.51592
I1026 18:17:57.708729 37958 solver.cpp:240]     Train net output #0: loss = 1.51592 (* 1 = 1.51592 loss)
I1026 18:17:57.708745 37958 sgd_solver.cpp:105] Iteration 11040, lr = 0.00935059
I1026 18:18:28.334674 37958 solver.cpp:221] Iteration 11080 (1.30613 iter/s, 30.6248s/40 iters), loss = 1.80706
I1026 18:18:28.334866 37958 solver.cpp:240]     Train net output #0: loss = 1.80706 (* 1 = 1.80706 loss)
I1026 18:18:28.334880 37958 sgd_solver.cpp:105] Iteration 11080, lr = 0.00934824
I1026 18:18:59.500087 37958 solver.cpp:221] Iteration 11120 (1.28353 iter/s, 31.164s/40 iters), loss = 2.04261
I1026 18:18:59.500330 37958 solver.cpp:240]     Train net output #0: loss = 2.04261 (* 1 = 2.04261 loss)
I1026 18:18:59.500346 37958 sgd_solver.cpp:105] Iteration 11120, lr = 0.00934588
I1026 18:19:30.971159 37958 solver.cpp:221] Iteration 11160 (1.27107 iter/s, 31.4696s/40 iters), loss = 1.84355
I1026 18:19:30.971467 37958 solver.cpp:240]     Train net output #0: loss = 1.84355 (* 1 = 1.84355 loss)
I1026 18:19:30.971482 37958 sgd_solver.cpp:105] Iteration 11160, lr = 0.00934353
I1026 18:20:01.992214 37958 solver.cpp:221] Iteration 11200 (1.28951 iter/s, 31.0196s/40 iters), loss = 2.05248
I1026 18:20:01.992449 37958 solver.cpp:240]     Train net output #0: loss = 2.05248 (* 1 = 2.05248 loss)
I1026 18:20:01.992465 37958 sgd_solver.cpp:105] Iteration 11200, lr = 0.00934118
I1026 18:20:32.988673 37958 solver.cpp:221] Iteration 11240 (1.29053 iter/s, 30.9951s/40 iters), loss = 1.66278
I1026 18:20:32.988863 37958 solver.cpp:240]     Train net output #0: loss = 1.66278 (* 1 = 1.66278 loss)
I1026 18:20:32.988878 37958 sgd_solver.cpp:105] Iteration 11240, lr = 0.00933882
I1026 18:21:03.273622 37958 solver.cpp:221] Iteration 11280 (1.32085 iter/s, 30.2836s/40 iters), loss = 2.0925
I1026 18:21:03.273807 37958 solver.cpp:240]     Train net output #0: loss = 2.0925 (* 1 = 2.0925 loss)
I1026 18:21:03.273820 37958 sgd_solver.cpp:105] Iteration 11280, lr = 0.00933647
I1026 18:21:33.717033 37958 solver.cpp:221] Iteration 11320 (1.31397 iter/s, 30.4421s/40 iters), loss = 1.97168
I1026 18:21:33.717242 37958 solver.cpp:240]     Train net output #0: loss = 1.97168 (* 1 = 1.97168 loss)
I1026 18:21:33.717257 37958 sgd_solver.cpp:105] Iteration 11320, lr = 0.00933412
I1026 18:22:04.108244 37958 solver.cpp:221] Iteration 11360 (1.31623 iter/s, 30.3898s/40 iters), loss = 1.92383
I1026 18:22:04.108382 37958 solver.cpp:240]     Train net output #0: loss = 1.92383 (* 1 = 1.92383 loss)
I1026 18:22:04.108397 37958 sgd_solver.cpp:105] Iteration 11360, lr = 0.00933176
I1026 18:22:34.542013 37958 solver.cpp:221] Iteration 11400 (1.31439 iter/s, 30.4325s/40 iters), loss = 1.85177
I1026 18:22:34.542187 37958 solver.cpp:240]     Train net output #0: loss = 1.85177 (* 1 = 1.85177 loss)
I1026 18:22:34.542201 37958 sgd_solver.cpp:105] Iteration 11400, lr = 0.00932941
I1026 18:23:04.857373 37958 solver.cpp:221] Iteration 11440 (1.31952 iter/s, 30.314s/40 iters), loss = 2.37232
I1026 18:23:04.857547 37958 solver.cpp:240]     Train net output #0: loss = 2.37232 (* 1 = 2.37232 loss)
I1026 18:23:04.857561 37958 sgd_solver.cpp:105] Iteration 11440, lr = 0.00932706
I1026 18:23:35.072937 37958 solver.cpp:221] Iteration 11480 (1.32388 iter/s, 30.2143s/40 iters), loss = 1.77505
I1026 18:23:35.073086 37958 solver.cpp:240]     Train net output #0: loss = 1.77505 (* 1 = 1.77505 loss)
I1026 18:23:35.073101 37958 sgd_solver.cpp:105] Iteration 11480, lr = 0.00932471
I1026 18:23:49.535161 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_11500.caffemodel
I1026 18:23:49.578440 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_11500.solverstate
I1026 18:23:49.596272 37958 solver.cpp:333] Iteration 11500, Testing net (#0)
I1026 18:24:20.327241 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 18:24:20.533426 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.51636
I1026 18:24:20.533480 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76492
I1026 18:24:20.533491 37958 solver.cpp:400]     Test net output #2: loss = 2.17012 (* 1 = 2.17012 loss)
I1026 18:24:36.446807 37958 solver.cpp:221] Iteration 11520 (0.651769 iter/s, 61.3714s/40 iters), loss = 1.90697
I1026 18:24:36.446858 37958 solver.cpp:240]     Train net output #0: loss = 1.90697 (* 1 = 1.90697 loss)
I1026 18:24:36.446871 37958 sgd_solver.cpp:105] Iteration 11520, lr = 0.00932235
I1026 18:25:06.814672 37958 solver.cpp:221] Iteration 11560 (1.31723 iter/s, 30.3667s/40 iters), loss = 1.8527
I1026 18:25:06.814805 37958 solver.cpp:240]     Train net output #0: loss = 1.8527 (* 1 = 1.8527 loss)
I1026 18:25:06.814819 37958 sgd_solver.cpp:105] Iteration 11560, lr = 0.00932
I1026 18:25:38.738570 37958 solver.cpp:221] Iteration 11600 (1.25303 iter/s, 31.9226s/40 iters), loss = 2.00851
I1026 18:25:38.738808 37958 solver.cpp:240]     Train net output #0: loss = 2.00851 (* 1 = 2.00851 loss)
I1026 18:25:38.738828 37958 sgd_solver.cpp:105] Iteration 11600, lr = 0.00931765
I1026 18:26:09.948933 37958 solver.cpp:221] Iteration 11640 (1.28168 iter/s, 31.209s/40 iters), loss = 1.90711
I1026 18:26:09.949178 37958 solver.cpp:240]     Train net output #0: loss = 1.90711 (* 1 = 1.90711 loss)
I1026 18:26:09.949204 37958 sgd_solver.cpp:105] Iteration 11640, lr = 0.00931529
I1026 18:26:40.385174 37958 solver.cpp:221] Iteration 11680 (1.31428 iter/s, 30.4348s/40 iters), loss = 1.82362
I1026 18:26:40.385376 37958 solver.cpp:240]     Train net output #0: loss = 1.82362 (* 1 = 1.82362 loss)
I1026 18:26:40.385390 37958 sgd_solver.cpp:105] Iteration 11680, lr = 0.00931294
I1026 18:27:11.134752 37958 solver.cpp:221] Iteration 11720 (1.30089 iter/s, 30.7482s/40 iters), loss = 1.91511
I1026 18:27:11.134958 37958 solver.cpp:240]     Train net output #0: loss = 1.91511 (* 1 = 1.91511 loss)
I1026 18:27:11.134974 37958 sgd_solver.cpp:105] Iteration 11720, lr = 0.00931059
I1026 18:27:41.520061 37958 solver.cpp:221] Iteration 11760 (1.31648 iter/s, 30.384s/40 iters), loss = 1.7203
I1026 18:27:41.520212 37958 solver.cpp:240]     Train net output #0: loss = 1.7203 (* 1 = 1.7203 loss)
I1026 18:27:41.520228 37958 sgd_solver.cpp:105] Iteration 11760, lr = 0.00930823
I1026 18:28:11.881757 37958 solver.cpp:221] Iteration 11800 (1.31751 iter/s, 30.3604s/40 iters), loss = 1.88257
I1026 18:28:11.881901 37958 solver.cpp:240]     Train net output #0: loss = 1.88257 (* 1 = 1.88257 loss)
I1026 18:28:11.881916 37958 sgd_solver.cpp:105] Iteration 11800, lr = 0.00930588
I1026 18:28:42.497012 37958 solver.cpp:221] Iteration 11840 (1.30659 iter/s, 30.614s/40 iters), loss = 2.06154
I1026 18:28:42.497200 37958 solver.cpp:240]     Train net output #0: loss = 2.06154 (* 1 = 2.06154 loss)
I1026 18:28:42.497215 37958 sgd_solver.cpp:105] Iteration 11840, lr = 0.00930353
I1026 18:29:12.746569 37958 solver.cpp:221] Iteration 11880 (1.32239 iter/s, 30.2482s/40 iters), loss = 2.2533
I1026 18:29:12.746744 37958 solver.cpp:240]     Train net output #0: loss = 2.2533 (* 1 = 2.2533 loss)
I1026 18:29:12.746759 37958 sgd_solver.cpp:105] Iteration 11880, lr = 0.00930118
I1026 18:29:43.377625 37958 solver.cpp:221] Iteration 11920 (1.30592 iter/s, 30.6297s/40 iters), loss = 1.70867
I1026 18:29:43.377831 37958 solver.cpp:240]     Train net output #0: loss = 1.70867 (* 1 = 1.70867 loss)
I1026 18:29:43.377846 37958 sgd_solver.cpp:105] Iteration 11920, lr = 0.00929882
I1026 18:30:13.909787 37958 solver.cpp:221] Iteration 11960 (1.31015 iter/s, 30.5308s/40 iters), loss = 1.90631
I1026 18:30:13.909970 37958 solver.cpp:240]     Train net output #0: loss = 1.90631 (* 1 = 1.90631 loss)
I1026 18:30:13.909983 37958 sgd_solver.cpp:105] Iteration 11960, lr = 0.00929647
I1026 18:30:43.714264 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_12000.caffemodel
I1026 18:30:43.748739 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_12000.solverstate
I1026 18:30:43.771963 37958 solver.cpp:333] Iteration 12000, Testing net (#0)
I1026 18:31:15.355732 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52372
I1026 18:31:15.355919 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.7656
I1026 18:31:15.355933 37958 solver.cpp:400]     Test net output #2: loss = 2.11039 (* 1 = 2.11039 loss)
I1026 18:31:16.124605 37958 solver.cpp:221] Iteration 12000 (0.64296 iter/s, 62.2123s/40 iters), loss = 2.17426
I1026 18:31:16.124665 37958 solver.cpp:240]     Train net output #0: loss = 2.17426 (* 1 = 2.17426 loss)
I1026 18:31:16.124680 37958 sgd_solver.cpp:105] Iteration 12000, lr = 0.00929412
I1026 18:31:46.917903 37958 solver.cpp:221] Iteration 12040 (1.29904 iter/s, 30.7921s/40 iters), loss = 1.9008
I1026 18:31:46.918115 37958 solver.cpp:240]     Train net output #0: loss = 1.9008 (* 1 = 1.9008 loss)
I1026 18:31:46.918131 37958 sgd_solver.cpp:105] Iteration 12040, lr = 0.00929176
I1026 18:32:17.624629 37958 solver.cpp:221] Iteration 12080 (1.3027 iter/s, 30.7054s/40 iters), loss = 1.95167
I1026 18:32:17.624806 37958 solver.cpp:240]     Train net output #0: loss = 1.95167 (* 1 = 1.95167 loss)
I1026 18:32:17.624821 37958 sgd_solver.cpp:105] Iteration 12080, lr = 0.00928941
I1026 18:32:48.242218 37958 solver.cpp:221] Iteration 12120 (1.3065 iter/s, 30.6162s/40 iters), loss = 2.18333
I1026 18:32:48.242455 37958 solver.cpp:240]     Train net output #0: loss = 2.18333 (* 1 = 2.18333 loss)
I1026 18:32:48.242470 37958 sgd_solver.cpp:105] Iteration 12120, lr = 0.00928706
I1026 18:33:18.863209 37958 solver.cpp:221] Iteration 12160 (1.30635 iter/s, 30.6196s/40 iters), loss = 2.07344
I1026 18:33:18.863370 37958 solver.cpp:240]     Train net output #0: loss = 2.07344 (* 1 = 2.07344 loss)
I1026 18:33:18.863385 37958 sgd_solver.cpp:105] Iteration 12160, lr = 0.00928471
I1026 18:33:49.616235 37958 solver.cpp:221] Iteration 12200 (1.30074 iter/s, 30.7517s/40 iters), loss = 1.73615
I1026 18:33:49.616474 37958 solver.cpp:240]     Train net output #0: loss = 1.73615 (* 1 = 1.73615 loss)
I1026 18:33:49.616495 37958 sgd_solver.cpp:105] Iteration 12200, lr = 0.00928235
I1026 18:34:21.088994 37958 solver.cpp:221] Iteration 12240 (1.271 iter/s, 31.4713s/40 iters), loss = 2.06513
I1026 18:34:21.089184 37958 solver.cpp:240]     Train net output #0: loss = 2.06513 (* 1 = 2.06513 loss)
I1026 18:34:21.089200 37958 sgd_solver.cpp:105] Iteration 12240, lr = 0.00928
I1026 18:34:51.685911 37958 solver.cpp:221] Iteration 12280 (1.30738 iter/s, 30.5956s/40 iters), loss = 2.4172
I1026 18:34:51.686084 37958 solver.cpp:240]     Train net output #0: loss = 2.4172 (* 1 = 2.4172 loss)
I1026 18:34:51.686100 37958 sgd_solver.cpp:105] Iteration 12280, lr = 0.00927765
I1026 18:35:22.594164 37958 solver.cpp:221] Iteration 12320 (1.29421 iter/s, 30.9069s/40 iters), loss = 1.89783
I1026 18:35:22.594339 37958 solver.cpp:240]     Train net output #0: loss = 1.89783 (* 1 = 1.89783 loss)
I1026 18:35:22.594354 37958 sgd_solver.cpp:105] Iteration 12320, lr = 0.00927529
I1026 18:35:53.245607 37958 solver.cpp:221] Iteration 12360 (1.30505 iter/s, 30.6501s/40 iters), loss = 1.37908
I1026 18:35:53.245805 37958 solver.cpp:240]     Train net output #0: loss = 1.37908 (* 1 = 1.37908 loss)
I1026 18:35:53.245820 37958 sgd_solver.cpp:105] Iteration 12360, lr = 0.00927294
I1026 18:36:23.891947 37958 solver.cpp:221] Iteration 12400 (1.30527 iter/s, 30.645s/40 iters), loss = 1.90453
I1026 18:36:23.892149 37958 solver.cpp:240]     Train net output #0: loss = 1.90453 (* 1 = 1.90453 loss)
I1026 18:36:23.892164 37958 sgd_solver.cpp:105] Iteration 12400, lr = 0.00927059
I1026 18:36:54.309101 37958 solver.cpp:221] Iteration 12440 (1.31511 iter/s, 30.4158s/40 iters), loss = 2.03407
I1026 18:36:54.309280 37958 solver.cpp:240]     Train net output #0: loss = 2.03407 (* 1 = 2.03407 loss)
I1026 18:36:54.309294 37958 sgd_solver.cpp:105] Iteration 12440, lr = 0.00926823
I1026 18:37:24.835115 37958 solver.cpp:221] Iteration 12480 (1.31042 iter/s, 30.5247s/40 iters), loss = 1.67309
I1026 18:37:24.835283 37958 solver.cpp:240]     Train net output #0: loss = 1.67309 (* 1 = 1.67309 loss)
I1026 18:37:24.835302 37958 sgd_solver.cpp:105] Iteration 12480, lr = 0.00926588
I1026 18:37:39.384610 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_12500.caffemodel
I1026 18:37:39.420450 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_12500.solverstate
I1026 18:37:39.442015 37958 solver.cpp:333] Iteration 12500, Testing net (#0)
I1026 18:38:10.152503 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 18:38:10.358492 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52056
I1026 18:38:10.358546 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.7676
I1026 18:38:10.358557 37958 solver.cpp:400]     Test net output #2: loss = 2.11927 (* 1 = 2.11927 loss)
I1026 18:38:16.745427 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1026 18:38:27.208037 37958 solver.cpp:221] Iteration 12520 (0.64133 iter/s, 62.3704s/40 iters), loss = 1.96098
I1026 18:38:27.208123 37958 solver.cpp:240]     Train net output #0: loss = 1.96098 (* 1 = 1.96098 loss)
I1026 18:38:27.208144 37958 sgd_solver.cpp:105] Iteration 12520, lr = 0.00926353
I1026 18:38:59.864796 37958 solver.cpp:221] Iteration 12560 (1.22491 iter/s, 32.6554s/40 iters), loss = 2.1
I1026 18:38:59.865041 37958 solver.cpp:240]     Train net output #0: loss = 2.1 (* 1 = 2.1 loss)
I1026 18:38:59.865057 37958 sgd_solver.cpp:105] Iteration 12560, lr = 0.00926118
I1026 18:39:31.321995 37958 solver.cpp:221] Iteration 12600 (1.27163 iter/s, 31.4558s/40 iters), loss = 2.00402
I1026 18:39:31.322171 37958 solver.cpp:240]     Train net output #0: loss = 2.00402 (* 1 = 2.00402 loss)
I1026 18:39:31.322186 37958 sgd_solver.cpp:105] Iteration 12600, lr = 0.00925882
I1026 18:40:03.362553 37958 solver.cpp:221] Iteration 12640 (1.24847 iter/s, 32.0392s/40 iters), loss = 2.01784
I1026 18:40:03.362745 37958 solver.cpp:240]     Train net output #0: loss = 2.01784 (* 1 = 2.01784 loss)
I1026 18:40:03.362759 37958 sgd_solver.cpp:105] Iteration 12640, lr = 0.00925647
I1026 18:40:35.269328 37958 solver.cpp:221] Iteration 12680 (1.25371 iter/s, 31.9054s/40 iters), loss = 1.69724
I1026 18:40:35.269512 37958 solver.cpp:240]     Train net output #0: loss = 1.69724 (* 1 = 1.69724 loss)
I1026 18:40:35.269527 37958 sgd_solver.cpp:105] Iteration 12680, lr = 0.00925412
I1026 18:41:06.911257 37958 solver.cpp:221] Iteration 12720 (1.2642 iter/s, 31.6405s/40 iters), loss = 2.00711
I1026 18:41:06.911507 37958 solver.cpp:240]     Train net output #0: loss = 2.00711 (* 1 = 2.00711 loss)
I1026 18:41:06.911530 37958 sgd_solver.cpp:105] Iteration 12720, lr = 0.00925176
I1026 18:41:41.625830 37958 solver.cpp:221] Iteration 12760 (1.15231 iter/s, 34.713s/40 iters), loss = 1.60436
I1026 18:41:41.626092 37958 solver.cpp:240]     Train net output #0: loss = 1.60436 (* 1 = 1.60436 loss)
I1026 18:41:41.626111 37958 sgd_solver.cpp:105] Iteration 12760, lr = 0.00924941
I1026 18:42:12.928247 37958 solver.cpp:221] Iteration 12800 (1.27791 iter/s, 31.301s/40 iters), loss = 2.11833
I1026 18:42:12.928455 37958 solver.cpp:240]     Train net output #0: loss = 2.11833 (* 1 = 2.11833 loss)
I1026 18:42:12.928470 37958 sgd_solver.cpp:105] Iteration 12800, lr = 0.00924706
I1026 18:42:44.632627 37958 solver.cpp:221] Iteration 12840 (1.26171 iter/s, 31.703s/40 iters), loss = 1.81855
I1026 18:42:44.632879 37958 solver.cpp:240]     Train net output #0: loss = 1.81855 (* 1 = 1.81855 loss)
I1026 18:42:44.632901 37958 sgd_solver.cpp:105] Iteration 12840, lr = 0.00924471
I1026 18:43:17.637835 37958 solver.cpp:221] Iteration 12880 (1.21199 iter/s, 33.0037s/40 iters), loss = 1.93033
I1026 18:43:17.638144 37958 solver.cpp:240]     Train net output #0: loss = 1.93033 (* 1 = 1.93033 loss)
I1026 18:43:17.638166 37958 sgd_solver.cpp:105] Iteration 12880, lr = 0.00924235
I1026 18:43:49.805434 37958 solver.cpp:221] Iteration 12920 (1.24355 iter/s, 32.1661s/40 iters), loss = 1.58386
I1026 18:43:49.805637 37958 solver.cpp:240]     Train net output #0: loss = 1.58386 (* 1 = 1.58386 loss)
I1026 18:43:49.805652 37958 sgd_solver.cpp:105] Iteration 12920, lr = 0.00924
I1026 18:44:20.316710 37958 solver.cpp:221] Iteration 12960 (1.31105 iter/s, 30.5099s/40 iters), loss = 2.31029
I1026 18:44:20.316913 37958 solver.cpp:240]     Train net output #0: loss = 2.31029 (* 1 = 2.31029 loss)
I1026 18:44:20.316928 37958 sgd_solver.cpp:105] Iteration 12960, lr = 0.00923765
I1026 18:44:50.070785 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_13000.caffemodel
I1026 18:44:50.113013 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_13000.solverstate
I1026 18:44:50.140486 37958 solver.cpp:333] Iteration 13000, Testing net (#0)
I1026 18:45:21.056138 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52452
I1026 18:45:21.056509 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76936
I1026 18:45:21.056521 37958 solver.cpp:400]     Test net output #2: loss = 2.11286 (* 1 = 2.11286 loss)
I1026 18:45:21.827236 37958 solver.cpp:221] Iteration 13000 (0.650322 iter/s, 61.508s/40 iters), loss = 1.42916
I1026 18:45:21.827303 37958 solver.cpp:240]     Train net output #0: loss = 1.42916 (* 1 = 1.42916 loss)
I1026 18:45:21.827332 37958 sgd_solver.cpp:105] Iteration 13000, lr = 0.00923529
I1026 18:45:52.354427 37958 solver.cpp:221] Iteration 13040 (1.31036 iter/s, 30.526s/40 iters), loss = 1.89811
I1026 18:45:52.354740 37958 solver.cpp:240]     Train net output #0: loss = 1.89811 (* 1 = 1.89811 loss)
I1026 18:45:52.354771 37958 sgd_solver.cpp:105] Iteration 13040, lr = 0.00923294
I1026 18:46:22.780995 37958 solver.cpp:221] Iteration 13080 (1.3147 iter/s, 30.4251s/40 iters), loss = 1.76879
I1026 18:46:22.781177 37958 solver.cpp:240]     Train net output #0: loss = 1.76879 (* 1 = 1.76879 loss)
I1026 18:46:22.781193 37958 sgd_solver.cpp:105] Iteration 13080, lr = 0.00923059
I1026 18:46:53.481717 37958 solver.cpp:221] Iteration 13120 (1.30296 iter/s, 30.6994s/40 iters), loss = 1.7261
I1026 18:46:53.481938 37958 solver.cpp:240]     Train net output #0: loss = 1.7261 (* 1 = 1.7261 loss)
I1026 18:46:53.481967 37958 sgd_solver.cpp:105] Iteration 13120, lr = 0.00922824
I1026 18:47:24.982496 37958 solver.cpp:221] Iteration 13160 (1.26987 iter/s, 31.4994s/40 iters), loss = 1.93943
I1026 18:47:24.982697 37958 solver.cpp:240]     Train net output #0: loss = 1.93943 (* 1 = 1.93943 loss)
I1026 18:47:24.982712 37958 sgd_solver.cpp:105] Iteration 13160, lr = 0.00922588
I1026 18:47:55.756350 37958 solver.cpp:221] Iteration 13200 (1.29986 iter/s, 30.7725s/40 iters), loss = 1.70107
I1026 18:47:55.756525 37958 solver.cpp:240]     Train net output #0: loss = 1.70107 (* 1 = 1.70107 loss)
I1026 18:47:55.756541 37958 sgd_solver.cpp:105] Iteration 13200, lr = 0.00922353
I1026 18:48:27.469521 37958 solver.cpp:221] Iteration 13240 (1.26136 iter/s, 31.7118s/40 iters), loss = 2.10009
I1026 18:48:27.469768 37958 solver.cpp:240]     Train net output #0: loss = 2.10009 (* 1 = 2.10009 loss)
I1026 18:48:27.469787 37958 sgd_solver.cpp:105] Iteration 13240, lr = 0.00922118
I1026 18:48:59.868312 37958 solver.cpp:221] Iteration 13280 (1.23467 iter/s, 32.3973s/40 iters), loss = 2.01338
I1026 18:48:59.868502 37958 solver.cpp:240]     Train net output #0: loss = 2.01338 (* 1 = 2.01338 loss)
I1026 18:48:59.868517 37958 sgd_solver.cpp:105] Iteration 13280, lr = 0.00921882
I1026 18:49:30.368780 37958 solver.cpp:221] Iteration 13320 (1.31151 iter/s, 30.4991s/40 iters), loss = 1.94962
I1026 18:49:30.368968 37958 solver.cpp:240]     Train net output #0: loss = 1.94962 (* 1 = 1.94962 loss)
I1026 18:49:30.368983 37958 sgd_solver.cpp:105] Iteration 13320, lr = 0.00921647
I1026 18:50:00.760463 37958 solver.cpp:221] Iteration 13360 (1.31621 iter/s, 30.3903s/40 iters), loss = 1.62097
I1026 18:50:00.760633 37958 solver.cpp:240]     Train net output #0: loss = 1.62097 (* 1 = 1.62097 loss)
I1026 18:50:00.760648 37958 sgd_solver.cpp:105] Iteration 13360, lr = 0.00921412
I1026 18:50:31.661056 37958 solver.cpp:221] Iteration 13400 (1.29453 iter/s, 30.8993s/40 iters), loss = 1.78828
I1026 18:50:31.661242 37958 solver.cpp:240]     Train net output #0: loss = 1.78828 (* 1 = 1.78828 loss)
I1026 18:50:31.661257 37958 sgd_solver.cpp:105] Iteration 13400, lr = 0.00921176
I1026 18:51:02.491127 37958 solver.cpp:221] Iteration 13440 (1.29749 iter/s, 30.8287s/40 iters), loss = 1.88249
I1026 18:51:02.491322 37958 solver.cpp:240]     Train net output #0: loss = 1.88249 (* 1 = 1.88249 loss)
I1026 18:51:02.491338 37958 sgd_solver.cpp:105] Iteration 13440, lr = 0.00920941
I1026 18:51:33.162400 37958 solver.cpp:221] Iteration 13480 (1.30421 iter/s, 30.6699s/40 iters), loss = 1.68309
I1026 18:51:33.162585 37958 solver.cpp:240]     Train net output #0: loss = 1.68309 (* 1 = 1.68309 loss)
I1026 18:51:33.162600 37958 sgd_solver.cpp:105] Iteration 13480, lr = 0.00920706
I1026 18:51:47.684190 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_13500.caffemodel
I1026 18:51:47.723249 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_13500.solverstate
I1026 18:51:47.747531 37958 solver.cpp:333] Iteration 13500, Testing net (#0)
I1026 18:52:18.472910 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 18:52:18.680743 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52452
I1026 18:52:18.680799 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.7676
I1026 18:52:18.680811 37958 solver.cpp:400]     Test net output #2: loss = 2.1156 (* 1 = 2.1156 loss)
I1026 18:52:34.691829 37958 solver.cpp:221] Iteration 13520 (0.650122 iter/s, 61.5269s/40 iters), loss = 1.77065
I1026 18:52:34.691887 37958 solver.cpp:240]     Train net output #0: loss = 1.77065 (* 1 = 1.77065 loss)
I1026 18:52:34.691901 37958 sgd_solver.cpp:105] Iteration 13520, lr = 0.00920471
I1026 18:53:05.096078 37958 solver.cpp:221] Iteration 13560 (1.31566 iter/s, 30.403s/40 iters), loss = 1.57088
I1026 18:53:05.096256 37958 solver.cpp:240]     Train net output #0: loss = 1.57088 (* 1 = 1.57088 loss)
I1026 18:53:05.096271 37958 sgd_solver.cpp:105] Iteration 13560, lr = 0.00920235
I1026 18:53:35.454910 37958 solver.cpp:221] Iteration 13600 (1.31763 iter/s, 30.3575s/40 iters), loss = 2.27896
I1026 18:53:35.455062 37958 solver.cpp:240]     Train net output #0: loss = 2.27896 (* 1 = 2.27896 loss)
I1026 18:53:35.455077 37958 sgd_solver.cpp:105] Iteration 13600, lr = 0.0092
I1026 18:54:05.959574 37958 solver.cpp:221] Iteration 13640 (1.31133 iter/s, 30.5034s/40 iters), loss = 1.90432
I1026 18:54:05.959733 37958 solver.cpp:240]     Train net output #0: loss = 1.90432 (* 1 = 1.90432 loss)
I1026 18:54:05.959748 37958 sgd_solver.cpp:105] Iteration 13640, lr = 0.00919765
I1026 18:54:36.564102 37958 solver.cpp:221] Iteration 13680 (1.30705 iter/s, 30.6032s/40 iters), loss = 1.77568
I1026 18:54:36.564294 37958 solver.cpp:240]     Train net output #0: loss = 1.77568 (* 1 = 1.77568 loss)
I1026 18:54:36.564316 37958 sgd_solver.cpp:105] Iteration 13680, lr = 0.00919529
I1026 18:55:07.300599 37958 solver.cpp:221] Iteration 13720 (1.30144 iter/s, 30.7351s/40 iters), loss = 1.65011
I1026 18:55:07.300801 37958 solver.cpp:240]     Train net output #0: loss = 1.65011 (* 1 = 1.65011 loss)
I1026 18:55:07.300817 37958 sgd_solver.cpp:105] Iteration 13720, lr = 0.00919294
I1026 18:55:38.415587 37958 solver.cpp:221] Iteration 13760 (1.28561 iter/s, 31.1136s/40 iters), loss = 2.20408
I1026 18:55:38.415783 37958 solver.cpp:240]     Train net output #0: loss = 2.20408 (* 1 = 2.20408 loss)
I1026 18:55:38.415797 37958 sgd_solver.cpp:105] Iteration 13760, lr = 0.00919059
I1026 18:56:09.478086 37958 solver.cpp:221] Iteration 13800 (1.28778 iter/s, 31.0611s/40 iters), loss = 1.5925
I1026 18:56:09.478282 37958 solver.cpp:240]     Train net output #0: loss = 1.5925 (* 1 = 1.5925 loss)
I1026 18:56:09.478302 37958 sgd_solver.cpp:105] Iteration 13800, lr = 0.00918823
I1026 18:56:40.549005 37958 solver.cpp:221] Iteration 13840 (1.28743 iter/s, 31.0695s/40 iters), loss = 1.85027
I1026 18:56:40.549213 37958 solver.cpp:240]     Train net output #0: loss = 1.85027 (* 1 = 1.85027 loss)
I1026 18:56:40.549227 37958 sgd_solver.cpp:105] Iteration 13840, lr = 0.00918588
I1026 18:57:11.738004 37958 solver.cpp:221] Iteration 13880 (1.28256 iter/s, 31.1876s/40 iters), loss = 2.05053
I1026 18:57:11.738162 37958 solver.cpp:240]     Train net output #0: loss = 2.05053 (* 1 = 2.05053 loss)
I1026 18:57:11.738178 37958 sgd_solver.cpp:105] Iteration 13880, lr = 0.00918353
I1026 18:57:42.611328 37958 solver.cpp:221] Iteration 13920 (1.29567 iter/s, 30.872s/40 iters), loss = 1.74793
I1026 18:57:42.611518 37958 solver.cpp:240]     Train net output #0: loss = 1.74793 (* 1 = 1.74793 loss)
I1026 18:57:42.611532 37958 sgd_solver.cpp:105] Iteration 13920, lr = 0.00918118
I1026 18:58:13.600770 37958 solver.cpp:221] Iteration 13960 (1.29082 iter/s, 30.9881s/40 iters), loss = 2.12644
I1026 18:58:13.600966 37958 solver.cpp:240]     Train net output #0: loss = 2.12644 (* 1 = 2.12644 loss)
I1026 18:58:13.600981 37958 sgd_solver.cpp:105] Iteration 13960, lr = 0.00917882
I1026 18:58:43.678306 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_14000.caffemodel
I1026 18:58:43.711068 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_14000.solverstate
I1026 18:58:43.728849 37958 solver.cpp:333] Iteration 14000, Testing net (#0)
I1026 18:59:14.664904 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.51744
I1026 18:59:14.665084 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.761
I1026 18:59:14.665099 37958 solver.cpp:400]     Test net output #2: loss = 2.14716 (* 1 = 2.14716 loss)
I1026 18:59:15.429464 37958 solver.cpp:221] Iteration 14000 (0.646975 iter/s, 61.8262s/40 iters), loss = 2.00092
I1026 18:59:15.429505 37958 solver.cpp:240]     Train net output #0: loss = 2.00092 (* 1 = 2.00092 loss)
I1026 18:59:15.429518 37958 sgd_solver.cpp:105] Iteration 14000, lr = 0.00917647
I1026 18:59:46.225940 37958 solver.cpp:221] Iteration 14040 (1.2989 iter/s, 30.7953s/40 iters), loss = 1.78909
I1026 18:59:46.226161 37958 solver.cpp:240]     Train net output #0: loss = 1.78909 (* 1 = 1.78909 loss)
I1026 18:59:46.226181 37958 sgd_solver.cpp:105] Iteration 14040, lr = 0.00917412
I1026 19:00:16.938347 37958 solver.cpp:221] Iteration 14080 (1.30246 iter/s, 30.711s/40 iters), loss = 1.83714
I1026 19:00:16.938524 37958 solver.cpp:240]     Train net output #0: loss = 1.83714 (* 1 = 1.83714 loss)
I1026 19:00:16.938539 37958 sgd_solver.cpp:105] Iteration 14080, lr = 0.00917176
I1026 19:00:47.737886 37958 solver.cpp:221] Iteration 14120 (1.29878 iter/s, 30.7982s/40 iters), loss = 1.82894
I1026 19:00:47.738116 37958 solver.cpp:240]     Train net output #0: loss = 1.82894 (* 1 = 1.82894 loss)
I1026 19:00:47.738142 37958 sgd_solver.cpp:105] Iteration 14120, lr = 0.00916941
I1026 19:01:18.756544 37958 solver.cpp:221] Iteration 14160 (1.28961 iter/s, 31.0172s/40 iters), loss = 1.92062
I1026 19:01:18.756778 37958 solver.cpp:240]     Train net output #0: loss = 1.92062 (* 1 = 1.92062 loss)
I1026 19:01:18.756800 37958 sgd_solver.cpp:105] Iteration 14160, lr = 0.00916706
I1026 19:01:50.304419 37958 solver.cpp:221] Iteration 14200 (1.26797 iter/s, 31.5464s/40 iters), loss = 2.12851
I1026 19:01:50.304613 37958 solver.cpp:240]     Train net output #0: loss = 2.12851 (* 1 = 2.12851 loss)
I1026 19:01:50.304628 37958 sgd_solver.cpp:105] Iteration 14200, lr = 0.00916471
I1026 19:02:21.173338 37958 solver.cpp:221] Iteration 14240 (1.29586 iter/s, 30.8676s/40 iters), loss = 2.10403
I1026 19:02:21.173534 37958 solver.cpp:240]     Train net output #0: loss = 2.10403 (* 1 = 2.10403 loss)
I1026 19:02:21.173549 37958 sgd_solver.cpp:105] Iteration 14240, lr = 0.00916235
I1026 19:02:52.077497 37958 solver.cpp:221] Iteration 14280 (1.29438 iter/s, 30.9028s/40 iters), loss = 1.7922
I1026 19:02:52.077670 37958 solver.cpp:240]     Train net output #0: loss = 1.7922 (* 1 = 1.7922 loss)
I1026 19:02:52.077685 37958 sgd_solver.cpp:105] Iteration 14280, lr = 0.00916
I1026 19:03:23.062763 37958 solver.cpp:221] Iteration 14320 (1.29099 iter/s, 30.9839s/40 iters), loss = 1.86604
I1026 19:03:23.062940 37958 solver.cpp:240]     Train net output #0: loss = 1.86604 (* 1 = 1.86604 loss)
I1026 19:03:23.062954 37958 sgd_solver.cpp:105] Iteration 14320, lr = 0.00915765
I1026 19:03:53.514878 37958 solver.cpp:221] Iteration 14360 (1.3136 iter/s, 30.4508s/40 iters), loss = 1.89042
I1026 19:03:53.515053 37958 solver.cpp:240]     Train net output #0: loss = 1.89042 (* 1 = 1.89042 loss)
I1026 19:03:53.515069 37958 sgd_solver.cpp:105] Iteration 14360, lr = 0.00915529
I1026 19:04:24.398252 37958 solver.cpp:221] Iteration 14400 (1.29525 iter/s, 30.882s/40 iters), loss = 1.84832
I1026 19:04:24.398465 37958 solver.cpp:240]     Train net output #0: loss = 1.84832 (* 1 = 1.84832 loss)
I1026 19:04:24.398480 37958 sgd_solver.cpp:105] Iteration 14400, lr = 0.00915294
I1026 19:04:55.244452 37958 solver.cpp:221] Iteration 14440 (1.29681 iter/s, 30.8448s/40 iters), loss = 2.22992
I1026 19:04:55.244657 37958 solver.cpp:240]     Train net output #0: loss = 2.22992 (* 1 = 2.22992 loss)
I1026 19:04:55.244671 37958 sgd_solver.cpp:105] Iteration 14440, lr = 0.00915059
I1026 19:05:26.085223 37958 solver.cpp:221] Iteration 14480 (1.29704 iter/s, 30.8394s/40 iters), loss = 1.77322
I1026 19:05:26.085467 37958 solver.cpp:240]     Train net output #0: loss = 1.77322 (* 1 = 1.77322 loss)
I1026 19:05:26.085482 37958 sgd_solver.cpp:105] Iteration 14480, lr = 0.00914824
I1026 19:05:40.715453 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_14500.caffemodel
I1026 19:05:40.747323 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_14500.solverstate
I1026 19:05:40.765182 37958 solver.cpp:333] Iteration 14500, Testing net (#0)
I1026 19:06:11.542754 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 19:06:11.750840 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52516
I1026 19:06:11.750900 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.7676
I1026 19:06:11.750911 37958 solver.cpp:400]     Test net output #2: loss = 2.15977 (* 1 = 2.15977 loss)
I1026 19:06:27.859031 37958 solver.cpp:221] Iteration 14520 (0.64755 iter/s, 61.7713s/40 iters), loss = 1.85762
I1026 19:06:27.859089 37958 solver.cpp:240]     Train net output #0: loss = 1.85762 (* 1 = 1.85762 loss)
I1026 19:06:27.859103 37958 sgd_solver.cpp:105] Iteration 14520, lr = 0.00914588
I1026 19:06:59.170728 37958 solver.cpp:221] Iteration 14560 (1.27753 iter/s, 31.3104s/40 iters), loss = 1.89174
I1026 19:06:59.170966 37958 solver.cpp:240]     Train net output #0: loss = 1.89174 (* 1 = 1.89174 loss)
I1026 19:06:59.170987 37958 sgd_solver.cpp:105] Iteration 14560, lr = 0.00914353
I1026 19:07:30.190605 37958 solver.cpp:221] Iteration 14600 (1.28955 iter/s, 31.0185s/40 iters), loss = 1.71635
I1026 19:07:30.190804 37958 solver.cpp:240]     Train net output #0: loss = 1.71635 (* 1 = 1.71635 loss)
I1026 19:07:30.190820 37958 sgd_solver.cpp:105] Iteration 14600, lr = 0.00914118
I1026 19:08:01.101061 37958 solver.cpp:221] Iteration 14640 (1.29412 iter/s, 30.9091s/40 iters), loss = 1.61647
I1026 19:08:01.101224 37958 solver.cpp:240]     Train net output #0: loss = 1.61647 (* 1 = 1.61647 loss)
I1026 19:08:01.101239 37958 sgd_solver.cpp:105] Iteration 14640, lr = 0.00913882
I1026 19:08:32.025045 37958 solver.cpp:221] Iteration 14680 (1.29355 iter/s, 30.9227s/40 iters), loss = 2.1296
I1026 19:08:32.025238 37958 solver.cpp:240]     Train net output #0: loss = 2.1296 (* 1 = 2.1296 loss)
I1026 19:08:32.025254 37958 sgd_solver.cpp:105] Iteration 14680, lr = 0.00913647
I1026 19:09:02.844125 37958 solver.cpp:221] Iteration 14720 (1.29795 iter/s, 30.8177s/40 iters), loss = 1.9075
I1026 19:09:02.844310 37958 solver.cpp:240]     Train net output #0: loss = 1.9075 (* 1 = 1.9075 loss)
I1026 19:09:02.844326 37958 sgd_solver.cpp:105] Iteration 14720, lr = 0.00913412
I1026 19:09:33.767539 37958 solver.cpp:221] Iteration 14760 (1.29358 iter/s, 30.9221s/40 iters), loss = 1.94855
I1026 19:09:33.767745 37958 solver.cpp:240]     Train net output #0: loss = 1.94855 (* 1 = 1.94855 loss)
I1026 19:09:33.767760 37958 sgd_solver.cpp:105] Iteration 14760, lr = 0.00913176
I1026 19:10:04.644443 37958 solver.cpp:221] Iteration 14800 (1.29552 iter/s, 30.8755s/40 iters), loss = 1.86993
I1026 19:10:04.644646 37958 solver.cpp:240]     Train net output #0: loss = 1.86993 (* 1 = 1.86993 loss)
I1026 19:10:04.644662 37958 sgd_solver.cpp:105] Iteration 14800, lr = 0.00912941
I1026 19:10:35.562139 37958 solver.cpp:221] Iteration 14840 (1.29381 iter/s, 30.9163s/40 iters), loss = 2.19643
I1026 19:10:35.562342 37958 solver.cpp:240]     Train net output #0: loss = 2.19643 (* 1 = 2.19643 loss)
I1026 19:10:35.562357 37958 sgd_solver.cpp:105] Iteration 14840, lr = 0.00912706
I1026 19:11:06.598455 37958 solver.cpp:221] Iteration 14880 (1.28887 iter/s, 31.0349s/40 iters), loss = 2.05838
I1026 19:11:06.598633 37958 solver.cpp:240]     Train net output #0: loss = 2.05838 (* 1 = 2.05838 loss)
I1026 19:11:06.598650 37958 sgd_solver.cpp:105] Iteration 14880, lr = 0.00912471
I1026 19:11:37.464004 37958 solver.cpp:221] Iteration 14920 (1.296 iter/s, 30.8642s/40 iters), loss = 1.58677
I1026 19:11:37.464253 37958 solver.cpp:240]     Train net output #0: loss = 1.58677 (* 1 = 1.58677 loss)
I1026 19:11:37.464278 37958 sgd_solver.cpp:105] Iteration 14920, lr = 0.00912235
I1026 19:12:08.086191 37958 solver.cpp:221] Iteration 14960 (1.3063 iter/s, 30.6208s/40 iters), loss = 1.4855
I1026 19:12:08.086396 37958 solver.cpp:240]     Train net output #0: loss = 1.4855 (* 1 = 1.4855 loss)
I1026 19:12:08.086411 37958 sgd_solver.cpp:105] Iteration 14960, lr = 0.00912
I1026 19:12:38.116667 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_15000.caffemodel
I1026 19:12:38.151204 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_15000.solverstate
I1026 19:12:38.173127 37958 solver.cpp:333] Iteration 15000, Testing net (#0)
I1026 19:13:09.121122 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.523
I1026 19:13:09.121268 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.765
I1026 19:13:09.121282 37958 solver.cpp:400]     Test net output #2: loss = 2.15114 (* 1 = 2.15114 loss)
I1026 19:13:09.883440 37958 solver.cpp:221] Iteration 15000 (0.647304 iter/s, 61.7947s/40 iters), loss = 1.63184
I1026 19:13:09.883496 37958 solver.cpp:240]     Train net output #0: loss = 1.63184 (* 1 = 1.63184 loss)
I1026 19:13:09.883509 37958 sgd_solver.cpp:105] Iteration 15000, lr = 0.00911765
I1026 19:13:17.208643 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1026 19:13:40.621944 37958 solver.cpp:221] Iteration 15040 (1.30135 iter/s, 30.7373s/40 iters), loss = 1.56986
I1026 19:13:40.622145 37958 solver.cpp:240]     Train net output #0: loss = 1.56986 (* 1 = 1.56986 loss)
I1026 19:13:40.622159 37958 sgd_solver.cpp:105] Iteration 15040, lr = 0.00911529
I1026 19:14:10.885463 37958 solver.cpp:221] Iteration 15080 (1.32178 iter/s, 30.2622s/40 iters), loss = 1.80003
I1026 19:14:10.885635 37958 solver.cpp:240]     Train net output #0: loss = 1.80003 (* 1 = 1.80003 loss)
I1026 19:14:10.885650 37958 sgd_solver.cpp:105] Iteration 15080, lr = 0.00911294
I1026 19:14:41.447638 37958 solver.cpp:221] Iteration 15120 (1.30886 iter/s, 30.5608s/40 iters), loss = 1.89254
I1026 19:14:41.447825 37958 solver.cpp:240]     Train net output #0: loss = 1.89254 (* 1 = 1.89254 loss)
I1026 19:14:41.447839 37958 sgd_solver.cpp:105] Iteration 15120, lr = 0.00911059
I1026 19:15:12.041131 37958 solver.cpp:221] Iteration 15160 (1.30753 iter/s, 30.5921s/40 iters), loss = 1.8023
I1026 19:15:12.041352 37958 solver.cpp:240]     Train net output #0: loss = 1.8023 (* 1 = 1.8023 loss)
I1026 19:15:12.041373 37958 sgd_solver.cpp:105] Iteration 15160, lr = 0.00910824
I1026 19:15:44.053433 37958 solver.cpp:221] Iteration 15200 (1.24958 iter/s, 32.0109s/40 iters), loss = 1.81179
I1026 19:15:44.053606 37958 solver.cpp:240]     Train net output #0: loss = 1.81179 (* 1 = 1.81179 loss)
I1026 19:15:44.053622 37958 sgd_solver.cpp:105] Iteration 15200, lr = 0.00910588
I1026 19:16:21.245084 37958 solver.cpp:221] Iteration 15240 (1.07556 iter/s, 37.1901s/40 iters), loss = 1.78929
I1026 19:16:21.245335 37958 solver.cpp:240]     Train net output #0: loss = 1.78929 (* 1 = 1.78929 loss)
I1026 19:16:21.245357 37958 sgd_solver.cpp:105] Iteration 15240, lr = 0.00910353
I1026 19:16:57.569980 37958 solver.cpp:221] Iteration 15280 (1.10122 iter/s, 36.3233s/40 iters), loss = 2.38407
I1026 19:16:57.570183 37958 solver.cpp:240]     Train net output #0: loss = 2.38407 (* 1 = 2.38407 loss)
I1026 19:16:57.570197 37958 sgd_solver.cpp:105] Iteration 15280, lr = 0.00910118
I1026 19:17:28.629716 37958 solver.cpp:221] Iteration 15320 (1.2879 iter/s, 31.0584s/40 iters), loss = 2.00079
I1026 19:17:28.629907 37958 solver.cpp:240]     Train net output #0: loss = 2.00079 (* 1 = 2.00079 loss)
I1026 19:17:28.629922 37958 sgd_solver.cpp:105] Iteration 15320, lr = 0.00909882
I1026 19:17:59.281626 37958 solver.cpp:221] Iteration 15360 (1.30503 iter/s, 30.6506s/40 iters), loss = 2.00841
I1026 19:17:59.281810 37958 solver.cpp:240]     Train net output #0: loss = 2.00841 (* 1 = 2.00841 loss)
I1026 19:17:59.281824 37958 sgd_solver.cpp:105] Iteration 15360, lr = 0.00909647
I1026 19:18:29.705121 37958 solver.cpp:221] Iteration 15400 (1.31483 iter/s, 30.4222s/40 iters), loss = 1.81309
I1026 19:18:29.705312 37958 solver.cpp:240]     Train net output #0: loss = 1.81309 (* 1 = 1.81309 loss)
I1026 19:18:29.705329 37958 sgd_solver.cpp:105] Iteration 15400, lr = 0.00909412
I1026 19:19:00.229521 37958 solver.cpp:221] Iteration 15440 (1.31048 iter/s, 30.5231s/40 iters), loss = 1.69266
I1026 19:19:00.229727 37958 solver.cpp:240]     Train net output #0: loss = 1.69266 (* 1 = 1.69266 loss)
I1026 19:19:00.229743 37958 sgd_solver.cpp:105] Iteration 15440, lr = 0.00909176
I1026 19:19:30.875100 37958 solver.cpp:221] Iteration 15480 (1.3053 iter/s, 30.6442s/40 iters), loss = 1.78321
I1026 19:19:30.875257 37958 solver.cpp:240]     Train net output #0: loss = 1.78321 (* 1 = 1.78321 loss)
I1026 19:19:30.875272 37958 sgd_solver.cpp:105] Iteration 15480, lr = 0.00908941
I1026 19:19:45.882344 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_15500.caffemodel
I1026 19:19:45.914036 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_15500.solverstate
I1026 19:19:45.931496 37958 solver.cpp:333] Iteration 15500, Testing net (#0)
I1026 19:20:16.639695 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 19:20:16.846236 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52224
I1026 19:20:16.846289 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76664
I1026 19:20:16.846304 37958 solver.cpp:400]     Test net output #2: loss = 2.13523 (* 1 = 2.13523 loss)
I1026 19:20:33.358959 37958 solver.cpp:221] Iteration 15520 (0.640191 iter/s, 62.4813s/40 iters), loss = 1.70895
I1026 19:20:33.359046 37958 solver.cpp:240]     Train net output #0: loss = 1.70895 (* 1 = 1.70895 loss)
I1026 19:20:33.359067 37958 sgd_solver.cpp:105] Iteration 15520, lr = 0.00908706
I1026 19:21:05.101410 37958 solver.cpp:221] Iteration 15560 (1.26019 iter/s, 31.7412s/40 iters), loss = 1.82381
I1026 19:21:05.101610 37958 solver.cpp:240]     Train net output #0: loss = 1.82381 (* 1 = 1.82381 loss)
I1026 19:21:05.101625 37958 sgd_solver.cpp:105] Iteration 15560, lr = 0.00908471
I1026 19:21:36.197651 37958 solver.cpp:221] Iteration 15600 (1.28639 iter/s, 31.0948s/40 iters), loss = 1.76539
I1026 19:21:36.197873 37958 solver.cpp:240]     Train net output #0: loss = 1.76539 (* 1 = 1.76539 loss)
I1026 19:21:36.197897 37958 sgd_solver.cpp:105] Iteration 15600, lr = 0.00908235
I1026 19:22:07.470782 37958 solver.cpp:221] Iteration 15640 (1.27911 iter/s, 31.2717s/40 iters), loss = 2.08945
I1026 19:22:07.470984 37958 solver.cpp:240]     Train net output #0: loss = 2.08945 (* 1 = 2.08945 loss)
I1026 19:22:07.471004 37958 sgd_solver.cpp:105] Iteration 15640, lr = 0.00908
I1026 19:22:39.245395 37958 solver.cpp:221] Iteration 15680 (1.25892 iter/s, 31.7732s/40 iters), loss = 1.95145
I1026 19:22:39.245594 37958 solver.cpp:240]     Train net output #0: loss = 1.95145 (* 1 = 1.95145 loss)
I1026 19:22:39.245607 37958 sgd_solver.cpp:105] Iteration 15680, lr = 0.00907765
I1026 19:23:09.878047 37958 solver.cpp:221] Iteration 15720 (1.30585 iter/s, 30.6313s/40 iters), loss = 1.96372
I1026 19:23:09.878201 37958 solver.cpp:240]     Train net output #0: loss = 1.96372 (* 1 = 1.96372 loss)
I1026 19:23:09.878216 37958 sgd_solver.cpp:105] Iteration 15720, lr = 0.00907529
I1026 19:23:40.391968 37958 solver.cpp:221] Iteration 15760 (1.31093 iter/s, 30.5126s/40 iters), loss = 1.88393
I1026 19:23:40.392122 37958 solver.cpp:240]     Train net output #0: loss = 1.88393 (* 1 = 1.88393 loss)
I1026 19:23:40.392137 37958 sgd_solver.cpp:105] Iteration 15760, lr = 0.00907294
I1026 19:24:10.665184 37958 solver.cpp:221] Iteration 15800 (1.32136 iter/s, 30.2719s/40 iters), loss = 1.99986
I1026 19:24:10.665406 37958 solver.cpp:240]     Train net output #0: loss = 1.99986 (* 1 = 1.99986 loss)
I1026 19:24:10.665421 37958 sgd_solver.cpp:105] Iteration 15800, lr = 0.00907059
I1026 19:24:41.479234 37958 solver.cpp:221] Iteration 15840 (1.29817 iter/s, 30.8127s/40 iters), loss = 1.77581
I1026 19:24:41.479485 37958 solver.cpp:240]     Train net output #0: loss = 1.77581 (* 1 = 1.77581 loss)
I1026 19:24:41.479501 37958 sgd_solver.cpp:105] Iteration 15840, lr = 0.00906823
I1026 19:25:12.355427 37958 solver.cpp:221] Iteration 15880 (1.29556 iter/s, 30.8748s/40 iters), loss = 1.81337
I1026 19:25:12.355630 37958 solver.cpp:240]     Train net output #0: loss = 1.81337 (* 1 = 1.81337 loss)
I1026 19:25:12.355664 37958 sgd_solver.cpp:105] Iteration 15880, lr = 0.00906588
I1026 19:25:42.998152 37958 solver.cpp:221] Iteration 15920 (1.30542 iter/s, 30.6414s/40 iters), loss = 2.17456
I1026 19:25:42.998319 37958 solver.cpp:240]     Train net output #0: loss = 2.17456 (* 1 = 2.17456 loss)
I1026 19:25:42.998335 37958 sgd_solver.cpp:105] Iteration 15920, lr = 0.00906353
I1026 19:26:14.002326 37958 solver.cpp:221] Iteration 15960 (1.2902 iter/s, 31.0028s/40 iters), loss = 1.73974
I1026 19:26:14.002488 37958 solver.cpp:240]     Train net output #0: loss = 1.73974 (* 1 = 1.73974 loss)
I1026 19:26:14.002503 37958 sgd_solver.cpp:105] Iteration 15960, lr = 0.00906118
I1026 19:26:44.591743 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_16000.caffemodel
I1026 19:26:44.624141 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_16000.solverstate
I1026 19:26:44.641942 37958 solver.cpp:333] Iteration 16000, Testing net (#0)
I1026 19:27:15.560533 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.5204
I1026 19:27:15.560681 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76752
I1026 19:27:15.560694 37958 solver.cpp:400]     Test net output #2: loss = 2.16584 (* 1 = 2.16584 loss)
I1026 19:27:16.328933 37958 solver.cpp:221] Iteration 16000 (0.641806 iter/s, 62.3241s/40 iters), loss = 1.84365
I1026 19:27:16.328987 37958 solver.cpp:240]     Train net output #0: loss = 1.84365 (* 1 = 1.84365 loss)
I1026 19:27:16.329001 37958 sgd_solver.cpp:105] Iteration 16000, lr = 0.00905882
I1026 19:27:47.045994 37958 solver.cpp:221] Iteration 16040 (1.30226 iter/s, 30.7158s/40 iters), loss = 2.06833
I1026 19:27:47.046175 37958 solver.cpp:240]     Train net output #0: loss = 2.06833 (* 1 = 2.06833 loss)
I1026 19:27:47.046190 37958 sgd_solver.cpp:105] Iteration 16040, lr = 0.00905647
I1026 19:28:18.328285 37958 solver.cpp:221] Iteration 16080 (1.27873 iter/s, 31.2809s/40 iters), loss = 1.73751
I1026 19:28:18.328470 37958 solver.cpp:240]     Train net output #0: loss = 1.73751 (* 1 = 1.73751 loss)
I1026 19:28:18.328485 37958 sgd_solver.cpp:105] Iteration 16080, lr = 0.00905412
I1026 19:28:49.641840 37958 solver.cpp:221] Iteration 16120 (1.27746 iter/s, 31.3122s/40 iters), loss = 1.92795
I1026 19:28:49.642009 37958 solver.cpp:240]     Train net output #0: loss = 1.92795 (* 1 = 1.92795 loss)
I1026 19:28:49.642024 37958 sgd_solver.cpp:105] Iteration 16120, lr = 0.00905176
I1026 19:29:21.513000 37958 solver.cpp:221] Iteration 16160 (1.25511 iter/s, 31.8698s/40 iters), loss = 1.86315
I1026 19:29:21.513175 37958 solver.cpp:240]     Train net output #0: loss = 1.86315 (* 1 = 1.86315 loss)
I1026 19:29:21.513190 37958 sgd_solver.cpp:105] Iteration 16160, lr = 0.00904941
I1026 19:29:55.046032 37958 solver.cpp:221] Iteration 16200 (1.19291 iter/s, 33.5316s/40 iters), loss = 1.84134
I1026 19:29:55.046243 37958 solver.cpp:240]     Train net output #0: loss = 1.84134 (* 1 = 1.84134 loss)
I1026 19:29:55.046265 37958 sgd_solver.cpp:105] Iteration 16200, lr = 0.00904706
I1026 19:30:26.055030 37958 solver.cpp:221] Iteration 16240 (1.29001 iter/s, 31.0076s/40 iters), loss = 1.78105
I1026 19:30:26.055212 37958 solver.cpp:240]     Train net output #0: loss = 1.78105 (* 1 = 1.78105 loss)
I1026 19:30:26.055227 37958 sgd_solver.cpp:105] Iteration 16240, lr = 0.00904471
I1026 19:30:57.948071 37958 solver.cpp:221] Iteration 16280 (1.25425 iter/s, 31.8917s/40 iters), loss = 1.80187
I1026 19:30:57.948320 37958 solver.cpp:240]     Train net output #0: loss = 1.80187 (* 1 = 1.80187 loss)
I1026 19:30:57.948346 37958 sgd_solver.cpp:105] Iteration 16280, lr = 0.00904235
I1026 19:31:28.851928 37958 solver.cpp:221] Iteration 16320 (1.2944 iter/s, 30.9024s/40 iters), loss = 1.80348
I1026 19:31:28.852171 37958 solver.cpp:240]     Train net output #0: loss = 1.80348 (* 1 = 1.80348 loss)
I1026 19:31:28.852186 37958 sgd_solver.cpp:105] Iteration 16320, lr = 0.00904
I1026 19:31:59.449323 37958 solver.cpp:221] Iteration 16360 (1.30736 iter/s, 30.596s/40 iters), loss = 1.96051
I1026 19:31:59.449491 37958 solver.cpp:240]     Train net output #0: loss = 1.96051 (* 1 = 1.96051 loss)
I1026 19:31:59.449506 37958 sgd_solver.cpp:105] Iteration 16360, lr = 0.00903765
I1026 19:32:30.389834 37958 solver.cpp:221] Iteration 16400 (1.29286 iter/s, 30.9392s/40 iters), loss = 1.89307
I1026 19:32:30.390116 37958 solver.cpp:240]     Train net output #0: loss = 1.89307 (* 1 = 1.89307 loss)
I1026 19:32:30.390153 37958 sgd_solver.cpp:105] Iteration 16400, lr = 0.00903529
I1026 19:33:01.925940 37958 solver.cpp:221] Iteration 16440 (1.26845 iter/s, 31.5346s/40 iters), loss = 1.95352
I1026 19:33:01.926132 37958 solver.cpp:240]     Train net output #0: loss = 1.95352 (* 1 = 1.95352 loss)
I1026 19:33:01.926147 37958 sgd_solver.cpp:105] Iteration 16440, lr = 0.00903294
I1026 19:33:32.835507 37958 solver.cpp:221] Iteration 16480 (1.29415 iter/s, 30.9082s/40 iters), loss = 1.95178
I1026 19:33:32.835697 37958 solver.cpp:240]     Train net output #0: loss = 1.95178 (* 1 = 1.95178 loss)
I1026 19:33:32.835712 37958 sgd_solver.cpp:105] Iteration 16480, lr = 0.00903059
I1026 19:33:47.544570 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_16500.caffemodel
I1026 19:33:47.583114 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_16500.solverstate
I1026 19:33:47.607012 37958 solver.cpp:333] Iteration 16500, Testing net (#0)
I1026 19:34:18.567565 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 19:34:18.774358 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52624
I1026 19:34:18.774401 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76784
I1026 19:34:18.774412 37958 solver.cpp:400]     Test net output #2: loss = 2.12162 (* 1 = 2.12162 loss)
I1026 19:34:34.775065 37958 solver.cpp:221] Iteration 16520 (0.645817 iter/s, 61.937s/40 iters), loss = 2.07118
I1026 19:34:34.775125 37958 solver.cpp:240]     Train net output #0: loss = 2.07118 (* 1 = 2.07118 loss)
I1026 19:34:34.775140 37958 sgd_solver.cpp:105] Iteration 16520, lr = 0.00902823
I1026 19:35:05.053690 37958 solver.cpp:221] Iteration 16560 (1.32112 iter/s, 30.2774s/40 iters), loss = 1.67831
I1026 19:35:05.053864 37958 solver.cpp:240]     Train net output #0: loss = 1.67831 (* 1 = 1.67831 loss)
I1026 19:35:05.053879 37958 sgd_solver.cpp:105] Iteration 16560, lr = 0.00902588
I1026 19:35:35.179673 37958 solver.cpp:221] Iteration 16600 (1.32782 iter/s, 30.1247s/40 iters), loss = 1.97381
I1026 19:35:35.179836 37958 solver.cpp:240]     Train net output #0: loss = 1.97381 (* 1 = 1.97381 loss)
I1026 19:35:35.179849 37958 sgd_solver.cpp:105] Iteration 16600, lr = 0.00902353
I1026 19:36:05.441709 37958 solver.cpp:221] Iteration 16640 (1.32185 iter/s, 30.2607s/40 iters), loss = 2.11753
I1026 19:36:05.441871 37958 solver.cpp:240]     Train net output #0: loss = 2.11753 (* 1 = 2.11753 loss)
I1026 19:36:05.441886 37958 sgd_solver.cpp:105] Iteration 16640, lr = 0.00902118
I1026 19:36:35.841235 37958 solver.cpp:221] Iteration 16680 (1.31587 iter/s, 30.3982s/40 iters), loss = 1.7053
I1026 19:36:35.841382 37958 solver.cpp:240]     Train net output #0: loss = 1.7053 (* 1 = 1.7053 loss)
I1026 19:36:35.841398 37958 sgd_solver.cpp:105] Iteration 16680, lr = 0.00901882
I1026 19:37:06.645596 37958 solver.cpp:221] Iteration 16720 (1.29857 iter/s, 30.803s/40 iters), loss = 2.0041
I1026 19:37:06.645781 37958 solver.cpp:240]     Train net output #0: loss = 2.0041 (* 1 = 2.0041 loss)
I1026 19:37:06.645797 37958 sgd_solver.cpp:105] Iteration 16720, lr = 0.00901647
I1026 19:37:37.409373 37958 solver.cpp:221] Iteration 16760 (1.30029 iter/s, 30.7624s/40 iters), loss = 1.65921
I1026 19:37:37.409605 37958 solver.cpp:240]     Train net output #0: loss = 1.65921 (* 1 = 1.65921 loss)
I1026 19:37:37.409621 37958 sgd_solver.cpp:105] Iteration 16760, lr = 0.00901412
I1026 19:38:08.850112 37958 solver.cpp:221] Iteration 16800 (1.27229 iter/s, 31.4393s/40 iters), loss = 1.95028
I1026 19:38:08.850329 37958 solver.cpp:240]     Train net output #0: loss = 1.95028 (* 1 = 1.95028 loss)
I1026 19:38:08.850350 37958 sgd_solver.cpp:105] Iteration 16800, lr = 0.00901176
I1026 19:38:41.366210 37958 solver.cpp:221] Iteration 16840 (1.23021 iter/s, 32.5147s/40 iters), loss = 1.78804
I1026 19:38:41.366405 37958 solver.cpp:240]     Train net output #0: loss = 1.78804 (* 1 = 1.78804 loss)
I1026 19:38:41.366427 37958 sgd_solver.cpp:105] Iteration 16840, lr = 0.00900941
I1026 19:39:12.414809 37958 solver.cpp:221] Iteration 16880 (1.28836 iter/s, 31.0472s/40 iters), loss = 1.60774
I1026 19:39:12.415027 37958 solver.cpp:240]     Train net output #0: loss = 1.60774 (* 1 = 1.60774 loss)
I1026 19:39:12.415047 37958 sgd_solver.cpp:105] Iteration 16880, lr = 0.00900706
I1026 19:39:43.497165 37958 solver.cpp:221] Iteration 16920 (1.28696 iter/s, 31.081s/40 iters), loss = 2.02089
I1026 19:39:43.497407 37958 solver.cpp:240]     Train net output #0: loss = 2.02089 (* 1 = 2.02089 loss)
I1026 19:39:43.497422 37958 sgd_solver.cpp:105] Iteration 16920, lr = 0.00900471
I1026 19:40:14.424814 37958 solver.cpp:221] Iteration 16960 (1.2934 iter/s, 30.9262s/40 iters), loss = 1.93796
I1026 19:40:14.425026 37958 solver.cpp:240]     Train net output #0: loss = 1.93796 (* 1 = 1.93796 loss)
I1026 19:40:14.425041 37958 sgd_solver.cpp:105] Iteration 16960, lr = 0.00900235
I1026 19:40:44.434177 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_17000.caffemodel
I1026 19:40:44.466343 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_17000.solverstate
I1026 19:40:44.484150 37958 solver.cpp:333] Iteration 17000, Testing net (#0)
I1026 19:41:15.360446 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.5318
I1026 19:41:15.360605 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77172
I1026 19:41:15.360618 37958 solver.cpp:400]     Test net output #2: loss = 2.09487 (* 1 = 2.09487 loss)
I1026 19:41:16.126344 37958 solver.cpp:221] Iteration 17000 (0.648309 iter/s, 61.699s/40 iters), loss = 1.9247
I1026 19:41:16.126408 37958 solver.cpp:240]     Train net output #0: loss = 1.9247 (* 1 = 1.9247 loss)
I1026 19:41:16.126422 37958 sgd_solver.cpp:105] Iteration 17000, lr = 0.009
I1026 19:41:47.064903 37958 solver.cpp:221] Iteration 17040 (1.29294 iter/s, 30.9373s/40 iters), loss = 2.11381
I1026 19:41:47.065098 37958 solver.cpp:240]     Train net output #0: loss = 2.11381 (* 1 = 2.11381 loss)
I1026 19:41:47.065112 37958 sgd_solver.cpp:105] Iteration 17040, lr = 0.00899765
I1026 19:42:17.828480 37958 solver.cpp:221] Iteration 17080 (1.3003 iter/s, 30.7622s/40 iters), loss = 2.00479
I1026 19:42:17.828649 37958 solver.cpp:240]     Train net output #0: loss = 2.00479 (* 1 = 2.00479 loss)
I1026 19:42:17.828663 37958 sgd_solver.cpp:105] Iteration 17080, lr = 0.00899529
I1026 19:42:48.100148 37958 solver.cpp:221] Iteration 17120 (1.32142 iter/s, 30.2704s/40 iters), loss = 1.87233
I1026 19:42:48.100371 37958 solver.cpp:240]     Train net output #0: loss = 1.87233 (* 1 = 1.87233 loss)
I1026 19:42:48.100386 37958 sgd_solver.cpp:105] Iteration 17120, lr = 0.00899294
I1026 19:43:18.427426 37958 solver.cpp:221] Iteration 17160 (1.319 iter/s, 30.3259s/40 iters), loss = 1.74664
I1026 19:43:18.427611 37958 solver.cpp:240]     Train net output #0: loss = 1.74664 (* 1 = 1.74664 loss)
I1026 19:43:18.427626 37958 sgd_solver.cpp:105] Iteration 17160, lr = 0.00899059
I1026 19:43:48.814671 37958 solver.cpp:221] Iteration 17200 (1.3164 iter/s, 30.3859s/40 iters), loss = 1.71074
I1026 19:43:48.814872 37958 solver.cpp:240]     Train net output #0: loss = 1.71074 (* 1 = 1.71074 loss)
I1026 19:43:48.814888 37958 sgd_solver.cpp:105] Iteration 17200, lr = 0.00898824
I1026 19:44:19.694923 37958 solver.cpp:221] Iteration 17240 (1.29538 iter/s, 30.8789s/40 iters), loss = 2.01478
I1026 19:44:19.695107 37958 solver.cpp:240]     Train net output #0: loss = 2.01478 (* 1 = 2.01478 loss)
I1026 19:44:19.695122 37958 sgd_solver.cpp:105] Iteration 17240, lr = 0.00898588
I1026 19:44:50.905426 37958 solver.cpp:221] Iteration 17280 (1.28168 iter/s, 31.2092s/40 iters), loss = 1.57749
I1026 19:44:50.905611 37958 solver.cpp:240]     Train net output #0: loss = 1.57749 (* 1 = 1.57749 loss)
I1026 19:44:50.905627 37958 sgd_solver.cpp:105] Iteration 17280, lr = 0.00898353
I1026 19:45:22.832455 37958 solver.cpp:221] Iteration 17320 (1.25291 iter/s, 31.9257s/40 iters), loss = 1.83431
I1026 19:45:22.832646 37958 solver.cpp:240]     Train net output #0: loss = 1.83431 (* 1 = 1.83431 loss)
I1026 19:45:22.832661 37958 sgd_solver.cpp:105] Iteration 17320, lr = 0.00898118
I1026 19:45:53.693687 37958 solver.cpp:221] Iteration 17360 (1.29618 iter/s, 30.8599s/40 iters), loss = 1.75901
I1026 19:45:53.693873 37958 solver.cpp:240]     Train net output #0: loss = 1.75901 (* 1 = 1.75901 loss)
I1026 19:45:53.693888 37958 sgd_solver.cpp:105] Iteration 17360, lr = 0.00897882
I1026 19:46:24.461135 37958 solver.cpp:221] Iteration 17400 (1.30013 iter/s, 30.7661s/40 iters), loss = 1.82918
I1026 19:46:24.461318 37958 solver.cpp:240]     Train net output #0: loss = 1.82918 (* 1 = 1.82918 loss)
I1026 19:46:24.461333 37958 sgd_solver.cpp:105] Iteration 17400, lr = 0.00897647
I1026 19:46:55.530910 37958 solver.cpp:221] Iteration 17440 (1.28748 iter/s, 31.0684s/40 iters), loss = 1.85206
I1026 19:46:55.531142 37958 solver.cpp:240]     Train net output #0: loss = 1.85206 (* 1 = 1.85206 loss)
I1026 19:46:55.531163 37958 sgd_solver.cpp:105] Iteration 17440, lr = 0.00897412
I1026 19:47:26.681882 37958 solver.cpp:221] Iteration 17480 (1.28413 iter/s, 31.1496s/40 iters), loss = 2.07245
I1026 19:47:26.682072 37958 solver.cpp:240]     Train net output #0: loss = 2.07245 (* 1 = 2.07245 loss)
I1026 19:47:26.682087 37958 sgd_solver.cpp:105] Iteration 17480, lr = 0.00897176
I1026 19:47:41.491904 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_17500.caffemodel
I1026 19:47:41.534868 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_17500.solverstate
I1026 19:47:41.558359 37958 solver.cpp:333] Iteration 17500, Testing net (#0)
I1026 19:48:12.226387 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 19:48:12.432641 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.51852
I1026 19:48:12.432699 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76388
I1026 19:48:12.432710 37958 solver.cpp:400]     Test net output #2: loss = 2.13343 (* 1 = 2.13343 loss)
I1026 19:48:22.225095 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1026 19:48:28.839227 37958 solver.cpp:221] Iteration 17520 (0.643554 iter/s, 62.1548s/40 iters), loss = 1.98774
I1026 19:48:28.839284 37958 solver.cpp:240]     Train net output #0: loss = 1.98774 (* 1 = 1.98774 loss)
I1026 19:48:28.839303 37958 sgd_solver.cpp:105] Iteration 17520, lr = 0.00896941
I1026 19:49:00.395228 37958 solver.cpp:221] Iteration 17560 (1.26764 iter/s, 31.5547s/40 iters), loss = 2.23688
I1026 19:49:00.395416 37958 solver.cpp:240]     Train net output #0: loss = 2.23688 (* 1 = 2.23688 loss)
I1026 19:49:00.395431 37958 sgd_solver.cpp:105] Iteration 17560, lr = 0.00896706
I1026 19:49:31.593235 37958 solver.cpp:221] Iteration 17600 (1.28219 iter/s, 31.1966s/40 iters), loss = 1.69782
I1026 19:49:31.593446 37958 solver.cpp:240]     Train net output #0: loss = 1.69782 (* 1 = 1.69782 loss)
I1026 19:49:31.593466 37958 sgd_solver.cpp:105] Iteration 17600, lr = 0.00896471
I1026 19:50:02.842856 37958 solver.cpp:221] Iteration 17640 (1.28007 iter/s, 31.2482s/40 iters), loss = 1.90715
I1026 19:50:02.843137 37958 solver.cpp:240]     Train net output #0: loss = 1.90715 (* 1 = 1.90715 loss)
I1026 19:50:02.843168 37958 sgd_solver.cpp:105] Iteration 17640, lr = 0.00896235
I1026 19:50:34.240612 37958 solver.cpp:221] Iteration 17680 (1.27404 iter/s, 31.3963s/40 iters), loss = 2.02505
I1026 19:50:34.240836 37958 solver.cpp:240]     Train net output #0: loss = 2.02505 (* 1 = 2.02505 loss)
I1026 19:50:34.240859 37958 sgd_solver.cpp:105] Iteration 17680, lr = 0.00896
I1026 19:51:05.968451 37958 solver.cpp:221] Iteration 17720 (1.26078 iter/s, 31.7264s/40 iters), loss = 1.7506
I1026 19:51:05.968641 37958 solver.cpp:240]     Train net output #0: loss = 1.7506 (* 1 = 1.7506 loss)
I1026 19:51:05.968657 37958 sgd_solver.cpp:105] Iteration 17720, lr = 0.00895765
I1026 19:51:36.418071 37958 solver.cpp:221] Iteration 17760 (1.3137 iter/s, 30.4483s/40 iters), loss = 2.29519
I1026 19:51:36.418237 37958 solver.cpp:240]     Train net output #0: loss = 2.29519 (* 1 = 2.29519 loss)
I1026 19:51:36.418251 37958 sgd_solver.cpp:105] Iteration 17760, lr = 0.00895529
I1026 19:52:06.831245 37958 solver.cpp:221] Iteration 17800 (1.31528 iter/s, 30.4119s/40 iters), loss = 1.63443
I1026 19:52:06.831404 37958 solver.cpp:240]     Train net output #0: loss = 1.63443 (* 1 = 1.63443 loss)
I1026 19:52:06.831418 37958 sgd_solver.cpp:105] Iteration 17800, lr = 0.00895294
I1026 19:52:37.383247 37958 solver.cpp:221] Iteration 17840 (1.3093 iter/s, 30.5507s/40 iters), loss = 1.94893
I1026 19:52:37.383409 37958 solver.cpp:240]     Train net output #0: loss = 1.94893 (* 1 = 1.94893 loss)
I1026 19:52:37.383424 37958 sgd_solver.cpp:105] Iteration 17840, lr = 0.00895059
I1026 19:53:07.900920 37958 solver.cpp:221] Iteration 17880 (1.31077 iter/s, 30.5164s/40 iters), loss = 1.82491
I1026 19:53:07.901093 37958 solver.cpp:240]     Train net output #0: loss = 1.82491 (* 1 = 1.82491 loss)
I1026 19:53:07.901108 37958 sgd_solver.cpp:105] Iteration 17880, lr = 0.00894824
I1026 19:53:38.402164 37958 solver.cpp:221] Iteration 17920 (1.31148 iter/s, 30.4999s/40 iters), loss = 1.69445
I1026 19:53:38.402469 37958 solver.cpp:240]     Train net output #0: loss = 1.69445 (* 1 = 1.69445 loss)
I1026 19:53:38.402483 37958 sgd_solver.cpp:105] Iteration 17920, lr = 0.00894588
I1026 19:54:08.630934 37958 solver.cpp:221] Iteration 17960 (1.32331 iter/s, 30.2273s/40 iters), loss = 2.18386
I1026 19:54:08.631083 37958 solver.cpp:240]     Train net output #0: loss = 2.18386 (* 1 = 2.18386 loss)
I1026 19:54:08.631096 37958 sgd_solver.cpp:105] Iteration 17960, lr = 0.00894353
I1026 19:54:38.447993 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_18000.caffemodel
I1026 19:54:38.479666 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_18000.solverstate
I1026 19:54:38.502539 37958 solver.cpp:333] Iteration 18000, Testing net (#0)
I1026 19:55:09.400626 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.5278
I1026 19:55:09.400858 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77056
I1026 19:55:09.400871 37958 solver.cpp:400]     Test net output #2: loss = 2.10094 (* 1 = 2.10094 loss)
I1026 19:55:10.158996 37958 solver.cpp:221] Iteration 18000 (0.650136 iter/s, 61.5256s/40 iters), loss = 1.77218
I1026 19:55:10.159034 37958 solver.cpp:240]     Train net output #0: loss = 1.77218 (* 1 = 1.77218 loss)
I1026 19:55:10.159046 37958 sgd_solver.cpp:105] Iteration 18000, lr = 0.00894118
I1026 19:55:40.724413 37958 solver.cpp:221] Iteration 18040 (1.30872 iter/s, 30.5642s/40 iters), loss = 1.46116
I1026 19:55:40.724570 37958 solver.cpp:240]     Train net output #0: loss = 1.46116 (* 1 = 1.46116 loss)
I1026 19:55:40.724583 37958 sgd_solver.cpp:105] Iteration 18040, lr = 0.00893882
I1026 19:56:11.294049 37958 solver.cpp:221] Iteration 18080 (1.30854 iter/s, 30.5683s/40 iters), loss = 1.92432
I1026 19:56:11.294289 37958 solver.cpp:240]     Train net output #0: loss = 1.92432 (* 1 = 1.92432 loss)
I1026 19:56:11.294311 37958 sgd_solver.cpp:105] Iteration 18080, lr = 0.00893647
I1026 19:56:41.862722 37958 solver.cpp:221] Iteration 18120 (1.30859 iter/s, 30.5673s/40 iters), loss = 1.67233
I1026 19:56:41.862937 37958 solver.cpp:240]     Train net output #0: loss = 1.67233 (* 1 = 1.67233 loss)
I1026 19:56:41.862957 37958 sgd_solver.cpp:105] Iteration 18120, lr = 0.00893412
I1026 19:57:12.457564 37958 solver.cpp:221] Iteration 18160 (1.30747 iter/s, 30.5935s/40 iters), loss = 1.90162
I1026 19:57:12.457744 37958 solver.cpp:240]     Train net output #0: loss = 1.90162 (* 1 = 1.90162 loss)
I1026 19:57:12.457759 37958 sgd_solver.cpp:105] Iteration 18160, lr = 0.00893176
I1026 19:58:00.750252 37958 solver.cpp:221] Iteration 18200 (0.828317 iter/s, 48.2907s/40 iters), loss = 1.66968
I1026 19:58:00.750437 37958 solver.cpp:240]     Train net output #0: loss = 1.66968 (* 1 = 1.66968 loss)
I1026 19:58:00.750455 37958 sgd_solver.cpp:105] Iteration 18200, lr = 0.00892941
I1026 19:58:41.400027 37958 solver.cpp:221] Iteration 18240 (0.984057 iter/s, 40.6481s/40 iters), loss = 1.79621
I1026 19:58:41.400261 37958 solver.cpp:240]     Train net output #0: loss = 1.79621 (* 1 = 1.79621 loss)
I1026 19:58:41.400283 37958 sgd_solver.cpp:105] Iteration 18240, lr = 0.00892706
I1026 19:59:12.767163 37958 solver.cpp:221] Iteration 18280 (1.27528 iter/s, 31.3657s/40 iters), loss = 2.08346
I1026 19:59:12.767366 37958 solver.cpp:240]     Train net output #0: loss = 2.08346 (* 1 = 2.08346 loss)
I1026 19:59:12.767381 37958 sgd_solver.cpp:105] Iteration 18280, lr = 0.00892471
I1026 19:59:43.661841 37958 solver.cpp:221] Iteration 18320 (1.29478 iter/s, 30.8933s/40 iters), loss = 1.9846
I1026 19:59:43.662050 37958 solver.cpp:240]     Train net output #0: loss = 1.9846 (* 1 = 1.9846 loss)
I1026 19:59:43.662063 37958 sgd_solver.cpp:105] Iteration 18320, lr = 0.00892235
I1026 20:00:14.004391 37958 solver.cpp:221] Iteration 18360 (1.31834 iter/s, 30.3412s/40 iters), loss = 2.0913
I1026 20:00:14.004567 37958 solver.cpp:240]     Train net output #0: loss = 2.0913 (* 1 = 2.0913 loss)
I1026 20:00:14.004581 37958 sgd_solver.cpp:105] Iteration 18360, lr = 0.00892
I1026 20:00:44.432433 37958 solver.cpp:221] Iteration 18400 (1.31463 iter/s, 30.4267s/40 iters), loss = 1.94635
I1026 20:00:44.432602 37958 solver.cpp:240]     Train net output #0: loss = 1.94635 (* 1 = 1.94635 loss)
I1026 20:00:44.432616 37958 sgd_solver.cpp:105] Iteration 18400, lr = 0.00891765
I1026 20:01:14.892051 37958 solver.cpp:221] Iteration 18440 (1.31327 iter/s, 30.4583s/40 iters), loss = 1.67468
I1026 20:01:14.892243 37958 solver.cpp:240]     Train net output #0: loss = 1.67468 (* 1 = 1.67468 loss)
I1026 20:01:14.892258 37958 sgd_solver.cpp:105] Iteration 18440, lr = 0.00891529
I1026 20:01:45.592885 37958 solver.cpp:221] Iteration 18480 (1.30295 iter/s, 30.6995s/40 iters), loss = 2.02599
I1026 20:01:45.593127 37958 solver.cpp:240]     Train net output #0: loss = 2.02599 (* 1 = 2.02599 loss)
I1026 20:01:45.593142 37958 sgd_solver.cpp:105] Iteration 18480, lr = 0.00891294
I1026 20:02:00.070660 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_18500.caffemodel
I1026 20:02:00.103235 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_18500.solverstate
I1026 20:02:00.122166 37958 solver.cpp:333] Iteration 18500, Testing net (#0)
I1026 20:02:30.812633 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 20:02:31.023115 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52936
I1026 20:02:31.023169 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77044
I1026 20:02:31.023180 37958 solver.cpp:400]     Test net output #2: loss = 2.11027 (* 1 = 2.11027 loss)
I1026 20:02:47.174362 37958 solver.cpp:221] Iteration 18520 (0.649573 iter/s, 61.5789s/40 iters), loss = 1.97618
I1026 20:02:47.174428 37958 solver.cpp:240]     Train net output #0: loss = 1.97618 (* 1 = 1.97618 loss)
I1026 20:02:47.174443 37958 sgd_solver.cpp:105] Iteration 18520, lr = 0.00891059
I1026 20:03:17.777261 37958 solver.cpp:221] Iteration 18560 (1.30712 iter/s, 30.6017s/40 iters), loss = 1.88359
I1026 20:03:17.777489 37958 solver.cpp:240]     Train net output #0: loss = 1.88359 (* 1 = 1.88359 loss)
I1026 20:03:17.777505 37958 sgd_solver.cpp:105] Iteration 18560, lr = 0.00890824
I1026 20:03:48.454102 37958 solver.cpp:221] Iteration 18600 (1.30397 iter/s, 30.6755s/40 iters), loss = 2.01573
I1026 20:03:48.454283 37958 solver.cpp:240]     Train net output #0: loss = 2.01573 (* 1 = 2.01573 loss)
I1026 20:03:48.454303 37958 sgd_solver.cpp:105] Iteration 18600, lr = 0.00890588
I1026 20:04:19.123829 37958 solver.cpp:221] Iteration 18640 (1.30427 iter/s, 30.6684s/40 iters), loss = 1.84737
I1026 20:04:19.124032 37958 solver.cpp:240]     Train net output #0: loss = 1.84737 (* 1 = 1.84737 loss)
I1026 20:04:19.124047 37958 sgd_solver.cpp:105] Iteration 18640, lr = 0.00890353
I1026 20:04:50.076334 37958 solver.cpp:221] Iteration 18680 (1.29236 iter/s, 30.9511s/40 iters), loss = 2.15429
I1026 20:04:50.076509 37958 solver.cpp:240]     Train net output #0: loss = 2.15429 (* 1 = 2.15429 loss)
I1026 20:04:50.076524 37958 sgd_solver.cpp:105] Iteration 18680, lr = 0.00890118
I1026 20:05:20.783219 37958 solver.cpp:221] Iteration 18720 (1.3027 iter/s, 30.7055s/40 iters), loss = 1.975
I1026 20:05:20.783402 37958 solver.cpp:240]     Train net output #0: loss = 1.975 (* 1 = 1.975 loss)
I1026 20:05:20.783417 37958 sgd_solver.cpp:105] Iteration 18720, lr = 0.00889882
I1026 20:05:51.673614 37958 solver.cpp:221] Iteration 18760 (1.29496 iter/s, 30.889s/40 iters), loss = 1.93213
I1026 20:05:51.673799 37958 solver.cpp:240]     Train net output #0: loss = 1.93213 (* 1 = 1.93213 loss)
I1026 20:05:51.673813 37958 sgd_solver.cpp:105] Iteration 18760, lr = 0.00889647
I1026 20:06:22.444604 37958 solver.cpp:221] Iteration 18800 (1.29998 iter/s, 30.7696s/40 iters), loss = 2.02991
I1026 20:06:22.444808 37958 solver.cpp:240]     Train net output #0: loss = 2.02991 (* 1 = 2.02991 loss)
I1026 20:06:22.444823 37958 sgd_solver.cpp:105] Iteration 18800, lr = 0.00889412
I1026 20:06:53.305429 37958 solver.cpp:221] Iteration 18840 (1.2962 iter/s, 30.8594s/40 iters), loss = 1.77968
I1026 20:06:53.305611 37958 solver.cpp:240]     Train net output #0: loss = 1.77968 (* 1 = 1.77968 loss)
I1026 20:06:53.305626 37958 sgd_solver.cpp:105] Iteration 18840, lr = 0.00889177
I1026 20:07:24.105521 37958 solver.cpp:221] Iteration 18880 (1.29875 iter/s, 30.7987s/40 iters), loss = 1.706
I1026 20:07:24.105717 37958 solver.cpp:240]     Train net output #0: loss = 1.706 (* 1 = 1.706 loss)
I1026 20:07:24.105732 37958 sgd_solver.cpp:105] Iteration 18880, lr = 0.00888941
I1026 20:07:55.190579 37958 solver.cpp:221] Iteration 18920 (1.28685 iter/s, 31.0837s/40 iters), loss = 1.62388
I1026 20:07:55.190762 37958 solver.cpp:240]     Train net output #0: loss = 1.62388 (* 1 = 1.62388 loss)
I1026 20:07:55.190776 37958 sgd_solver.cpp:105] Iteration 18920, lr = 0.00888706
I1026 20:08:25.800220 37958 solver.cpp:221] Iteration 18960 (1.30683 iter/s, 30.6083s/40 iters), loss = 2.16765
I1026 20:08:25.800384 37958 solver.cpp:240]     Train net output #0: loss = 2.16765 (* 1 = 2.16765 loss)
I1026 20:08:25.800398 37958 sgd_solver.cpp:105] Iteration 18960, lr = 0.00888471
I1026 20:08:55.651177 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_19000.caffemodel
I1026 20:08:55.685652 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_19000.solverstate
I1026 20:08:55.705543 37958 solver.cpp:333] Iteration 19000, Testing net (#0)
I1026 20:09:26.572033 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.51808
I1026 20:09:26.572206 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76208
I1026 20:09:26.572221 37958 solver.cpp:400]     Test net output #2: loss = 2.1757 (* 1 = 2.1757 loss)
I1026 20:09:27.342789 37958 solver.cpp:221] Iteration 19000 (0.649983 iter/s, 61.5401s/40 iters), loss = 1.7459
I1026 20:09:27.342846 37958 solver.cpp:240]     Train net output #0: loss = 1.7459 (* 1 = 1.7459 loss)
I1026 20:09:27.342882 37958 sgd_solver.cpp:105] Iteration 19000, lr = 0.00888235
I1026 20:09:58.207021 37958 solver.cpp:221] Iteration 19040 (1.29605 iter/s, 30.863s/40 iters), loss = 1.7744
I1026 20:09:58.207293 37958 solver.cpp:240]     Train net output #0: loss = 1.7744 (* 1 = 1.7744 loss)
I1026 20:09:58.207332 37958 sgd_solver.cpp:105] Iteration 19040, lr = 0.00888
I1026 20:10:30.934494 37958 solver.cpp:221] Iteration 19080 (1.22227 iter/s, 32.726s/40 iters), loss = 1.63701
I1026 20:10:30.934710 37958 solver.cpp:240]     Train net output #0: loss = 1.63701 (* 1 = 1.63701 loss)
I1026 20:10:30.934731 37958 sgd_solver.cpp:105] Iteration 19080, lr = 0.00887765
I1026 20:11:03.318002 37958 solver.cpp:221] Iteration 19120 (1.23525 iter/s, 32.3821s/40 iters), loss = 1.85772
I1026 20:11:03.318178 37958 solver.cpp:240]     Train net output #0: loss = 1.85772 (* 1 = 1.85772 loss)
I1026 20:11:03.318194 37958 sgd_solver.cpp:105] Iteration 19120, lr = 0.00887529
I1026 20:11:34.716081 37958 solver.cpp:221] Iteration 19160 (1.27402 iter/s, 31.3967s/40 iters), loss = 1.75114
I1026 20:11:34.716289 37958 solver.cpp:240]     Train net output #0: loss = 1.75114 (* 1 = 1.75114 loss)
I1026 20:11:34.716310 37958 sgd_solver.cpp:105] Iteration 19160, lr = 0.00887294
I1026 20:12:05.571602 37958 solver.cpp:221] Iteration 19200 (1.29642 iter/s, 30.8542s/40 iters), loss = 1.5972
I1026 20:12:05.571768 37958 solver.cpp:240]     Train net output #0: loss = 1.5972 (* 1 = 1.5972 loss)
I1026 20:12:05.571784 37958 sgd_solver.cpp:105] Iteration 19200, lr = 0.00887059
I1026 20:12:36.406776 37958 solver.cpp:221] Iteration 19240 (1.29728 iter/s, 30.8339s/40 iters), loss = 1.84147
I1026 20:12:36.406962 37958 solver.cpp:240]     Train net output #0: loss = 1.84147 (* 1 = 1.84147 loss)
I1026 20:12:36.406976 37958 sgd_solver.cpp:105] Iteration 19240, lr = 0.00886824
I1026 20:13:07.112890 37958 solver.cpp:221] Iteration 19280 (1.30273 iter/s, 30.7048s/40 iters), loss = 1.68479
I1026 20:13:07.113065 37958 solver.cpp:240]     Train net output #0: loss = 1.68479 (* 1 = 1.68479 loss)
I1026 20:13:07.113080 37958 sgd_solver.cpp:105] Iteration 19280, lr = 0.00886588
I1026 20:13:38.008129 37958 solver.cpp:221] Iteration 19320 (1.29475 iter/s, 30.8939s/40 iters), loss = 2.24943
I1026 20:13:38.008313 37958 solver.cpp:240]     Train net output #0: loss = 2.24943 (* 1 = 2.24943 loss)
I1026 20:13:38.008329 37958 sgd_solver.cpp:105] Iteration 19320, lr = 0.00886353
I1026 20:14:08.827605 37958 solver.cpp:221] Iteration 19360 (1.29794 iter/s, 30.8181s/40 iters), loss = 1.94536
I1026 20:14:08.827780 37958 solver.cpp:240]     Train net output #0: loss = 1.94536 (* 1 = 1.94536 loss)
I1026 20:14:08.827795 37958 sgd_solver.cpp:105] Iteration 19360, lr = 0.00886118
I1026 20:14:39.571308 37958 solver.cpp:221] Iteration 19400 (1.30114 iter/s, 30.7424s/40 iters), loss = 1.90775
I1026 20:14:39.571504 37958 solver.cpp:240]     Train net output #0: loss = 1.90775 (* 1 = 1.90775 loss)
I1026 20:14:39.571519 37958 sgd_solver.cpp:105] Iteration 19400, lr = 0.00885882
I1026 20:15:11.258630 37958 solver.cpp:221] Iteration 19440 (1.26239 iter/s, 31.6859s/40 iters), loss = 2.0514
I1026 20:15:11.258819 37958 solver.cpp:240]     Train net output #0: loss = 2.0514 (* 1 = 2.0514 loss)
I1026 20:15:11.258834 37958 sgd_solver.cpp:105] Iteration 19440, lr = 0.00885647
I1026 20:15:42.366319 37958 solver.cpp:221] Iteration 19480 (1.28591 iter/s, 31.1063s/40 iters), loss = 1.54489
I1026 20:15:42.366503 37958 solver.cpp:240]     Train net output #0: loss = 1.54489 (* 1 = 1.54489 loss)
I1026 20:15:42.366518 37958 sgd_solver.cpp:105] Iteration 19480, lr = 0.00885412
I1026 20:15:59.310717 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_19500.caffemodel
I1026 20:15:59.353844 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_19500.solverstate
I1026 20:15:59.582787 37958 solver.cpp:333] Iteration 19500, Testing net (#0)
I1026 20:16:33.718065 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 20:16:33.849606 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52936
I1026 20:16:33.849664 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77104
I1026 20:16:33.849675 37958 solver.cpp:400]     Test net output #2: loss = 2.09583 (* 1 = 2.09583 loss)
I1026 20:16:49.829258 37958 solver.cpp:221] Iteration 19520 (0.592942 iter/s, 67.4602s/40 iters), loss = 1.97396
I1026 20:16:49.829318 37958 solver.cpp:240]     Train net output #0: loss = 1.97396 (* 1 = 1.97396 loss)
I1026 20:16:49.829332 37958 sgd_solver.cpp:105] Iteration 19520, lr = 0.00885176
I1026 20:17:20.113677 37958 solver.cpp:221] Iteration 19560 (1.32086 iter/s, 30.2832s/40 iters), loss = 1.598
I1026 20:17:20.113875 37958 solver.cpp:240]     Train net output #0: loss = 1.598 (* 1 = 1.598 loss)
I1026 20:17:20.113890 37958 sgd_solver.cpp:105] Iteration 19560, lr = 0.00884941
I1026 20:17:50.484800 37958 solver.cpp:221] Iteration 19600 (1.3171 iter/s, 30.3698s/40 iters), loss = 1.80123
I1026 20:17:50.484964 37958 solver.cpp:240]     Train net output #0: loss = 1.80123 (* 1 = 1.80123 loss)
I1026 20:17:50.484978 37958 sgd_solver.cpp:105] Iteration 19600, lr = 0.00884706
I1026 20:18:20.704977 37958 solver.cpp:221] Iteration 19640 (1.32368 iter/s, 30.2189s/40 iters), loss = 2.18901
I1026 20:18:20.705137 37958 solver.cpp:240]     Train net output #0: loss = 2.18901 (* 1 = 2.18901 loss)
I1026 20:18:20.705152 37958 sgd_solver.cpp:105] Iteration 19640, lr = 0.00884471
I1026 20:18:51.341557 37958 solver.cpp:221] Iteration 19680 (1.30569 iter/s, 30.6353s/40 iters), loss = 1.88939
I1026 20:18:51.341732 37958 solver.cpp:240]     Train net output #0: loss = 1.88939 (* 1 = 1.88939 loss)
I1026 20:18:51.341747 37958 sgd_solver.cpp:105] Iteration 19680, lr = 0.00884235
I1026 20:19:22.736871 37958 solver.cpp:221] Iteration 19720 (1.27413 iter/s, 31.3939s/40 iters), loss = 2.0618
I1026 20:19:22.737071 37958 solver.cpp:240]     Train net output #0: loss = 2.0618 (* 1 = 2.0618 loss)
I1026 20:19:22.737087 37958 sgd_solver.cpp:105] Iteration 19720, lr = 0.00884
I1026 20:19:53.974081 37958 solver.cpp:221] Iteration 19760 (1.28058 iter/s, 31.2358s/40 iters), loss = 1.62454
I1026 20:19:53.974278 37958 solver.cpp:240]     Train net output #0: loss = 1.62454 (* 1 = 1.62454 loss)
I1026 20:19:53.974293 37958 sgd_solver.cpp:105] Iteration 19760, lr = 0.00883765
I1026 20:20:25.002499 37958 solver.cpp:221] Iteration 19800 (1.2892 iter/s, 31.027s/40 iters), loss = 1.98188
I1026 20:20:25.002681 37958 solver.cpp:240]     Train net output #0: loss = 1.98188 (* 1 = 1.98188 loss)
I1026 20:20:25.002694 37958 sgd_solver.cpp:105] Iteration 19800, lr = 0.00883529
I1026 20:20:56.086805 37958 solver.cpp:221] Iteration 19840 (1.28688 iter/s, 31.0829s/40 iters), loss = 1.8811
I1026 20:20:56.086977 37958 solver.cpp:240]     Train net output #0: loss = 1.8811 (* 1 = 1.8811 loss)
I1026 20:20:56.086992 37958 sgd_solver.cpp:105] Iteration 19840, lr = 0.00883294
I1026 20:21:27.218291 37958 solver.cpp:221] Iteration 19880 (1.28493 iter/s, 31.1301s/40 iters), loss = 1.94185
I1026 20:21:27.218499 37958 solver.cpp:240]     Train net output #0: loss = 1.94185 (* 1 = 1.94185 loss)
I1026 20:21:27.218513 37958 sgd_solver.cpp:105] Iteration 19880, lr = 0.00883059
I1026 20:21:58.292831 37958 solver.cpp:221] Iteration 19920 (1.28728 iter/s, 31.0732s/40 iters), loss = 1.76923
I1026 20:21:58.293048 37958 solver.cpp:240]     Train net output #0: loss = 1.76923 (* 1 = 1.76923 loss)
I1026 20:21:58.293062 37958 sgd_solver.cpp:105] Iteration 19920, lr = 0.00882823
I1026 20:22:29.121309 37958 solver.cpp:221] Iteration 19960 (1.29756 iter/s, 30.8271s/40 iters), loss = 2.11969
I1026 20:22:29.121502 37958 solver.cpp:240]     Train net output #0: loss = 2.11969 (* 1 = 2.11969 loss)
I1026 20:22:29.121516 37958 sgd_solver.cpp:105] Iteration 19960, lr = 0.00882588
I1026 20:22:59.410852 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_20000.caffemodel
I1026 20:22:59.448058 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_20000.solverstate
I1026 20:22:59.472486 37958 solver.cpp:333] Iteration 20000, Testing net (#0)
I1026 20:23:30.393869 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.5192
I1026 20:23:30.394037 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76328
I1026 20:23:30.394050 37958 solver.cpp:400]     Test net output #2: loss = 2.13208 (* 1 = 2.13208 loss)
I1026 20:23:31.157603 37958 solver.cpp:221] Iteration 20000 (0.64481 iter/s, 62.0338s/40 iters), loss = 2.50048
I1026 20:23:31.157658 37958 solver.cpp:240]     Train net output #0: loss = 2.50048 (* 1 = 2.50048 loss)
I1026 20:23:31.157672 37958 sgd_solver.cpp:105] Iteration 20000, lr = 0.00882353
I1026 20:23:41.966421 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1026 20:24:02.182404 37958 solver.cpp:221] Iteration 20040 (1.28934 iter/s, 31.0236s/40 iters), loss = 1.78174
I1026 20:24:02.182608 37958 solver.cpp:240]     Train net output #0: loss = 1.78174 (* 1 = 1.78174 loss)
I1026 20:24:02.182623 37958 sgd_solver.cpp:105] Iteration 20040, lr = 0.00882118
I1026 20:24:33.277397 37958 solver.cpp:221] Iteration 20080 (1.28644 iter/s, 31.0936s/40 iters), loss = 1.91374
I1026 20:24:33.277575 37958 solver.cpp:240]     Train net output #0: loss = 1.91374 (* 1 = 1.91374 loss)
I1026 20:24:33.277590 37958 sgd_solver.cpp:105] Iteration 20080, lr = 0.00881882
I1026 20:25:03.798030 37958 solver.cpp:221] Iteration 20120 (1.31065 iter/s, 30.5193s/40 iters), loss = 1.92049
I1026 20:25:03.798229 37958 solver.cpp:240]     Train net output #0: loss = 1.92049 (* 1 = 1.92049 loss)
I1026 20:25:03.798243 37958 sgd_solver.cpp:105] Iteration 20120, lr = 0.00881647
I1026 20:25:34.616533 37958 solver.cpp:221] Iteration 20160 (1.29798 iter/s, 30.8171s/40 iters), loss = 1.71796
I1026 20:25:34.616746 37958 solver.cpp:240]     Train net output #0: loss = 1.71796 (* 1 = 1.71796 loss)
I1026 20:25:34.616766 37958 sgd_solver.cpp:105] Iteration 20160, lr = 0.00881412
I1026 20:26:05.360203 37958 solver.cpp:221] Iteration 20200 (1.30114 iter/s, 30.7423s/40 iters), loss = 1.78081
I1026 20:26:05.360404 37958 solver.cpp:240]     Train net output #0: loss = 1.78081 (* 1 = 1.78081 loss)
I1026 20:26:05.360419 37958 sgd_solver.cpp:105] Iteration 20200, lr = 0.00881176
I1026 20:26:36.248920 37958 solver.cpp:221] Iteration 20240 (1.29503 iter/s, 30.8873s/40 iters), loss = 1.76052
I1026 20:26:36.249126 37958 solver.cpp:240]     Train net output #0: loss = 1.76052 (* 1 = 1.76052 loss)
I1026 20:26:36.249143 37958 sgd_solver.cpp:105] Iteration 20240, lr = 0.00880941
I1026 20:27:06.958469 37958 solver.cpp:221] Iteration 20280 (1.30258 iter/s, 30.7082s/40 iters), loss = 1.84369
I1026 20:27:06.958680 37958 solver.cpp:240]     Train net output #0: loss = 1.84369 (* 1 = 1.84369 loss)
I1026 20:27:06.958695 37958 sgd_solver.cpp:105] Iteration 20280, lr = 0.00880706
I1026 20:27:37.575932 37958 solver.cpp:221] Iteration 20320 (1.3065 iter/s, 30.6161s/40 iters), loss = 1.76411
I1026 20:27:37.576118 37958 solver.cpp:240]     Train net output #0: loss = 1.76411 (* 1 = 1.76411 loss)
I1026 20:27:37.576133 37958 sgd_solver.cpp:105] Iteration 20320, lr = 0.00880471
I1026 20:28:08.023743 37958 solver.cpp:221] Iteration 20360 (1.31378 iter/s, 30.4465s/40 iters), loss = 1.65436
I1026 20:28:08.023895 37958 solver.cpp:240]     Train net output #0: loss = 1.65436 (* 1 = 1.65436 loss)
I1026 20:28:08.023910 37958 sgd_solver.cpp:105] Iteration 20360, lr = 0.00880235
I1026 20:28:38.521898 37958 solver.cpp:221] Iteration 20400 (1.31161 iter/s, 30.4968s/40 iters), loss = 1.90147
I1026 20:28:38.522068 37958 solver.cpp:240]     Train net output #0: loss = 1.90147 (* 1 = 1.90147 loss)
I1026 20:28:38.522083 37958 sgd_solver.cpp:105] Iteration 20400, lr = 0.0088
I1026 20:29:09.698020 37958 solver.cpp:221] Iteration 20440 (1.28309 iter/s, 31.1748s/40 iters), loss = 1.54758
I1026 20:29:09.698212 37958 solver.cpp:240]     Train net output #0: loss = 1.54758 (* 1 = 1.54758 loss)
I1026 20:29:09.698227 37958 sgd_solver.cpp:105] Iteration 20440, lr = 0.00879765
I1026 20:29:40.732103 37958 solver.cpp:221] Iteration 20480 (1.28896 iter/s, 31.0327s/40 iters), loss = 1.87452
I1026 20:29:40.732339 37958 solver.cpp:240]     Train net output #0: loss = 1.87452 (* 1 = 1.87452 loss)
I1026 20:29:40.732355 37958 sgd_solver.cpp:105] Iteration 20480, lr = 0.00879529
I1026 20:29:55.244190 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_20500.caffemodel
I1026 20:29:55.279675 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_20500.solverstate
I1026 20:29:55.299434 37958 solver.cpp:333] Iteration 20500, Testing net (#0)
I1026 20:30:25.914068 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 20:30:26.120769 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52468
I1026 20:30:26.120822 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77072
I1026 20:30:26.120833 37958 solver.cpp:400]     Test net output #2: loss = 2.14578 (* 1 = 2.14578 loss)
I1026 20:30:42.572805 37958 solver.cpp:221] Iteration 20520 (0.64685 iter/s, 61.8381s/40 iters), loss = 1.92603
I1026 20:30:42.572907 37958 solver.cpp:240]     Train net output #0: loss = 1.92603 (* 1 = 1.92603 loss)
I1026 20:30:42.572930 37958 sgd_solver.cpp:105] Iteration 20520, lr = 0.00879294
I1026 20:31:15.062270 37958 solver.cpp:221] Iteration 20560 (1.23122 iter/s, 32.4881s/40 iters), loss = 1.66804
I1026 20:31:15.062480 37958 solver.cpp:240]     Train net output #0: loss = 1.66804 (* 1 = 1.66804 loss)
I1026 20:31:15.062495 37958 sgd_solver.cpp:105] Iteration 20560, lr = 0.00879059
I1026 20:31:45.923498 37958 solver.cpp:221] Iteration 20600 (1.29618 iter/s, 30.8599s/40 iters), loss = 1.68126
I1026 20:31:45.923687 37958 solver.cpp:240]     Train net output #0: loss = 1.68126 (* 1 = 1.68126 loss)
I1026 20:31:45.923702 37958 sgd_solver.cpp:105] Iteration 20600, lr = 0.00878823
I1026 20:32:16.961261 37958 solver.cpp:221] Iteration 20640 (1.28881 iter/s, 31.0364s/40 iters), loss = 1.79463
I1026 20:32:16.961513 37958 solver.cpp:240]     Train net output #0: loss = 1.79463 (* 1 = 1.79463 loss)
I1026 20:32:16.961529 37958 sgd_solver.cpp:105] Iteration 20640, lr = 0.00878588
I1026 20:32:47.532101 37958 solver.cpp:221] Iteration 20680 (1.3085 iter/s, 30.5694s/40 iters), loss = 2.22745
I1026 20:32:47.532258 37958 solver.cpp:240]     Train net output #0: loss = 2.22745 (* 1 = 2.22745 loss)
I1026 20:32:47.532272 37958 sgd_solver.cpp:105] Iteration 20680, lr = 0.00878353
I1026 20:33:18.002897 37958 solver.cpp:221] Iteration 20720 (1.31279 iter/s, 30.4695s/40 iters), loss = 1.29744
I1026 20:33:18.003047 37958 solver.cpp:240]     Train net output #0: loss = 1.29744 (* 1 = 1.29744 loss)
I1026 20:33:18.003062 37958 sgd_solver.cpp:105] Iteration 20720, lr = 0.00878118
I1026 20:33:48.354581 37958 solver.cpp:221] Iteration 20760 (1.31794 iter/s, 30.3504s/40 iters), loss = 1.80997
I1026 20:33:48.354724 37958 solver.cpp:240]     Train net output #0: loss = 1.80997 (* 1 = 1.80997 loss)
I1026 20:33:48.354738 37958 sgd_solver.cpp:105] Iteration 20760, lr = 0.00877882
I1026 20:34:18.644990 37958 solver.cpp:221] Iteration 20800 (1.32061 iter/s, 30.2891s/40 iters), loss = 1.75462
I1026 20:34:18.645144 37958 solver.cpp:240]     Train net output #0: loss = 1.75462 (* 1 = 1.75462 loss)
I1026 20:34:18.645159 37958 sgd_solver.cpp:105] Iteration 20800, lr = 0.00877647
I1026 20:34:48.886860 37958 solver.cpp:221] Iteration 20840 (1.32273 iter/s, 30.2406s/40 iters), loss = 1.7955
I1026 20:34:48.886989 37958 solver.cpp:240]     Train net output #0: loss = 1.7955 (* 1 = 1.7955 loss)
I1026 20:34:48.887003 37958 sgd_solver.cpp:105] Iteration 20840, lr = 0.00877412
I1026 20:35:19.142369 37958 solver.cpp:221] Iteration 20880 (1.32213 iter/s, 30.2542s/40 iters), loss = 1.91369
I1026 20:35:19.142496 37958 solver.cpp:240]     Train net output #0: loss = 1.91369 (* 1 = 1.91369 loss)
I1026 20:35:19.142511 37958 sgd_solver.cpp:105] Iteration 20880, lr = 0.00877176
I1026 20:35:49.235479 37958 solver.cpp:221] Iteration 20920 (1.32926 iter/s, 30.0918s/40 iters), loss = 1.62429
I1026 20:35:49.235683 37958 solver.cpp:240]     Train net output #0: loss = 1.62429 (* 1 = 1.62429 loss)
I1026 20:35:49.235698 37958 sgd_solver.cpp:105] Iteration 20920, lr = 0.00876941
I1026 20:36:19.658695 37958 solver.cpp:221] Iteration 20960 (1.31484 iter/s, 30.4219s/40 iters), loss = 1.77843
I1026 20:36:19.658859 37958 solver.cpp:240]     Train net output #0: loss = 1.77843 (* 1 = 1.77843 loss)
I1026 20:36:19.658872 37958 sgd_solver.cpp:105] Iteration 20960, lr = 0.00876706
I1026 20:36:49.327941 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_21000.caffemodel
I1026 20:36:49.371740 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_21000.solverstate
I1026 20:36:49.396340 37958 solver.cpp:333] Iteration 21000, Testing net (#0)
I1026 20:37:20.317543 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52376
I1026 20:37:20.317735 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.769759
I1026 20:37:20.317749 37958 solver.cpp:400]     Test net output #2: loss = 2.12047 (* 1 = 2.12047 loss)
I1026 20:37:21.078945 37958 solver.cpp:221] Iteration 21000 (0.651277 iter/s, 61.4178s/40 iters), loss = 2.04599
I1026 20:37:21.079007 37958 solver.cpp:240]     Train net output #0: loss = 2.04599 (* 1 = 2.04599 loss)
I1026 20:37:21.079021 37958 sgd_solver.cpp:105] Iteration 21000, lr = 0.00876471
I1026 20:37:51.674968 37958 solver.cpp:221] Iteration 21040 (1.30741 iter/s, 30.5948s/40 iters), loss = 1.79253
I1026 20:37:51.675139 37958 solver.cpp:240]     Train net output #0: loss = 1.79253 (* 1 = 1.79253 loss)
I1026 20:37:51.675153 37958 sgd_solver.cpp:105] Iteration 21040, lr = 0.00876235
I1026 20:38:22.425603 37958 solver.cpp:221] Iteration 21080 (1.30084 iter/s, 30.7493s/40 iters), loss = 1.90079
I1026 20:38:22.425783 37958 solver.cpp:240]     Train net output #0: loss = 1.90079 (* 1 = 1.90079 loss)
I1026 20:38:22.425798 37958 sgd_solver.cpp:105] Iteration 21080, lr = 0.00876
I1026 20:38:53.154719 37958 solver.cpp:221] Iteration 21120 (1.30175 iter/s, 30.7278s/40 iters), loss = 1.75296
I1026 20:38:53.154938 37958 solver.cpp:240]     Train net output #0: loss = 1.75296 (* 1 = 1.75296 loss)
I1026 20:38:53.154953 37958 sgd_solver.cpp:105] Iteration 21120, lr = 0.00875765
I1026 20:39:23.775713 37958 solver.cpp:221] Iteration 21160 (1.30635 iter/s, 30.6196s/40 iters), loss = 1.80019
I1026 20:39:23.775904 37958 solver.cpp:240]     Train net output #0: loss = 1.80019 (* 1 = 1.80019 loss)
I1026 20:39:23.775918 37958 sgd_solver.cpp:105] Iteration 21160, lr = 0.00875529
I1026 20:39:54.386315 37958 solver.cpp:221] Iteration 21200 (1.30679 iter/s, 30.6092s/40 iters), loss = 1.90115
I1026 20:39:54.386520 37958 solver.cpp:240]     Train net output #0: loss = 1.90115 (* 1 = 1.90115 loss)
I1026 20:39:54.386535 37958 sgd_solver.cpp:105] Iteration 21200, lr = 0.00875294
I1026 20:40:25.494808 37958 solver.cpp:221] Iteration 21240 (1.28588 iter/s, 31.1071s/40 iters), loss = 1.70761
I1026 20:40:25.495010 37958 solver.cpp:240]     Train net output #0: loss = 1.70761 (* 1 = 1.70761 loss)
I1026 20:40:25.495025 37958 sgd_solver.cpp:105] Iteration 21240, lr = 0.00875059
I1026 20:40:56.354915 37958 solver.cpp:221] Iteration 21280 (1.29623 iter/s, 30.8587s/40 iters), loss = 2.07939
I1026 20:40:56.355161 37958 solver.cpp:240]     Train net output #0: loss = 2.07939 (* 1 = 2.07939 loss)
I1026 20:40:56.355182 37958 sgd_solver.cpp:105] Iteration 21280, lr = 0.00874824
I1026 20:41:38.155925 37958 solver.cpp:221] Iteration 21320 (0.956957 iter/s, 41.7992s/40 iters), loss = 1.98829
I1026 20:41:38.156114 37958 solver.cpp:240]     Train net output #0: loss = 1.98829 (* 1 = 1.98829 loss)
I1026 20:41:38.156131 37958 sgd_solver.cpp:105] Iteration 21320, lr = 0.00874588
I1026 20:42:09.434041 37958 solver.cpp:221] Iteration 21360 (1.27891 iter/s, 31.2768s/40 iters), loss = 2.09427
I1026 20:42:09.434254 37958 solver.cpp:240]     Train net output #0: loss = 2.09427 (* 1 = 2.09427 loss)
I1026 20:42:09.434280 37958 sgd_solver.cpp:105] Iteration 21360, lr = 0.00874353
I1026 20:42:40.073551 37958 solver.cpp:221] Iteration 21400 (1.30556 iter/s, 30.6381s/40 iters), loss = 1.77667
I1026 20:42:40.073757 37958 solver.cpp:240]     Train net output #0: loss = 1.77667 (* 1 = 1.77667 loss)
I1026 20:42:40.073772 37958 sgd_solver.cpp:105] Iteration 21400, lr = 0.00874118
I1026 20:43:11.103379 37958 solver.cpp:221] Iteration 21440 (1.28914 iter/s, 31.0285s/40 iters), loss = 2.22741
I1026 20:43:11.103591 37958 solver.cpp:240]     Train net output #0: loss = 2.22741 (* 1 = 2.22741 loss)
I1026 20:43:11.103605 37958 sgd_solver.cpp:105] Iteration 21440, lr = 0.00873882
I1026 20:43:42.074309 37958 solver.cpp:221] Iteration 21480 (1.29159 iter/s, 30.9696s/40 iters), loss = 1.96802
I1026 20:43:42.074488 37958 solver.cpp:240]     Train net output #0: loss = 1.96802 (* 1 = 1.96802 loss)
I1026 20:43:42.074506 37958 sgd_solver.cpp:105] Iteration 21480, lr = 0.00873647
I1026 20:43:56.806551 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_21500.caffemodel
I1026 20:43:56.839359 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_21500.solverstate
I1026 20:43:56.857184 37958 solver.cpp:333] Iteration 21500, Testing net (#0)
I1026 20:44:27.540676 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 20:44:27.747311 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.51956
I1026 20:44:27.747365 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.765
I1026 20:44:27.747376 37958 solver.cpp:400]     Test net output #2: loss = 2.12672 (* 1 = 2.12672 loss)
I1026 20:44:43.918898 37958 solver.cpp:221] Iteration 21520 (0.646809 iter/s, 61.8421s/40 iters), loss = 1.72635
I1026 20:44:43.918962 37958 solver.cpp:240]     Train net output #0: loss = 1.72635 (* 1 = 1.72635 loss)
I1026 20:44:43.918975 37958 sgd_solver.cpp:105] Iteration 21520, lr = 0.00873412
I1026 20:45:15.418893 37958 solver.cpp:221] Iteration 21560 (1.26989 iter/s, 31.4987s/40 iters), loss = 1.93042
I1026 20:45:15.419104 37958 solver.cpp:240]     Train net output #0: loss = 1.93042 (* 1 = 1.93042 loss)
I1026 20:45:15.419119 37958 sgd_solver.cpp:105] Iteration 21560, lr = 0.00873176
I1026 20:45:46.868852 37958 solver.cpp:221] Iteration 21600 (1.27192 iter/s, 31.4486s/40 iters), loss = 2.06441
I1026 20:45:46.869068 37958 solver.cpp:240]     Train net output #0: loss = 2.06441 (* 1 = 2.06441 loss)
I1026 20:45:46.869083 37958 sgd_solver.cpp:105] Iteration 21600, lr = 0.00872941
I1026 20:46:17.405766 37958 solver.cpp:221] Iteration 21640 (1.30995 iter/s, 30.5355s/40 iters), loss = 1.84746
I1026 20:46:17.405925 37958 solver.cpp:240]     Train net output #0: loss = 1.84746 (* 1 = 1.84746 loss)
I1026 20:46:17.405941 37958 sgd_solver.cpp:105] Iteration 21640, lr = 0.00872706
I1026 20:46:47.798410 37958 solver.cpp:221] Iteration 21680 (1.31616 iter/s, 30.3913s/40 iters), loss = 1.83165
I1026 20:46:47.798578 37958 solver.cpp:240]     Train net output #0: loss = 1.83165 (* 1 = 1.83165 loss)
I1026 20:46:47.798593 37958 sgd_solver.cpp:105] Iteration 21680, lr = 0.00872471
I1026 20:47:18.374955 37958 solver.cpp:221] Iteration 21720 (1.30825 iter/s, 30.5752s/40 iters), loss = 1.82826
I1026 20:47:18.375099 37958 solver.cpp:240]     Train net output #0: loss = 1.82826 (* 1 = 1.82826 loss)
I1026 20:47:18.375114 37958 sgd_solver.cpp:105] Iteration 21720, lr = 0.00872235
I1026 20:47:49.228606 37958 solver.cpp:221] Iteration 21760 (1.2965 iter/s, 30.8523s/40 iters), loss = 1.73065
I1026 20:47:49.228787 37958 solver.cpp:240]     Train net output #0: loss = 1.73065 (* 1 = 1.73065 loss)
I1026 20:47:49.228801 37958 sgd_solver.cpp:105] Iteration 21760, lr = 0.00872
I1026 20:48:19.538647 37958 solver.cpp:221] Iteration 21800 (1.31975 iter/s, 30.3087s/40 iters), loss = 1.88854
I1026 20:48:19.538787 37958 solver.cpp:240]     Train net output #0: loss = 1.88854 (* 1 = 1.88854 loss)
I1026 20:48:19.538802 37958 sgd_solver.cpp:105] Iteration 21800, lr = 0.00871765
I1026 20:48:50.441242 37958 solver.cpp:221] Iteration 21840 (1.29444 iter/s, 30.9013s/40 iters), loss = 1.8539
I1026 20:48:50.441532 37958 solver.cpp:240]     Train net output #0: loss = 1.8539 (* 1 = 1.8539 loss)
I1026 20:48:50.441563 37958 sgd_solver.cpp:105] Iteration 21840, lr = 0.00871529
I1026 20:49:21.265025 37958 solver.cpp:221] Iteration 21880 (1.29776 iter/s, 30.8223s/40 iters), loss = 2.00171
I1026 20:49:21.265235 37958 solver.cpp:240]     Train net output #0: loss = 2.00171 (* 1 = 2.00171 loss)
I1026 20:49:21.265249 37958 sgd_solver.cpp:105] Iteration 21880, lr = 0.00871294
I1026 20:49:52.197000 37958 solver.cpp:221] Iteration 21920 (1.29322 iter/s, 30.9306s/40 iters), loss = 1.67421
I1026 20:49:52.197202 37958 solver.cpp:240]     Train net output #0: loss = 1.67421 (* 1 = 1.67421 loss)
I1026 20:49:52.197217 37958 sgd_solver.cpp:105] Iteration 21920, lr = 0.00871059
I1026 20:50:23.312275 37958 solver.cpp:221] Iteration 21960 (1.2856 iter/s, 31.1139s/40 iters), loss = 1.5201
I1026 20:50:23.312494 37958 solver.cpp:240]     Train net output #0: loss = 1.5201 (* 1 = 1.5201 loss)
I1026 20:50:23.312510 37958 sgd_solver.cpp:105] Iteration 21960, lr = 0.00870823
I1026 20:50:53.140242 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_22000.caffemodel
I1026 20:50:53.176342 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_22000.solverstate
I1026 20:50:53.197181 37958 solver.cpp:333] Iteration 22000, Testing net (#0)
I1026 20:51:24.170419 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52244
I1026 20:51:24.170630 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76716
I1026 20:51:24.170644 37958 solver.cpp:400]     Test net output #2: loss = 2.12292 (* 1 = 2.12292 loss)
I1026 20:51:24.931478 37958 solver.cpp:221] Iteration 22000 (0.649175 iter/s, 61.6167s/40 iters), loss = 1.51339
I1026 20:51:24.931538 37958 solver.cpp:240]     Train net output #0: loss = 1.51339 (* 1 = 1.51339 loss)
I1026 20:51:24.931552 37958 sgd_solver.cpp:105] Iteration 22000, lr = 0.00870588
I1026 20:52:46.744957 37958 solver.cpp:221] Iteration 22040 (0.488936 iter/s, 81.8103s/40 iters), loss = 2.04888
I1026 20:52:46.745198 37958 solver.cpp:240]     Train net output #0: loss = 2.04888 (* 1 = 2.04888 loss)
I1026 20:52:46.745213 37958 sgd_solver.cpp:105] Iteration 22040, lr = 0.00870353
I1026 20:53:17.123497 37958 solver.cpp:221] Iteration 22080 (1.31678 iter/s, 30.3772s/40 iters), loss = 2.14011
I1026 20:53:17.123648 37958 solver.cpp:240]     Train net output #0: loss = 2.14011 (* 1 = 2.14011 loss)
I1026 20:53:17.123662 37958 sgd_solver.cpp:105] Iteration 22080, lr = 0.00870118
I1026 20:53:47.319087 37958 solver.cpp:221] Iteration 22120 (1.32475 iter/s, 30.1943s/40 iters), loss = 1.39413
I1026 20:53:47.319231 37958 solver.cpp:240]     Train net output #0: loss = 1.39413 (* 1 = 1.39413 loss)
I1026 20:53:47.319245 37958 sgd_solver.cpp:105] Iteration 22120, lr = 0.00869882
I1026 20:54:17.534211 37958 solver.cpp:221] Iteration 22160 (1.3239 iter/s, 30.2138s/40 iters), loss = 1.93095
I1026 20:54:17.534366 37958 solver.cpp:240]     Train net output #0: loss = 1.93095 (* 1 = 1.93095 loss)
I1026 20:54:17.534381 37958 sgd_solver.cpp:105] Iteration 22160, lr = 0.00869647
I1026 20:54:48.076289 37958 solver.cpp:221] Iteration 22200 (1.30972 iter/s, 30.5408s/40 iters), loss = 1.91186
I1026 20:54:48.076460 37958 solver.cpp:240]     Train net output #0: loss = 1.91186 (* 1 = 1.91186 loss)
I1026 20:54:48.076477 37958 sgd_solver.cpp:105] Iteration 22200, lr = 0.00869412
I1026 20:55:21.321554 37958 solver.cpp:221] Iteration 22240 (1.20323 iter/s, 33.2438s/40 iters), loss = 1.9053
I1026 20:55:21.321815 37958 solver.cpp:240]     Train net output #0: loss = 1.9053 (* 1 = 1.9053 loss)
I1026 20:55:21.321838 37958 sgd_solver.cpp:105] Iteration 22240, lr = 0.00869176
I1026 20:55:52.075650 37958 solver.cpp:221] Iteration 22280 (1.3007 iter/s, 30.7527s/40 iters), loss = 1.95045
I1026 20:55:52.075871 37958 solver.cpp:240]     Train net output #0: loss = 1.95045 (* 1 = 1.95045 loss)
I1026 20:55:52.075896 37958 sgd_solver.cpp:105] Iteration 22280, lr = 0.00868941
I1026 20:56:22.461971 37958 solver.cpp:221] Iteration 22320 (1.31644 iter/s, 30.385s/40 iters), loss = 1.99505
I1026 20:56:22.462144 37958 solver.cpp:240]     Train net output #0: loss = 1.99505 (* 1 = 1.99505 loss)
I1026 20:56:22.462158 37958 sgd_solver.cpp:105] Iteration 22320, lr = 0.00868706
I1026 20:56:53.161723 37958 solver.cpp:221] Iteration 22360 (1.303 iter/s, 30.6984s/40 iters), loss = 1.88138
I1026 20:56:53.161908 37958 solver.cpp:240]     Train net output #0: loss = 1.88138 (* 1 = 1.88138 loss)
I1026 20:56:53.161923 37958 sgd_solver.cpp:105] Iteration 22360, lr = 0.00868471
I1026 20:57:23.711458 37958 solver.cpp:221] Iteration 22400 (1.3094 iter/s, 30.5484s/40 iters), loss = 2.3184
I1026 20:57:23.711658 37958 solver.cpp:240]     Train net output #0: loss = 2.3184 (* 1 = 2.3184 loss)
I1026 20:57:23.711673 37958 sgd_solver.cpp:105] Iteration 22400, lr = 0.00868235
I1026 20:57:54.328198 37958 solver.cpp:221] Iteration 22440 (1.30653 iter/s, 30.6154s/40 iters), loss = 1.87783
I1026 20:57:54.328436 37958 solver.cpp:240]     Train net output #0: loss = 1.87783 (* 1 = 1.87783 loss)
I1026 20:57:54.328451 37958 sgd_solver.cpp:105] Iteration 22440, lr = 0.00868
I1026 20:58:24.823473 37958 solver.cpp:221] Iteration 22480 (1.31174 iter/s, 30.4939s/40 iters), loss = 1.97588
I1026 20:58:24.823635 37958 solver.cpp:240]     Train net output #0: loss = 1.97588 (* 1 = 1.97588 loss)
I1026 20:58:24.823650 37958 sgd_solver.cpp:105] Iteration 22480, lr = 0.00867765
I1026 20:58:39.269572 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_22500.caffemodel
I1026 20:58:39.302284 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_22500.solverstate
I1026 20:58:39.320412 37958 solver.cpp:333] Iteration 22500, Testing net (#0)
I1026 20:59:09.948591 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 20:59:10.154608 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52356
I1026 20:59:10.154665 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77044
I1026 20:59:10.154677 37958 solver.cpp:400]     Test net output #2: loss = 2.12745 (* 1 = 2.12745 loss)
I1026 20:59:23.224577 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1026 20:59:26.217254 37958 solver.cpp:221] Iteration 22520 (0.651558 iter/s, 61.3913s/40 iters), loss = 1.82607
I1026 20:59:26.217316 37958 solver.cpp:240]     Train net output #0: loss = 1.82607 (* 1 = 1.82607 loss)
I1026 20:59:26.217331 37958 sgd_solver.cpp:105] Iteration 22520, lr = 0.00867529
I1026 20:59:56.986330 37958 solver.cpp:221] Iteration 22560 (1.30006 iter/s, 30.7678s/40 iters), loss = 1.67543
I1026 20:59:56.986486 37958 solver.cpp:240]     Train net output #0: loss = 1.67543 (* 1 = 1.67543 loss)
I1026 20:59:56.986501 37958 sgd_solver.cpp:105] Iteration 22560, lr = 0.00867294
I1026 21:00:27.796468 37958 solver.cpp:221] Iteration 22600 (1.29833 iter/s, 30.8088s/40 iters), loss = 2.03049
I1026 21:00:27.796648 37958 solver.cpp:240]     Train net output #0: loss = 2.03049 (* 1 = 2.03049 loss)
I1026 21:00:27.796663 37958 sgd_solver.cpp:105] Iteration 22600, lr = 0.00867059
I1026 21:00:58.871421 37958 solver.cpp:221] Iteration 22640 (1.28727 iter/s, 31.0736s/40 iters), loss = 1.66105
I1026 21:00:58.871590 37958 solver.cpp:240]     Train net output #0: loss = 1.66105 (* 1 = 1.66105 loss)
I1026 21:00:58.871605 37958 sgd_solver.cpp:105] Iteration 22640, lr = 0.00866824
I1026 21:01:29.486847 37958 solver.cpp:221] Iteration 22680 (1.30659 iter/s, 30.6141s/40 iters), loss = 1.6912
I1026 21:01:29.487062 37958 solver.cpp:240]     Train net output #0: loss = 1.6912 (* 1 = 1.6912 loss)
I1026 21:01:29.487077 37958 sgd_solver.cpp:105] Iteration 22680, lr = 0.00866588
I1026 21:02:00.047539 37958 solver.cpp:221] Iteration 22720 (1.30893 iter/s, 30.5593s/40 iters), loss = 1.45904
I1026 21:02:00.047778 37958 solver.cpp:240]     Train net output #0: loss = 1.45904 (* 1 = 1.45904 loss)
I1026 21:02:00.047827 37958 sgd_solver.cpp:105] Iteration 22720, lr = 0.00866353
I1026 21:02:31.018795 37958 solver.cpp:221] Iteration 22760 (1.29158 iter/s, 30.9699s/40 iters), loss = 1.37117
I1026 21:02:31.018990 37958 solver.cpp:240]     Train net output #0: loss = 1.37117 (* 1 = 1.37117 loss)
I1026 21:02:31.019004 37958 sgd_solver.cpp:105] Iteration 22760, lr = 0.00866118
I1026 21:03:03.186190 37958 solver.cpp:221] Iteration 22800 (1.24355 iter/s, 32.166s/40 iters), loss = 1.803
I1026 21:03:03.186383 37958 solver.cpp:240]     Train net output #0: loss = 1.803 (* 1 = 1.803 loss)
I1026 21:03:03.186396 37958 sgd_solver.cpp:105] Iteration 22800, lr = 0.00865882
I1026 21:03:34.299412 37958 solver.cpp:221] Iteration 22840 (1.28568 iter/s, 31.1119s/40 iters), loss = 1.67968
I1026 21:03:34.299603 37958 solver.cpp:240]     Train net output #0: loss = 1.67968 (* 1 = 1.67968 loss)
I1026 21:03:34.299618 37958 sgd_solver.cpp:105] Iteration 22840, lr = 0.00865647
I1026 21:04:06.380183 37958 solver.cpp:221] Iteration 22880 (1.24691 iter/s, 32.0794s/40 iters), loss = 1.81706
I1026 21:04:06.380432 37958 solver.cpp:240]     Train net output #0: loss = 1.81706 (* 1 = 1.81706 loss)
I1026 21:04:06.380446 37958 sgd_solver.cpp:105] Iteration 22880, lr = 0.00865412
I1026 21:04:37.254997 37958 solver.cpp:221] Iteration 22920 (1.29561 iter/s, 30.8734s/40 iters), loss = 1.58877
I1026 21:04:37.255215 37958 solver.cpp:240]     Train net output #0: loss = 1.58877 (* 1 = 1.58877 loss)
I1026 21:04:37.255230 37958 sgd_solver.cpp:105] Iteration 22920, lr = 0.00865176
I1026 21:05:07.735630 37958 solver.cpp:221] Iteration 22960 (1.31237 iter/s, 30.4793s/40 iters), loss = 1.74554
I1026 21:05:07.735819 37958 solver.cpp:240]     Train net output #0: loss = 1.74554 (* 1 = 1.74554 loss)
I1026 21:05:07.735834 37958 sgd_solver.cpp:105] Iteration 22960, lr = 0.00864941
I1026 21:05:37.389245 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_23000.caffemodel
I1026 21:05:37.426034 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_23000.solverstate
I1026 21:05:37.449934 37958 solver.cpp:333] Iteration 23000, Testing net (#0)
I1026 21:06:08.351918 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.5266
I1026 21:06:08.352116 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76848
I1026 21:06:08.352129 37958 solver.cpp:400]     Test net output #2: loss = 2.09823 (* 1 = 2.09823 loss)
I1026 21:06:09.114152 37958 solver.cpp:221] Iteration 23000 (0.65172 iter/s, 61.376s/40 iters), loss = 1.7666
I1026 21:06:09.114212 37958 solver.cpp:240]     Train net output #0: loss = 1.7666 (* 1 = 1.7666 loss)
I1026 21:06:09.114226 37958 sgd_solver.cpp:105] Iteration 23000, lr = 0.00864706
I1026 21:06:39.660467 37958 solver.cpp:221] Iteration 23040 (1.30954 iter/s, 30.5451s/40 iters), loss = 1.949
I1026 21:06:39.660634 37958 solver.cpp:240]     Train net output #0: loss = 1.949 (* 1 = 1.949 loss)
I1026 21:06:39.660648 37958 sgd_solver.cpp:105] Iteration 23040, lr = 0.00864471
I1026 21:07:10.117092 37958 solver.cpp:221] Iteration 23080 (1.3134 iter/s, 30.4553s/40 iters), loss = 1.89962
I1026 21:07:10.117254 37958 solver.cpp:240]     Train net output #0: loss = 1.89962 (* 1 = 1.89962 loss)
I1026 21:07:10.117269 37958 sgd_solver.cpp:105] Iteration 23080, lr = 0.00864235
I1026 21:07:40.561256 37958 solver.cpp:221] Iteration 23120 (1.31394 iter/s, 30.4429s/40 iters), loss = 1.5369
I1026 21:07:40.561421 37958 solver.cpp:240]     Train net output #0: loss = 1.5369 (* 1 = 1.5369 loss)
I1026 21:07:40.561437 37958 sgd_solver.cpp:105] Iteration 23120, lr = 0.00864
I1026 21:08:10.962534 37958 solver.cpp:221] Iteration 23160 (1.31579 iter/s, 30.4s/40 iters), loss = 1.70994
I1026 21:08:10.962680 37958 solver.cpp:240]     Train net output #0: loss = 1.70994 (* 1 = 1.70994 loss)
I1026 21:08:10.962694 37958 sgd_solver.cpp:105] Iteration 23160, lr = 0.00863765
I1026 21:08:41.373040 37958 solver.cpp:221] Iteration 23200 (1.31539 iter/s, 30.4092s/40 iters), loss = 1.56013
I1026 21:08:41.373227 37958 solver.cpp:240]     Train net output #0: loss = 1.56013 (* 1 = 1.56013 loss)
I1026 21:08:41.373244 37958 sgd_solver.cpp:105] Iteration 23200, lr = 0.00863529
I1026 21:09:12.567060 37958 solver.cpp:221] Iteration 23240 (1.28235 iter/s, 31.1927s/40 iters), loss = 1.77559
I1026 21:09:12.567250 37958 solver.cpp:240]     Train net output #0: loss = 1.77559 (* 1 = 1.77559 loss)
I1026 21:09:12.567265 37958 sgd_solver.cpp:105] Iteration 23240, lr = 0.00863294
I1026 21:09:47.582862 37958 solver.cpp:221] Iteration 23280 (1.14239 iter/s, 35.0143s/40 iters), loss = 1.78854
I1026 21:09:47.583127 37958 solver.cpp:240]     Train net output #0: loss = 1.78854 (* 1 = 1.78854 loss)
I1026 21:09:47.583148 37958 sgd_solver.cpp:105] Iteration 23280, lr = 0.00863059
I1026 21:10:30.133559 37958 solver.cpp:221] Iteration 23320 (0.940096 iter/s, 42.5488s/40 iters), loss = 1.5884
I1026 21:10:30.133760 37958 solver.cpp:240]     Train net output #0: loss = 1.5884 (* 1 = 1.5884 loss)
I1026 21:10:30.133775 37958 sgd_solver.cpp:105] Iteration 23320, lr = 0.00862824
I1026 21:11:00.911319 37958 solver.cpp:221] Iteration 23360 (1.2997 iter/s, 30.7764s/40 iters), loss = 1.83535
I1026 21:11:00.911479 37958 solver.cpp:240]     Train net output #0: loss = 1.83535 (* 1 = 1.83535 loss)
I1026 21:11:00.911494 37958 sgd_solver.cpp:105] Iteration 23360, lr = 0.00862588
I1026 21:11:31.324363 37958 solver.cpp:221] Iteration 23400 (1.31528 iter/s, 30.4117s/40 iters), loss = 1.65771
I1026 21:11:31.324565 37958 solver.cpp:240]     Train net output #0: loss = 1.65771 (* 1 = 1.65771 loss)
I1026 21:11:31.324580 37958 sgd_solver.cpp:105] Iteration 23400, lr = 0.00862353
I1026 21:12:02.041211 37958 solver.cpp:221] Iteration 23440 (1.30227 iter/s, 30.7155s/40 iters), loss = 2.51617
I1026 21:12:02.041448 37958 solver.cpp:240]     Train net output #0: loss = 2.51617 (* 1 = 2.51617 loss)
I1026 21:12:02.041463 37958 sgd_solver.cpp:105] Iteration 23440, lr = 0.00862118
I1026 21:12:32.742305 37958 solver.cpp:221] Iteration 23480 (1.30294 iter/s, 30.6997s/40 iters), loss = 1.51378
I1026 21:12:32.742499 37958 solver.cpp:240]     Train net output #0: loss = 1.51378 (* 1 = 1.51378 loss)
I1026 21:12:32.742514 37958 sgd_solver.cpp:105] Iteration 23480, lr = 0.00861882
I1026 21:12:47.325794 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_23500.caffemodel
I1026 21:12:47.357537 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_23500.solverstate
I1026 21:12:47.376116 37958 solver.cpp:333] Iteration 23500, Testing net (#0)
I1026 21:13:18.055248 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 21:13:18.260900 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52136
I1026 21:13:18.260954 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76704
I1026 21:13:18.260965 37958 solver.cpp:400]     Test net output #2: loss = 2.10547 (* 1 = 2.10547 loss)
I1026 21:13:34.287204 37958 solver.cpp:221] Iteration 23520 (0.649958 iter/s, 61.5424s/40 iters), loss = 1.6462
I1026 21:13:34.287257 37958 solver.cpp:240]     Train net output #0: loss = 1.6462 (* 1 = 1.6462 loss)
I1026 21:13:34.287271 37958 sgd_solver.cpp:105] Iteration 23520, lr = 0.00861647
I1026 21:14:04.953727 37958 solver.cpp:221] Iteration 23560 (1.30441 iter/s, 30.6653s/40 iters), loss = 1.87054
I1026 21:14:04.953927 37958 solver.cpp:240]     Train net output #0: loss = 1.87054 (* 1 = 1.87054 loss)
I1026 21:14:04.953943 37958 sgd_solver.cpp:105] Iteration 23560, lr = 0.00861412
I1026 21:14:35.464453 37958 solver.cpp:221] Iteration 23600 (1.31107 iter/s, 30.5094s/40 iters), loss = 1.9638
I1026 21:14:35.464624 37958 solver.cpp:240]     Train net output #0: loss = 1.9638 (* 1 = 1.9638 loss)
I1026 21:14:35.464639 37958 sgd_solver.cpp:105] Iteration 23600, lr = 0.00861176
I1026 21:15:06.036135 37958 solver.cpp:221] Iteration 23640 (1.30846 iter/s, 30.5704s/40 iters), loss = 1.81246
I1026 21:15:06.036419 37958 solver.cpp:240]     Train net output #0: loss = 1.81246 (* 1 = 1.81246 loss)
I1026 21:15:06.036451 37958 sgd_solver.cpp:105] Iteration 23640, lr = 0.00860941
I1026 21:15:37.522754 37958 solver.cpp:221] Iteration 23680 (1.27044 iter/s, 31.4852s/40 iters), loss = 1.86979
I1026 21:15:37.522965 37958 solver.cpp:240]     Train net output #0: loss = 1.86979 (* 1 = 1.86979 loss)
I1026 21:15:37.522980 37958 sgd_solver.cpp:105] Iteration 23680, lr = 0.00860706
I1026 21:16:09.057164 37958 solver.cpp:221] Iteration 23720 (1.26851 iter/s, 31.533s/40 iters), loss = 1.91241
I1026 21:16:09.057407 37958 solver.cpp:240]     Train net output #0: loss = 1.91241 (* 1 = 1.91241 loss)
I1026 21:16:09.057430 37958 sgd_solver.cpp:105] Iteration 23720, lr = 0.00860471
I1026 21:16:40.486862 37958 solver.cpp:221] Iteration 23760 (1.27274 iter/s, 31.4283s/40 iters), loss = 1.79346
I1026 21:16:40.487056 37958 solver.cpp:240]     Train net output #0: loss = 1.79346 (* 1 = 1.79346 loss)
I1026 21:16:40.487082 37958 sgd_solver.cpp:105] Iteration 23760, lr = 0.00860235
I1026 21:17:11.393759 37958 solver.cpp:221] Iteration 23800 (1.29427 iter/s, 30.9055s/40 iters), loss = 1.76835
I1026 21:17:11.393951 37958 solver.cpp:240]     Train net output #0: loss = 1.76835 (* 1 = 1.76835 loss)
I1026 21:17:11.393965 37958 sgd_solver.cpp:105] Iteration 23800, lr = 0.0086
I1026 21:17:41.916321 37958 solver.cpp:221] Iteration 23840 (1.31056 iter/s, 30.5212s/40 iters), loss = 2.0877
I1026 21:17:41.916508 37958 solver.cpp:240]     Train net output #0: loss = 2.0877 (* 1 = 2.0877 loss)
I1026 21:17:41.916523 37958 sgd_solver.cpp:105] Iteration 23840, lr = 0.00859765
I1026 21:18:12.771080 37958 solver.cpp:221] Iteration 23880 (1.29645 iter/s, 30.8534s/40 iters), loss = 1.66744
I1026 21:18:12.771282 37958 solver.cpp:240]     Train net output #0: loss = 1.66744 (* 1 = 1.66744 loss)
I1026 21:18:12.771302 37958 sgd_solver.cpp:105] Iteration 23880, lr = 0.00859529
I1026 21:18:43.675309 37958 solver.cpp:221] Iteration 23920 (1.29438 iter/s, 30.9029s/40 iters), loss = 1.64403
I1026 21:18:43.675498 37958 solver.cpp:240]     Train net output #0: loss = 1.64403 (* 1 = 1.64403 loss)
I1026 21:18:43.675513 37958 sgd_solver.cpp:105] Iteration 23920, lr = 0.00859294
I1026 21:19:14.706410 37958 solver.cpp:221] Iteration 23960 (1.28909 iter/s, 31.0297s/40 iters), loss = 1.7132
I1026 21:19:14.706604 37958 solver.cpp:240]     Train net output #0: loss = 1.7132 (* 1 = 1.7132 loss)
I1026 21:19:14.706619 37958 sgd_solver.cpp:105] Iteration 23960, lr = 0.00859059
I1026 21:19:44.606115 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_24000.caffemodel
I1026 21:19:44.639758 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_24000.solverstate
I1026 21:19:44.659894 37958 solver.cpp:333] Iteration 24000, Testing net (#0)
I1026 21:20:15.511997 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52312
I1026 21:20:15.512181 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.7634
I1026 21:20:15.512195 37958 solver.cpp:400]     Test net output #2: loss = 2.13106 (* 1 = 2.13106 loss)
I1026 21:20:16.281177 37958 solver.cpp:221] Iteration 24000 (0.649643 iter/s, 61.5723s/40 iters), loss = 2.22616
I1026 21:20:16.281235 37958 solver.cpp:240]     Train net output #0: loss = 2.22616 (* 1 = 2.22616 loss)
I1026 21:20:16.281250 37958 sgd_solver.cpp:105] Iteration 24000, lr = 0.00858823
I1026 21:20:46.806903 37958 solver.cpp:221] Iteration 24040 (1.31042 iter/s, 30.5245s/40 iters), loss = 1.76995
I1026 21:20:46.807066 37958 solver.cpp:240]     Train net output #0: loss = 1.76995 (* 1 = 1.76995 loss)
I1026 21:20:46.807081 37958 sgd_solver.cpp:105] Iteration 24040, lr = 0.00858588
I1026 21:21:17.234107 37958 solver.cpp:221] Iteration 24080 (1.31467 iter/s, 30.4259s/40 iters), loss = 2.05708
I1026 21:21:17.234299 37958 solver.cpp:240]     Train net output #0: loss = 2.05708 (* 1 = 2.05708 loss)
I1026 21:21:17.234315 37958 sgd_solver.cpp:105] Iteration 24080, lr = 0.00858353
I1026 21:21:47.608765 37958 solver.cpp:221] Iteration 24120 (1.31695 iter/s, 30.3733s/40 iters), loss = 1.89274
I1026 21:21:47.608968 37958 solver.cpp:240]     Train net output #0: loss = 1.89274 (* 1 = 1.89274 loss)
I1026 21:21:47.608983 37958 sgd_solver.cpp:105] Iteration 24120, lr = 0.00858118
I1026 21:22:17.944510 37958 solver.cpp:221] Iteration 24160 (1.31864 iter/s, 30.3344s/40 iters), loss = 1.54679
I1026 21:22:17.944679 37958 solver.cpp:240]     Train net output #0: loss = 1.54679 (* 1 = 1.54679 loss)
I1026 21:22:17.944694 37958 sgd_solver.cpp:105] Iteration 24160, lr = 0.00857882
I1026 21:22:48.515542 37958 solver.cpp:221] Iteration 24200 (1.30849 iter/s, 30.5697s/40 iters), loss = 1.95738
I1026 21:22:48.515748 37958 solver.cpp:240]     Train net output #0: loss = 1.95738 (* 1 = 1.95738 loss)
I1026 21:22:48.515769 37958 sgd_solver.cpp:105] Iteration 24200, lr = 0.00857647
I1026 21:23:19.557137 37958 solver.cpp:221] Iteration 24240 (1.28865 iter/s, 31.0402s/40 iters), loss = 2.00535
I1026 21:23:19.557330 37958 solver.cpp:240]     Train net output #0: loss = 2.00535 (* 1 = 2.00535 loss)
I1026 21:23:19.557346 37958 sgd_solver.cpp:105] Iteration 24240, lr = 0.00857412
I1026 21:23:50.385118 37958 solver.cpp:221] Iteration 24280 (1.29758 iter/s, 30.8266s/40 iters), loss = 2.08456
I1026 21:23:50.385324 37958 solver.cpp:240]     Train net output #0: loss = 2.08456 (* 1 = 2.08456 loss)
I1026 21:23:50.385339 37958 sgd_solver.cpp:105] Iteration 24280, lr = 0.00857176
I1026 21:24:34.516362 37958 solver.cpp:221] Iteration 24320 (0.906426 iter/s, 44.1294s/40 iters), loss = 2.00473
I1026 21:24:34.516605 37958 solver.cpp:240]     Train net output #0: loss = 2.00473 (* 1 = 2.00473 loss)
I1026 21:24:34.516635 37958 sgd_solver.cpp:105] Iteration 24320, lr = 0.00856941
I1026 21:25:17.291945 37958 solver.cpp:221] Iteration 24360 (0.935153 iter/s, 42.7737s/40 iters), loss = 1.89079
I1026 21:25:17.292196 37958 solver.cpp:240]     Train net output #0: loss = 1.89079 (* 1 = 1.89079 loss)
I1026 21:25:17.292218 37958 sgd_solver.cpp:105] Iteration 24360, lr = 0.00856706
I1026 21:25:49.475028 37958 solver.cpp:221] Iteration 24400 (1.24295 iter/s, 32.1816s/40 iters), loss = 1.85702
I1026 21:25:49.475215 37958 solver.cpp:240]     Train net output #0: loss = 1.85702 (* 1 = 1.85702 loss)
I1026 21:25:49.475229 37958 sgd_solver.cpp:105] Iteration 24400, lr = 0.00856471
I1026 21:26:20.724496 37958 solver.cpp:221] Iteration 24440 (1.28008 iter/s, 31.2481s/40 iters), loss = 2.13553
I1026 21:26:20.724676 37958 solver.cpp:240]     Train net output #0: loss = 2.13553 (* 1 = 2.13553 loss)
I1026 21:26:20.724691 37958 sgd_solver.cpp:105] Iteration 24440, lr = 0.00856235
I1026 21:26:51.717242 37958 solver.cpp:221] Iteration 24480 (1.29068 iter/s, 30.9914s/40 iters), loss = 1.87589
I1026 21:26:51.717469 37958 solver.cpp:240]     Train net output #0: loss = 1.87589 (* 1 = 1.87589 loss)
I1026 21:26:51.717484 37958 sgd_solver.cpp:105] Iteration 24480, lr = 0.00856
I1026 21:27:06.820091 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_24500.caffemodel
I1026 21:27:06.851488 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_24500.solverstate
I1026 21:27:06.868760 37958 solver.cpp:333] Iteration 24500, Testing net (#0)
I1026 21:27:37.729837 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 21:27:37.936699 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.51988
I1026 21:27:37.936743 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.764
I1026 21:27:37.936753 37958 solver.cpp:400]     Test net output #2: loss = 2.12869 (* 1 = 2.12869 loss)
I1026 21:27:54.214378 37958 solver.cpp:221] Iteration 24520 (0.640056 iter/s, 62.4946s/40 iters), loss = 2.24071
I1026 21:27:54.214437 37958 solver.cpp:240]     Train net output #0: loss = 2.24071 (* 1 = 2.24071 loss)
I1026 21:27:54.214450 37958 sgd_solver.cpp:105] Iteration 24520, lr = 0.00855765
I1026 21:28:24.707590 37958 solver.cpp:221] Iteration 24560 (1.31182 iter/s, 30.492s/40 iters), loss = 1.52714
I1026 21:28:24.707873 37958 solver.cpp:240]     Train net output #0: loss = 1.52714 (* 1 = 1.52714 loss)
I1026 21:28:24.707890 37958 sgd_solver.cpp:105] Iteration 24560, lr = 0.00855529
I1026 21:28:55.155532 37958 solver.cpp:221] Iteration 24600 (1.31378 iter/s, 30.4465s/40 iters), loss = 1.86112
I1026 21:28:55.155714 37958 solver.cpp:240]     Train net output #0: loss = 1.86112 (* 1 = 1.86112 loss)
I1026 21:28:55.155728 37958 sgd_solver.cpp:105] Iteration 24600, lr = 0.00855294
I1026 21:29:26.287164 37958 solver.cpp:221] Iteration 24640 (1.28492 iter/s, 31.1303s/40 iters), loss = 2.0528
I1026 21:29:26.287528 37958 solver.cpp:240]     Train net output #0: loss = 2.0528 (* 1 = 2.0528 loss)
I1026 21:29:26.287542 37958 sgd_solver.cpp:105] Iteration 24640, lr = 0.00855059
I1026 21:29:57.883043 37958 solver.cpp:221] Iteration 24680 (1.26605 iter/s, 31.5943s/40 iters), loss = 1.61348
I1026 21:29:57.883263 37958 solver.cpp:240]     Train net output #0: loss = 1.61348 (* 1 = 1.61348 loss)
I1026 21:29:57.883277 37958 sgd_solver.cpp:105] Iteration 24680, lr = 0.00854824
I1026 21:30:29.322857 37958 solver.cpp:221] Iteration 24720 (1.27233 iter/s, 31.4384s/40 iters), loss = 1.99562
I1026 21:30:29.323087 37958 solver.cpp:240]     Train net output #0: loss = 1.99562 (* 1 = 1.99562 loss)
I1026 21:30:29.323102 37958 sgd_solver.cpp:105] Iteration 24720, lr = 0.00854588
I1026 21:31:00.109920 37958 solver.cpp:221] Iteration 24760 (1.29931 iter/s, 30.7857s/40 iters), loss = 1.87014
I1026 21:31:00.110095 37958 solver.cpp:240]     Train net output #0: loss = 1.87014 (* 1 = 1.87014 loss)
I1026 21:31:00.110110 37958 sgd_solver.cpp:105] Iteration 24760, lr = 0.00854353
I1026 21:31:31.067508 37958 solver.cpp:221] Iteration 24800 (1.29215 iter/s, 30.9562s/40 iters), loss = 2.06841
I1026 21:31:31.067705 37958 solver.cpp:240]     Train net output #0: loss = 2.06841 (* 1 = 2.06841 loss)
I1026 21:31:31.067720 37958 sgd_solver.cpp:105] Iteration 24800, lr = 0.00854118
I1026 21:32:02.244040 37958 solver.cpp:221] Iteration 24840 (1.28307 iter/s, 31.1752s/40 iters), loss = 1.76383
I1026 21:32:02.244206 37958 solver.cpp:240]     Train net output #0: loss = 1.76383 (* 1 = 1.76383 loss)
I1026 21:32:02.244221 37958 sgd_solver.cpp:105] Iteration 24840, lr = 0.00853882
I1026 21:32:33.747794 37958 solver.cpp:221] Iteration 24880 (1.26975 iter/s, 31.5024s/40 iters), loss = 1.97342
I1026 21:32:33.748003 37958 solver.cpp:240]     Train net output #0: loss = 1.97342 (* 1 = 1.97342 loss)
I1026 21:32:33.748024 37958 sgd_solver.cpp:105] Iteration 24880, lr = 0.00853647
I1026 21:33:14.953716 37958 solver.cpp:221] Iteration 24920 (0.970776 iter/s, 41.2041s/40 iters), loss = 1.63285
I1026 21:33:14.953928 37958 solver.cpp:240]     Train net output #0: loss = 1.63285 (* 1 = 1.63285 loss)
I1026 21:33:14.953943 37958 sgd_solver.cpp:105] Iteration 24920, lr = 0.00853412
I1026 21:33:45.635165 37958 solver.cpp:221] Iteration 24960 (1.30378 iter/s, 30.6801s/40 iters), loss = 1.97148
I1026 21:33:45.635530 37958 solver.cpp:240]     Train net output #0: loss = 1.97148 (* 1 = 1.97148 loss)
I1026 21:33:45.635545 37958 sgd_solver.cpp:105] Iteration 24960, lr = 0.00853176
I1026 21:34:15.443838 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_25000.caffemodel
I1026 21:34:15.476655 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_25000.solverstate
I1026 21:34:15.494729 37958 solver.cpp:333] Iteration 25000, Testing net (#0)
I1026 21:34:46.426519 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.5268
I1026 21:34:46.426728 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76708
I1026 21:34:46.426741 37958 solver.cpp:400]     Test net output #2: loss = 2.14039 (* 1 = 2.14039 loss)
I1026 21:34:47.191469 37958 solver.cpp:221] Iteration 25000 (0.64984 iter/s, 61.5536s/40 iters), loss = 2.00452
I1026 21:34:47.191530 37958 solver.cpp:240]     Train net output #0: loss = 2.00452 (* 1 = 2.00452 loss)
I1026 21:34:47.191555 37958 sgd_solver.cpp:105] Iteration 25000, lr = 0.00852941
I1026 21:35:01.362694 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1026 21:35:17.749972 37958 solver.cpp:221] Iteration 25040 (1.30902 iter/s, 30.5573s/40 iters), loss = 1.93553
I1026 21:35:17.750255 37958 solver.cpp:240]     Train net output #0: loss = 1.93553 (* 1 = 1.93553 loss)
I1026 21:35:17.750286 37958 sgd_solver.cpp:105] Iteration 25040, lr = 0.00852706
I1026 21:35:48.139549 37958 solver.cpp:221] Iteration 25080 (1.3163 iter/s, 30.3882s/40 iters), loss = 1.9729
I1026 21:35:48.139757 37958 solver.cpp:240]     Train net output #0: loss = 1.9729 (* 1 = 1.9729 loss)
I1026 21:35:48.139773 37958 sgd_solver.cpp:105] Iteration 25080, lr = 0.00852471
I1026 21:36:18.751744 37958 solver.cpp:221] Iteration 25120 (1.30673 iter/s, 30.6108s/40 iters), loss = 1.46277
I1026 21:36:18.751960 37958 solver.cpp:240]     Train net output #0: loss = 1.46277 (* 1 = 1.46277 loss)
I1026 21:36:18.751974 37958 sgd_solver.cpp:105] Iteration 25120, lr = 0.00852235
I1026 21:36:49.369287 37958 solver.cpp:221] Iteration 25160 (1.3065 iter/s, 30.6162s/40 iters), loss = 1.62154
I1026 21:36:49.369472 37958 solver.cpp:240]     Train net output #0: loss = 1.62154 (* 1 = 1.62154 loss)
I1026 21:36:49.369488 37958 sgd_solver.cpp:105] Iteration 25160, lr = 0.00852
I1026 21:37:20.173821 37958 solver.cpp:221] Iteration 25200 (1.29857 iter/s, 30.8032s/40 iters), loss = 1.75564
I1026 21:37:20.174012 37958 solver.cpp:240]     Train net output #0: loss = 1.75564 (* 1 = 1.75564 loss)
I1026 21:37:20.174027 37958 sgd_solver.cpp:105] Iteration 25200, lr = 0.00851765
I1026 21:37:51.033380 37958 solver.cpp:221] Iteration 25240 (1.29625 iter/s, 30.8582s/40 iters), loss = 1.84627
I1026 21:37:51.033579 37958 solver.cpp:240]     Train net output #0: loss = 1.84627 (* 1 = 1.84627 loss)
I1026 21:37:51.033593 37958 sgd_solver.cpp:105] Iteration 25240, lr = 0.00851529
I1026 21:38:21.586609 37958 solver.cpp:221] Iteration 25280 (1.30925 iter/s, 30.5519s/40 iters), loss = 1.67873
I1026 21:38:21.586809 37958 solver.cpp:240]     Train net output #0: loss = 1.67873 (* 1 = 1.67873 loss)
I1026 21:38:21.586824 37958 sgd_solver.cpp:105] Iteration 25280, lr = 0.00851294
I1026 21:38:52.481226 37958 solver.cpp:221] Iteration 25320 (1.29478 iter/s, 30.8933s/40 iters), loss = 1.80723
I1026 21:38:52.481413 37958 solver.cpp:240]     Train net output #0: loss = 1.80723 (* 1 = 1.80723 loss)
I1026 21:38:52.481428 37958 sgd_solver.cpp:105] Iteration 25320, lr = 0.00851059
I1026 21:39:23.146723 37958 solver.cpp:221] Iteration 25360 (1.30445 iter/s, 30.6642s/40 iters), loss = 1.83141
I1026 21:39:23.146929 37958 solver.cpp:240]     Train net output #0: loss = 1.83141 (* 1 = 1.83141 loss)
I1026 21:39:23.146944 37958 sgd_solver.cpp:105] Iteration 25360, lr = 0.00850824
I1026 21:39:53.756762 37958 solver.cpp:221] Iteration 25400 (1.30682 iter/s, 30.6087s/40 iters), loss = 1.73776
I1026 21:39:53.756943 37958 solver.cpp:240]     Train net output #0: loss = 1.73776 (* 1 = 1.73776 loss)
I1026 21:39:53.756958 37958 sgd_solver.cpp:105] Iteration 25400, lr = 0.00850588
I1026 21:40:24.502542 37958 solver.cpp:221] Iteration 25440 (1.30105 iter/s, 30.7444s/40 iters), loss = 1.75946
I1026 21:40:24.502739 37958 solver.cpp:240]     Train net output #0: loss = 1.75946 (* 1 = 1.75946 loss)
I1026 21:40:24.502753 37958 sgd_solver.cpp:105] Iteration 25440, lr = 0.00850353
I1026 21:41:01.201061 37958 solver.cpp:221] Iteration 25480 (1.09001 iter/s, 36.6969s/40 iters), loss = 1.76565
I1026 21:41:01.201256 37958 solver.cpp:240]     Train net output #0: loss = 1.76565 (* 1 = 1.76565 loss)
I1026 21:41:01.201273 37958 sgd_solver.cpp:105] Iteration 25480, lr = 0.00850118
I1026 21:41:16.557826 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_25500.caffemodel
I1026 21:41:16.590916 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_25500.solverstate
I1026 21:41:16.609280 37958 solver.cpp:333] Iteration 25500, Testing net (#0)
I1026 21:41:47.278519 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 21:41:47.484378 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.5256
I1026 21:41:47.484426 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77
I1026 21:41:47.484437 37958 solver.cpp:400]     Test net output #2: loss = 2.11903 (* 1 = 2.11903 loss)
I1026 21:42:03.783977 37958 solver.cpp:221] Iteration 25520 (0.639178 iter/s, 62.5804s/40 iters), loss = 2.09992
I1026 21:42:03.784044 37958 solver.cpp:240]     Train net output #0: loss = 2.09992 (* 1 = 2.09992 loss)
I1026 21:42:03.784056 37958 sgd_solver.cpp:105] Iteration 25520, lr = 0.00849882
I1026 21:42:35.703351 37958 solver.cpp:221] Iteration 25560 (1.25321 iter/s, 31.9181s/40 iters), loss = 1.55681
I1026 21:42:35.703583 37958 solver.cpp:240]     Train net output #0: loss = 1.55681 (* 1 = 1.55681 loss)
I1026 21:42:35.703599 37958 sgd_solver.cpp:105] Iteration 25560, lr = 0.00849647
I1026 21:43:07.128998 37958 solver.cpp:221] Iteration 25600 (1.2729 iter/s, 31.4242s/40 iters), loss = 1.95584
I1026 21:43:07.129186 37958 solver.cpp:240]     Train net output #0: loss = 1.95584 (* 1 = 1.95584 loss)
I1026 21:43:07.129200 37958 sgd_solver.cpp:105] Iteration 25600, lr = 0.00849412
I1026 21:43:38.191576 37958 solver.cpp:221] Iteration 25640 (1.28778 iter/s, 31.0612s/40 iters), loss = 1.79238
I1026 21:43:38.191753 37958 solver.cpp:240]     Train net output #0: loss = 1.79238 (* 1 = 1.79238 loss)
I1026 21:43:38.191768 37958 sgd_solver.cpp:105] Iteration 25640, lr = 0.00849176
I1026 21:44:08.588996 37958 solver.cpp:221] Iteration 25680 (1.31596 iter/s, 30.3961s/40 iters), loss = 1.78974
I1026 21:44:08.589166 37958 solver.cpp:240]     Train net output #0: loss = 1.78974 (* 1 = 1.78974 loss)
I1026 21:44:08.589181 37958 sgd_solver.cpp:105] Iteration 25680, lr = 0.00848941
I1026 21:44:39.177847 37958 solver.cpp:221] Iteration 25720 (1.30772 iter/s, 30.5875s/40 iters), loss = 1.84684
I1026 21:44:39.178025 37958 solver.cpp:240]     Train net output #0: loss = 1.84684 (* 1 = 1.84684 loss)
I1026 21:44:39.178040 37958 sgd_solver.cpp:105] Iteration 25720, lr = 0.00848706
I1026 21:45:09.845969 37958 solver.cpp:221] Iteration 25760 (1.30434 iter/s, 30.6668s/40 iters), loss = 1.93192
I1026 21:45:09.846143 37958 solver.cpp:240]     Train net output #0: loss = 1.93192 (* 1 = 1.93192 loss)
I1026 21:45:09.846161 37958 sgd_solver.cpp:105] Iteration 25760, lr = 0.00848471
I1026 21:45:40.692211 37958 solver.cpp:221] Iteration 25800 (1.29681 iter/s, 30.8449s/40 iters), loss = 1.66763
I1026 21:45:40.692387 37958 solver.cpp:240]     Train net output #0: loss = 1.66763 (* 1 = 1.66763 loss)
I1026 21:45:40.692402 37958 sgd_solver.cpp:105] Iteration 25800, lr = 0.00848235
I1026 21:46:11.437530 37958 solver.cpp:221] Iteration 25840 (1.30107 iter/s, 30.744s/40 iters), loss = 1.66983
I1026 21:46:11.437705 37958 solver.cpp:240]     Train net output #0: loss = 1.66983 (* 1 = 1.66983 loss)
I1026 21:46:11.437718 37958 sgd_solver.cpp:105] Iteration 25840, lr = 0.00848
I1026 21:46:42.521435 37958 solver.cpp:221] Iteration 25880 (1.2869 iter/s, 31.0826s/40 iters), loss = 1.80016
I1026 21:46:42.521661 37958 solver.cpp:240]     Train net output #0: loss = 1.80016 (* 1 = 1.80016 loss)
I1026 21:46:42.521675 37958 sgd_solver.cpp:105] Iteration 25880, lr = 0.00847765
I1026 21:47:13.146385 37958 solver.cpp:221] Iteration 25920 (1.30618 iter/s, 30.6236s/40 iters), loss = 1.80606
I1026 21:47:13.146574 37958 solver.cpp:240]     Train net output #0: loss = 1.80606 (* 1 = 1.80606 loss)
I1026 21:47:13.146590 37958 sgd_solver.cpp:105] Iteration 25920, lr = 0.00847529
I1026 21:47:43.577862 37958 solver.cpp:221] Iteration 25960 (1.31449 iter/s, 30.4301s/40 iters), loss = 1.85747
I1026 21:47:43.578042 37958 solver.cpp:240]     Train net output #0: loss = 1.85747 (* 1 = 1.85747 loss)
I1026 21:47:43.578055 37958 sgd_solver.cpp:105] Iteration 25960, lr = 0.00847294
I1026 21:48:13.577303 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_26000.caffemodel
I1026 21:48:13.609211 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_26000.solverstate
I1026 21:48:13.627061 37958 solver.cpp:333] Iteration 26000, Testing net (#0)
I1026 21:48:44.688447 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52932
I1026 21:48:44.688551 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76984
I1026 21:48:44.688565 37958 solver.cpp:400]     Test net output #2: loss = 2.14422 (* 1 = 2.14422 loss)
I1026 21:48:45.451107 37958 solver.cpp:221] Iteration 26000 (0.646509 iter/s, 61.8708s/40 iters), loss = 2.02009
I1026 21:48:45.451145 37958 solver.cpp:240]     Train net output #0: loss = 2.02009 (* 1 = 2.02009 loss)
I1026 21:48:45.451159 37958 sgd_solver.cpp:105] Iteration 26000, lr = 0.00847059
I1026 21:49:16.017530 37958 solver.cpp:221] Iteration 26040 (1.30868 iter/s, 30.5652s/40 iters), loss = 1.76699
I1026 21:49:16.017715 37958 solver.cpp:240]     Train net output #0: loss = 1.76699 (* 1 = 1.76699 loss)
I1026 21:49:16.017730 37958 sgd_solver.cpp:105] Iteration 26040, lr = 0.00846823
I1026 21:49:46.628809 37958 solver.cpp:221] Iteration 26080 (1.30677 iter/s, 30.6099s/40 iters), loss = 2.08395
I1026 21:49:46.628991 37958 solver.cpp:240]     Train net output #0: loss = 2.08395 (* 1 = 2.08395 loss)
I1026 21:49:46.629005 37958 sgd_solver.cpp:105] Iteration 26080, lr = 0.00846588
I1026 21:50:17.382917 37958 solver.cpp:221] Iteration 26120 (1.3007 iter/s, 30.7528s/40 iters), loss = 2.18503
I1026 21:50:17.383116 37958 solver.cpp:240]     Train net output #0: loss = 2.18503 (* 1 = 2.18503 loss)
I1026 21:50:17.383129 37958 sgd_solver.cpp:105] Iteration 26120, lr = 0.00846353
I1026 21:50:48.588754 37958 solver.cpp:221] Iteration 26160 (1.28187 iter/s, 31.2045s/40 iters), loss = 1.87687
I1026 21:50:48.588984 37958 solver.cpp:240]     Train net output #0: loss = 1.87687 (* 1 = 1.87687 loss)
I1026 21:50:48.588999 37958 sgd_solver.cpp:105] Iteration 26160, lr = 0.00846118
I1026 21:51:19.303117 37958 solver.cpp:221] Iteration 26200 (1.30238 iter/s, 30.713s/40 iters), loss = 2.16705
I1026 21:51:19.303326 37958 solver.cpp:240]     Train net output #0: loss = 2.16705 (* 1 = 2.16705 loss)
I1026 21:51:19.303341 37958 sgd_solver.cpp:105] Iteration 26200, lr = 0.00845882
I1026 21:51:49.957011 37958 solver.cpp:221] Iteration 26240 (1.30495 iter/s, 30.6525s/40 iters), loss = 1.75104
I1026 21:51:49.957192 37958 solver.cpp:240]     Train net output #0: loss = 1.75104 (* 1 = 1.75104 loss)
I1026 21:51:49.957207 37958 sgd_solver.cpp:105] Iteration 26240, lr = 0.00845647
I1026 21:52:20.617435 37958 solver.cpp:221] Iteration 26280 (1.30467 iter/s, 30.6591s/40 iters), loss = 1.70449
I1026 21:52:20.617626 37958 solver.cpp:240]     Train net output #0: loss = 1.70449 (* 1 = 1.70449 loss)
I1026 21:52:20.617640 37958 sgd_solver.cpp:105] Iteration 26280, lr = 0.00845412
I1026 21:52:51.635829 37958 solver.cpp:221] Iteration 26320 (1.28961 iter/s, 31.017s/40 iters), loss = 1.56407
I1026 21:52:51.636042 37958 solver.cpp:240]     Train net output #0: loss = 1.56407 (* 1 = 1.56407 loss)
I1026 21:52:51.636056 37958 sgd_solver.cpp:105] Iteration 26320, lr = 0.00845176
I1026 21:53:22.246109 37958 solver.cpp:221] Iteration 26360 (1.30681 iter/s, 30.6089s/40 iters), loss = 1.97297
I1026 21:53:22.246289 37958 solver.cpp:240]     Train net output #0: loss = 1.97297 (* 1 = 1.97297 loss)
I1026 21:53:22.246309 37958 sgd_solver.cpp:105] Iteration 26360, lr = 0.00844941
I1026 21:53:52.663832 37958 solver.cpp:221] Iteration 26400 (1.31508 iter/s, 30.4164s/40 iters), loss = 1.74994
I1026 21:53:52.664021 37958 solver.cpp:240]     Train net output #0: loss = 1.74994 (* 1 = 1.74994 loss)
I1026 21:53:52.664034 37958 sgd_solver.cpp:105] Iteration 26400, lr = 0.00844706
I1026 21:54:23.754317 37958 solver.cpp:221] Iteration 26440 (1.28662 iter/s, 31.0891s/40 iters), loss = 1.6775
I1026 21:54:23.754518 37958 solver.cpp:240]     Train net output #0: loss = 1.6775 (* 1 = 1.6775 loss)
I1026 21:54:23.754532 37958 sgd_solver.cpp:105] Iteration 26440, lr = 0.00844471
I1026 21:54:55.634843 37958 solver.cpp:221] Iteration 26480 (1.25474 iter/s, 31.8791s/40 iters), loss = 2.23489
I1026 21:54:55.635171 37958 solver.cpp:240]     Train net output #0: loss = 2.23489 (* 1 = 2.23489 loss)
I1026 21:54:55.635218 37958 sgd_solver.cpp:105] Iteration 26480, lr = 0.00844235
I1026 21:55:10.822064 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_26500.caffemodel
I1026 21:55:10.854702 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_26500.solverstate
I1026 21:55:10.872967 37958 solver.cpp:333] Iteration 26500, Testing net (#0)
I1026 21:55:41.648674 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 21:55:41.857517 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.525
I1026 21:55:41.857569 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76932
I1026 21:55:41.857580 37958 solver.cpp:400]     Test net output #2: loss = 2.14388 (* 1 = 2.14388 loss)
I1026 21:56:01.638933 37958 solver.cpp:221] Iteration 26520 (0.606049 iter/s, 66.0013s/40 iters), loss = 1.88019
I1026 21:56:01.639041 37958 solver.cpp:240]     Train net output #0: loss = 1.88019 (* 1 = 1.88019 loss)
I1026 21:56:01.639061 37958 sgd_solver.cpp:105] Iteration 26520, lr = 0.00844
I1026 21:56:37.476666 37958 solver.cpp:221] Iteration 26560 (1.11619 iter/s, 35.8363s/40 iters), loss = 1.70928
I1026 21:56:37.476886 37958 solver.cpp:240]     Train net output #0: loss = 1.70928 (* 1 = 1.70928 loss)
I1026 21:56:37.476902 37958 sgd_solver.cpp:105] Iteration 26560, lr = 0.00843765
I1026 21:57:08.439877 37958 solver.cpp:221] Iteration 26600 (1.29191 iter/s, 30.9618s/40 iters), loss = 2.14894
I1026 21:57:08.440079 37958 solver.cpp:240]     Train net output #0: loss = 2.14894 (* 1 = 2.14894 loss)
I1026 21:57:08.440094 37958 sgd_solver.cpp:105] Iteration 26600, lr = 0.00843529
I1026 21:57:39.295785 37958 solver.cpp:221] Iteration 26640 (1.29641 iter/s, 30.8545s/40 iters), loss = 1.59951
I1026 21:57:39.295987 37958 solver.cpp:240]     Train net output #0: loss = 1.59951 (* 1 = 1.59951 loss)
I1026 21:57:39.296001 37958 sgd_solver.cpp:105] Iteration 26640, lr = 0.00843294
I1026 21:58:09.866602 37958 solver.cpp:221] Iteration 26680 (1.3085 iter/s, 30.5695s/40 iters), loss = 2.05449
I1026 21:58:09.866747 37958 solver.cpp:240]     Train net output #0: loss = 2.05449 (* 1 = 2.05449 loss)
I1026 21:58:09.866762 37958 sgd_solver.cpp:105] Iteration 26680, lr = 0.00843059
I1026 21:58:40.626340 37958 solver.cpp:221] Iteration 26720 (1.30046 iter/s, 30.7584s/40 iters), loss = 1.74898
I1026 21:58:40.626565 37958 solver.cpp:240]     Train net output #0: loss = 1.74898 (* 1 = 1.74898 loss)
I1026 21:58:40.626586 37958 sgd_solver.cpp:105] Iteration 26720, lr = 0.00842823
I1026 21:59:12.736480 37958 solver.cpp:221] Iteration 26760 (1.24577 iter/s, 32.1087s/40 iters), loss = 1.54633
I1026 21:59:12.736654 37958 solver.cpp:240]     Train net output #0: loss = 1.54633 (* 1 = 1.54633 loss)
I1026 21:59:12.736668 37958 sgd_solver.cpp:105] Iteration 26760, lr = 0.00842588
I1026 21:59:45.026929 37958 solver.cpp:221] Iteration 26800 (1.23881 iter/s, 32.289s/40 iters), loss = 2.0401
I1026 21:59:45.027129 37958 solver.cpp:240]     Train net output #0: loss = 2.0401 (* 1 = 2.0401 loss)
I1026 21:59:45.027144 37958 sgd_solver.cpp:105] Iteration 26800, lr = 0.00842353
I1026 22:00:15.844530 37958 solver.cpp:221] Iteration 26840 (1.29802 iter/s, 30.8162s/40 iters), loss = 1.74123
I1026 22:00:15.844763 37958 solver.cpp:240]     Train net output #0: loss = 1.74123 (* 1 = 1.74123 loss)
I1026 22:00:15.844782 37958 sgd_solver.cpp:105] Iteration 26840, lr = 0.00842118
I1026 22:00:46.532430 37958 solver.cpp:221] Iteration 26880 (1.3035 iter/s, 30.6865s/40 iters), loss = 1.84802
I1026 22:00:46.532595 37958 solver.cpp:240]     Train net output #0: loss = 1.84802 (* 1 = 1.84802 loss)
I1026 22:00:46.532610 37958 sgd_solver.cpp:105] Iteration 26880, lr = 0.00841882
I1026 22:01:17.031040 37958 solver.cpp:221] Iteration 26920 (1.31159 iter/s, 30.4973s/40 iters), loss = 1.73371
I1026 22:01:17.031293 37958 solver.cpp:240]     Train net output #0: loss = 1.73371 (* 1 = 1.73371 loss)
I1026 22:01:17.031314 37958 sgd_solver.cpp:105] Iteration 26920, lr = 0.00841647
I1026 22:01:47.508543 37958 solver.cpp:221] Iteration 26960 (1.3125 iter/s, 30.4761s/40 iters), loss = 1.90919
I1026 22:01:47.508730 37958 solver.cpp:240]     Train net output #0: loss = 1.90919 (* 1 = 1.90919 loss)
I1026 22:01:47.508744 37958 sgd_solver.cpp:105] Iteration 26960, lr = 0.00841412
I1026 22:02:17.117303 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_27000.caffemodel
I1026 22:02:17.151942 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_27000.solverstate
I1026 22:02:17.174702 37958 solver.cpp:333] Iteration 27000, Testing net (#0)
I1026 22:02:48.051496 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.5292
I1026 22:02:48.051703 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76952
I1026 22:02:48.051717 37958 solver.cpp:400]     Test net output #2: loss = 2.10404 (* 1 = 2.10404 loss)
I1026 22:02:48.820545 37958 solver.cpp:221] Iteration 27000 (0.652427 iter/s, 61.3095s/40 iters), loss = 1.92161
I1026 22:02:48.820605 37958 solver.cpp:240]     Train net output #0: loss = 1.92161 (* 1 = 1.92161 loss)
I1026 22:02:48.820619 37958 sgd_solver.cpp:105] Iteration 27000, lr = 0.00841176
I1026 22:03:19.268611 37958 solver.cpp:221] Iteration 27040 (1.31376 iter/s, 30.4469s/40 iters), loss = 2.10218
I1026 22:03:19.268792 37958 solver.cpp:240]     Train net output #0: loss = 2.10218 (* 1 = 2.10218 loss)
I1026 22:03:19.268806 37958 sgd_solver.cpp:105] Iteration 27040, lr = 0.00840941
I1026 22:03:52.185887 37958 solver.cpp:221] Iteration 27080 (1.21522 iter/s, 32.9158s/40 iters), loss = 1.98255
I1026 22:03:52.186195 37958 solver.cpp:240]     Train net output #0: loss = 1.98255 (* 1 = 1.98255 loss)
I1026 22:03:52.186215 37958 sgd_solver.cpp:105] Iteration 27080, lr = 0.00840706
I1026 22:04:24.828753 37958 solver.cpp:221] Iteration 27120 (1.22544 iter/s, 32.6413s/40 iters), loss = 1.48475
I1026 22:04:24.828971 37958 solver.cpp:240]     Train net output #0: loss = 1.48475 (* 1 = 1.48475 loss)
I1026 22:04:24.828992 37958 sgd_solver.cpp:105] Iteration 27120, lr = 0.00840471
I1026 22:04:56.137678 37958 solver.cpp:221] Iteration 27160 (1.27765 iter/s, 31.3075s/40 iters), loss = 1.73848
I1026 22:04:56.137861 37958 solver.cpp:240]     Train net output #0: loss = 1.73848 (* 1 = 1.73848 loss)
I1026 22:04:56.137876 37958 sgd_solver.cpp:105] Iteration 27160, lr = 0.00840235
I1026 22:05:26.891599 37958 solver.cpp:221] Iteration 27200 (1.3007 iter/s, 30.7526s/40 iters), loss = 1.90747
I1026 22:05:26.891783 37958 solver.cpp:240]     Train net output #0: loss = 1.90747 (* 1 = 1.90747 loss)
I1026 22:05:26.891798 37958 sgd_solver.cpp:105] Iteration 27200, lr = 0.0084
I1026 22:05:57.988879 37958 solver.cpp:221] Iteration 27240 (1.28634 iter/s, 31.0959s/40 iters), loss = 1.86644
I1026 22:05:57.989069 37958 solver.cpp:240]     Train net output #0: loss = 1.86644 (* 1 = 1.86644 loss)
I1026 22:05:57.989084 37958 sgd_solver.cpp:105] Iteration 27240, lr = 0.00839765
I1026 22:06:28.913121 37958 solver.cpp:221] Iteration 27280 (1.29354 iter/s, 30.9229s/40 iters), loss = 1.70627
I1026 22:06:28.913321 37958 solver.cpp:240]     Train net output #0: loss = 1.70627 (* 1 = 1.70627 loss)
I1026 22:06:28.913336 37958 sgd_solver.cpp:105] Iteration 27280, lr = 0.00839529
I1026 22:07:00.131635 37958 solver.cpp:221] Iteration 27320 (1.28135 iter/s, 31.2171s/40 iters), loss = 1.76368
I1026 22:07:00.131803 37958 solver.cpp:240]     Train net output #0: loss = 1.76368 (* 1 = 1.76368 loss)
I1026 22:07:00.131817 37958 sgd_solver.cpp:105] Iteration 27320, lr = 0.00839294
I1026 22:07:31.471382 37958 solver.cpp:221] Iteration 27360 (1.27639 iter/s, 31.3384s/40 iters), loss = 1.89076
I1026 22:07:31.471598 37958 solver.cpp:240]     Train net output #0: loss = 1.89076 (* 1 = 1.89076 loss)
I1026 22:07:31.471624 37958 sgd_solver.cpp:105] Iteration 27360, lr = 0.00839059
I1026 22:08:02.328944 37958 solver.cpp:221] Iteration 27400 (1.29634 iter/s, 30.8562s/40 iters), loss = 1.76308
I1026 22:08:02.329119 37958 solver.cpp:240]     Train net output #0: loss = 1.76308 (* 1 = 1.76308 loss)
I1026 22:08:02.329134 37958 sgd_solver.cpp:105] Iteration 27400, lr = 0.00838824
I1026 22:08:33.029551 37958 solver.cpp:221] Iteration 27440 (1.30296 iter/s, 30.6993s/40 iters), loss = 2.01975
I1026 22:08:33.029739 37958 solver.cpp:240]     Train net output #0: loss = 2.01975 (* 1 = 2.01975 loss)
I1026 22:08:33.029753 37958 sgd_solver.cpp:105] Iteration 27440, lr = 0.00838588
I1026 22:09:04.116324 37958 solver.cpp:221] Iteration 27480 (1.28678 iter/s, 31.0854s/40 iters), loss = 1.87603
I1026 22:09:04.116494 37958 solver.cpp:240]     Train net output #0: loss = 1.87603 (* 1 = 1.87603 loss)
I1026 22:09:04.116509 37958 sgd_solver.cpp:105] Iteration 27480, lr = 0.00838353
I1026 22:09:19.290941 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_27500.caffemodel
I1026 22:09:19.356015 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_27500.solverstate
I1026 22:09:20.122089 37958 solver.cpp:333] Iteration 27500, Testing net (#0)
I1026 22:09:50.793647 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 22:09:51.000902 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.51908
I1026 22:09:51.000949 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76776
I1026 22:09:51.000962 37958 solver.cpp:400]     Test net output #2: loss = 2.129 (* 1 = 2.129 loss)
I1026 22:10:07.873327 37958 solver.cpp:221] Iteration 27520 (0.627407 iter/s, 63.7544s/40 iters), loss = 1.85555
I1026 22:10:07.873420 37958 solver.cpp:240]     Train net output #0: loss = 1.85555 (* 1 = 1.85555 loss)
I1026 22:10:07.873441 37958 sgd_solver.cpp:105] Iteration 27520, lr = 0.00838118
I1026 22:10:08.774479 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1026 22:10:41.776054 37958 solver.cpp:221] Iteration 27560 (1.17989 iter/s, 33.9013s/40 iters), loss = 1.81194
I1026 22:10:41.776271 37958 solver.cpp:240]     Train net output #0: loss = 1.81194 (* 1 = 1.81194 loss)
I1026 22:10:41.776285 37958 sgd_solver.cpp:105] Iteration 27560, lr = 0.00837882
I1026 22:11:12.979404 37958 solver.cpp:221] Iteration 27600 (1.28197 iter/s, 31.2019s/40 iters), loss = 1.93485
I1026 22:11:12.979574 37958 solver.cpp:240]     Train net output #0: loss = 1.93485 (* 1 = 1.93485 loss)
I1026 22:11:12.979595 37958 sgd_solver.cpp:105] Iteration 27600, lr = 0.00837647
I1026 22:11:44.250535 37958 solver.cpp:221] Iteration 27640 (1.27919 iter/s, 31.2698s/40 iters), loss = 1.92201
I1026 22:11:44.250732 37958 solver.cpp:240]     Train net output #0: loss = 1.92201 (* 1 = 1.92201 loss)
I1026 22:11:44.250748 37958 sgd_solver.cpp:105] Iteration 27640, lr = 0.00837412
I1026 22:12:14.849803 37958 solver.cpp:221] Iteration 27680 (1.30728 iter/s, 30.5979s/40 iters), loss = 1.74924
I1026 22:12:14.850016 37958 solver.cpp:240]     Train net output #0: loss = 1.74924 (* 1 = 1.74924 loss)
I1026 22:12:14.850031 37958 sgd_solver.cpp:105] Iteration 27680, lr = 0.00837176
I1026 22:12:45.659101 37958 solver.cpp:221] Iteration 27720 (1.29837 iter/s, 30.8079s/40 iters), loss = 1.63629
I1026 22:12:45.659313 37958 solver.cpp:240]     Train net output #0: loss = 1.63629 (* 1 = 1.63629 loss)
I1026 22:12:45.659329 37958 sgd_solver.cpp:105] Iteration 27720, lr = 0.00836941
I1026 22:13:16.127595 37958 solver.cpp:221] Iteration 27760 (1.31289 iter/s, 30.4671s/40 iters), loss = 1.63351
I1026 22:13:16.127779 37958 solver.cpp:240]     Train net output #0: loss = 1.63351 (* 1 = 1.63351 loss)
I1026 22:13:16.127794 37958 sgd_solver.cpp:105] Iteration 27760, lr = 0.00836706
I1026 22:13:46.719790 37958 solver.cpp:221] Iteration 27800 (1.30758 iter/s, 30.5909s/40 iters), loss = 1.87355
I1026 22:13:46.720002 37958 solver.cpp:240]     Train net output #0: loss = 1.87355 (* 1 = 1.87355 loss)
I1026 22:13:46.720027 37958 sgd_solver.cpp:105] Iteration 27800, lr = 0.00836471
I1026 22:14:17.336132 37958 solver.cpp:221] Iteration 27840 (1.30655 iter/s, 30.615s/40 iters), loss = 1.9514
I1026 22:14:17.336357 37958 solver.cpp:240]     Train net output #0: loss = 1.9514 (* 1 = 1.9514 loss)
I1026 22:14:17.336376 37958 sgd_solver.cpp:105] Iteration 27840, lr = 0.00836235
I1026 22:14:48.835765 37958 solver.cpp:221] Iteration 27880 (1.26991 iter/s, 31.4982s/40 iters), loss = 2.03667
I1026 22:14:48.835968 37958 solver.cpp:240]     Train net output #0: loss = 2.03667 (* 1 = 2.03667 loss)
I1026 22:14:48.835983 37958 sgd_solver.cpp:105] Iteration 27880, lr = 0.00836
I1026 22:15:19.059103 37958 solver.cpp:221] Iteration 27920 (1.32354 iter/s, 30.222s/40 iters), loss = 2.048
I1026 22:15:19.059273 37958 solver.cpp:240]     Train net output #0: loss = 2.048 (* 1 = 2.048 loss)
I1026 22:15:19.059288 37958 sgd_solver.cpp:105] Iteration 27920, lr = 0.00835765
I1026 22:15:49.275002 37958 solver.cpp:221] Iteration 27960 (1.32386 iter/s, 30.2146s/40 iters), loss = 1.59431
I1026 22:15:49.275153 37958 solver.cpp:240]     Train net output #0: loss = 1.59431 (* 1 = 1.59431 loss)
I1026 22:15:49.275168 37958 sgd_solver.cpp:105] Iteration 27960, lr = 0.00835529
I1026 22:16:18.798990 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_28000.caffemodel
I1026 22:16:18.833318 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_28000.solverstate
I1026 22:16:18.852584 37958 solver.cpp:333] Iteration 28000, Testing net (#0)
I1026 22:16:49.709585 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52524
I1026 22:16:49.709795 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76496
I1026 22:16:49.709808 37958 solver.cpp:400]     Test net output #2: loss = 2.16293 (* 1 = 2.16293 loss)
I1026 22:16:50.477809 37958 solver.cpp:221] Iteration 28000 (0.653591 iter/s, 61.2004s/40 iters), loss = 1.41695
I1026 22:16:50.477849 37958 solver.cpp:240]     Train net output #0: loss = 1.41695 (* 1 = 1.41695 loss)
I1026 22:16:50.477862 37958 sgd_solver.cpp:105] Iteration 28000, lr = 0.00835294
I1026 22:17:20.793545 37958 solver.cpp:221] Iteration 28040 (1.3195 iter/s, 30.3145s/40 iters), loss = 1.68336
I1026 22:17:20.793694 37958 solver.cpp:240]     Train net output #0: loss = 1.68336 (* 1 = 1.68336 loss)
I1026 22:17:20.793709 37958 sgd_solver.cpp:105] Iteration 28040, lr = 0.00835059
I1026 22:17:50.982923 37958 solver.cpp:221] Iteration 28080 (1.32503 iter/s, 30.1881s/40 iters), loss = 1.91514
I1026 22:17:50.983098 37958 solver.cpp:240]     Train net output #0: loss = 1.91514 (* 1 = 1.91514 loss)
I1026 22:17:50.983114 37958 sgd_solver.cpp:105] Iteration 28080, lr = 0.00834823
I1026 22:18:21.167722 37958 solver.cpp:221] Iteration 28120 (1.32523 iter/s, 30.1835s/40 iters), loss = 1.66349
I1026 22:18:21.167881 37958 solver.cpp:240]     Train net output #0: loss = 1.66349 (* 1 = 1.66349 loss)
I1026 22:18:21.167896 37958 sgd_solver.cpp:105] Iteration 28120, lr = 0.00834588
I1026 22:18:51.348809 37958 solver.cpp:221] Iteration 28160 (1.32539 iter/s, 30.1798s/40 iters), loss = 1.81371
I1026 22:18:51.348953 37958 solver.cpp:240]     Train net output #0: loss = 1.81371 (* 1 = 1.81371 loss)
I1026 22:18:51.348968 37958 sgd_solver.cpp:105] Iteration 28160, lr = 0.00834353
I1026 22:19:21.606243 37958 solver.cpp:221] Iteration 28200 (1.32205 iter/s, 30.2561s/40 iters), loss = 1.48849
I1026 22:19:21.606393 37958 solver.cpp:240]     Train net output #0: loss = 1.48849 (* 1 = 1.48849 loss)
I1026 22:19:21.606407 37958 sgd_solver.cpp:105] Iteration 28200, lr = 0.00834118
I1026 22:19:55.440863 37958 solver.cpp:221] Iteration 28240 (1.18227 iter/s, 33.8332s/40 iters), loss = 1.69062
I1026 22:19:55.441110 37958 solver.cpp:240]     Train net output #0: loss = 1.69062 (* 1 = 1.69062 loss)
I1026 22:19:55.441133 37958 sgd_solver.cpp:105] Iteration 28240, lr = 0.00833882
I1026 22:20:26.728953 37958 solver.cpp:221] Iteration 28280 (1.2785 iter/s, 31.2867s/40 iters), loss = 1.81895
I1026 22:20:26.729243 37958 solver.cpp:240]     Train net output #0: loss = 1.81895 (* 1 = 1.81895 loss)
I1026 22:20:26.729274 37958 sgd_solver.cpp:105] Iteration 28280, lr = 0.00833647
I1026 22:20:58.390935 37958 solver.cpp:221] Iteration 28320 (1.2634 iter/s, 31.6605s/40 iters), loss = 1.72246
I1026 22:20:58.391129 37958 solver.cpp:240]     Train net output #0: loss = 1.72246 (* 1 = 1.72246 loss)
I1026 22:20:58.391144 37958 sgd_solver.cpp:105] Iteration 28320, lr = 0.00833412
I1026 22:21:29.472023 37958 solver.cpp:221] Iteration 28360 (1.28701 iter/s, 31.0797s/40 iters), loss = 1.79616
I1026 22:21:29.472215 37958 solver.cpp:240]     Train net output #0: loss = 1.79616 (* 1 = 1.79616 loss)
I1026 22:21:29.472229 37958 sgd_solver.cpp:105] Iteration 28360, lr = 0.00833176
I1026 22:22:00.153275 37958 solver.cpp:221] Iteration 28400 (1.30378 iter/s, 30.6799s/40 iters), loss = 1.82942
I1026 22:22:00.153463 37958 solver.cpp:240]     Train net output #0: loss = 1.82942 (* 1 = 1.82942 loss)
I1026 22:22:00.153477 37958 sgd_solver.cpp:105] Iteration 28400, lr = 0.00832941
I1026 22:22:30.982940 37958 solver.cpp:221] Iteration 28440 (1.29751 iter/s, 30.8283s/40 iters), loss = 1.66749
I1026 22:22:30.983124 37958 solver.cpp:240]     Train net output #0: loss = 1.66749 (* 1 = 1.66749 loss)
I1026 22:22:30.983139 37958 sgd_solver.cpp:105] Iteration 28440, lr = 0.00832706
I1026 22:23:04.265607 37958 solver.cpp:221] Iteration 28480 (1.20188 iter/s, 33.2812s/40 iters), loss = 1.73381
I1026 22:23:04.265859 37958 solver.cpp:240]     Train net output #0: loss = 1.73381 (* 1 = 1.73381 loss)
I1026 22:23:04.265887 37958 sgd_solver.cpp:105] Iteration 28480, lr = 0.00832471
I1026 22:23:19.039810 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_28500.caffemodel
I1026 22:23:19.072224 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_28500.solverstate
I1026 22:23:19.089865 37958 solver.cpp:333] Iteration 28500, Testing net (#0)
I1026 22:23:49.738437 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 22:23:49.945034 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53012
I1026 22:23:49.945086 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.7716
I1026 22:23:49.945098 37958 solver.cpp:400]     Test net output #2: loss = 2.09946 (* 1 = 2.09946 loss)
I1026 22:24:05.916169 37958 solver.cpp:221] Iteration 28520 (0.648845 iter/s, 61.648s/40 iters), loss = 2.06646
I1026 22:24:05.916221 37958 solver.cpp:240]     Train net output #0: loss = 2.06646 (* 1 = 2.06646 loss)
I1026 22:24:05.916235 37958 sgd_solver.cpp:105] Iteration 28520, lr = 0.00832235
I1026 22:24:36.180305 37958 solver.cpp:221] Iteration 28560 (1.32175 iter/s, 30.2629s/40 iters), loss = 1.6042
I1026 22:24:36.180452 37958 solver.cpp:240]     Train net output #0: loss = 1.6042 (* 1 = 1.6042 loss)
I1026 22:24:36.180467 37958 sgd_solver.cpp:105] Iteration 28560, lr = 0.00832
I1026 22:25:06.516391 37958 solver.cpp:221] Iteration 28600 (1.31862 iter/s, 30.3348s/40 iters), loss = 2.15595
I1026 22:25:06.516525 37958 solver.cpp:240]     Train net output #0: loss = 2.15595 (* 1 = 2.15595 loss)
I1026 22:25:06.516540 37958 sgd_solver.cpp:105] Iteration 28600, lr = 0.00831765
I1026 22:25:37.123893 37958 solver.cpp:221] Iteration 28640 (1.30692 iter/s, 30.6062s/40 iters), loss = 2.188
I1026 22:25:37.124047 37958 solver.cpp:240]     Train net output #0: loss = 2.188 (* 1 = 2.188 loss)
I1026 22:25:37.124060 37958 sgd_solver.cpp:105] Iteration 28640, lr = 0.00831529
I1026 22:26:08.017935 37958 solver.cpp:221] Iteration 28680 (1.2948 iter/s, 30.8927s/40 iters), loss = 1.54742
I1026 22:26:08.018149 37958 solver.cpp:240]     Train net output #0: loss = 1.54742 (* 1 = 1.54742 loss)
I1026 22:26:08.018164 37958 sgd_solver.cpp:105] Iteration 28680, lr = 0.00831294
I1026 22:26:51.541070 37958 solver.cpp:221] Iteration 28720 (0.919091 iter/s, 43.5213s/40 iters), loss = 1.80458
I1026 22:26:51.541357 37958 solver.cpp:240]     Train net output #0: loss = 1.80458 (* 1 = 1.80458 loss)
I1026 22:26:51.541383 37958 sgd_solver.cpp:105] Iteration 28720, lr = 0.00831059
I1026 22:27:22.489004 37958 solver.cpp:221] Iteration 28760 (1.29255 iter/s, 30.9465s/40 iters), loss = 1.67619
I1026 22:27:22.489208 37958 solver.cpp:240]     Train net output #0: loss = 1.67619 (* 1 = 1.67619 loss)
I1026 22:27:22.489223 37958 sgd_solver.cpp:105] Iteration 28760, lr = 0.00830824
I1026 22:27:53.227059 37958 solver.cpp:221] Iteration 28800 (1.30138 iter/s, 30.7367s/40 iters), loss = 2.09891
I1026 22:27:53.227252 37958 solver.cpp:240]     Train net output #0: loss = 2.09891 (* 1 = 2.09891 loss)
I1026 22:27:53.227267 37958 sgd_solver.cpp:105] Iteration 28800, lr = 0.00830588
I1026 22:28:23.770220 37958 solver.cpp:221] Iteration 28840 (1.30968 iter/s, 30.5418s/40 iters), loss = 1.93515
I1026 22:28:23.770401 37958 solver.cpp:240]     Train net output #0: loss = 1.93515 (* 1 = 1.93515 loss)
I1026 22:28:23.770416 37958 sgd_solver.cpp:105] Iteration 28840, lr = 0.00830353
I1026 22:28:54.521986 37958 solver.cpp:221] Iteration 28880 (1.3008 iter/s, 30.7504s/40 iters), loss = 1.50218
I1026 22:28:54.522174 37958 solver.cpp:240]     Train net output #0: loss = 1.50218 (* 1 = 1.50218 loss)
I1026 22:28:54.522191 37958 sgd_solver.cpp:105] Iteration 28880, lr = 0.00830118
I1026 22:29:25.337028 37958 solver.cpp:221] Iteration 28920 (1.29812 iter/s, 30.8137s/40 iters), loss = 2.00659
I1026 22:29:25.337213 37958 solver.cpp:240]     Train net output #0: loss = 2.00659 (* 1 = 2.00659 loss)
I1026 22:29:25.337229 37958 sgd_solver.cpp:105] Iteration 28920, lr = 0.00829882
I1026 22:29:56.781867 37958 solver.cpp:221] Iteration 28960 (1.27212 iter/s, 31.4435s/40 iters), loss = 1.94322
I1026 22:29:56.782059 37958 solver.cpp:240]     Train net output #0: loss = 1.94322 (* 1 = 1.94322 loss)
I1026 22:29:56.782073 37958 sgd_solver.cpp:105] Iteration 28960, lr = 0.00829647
I1026 22:30:26.651075 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_29000.caffemodel
I1026 22:30:26.682884 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_29000.solverstate
I1026 22:30:26.700580 37958 solver.cpp:333] Iteration 29000, Testing net (#0)
I1026 22:30:57.644639 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53212
I1026 22:30:57.644834 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76836
I1026 22:30:57.644848 37958 solver.cpp:400]     Test net output #2: loss = 2.13822 (* 1 = 2.13822 loss)
I1026 22:30:58.419855 37958 solver.cpp:221] Iteration 29000 (0.648977 iter/s, 61.6355s/40 iters), loss = 1.89611
I1026 22:30:58.419919 37958 solver.cpp:240]     Train net output #0: loss = 1.89611 (* 1 = 1.89611 loss)
I1026 22:30:58.419935 37958 sgd_solver.cpp:105] Iteration 29000, lr = 0.00829412
I1026 22:31:28.778533 37958 solver.cpp:221] Iteration 29040 (1.31763 iter/s, 30.3575s/40 iters), loss = 2.09131
I1026 22:31:28.778731 37958 solver.cpp:240]     Train net output #0: loss = 2.09131 (* 1 = 2.09131 loss)
I1026 22:31:28.778746 37958 sgd_solver.cpp:105] Iteration 29040, lr = 0.00829177
I1026 22:31:59.588450 37958 solver.cpp:221] Iteration 29080 (1.29834 iter/s, 30.8085s/40 iters), loss = 1.65818
I1026 22:31:59.588656 37958 solver.cpp:240]     Train net output #0: loss = 1.65818 (* 1 = 1.65818 loss)
I1026 22:31:59.588671 37958 sgd_solver.cpp:105] Iteration 29080, lr = 0.00828941
I1026 22:32:30.331324 37958 solver.cpp:221] Iteration 29120 (1.30117 iter/s, 30.7415s/40 iters), loss = 1.69527
I1026 22:32:30.331496 37958 solver.cpp:240]     Train net output #0: loss = 1.69527 (* 1 = 1.69527 loss)
I1026 22:32:30.331511 37958 sgd_solver.cpp:105] Iteration 29120, lr = 0.00828706
I1026 22:33:01.181143 37958 solver.cpp:221] Iteration 29160 (1.29666 iter/s, 30.8485s/40 iters), loss = 1.84839
I1026 22:33:01.181325 37958 solver.cpp:240]     Train net output #0: loss = 1.84839 (* 1 = 1.84839 loss)
I1026 22:33:01.181344 37958 sgd_solver.cpp:105] Iteration 29160, lr = 0.00828471
I1026 22:33:31.891156 37958 solver.cpp:221] Iteration 29200 (1.30256 iter/s, 30.7087s/40 iters), loss = 1.41021
I1026 22:33:31.891567 37958 solver.cpp:240]     Train net output #0: loss = 1.41021 (* 1 = 1.41021 loss)
I1026 22:33:31.891598 37958 sgd_solver.cpp:105] Iteration 29200, lr = 0.00828235
I1026 22:34:02.442770 37958 solver.cpp:221] Iteration 29240 (1.30933 iter/s, 30.5501s/40 iters), loss = 1.78226
I1026 22:34:02.442946 37958 solver.cpp:240]     Train net output #0: loss = 1.78226 (* 1 = 1.78226 loss)
I1026 22:34:02.442960 37958 sgd_solver.cpp:105] Iteration 29240, lr = 0.00828
I1026 22:34:32.970882 37958 solver.cpp:221] Iteration 29280 (1.31033 iter/s, 30.5268s/40 iters), loss = 1.87552
I1026 22:34:32.971071 37958 solver.cpp:240]     Train net output #0: loss = 1.87552 (* 1 = 1.87552 loss)
I1026 22:34:32.971086 37958 sgd_solver.cpp:105] Iteration 29280, lr = 0.00827765
I1026 22:35:03.874876 37958 solver.cpp:221] Iteration 29320 (1.29439 iter/s, 30.9026s/40 iters), loss = 1.74217
I1026 22:35:03.875058 37958 solver.cpp:240]     Train net output #0: loss = 1.74217 (* 1 = 1.74217 loss)
I1026 22:35:03.875073 37958 sgd_solver.cpp:105] Iteration 29320, lr = 0.00827529
I1026 22:35:34.952554 37958 solver.cpp:221] Iteration 29360 (1.28715 iter/s, 31.0763s/40 iters), loss = 1.48371
I1026 22:35:34.952731 37958 solver.cpp:240]     Train net output #0: loss = 1.48371 (* 1 = 1.48371 loss)
I1026 22:35:34.952746 37958 sgd_solver.cpp:105] Iteration 29360, lr = 0.00827294
I1026 22:36:05.792189 37958 solver.cpp:221] Iteration 29400 (1.29709 iter/s, 30.8383s/40 iters), loss = 2.02265
I1026 22:36:05.792382 37958 solver.cpp:240]     Train net output #0: loss = 2.02265 (* 1 = 2.02265 loss)
I1026 22:36:05.792397 37958 sgd_solver.cpp:105] Iteration 29400, lr = 0.00827059
I1026 22:36:36.367012 37958 solver.cpp:221] Iteration 29440 (1.30832 iter/s, 30.5735s/40 iters), loss = 1.78458
I1026 22:36:36.367210 37958 solver.cpp:240]     Train net output #0: loss = 1.78458 (* 1 = 1.78458 loss)
I1026 22:36:36.367225 37958 sgd_solver.cpp:105] Iteration 29440, lr = 0.00826824
I1026 22:37:07.101065 37958 solver.cpp:221] Iteration 29480 (1.30155 iter/s, 30.7327s/40 iters), loss = 1.88198
I1026 22:37:07.101235 37958 solver.cpp:240]     Train net output #0: loss = 1.88198 (* 1 = 1.88198 loss)
I1026 22:37:07.101250 37958 sgd_solver.cpp:105] Iteration 29480, lr = 0.00826588
I1026 22:37:21.623226 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_29500.caffemodel
I1026 22:37:21.655110 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_29500.solverstate
I1026 22:37:21.672590 37958 solver.cpp:333] Iteration 29500, Testing net (#0)
I1026 22:37:52.323294 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 22:37:52.529131 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.531
I1026 22:37:52.529183 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.771
I1026 22:37:52.529196 37958 solver.cpp:400]     Test net output #2: loss = 2.1017 (* 1 = 2.1017 loss)
I1026 22:38:08.509588 37958 solver.cpp:221] Iteration 29520 (0.651402 iter/s, 61.406s/40 iters), loss = 1.70982
I1026 22:38:08.509639 37958 solver.cpp:240]     Train net output #0: loss = 1.70982 (* 1 = 1.70982 loss)
I1026 22:38:08.509651 37958 sgd_solver.cpp:105] Iteration 29520, lr = 0.00826353
I1026 22:38:38.952921 37958 solver.cpp:221] Iteration 29560 (1.31397 iter/s, 30.4421s/40 iters), loss = 2.16956
I1026 22:38:38.953099 37958 solver.cpp:240]     Train net output #0: loss = 2.16956 (* 1 = 2.16956 loss)
I1026 22:38:38.953114 37958 sgd_solver.cpp:105] Iteration 29560, lr = 0.00826118
I1026 22:39:09.431041 37958 solver.cpp:221] Iteration 29600 (1.31247 iter/s, 30.4768s/40 iters), loss = 1.78256
I1026 22:39:09.431169 37958 solver.cpp:240]     Train net output #0: loss = 1.78256 (* 1 = 1.78256 loss)
I1026 22:39:09.431185 37958 sgd_solver.cpp:105] Iteration 29600, lr = 0.00825882
I1026 22:39:39.928339 37958 solver.cpp:221] Iteration 29640 (1.31165 iter/s, 30.496s/40 iters), loss = 1.77451
I1026 22:39:39.928493 37958 solver.cpp:240]     Train net output #0: loss = 1.77451 (* 1 = 1.77451 loss)
I1026 22:39:39.928508 37958 sgd_solver.cpp:105] Iteration 29640, lr = 0.00825647
I1026 22:40:10.363451 37958 solver.cpp:221] Iteration 29680 (1.31433 iter/s, 30.4338s/40 iters), loss = 1.62321
I1026 22:40:10.363636 37958 solver.cpp:240]     Train net output #0: loss = 1.62321 (* 1 = 1.62321 loss)
I1026 22:40:10.363651 37958 sgd_solver.cpp:105] Iteration 29680, lr = 0.00825412
I1026 22:40:40.743784 37958 solver.cpp:221] Iteration 29720 (1.3167 iter/s, 30.379s/40 iters), loss = 1.90235
I1026 22:40:40.743885 37958 solver.cpp:240]     Train net output #0: loss = 1.90235 (* 1 = 1.90235 loss)
I1026 22:40:40.743897 37958 sgd_solver.cpp:105] Iteration 29720, lr = 0.00825176
I1026 22:41:12.351837 37958 solver.cpp:221] Iteration 29760 (1.26555 iter/s, 31.6068s/40 iters), loss = 1.9429
I1026 22:41:12.352066 37958 solver.cpp:240]     Train net output #0: loss = 1.9429 (* 1 = 1.9429 loss)
I1026 22:41:12.352087 37958 sgd_solver.cpp:105] Iteration 29760, lr = 0.00824941
I1026 22:41:46.273843 37958 solver.cpp:221] Iteration 29800 (1.17923 iter/s, 33.9205s/40 iters), loss = 2.03159
I1026 22:41:46.274070 37958 solver.cpp:240]     Train net output #0: loss = 2.03159 (* 1 = 2.03159 loss)
I1026 22:41:46.274092 37958 sgd_solver.cpp:105] Iteration 29800, lr = 0.00824706
I1026 22:42:17.836030 37958 solver.cpp:221] Iteration 29840 (1.2674 iter/s, 31.5608s/40 iters), loss = 1.67207
I1026 22:42:17.836212 37958 solver.cpp:240]     Train net output #0: loss = 1.67207 (* 1 = 1.67207 loss)
I1026 22:42:17.836227 37958 sgd_solver.cpp:105] Iteration 29840, lr = 0.00824471
I1026 22:42:49.536020 37958 solver.cpp:221] Iteration 29880 (1.26188 iter/s, 31.6986s/40 iters), loss = 1.87323
I1026 22:42:49.536193 37958 solver.cpp:240]     Train net output #0: loss = 1.87323 (* 1 = 1.87323 loss)
I1026 22:42:49.536207 37958 sgd_solver.cpp:105] Iteration 29880, lr = 0.00824235
I1026 22:43:20.430785 37958 solver.cpp:221] Iteration 29920 (1.29477 iter/s, 30.8934s/40 iters), loss = 1.6949
I1026 22:43:20.430981 37958 solver.cpp:240]     Train net output #0: loss = 1.6949 (* 1 = 1.6949 loss)
I1026 22:43:20.430995 37958 sgd_solver.cpp:105] Iteration 29920, lr = 0.00824
I1026 22:43:51.147684 37958 solver.cpp:221] Iteration 29960 (1.30227 iter/s, 30.7155s/40 iters), loss = 1.82126
I1026 22:43:51.147871 37958 solver.cpp:240]     Train net output #0: loss = 1.82126 (* 1 = 1.82126 loss)
I1026 22:43:51.147884 37958 sgd_solver.cpp:105] Iteration 29960, lr = 0.00823765
I1026 22:44:21.067806 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_30000.caffemodel
I1026 22:44:21.100186 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_30000.solverstate
I1026 22:44:21.118091 37958 solver.cpp:333] Iteration 30000, Testing net (#0)
I1026 22:44:51.977277 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52652
I1026 22:44:51.977490 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76528
I1026 22:44:51.977504 37958 solver.cpp:400]     Test net output #2: loss = 2.11738 (* 1 = 2.11738 loss)
I1026 22:44:52.735741 37958 solver.cpp:221] Iteration 30000 (0.649503 iter/s, 61.5856s/40 iters), loss = 1.87077
I1026 22:44:52.735780 37958 solver.cpp:240]     Train net output #0: loss = 1.87077 (* 1 = 1.87077 loss)
I1026 22:44:52.735792 37958 sgd_solver.cpp:105] Iteration 30000, lr = 0.00823529
I1026 22:45:10.594969 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1026 22:45:23.506036 37958 solver.cpp:221] Iteration 30040 (1.30001 iter/s, 30.7691s/40 iters), loss = 1.62695
I1026 22:45:23.506213 37958 solver.cpp:240]     Train net output #0: loss = 1.62695 (* 1 = 1.62695 loss)
I1026 22:45:23.506232 37958 sgd_solver.cpp:105] Iteration 30040, lr = 0.00823294
I1026 22:45:54.939258 37958 solver.cpp:221] Iteration 30080 (1.27259 iter/s, 31.4319s/40 iters), loss = 1.85194
I1026 22:45:54.939502 37958 solver.cpp:240]     Train net output #0: loss = 1.85194 (* 1 = 1.85194 loss)
I1026 22:45:54.939517 37958 sgd_solver.cpp:105] Iteration 30080, lr = 0.00823059
I1026 22:46:26.217327 37958 solver.cpp:221] Iteration 30120 (1.27891 iter/s, 31.2766s/40 iters), loss = 1.58406
I1026 22:46:26.217535 37958 solver.cpp:240]     Train net output #0: loss = 1.58406 (* 1 = 1.58406 loss)
I1026 22:46:26.217550 37958 sgd_solver.cpp:105] Iteration 30120, lr = 0.00822823
I1026 22:46:56.985117 37958 solver.cpp:221] Iteration 30160 (1.30012 iter/s, 30.7664s/40 iters), loss = 1.65983
I1026 22:46:56.985324 37958 solver.cpp:240]     Train net output #0: loss = 1.65983 (* 1 = 1.65983 loss)
I1026 22:46:56.985340 37958 sgd_solver.cpp:105] Iteration 30160, lr = 0.00822588
I1026 22:47:28.142124 37958 solver.cpp:221] Iteration 30200 (1.28388 iter/s, 31.1556s/40 iters), loss = 1.98596
I1026 22:47:28.142313 37958 solver.cpp:240]     Train net output #0: loss = 1.98596 (* 1 = 1.98596 loss)
I1026 22:47:28.142328 37958 sgd_solver.cpp:105] Iteration 30200, lr = 0.00822353
I1026 22:47:59.231729 37958 solver.cpp:221] Iteration 30240 (1.28666 iter/s, 31.0882s/40 iters), loss = 1.90101
I1026 22:47:59.231914 37958 solver.cpp:240]     Train net output #0: loss = 1.90101 (* 1 = 1.90101 loss)
I1026 22:47:59.231928 37958 sgd_solver.cpp:105] Iteration 30240, lr = 0.00822118
I1026 22:48:30.222306 37958 solver.cpp:221] Iteration 30280 (1.29077 iter/s, 30.9892s/40 iters), loss = 1.7347
I1026 22:48:30.222523 37958 solver.cpp:240]     Train net output #0: loss = 1.7347 (* 1 = 1.7347 loss)
I1026 22:48:30.222537 37958 sgd_solver.cpp:105] Iteration 30280, lr = 0.00821882
I1026 22:49:01.343842 37958 solver.cpp:221] Iteration 30320 (1.28534 iter/s, 31.1201s/40 iters), loss = 1.98505
I1026 22:49:01.344013 37958 solver.cpp:240]     Train net output #0: loss = 1.98505 (* 1 = 1.98505 loss)
I1026 22:49:01.344028 37958 sgd_solver.cpp:105] Iteration 30320, lr = 0.00821647
I1026 22:49:32.309080 37958 solver.cpp:221] Iteration 30360 (1.29183 iter/s, 30.9639s/40 iters), loss = 1.84125
I1026 22:49:32.309259 37958 solver.cpp:240]     Train net output #0: loss = 1.84125 (* 1 = 1.84125 loss)
I1026 22:49:32.309274 37958 sgd_solver.cpp:105] Iteration 30360, lr = 0.00821412
I1026 22:50:03.269600 37958 solver.cpp:221] Iteration 30400 (1.29202 iter/s, 30.9592s/40 iters), loss = 1.69446
I1026 22:50:03.269841 37958 solver.cpp:240]     Train net output #0: loss = 1.69446 (* 1 = 1.69446 loss)
I1026 22:50:03.269863 37958 sgd_solver.cpp:105] Iteration 30400, lr = 0.00821176
I1026 22:50:34.411753 37958 solver.cpp:221] Iteration 30440 (1.28449 iter/s, 31.1407s/40 iters), loss = 2.01119
I1026 22:50:34.411929 37958 solver.cpp:240]     Train net output #0: loss = 2.01119 (* 1 = 2.01119 loss)
I1026 22:50:34.411944 37958 sgd_solver.cpp:105] Iteration 30440, lr = 0.00820941
I1026 22:51:04.974695 37958 solver.cpp:221] Iteration 30480 (1.30883 iter/s, 30.5616s/40 iters), loss = 1.72818
I1026 22:51:04.974910 37958 solver.cpp:240]     Train net output #0: loss = 1.72818 (* 1 = 1.72818 loss)
I1026 22:51:04.974925 37958 sgd_solver.cpp:105] Iteration 30480, lr = 0.00820706
I1026 22:51:19.920791 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_30500.caffemodel
I1026 22:51:19.953523 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_30500.solverstate
I1026 22:51:19.971611 37958 solver.cpp:333] Iteration 30500, Testing net (#0)
I1026 22:51:50.655464 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 22:51:50.861464 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52508
I1026 22:51:50.861516 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76668
I1026 22:51:50.861528 37958 solver.cpp:400]     Test net output #2: loss = 2.12094 (* 1 = 2.12094 loss)
I1026 22:52:07.313086 37958 solver.cpp:221] Iteration 30520 (0.641686 iter/s, 62.3358s/40 iters), loss = 1.70902
I1026 22:52:07.313179 37958 solver.cpp:240]     Train net output #0: loss = 1.70902 (* 1 = 1.70902 loss)
I1026 22:52:07.313218 37958 sgd_solver.cpp:105] Iteration 30520, lr = 0.00820471
I1026 22:53:01.858899 37958 solver.cpp:221] Iteration 30560 (0.733357 iter/s, 54.5437s/40 iters), loss = 1.66531
I1026 22:53:01.859171 37958 solver.cpp:240]     Train net output #0: loss = 1.66531 (* 1 = 1.66531 loss)
I1026 22:53:01.859190 37958 sgd_solver.cpp:105] Iteration 30560, lr = 0.00820235
I1026 22:53:34.055023 37958 solver.cpp:221] Iteration 30600 (1.24244 iter/s, 32.1946s/40 iters), loss = 1.84606
I1026 22:53:34.055208 37958 solver.cpp:240]     Train net output #0: loss = 1.84606 (* 1 = 1.84606 loss)
I1026 22:53:34.055223 37958 sgd_solver.cpp:105] Iteration 30600, lr = 0.0082
I1026 22:54:05.348328 37958 solver.cpp:221] Iteration 30640 (1.27828 iter/s, 31.2919s/40 iters), loss = 2.08986
I1026 22:54:05.348526 37958 solver.cpp:240]     Train net output #0: loss = 2.08986 (* 1 = 2.08986 loss)
I1026 22:54:05.348541 37958 sgd_solver.cpp:105] Iteration 30640, lr = 0.00819765
I1026 22:54:37.132586 37958 solver.cpp:221] Iteration 30680 (1.25854 iter/s, 31.7829s/40 iters), loss = 1.75816
I1026 22:54:37.132807 37958 solver.cpp:240]     Train net output #0: loss = 1.75816 (* 1 = 1.75816 loss)
I1026 22:54:37.132822 37958 sgd_solver.cpp:105] Iteration 30680, lr = 0.00819529
I1026 22:55:08.921306 37958 solver.cpp:221] Iteration 30720 (1.25836 iter/s, 31.7873s/40 iters), loss = 1.83697
I1026 22:55:08.921494 37958 solver.cpp:240]     Train net output #0: loss = 1.83697 (* 1 = 1.83697 loss)
I1026 22:55:08.921509 37958 sgd_solver.cpp:105] Iteration 30720, lr = 0.00819294
I1026 22:55:39.283864 37958 solver.cpp:221] Iteration 30760 (1.31747 iter/s, 30.3612s/40 iters), loss = 2.04574
I1026 22:55:39.284031 37958 solver.cpp:240]     Train net output #0: loss = 2.04574 (* 1 = 2.04574 loss)
I1026 22:55:39.284045 37958 sgd_solver.cpp:105] Iteration 30760, lr = 0.00819059
I1026 22:56:10.599618 37958 solver.cpp:221] Iteration 30800 (1.27737 iter/s, 31.3144s/40 iters), loss = 1.75439
I1026 22:56:10.599817 37958 solver.cpp:240]     Train net output #0: loss = 1.75439 (* 1 = 1.75439 loss)
I1026 22:56:10.599834 37958 sgd_solver.cpp:105] Iteration 30800, lr = 0.00818823
I1026 22:56:41.547653 37958 solver.cpp:221] Iteration 30840 (1.29255 iter/s, 30.9467s/40 iters), loss = 1.79765
I1026 22:56:41.547829 37958 solver.cpp:240]     Train net output #0: loss = 1.79765 (* 1 = 1.79765 loss)
I1026 22:56:41.547843 37958 sgd_solver.cpp:105] Iteration 30840, lr = 0.00818588
I1026 22:57:12.619442 37958 solver.cpp:221] Iteration 30880 (1.2874 iter/s, 31.0704s/40 iters), loss = 1.9128
I1026 22:57:12.619648 37958 solver.cpp:240]     Train net output #0: loss = 1.9128 (* 1 = 1.9128 loss)
I1026 22:57:12.619663 37958 sgd_solver.cpp:105] Iteration 30880, lr = 0.00818353
I1026 22:57:44.319896 37958 solver.cpp:221] Iteration 30920 (1.26187 iter/s, 31.6991s/40 iters), loss = 1.98082
I1026 22:57:44.320117 37958 solver.cpp:240]     Train net output #0: loss = 1.98082 (* 1 = 1.98082 loss)
I1026 22:57:44.320132 37958 sgd_solver.cpp:105] Iteration 30920, lr = 0.00818118
I1026 22:58:15.640147 37958 solver.cpp:221] Iteration 30960 (1.27719 iter/s, 31.3188s/40 iters), loss = 1.61714
I1026 22:58:15.640337 37958 solver.cpp:240]     Train net output #0: loss = 1.61714 (* 1 = 1.61714 loss)
I1026 22:58:15.640352 37958 sgd_solver.cpp:105] Iteration 30960, lr = 0.00817882
I1026 22:58:46.296663 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_31000.caffemodel
I1026 22:58:46.329931 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_31000.solverstate
I1026 22:58:46.347911 37958 solver.cpp:333] Iteration 31000, Testing net (#0)
I1026 22:59:17.205343 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53204
I1026 22:59:17.205513 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77348
I1026 22:59:17.205526 37958 solver.cpp:400]     Test net output #2: loss = 2.08887 (* 1 = 2.08887 loss)
I1026 22:59:17.976629 37958 solver.cpp:221] Iteration 31000 (0.641705 iter/s, 62.334s/40 iters), loss = 1.40876
I1026 22:59:17.976712 37958 solver.cpp:240]     Train net output #0: loss = 1.40876 (* 1 = 1.40876 loss)
I1026 22:59:17.976727 37958 sgd_solver.cpp:105] Iteration 31000, lr = 0.00817647
I1026 22:59:48.728618 37958 solver.cpp:221] Iteration 31040 (1.30078 iter/s, 30.7507s/40 iters), loss = 1.6192
I1026 22:59:48.728847 37958 solver.cpp:240]     Train net output #0: loss = 1.6192 (* 1 = 1.6192 loss)
I1026 22:59:48.728862 37958 sgd_solver.cpp:105] Iteration 31040, lr = 0.00817412
I1026 23:00:20.003541 37958 solver.cpp:221] Iteration 31080 (1.27904 iter/s, 31.2735s/40 iters), loss = 1.60839
I1026 23:00:20.003784 37958 solver.cpp:240]     Train net output #0: loss = 1.60839 (* 1 = 1.60839 loss)
I1026 23:00:20.003806 37958 sgd_solver.cpp:105] Iteration 31080, lr = 0.00817176
I1026 23:00:51.783366 37958 solver.cpp:221] Iteration 31120 (1.25872 iter/s, 31.7784s/40 iters), loss = 1.60201
I1026 23:00:51.783553 37958 solver.cpp:240]     Train net output #0: loss = 1.60201 (* 1 = 1.60201 loss)
I1026 23:00:51.783568 37958 sgd_solver.cpp:105] Iteration 31120, lr = 0.00816941
I1026 23:01:22.128013 37958 solver.cpp:221] Iteration 31160 (1.31825 iter/s, 30.3433s/40 iters), loss = 1.80524
I1026 23:01:22.128182 37958 solver.cpp:240]     Train net output #0: loss = 1.80524 (* 1 = 1.80524 loss)
I1026 23:01:22.128197 37958 sgd_solver.cpp:105] Iteration 31160, lr = 0.00816706
I1026 23:01:52.626279 37958 solver.cpp:221] Iteration 31200 (1.31161 iter/s, 30.4969s/40 iters), loss = 1.91594
I1026 23:01:52.626482 37958 solver.cpp:240]     Train net output #0: loss = 1.91594 (* 1 = 1.91594 loss)
I1026 23:01:52.626497 37958 sgd_solver.cpp:105] Iteration 31200, lr = 0.00816471
I1026 23:02:23.294594 37958 solver.cpp:221] Iteration 31240 (1.30434 iter/s, 30.667s/40 iters), loss = 1.81095
I1026 23:02:23.294773 37958 solver.cpp:240]     Train net output #0: loss = 1.81095 (* 1 = 1.81095 loss)
I1026 23:02:23.294788 37958 sgd_solver.cpp:105] Iteration 31240, lr = 0.00816235
I1026 23:02:53.908535 37958 solver.cpp:221] Iteration 31280 (1.30665 iter/s, 30.6126s/40 iters), loss = 1.50552
I1026 23:02:53.908713 37958 solver.cpp:240]     Train net output #0: loss = 1.50552 (* 1 = 1.50552 loss)
I1026 23:02:53.908728 37958 sgd_solver.cpp:105] Iteration 31280, lr = 0.00816
I1026 23:03:24.618134 37958 solver.cpp:221] Iteration 31320 (1.30258 iter/s, 30.7083s/40 iters), loss = 1.64863
I1026 23:03:24.618307 37958 solver.cpp:240]     Train net output #0: loss = 1.64863 (* 1 = 1.64863 loss)
I1026 23:03:24.618322 37958 sgd_solver.cpp:105] Iteration 31320, lr = 0.00815765
I1026 23:03:55.873003 37958 solver.cpp:221] Iteration 31360 (1.27986 iter/s, 31.2535s/40 iters), loss = 1.79597
I1026 23:03:55.873175 37958 solver.cpp:240]     Train net output #0: loss = 1.79597 (* 1 = 1.79597 loss)
I1026 23:03:55.873190 37958 sgd_solver.cpp:105] Iteration 31360, lr = 0.00815529
I1026 23:04:26.858641 37958 solver.cpp:221] Iteration 31400 (1.29098 iter/s, 30.9843s/40 iters), loss = 1.94047
I1026 23:04:26.858831 37958 solver.cpp:240]     Train net output #0: loss = 1.94047 (* 1 = 1.94047 loss)
I1026 23:04:26.858846 37958 sgd_solver.cpp:105] Iteration 31400, lr = 0.00815294
I1026 23:04:57.697847 37958 solver.cpp:221] Iteration 31440 (1.29711 iter/s, 30.8379s/40 iters), loss = 1.758
I1026 23:04:57.698024 37958 solver.cpp:240]     Train net output #0: loss = 1.758 (* 1 = 1.758 loss)
I1026 23:04:57.698038 37958 sgd_solver.cpp:105] Iteration 31440, lr = 0.00815059
I1026 23:05:28.311888 37958 solver.cpp:221] Iteration 31480 (1.30665 iter/s, 30.6127s/40 iters), loss = 2.1138
I1026 23:05:28.312098 37958 solver.cpp:240]     Train net output #0: loss = 2.1138 (* 1 = 2.1138 loss)
I1026 23:05:28.312111 37958 sgd_solver.cpp:105] Iteration 31480, lr = 0.00814824
I1026 23:05:42.768939 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_31500.caffemodel
I1026 23:05:42.801267 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_31500.solverstate
I1026 23:05:42.819021 37958 solver.cpp:333] Iteration 31500, Testing net (#0)
I1026 23:06:13.465847 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 23:06:13.674763 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52584
I1026 23:06:13.674808 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76804
I1026 23:06:13.674819 37958 solver.cpp:400]     Test net output #2: loss = 2.10307 (* 1 = 2.10307 loss)
I1026 23:06:29.707141 37958 solver.cpp:221] Iteration 31520 (0.651543 iter/s, 61.3927s/40 iters), loss = 1.52873
I1026 23:06:29.707209 37958 solver.cpp:240]     Train net output #0: loss = 1.52873 (* 1 = 1.52873 loss)
I1026 23:06:29.707222 37958 sgd_solver.cpp:105] Iteration 31520, lr = 0.00814588
I1026 23:07:00.207489 37958 solver.cpp:221] Iteration 31560 (1.31151 iter/s, 30.4991s/40 iters), loss = 2.09008
I1026 23:07:00.207682 37958 solver.cpp:240]     Train net output #0: loss = 2.09008 (* 1 = 2.09008 loss)
I1026 23:07:00.207696 37958 sgd_solver.cpp:105] Iteration 31560, lr = 0.00814353
I1026 23:07:30.555683 37958 solver.cpp:221] Iteration 31600 (1.31809 iter/s, 30.3468s/40 iters), loss = 1.75616
I1026 23:07:30.555865 37958 solver.cpp:240]     Train net output #0: loss = 1.75616 (* 1 = 1.75616 loss)
I1026 23:07:30.555879 37958 sgd_solver.cpp:105] Iteration 31600, lr = 0.00814118
I1026 23:08:01.002357 37958 solver.cpp:221] Iteration 31640 (1.31383 iter/s, 30.4453s/40 iters), loss = 1.45558
I1026 23:08:01.003998 37958 solver.cpp:240]     Train net output #0: loss = 1.45558 (* 1 = 1.45558 loss)
I1026 23:08:01.004012 37958 sgd_solver.cpp:105] Iteration 31640, lr = 0.00813882
I1026 23:08:31.391393 37958 solver.cpp:221] Iteration 31680 (1.31639 iter/s, 30.3862s/40 iters), loss = 1.89899
I1026 23:08:31.391547 37958 solver.cpp:240]     Train net output #0: loss = 1.89899 (* 1 = 1.89899 loss)
I1026 23:08:31.391562 37958 sgd_solver.cpp:105] Iteration 31680, lr = 0.00813647
I1026 23:09:01.714361 37958 solver.cpp:221] Iteration 31720 (1.31919 iter/s, 30.3217s/40 iters), loss = 1.63319
I1026 23:09:01.714509 37958 solver.cpp:240]     Train net output #0: loss = 1.63319 (* 1 = 1.63319 loss)
I1026 23:09:01.714524 37958 sgd_solver.cpp:105] Iteration 31720, lr = 0.00813412
I1026 23:09:32.196764 37958 solver.cpp:221] Iteration 31760 (1.31229 iter/s, 30.4811s/40 iters), loss = 1.72553
I1026 23:09:32.196926 37958 solver.cpp:240]     Train net output #0: loss = 1.72553 (* 1 = 1.72553 loss)
I1026 23:09:32.196940 37958 sgd_solver.cpp:105] Iteration 31760, lr = 0.00813176
I1026 23:10:02.556454 37958 solver.cpp:221] Iteration 31800 (1.31759 iter/s, 30.3584s/40 iters), loss = 1.73634
I1026 23:10:02.556619 37958 solver.cpp:240]     Train net output #0: loss = 1.73634 (* 1 = 1.73634 loss)
I1026 23:10:02.556634 37958 sgd_solver.cpp:105] Iteration 31800, lr = 0.00812941
I1026 23:10:32.952906 37958 solver.cpp:221] Iteration 31840 (1.316 iter/s, 30.3951s/40 iters), loss = 1.47512
I1026 23:10:32.953089 37958 solver.cpp:240]     Train net output #0: loss = 1.47512 (* 1 = 1.47512 loss)
I1026 23:10:32.953104 37958 sgd_solver.cpp:105] Iteration 31840, lr = 0.00812706
I1026 23:11:03.734810 37958 solver.cpp:221] Iteration 31880 (1.29952 iter/s, 30.7806s/40 iters), loss = 1.78168
I1026 23:11:03.734997 37958 solver.cpp:240]     Train net output #0: loss = 1.78168 (* 1 = 1.78168 loss)
I1026 23:11:03.735010 37958 sgd_solver.cpp:105] Iteration 31880, lr = 0.00812471
I1026 23:11:34.289445 37958 solver.cpp:221] Iteration 31920 (1.30919 iter/s, 30.5533s/40 iters), loss = 1.67355
I1026 23:11:34.289607 37958 solver.cpp:240]     Train net output #0: loss = 1.67355 (* 1 = 1.67355 loss)
I1026 23:11:34.289620 37958 sgd_solver.cpp:105] Iteration 31920, lr = 0.00812235
I1026 23:12:05.060843 37958 solver.cpp:221] Iteration 31960 (1.29996 iter/s, 30.7701s/40 iters), loss = 1.66648
I1026 23:12:05.061009 37958 solver.cpp:240]     Train net output #0: loss = 1.66648 (* 1 = 1.66648 loss)
I1026 23:12:05.061024 37958 sgd_solver.cpp:105] Iteration 31960, lr = 0.00812
I1026 23:12:34.848507 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_32000.caffemodel
I1026 23:12:34.881117 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_32000.solverstate
I1026 23:12:34.898910 37958 solver.cpp:333] Iteration 32000, Testing net (#0)
I1026 23:13:05.729286 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53232
I1026 23:13:05.729527 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77172
I1026 23:13:05.729542 37958 solver.cpp:400]     Test net output #2: loss = 2.09434 (* 1 = 2.09434 loss)
I1026 23:13:06.498307 37958 solver.cpp:221] Iteration 32000 (0.651095 iter/s, 61.435s/40 iters), loss = 1.78597
I1026 23:13:06.498366 37958 solver.cpp:240]     Train net output #0: loss = 1.78597 (* 1 = 1.78597 loss)
I1026 23:13:06.498380 37958 sgd_solver.cpp:105] Iteration 32000, lr = 0.00811765
I1026 23:13:37.137672 37958 solver.cpp:221] Iteration 32040 (1.30556 iter/s, 30.6381s/40 iters), loss = 2.1136
I1026 23:13:37.137869 37958 solver.cpp:240]     Train net output #0: loss = 2.1136 (* 1 = 2.1136 loss)
I1026 23:13:37.137883 37958 sgd_solver.cpp:105] Iteration 32040, lr = 0.00811529
I1026 23:14:07.768234 37958 solver.cpp:221] Iteration 32080 (1.30594 iter/s, 30.6292s/40 iters), loss = 1.74499
I1026 23:14:07.768436 37958 solver.cpp:240]     Train net output #0: loss = 1.74499 (* 1 = 1.74499 loss)
I1026 23:14:07.768451 37958 sgd_solver.cpp:105] Iteration 32080, lr = 0.00811294
I1026 23:14:38.650357 37958 solver.cpp:221] Iteration 32120 (1.29531 iter/s, 30.8808s/40 iters), loss = 1.95866
I1026 23:14:38.650558 37958 solver.cpp:240]     Train net output #0: loss = 1.95866 (* 1 = 1.95866 loss)
I1026 23:14:38.650573 37958 sgd_solver.cpp:105] Iteration 32120, lr = 0.00811059
I1026 23:15:09.902034 37958 solver.cpp:221] Iteration 32160 (1.27999 iter/s, 31.2503s/40 iters), loss = 1.69132
I1026 23:15:09.902258 37958 solver.cpp:240]     Train net output #0: loss = 1.69132 (* 1 = 1.69132 loss)
I1026 23:15:09.902281 37958 sgd_solver.cpp:105] Iteration 32160, lr = 0.00810823
I1026 23:15:42.235795 37958 solver.cpp:221] Iteration 32200 (1.23715 iter/s, 32.3323s/40 iters), loss = 1.73113
I1026 23:15:42.235981 37958 solver.cpp:240]     Train net output #0: loss = 1.73113 (* 1 = 1.73113 loss)
I1026 23:15:42.235996 37958 sgd_solver.cpp:105] Iteration 32200, lr = 0.00810588
I1026 23:16:15.165575 37958 solver.cpp:221] Iteration 32240 (1.21476 iter/s, 32.9283s/40 iters), loss = 1.71742
I1026 23:16:15.165793 37958 solver.cpp:240]     Train net output #0: loss = 1.71742 (* 1 = 1.71742 loss)
I1026 23:16:15.165808 37958 sgd_solver.cpp:105] Iteration 32240, lr = 0.00810353
I1026 23:16:46.405956 37958 solver.cpp:221] Iteration 32280 (1.28045 iter/s, 31.239s/40 iters), loss = 2.12013
I1026 23:16:46.406154 37958 solver.cpp:240]     Train net output #0: loss = 2.12013 (* 1 = 2.12013 loss)
I1026 23:16:46.406169 37958 sgd_solver.cpp:105] Iteration 32280, lr = 0.00810118
I1026 23:17:17.947335 37958 solver.cpp:221] Iteration 32320 (1.26823 iter/s, 31.54s/40 iters), loss = 1.96807
I1026 23:17:17.947520 37958 solver.cpp:240]     Train net output #0: loss = 1.96807 (* 1 = 1.96807 loss)
I1026 23:17:17.947535 37958 sgd_solver.cpp:105] Iteration 32320, lr = 0.00809882
I1026 23:17:48.940467 37958 solver.cpp:221] Iteration 32360 (1.29066 iter/s, 30.9918s/40 iters), loss = 2.05597
I1026 23:17:48.940657 37958 solver.cpp:240]     Train net output #0: loss = 2.05597 (* 1 = 2.05597 loss)
I1026 23:17:48.940671 37958 sgd_solver.cpp:105] Iteration 32360, lr = 0.00809647
I1026 23:18:19.639153 37958 solver.cpp:221] Iteration 32400 (1.30304 iter/s, 30.6973s/40 iters), loss = 1.70526
I1026 23:18:19.639320 37958 solver.cpp:240]     Train net output #0: loss = 1.70526 (* 1 = 1.70526 loss)
I1026 23:18:19.639336 37958 sgd_solver.cpp:105] Iteration 32400, lr = 0.00809412
I1026 23:18:50.096716 37958 solver.cpp:221] Iteration 32440 (1.31336 iter/s, 30.4563s/40 iters), loss = 1.7346
I1026 23:18:50.096971 37958 solver.cpp:240]     Train net output #0: loss = 1.7346 (* 1 = 1.7346 loss)
I1026 23:18:50.097018 37958 sgd_solver.cpp:105] Iteration 32440, lr = 0.00809176
I1026 23:19:21.040391 37958 solver.cpp:221] Iteration 32480 (1.29273 iter/s, 30.9423s/40 iters), loss = 1.73452
I1026 23:19:21.040606 37958 solver.cpp:240]     Train net output #0: loss = 1.73452 (* 1 = 1.73452 loss)
I1026 23:19:21.040621 37958 sgd_solver.cpp:105] Iteration 32480, lr = 0.00808941
I1026 23:19:35.763085 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_32500.caffemodel
I1026 23:19:35.796226 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_32500.solverstate
I1026 23:19:35.814327 37958 solver.cpp:333] Iteration 32500, Testing net (#0)
I1026 23:20:06.531852 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 23:20:06.740140 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.527
I1026 23:20:06.740195 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76908
I1026 23:20:06.740206 37958 solver.cpp:400]     Test net output #2: loss = 2.11867 (* 1 = 2.11867 loss)
I1026 23:20:22.776687 37958 solver.cpp:221] Iteration 32520 (0.647944 iter/s, 61.7338s/40 iters), loss = 1.59006
I1026 23:20:22.776751 37958 solver.cpp:240]     Train net output #0: loss = 1.59006 (* 1 = 1.59006 loss)
I1026 23:20:22.776765 37958 sgd_solver.cpp:105] Iteration 32520, lr = 0.00808706
I1026 23:20:26.645639 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1026 23:20:53.414652 37958 solver.cpp:221] Iteration 32560 (1.30562 iter/s, 30.6367s/40 iters), loss = 1.82098
I1026 23:20:53.414851 37958 solver.cpp:240]     Train net output #0: loss = 1.82098 (* 1 = 1.82098 loss)
I1026 23:20:53.414865 37958 sgd_solver.cpp:105] Iteration 32560, lr = 0.00808471
I1026 23:21:34.106112 37958 solver.cpp:221] Iteration 32600 (0.983049 iter/s, 40.6897s/40 iters), loss = 1.7554
I1026 23:21:34.106329 37958 solver.cpp:240]     Train net output #0: loss = 1.7554 (* 1 = 1.7554 loss)
I1026 23:21:34.106353 37958 sgd_solver.cpp:105] Iteration 32600, lr = 0.00808235
I1026 23:22:06.226063 37958 solver.cpp:221] Iteration 32640 (1.24539 iter/s, 32.1185s/40 iters), loss = 1.83039
I1026 23:22:06.226271 37958 solver.cpp:240]     Train net output #0: loss = 1.83039 (* 1 = 1.83039 loss)
I1026 23:22:06.226286 37958 sgd_solver.cpp:105] Iteration 32640, lr = 0.00808
I1026 23:22:36.749992 37958 solver.cpp:221] Iteration 32680 (1.31051 iter/s, 30.5226s/40 iters), loss = 1.75362
I1026 23:22:36.750175 37958 solver.cpp:240]     Train net output #0: loss = 1.75362 (* 1 = 1.75362 loss)
I1026 23:22:36.750190 37958 sgd_solver.cpp:105] Iteration 32680, lr = 0.00807765
I1026 23:23:07.781915 37958 solver.cpp:221] Iteration 32720 (1.28905 iter/s, 31.0306s/40 iters), loss = 1.76881
I1026 23:23:07.782132 37958 solver.cpp:240]     Train net output #0: loss = 1.76881 (* 1 = 1.76881 loss)
I1026 23:23:07.782147 37958 sgd_solver.cpp:105] Iteration 32720, lr = 0.00807529
I1026 23:23:38.623276 37958 solver.cpp:221] Iteration 32760 (1.29702 iter/s, 30.84s/40 iters), loss = 1.93711
I1026 23:23:38.623467 37958 solver.cpp:240]     Train net output #0: loss = 1.93711 (* 1 = 1.93711 loss)
I1026 23:23:38.623482 37958 sgd_solver.cpp:105] Iteration 32760, lr = 0.00807294
I1026 23:24:10.599256 37958 solver.cpp:221] Iteration 32800 (1.25099 iter/s, 31.9746s/40 iters), loss = 1.35579
I1026 23:24:10.599472 37958 solver.cpp:240]     Train net output #0: loss = 1.35579 (* 1 = 1.35579 loss)
I1026 23:24:10.599486 37958 sgd_solver.cpp:105] Iteration 32800, lr = 0.00807059
I1026 23:24:41.445896 37958 solver.cpp:221] Iteration 32840 (1.2968 iter/s, 30.8453s/40 iters), loss = 2.01931
I1026 23:24:41.446105 37958 solver.cpp:240]     Train net output #0: loss = 2.01931 (* 1 = 2.01931 loss)
I1026 23:24:41.446118 37958 sgd_solver.cpp:105] Iteration 32840, lr = 0.00806824
I1026 23:25:12.840602 37958 solver.cpp:221] Iteration 32880 (1.27416 iter/s, 31.3933s/40 iters), loss = 1.84867
I1026 23:25:12.840816 37958 solver.cpp:240]     Train net output #0: loss = 1.84867 (* 1 = 1.84867 loss)
I1026 23:25:12.840840 37958 sgd_solver.cpp:105] Iteration 32880, lr = 0.00806588
I1026 23:25:44.210604 37958 solver.cpp:221] Iteration 32920 (1.27516 iter/s, 31.3686s/40 iters), loss = 1.79561
I1026 23:25:44.210803 37958 solver.cpp:240]     Train net output #0: loss = 1.79561 (* 1 = 1.79561 loss)
I1026 23:25:44.210817 37958 sgd_solver.cpp:105] Iteration 32920, lr = 0.00806353
I1026 23:26:14.787700 37958 solver.cpp:221] Iteration 32960 (1.30823 iter/s, 30.5758s/40 iters), loss = 2.05463
I1026 23:26:14.787897 37958 solver.cpp:240]     Train net output #0: loss = 2.05463 (* 1 = 2.05463 loss)
I1026 23:26:14.787911 37958 sgd_solver.cpp:105] Iteration 32960, lr = 0.00806118
I1026 23:26:44.663816 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_33000.caffemodel
I1026 23:26:44.695576 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_33000.solverstate
I1026 23:26:44.713258 37958 solver.cpp:333] Iteration 33000, Testing net (#0)
I1026 23:27:15.575621 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52476
I1026 23:27:15.575799 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76788
I1026 23:27:15.575814 37958 solver.cpp:400]     Test net output #2: loss = 2.14364 (* 1 = 2.14364 loss)
I1026 23:27:16.344943 37958 solver.cpp:221] Iteration 33000 (0.649828 iter/s, 61.5547s/40 iters), loss = 1.72424
I1026 23:27:16.345019 37958 solver.cpp:240]     Train net output #0: loss = 1.72424 (* 1 = 1.72424 loss)
I1026 23:27:16.345033 37958 sgd_solver.cpp:105] Iteration 33000, lr = 0.00805882
I1026 23:27:46.876909 37958 solver.cpp:221] Iteration 33040 (1.31016 iter/s, 30.5307s/40 iters), loss = 1.71829
I1026 23:27:46.877105 37958 solver.cpp:240]     Train net output #0: loss = 1.71829 (* 1 = 1.71829 loss)
I1026 23:27:46.877120 37958 sgd_solver.cpp:105] Iteration 33040, lr = 0.00805647
I1026 23:28:17.209390 37958 solver.cpp:221] Iteration 33080 (1.31878 iter/s, 30.3311s/40 iters), loss = 1.91174
I1026 23:28:17.209564 37958 solver.cpp:240]     Train net output #0: loss = 1.91174 (* 1 = 1.91174 loss)
I1026 23:28:17.209579 37958 sgd_solver.cpp:105] Iteration 33080, lr = 0.00805412
I1026 23:28:47.761530 37958 solver.cpp:221] Iteration 33120 (1.30929 iter/s, 30.5508s/40 iters), loss = 1.91411
I1026 23:28:47.761696 37958 solver.cpp:240]     Train net output #0: loss = 1.91411 (* 1 = 1.91411 loss)
I1026 23:28:47.761710 37958 sgd_solver.cpp:105] Iteration 33120, lr = 0.00805177
I1026 23:29:18.377566 37958 solver.cpp:221] Iteration 33160 (1.30656 iter/s, 30.6147s/40 iters), loss = 1.70992
I1026 23:29:18.377812 37958 solver.cpp:240]     Train net output #0: loss = 1.70992 (* 1 = 1.70992 loss)
I1026 23:29:18.377835 37958 sgd_solver.cpp:105] Iteration 33160, lr = 0.00804941
I1026 23:29:49.260757 37958 solver.cpp:221] Iteration 33200 (1.29526 iter/s, 30.8818s/40 iters), loss = 1.98478
I1026 23:29:49.260937 37958 solver.cpp:240]     Train net output #0: loss = 1.98478 (* 1 = 1.98478 loss)
I1026 23:29:49.260951 37958 sgd_solver.cpp:105] Iteration 33200, lr = 0.00804706
I1026 23:30:20.115164 37958 solver.cpp:221] Iteration 33240 (1.29647 iter/s, 30.8531s/40 iters), loss = 2.13756
I1026 23:30:20.115443 37958 solver.cpp:240]     Train net output #0: loss = 2.13756 (* 1 = 2.13756 loss)
I1026 23:30:20.115458 37958 sgd_solver.cpp:105] Iteration 33240, lr = 0.00804471
I1026 23:30:51.268056 37958 solver.cpp:221] Iteration 33280 (1.28405 iter/s, 31.1514s/40 iters), loss = 1.88571
I1026 23:30:51.268247 37958 solver.cpp:240]     Train net output #0: loss = 1.88571 (* 1 = 1.88571 loss)
I1026 23:30:51.268262 37958 sgd_solver.cpp:105] Iteration 33280, lr = 0.00804235
I1026 23:31:22.069250 37958 solver.cpp:221] Iteration 33320 (1.29871 iter/s, 30.7998s/40 iters), loss = 1.74618
I1026 23:31:22.069437 37958 solver.cpp:240]     Train net output #0: loss = 1.74618 (* 1 = 1.74618 loss)
I1026 23:31:22.069452 37958 sgd_solver.cpp:105] Iteration 33320, lr = 0.00804
I1026 23:31:52.929388 37958 solver.cpp:221] Iteration 33360 (1.29623 iter/s, 30.8588s/40 iters), loss = 1.62085
I1026 23:31:52.929617 37958 solver.cpp:240]     Train net output #0: loss = 1.62085 (* 1 = 1.62085 loss)
I1026 23:31:52.929633 37958 sgd_solver.cpp:105] Iteration 33360, lr = 0.00803765
I1026 23:32:25.575326 37958 solver.cpp:221] Iteration 33400 (1.22532 iter/s, 32.6445s/40 iters), loss = 1.81676
I1026 23:32:25.575511 37958 solver.cpp:240]     Train net output #0: loss = 1.81676 (* 1 = 1.81676 loss)
I1026 23:32:25.575526 37958 sgd_solver.cpp:105] Iteration 33400, lr = 0.00803529
I1026 23:32:57.842851 37958 solver.cpp:221] Iteration 33440 (1.23969 iter/s, 32.2661s/40 iters), loss = 1.56899
I1026 23:32:57.843029 37958 solver.cpp:240]     Train net output #0: loss = 1.56899 (* 1 = 1.56899 loss)
I1026 23:32:57.843044 37958 sgd_solver.cpp:105] Iteration 33440, lr = 0.00803294
I1026 23:33:28.651000 37958 solver.cpp:221] Iteration 33480 (1.29841 iter/s, 30.8068s/40 iters), loss = 2.03833
I1026 23:33:28.651198 37958 solver.cpp:240]     Train net output #0: loss = 2.03833 (* 1 = 2.03833 loss)
I1026 23:33:28.651212 37958 sgd_solver.cpp:105] Iteration 33480, lr = 0.00803059
I1026 23:33:43.382877 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_33500.caffemodel
I1026 23:33:43.414860 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_33500.solverstate
I1026 23:33:43.432837 37958 solver.cpp:333] Iteration 33500, Testing net (#0)
I1026 23:34:14.037144 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 23:34:14.243243 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53204
I1026 23:34:14.243314 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77484
I1026 23:34:14.243327 37958 solver.cpp:400]     Test net output #2: loss = 2.08338 (* 1 = 2.08338 loss)
I1026 23:34:30.671989 37958 solver.cpp:221] Iteration 33520 (0.644969 iter/s, 62.0185s/40 iters), loss = 1.7154
I1026 23:34:30.672052 37958 solver.cpp:240]     Train net output #0: loss = 1.7154 (* 1 = 1.7154 loss)
I1026 23:34:30.672066 37958 sgd_solver.cpp:105] Iteration 33520, lr = 0.00802824
I1026 23:35:01.529937 37958 solver.cpp:221] Iteration 33560 (1.29631 iter/s, 30.8567s/40 iters), loss = 2.0929
I1026 23:35:01.530199 37958 solver.cpp:240]     Train net output #0: loss = 2.0929 (* 1 = 2.0929 loss)
I1026 23:35:01.530221 37958 sgd_solver.cpp:105] Iteration 33560, lr = 0.00802588
I1026 23:35:32.126497 37958 solver.cpp:221] Iteration 33600 (1.3074 iter/s, 30.5951s/40 iters), loss = 2.23111
I1026 23:35:32.126687 37958 solver.cpp:240]     Train net output #0: loss = 2.23111 (* 1 = 2.23111 loss)
I1026 23:35:32.126701 37958 sgd_solver.cpp:105] Iteration 33600, lr = 0.00802353
I1026 23:36:02.640776 37958 solver.cpp:221] Iteration 33640 (1.31092 iter/s, 30.5129s/40 iters), loss = 1.74694
I1026 23:36:02.640936 37958 solver.cpp:240]     Train net output #0: loss = 1.74694 (* 1 = 1.74694 loss)
I1026 23:36:02.640950 37958 sgd_solver.cpp:105] Iteration 33640, lr = 0.00802118
I1026 23:36:34.254050 37958 solver.cpp:221] Iteration 33680 (1.26535 iter/s, 31.6119s/40 iters), loss = 1.83832
I1026 23:36:34.254252 37958 solver.cpp:240]     Train net output #0: loss = 1.83832 (* 1 = 1.83832 loss)
I1026 23:36:34.254266 37958 sgd_solver.cpp:105] Iteration 33680, lr = 0.00801882
I1026 23:37:04.742566 37958 solver.cpp:221] Iteration 33720 (1.31203 iter/s, 30.4872s/40 iters), loss = 1.90962
I1026 23:37:04.742727 37958 solver.cpp:240]     Train net output #0: loss = 1.90962 (* 1 = 1.90962 loss)
I1026 23:37:04.742741 37958 sgd_solver.cpp:105] Iteration 33720, lr = 0.00801647
I1026 23:37:35.216634 37958 solver.cpp:221] Iteration 33760 (1.31265 iter/s, 30.4728s/40 iters), loss = 1.49231
I1026 23:37:35.216825 37958 solver.cpp:240]     Train net output #0: loss = 1.49231 (* 1 = 1.49231 loss)
I1026 23:37:35.216856 37958 sgd_solver.cpp:105] Iteration 33760, lr = 0.00801412
I1026 23:38:05.735273 37958 solver.cpp:221] Iteration 33800 (1.31073 iter/s, 30.5173s/40 iters), loss = 1.94003
I1026 23:38:05.735472 37958 solver.cpp:240]     Train net output #0: loss = 1.94003 (* 1 = 1.94003 loss)
I1026 23:38:05.735496 37958 sgd_solver.cpp:105] Iteration 33800, lr = 0.00801176
I1026 23:38:36.163802 37958 solver.cpp:221] Iteration 33840 (1.31461 iter/s, 30.4272s/40 iters), loss = 2.04095
I1026 23:38:36.163976 37958 solver.cpp:240]     Train net output #0: loss = 2.04095 (* 1 = 2.04095 loss)
I1026 23:38:36.163990 37958 sgd_solver.cpp:105] Iteration 33840, lr = 0.00800941
I1026 23:39:06.459328 37958 solver.cpp:221] Iteration 33880 (1.32038 iter/s, 30.2942s/40 iters), loss = 1.91597
I1026 23:39:06.459476 37958 solver.cpp:240]     Train net output #0: loss = 1.91597 (* 1 = 1.91597 loss)
I1026 23:39:06.459491 37958 sgd_solver.cpp:105] Iteration 33880, lr = 0.00800706
I1026 23:39:36.697881 37958 solver.cpp:221] Iteration 33920 (1.32287 iter/s, 30.2373s/40 iters), loss = 1.79649
I1026 23:39:36.698027 37958 solver.cpp:240]     Train net output #0: loss = 1.79649 (* 1 = 1.79649 loss)
I1026 23:39:36.698042 37958 sgd_solver.cpp:105] Iteration 33920, lr = 0.00800471
I1026 23:40:06.908926 37958 solver.cpp:221] Iteration 33960 (1.32408 iter/s, 30.2098s/40 iters), loss = 2.19332
I1026 23:40:06.909087 37958 solver.cpp:240]     Train net output #0: loss = 2.19332 (* 1 = 2.19332 loss)
I1026 23:40:06.909102 37958 sgd_solver.cpp:105] Iteration 33960, lr = 0.00800235
I1026 23:40:36.523113 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_34000.caffemodel
I1026 23:40:36.556213 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_34000.solverstate
I1026 23:40:36.574355 37958 solver.cpp:333] Iteration 34000, Testing net (#0)
I1026 23:41:07.384922 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.5244
I1026 23:41:07.385133 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76636
I1026 23:41:07.385148 37958 solver.cpp:400]     Test net output #2: loss = 2.12176 (* 1 = 2.12176 loss)
I1026 23:41:08.147351 37958 solver.cpp:221] Iteration 34000 (0.653211 iter/s, 61.236s/40 iters), loss = 1.97375
I1026 23:41:08.147408 37958 solver.cpp:240]     Train net output #0: loss = 1.97375 (* 1 = 1.97375 loss)
I1026 23:41:08.147423 37958 sgd_solver.cpp:105] Iteration 34000, lr = 0.008
I1026 23:41:38.338970 37958 solver.cpp:221] Iteration 34040 (1.32492 iter/s, 30.1904s/40 iters), loss = 1.783
I1026 23:41:38.339128 37958 solver.cpp:240]     Train net output #0: loss = 1.783 (* 1 = 1.783 loss)
I1026 23:41:38.339143 37958 sgd_solver.cpp:105] Iteration 34040, lr = 0.00799765
I1026 23:42:08.615774 37958 solver.cpp:221] Iteration 34080 (1.3212 iter/s, 30.2755s/40 iters), loss = 1.92826
I1026 23:42:08.615926 37958 solver.cpp:240]     Train net output #0: loss = 1.92826 (* 1 = 1.92826 loss)
I1026 23:42:08.615939 37958 sgd_solver.cpp:105] Iteration 34080, lr = 0.00799529
I1026 23:42:38.955883 37958 solver.cpp:221] Iteration 34120 (1.31844 iter/s, 30.3388s/40 iters), loss = 1.80718
I1026 23:42:38.956048 37958 solver.cpp:240]     Train net output #0: loss = 1.80718 (* 1 = 1.80718 loss)
I1026 23:42:38.956063 37958 sgd_solver.cpp:105] Iteration 34120, lr = 0.00799294
I1026 23:43:09.521998 37958 solver.cpp:221] Iteration 34160 (1.3087 iter/s, 30.5648s/40 iters), loss = 1.94551
I1026 23:43:09.522172 37958 solver.cpp:240]     Train net output #0: loss = 1.94551 (* 1 = 1.94551 loss)
I1026 23:43:09.522187 37958 sgd_solver.cpp:105] Iteration 34160, lr = 0.00799059
I1026 23:43:39.822703 37958 solver.cpp:221] Iteration 34200 (1.32016 iter/s, 30.2994s/40 iters), loss = 1.73239
I1026 23:43:39.822860 37958 solver.cpp:240]     Train net output #0: loss = 1.73239 (* 1 = 1.73239 loss)
I1026 23:43:39.822875 37958 sgd_solver.cpp:105] Iteration 34200, lr = 0.00798823
I1026 23:44:10.116535 37958 solver.cpp:221] Iteration 34240 (1.32046 iter/s, 30.2925s/40 iters), loss = 1.91391
I1026 23:44:10.116698 37958 solver.cpp:240]     Train net output #0: loss = 1.91391 (* 1 = 1.91391 loss)
I1026 23:44:10.116713 37958 sgd_solver.cpp:105] Iteration 34240, lr = 0.00798588
I1026 23:44:41.270205 37958 solver.cpp:221] Iteration 34280 (1.28401 iter/s, 31.1523s/40 iters), loss = 1.61936
I1026 23:44:41.270478 37958 solver.cpp:240]     Train net output #0: loss = 1.61936 (* 1 = 1.61936 loss)
I1026 23:44:41.270509 37958 sgd_solver.cpp:105] Iteration 34280, lr = 0.00798353
I1026 23:45:12.392587 37958 solver.cpp:221] Iteration 34320 (1.28531 iter/s, 31.1209s/40 iters), loss = 2.14718
I1026 23:45:12.392810 37958 solver.cpp:240]     Train net output #0: loss = 2.14718 (* 1 = 2.14718 loss)
I1026 23:45:12.392832 37958 sgd_solver.cpp:105] Iteration 34320, lr = 0.00798118
I1026 23:45:44.550528 37958 solver.cpp:221] Iteration 34360 (1.24392 iter/s, 32.1565s/40 iters), loss = 1.60811
I1026 23:45:44.550701 37958 solver.cpp:240]     Train net output #0: loss = 1.60811 (* 1 = 1.60811 loss)
I1026 23:45:44.550716 37958 sgd_solver.cpp:105] Iteration 34360, lr = 0.00797882
I1026 23:46:16.256716 37958 solver.cpp:221] Iteration 34400 (1.26164 iter/s, 31.7048s/40 iters), loss = 2.15673
I1026 23:46:16.256980 37958 solver.cpp:240]     Train net output #0: loss = 2.15673 (* 1 = 2.15673 loss)
I1026 23:46:16.257002 37958 sgd_solver.cpp:105] Iteration 34400, lr = 0.00797647
I1026 23:46:47.401995 37958 solver.cpp:221] Iteration 34440 (1.28436 iter/s, 31.1438s/40 iters), loss = 1.86931
I1026 23:46:47.402185 37958 solver.cpp:240]     Train net output #0: loss = 1.86931 (* 1 = 1.86931 loss)
I1026 23:46:47.402199 37958 sgd_solver.cpp:105] Iteration 34440, lr = 0.00797412
I1026 23:47:18.546243 37958 solver.cpp:221] Iteration 34480 (1.2844 iter/s, 31.1429s/40 iters), loss = 1.52754
I1026 23:47:18.546448 37958 solver.cpp:240]     Train net output #0: loss = 1.52754 (* 1 = 1.52754 loss)
I1026 23:47:18.546463 37958 sgd_solver.cpp:105] Iteration 34480, lr = 0.00797176
I1026 23:47:33.257627 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_34500.caffemodel
I1026 23:47:33.296630 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_34500.solverstate
I1026 23:47:33.314496 37958 solver.cpp:333] Iteration 34500, Testing net (#0)
I1026 23:48:03.958195 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1026 23:48:04.165607 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53004
I1026 23:48:04.165660 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77088
I1026 23:48:04.165671 37958 solver.cpp:400]     Test net output #2: loss = 2.09906 (* 1 = 2.09906 loss)
I1026 23:48:20.514370 37958 solver.cpp:221] Iteration 34520 (0.64552 iter/s, 61.9656s/40 iters), loss = 1.76564
I1026 23:48:20.514457 37958 solver.cpp:240]     Train net output #0: loss = 1.76564 (* 1 = 1.76564 loss)
I1026 23:48:20.514477 37958 sgd_solver.cpp:105] Iteration 34520, lr = 0.00796941
I1026 23:48:52.142143 37958 solver.cpp:221] Iteration 34560 (1.26476 iter/s, 31.6265s/40 iters), loss = 1.77706
I1026 23:48:52.142321 37958 solver.cpp:240]     Train net output #0: loss = 1.77706 (* 1 = 1.77706 loss)
I1026 23:48:52.142340 37958 sgd_solver.cpp:105] Iteration 34560, lr = 0.00796706
I1026 23:49:23.268610 37958 solver.cpp:221] Iteration 34600 (1.28514 iter/s, 31.1251s/40 iters), loss = 1.72371
I1026 23:49:23.268836 37958 solver.cpp:240]     Train net output #0: loss = 1.72371 (* 1 = 1.72371 loss)
I1026 23:49:23.268857 37958 sgd_solver.cpp:105] Iteration 34600, lr = 0.00796471
I1026 23:50:09.787001 37958 solver.cpp:221] Iteration 34640 (0.859912 iter/s, 46.5164s/40 iters), loss = 1.74171
I1026 23:50:09.787250 37958 solver.cpp:240]     Train net output #0: loss = 1.74171 (* 1 = 1.74171 loss)
I1026 23:50:09.787269 37958 sgd_solver.cpp:105] Iteration 34640, lr = 0.00796235
I1026 23:51:15.346887 37958 solver.cpp:221] Iteration 34680 (0.610154 iter/s, 65.5572s/40 iters), loss = 1.96047
I1026 23:51:15.347141 37958 solver.cpp:240]     Train net output #0: loss = 1.96047 (* 1 = 1.96047 loss)
I1026 23:51:15.347164 37958 sgd_solver.cpp:105] Iteration 34680, lr = 0.00796
I1026 23:51:47.486768 37958 solver.cpp:221] Iteration 34720 (1.24462 iter/s, 32.1384s/40 iters), loss = 1.91967
I1026 23:51:47.486979 37958 solver.cpp:240]     Train net output #0: loss = 1.91967 (* 1 = 1.91967 loss)
I1026 23:51:47.486994 37958 sgd_solver.cpp:105] Iteration 34720, lr = 0.00795765
I1026 23:52:18.438241 37958 solver.cpp:221] Iteration 34760 (1.2924 iter/s, 30.9501s/40 iters), loss = 1.60311
I1026 23:52:18.438431 37958 solver.cpp:240]     Train net output #0: loss = 1.60311 (* 1 = 1.60311 loss)
I1026 23:52:18.438446 37958 sgd_solver.cpp:105] Iteration 34760, lr = 0.00795529
I1026 23:52:49.525662 37958 solver.cpp:221] Iteration 34800 (1.28675 iter/s, 31.0861s/40 iters), loss = 1.55611
I1026 23:52:49.525845 37958 solver.cpp:240]     Train net output #0: loss = 1.55611 (* 1 = 1.55611 loss)
I1026 23:52:49.525861 37958 sgd_solver.cpp:105] Iteration 34800, lr = 0.00795294
I1026 23:53:20.496409 37958 solver.cpp:221] Iteration 34840 (1.2916 iter/s, 30.9694s/40 iters), loss = 1.86703
I1026 23:53:20.496608 37958 solver.cpp:240]     Train net output #0: loss = 1.86703 (* 1 = 1.86703 loss)
I1026 23:53:20.496623 37958 sgd_solver.cpp:105] Iteration 34840, lr = 0.00795059
I1026 23:53:51.646173 37958 solver.cpp:221] Iteration 34880 (1.28417 iter/s, 31.1484s/40 iters), loss = 1.67759
I1026 23:53:51.646384 37958 solver.cpp:240]     Train net output #0: loss = 1.67759 (* 1 = 1.67759 loss)
I1026 23:53:51.646397 37958 sgd_solver.cpp:105] Iteration 34880, lr = 0.00794823
I1026 23:54:23.493490 37958 solver.cpp:221] Iteration 34920 (1.25605 iter/s, 31.8459s/40 iters), loss = 1.68249
I1026 23:54:23.493685 37958 solver.cpp:240]     Train net output #0: loss = 1.68249 (* 1 = 1.68249 loss)
I1026 23:54:23.493700 37958 sgd_solver.cpp:105] Iteration 34920, lr = 0.00794588
I1026 23:54:54.692679 37958 solver.cpp:221] Iteration 34960 (1.28214 iter/s, 31.1978s/40 iters), loss = 1.7857
I1026 23:54:54.692852 37958 solver.cpp:240]     Train net output #0: loss = 1.7857 (* 1 = 1.7857 loss)
I1026 23:54:54.692867 37958 sgd_solver.cpp:105] Iteration 34960, lr = 0.00794353
I1026 23:55:25.522778 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_35000.caffemodel
I1026 23:55:25.557032 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_35000.solverstate
I1026 23:55:25.576475 37958 solver.cpp:333] Iteration 35000, Testing net (#0)
I1026 23:55:56.435504 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52356
I1026 23:55:56.435641 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.7672
I1026 23:55:56.435654 37958 solver.cpp:400]     Test net output #2: loss = 2.12411 (* 1 = 2.12411 loss)
I1026 23:55:57.208603 37958 solver.cpp:221] Iteration 35000 (0.639863 iter/s, 62.5134s/40 iters), loss = 1.8441
I1026 23:55:57.208669 37958 solver.cpp:240]     Train net output #0: loss = 1.8441 (* 1 = 1.8441 loss)
I1026 23:55:57.208685 37958 sgd_solver.cpp:105] Iteration 35000, lr = 0.00794118
I1026 23:56:18.383219 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1026 23:56:27.924613 37958 solver.cpp:221] Iteration 35040 (1.3023 iter/s, 30.7148s/40 iters), loss = 1.8317
I1026 23:56:27.924783 37958 solver.cpp:240]     Train net output #0: loss = 1.8317 (* 1 = 1.8317 loss)
I1026 23:56:27.924798 37958 sgd_solver.cpp:105] Iteration 35040, lr = 0.00793882
I1026 23:56:58.539321 37958 solver.cpp:221] Iteration 35080 (1.30662 iter/s, 30.6134s/40 iters), loss = 1.34837
I1026 23:56:58.539508 37958 solver.cpp:240]     Train net output #0: loss = 1.34837 (* 1 = 1.34837 loss)
I1026 23:56:58.539523 37958 sgd_solver.cpp:105] Iteration 35080, lr = 0.00793647
I1026 23:57:28.607723 37958 solver.cpp:221] Iteration 35120 (1.33036 iter/s, 30.0671s/40 iters), loss = 1.6123
I1026 23:57:28.607869 37958 solver.cpp:240]     Train net output #0: loss = 1.6123 (* 1 = 1.6123 loss)
I1026 23:57:28.607883 37958 sgd_solver.cpp:105] Iteration 35120, lr = 0.00793412
I1026 23:57:59.014228 37958 solver.cpp:221] Iteration 35160 (1.31556 iter/s, 30.4052s/40 iters), loss = 1.62756
I1026 23:57:59.014453 37958 solver.cpp:240]     Train net output #0: loss = 1.62756 (* 1 = 1.62756 loss)
I1026 23:57:59.014498 37958 sgd_solver.cpp:105] Iteration 35160, lr = 0.00793176
I1026 23:58:29.603770 37958 solver.cpp:221] Iteration 35200 (1.3077 iter/s, 30.5882s/40 iters), loss = 1.7854
I1026 23:58:29.603996 37958 solver.cpp:240]     Train net output #0: loss = 1.7854 (* 1 = 1.7854 loss)
I1026 23:58:29.604012 37958 sgd_solver.cpp:105] Iteration 35200, lr = 0.00792941
I1026 23:59:00.771862 37958 solver.cpp:221] Iteration 35240 (1.28342 iter/s, 31.1667s/40 iters), loss = 1.75776
I1026 23:59:00.772027 37958 solver.cpp:240]     Train net output #0: loss = 1.75776 (* 1 = 1.75776 loss)
I1026 23:59:00.772042 37958 sgd_solver.cpp:105] Iteration 35240, lr = 0.00792706
I1026 23:59:31.940845 37958 solver.cpp:221] Iteration 35280 (1.28338 iter/s, 31.1676s/40 iters), loss = 1.93874
I1026 23:59:31.941043 37958 solver.cpp:240]     Train net output #0: loss = 1.93874 (* 1 = 1.93874 loss)
I1026 23:59:31.941058 37958 sgd_solver.cpp:105] Iteration 35280, lr = 0.00792471
I1027 00:00:02.395596 37958 solver.cpp:221] Iteration 35320 (1.31348 iter/s, 30.4534s/40 iters), loss = 1.52756
I1027 00:00:02.395768 37958 solver.cpp:240]     Train net output #0: loss = 1.52756 (* 1 = 1.52756 loss)
I1027 00:00:02.395783 37958 sgd_solver.cpp:105] Iteration 35320, lr = 0.00792235
I1027 00:00:33.225600 37958 solver.cpp:221] Iteration 35360 (1.29749 iter/s, 30.8287s/40 iters), loss = 1.56
I1027 00:00:33.225798 37958 solver.cpp:240]     Train net output #0: loss = 1.56 (* 1 = 1.56 loss)
I1027 00:00:33.225813 37958 sgd_solver.cpp:105] Iteration 35360, lr = 0.00792
I1027 00:01:03.866497 37958 solver.cpp:221] Iteration 35400 (1.3055 iter/s, 30.6395s/40 iters), loss = 1.80028
I1027 00:01:03.866684 37958 solver.cpp:240]     Train net output #0: loss = 1.80028 (* 1 = 1.80028 loss)
I1027 00:01:03.866699 37958 sgd_solver.cpp:105] Iteration 35400, lr = 0.00791765
I1027 00:01:34.572042 37958 solver.cpp:221] Iteration 35440 (1.30275 iter/s, 30.7042s/40 iters), loss = 1.87742
I1027 00:01:34.572244 37958 solver.cpp:240]     Train net output #0: loss = 1.87742 (* 1 = 1.87742 loss)
I1027 00:01:34.572259 37958 sgd_solver.cpp:105] Iteration 35440, lr = 0.00791529
I1027 00:02:05.997126 37958 solver.cpp:221] Iteration 35480 (1.27292 iter/s, 31.4237s/40 iters), loss = 1.63401
I1027 00:02:05.997319 37958 solver.cpp:240]     Train net output #0: loss = 1.63401 (* 1 = 1.63401 loss)
I1027 00:02:05.997335 37958 sgd_solver.cpp:105] Iteration 35480, lr = 0.00791294
I1027 00:02:21.464938 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_35500.caffemodel
I1027 00:02:21.497685 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_35500.solverstate
I1027 00:02:21.515452 37958 solver.cpp:333] Iteration 35500, Testing net (#0)
I1027 00:02:52.153942 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 00:02:52.360069 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53012
I1027 00:02:52.360108 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76948
I1027 00:02:52.360118 37958 solver.cpp:400]     Test net output #2: loss = 2.09009 (* 1 = 2.09009 loss)
I1027 00:03:08.784530 37958 solver.cpp:221] Iteration 35520 (0.637096 iter/s, 62.7849s/40 iters), loss = 1.74192
I1027 00:03:08.784613 37958 solver.cpp:240]     Train net output #0: loss = 1.74192 (* 1 = 1.74192 loss)
I1027 00:03:08.784631 37958 sgd_solver.cpp:105] Iteration 35520, lr = 0.00791059
I1027 00:03:39.958693 37958 solver.cpp:221] Iteration 35560 (1.28317 iter/s, 31.1729s/40 iters), loss = 1.71387
I1027 00:03:39.958899 37958 solver.cpp:240]     Train net output #0: loss = 1.71387 (* 1 = 1.71387 loss)
I1027 00:03:39.958914 37958 sgd_solver.cpp:105] Iteration 35560, lr = 0.00790824
I1027 00:04:10.982239 37958 solver.cpp:221] Iteration 35600 (1.2894 iter/s, 31.0222s/40 iters), loss = 1.9572
I1027 00:04:10.982502 37958 solver.cpp:240]     Train net output #0: loss = 1.9572 (* 1 = 1.9572 loss)
I1027 00:04:10.982524 37958 sgd_solver.cpp:105] Iteration 35600, lr = 0.00790588
I1027 00:04:42.164852 37958 solver.cpp:221] Iteration 35640 (1.28283 iter/s, 31.1812s/40 iters), loss = 1.9836
I1027 00:04:42.165042 37958 solver.cpp:240]     Train net output #0: loss = 1.9836 (* 1 = 1.9836 loss)
I1027 00:04:42.165056 37958 sgd_solver.cpp:105] Iteration 35640, lr = 0.00790353
I1027 00:05:13.128376 37958 solver.cpp:221] Iteration 35680 (1.2919 iter/s, 30.9622s/40 iters), loss = 1.73878
I1027 00:05:13.128573 37958 solver.cpp:240]     Train net output #0: loss = 1.73878 (* 1 = 1.73878 loss)
I1027 00:05:13.128588 37958 sgd_solver.cpp:105] Iteration 35680, lr = 0.00790118
I1027 00:05:43.912576 37958 solver.cpp:221] Iteration 35720 (1.29943 iter/s, 30.7828s/40 iters), loss = 1.77174
I1027 00:05:43.912752 37958 solver.cpp:240]     Train net output #0: loss = 1.77174 (* 1 = 1.77174 loss)
I1027 00:05:43.912766 37958 sgd_solver.cpp:105] Iteration 35720, lr = 0.00789882
I1027 00:06:14.322000 37958 solver.cpp:221] Iteration 35760 (1.31544 iter/s, 30.4081s/40 iters), loss = 1.60262
I1027 00:06:14.322229 37958 solver.cpp:240]     Train net output #0: loss = 1.60262 (* 1 = 1.60262 loss)
I1027 00:06:14.322244 37958 sgd_solver.cpp:105] Iteration 35760, lr = 0.00789647
I1027 00:06:44.731801 37958 solver.cpp:221] Iteration 35800 (1.31543 iter/s, 30.4084s/40 iters), loss = 1.60039
I1027 00:06:44.731989 37958 solver.cpp:240]     Train net output #0: loss = 1.60039 (* 1 = 1.60039 loss)
I1027 00:06:44.732004 37958 sgd_solver.cpp:105] Iteration 35800, lr = 0.00789412
I1027 00:07:15.183578 37958 solver.cpp:221] Iteration 35840 (1.31361 iter/s, 30.4504s/40 iters), loss = 1.88784
I1027 00:07:15.183781 37958 solver.cpp:240]     Train net output #0: loss = 1.88784 (* 1 = 1.88784 loss)
I1027 00:07:15.183795 37958 sgd_solver.cpp:105] Iteration 35840, lr = 0.00789176
I1027 00:07:45.924983 37958 solver.cpp:221] Iteration 35880 (1.30124 iter/s, 30.74s/40 iters), loss = 1.60142
I1027 00:07:45.925184 37958 solver.cpp:240]     Train net output #0: loss = 1.60142 (* 1 = 1.60142 loss)
I1027 00:07:45.925200 37958 sgd_solver.cpp:105] Iteration 35880, lr = 0.00788941
I1027 00:08:16.615136 37958 solver.cpp:221] Iteration 35920 (1.30341 iter/s, 30.6888s/40 iters), loss = 1.69668
I1027 00:08:16.615321 37958 solver.cpp:240]     Train net output #0: loss = 1.69668 (* 1 = 1.69668 loss)
I1027 00:08:16.615337 37958 sgd_solver.cpp:105] Iteration 35920, lr = 0.00788706
I1027 00:08:47.076736 37958 solver.cpp:221] Iteration 35960 (1.31319 iter/s, 30.4603s/40 iters), loss = 1.83192
I1027 00:08:47.076917 37958 solver.cpp:240]     Train net output #0: loss = 1.83192 (* 1 = 1.83192 loss)
I1027 00:08:47.076932 37958 sgd_solver.cpp:105] Iteration 35960, lr = 0.00788471
I1027 00:09:16.682021 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_36000.caffemodel
I1027 00:09:16.713907 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_36000.solverstate
I1027 00:09:16.731752 37958 solver.cpp:333] Iteration 36000, Testing net (#0)
I1027 00:09:47.651094 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52792
I1027 00:09:47.651295 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.771599
I1027 00:09:47.651314 37958 solver.cpp:400]     Test net output #2: loss = 2.10659 (* 1 = 2.10659 loss)
I1027 00:09:48.417865 37958 solver.cpp:221] Iteration 36000 (0.652117 iter/s, 61.3386s/40 iters), loss = 2.00396
I1027 00:09:48.417909 37958 solver.cpp:240]     Train net output #0: loss = 2.00396 (* 1 = 2.00396 loss)
I1027 00:09:48.417924 37958 sgd_solver.cpp:105] Iteration 36000, lr = 0.00788235
I1027 00:10:18.803381 37958 solver.cpp:221] Iteration 36040 (1.31647 iter/s, 30.3843s/40 iters), loss = 1.64979
I1027 00:10:18.803582 37958 solver.cpp:240]     Train net output #0: loss = 1.64979 (* 1 = 1.64979 loss)
I1027 00:10:18.803597 37958 sgd_solver.cpp:105] Iteration 36040, lr = 0.00788
I1027 00:10:49.644109 37958 solver.cpp:221] Iteration 36080 (1.29704 iter/s, 30.8393s/40 iters), loss = 1.99602
I1027 00:10:49.644373 37958 solver.cpp:240]     Train net output #0: loss = 1.99602 (* 1 = 1.99602 loss)
I1027 00:10:49.644390 37958 sgd_solver.cpp:105] Iteration 36080, lr = 0.00787765
I1027 00:11:20.785104 37958 solver.cpp:221] Iteration 36120 (1.28454 iter/s, 31.1395s/40 iters), loss = 1.65309
I1027 00:11:20.785315 37958 solver.cpp:240]     Train net output #0: loss = 1.65309 (* 1 = 1.65309 loss)
I1027 00:11:20.785331 37958 sgd_solver.cpp:105] Iteration 36120, lr = 0.00787529
I1027 00:11:51.642828 37958 solver.cpp:221] Iteration 36160 (1.29633 iter/s, 30.8563s/40 iters), loss = 1.84984
I1027 00:11:51.643023 37958 solver.cpp:240]     Train net output #0: loss = 1.84984 (* 1 = 1.84984 loss)
I1027 00:11:51.643038 37958 sgd_solver.cpp:105] Iteration 36160, lr = 0.00787294
I1027 00:12:22.479285 37958 solver.cpp:221] Iteration 36200 (1.29722 iter/s, 30.8351s/40 iters), loss = 1.75825
I1027 00:12:22.479478 37958 solver.cpp:240]     Train net output #0: loss = 1.75825 (* 1 = 1.75825 loss)
I1027 00:12:22.479493 37958 sgd_solver.cpp:105] Iteration 36200, lr = 0.00787059
I1027 00:12:53.500556 37958 solver.cpp:221] Iteration 36240 (1.28949 iter/s, 31.0199s/40 iters), loss = 1.73008
I1027 00:12:53.500733 37958 solver.cpp:240]     Train net output #0: loss = 1.73008 (* 1 = 1.73008 loss)
I1027 00:12:53.500748 37958 sgd_solver.cpp:105] Iteration 36240, lr = 0.00786823
I1027 00:13:24.024281 37958 solver.cpp:221] Iteration 36280 (1.31051 iter/s, 30.5224s/40 iters), loss = 1.8049
I1027 00:13:24.024461 37958 solver.cpp:240]     Train net output #0: loss = 1.8049 (* 1 = 1.8049 loss)
I1027 00:13:24.024477 37958 sgd_solver.cpp:105] Iteration 36280, lr = 0.00786588
I1027 00:13:54.647691 37958 solver.cpp:221] Iteration 36320 (1.30625 iter/s, 30.6221s/40 iters), loss = 1.84318
I1027 00:13:54.647909 37958 solver.cpp:240]     Train net output #0: loss = 1.84318 (* 1 = 1.84318 loss)
I1027 00:13:54.647931 37958 sgd_solver.cpp:105] Iteration 36320, lr = 0.00786353
I1027 00:14:25.829030 37958 solver.cpp:221] Iteration 36360 (1.28288 iter/s, 31.1799s/40 iters), loss = 1.75708
I1027 00:14:25.829254 37958 solver.cpp:240]     Train net output #0: loss = 1.75708 (* 1 = 1.75708 loss)
I1027 00:14:25.829278 37958 sgd_solver.cpp:105] Iteration 36360, lr = 0.00786118
I1027 00:14:57.009109 37958 solver.cpp:221] Iteration 36400 (1.28293 iter/s, 31.1787s/40 iters), loss = 1.86047
I1027 00:14:57.009279 37958 solver.cpp:240]     Train net output #0: loss = 1.86047 (* 1 = 1.86047 loss)
I1027 00:14:57.009294 37958 sgd_solver.cpp:105] Iteration 36400, lr = 0.00785882
I1027 00:15:28.365366 37958 solver.cpp:221] Iteration 36440 (1.27572 iter/s, 31.3549s/40 iters), loss = 1.80321
I1027 00:15:28.365558 37958 solver.cpp:240]     Train net output #0: loss = 1.80321 (* 1 = 1.80321 loss)
I1027 00:15:28.365573 37958 sgd_solver.cpp:105] Iteration 36440, lr = 0.00785647
I1027 00:16:00.795321 37958 solver.cpp:221] Iteration 36480 (1.23348 iter/s, 32.4285s/40 iters), loss = 1.95244
I1027 00:16:00.795531 37958 solver.cpp:240]     Train net output #0: loss = 1.95244 (* 1 = 1.95244 loss)
I1027 00:16:00.795547 37958 sgd_solver.cpp:105] Iteration 36480, lr = 0.00785412
I1027 00:16:15.881466 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_36500.caffemodel
I1027 00:16:15.913309 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_36500.solverstate
I1027 00:16:15.931759 37958 solver.cpp:333] Iteration 36500, Testing net (#0)
I1027 00:16:46.854583 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 00:16:47.065801 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52376
I1027 00:16:47.065860 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.771
I1027 00:16:47.065871 37958 solver.cpp:400]     Test net output #2: loss = 2.12125 (* 1 = 2.12125 loss)
I1027 00:17:04.197711 37958 solver.cpp:221] Iteration 36520 (0.630917 iter/s, 63.3998s/40 iters), loss = 2.00158
I1027 00:17:04.197798 37958 solver.cpp:240]     Train net output #0: loss = 2.00158 (* 1 = 2.00158 loss)
I1027 00:17:04.197832 37958 sgd_solver.cpp:105] Iteration 36520, lr = 0.00785176
I1027 00:17:35.142588 37958 solver.cpp:221] Iteration 36560 (1.29267 iter/s, 30.9436s/40 iters), loss = 1.93029
I1027 00:17:35.142845 37958 solver.cpp:240]     Train net output #0: loss = 1.93029 (* 1 = 1.93029 loss)
I1027 00:17:35.142861 37958 sgd_solver.cpp:105] Iteration 36560, lr = 0.00784941
I1027 00:18:06.129420 37958 solver.cpp:221] Iteration 36600 (1.29093 iter/s, 30.9854s/40 iters), loss = 1.82274
I1027 00:18:06.129606 37958 solver.cpp:240]     Train net output #0: loss = 1.82274 (* 1 = 1.82274 loss)
I1027 00:18:06.129619 37958 sgd_solver.cpp:105] Iteration 36600, lr = 0.00784706
I1027 00:18:36.822351 37958 solver.cpp:221] Iteration 36640 (1.30329 iter/s, 30.6916s/40 iters), loss = 1.5232
I1027 00:18:36.822530 37958 solver.cpp:240]     Train net output #0: loss = 1.5232 (* 1 = 1.5232 loss)
I1027 00:18:36.822544 37958 sgd_solver.cpp:105] Iteration 36640, lr = 0.00784471
I1027 00:19:07.520231 37958 solver.cpp:221] Iteration 36680 (1.30308 iter/s, 30.6965s/40 iters), loss = 1.87329
I1027 00:19:07.520351 37958 solver.cpp:240]     Train net output #0: loss = 1.87329 (* 1 = 1.87329 loss)
I1027 00:19:07.520365 37958 sgd_solver.cpp:105] Iteration 36680, lr = 0.00784235
I1027 00:19:38.075026 37958 solver.cpp:221] Iteration 36720 (1.30918 iter/s, 30.5535s/40 iters), loss = 2.02622
I1027 00:19:38.075167 37958 solver.cpp:240]     Train net output #0: loss = 2.02622 (* 1 = 2.02622 loss)
I1027 00:19:38.075181 37958 sgd_solver.cpp:105] Iteration 36720, lr = 0.00784
I1027 00:20:10.441926 37958 solver.cpp:221] Iteration 36760 (1.23588 iter/s, 32.3655s/40 iters), loss = 1.983
I1027 00:20:10.442174 37958 solver.cpp:240]     Train net output #0: loss = 1.983 (* 1 = 1.983 loss)
I1027 00:20:10.442193 37958 sgd_solver.cpp:105] Iteration 36760, lr = 0.00783765
I1027 00:20:51.838289 37958 solver.cpp:221] Iteration 36800 (0.966311 iter/s, 41.3946s/40 iters), loss = 2.01817
I1027 00:20:51.838500 37958 solver.cpp:240]     Train net output #0: loss = 2.01817 (* 1 = 2.01817 loss)
I1027 00:20:51.838515 37958 sgd_solver.cpp:105] Iteration 36800, lr = 0.00783529
I1027 00:21:22.421813 37958 solver.cpp:221] Iteration 36840 (1.30795 iter/s, 30.5822s/40 iters), loss = 2.25343
I1027 00:21:22.421998 37958 solver.cpp:240]     Train net output #0: loss = 2.25343 (* 1 = 2.25343 loss)
I1027 00:21:22.422013 37958 sgd_solver.cpp:105] Iteration 36840, lr = 0.00783294
I1027 00:21:53.455356 37958 solver.cpp:221] Iteration 36880 (1.28898 iter/s, 31.0322s/40 iters), loss = 1.76696
I1027 00:21:53.455579 37958 solver.cpp:240]     Train net output #0: loss = 1.76696 (* 1 = 1.76696 loss)
I1027 00:21:53.455593 37958 sgd_solver.cpp:105] Iteration 36880, lr = 0.00783059
I1027 00:22:25.474247 37958 solver.cpp:221] Iteration 36920 (1.24932 iter/s, 32.0175s/40 iters), loss = 2.08799
I1027 00:22:25.474504 37958 solver.cpp:240]     Train net output #0: loss = 2.08799 (* 1 = 2.08799 loss)
I1027 00:22:25.474526 37958 sgd_solver.cpp:105] Iteration 36920, lr = 0.00782824
I1027 00:23:02.051573 37958 solver.cpp:221] Iteration 36960 (1.09362 iter/s, 36.5757s/40 iters), loss = 1.85712
I1027 00:23:02.051815 37958 solver.cpp:240]     Train net output #0: loss = 1.85712 (* 1 = 1.85712 loss)
I1027 00:23:02.051838 37958 sgd_solver.cpp:105] Iteration 36960, lr = 0.00782588
I1027 00:23:33.778218 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_37000.caffemodel
I1027 00:23:33.811753 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_37000.solverstate
I1027 00:23:33.831118 37958 solver.cpp:333] Iteration 37000, Testing net (#0)
I1027 00:24:04.765183 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53488
I1027 00:24:04.765599 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77228
I1027 00:24:04.765612 37958 solver.cpp:400]     Test net output #2: loss = 2.06492 (* 1 = 2.06492 loss)
I1027 00:24:05.538202 37958 solver.cpp:221] Iteration 37000 (0.63008 iter/s, 63.484s/40 iters), loss = 1.63132
I1027 00:24:05.538276 37958 solver.cpp:240]     Train net output #0: loss = 1.63132 (* 1 = 1.63132 loss)
I1027 00:24:05.538290 37958 sgd_solver.cpp:105] Iteration 37000, lr = 0.00782353
I1027 00:24:36.421337 37958 solver.cpp:221] Iteration 37040 (1.29526 iter/s, 30.8819s/40 iters), loss = 2.00988
I1027 00:24:36.421602 37958 solver.cpp:240]     Train net output #0: loss = 2.00988 (* 1 = 2.00988 loss)
I1027 00:24:36.421633 37958 sgd_solver.cpp:105] Iteration 37040, lr = 0.00782118
I1027 00:25:07.753643 37958 solver.cpp:221] Iteration 37080 (1.2767 iter/s, 31.3309s/40 iters), loss = 1.65626
I1027 00:25:07.753816 37958 solver.cpp:240]     Train net output #0: loss = 1.65626 (* 1 = 1.65626 loss)
I1027 00:25:07.753831 37958 sgd_solver.cpp:105] Iteration 37080, lr = 0.00781882
I1027 00:25:38.791508 37958 solver.cpp:221] Iteration 37120 (1.2888 iter/s, 31.0365s/40 iters), loss = 2.01434
I1027 00:25:38.791684 37958 solver.cpp:240]     Train net output #0: loss = 2.01434 (* 1 = 2.01434 loss)
I1027 00:25:38.791698 37958 sgd_solver.cpp:105] Iteration 37120, lr = 0.00781647
I1027 00:26:09.635877 37958 solver.cpp:221] Iteration 37160 (1.29689 iter/s, 30.843s/40 iters), loss = 2.0653
I1027 00:26:09.636055 37958 solver.cpp:240]     Train net output #0: loss = 2.0653 (* 1 = 2.0653 loss)
I1027 00:26:09.636070 37958 sgd_solver.cpp:105] Iteration 37160, lr = 0.00781412
I1027 00:26:40.673337 37958 solver.cpp:221] Iteration 37200 (1.28882 iter/s, 31.0361s/40 iters), loss = 1.72253
I1027 00:26:40.673552 37958 solver.cpp:240]     Train net output #0: loss = 1.72253 (* 1 = 1.72253 loss)
I1027 00:26:40.673589 37958 sgd_solver.cpp:105] Iteration 37200, lr = 0.00781176
I1027 00:27:12.502732 37958 solver.cpp:221] Iteration 37240 (1.25676 iter/s, 31.828s/40 iters), loss = 1.5687
I1027 00:27:12.502992 37958 solver.cpp:240]     Train net output #0: loss = 1.5687 (* 1 = 1.5687 loss)
I1027 00:27:12.503015 37958 sgd_solver.cpp:105] Iteration 37240, lr = 0.00780941
I1027 00:27:43.401814 37958 solver.cpp:221] Iteration 37280 (1.2946 iter/s, 30.8977s/40 iters), loss = 1.73371
I1027 00:27:43.401988 37958 solver.cpp:240]     Train net output #0: loss = 1.73371 (* 1 = 1.73371 loss)
I1027 00:27:43.402003 37958 sgd_solver.cpp:105] Iteration 37280, lr = 0.00780706
I1027 00:28:13.920454 37958 solver.cpp:221] Iteration 37320 (1.31073 iter/s, 30.5173s/40 iters), loss = 1.59194
I1027 00:28:13.920667 37958 solver.cpp:240]     Train net output #0: loss = 1.59194 (* 1 = 1.59194 loss)
I1027 00:28:13.920682 37958 sgd_solver.cpp:105] Iteration 37320, lr = 0.00780471
I1027 00:28:44.446419 37958 solver.cpp:221] Iteration 37360 (1.31042 iter/s, 30.5246s/40 iters), loss = 1.94109
I1027 00:28:44.446636 37958 solver.cpp:240]     Train net output #0: loss = 1.94109 (* 1 = 1.94109 loss)
I1027 00:28:44.446651 37958 sgd_solver.cpp:105] Iteration 37360, lr = 0.00780235
I1027 00:29:14.827039 37958 solver.cpp:221] Iteration 37400 (1.31669 iter/s, 30.3792s/40 iters), loss = 1.79415
I1027 00:29:14.827200 37958 solver.cpp:240]     Train net output #0: loss = 1.79415 (* 1 = 1.79415 loss)
I1027 00:29:14.827215 37958 sgd_solver.cpp:105] Iteration 37400, lr = 0.0078
I1027 00:29:45.419353 37958 solver.cpp:221] Iteration 37440 (1.30757 iter/s, 30.591s/40 iters), loss = 1.76705
I1027 00:29:45.419528 37958 solver.cpp:240]     Train net output #0: loss = 1.76705 (* 1 = 1.76705 loss)
I1027 00:29:45.419543 37958 sgd_solver.cpp:105] Iteration 37440, lr = 0.00779765
I1027 00:30:15.972731 37958 solver.cpp:221] Iteration 37480 (1.30924 iter/s, 30.552s/40 iters), loss = 1.81821
I1027 00:30:15.972909 37958 solver.cpp:240]     Train net output #0: loss = 1.81821 (* 1 = 1.81821 loss)
I1027 00:30:15.972924 37958 sgd_solver.cpp:105] Iteration 37480, lr = 0.00779529
I1027 00:30:30.383750 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_37500.caffemodel
I1027 00:30:30.418911 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_37500.solverstate
I1027 00:30:30.438933 37958 solver.cpp:333] Iteration 37500, Testing net (#0)
I1027 00:31:01.132012 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 00:31:01.340762 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52116
I1027 00:31:01.340818 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76876
I1027 00:31:01.340831 37958 solver.cpp:400]     Test net output #2: loss = 2.13754 (* 1 = 2.13754 loss)
I1027 00:31:17.291355 37958 solver.cpp:221] Iteration 37520 (0.652357 iter/s, 61.3161s/40 iters), loss = 1.69373
I1027 00:31:17.291427 37958 solver.cpp:240]     Train net output #0: loss = 1.69373 (* 1 = 1.69373 loss)
I1027 00:31:17.291442 37958 sgd_solver.cpp:105] Iteration 37520, lr = 0.00779294
I1027 00:31:24.927109 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1027 00:31:48.074932 37958 solver.cpp:221] Iteration 37560 (1.29945 iter/s, 30.7823s/40 iters), loss = 1.98889
I1027 00:31:48.075153 37958 solver.cpp:240]     Train net output #0: loss = 1.98889 (* 1 = 1.98889 loss)
I1027 00:31:48.075170 37958 sgd_solver.cpp:105] Iteration 37560, lr = 0.00779059
I1027 00:32:18.937199 37958 solver.cpp:221] Iteration 37600 (1.29614 iter/s, 30.8609s/40 iters), loss = 1.58143
I1027 00:32:18.937352 37958 solver.cpp:240]     Train net output #0: loss = 1.58143 (* 1 = 1.58143 loss)
I1027 00:32:18.937366 37958 sgd_solver.cpp:105] Iteration 37600, lr = 0.00778823
I1027 00:32:49.631117 37958 solver.cpp:221] Iteration 37640 (1.30325 iter/s, 30.6926s/40 iters), loss = 1.65484
I1027 00:32:49.631281 37958 solver.cpp:240]     Train net output #0: loss = 1.65484 (* 1 = 1.65484 loss)
I1027 00:32:49.631309 37958 sgd_solver.cpp:105] Iteration 37640, lr = 0.00778588
I1027 00:33:19.838898 37958 solver.cpp:221] Iteration 37680 (1.32422 iter/s, 30.2065s/40 iters), loss = 1.86489
I1027 00:33:19.839035 37958 solver.cpp:240]     Train net output #0: loss = 1.86489 (* 1 = 1.86489 loss)
I1027 00:33:19.839049 37958 sgd_solver.cpp:105] Iteration 37680, lr = 0.00778353
I1027 00:33:50.380403 37958 solver.cpp:221] Iteration 37720 (1.30975 iter/s, 30.5402s/40 iters), loss = 2.05606
I1027 00:33:50.380615 37958 solver.cpp:240]     Train net output #0: loss = 2.05606 (* 1 = 2.05606 loss)
I1027 00:33:50.380635 37958 sgd_solver.cpp:105] Iteration 37720, lr = 0.00778118
I1027 00:34:21.891690 37958 solver.cpp:221] Iteration 37760 (1.26944 iter/s, 31.5099s/40 iters), loss = 1.7153
I1027 00:34:21.891887 37958 solver.cpp:240]     Train net output #0: loss = 1.7153 (* 1 = 1.7153 loss)
I1027 00:34:21.891909 37958 sgd_solver.cpp:105] Iteration 37760, lr = 0.00777882
I1027 00:34:54.184223 37958 solver.cpp:221] Iteration 37800 (1.23873 iter/s, 32.2911s/40 iters), loss = 1.82886
I1027 00:34:54.184453 37958 solver.cpp:240]     Train net output #0: loss = 1.82886 (* 1 = 1.82886 loss)
I1027 00:34:54.184476 37958 sgd_solver.cpp:105] Iteration 37800, lr = 0.00777647
I1027 00:35:26.443023 37958 solver.cpp:221] Iteration 37840 (1.24003 iter/s, 32.2574s/40 iters), loss = 1.55514
I1027 00:35:26.443199 37958 solver.cpp:240]     Train net output #0: loss = 1.55514 (* 1 = 1.55514 loss)
I1027 00:35:26.443214 37958 sgd_solver.cpp:105] Iteration 37840, lr = 0.00777412
I1027 00:35:57.105707 37958 solver.cpp:221] Iteration 37880 (1.30457 iter/s, 30.6613s/40 iters), loss = 1.7537
I1027 00:35:57.105898 37958 solver.cpp:240]     Train net output #0: loss = 1.7537 (* 1 = 1.7537 loss)
I1027 00:35:57.105913 37958 sgd_solver.cpp:105] Iteration 37880, lr = 0.00777176
I1027 00:36:34.942648 37958 solver.cpp:221] Iteration 37920 (1.05721 iter/s, 37.8353s/40 iters), loss = 1.74988
I1027 00:36:34.942822 37958 solver.cpp:240]     Train net output #0: loss = 1.74988 (* 1 = 1.74988 loss)
I1027 00:36:34.942837 37958 sgd_solver.cpp:105] Iteration 37920, lr = 0.00776941
I1027 00:37:05.678200 37958 solver.cpp:221] Iteration 37960 (1.30148 iter/s, 30.7342s/40 iters), loss = 1.57346
I1027 00:37:05.678380 37958 solver.cpp:240]     Train net output #0: loss = 1.57346 (* 1 = 1.57346 loss)
I1027 00:37:05.678405 37958 sgd_solver.cpp:105] Iteration 37960, lr = 0.00776706
I1027 00:37:35.607435 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_38000.caffemodel
I1027 00:37:35.640063 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_38000.solverstate
I1027 00:37:35.657938 37958 solver.cpp:333] Iteration 38000, Testing net (#0)
I1027 00:38:06.595294 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53448
I1027 00:38:06.595556 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77592
I1027 00:38:06.595571 37958 solver.cpp:400]     Test net output #2: loss = 2.10647 (* 1 = 2.10647 loss)
I1027 00:38:07.365751 37958 solver.cpp:221] Iteration 38000 (0.648455 iter/s, 61.6851s/40 iters), loss = 1.75578
I1027 00:38:07.365813 37958 solver.cpp:240]     Train net output #0: loss = 1.75578 (* 1 = 1.75578 loss)
I1027 00:38:07.365828 37958 sgd_solver.cpp:105] Iteration 38000, lr = 0.00776471
I1027 00:38:38.908164 37958 solver.cpp:221] Iteration 38040 (1.26818 iter/s, 31.5412s/40 iters), loss = 1.84508
I1027 00:38:38.908439 37958 solver.cpp:240]     Train net output #0: loss = 1.84508 (* 1 = 1.84508 loss)
I1027 00:38:38.908454 37958 sgd_solver.cpp:105] Iteration 38040, lr = 0.00776235
I1027 00:39:09.390507 37958 solver.cpp:221] Iteration 38080 (1.3123 iter/s, 30.4809s/40 iters), loss = 1.71142
I1027 00:39:09.390650 37958 solver.cpp:240]     Train net output #0: loss = 1.71142 (* 1 = 1.71142 loss)
I1027 00:39:09.390666 37958 sgd_solver.cpp:105] Iteration 38080, lr = 0.00776
I1027 00:39:39.699564 37958 solver.cpp:221] Iteration 38120 (1.31979 iter/s, 30.3078s/40 iters), loss = 1.89441
I1027 00:39:39.699699 37958 solver.cpp:240]     Train net output #0: loss = 1.89441 (* 1 = 1.89441 loss)
I1027 00:39:39.699714 37958 sgd_solver.cpp:105] Iteration 38120, lr = 0.00775765
I1027 00:40:09.934839 37958 solver.cpp:221] Iteration 38160 (1.32301 iter/s, 30.234s/40 iters), loss = 1.89781
I1027 00:40:09.934980 37958 solver.cpp:240]     Train net output #0: loss = 1.89781 (* 1 = 1.89781 loss)
I1027 00:40:09.934995 37958 sgd_solver.cpp:105] Iteration 38160, lr = 0.00775529
I1027 00:40:40.176728 37958 solver.cpp:221] Iteration 38200 (1.32272 iter/s, 30.2406s/40 iters), loss = 1.68528
I1027 00:40:40.176867 37958 solver.cpp:240]     Train net output #0: loss = 1.68528 (* 1 = 1.68528 loss)
I1027 00:40:40.176882 37958 sgd_solver.cpp:105] Iteration 38200, lr = 0.00775294
I1027 00:41:12.406620 37958 solver.cpp:221] Iteration 38240 (1.24114 iter/s, 32.2285s/40 iters), loss = 1.87725
I1027 00:41:12.406893 37958 solver.cpp:240]     Train net output #0: loss = 1.87725 (* 1 = 1.87725 loss)
I1027 00:41:12.406915 37958 sgd_solver.cpp:105] Iteration 38240, lr = 0.00775059
I1027 00:41:43.757580 37958 solver.cpp:221] Iteration 38280 (1.27594 iter/s, 31.3495s/40 iters), loss = 1.84144
I1027 00:41:43.757776 37958 solver.cpp:240]     Train net output #0: loss = 1.84144 (* 1 = 1.84144 loss)
I1027 00:41:43.757793 37958 sgd_solver.cpp:105] Iteration 38280, lr = 0.00774824
I1027 00:42:15.538020 37958 solver.cpp:221] Iteration 38320 (1.25869 iter/s, 31.779s/40 iters), loss = 1.71617
I1027 00:42:15.538259 37958 solver.cpp:240]     Train net output #0: loss = 1.71617 (* 1 = 1.71617 loss)
I1027 00:42:15.538277 37958 sgd_solver.cpp:105] Iteration 38320, lr = 0.00774588
I1027 00:42:46.069680 37958 solver.cpp:221] Iteration 38360 (1.31018 iter/s, 30.5303s/40 iters), loss = 2.01624
I1027 00:42:46.069860 37958 solver.cpp:240]     Train net output #0: loss = 2.01624 (* 1 = 2.01624 loss)
I1027 00:42:46.069875 37958 sgd_solver.cpp:105] Iteration 38360, lr = 0.00774353
I1027 00:43:16.645164 37958 solver.cpp:221] Iteration 38400 (1.30829 iter/s, 30.5741s/40 iters), loss = 2.01324
I1027 00:43:16.645337 37958 solver.cpp:240]     Train net output #0: loss = 2.01324 (* 1 = 2.01324 loss)
I1027 00:43:16.645354 37958 sgd_solver.cpp:105] Iteration 38400, lr = 0.00774118
I1027 00:43:47.169087 37958 solver.cpp:221] Iteration 38440 (1.3105 iter/s, 30.5226s/40 iters), loss = 1.84554
I1027 00:43:47.169415 37958 solver.cpp:240]     Train net output #0: loss = 1.84554 (* 1 = 1.84554 loss)
I1027 00:43:47.169448 37958 sgd_solver.cpp:105] Iteration 38440, lr = 0.00773882
I1027 00:44:25.110121 37958 solver.cpp:221] Iteration 38480 (1.05432 iter/s, 37.9393s/40 iters), loss = 1.88451
I1027 00:44:25.110339 37958 solver.cpp:240]     Train net output #0: loss = 1.88451 (* 1 = 1.88451 loss)
I1027 00:44:25.110354 37958 sgd_solver.cpp:105] Iteration 38480, lr = 0.00773647
I1027 00:44:39.887764 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_38500.caffemodel
I1027 00:44:39.920186 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_38500.solverstate
I1027 00:44:39.939821 37958 solver.cpp:333] Iteration 38500, Testing net (#0)
I1027 00:45:10.546831 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 00:45:10.752722 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53624
I1027 00:45:10.752776 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.774919
I1027 00:45:10.752789 37958 solver.cpp:400]     Test net output #2: loss = 2.06236 (* 1 = 2.06236 loss)
I1027 00:45:27.028153 37958 solver.cpp:221] Iteration 38520 (0.646042 iter/s, 61.9155s/40 iters), loss = 1.81654
I1027 00:45:27.028235 37958 solver.cpp:240]     Train net output #0: loss = 1.81654 (* 1 = 1.81654 loss)
I1027 00:45:27.028254 37958 sgd_solver.cpp:105] Iteration 38520, lr = 0.00773412
I1027 00:46:05.877805 37958 solver.cpp:221] Iteration 38560 (1.02965 iter/s, 38.8481s/40 iters), loss = 2.09184
I1027 00:46:05.878000 37958 solver.cpp:240]     Train net output #0: loss = 2.09184 (* 1 = 2.09184 loss)
I1027 00:46:05.878015 37958 sgd_solver.cpp:105] Iteration 38560, lr = 0.00773176
I1027 00:46:36.526517 37958 solver.cpp:221] Iteration 38600 (1.30517 iter/s, 30.6474s/40 iters), loss = 1.91949
I1027 00:46:36.526697 37958 solver.cpp:240]     Train net output #0: loss = 1.91949 (* 1 = 1.91949 loss)
I1027 00:46:36.526712 37958 sgd_solver.cpp:105] Iteration 38600, lr = 0.00772941
I1027 00:47:07.428616 37958 solver.cpp:221] Iteration 38640 (1.29447 iter/s, 30.9007s/40 iters), loss = 1.59847
I1027 00:47:07.428884 37958 solver.cpp:240]     Train net output #0: loss = 1.59847 (* 1 = 1.59847 loss)
I1027 00:47:07.428907 37958 sgd_solver.cpp:105] Iteration 38640, lr = 0.00772706
I1027 00:47:43.638622 37958 solver.cpp:221] Iteration 38680 (1.10472 iter/s, 36.2084s/40 iters), loss = 1.92496
I1027 00:47:43.638803 37958 solver.cpp:240]     Train net output #0: loss = 1.92496 (* 1 = 1.92496 loss)
I1027 00:47:43.638816 37958 sgd_solver.cpp:105] Iteration 38680, lr = 0.00772471
I1027 00:48:14.673579 37958 solver.cpp:221] Iteration 38720 (1.28893 iter/s, 31.0336s/40 iters), loss = 2.06304
I1027 00:48:14.673745 37958 solver.cpp:240]     Train net output #0: loss = 2.06304 (* 1 = 2.06304 loss)
I1027 00:48:14.673760 37958 sgd_solver.cpp:105] Iteration 38720, lr = 0.00772235
I1027 00:48:45.920753 37958 solver.cpp:221] Iteration 38760 (1.28017 iter/s, 31.2458s/40 iters), loss = 1.91206
I1027 00:48:45.920908 37958 solver.cpp:240]     Train net output #0: loss = 1.91206 (* 1 = 1.91206 loss)
I1027 00:48:45.920923 37958 sgd_solver.cpp:105] Iteration 38760, lr = 0.00772
I1027 00:49:17.316572 37958 solver.cpp:221] Iteration 38800 (1.27411 iter/s, 31.3945s/40 iters), loss = 2.04292
I1027 00:49:17.316767 37958 solver.cpp:240]     Train net output #0: loss = 2.04292 (* 1 = 2.04292 loss)
I1027 00:49:17.316788 37958 sgd_solver.cpp:105] Iteration 38800, lr = 0.00771765
I1027 00:49:48.409783 37958 solver.cpp:221] Iteration 38840 (1.28651 iter/s, 31.0918s/40 iters), loss = 1.88479
I1027 00:49:48.409970 37958 solver.cpp:240]     Train net output #0: loss = 1.88479 (* 1 = 1.88479 loss)
I1027 00:49:48.409986 37958 sgd_solver.cpp:105] Iteration 38840, lr = 0.00771529
I1027 00:50:19.232446 37958 solver.cpp:221] Iteration 38880 (1.2978 iter/s, 30.8213s/40 iters), loss = 1.52188
I1027 00:50:19.232655 37958 solver.cpp:240]     Train net output #0: loss = 1.52188 (* 1 = 1.52188 loss)
I1027 00:50:19.232682 37958 sgd_solver.cpp:105] Iteration 38880, lr = 0.00771294
I1027 00:50:50.590555 37958 solver.cpp:221] Iteration 38920 (1.27564 iter/s, 31.3567s/40 iters), loss = 2.19067
I1027 00:50:50.590744 37958 solver.cpp:240]     Train net output #0: loss = 2.19067 (* 1 = 2.19067 loss)
I1027 00:50:50.590759 37958 sgd_solver.cpp:105] Iteration 38920, lr = 0.00771059
I1027 00:51:21.464661 37958 solver.cpp:221] Iteration 38960 (1.29564 iter/s, 30.8728s/40 iters), loss = 1.42354
I1027 00:51:21.464869 37958 solver.cpp:240]     Train net output #0: loss = 1.42354 (* 1 = 1.42354 loss)
I1027 00:51:21.464884 37958 sgd_solver.cpp:105] Iteration 38960, lr = 0.00770824
I1027 00:51:52.744638 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_39000.caffemodel
I1027 00:51:52.789753 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_39000.solverstate
I1027 00:51:52.815891 37958 solver.cpp:333] Iteration 39000, Testing net (#0)
I1027 00:52:24.155030 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53568
I1027 00:52:24.155184 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77568
I1027 00:52:24.155196 37958 solver.cpp:400]     Test net output #2: loss = 2.10102 (* 1 = 2.10102 loss)
I1027 00:52:24.929747 37958 solver.cpp:221] Iteration 39000 (0.630293 iter/s, 63.4625s/40 iters), loss = 1.48983
I1027 00:52:24.929811 37958 solver.cpp:240]     Train net output #0: loss = 1.48983 (* 1 = 1.48983 loss)
I1027 00:52:24.929824 37958 sgd_solver.cpp:105] Iteration 39000, lr = 0.00770588
I1027 00:52:55.352780 37958 solver.cpp:221] Iteration 39040 (1.31485 iter/s, 30.4218s/40 iters), loss = 1.64858
I1027 00:52:55.352958 37958 solver.cpp:240]     Train net output #0: loss = 1.64858 (* 1 = 1.64858 loss)
I1027 00:52:55.352973 37958 sgd_solver.cpp:105] Iteration 39040, lr = 0.00770353
I1027 00:53:25.749238 37958 solver.cpp:221] Iteration 39080 (1.316 iter/s, 30.3951s/40 iters), loss = 1.63311
I1027 00:53:25.749415 37958 solver.cpp:240]     Train net output #0: loss = 1.63311 (* 1 = 1.63311 loss)
I1027 00:53:25.749430 37958 sgd_solver.cpp:105] Iteration 39080, lr = 0.00770118
I1027 00:53:56.077695 37958 solver.cpp:221] Iteration 39120 (1.31895 iter/s, 30.3271s/40 iters), loss = 1.80209
I1027 00:53:56.077852 37958 solver.cpp:240]     Train net output #0: loss = 1.80209 (* 1 = 1.80209 loss)
I1027 00:53:56.077867 37958 sgd_solver.cpp:105] Iteration 39120, lr = 0.00769882
I1027 00:54:26.842295 37958 solver.cpp:221] Iteration 39160 (1.30025 iter/s, 30.7633s/40 iters), loss = 1.94725
I1027 00:54:26.842460 37958 solver.cpp:240]     Train net output #0: loss = 1.94725 (* 1 = 1.94725 loss)
I1027 00:54:26.842475 37958 sgd_solver.cpp:105] Iteration 39160, lr = 0.00769647
I1027 00:54:57.558728 37958 solver.cpp:221] Iteration 39200 (1.30229 iter/s, 30.7151s/40 iters), loss = 1.75826
I1027 00:54:57.558933 37958 solver.cpp:240]     Train net output #0: loss = 1.75826 (* 1 = 1.75826 loss)
I1027 00:54:57.558948 37958 sgd_solver.cpp:105] Iteration 39200, lr = 0.00769412
I1027 00:55:29.359377 37958 solver.cpp:221] Iteration 39240 (1.25789 iter/s, 31.7992s/40 iters), loss = 1.62679
I1027 00:55:29.359576 37958 solver.cpp:240]     Train net output #0: loss = 1.62679 (* 1 = 1.62679 loss)
I1027 00:55:29.359591 37958 sgd_solver.cpp:105] Iteration 39240, lr = 0.00769176
I1027 00:56:00.578872 37958 solver.cpp:221] Iteration 39280 (1.28131 iter/s, 31.2181s/40 iters), loss = 1.59144
I1027 00:56:00.579051 37958 solver.cpp:240]     Train net output #0: loss = 1.59144 (* 1 = 1.59144 loss)
I1027 00:56:00.579064 37958 sgd_solver.cpp:105] Iteration 39280, lr = 0.00768941
I1027 00:56:32.067128 37958 solver.cpp:221] Iteration 39320 (1.27037 iter/s, 31.4869s/40 iters), loss = 1.71548
I1027 00:56:32.067345 37958 solver.cpp:240]     Train net output #0: loss = 1.71548 (* 1 = 1.71548 loss)
I1027 00:56:32.067365 37958 sgd_solver.cpp:105] Iteration 39320, lr = 0.00768706
I1027 00:57:03.760648 37958 solver.cpp:221] Iteration 39360 (1.26214 iter/s, 31.6921s/40 iters), loss = 1.60872
I1027 00:57:03.760967 37958 solver.cpp:240]     Train net output #0: loss = 1.60872 (* 1 = 1.60872 loss)
I1027 00:57:03.760998 37958 sgd_solver.cpp:105] Iteration 39360, lr = 0.00768471
I1027 00:57:35.317425 37958 solver.cpp:221] Iteration 39400 (1.26762 iter/s, 31.5553s/40 iters), loss = 1.87237
I1027 00:57:35.317636 37958 solver.cpp:240]     Train net output #0: loss = 1.87237 (* 1 = 1.87237 loss)
I1027 00:57:35.317651 37958 sgd_solver.cpp:105] Iteration 39400, lr = 0.00768235
I1027 00:58:06.162642 37958 solver.cpp:221] Iteration 39440 (1.29686 iter/s, 30.8438s/40 iters), loss = 2.02243
I1027 00:58:06.162825 37958 solver.cpp:240]     Train net output #0: loss = 2.02243 (* 1 = 2.02243 loss)
I1027 00:58:06.162840 37958 sgd_solver.cpp:105] Iteration 39440, lr = 0.00768
I1027 00:58:37.179463 37958 solver.cpp:221] Iteration 39480 (1.28968 iter/s, 31.0155s/40 iters), loss = 1.73587
I1027 00:58:37.179627 37958 solver.cpp:240]     Train net output #0: loss = 1.73587 (* 1 = 1.73587 loss)
I1027 00:58:37.179641 37958 sgd_solver.cpp:105] Iteration 39480, lr = 0.00767765
I1027 00:58:51.773486 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_39500.caffemodel
I1027 00:58:51.810794 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_39500.solverstate
I1027 00:58:51.835777 37958 solver.cpp:333] Iteration 39500, Testing net (#0)
I1027 00:59:22.485256 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 00:59:22.690732 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52424
I1027 00:59:22.690789 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76724
I1027 00:59:22.690801 37958 solver.cpp:400]     Test net output #2: loss = 2.13573 (* 1 = 2.13573 loss)
I1027 00:59:38.830130 37958 solver.cpp:221] Iteration 39520 (0.648843 iter/s, 61.6482s/40 iters), loss = 1.86593
I1027 00:59:38.830195 37958 solver.cpp:240]     Train net output #0: loss = 1.86593 (* 1 = 1.86593 loss)
I1027 00:59:38.830209 37958 sgd_solver.cpp:105] Iteration 39520, lr = 0.00767529
I1027 01:00:09.151584 37958 solver.cpp:221] Iteration 39560 (1.31925 iter/s, 30.3202s/40 iters), loss = 1.69525
I1027 01:00:09.151772 37958 solver.cpp:240]     Train net output #0: loss = 1.69525 (* 1 = 1.69525 loss)
I1027 01:00:09.151787 37958 sgd_solver.cpp:105] Iteration 39560, lr = 0.00767294
I1027 01:00:39.790206 37958 solver.cpp:221] Iteration 39600 (1.3056 iter/s, 30.6373s/40 iters), loss = 1.52549
I1027 01:00:39.790396 37958 solver.cpp:240]     Train net output #0: loss = 1.52549 (* 1 = 1.52549 loss)
I1027 01:00:39.790412 37958 sgd_solver.cpp:105] Iteration 39600, lr = 0.00767059
I1027 01:01:10.299844 37958 solver.cpp:221] Iteration 39640 (1.31112 iter/s, 30.5083s/40 iters), loss = 1.76226
I1027 01:01:10.300047 37958 solver.cpp:240]     Train net output #0: loss = 1.76226 (* 1 = 1.76226 loss)
I1027 01:01:10.300062 37958 sgd_solver.cpp:105] Iteration 39640, lr = 0.00766824
I1027 01:01:40.609858 37958 solver.cpp:221] Iteration 39680 (1.31976 iter/s, 30.3087s/40 iters), loss = 1.7866
I1027 01:01:40.610044 37958 solver.cpp:240]     Train net output #0: loss = 1.7866 (* 1 = 1.7866 loss)
I1027 01:01:40.610059 37958 sgd_solver.cpp:105] Iteration 39680, lr = 0.00766588
I1027 01:02:11.396594 37958 solver.cpp:221] Iteration 39720 (1.29932 iter/s, 30.7854s/40 iters), loss = 1.53538
I1027 01:02:11.396782 37958 solver.cpp:240]     Train net output #0: loss = 1.53538 (* 1 = 1.53538 loss)
I1027 01:02:11.396796 37958 sgd_solver.cpp:105] Iteration 39720, lr = 0.00766353
I1027 01:02:42.339897 37958 solver.cpp:221] Iteration 39760 (1.29274 iter/s, 30.9419s/40 iters), loss = 1.86441
I1027 01:02:42.340080 37958 solver.cpp:240]     Train net output #0: loss = 1.86441 (* 1 = 1.86441 loss)
I1027 01:02:42.340095 37958 sgd_solver.cpp:105] Iteration 39760, lr = 0.00766118
I1027 01:03:14.096135 37958 solver.cpp:221] Iteration 39800 (1.25965 iter/s, 31.7548s/40 iters), loss = 1.9893
I1027 01:03:14.096468 37958 solver.cpp:240]     Train net output #0: loss = 1.9893 (* 1 = 1.9893 loss)
I1027 01:03:14.096493 37958 sgd_solver.cpp:105] Iteration 39800, lr = 0.00765882
I1027 01:03:44.950184 37958 solver.cpp:221] Iteration 39840 (1.29649 iter/s, 30.8526s/40 iters), loss = 1.72937
I1027 01:03:44.950403 37958 solver.cpp:240]     Train net output #0: loss = 1.72937 (* 1 = 1.72937 loss)
I1027 01:03:44.950418 37958 sgd_solver.cpp:105] Iteration 39840, lr = 0.00765647
I1027 01:04:15.953953 37958 solver.cpp:221] Iteration 39880 (1.29022 iter/s, 31.0024s/40 iters), loss = 2.13035
I1027 01:04:15.954164 37958 solver.cpp:240]     Train net output #0: loss = 2.13035 (* 1 = 2.13035 loss)
I1027 01:04:15.954180 37958 sgd_solver.cpp:105] Iteration 39880, lr = 0.00765412
I1027 01:04:47.206239 37958 solver.cpp:221] Iteration 39920 (1.27996 iter/s, 31.2509s/40 iters), loss = 1.60144
I1027 01:04:47.206429 37958 solver.cpp:240]     Train net output #0: loss = 1.60144 (* 1 = 1.60144 loss)
I1027 01:04:47.206444 37958 sgd_solver.cpp:105] Iteration 39920, lr = 0.00765176
I1027 01:05:19.061120 37958 solver.cpp:221] Iteration 39960 (1.25575 iter/s, 31.8535s/40 iters), loss = 1.79101
I1027 01:05:19.061295 37958 solver.cpp:240]     Train net output #0: loss = 1.79101 (* 1 = 1.79101 loss)
I1027 01:05:19.061316 37958 sgd_solver.cpp:105] Iteration 39960, lr = 0.00764941
I1027 01:05:49.232954 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_40000.caffemodel
I1027 01:05:49.264773 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_40000.solverstate
I1027 01:05:49.282272 37958 solver.cpp:333] Iteration 40000, Testing net (#0)
I1027 01:06:20.121443 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52936
I1027 01:06:20.121623 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.76748
I1027 01:06:20.121636 37958 solver.cpp:400]     Test net output #2: loss = 2.12933 (* 1 = 2.12933 loss)
I1027 01:06:20.886646 37958 solver.cpp:221] Iteration 40000 (0.647008 iter/s, 61.823s/40 iters), loss = 1.58877
I1027 01:06:20.886682 37958 solver.cpp:240]     Train net output #0: loss = 1.58877 (* 1 = 1.58877 loss)
I1027 01:06:20.886695 37958 sgd_solver.cpp:105] Iteration 40000, lr = 0.00764706
I1027 01:06:45.851478 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1027 01:06:51.820927 37958 solver.cpp:221] Iteration 40040 (1.29311 iter/s, 30.9331s/40 iters), loss = 1.88846
I1027 01:06:51.821113 37958 solver.cpp:240]     Train net output #0: loss = 1.88846 (* 1 = 1.88846 loss)
I1027 01:06:51.821127 37958 sgd_solver.cpp:105] Iteration 40040, lr = 0.00764471
I1027 01:07:23.162760 37958 solver.cpp:221] Iteration 40080 (1.27631 iter/s, 31.3405s/40 iters), loss = 1.87001
I1027 01:07:23.162942 37958 solver.cpp:240]     Train net output #0: loss = 1.87001 (* 1 = 1.87001 loss)
I1027 01:07:23.162957 37958 sgd_solver.cpp:105] Iteration 40080, lr = 0.00764235
I1027 01:07:53.987480 37958 solver.cpp:221] Iteration 40120 (1.29772 iter/s, 30.8234s/40 iters), loss = 2.2836
I1027 01:07:53.987673 37958 solver.cpp:240]     Train net output #0: loss = 2.2836 (* 1 = 2.2836 loss)
I1027 01:07:53.987689 37958 sgd_solver.cpp:105] Iteration 40120, lr = 0.00764
I1027 01:08:25.730625 37958 solver.cpp:221] Iteration 40160 (1.26017 iter/s, 31.7418s/40 iters), loss = 1.66424
I1027 01:08:25.730805 37958 solver.cpp:240]     Train net output #0: loss = 1.66424 (* 1 = 1.66424 loss)
I1027 01:08:25.730826 37958 sgd_solver.cpp:105] Iteration 40160, lr = 0.00763765
I1027 01:08:58.735710 37958 solver.cpp:221] Iteration 40200 (1.21199 iter/s, 33.0037s/40 iters), loss = 2.24689
I1027 01:08:58.735909 37958 solver.cpp:240]     Train net output #0: loss = 2.24689 (* 1 = 2.24689 loss)
I1027 01:08:58.735925 37958 sgd_solver.cpp:105] Iteration 40200, lr = 0.00763529
I1027 01:09:29.926060 37958 solver.cpp:221] Iteration 40240 (1.2825 iter/s, 31.189s/40 iters), loss = 2.17874
I1027 01:09:29.926400 37958 solver.cpp:240]     Train net output #0: loss = 2.17874 (* 1 = 2.17874 loss)
I1027 01:09:29.926450 37958 sgd_solver.cpp:105] Iteration 40240, lr = 0.00763294
I1027 01:10:01.005883 37958 solver.cpp:221] Iteration 40280 (1.28707 iter/s, 31.0783s/40 iters), loss = 1.76228
I1027 01:10:01.006078 37958 solver.cpp:240]     Train net output #0: loss = 1.76228 (* 1 = 1.76228 loss)
I1027 01:10:01.006093 37958 sgd_solver.cpp:105] Iteration 40280, lr = 0.00763059
I1027 01:10:31.499162 37958 solver.cpp:221] Iteration 40320 (1.31182 iter/s, 30.4919s/40 iters), loss = 1.8729
I1027 01:10:31.499549 37958 solver.cpp:240]     Train net output #0: loss = 1.8729 (* 1 = 1.8729 loss)
I1027 01:10:31.499564 37958 sgd_solver.cpp:105] Iteration 40320, lr = 0.00762824
I1027 01:11:01.691844 37958 solver.cpp:221] Iteration 40360 (1.32489 iter/s, 30.1912s/40 iters), loss = 1.67906
I1027 01:11:01.691998 37958 solver.cpp:240]     Train net output #0: loss = 1.67906 (* 1 = 1.67906 loss)
I1027 01:11:01.692013 37958 sgd_solver.cpp:105] Iteration 40360, lr = 0.00762588
I1027 01:11:32.528749 37958 solver.cpp:221] Iteration 40400 (1.2972 iter/s, 30.8356s/40 iters), loss = 1.38913
I1027 01:11:32.528970 37958 solver.cpp:240]     Train net output #0: loss = 1.38913 (* 1 = 1.38913 loss)
I1027 01:11:32.528985 37958 sgd_solver.cpp:105] Iteration 40400, lr = 0.00762353
I1027 01:12:03.223394 37958 solver.cpp:221] Iteration 40440 (1.30322 iter/s, 30.6933s/40 iters), loss = 1.7428
I1027 01:12:03.223604 37958 solver.cpp:240]     Train net output #0: loss = 1.7428 (* 1 = 1.7428 loss)
I1027 01:12:03.223619 37958 sgd_solver.cpp:105] Iteration 40440, lr = 0.00762118
I1027 01:12:33.851052 37958 solver.cpp:221] Iteration 40480 (1.30607 iter/s, 30.6263s/40 iters), loss = 1.92941
I1027 01:12:33.851227 37958 solver.cpp:240]     Train net output #0: loss = 1.92941 (* 1 = 1.92941 loss)
I1027 01:12:33.851243 37958 sgd_solver.cpp:105] Iteration 40480, lr = 0.00761882
I1027 01:12:48.400358 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_40500.caffemodel
I1027 01:12:48.432272 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_40500.solverstate
I1027 01:12:48.449918 37958 solver.cpp:333] Iteration 40500, Testing net (#0)
I1027 01:13:19.344981 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 01:13:19.557303 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53704
I1027 01:13:19.557359 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77244
I1027 01:13:19.557371 37958 solver.cpp:400]     Test net output #2: loss = 2.07109 (* 1 = 2.07109 loss)
I1027 01:13:35.820226 37958 solver.cpp:221] Iteration 40520 (0.645508 iter/s, 61.9667s/40 iters), loss = 2.13028
I1027 01:13:35.820287 37958 solver.cpp:240]     Train net output #0: loss = 2.13028 (* 1 = 2.13028 loss)
I1027 01:13:35.820305 37958 sgd_solver.cpp:105] Iteration 40520, lr = 0.00761647
I1027 01:14:07.348359 37958 solver.cpp:221] Iteration 40560 (1.26876 iter/s, 31.5269s/40 iters), loss = 1.6059
I1027 01:14:07.348553 37958 solver.cpp:240]     Train net output #0: loss = 1.6059 (* 1 = 1.6059 loss)
I1027 01:14:07.348568 37958 sgd_solver.cpp:105] Iteration 40560, lr = 0.00761412
I1027 01:14:38.368490 37958 solver.cpp:221] Iteration 40600 (1.28954 iter/s, 31.0188s/40 iters), loss = 1.65277
I1027 01:14:38.368702 37958 solver.cpp:240]     Train net output #0: loss = 1.65277 (* 1 = 1.65277 loss)
I1027 01:14:38.368717 37958 sgd_solver.cpp:105] Iteration 40600, lr = 0.00761176
I1027 01:15:09.221981 37958 solver.cpp:221] Iteration 40640 (1.29651 iter/s, 30.8521s/40 iters), loss = 1.60078
I1027 01:15:09.222167 37958 solver.cpp:240]     Train net output #0: loss = 1.60078 (* 1 = 1.60078 loss)
I1027 01:15:09.222182 37958 sgd_solver.cpp:105] Iteration 40640, lr = 0.00760941
I1027 01:15:40.264477 37958 solver.cpp:221] Iteration 40680 (1.28861 iter/s, 31.0411s/40 iters), loss = 1.49279
I1027 01:15:40.264673 37958 solver.cpp:240]     Train net output #0: loss = 1.49279 (* 1 = 1.49279 loss)
I1027 01:15:40.264688 37958 sgd_solver.cpp:105] Iteration 40680, lr = 0.00760706
I1027 01:16:11.897269 37958 solver.cpp:221] Iteration 40720 (1.26457 iter/s, 31.6314s/40 iters), loss = 1.65342
I1027 01:16:11.897596 37958 solver.cpp:240]     Train net output #0: loss = 1.65342 (* 1 = 1.65342 loss)
I1027 01:16:11.897620 37958 sgd_solver.cpp:105] Iteration 40720, lr = 0.00760471
I1027 01:16:43.856719 37958 solver.cpp:221] Iteration 40760 (1.25165 iter/s, 31.9579s/40 iters), loss = 1.93533
I1027 01:16:43.856925 37958 solver.cpp:240]     Train net output #0: loss = 1.93533 (* 1 = 1.93533 loss)
I1027 01:16:43.856940 37958 sgd_solver.cpp:105] Iteration 40760, lr = 0.00760235
I1027 01:17:14.904395 37958 solver.cpp:221] Iteration 40800 (1.2884 iter/s, 31.0463s/40 iters), loss = 2.11066
I1027 01:17:14.904564 37958 solver.cpp:240]     Train net output #0: loss = 2.11066 (* 1 = 2.11066 loss)
I1027 01:17:14.904579 37958 sgd_solver.cpp:105] Iteration 40800, lr = 0.0076
I1027 01:17:46.260556 37958 solver.cpp:221] Iteration 40840 (1.27572 iter/s, 31.3548s/40 iters), loss = 1.85474
I1027 01:17:46.260735 37958 solver.cpp:240]     Train net output #0: loss = 1.85474 (* 1 = 1.85474 loss)
I1027 01:17:46.260751 37958 sgd_solver.cpp:105] Iteration 40840, lr = 0.00759765
I1027 01:18:17.029979 37958 solver.cpp:221] Iteration 40880 (1.30005 iter/s, 30.7681s/40 iters), loss = 1.29977
I1027 01:18:17.030149 37958 solver.cpp:240]     Train net output #0: loss = 1.29977 (* 1 = 1.29977 loss)
I1027 01:18:17.030164 37958 sgd_solver.cpp:105] Iteration 40880, lr = 0.00759529
I1027 01:18:47.962530 37958 solver.cpp:221] Iteration 40920 (1.29319 iter/s, 30.9312s/40 iters), loss = 1.92832
I1027 01:18:47.962685 37958 solver.cpp:240]     Train net output #0: loss = 1.92832 (* 1 = 1.92832 loss)
I1027 01:18:47.962700 37958 sgd_solver.cpp:105] Iteration 40920, lr = 0.00759294
I1027 01:19:19.083591 37958 solver.cpp:221] Iteration 40960 (1.28536 iter/s, 31.1197s/40 iters), loss = 2.00016
I1027 01:19:19.083766 37958 solver.cpp:240]     Train net output #0: loss = 2.00016 (* 1 = 2.00016 loss)
I1027 01:19:19.083784 37958 sgd_solver.cpp:105] Iteration 40960, lr = 0.00759059
I1027 01:19:49.004027 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_41000.caffemodel
I1027 01:19:49.039175 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_41000.solverstate
I1027 01:19:49.058604 37958 solver.cpp:333] Iteration 41000, Testing net (#0)
I1027 01:20:19.913595 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53348
I1027 01:20:19.913786 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.7764
I1027 01:20:19.913800 37958 solver.cpp:400]     Test net output #2: loss = 2.10646 (* 1 = 2.10646 loss)
I1027 01:20:20.685376 37958 solver.cpp:221] Iteration 41000 (0.649358 iter/s, 61.5993s/40 iters), loss = 1.92772
I1027 01:20:20.685431 37958 solver.cpp:240]     Train net output #0: loss = 1.92772 (* 1 = 1.92772 loss)
I1027 01:20:20.685446 37958 sgd_solver.cpp:105] Iteration 41000, lr = 0.00758824
I1027 01:20:51.521752 37958 solver.cpp:221] Iteration 41040 (1.29722 iter/s, 30.8351s/40 iters), loss = 1.76342
I1027 01:20:51.521948 37958 solver.cpp:240]     Train net output #0: loss = 1.76342 (* 1 = 1.76342 loss)
I1027 01:20:51.521963 37958 sgd_solver.cpp:105] Iteration 41040, lr = 0.00758588
I1027 01:21:24.865356 37958 solver.cpp:221] Iteration 41080 (1.19968 iter/s, 33.3421s/40 iters), loss = 1.83954
I1027 01:21:24.865532 37958 solver.cpp:240]     Train net output #0: loss = 1.83954 (* 1 = 1.83954 loss)
I1027 01:21:24.865546 37958 sgd_solver.cpp:105] Iteration 41080, lr = 0.00758353
I1027 01:21:56.419983 37958 solver.cpp:221] Iteration 41120 (1.2677 iter/s, 31.5532s/40 iters), loss = 1.82191
I1027 01:21:56.420214 37958 solver.cpp:240]     Train net output #0: loss = 1.82191 (* 1 = 1.82191 loss)
I1027 01:21:56.420235 37958 sgd_solver.cpp:105] Iteration 41120, lr = 0.00758118
I1027 01:22:27.468591 37958 solver.cpp:221] Iteration 41160 (1.28836 iter/s, 31.0472s/40 iters), loss = 1.67252
I1027 01:22:27.468834 37958 solver.cpp:240]     Train net output #0: loss = 1.67252 (* 1 = 1.67252 loss)
I1027 01:22:27.468850 37958 sgd_solver.cpp:105] Iteration 41160, lr = 0.00757882
I1027 01:22:58.944265 37958 solver.cpp:221] Iteration 41200 (1.27088 iter/s, 31.4742s/40 iters), loss = 1.70977
I1027 01:22:58.944589 37958 solver.cpp:240]     Train net output #0: loss = 1.70977 (* 1 = 1.70977 loss)
I1027 01:22:58.944619 37958 sgd_solver.cpp:105] Iteration 41200, lr = 0.00757647
I1027 01:23:30.272382 37958 solver.cpp:221] Iteration 41240 (1.27687 iter/s, 31.3266s/40 iters), loss = 1.42758
I1027 01:23:30.272589 37958 solver.cpp:240]     Train net output #0: loss = 1.42758 (* 1 = 1.42758 loss)
I1027 01:23:30.272604 37958 sgd_solver.cpp:105] Iteration 41240, lr = 0.00757412
I1027 01:24:01.700335 37958 solver.cpp:221] Iteration 41280 (1.27281 iter/s, 31.4266s/40 iters), loss = 1.37646
I1027 01:24:01.700520 37958 solver.cpp:240]     Train net output #0: loss = 1.37646 (* 1 = 1.37646 loss)
I1027 01:24:01.700536 37958 sgd_solver.cpp:105] Iteration 41280, lr = 0.00757176
I1027 01:24:32.041520 37958 solver.cpp:221] Iteration 41320 (1.3184 iter/s, 30.3399s/40 iters), loss = 2.01383
I1027 01:24:32.041679 37958 solver.cpp:240]     Train net output #0: loss = 2.01383 (* 1 = 2.01383 loss)
I1027 01:24:32.041694 37958 sgd_solver.cpp:105] Iteration 41320, lr = 0.00756941
I1027 01:25:02.574579 37958 solver.cpp:221] Iteration 41360 (1.31011 iter/s, 30.5317s/40 iters), loss = 1.94207
I1027 01:25:02.574770 37958 solver.cpp:240]     Train net output #0: loss = 1.94207 (* 1 = 1.94207 loss)
I1027 01:25:02.574785 37958 sgd_solver.cpp:105] Iteration 41360, lr = 0.00756706
I1027 01:25:32.943080 37958 solver.cpp:221] Iteration 41400 (1.31721 iter/s, 30.3672s/40 iters), loss = 1.74298
I1027 01:25:32.943236 37958 solver.cpp:240]     Train net output #0: loss = 1.74298 (* 1 = 1.74298 loss)
I1027 01:25:32.943250 37958 sgd_solver.cpp:105] Iteration 41400, lr = 0.00756471
I1027 01:26:03.241158 37958 solver.cpp:221] Iteration 41440 (1.32027 iter/s, 30.2968s/40 iters), loss = 1.67425
I1027 01:26:03.241323 37958 solver.cpp:240]     Train net output #0: loss = 1.67425 (* 1 = 1.67425 loss)
I1027 01:26:03.241339 37958 sgd_solver.cpp:105] Iteration 41440, lr = 0.00756235
I1027 01:26:33.577277 37958 solver.cpp:221] Iteration 41480 (1.31862 iter/s, 30.3348s/40 iters), loss = 1.71896
I1027 01:26:33.577435 37958 solver.cpp:240]     Train net output #0: loss = 1.71896 (* 1 = 1.71896 loss)
I1027 01:26:33.577450 37958 sgd_solver.cpp:105] Iteration 41480, lr = 0.00756
I1027 01:26:48.005422 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_41500.caffemodel
I1027 01:26:48.044225 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_41500.solverstate
I1027 01:26:48.067646 37958 solver.cpp:333] Iteration 41500, Testing net (#0)
I1027 01:27:19.624867 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 01:27:19.830655 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53808
I1027 01:27:19.830714 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.774639
I1027 01:27:19.830726 37958 solver.cpp:400]     Test net output #2: loss = 2.07909 (* 1 = 2.07909 loss)
I1027 01:27:35.860491 37958 solver.cpp:221] Iteration 41520 (0.642253 iter/s, 62.2807s/40 iters), loss = 1.79666
I1027 01:27:35.860553 37958 solver.cpp:240]     Train net output #0: loss = 1.79666 (* 1 = 1.79666 loss)
I1027 01:27:35.860569 37958 sgd_solver.cpp:105] Iteration 41520, lr = 0.00755765
I1027 01:28:06.470149 37958 solver.cpp:221] Iteration 41560 (1.30683 iter/s, 30.6084s/40 iters), loss = 1.87057
I1027 01:28:06.470367 37958 solver.cpp:240]     Train net output #0: loss = 1.87057 (* 1 = 1.87057 loss)
I1027 01:28:06.470382 37958 sgd_solver.cpp:105] Iteration 41560, lr = 0.00755529
I1027 01:28:37.465009 37958 solver.cpp:221] Iteration 41600 (1.29059 iter/s, 30.9935s/40 iters), loss = 1.87315
I1027 01:28:37.465243 37958 solver.cpp:240]     Train net output #0: loss = 1.87315 (* 1 = 1.87315 loss)
I1027 01:28:37.465270 37958 sgd_solver.cpp:105] Iteration 41600, lr = 0.00755294
I1027 01:29:08.277284 37958 solver.cpp:221] Iteration 41640 (1.29824 iter/s, 30.8109s/40 iters), loss = 1.79289
I1027 01:29:08.277487 37958 solver.cpp:240]     Train net output #0: loss = 1.79289 (* 1 = 1.79289 loss)
I1027 01:29:08.277503 37958 sgd_solver.cpp:105] Iteration 41640, lr = 0.00755059
I1027 01:29:38.730911 37958 solver.cpp:221] Iteration 41680 (1.31353 iter/s, 30.4523s/40 iters), loss = 1.64605
I1027 01:29:38.731055 37958 solver.cpp:240]     Train net output #0: loss = 1.64605 (* 1 = 1.64605 loss)
I1027 01:29:38.731070 37958 sgd_solver.cpp:105] Iteration 41680, lr = 0.00754824
I1027 01:30:09.422009 37958 solver.cpp:221] Iteration 41720 (1.30336 iter/s, 30.6898s/40 iters), loss = 1.61017
I1027 01:30:09.422183 37958 solver.cpp:240]     Train net output #0: loss = 1.61017 (* 1 = 1.61017 loss)
I1027 01:30:09.422197 37958 sgd_solver.cpp:105] Iteration 41720, lr = 0.00754588
I1027 01:30:40.095232 37958 solver.cpp:221] Iteration 41760 (1.30413 iter/s, 30.6719s/40 iters), loss = 1.81616
I1027 01:30:40.095409 37958 solver.cpp:240]     Train net output #0: loss = 1.81616 (* 1 = 1.81616 loss)
I1027 01:30:40.095433 37958 sgd_solver.cpp:105] Iteration 41760, lr = 0.00754353
I1027 01:31:10.713618 37958 solver.cpp:221] Iteration 41800 (1.30646 iter/s, 30.617s/40 iters), loss = 2.12076
I1027 01:31:10.713794 37958 solver.cpp:240]     Train net output #0: loss = 2.12076 (* 1 = 2.12076 loss)
I1027 01:31:10.713809 37958 sgd_solver.cpp:105] Iteration 41800, lr = 0.00754118
I1027 01:31:41.609684 37958 solver.cpp:221] Iteration 41840 (1.29472 iter/s, 30.8947s/40 iters), loss = 1.47031
I1027 01:31:41.609853 37958 solver.cpp:240]     Train net output #0: loss = 1.47031 (* 1 = 1.47031 loss)
I1027 01:31:41.609868 37958 sgd_solver.cpp:105] Iteration 41840, lr = 0.00753882
I1027 01:32:12.278385 37958 solver.cpp:221] Iteration 41880 (1.30432 iter/s, 30.6674s/40 iters), loss = 1.72001
I1027 01:32:12.278539 37958 solver.cpp:240]     Train net output #0: loss = 1.72001 (* 1 = 1.72001 loss)
I1027 01:32:12.278554 37958 sgd_solver.cpp:105] Iteration 41880, lr = 0.00753647
I1027 01:32:43.182345 37958 solver.cpp:221] Iteration 41920 (1.29439 iter/s, 30.9026s/40 iters), loss = 1.42529
I1027 01:32:43.182497 37958 solver.cpp:240]     Train net output #0: loss = 1.42529 (* 1 = 1.42529 loss)
I1027 01:32:43.182512 37958 sgd_solver.cpp:105] Iteration 41920, lr = 0.00753412
I1027 01:33:14.154330 37958 solver.cpp:221] Iteration 41960 (1.29155 iter/s, 30.9707s/40 iters), loss = 1.74688
I1027 01:33:14.154511 37958 solver.cpp:240]     Train net output #0: loss = 1.74688 (* 1 = 1.74688 loss)
I1027 01:33:14.154526 37958 sgd_solver.cpp:105] Iteration 41960, lr = 0.00753176
I1027 01:33:43.762397 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_42000.caffemodel
I1027 01:33:43.795766 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_42000.solverstate
I1027 01:33:43.815352 37958 solver.cpp:333] Iteration 42000, Testing net (#0)
I1027 01:34:14.696873 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53356
I1027 01:34:14.697049 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77284
I1027 01:34:14.697063 37958 solver.cpp:400]     Test net output #2: loss = 2.06907 (* 1 = 2.06907 loss)
I1027 01:34:15.466092 37958 solver.cpp:221] Iteration 42000 (0.65243 iter/s, 61.3093s/40 iters), loss = 1.69889
I1027 01:34:15.466156 37958 solver.cpp:240]     Train net output #0: loss = 1.69889 (* 1 = 1.69889 loss)
I1027 01:34:15.466168 37958 sgd_solver.cpp:105] Iteration 42000, lr = 0.00752941
I1027 01:34:46.585131 37958 solver.cpp:221] Iteration 42040 (1.28544 iter/s, 31.1178s/40 iters), loss = 1.68383
I1027 01:34:46.585392 37958 solver.cpp:240]     Train net output #0: loss = 1.68383 (* 1 = 1.68383 loss)
I1027 01:34:46.585413 37958 sgd_solver.cpp:105] Iteration 42040, lr = 0.00752706
I1027 01:35:16.808122 37958 solver.cpp:221] Iteration 42080 (1.32356 iter/s, 30.2216s/40 iters), loss = 1.98067
I1027 01:35:16.808372 37958 solver.cpp:240]     Train net output #0: loss = 1.98067 (* 1 = 1.98067 loss)
I1027 01:35:16.808387 37958 sgd_solver.cpp:105] Iteration 42080, lr = 0.00752471
I1027 01:35:47.516402 37958 solver.cpp:221] Iteration 42120 (1.30264 iter/s, 30.7069s/40 iters), loss = 1.73785
I1027 01:35:47.516584 37958 solver.cpp:240]     Train net output #0: loss = 1.73785 (* 1 = 1.73785 loss)
I1027 01:35:47.516599 37958 sgd_solver.cpp:105] Iteration 42120, lr = 0.00752235
I1027 01:36:18.210691 37958 solver.cpp:221] Iteration 42160 (1.30323 iter/s, 30.6929s/40 iters), loss = 1.81943
I1027 01:36:18.210881 37958 solver.cpp:240]     Train net output #0: loss = 1.81943 (* 1 = 1.81943 loss)
I1027 01:36:18.210896 37958 sgd_solver.cpp:105] Iteration 42160, lr = 0.00752
I1027 01:36:48.920804 37958 solver.cpp:221] Iteration 42200 (1.30256 iter/s, 30.7088s/40 iters), loss = 1.89895
I1027 01:36:48.921008 37958 solver.cpp:240]     Train net output #0: loss = 1.89895 (* 1 = 1.89895 loss)
I1027 01:36:48.921023 37958 sgd_solver.cpp:105] Iteration 42200, lr = 0.00751765
I1027 01:37:20.169849 37958 solver.cpp:221] Iteration 42240 (1.2801 iter/s, 31.2477s/40 iters), loss = 1.95977
I1027 01:37:20.170083 37958 solver.cpp:240]     Train net output #0: loss = 1.95977 (* 1 = 1.95977 loss)
I1027 01:37:20.170099 37958 sgd_solver.cpp:105] Iteration 42240, lr = 0.00751529
I1027 01:37:51.634438 37958 solver.cpp:221] Iteration 42280 (1.27133 iter/s, 31.4632s/40 iters), loss = 1.86775
I1027 01:37:51.634616 37958 solver.cpp:240]     Train net output #0: loss = 1.86775 (* 1 = 1.86775 loss)
I1027 01:37:51.634630 37958 sgd_solver.cpp:105] Iteration 42280, lr = 0.00751294
I1027 01:38:22.885203 37958 solver.cpp:221] Iteration 42320 (1.28002 iter/s, 31.2494s/40 iters), loss = 1.72881
I1027 01:38:22.885439 37958 solver.cpp:240]     Train net output #0: loss = 1.72881 (* 1 = 1.72881 loss)
I1027 01:38:22.885460 37958 sgd_solver.cpp:105] Iteration 42320, lr = 0.00751059
I1027 01:38:56.453716 37958 solver.cpp:221] Iteration 42360 (1.19165 iter/s, 33.567s/40 iters), loss = 1.74949
I1027 01:38:56.453933 37958 solver.cpp:240]     Train net output #0: loss = 1.74949 (* 1 = 1.74949 loss)
I1027 01:38:56.453949 37958 sgd_solver.cpp:105] Iteration 42360, lr = 0.00750823
I1027 01:39:27.434871 37958 solver.cpp:221] Iteration 42400 (1.29117 iter/s, 30.9798s/40 iters), loss = 1.72848
I1027 01:39:27.435086 37958 solver.cpp:240]     Train net output #0: loss = 1.72848 (* 1 = 1.72848 loss)
I1027 01:39:27.435101 37958 sgd_solver.cpp:105] Iteration 42400, lr = 0.00750588
I1027 01:39:57.586596 37958 solver.cpp:221] Iteration 42440 (1.32668 iter/s, 30.1504s/40 iters), loss = 1.81333
I1027 01:39:57.586786 37958 solver.cpp:240]     Train net output #0: loss = 1.81333 (* 1 = 1.81333 loss)
I1027 01:39:57.586800 37958 sgd_solver.cpp:105] Iteration 42440, lr = 0.00750353
I1027 01:40:28.534374 37958 solver.cpp:221] Iteration 42480 (1.29256 iter/s, 30.9464s/40 iters), loss = 1.69282
I1027 01:40:28.534562 37958 solver.cpp:240]     Train net output #0: loss = 1.69282 (* 1 = 1.69282 loss)
I1027 01:40:28.534577 37958 sgd_solver.cpp:105] Iteration 42480, lr = 0.00750118
I1027 01:40:43.197212 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_42500.caffemodel
I1027 01:40:43.229919 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_42500.solverstate
I1027 01:40:43.248124 37958 solver.cpp:333] Iteration 42500, Testing net (#0)
I1027 01:41:13.934861 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 01:41:14.140915 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53252
I1027 01:41:14.140969 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77604
I1027 01:41:14.140980 37958 solver.cpp:400]     Test net output #2: loss = 2.08811 (* 1 = 2.08811 loss)
I1027 01:41:30.386378 37958 solver.cpp:221] Iteration 42520 (0.646731 iter/s, 61.8495s/40 iters), loss = 1.80486
I1027 01:41:30.386447 37958 solver.cpp:240]     Train net output #0: loss = 1.80486 (* 1 = 1.80486 loss)
I1027 01:41:30.386461 37958 sgd_solver.cpp:105] Iteration 42520, lr = 0.00749882
I1027 01:41:41.419083 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1027 01:42:01.325618 37958 solver.cpp:221] Iteration 42560 (1.29291 iter/s, 30.938s/40 iters), loss = 1.79329
I1027 01:42:01.325903 37958 solver.cpp:240]     Train net output #0: loss = 1.79329 (* 1 = 1.79329 loss)
I1027 01:42:01.325935 37958 sgd_solver.cpp:105] Iteration 42560, lr = 0.00749647
I1027 01:42:32.822525 37958 solver.cpp:221] Iteration 42600 (1.27003 iter/s, 31.4954s/40 iters), loss = 1.64692
I1027 01:42:32.822775 37958 solver.cpp:240]     Train net output #0: loss = 1.64692 (* 1 = 1.64692 loss)
I1027 01:42:32.822795 37958 sgd_solver.cpp:105] Iteration 42600, lr = 0.00749412
I1027 01:43:04.448299 37958 solver.cpp:221] Iteration 42640 (1.26485 iter/s, 31.6243s/40 iters), loss = 1.99902
I1027 01:43:04.448484 37958 solver.cpp:240]     Train net output #0: loss = 1.99902 (* 1 = 1.99902 loss)
I1027 01:43:04.448499 37958 sgd_solver.cpp:105] Iteration 42640, lr = 0.00749177
I1027 01:43:46.225309 37958 solver.cpp:221] Iteration 42680 (0.957505 iter/s, 41.7752s/40 iters), loss = 1.82561
I1027 01:43:46.225538 37958 solver.cpp:240]     Train net output #0: loss = 1.82561 (* 1 = 1.82561 loss)
I1027 01:43:46.225558 37958 sgd_solver.cpp:105] Iteration 42680, lr = 0.00748941
I1027 01:44:19.234470 37958 solver.cpp:221] Iteration 42720 (1.21184 iter/s, 33.0077s/40 iters), loss = 1.8135
I1027 01:44:19.234691 37958 solver.cpp:240]     Train net output #0: loss = 1.8135 (* 1 = 1.8135 loss)
I1027 01:44:19.234706 37958 sgd_solver.cpp:105] Iteration 42720, lr = 0.00748706
I1027 01:44:50.369724 37958 solver.cpp:221] Iteration 42760 (1.28478 iter/s, 31.1339s/40 iters), loss = 1.56316
I1027 01:44:50.369899 37958 solver.cpp:240]     Train net output #0: loss = 1.56316 (* 1 = 1.56316 loss)
I1027 01:44:50.369912 37958 sgd_solver.cpp:105] Iteration 42760, lr = 0.00748471
I1027 01:45:21.702766 37958 solver.cpp:221] Iteration 42800 (1.27666 iter/s, 31.3317s/40 iters), loss = 1.58727
I1027 01:45:21.702980 37958 solver.cpp:240]     Train net output #0: loss = 1.58727 (* 1 = 1.58727 loss)
I1027 01:45:21.702996 37958 sgd_solver.cpp:105] Iteration 42800, lr = 0.00748235
I1027 01:45:52.732157 37958 solver.cpp:221] Iteration 42840 (1.28916 iter/s, 31.028s/40 iters), loss = 1.60324
I1027 01:45:52.732337 37958 solver.cpp:240]     Train net output #0: loss = 1.60324 (* 1 = 1.60324 loss)
I1027 01:45:52.732352 37958 sgd_solver.cpp:105] Iteration 42840, lr = 0.00748
I1027 01:46:23.613134 37958 solver.cpp:221] Iteration 42880 (1.29535 iter/s, 30.8796s/40 iters), loss = 1.91362
I1027 01:46:23.613328 37958 solver.cpp:240]     Train net output #0: loss = 1.91362 (* 1 = 1.91362 loss)
I1027 01:46:23.613343 37958 sgd_solver.cpp:105] Iteration 42880, lr = 0.00747765
I1027 01:46:54.320127 37958 solver.cpp:221] Iteration 42920 (1.30269 iter/s, 30.7056s/40 iters), loss = 1.73588
I1027 01:46:54.320294 37958 solver.cpp:240]     Train net output #0: loss = 1.73588 (* 1 = 1.73588 loss)
I1027 01:46:54.320315 37958 sgd_solver.cpp:105] Iteration 42920, lr = 0.00747529
I1027 01:47:24.666103 37958 solver.cpp:221] Iteration 42960 (1.31819 iter/s, 30.3447s/40 iters), loss = 1.57467
I1027 01:47:24.666307 37958 solver.cpp:240]     Train net output #0: loss = 1.57467 (* 1 = 1.57467 loss)
I1027 01:47:24.666326 37958 sgd_solver.cpp:105] Iteration 42960, lr = 0.00747294
I1027 01:47:54.630097 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_43000.caffemodel
I1027 01:47:54.662045 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_43000.solverstate
I1027 01:47:54.685130 37958 solver.cpp:333] Iteration 43000, Testing net (#0)
I1027 01:48:25.547610 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.5364
I1027 01:48:25.547888 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.775119
I1027 01:48:25.547935 37958 solver.cpp:400]     Test net output #2: loss = 2.05726 (* 1 = 2.05726 loss)
I1027 01:48:26.310037 37958 solver.cpp:221] Iteration 43000 (0.648914 iter/s, 61.6414s/40 iters), loss = 1.84906
I1027 01:48:26.310098 37958 solver.cpp:240]     Train net output #0: loss = 1.84906 (* 1 = 1.84906 loss)
I1027 01:48:26.310112 37958 sgd_solver.cpp:105] Iteration 43000, lr = 0.00747059
I1027 01:48:56.760272 37958 solver.cpp:221] Iteration 43040 (1.31367 iter/s, 30.449s/40 iters), loss = 1.66071
I1027 01:48:56.760514 37958 solver.cpp:240]     Train net output #0: loss = 1.66071 (* 1 = 1.66071 loss)
I1027 01:48:56.760529 37958 sgd_solver.cpp:105] Iteration 43040, lr = 0.00746824
I1027 01:49:27.274555 37958 solver.cpp:221] Iteration 43080 (1.31092 iter/s, 30.5129s/40 iters), loss = 1.98598
I1027 01:49:27.274686 37958 solver.cpp:240]     Train net output #0: loss = 1.98598 (* 1 = 1.98598 loss)
I1027 01:49:27.274700 37958 sgd_solver.cpp:105] Iteration 43080, lr = 0.00746588
I1027 01:49:57.793956 37958 solver.cpp:221] Iteration 43120 (1.3107 iter/s, 30.5181s/40 iters), loss = 1.50592
I1027 01:49:57.794102 37958 solver.cpp:240]     Train net output #0: loss = 1.50592 (* 1 = 1.50592 loss)
I1027 01:49:57.794117 37958 sgd_solver.cpp:105] Iteration 43120, lr = 0.00746353
I1027 01:50:35.474051 37958 solver.cpp:221] Iteration 43160 (1.06161 iter/s, 37.6785s/40 iters), loss = 1.75699
I1027 01:50:35.474244 37958 solver.cpp:240]     Train net output #0: loss = 1.75699 (* 1 = 1.75699 loss)
I1027 01:50:35.474259 37958 sgd_solver.cpp:105] Iteration 43160, lr = 0.00746118
I1027 01:51:06.280706 37958 solver.cpp:221] Iteration 43200 (1.29848 iter/s, 30.8053s/40 iters), loss = 2.08796
I1027 01:51:06.280894 37958 solver.cpp:240]     Train net output #0: loss = 2.08796 (* 1 = 2.08796 loss)
I1027 01:51:06.280908 37958 sgd_solver.cpp:105] Iteration 43200, lr = 0.00745882
I1027 01:51:36.770964 37958 solver.cpp:221] Iteration 43240 (1.31195 iter/s, 30.4889s/40 iters), loss = 2.14496
I1027 01:51:36.771124 37958 solver.cpp:240]     Train net output #0: loss = 2.14496 (* 1 = 2.14496 loss)
I1027 01:51:36.771138 37958 sgd_solver.cpp:105] Iteration 43240, lr = 0.00745647
I1027 01:52:10.518510 37958 solver.cpp:221] Iteration 43280 (1.18532 iter/s, 33.7461s/40 iters), loss = 1.70967
I1027 01:52:10.518676 37958 solver.cpp:240]     Train net output #0: loss = 1.70967 (* 1 = 1.70967 loss)
I1027 01:52:10.518690 37958 sgd_solver.cpp:105] Iteration 43280, lr = 0.00745412
I1027 01:52:41.112702 37958 solver.cpp:221] Iteration 43320 (1.30749 iter/s, 30.5929s/40 iters), loss = 1.96964
I1027 01:52:41.112860 37958 solver.cpp:240]     Train net output #0: loss = 1.96964 (* 1 = 1.96964 loss)
I1027 01:52:41.112874 37958 sgd_solver.cpp:105] Iteration 43320, lr = 0.00745176
I1027 01:53:11.858268 37958 solver.cpp:221] Iteration 43360 (1.30106 iter/s, 30.7442s/40 iters), loss = 2.0926
I1027 01:53:11.858440 37958 solver.cpp:240]     Train net output #0: loss = 2.0926 (* 1 = 2.0926 loss)
I1027 01:53:11.858455 37958 sgd_solver.cpp:105] Iteration 43360, lr = 0.00744941
I1027 01:53:44.177281 37958 solver.cpp:221] Iteration 43400 (1.23772 iter/s, 32.3176s/40 iters), loss = 1.53887
I1027 01:53:44.177532 37958 solver.cpp:240]     Train net output #0: loss = 1.53887 (* 1 = 1.53887 loss)
I1027 01:53:44.177556 37958 sgd_solver.cpp:105] Iteration 43400, lr = 0.00744706
I1027 01:54:16.435823 37958 solver.cpp:221] Iteration 43440 (1.24004 iter/s, 32.2571s/40 iters), loss = 1.82749
I1027 01:54:16.436030 37958 solver.cpp:240]     Train net output #0: loss = 1.82749 (* 1 = 1.82749 loss)
I1027 01:54:16.436045 37958 sgd_solver.cpp:105] Iteration 43440, lr = 0.00744471
I1027 01:54:47.385601 37958 solver.cpp:221] Iteration 43480 (1.29247 iter/s, 30.9484s/40 iters), loss = 1.81103
I1027 01:54:47.385810 37958 solver.cpp:240]     Train net output #0: loss = 1.81103 (* 1 = 1.81103 loss)
I1027 01:54:47.385825 37958 sgd_solver.cpp:105] Iteration 43480, lr = 0.00744235
I1027 01:55:01.976415 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_43500.caffemodel
I1027 01:55:02.010056 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_43500.solverstate
I1027 01:55:02.029772 37958 solver.cpp:333] Iteration 43500, Testing net (#0)
I1027 01:55:32.756986 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 01:55:32.963219 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52672
I1027 01:55:32.963270 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77036
I1027 01:55:32.963282 37958 solver.cpp:400]     Test net output #2: loss = 2.10157 (* 1 = 2.10157 loss)
I1027 01:55:49.108469 37958 solver.cpp:221] Iteration 43520 (0.648085 iter/s, 61.7203s/40 iters), loss = 2.09893
I1027 01:55:49.108530 37958 solver.cpp:240]     Train net output #0: loss = 2.09893 (* 1 = 2.09893 loss)
I1027 01:55:49.108543 37958 sgd_solver.cpp:105] Iteration 43520, lr = 0.00744
I1027 01:56:20.017484 37958 solver.cpp:221] Iteration 43560 (1.29417 iter/s, 30.9078s/40 iters), loss = 1.60693
I1027 01:56:20.017699 37958 solver.cpp:240]     Train net output #0: loss = 1.60693 (* 1 = 1.60693 loss)
I1027 01:56:20.017714 37958 sgd_solver.cpp:105] Iteration 43560, lr = 0.00743765
I1027 01:56:51.017202 37958 solver.cpp:221] Iteration 43600 (1.29039 iter/s, 30.9983s/40 iters), loss = 1.74306
I1027 01:56:51.017395 37958 solver.cpp:240]     Train net output #0: loss = 1.74306 (* 1 = 1.74306 loss)
I1027 01:56:51.017410 37958 sgd_solver.cpp:105] Iteration 43600, lr = 0.00743529
I1027 01:57:21.753154 37958 solver.cpp:221] Iteration 43640 (1.30147 iter/s, 30.7346s/40 iters), loss = 1.64373
I1027 01:57:21.753324 37958 solver.cpp:240]     Train net output #0: loss = 1.64373 (* 1 = 1.64373 loss)
I1027 01:57:21.753340 37958 sgd_solver.cpp:105] Iteration 43640, lr = 0.00743294
I1027 01:57:53.058704 37958 solver.cpp:221] Iteration 43680 (1.27778 iter/s, 31.3042s/40 iters), loss = 1.6996
I1027 01:57:53.058888 37958 solver.cpp:240]     Train net output #0: loss = 1.6996 (* 1 = 1.6996 loss)
I1027 01:57:53.058902 37958 sgd_solver.cpp:105] Iteration 43680, lr = 0.00743059
I1027 01:58:23.899554 37958 solver.cpp:221] Iteration 43720 (1.29704 iter/s, 30.8395s/40 iters), loss = 1.82571
I1027 01:58:23.899745 37958 solver.cpp:240]     Train net output #0: loss = 1.82571 (* 1 = 1.82571 loss)
I1027 01:58:23.899760 37958 sgd_solver.cpp:105] Iteration 43720, lr = 0.00742824
I1027 01:58:54.846220 37958 solver.cpp:221] Iteration 43760 (1.2926 iter/s, 30.9453s/40 iters), loss = 1.59785
I1027 01:58:54.846401 37958 solver.cpp:240]     Train net output #0: loss = 1.59785 (* 1 = 1.59785 loss)
I1027 01:58:54.846416 37958 sgd_solver.cpp:105] Iteration 43760, lr = 0.00742588
I1027 01:59:25.596633 37958 solver.cpp:221] Iteration 43800 (1.30085 iter/s, 30.7491s/40 iters), loss = 1.81058
I1027 01:59:25.596801 37958 solver.cpp:240]     Train net output #0: loss = 1.81058 (* 1 = 1.81058 loss)
I1027 01:59:25.596815 37958 sgd_solver.cpp:105] Iteration 43800, lr = 0.00742353
I1027 01:59:56.508189 37958 solver.cpp:221] Iteration 43840 (1.29407 iter/s, 30.9102s/40 iters), loss = 2.05597
I1027 01:59:56.508378 37958 solver.cpp:240]     Train net output #0: loss = 2.05597 (* 1 = 2.05597 loss)
I1027 01:59:56.508393 37958 sgd_solver.cpp:105] Iteration 43840, lr = 0.00742118
I1027 02:00:26.914255 37958 solver.cpp:221] Iteration 43880 (1.31559 iter/s, 30.4047s/40 iters), loss = 1.87354
I1027 02:00:26.914429 37958 solver.cpp:240]     Train net output #0: loss = 1.87354 (* 1 = 1.87354 loss)
I1027 02:00:26.914445 37958 sgd_solver.cpp:105] Iteration 43880, lr = 0.00741882
I1027 02:00:57.340621 37958 solver.cpp:221] Iteration 43920 (1.31471 iter/s, 30.425s/40 iters), loss = 1.89162
I1027 02:00:57.340821 37958 solver.cpp:240]     Train net output #0: loss = 1.89162 (* 1 = 1.89162 loss)
I1027 02:00:57.340836 37958 sgd_solver.cpp:105] Iteration 43920, lr = 0.00741647
I1027 02:01:27.739768 37958 solver.cpp:221] Iteration 43960 (1.31588 iter/s, 30.3978s/40 iters), loss = 1.70949
I1027 02:01:27.740011 37958 solver.cpp:240]     Train net output #0: loss = 1.70949 (* 1 = 1.70949 loss)
I1027 02:01:27.740036 37958 sgd_solver.cpp:105] Iteration 43960, lr = 0.00741412
I1027 02:01:57.295620 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_44000.caffemodel
I1027 02:01:57.328393 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_44000.solverstate
I1027 02:01:57.351253 37958 solver.cpp:333] Iteration 44000, Testing net (#0)
I1027 02:02:28.272523 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53372
I1027 02:02:28.272711 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77192
I1027 02:02:28.272723 37958 solver.cpp:400]     Test net output #2: loss = 2.06743 (* 1 = 2.06743 loss)
I1027 02:02:29.035064 37958 solver.cpp:221] Iteration 44000 (0.652606 iter/s, 61.2928s/40 iters), loss = 1.57379
I1027 02:02:29.035125 37958 solver.cpp:240]     Train net output #0: loss = 1.57379 (* 1 = 1.57379 loss)
I1027 02:02:29.035137 37958 sgd_solver.cpp:105] Iteration 44000, lr = 0.00741176
I1027 02:02:59.685276 37958 solver.cpp:221] Iteration 44040 (1.3051 iter/s, 30.649s/40 iters), loss = 1.68482
I1027 02:02:59.685452 37958 solver.cpp:240]     Train net output #0: loss = 1.68482 (* 1 = 1.68482 loss)
I1027 02:02:59.685467 37958 sgd_solver.cpp:105] Iteration 44040, lr = 0.00740941
I1027 02:03:30.422922 37958 solver.cpp:221] Iteration 44080 (1.30139 iter/s, 30.7363s/40 iters), loss = 1.47056
I1027 02:03:30.423084 37958 solver.cpp:240]     Train net output #0: loss = 1.47056 (* 1 = 1.47056 loss)
I1027 02:03:30.423099 37958 sgd_solver.cpp:105] Iteration 44080, lr = 0.00740706
I1027 02:04:01.690124 37958 solver.cpp:221] Iteration 44120 (1.27935 iter/s, 31.2658s/40 iters), loss = 1.56703
I1027 02:04:01.690382 37958 solver.cpp:240]     Train net output #0: loss = 1.56703 (* 1 = 1.56703 loss)
I1027 02:04:01.690403 37958 sgd_solver.cpp:105] Iteration 44120, lr = 0.00740471
I1027 02:04:33.480914 37958 solver.cpp:221] Iteration 44160 (1.25828 iter/s, 31.7893s/40 iters), loss = 1.57098
I1027 02:04:33.481112 37958 solver.cpp:240]     Train net output #0: loss = 1.57098 (* 1 = 1.57098 loss)
I1027 02:04:33.481127 37958 sgd_solver.cpp:105] Iteration 44160, lr = 0.00740235
I1027 02:05:04.869828 37958 solver.cpp:221] Iteration 44200 (1.27439 iter/s, 31.3875s/40 iters), loss = 1.92823
I1027 02:05:04.870039 37958 solver.cpp:240]     Train net output #0: loss = 1.92823 (* 1 = 1.92823 loss)
I1027 02:05:04.870054 37958 sgd_solver.cpp:105] Iteration 44200, lr = 0.0074
I1027 02:05:35.514673 37958 solver.cpp:221] Iteration 44240 (1.30534 iter/s, 30.6435s/40 iters), loss = 1.78647
I1027 02:05:35.514864 37958 solver.cpp:240]     Train net output #0: loss = 1.78647 (* 1 = 1.78647 loss)
I1027 02:05:35.514879 37958 sgd_solver.cpp:105] Iteration 44240, lr = 0.00739765
I1027 02:06:06.762413 37958 solver.cpp:221] Iteration 44280 (1.28015 iter/s, 31.2464s/40 iters), loss = 1.39667
I1027 02:06:06.762624 37958 solver.cpp:240]     Train net output #0: loss = 1.39667 (* 1 = 1.39667 loss)
I1027 02:06:06.762639 37958 sgd_solver.cpp:105] Iteration 44280, lr = 0.00739529
I1027 02:06:37.301039 37958 solver.cpp:221] Iteration 44320 (1.30988 iter/s, 30.5373s/40 iters), loss = 1.72826
I1027 02:06:37.301199 37958 solver.cpp:240]     Train net output #0: loss = 1.72826 (* 1 = 1.72826 loss)
I1027 02:06:37.301214 37958 sgd_solver.cpp:105] Iteration 44320, lr = 0.00739294
I1027 02:07:08.116513 37958 solver.cpp:221] Iteration 44360 (1.29811 iter/s, 30.8141s/40 iters), loss = 1.76439
I1027 02:07:08.116734 37958 solver.cpp:240]     Train net output #0: loss = 1.76439 (* 1 = 1.76439 loss)
I1027 02:07:08.116756 37958 sgd_solver.cpp:105] Iteration 44360, lr = 0.00739059
I1027 02:07:38.892495 37958 solver.cpp:221] Iteration 44400 (1.29977 iter/s, 30.7746s/40 iters), loss = 1.99404
I1027 02:07:38.892693 37958 solver.cpp:240]     Train net output #0: loss = 1.99404 (* 1 = 1.99404 loss)
I1027 02:07:38.892707 37958 sgd_solver.cpp:105] Iteration 44400, lr = 0.00738824
I1027 02:08:10.506450 37958 solver.cpp:221] Iteration 44440 (1.26532 iter/s, 31.6126s/40 iters), loss = 1.95663
I1027 02:08:10.506785 37958 solver.cpp:240]     Train net output #0: loss = 1.95663 (* 1 = 1.95663 loss)
I1027 02:08:10.506808 37958 sgd_solver.cpp:105] Iteration 44440, lr = 0.00738588
I1027 02:08:43.110360 37958 solver.cpp:221] Iteration 44480 (1.22691 iter/s, 32.6023s/40 iters), loss = 1.58239
I1027 02:08:43.110532 37958 solver.cpp:240]     Train net output #0: loss = 1.58239 (* 1 = 1.58239 loss)
I1027 02:08:43.110548 37958 sgd_solver.cpp:105] Iteration 44480, lr = 0.00738353
I1027 02:08:57.585070 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_44500.caffemodel
I1027 02:08:57.618930 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_44500.solverstate
I1027 02:08:57.638222 37958 solver.cpp:333] Iteration 44500, Testing net (#0)
I1027 02:09:28.244518 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 02:09:28.450532 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53628
I1027 02:09:28.450585 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77668
I1027 02:09:28.450597 37958 solver.cpp:400]     Test net output #2: loss = 2.06326 (* 1 = 2.06326 loss)
I1027 02:09:44.532563 37958 solver.cpp:221] Iteration 44520 (0.651257 iter/s, 61.4197s/40 iters), loss = 1.51574
I1027 02:09:44.532632 37958 solver.cpp:240]     Train net output #0: loss = 1.51574 (* 1 = 1.51574 loss)
I1027 02:09:44.532646 37958 sgd_solver.cpp:105] Iteration 44520, lr = 0.00738118
I1027 02:10:14.974750 37958 solver.cpp:221] Iteration 44560 (1.31402 iter/s, 30.441s/40 iters), loss = 1.9265
I1027 02:10:14.974952 37958 solver.cpp:240]     Train net output #0: loss = 1.9265 (* 1 = 1.9265 loss)
I1027 02:10:14.974967 37958 sgd_solver.cpp:105] Iteration 44560, lr = 0.00737882
I1027 02:10:45.203474 37958 solver.cpp:221] Iteration 44600 (1.3233 iter/s, 30.2274s/40 iters), loss = 1.67605
I1027 02:10:45.203615 37958 solver.cpp:240]     Train net output #0: loss = 1.67605 (* 1 = 1.67605 loss)
I1027 02:10:45.203630 37958 sgd_solver.cpp:105] Iteration 44600, lr = 0.00737647
I1027 02:11:15.453410 37958 solver.cpp:221] Iteration 44640 (1.32237 iter/s, 30.2487s/40 iters), loss = 1.76525
I1027 02:11:15.453589 37958 solver.cpp:240]     Train net output #0: loss = 1.76525 (* 1 = 1.76525 loss)
I1027 02:11:15.453604 37958 sgd_solver.cpp:105] Iteration 44640, lr = 0.00737412
I1027 02:11:46.254206 37958 solver.cpp:221] Iteration 44680 (1.29872 iter/s, 30.7995s/40 iters), loss = 1.64227
I1027 02:11:46.254387 37958 solver.cpp:240]     Train net output #0: loss = 1.64227 (* 1 = 1.64227 loss)
I1027 02:11:46.254402 37958 sgd_solver.cpp:105] Iteration 44680, lr = 0.00737176
I1027 02:12:16.654278 37958 solver.cpp:221] Iteration 44720 (1.31584 iter/s, 30.3987s/40 iters), loss = 1.92106
I1027 02:12:16.654430 37958 solver.cpp:240]     Train net output #0: loss = 1.92106 (* 1 = 1.92106 loss)
I1027 02:12:16.654446 37958 sgd_solver.cpp:105] Iteration 44720, lr = 0.00736941
I1027 02:12:47.067276 37958 solver.cpp:221] Iteration 44760 (1.31528 iter/s, 30.4117s/40 iters), loss = 1.71821
I1027 02:12:47.067433 37958 solver.cpp:240]     Train net output #0: loss = 1.71821 (* 1 = 1.71821 loss)
I1027 02:12:47.067448 37958 sgd_solver.cpp:105] Iteration 44760, lr = 0.00736706
I1027 02:13:18.080087 37958 solver.cpp:221] Iteration 44800 (1.28984 iter/s, 31.0115s/40 iters), loss = 2.20245
I1027 02:13:18.080240 37958 solver.cpp:240]     Train net output #0: loss = 2.20245 (* 1 = 2.20245 loss)
I1027 02:13:18.080255 37958 sgd_solver.cpp:105] Iteration 44800, lr = 0.00736471
I1027 02:13:48.709172 37958 solver.cpp:221] Iteration 44840 (1.306 iter/s, 30.6278s/40 iters), loss = 1.85075
I1027 02:13:48.709358 37958 solver.cpp:240]     Train net output #0: loss = 1.85075 (* 1 = 1.85075 loss)
I1027 02:13:48.709373 37958 sgd_solver.cpp:105] Iteration 44840, lr = 0.00736235
I1027 02:14:19.701860 37958 solver.cpp:221] Iteration 44880 (1.29068 iter/s, 30.9913s/40 iters), loss = 1.69344
I1027 02:14:19.702070 37958 solver.cpp:240]     Train net output #0: loss = 1.69344 (* 1 = 1.69344 loss)
I1027 02:14:19.702087 37958 sgd_solver.cpp:105] Iteration 44880, lr = 0.00736
I1027 02:14:50.707299 37958 solver.cpp:221] Iteration 44920 (1.29015 iter/s, 31.0041s/40 iters), loss = 1.56493
I1027 02:14:50.707492 37958 solver.cpp:240]     Train net output #0: loss = 1.56493 (* 1 = 1.56493 loss)
I1027 02:14:50.707507 37958 sgd_solver.cpp:105] Iteration 44920, lr = 0.00735765
I1027 02:15:21.627209 37958 solver.cpp:221] Iteration 44960 (1.29372 iter/s, 30.9185s/40 iters), loss = 2.021
I1027 02:15:21.627409 37958 solver.cpp:240]     Train net output #0: loss = 2.021 (* 1 = 2.021 loss)
I1027 02:15:21.627425 37958 sgd_solver.cpp:105] Iteration 44960, lr = 0.00735529
I1027 02:15:52.039412 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_45000.caffemodel
I1027 02:15:52.078979 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_45000.solverstate
I1027 02:15:52.102879 37958 solver.cpp:333] Iteration 45000, Testing net (#0)
I1027 02:16:23.017117 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.5294
I1027 02:16:23.017278 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.770279
I1027 02:16:23.017292 37958 solver.cpp:400]     Test net output #2: loss = 2.09456 (* 1 = 2.09456 loss)
I1027 02:16:23.776329 37958 solver.cpp:221] Iteration 45000 (0.64364 iter/s, 62.1466s/40 iters), loss = 1.88024
I1027 02:16:23.776388 37958 solver.cpp:240]     Train net output #0: loss = 1.88024 (* 1 = 1.88024 loss)
I1027 02:16:23.776404 37958 sgd_solver.cpp:105] Iteration 45000, lr = 0.00735294
I1027 02:16:52.010852 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1027 02:16:54.298413 37958 solver.cpp:221] Iteration 45040 (1.31058 iter/s, 30.5208s/40 iters), loss = 2.24484
I1027 02:16:54.298645 37958 solver.cpp:240]     Train net output #0: loss = 2.24484 (* 1 = 2.24484 loss)
I1027 02:16:54.298666 37958 sgd_solver.cpp:105] Iteration 45040, lr = 0.00735059
I1027 02:17:25.370342 37958 solver.cpp:221] Iteration 45080 (1.28739 iter/s, 31.0705s/40 iters), loss = 2.01359
I1027 02:17:25.370524 37958 solver.cpp:240]     Train net output #0: loss = 2.01359 (* 1 = 2.01359 loss)
I1027 02:17:25.370539 37958 sgd_solver.cpp:105] Iteration 45080, lr = 0.00734824
I1027 02:17:55.787580 37958 solver.cpp:221] Iteration 45120 (1.3151 iter/s, 30.4159s/40 iters), loss = 1.92137
I1027 02:17:55.787786 37958 solver.cpp:240]     Train net output #0: loss = 1.92137 (* 1 = 1.92137 loss)
I1027 02:17:55.787801 37958 sgd_solver.cpp:105] Iteration 45120, lr = 0.00734588
I1027 02:18:27.199185 37958 solver.cpp:221] Iteration 45160 (1.27347 iter/s, 31.4102s/40 iters), loss = 1.95916
I1027 02:18:27.199415 37958 solver.cpp:240]     Train net output #0: loss = 1.95916 (* 1 = 1.95916 loss)
I1027 02:18:27.199430 37958 sgd_solver.cpp:105] Iteration 45160, lr = 0.00734353
I1027 02:18:57.618063 37958 solver.cpp:221] Iteration 45200 (1.31503 iter/s, 30.4175s/40 iters), loss = 1.58349
I1027 02:18:57.618221 37958 solver.cpp:240]     Train net output #0: loss = 1.58349 (* 1 = 1.58349 loss)
I1027 02:18:57.618235 37958 sgd_solver.cpp:105] Iteration 45200, lr = 0.00734118
I1027 02:19:28.022904 37958 solver.cpp:221] Iteration 45240 (1.31564 iter/s, 30.4035s/40 iters), loss = 1.75247
I1027 02:19:28.022997 37958 solver.cpp:240]     Train net output #0: loss = 1.75247 (* 1 = 1.75247 loss)
I1027 02:19:28.023012 37958 sgd_solver.cpp:105] Iteration 45240, lr = 0.00733882
I1027 02:19:58.403797 37958 solver.cpp:221] Iteration 45280 (1.31667 iter/s, 30.3796s/40 iters), loss = 1.75778
I1027 02:19:58.403937 37958 solver.cpp:240]     Train net output #0: loss = 1.75778 (* 1 = 1.75778 loss)
I1027 02:19:58.403952 37958 sgd_solver.cpp:105] Iteration 45280, lr = 0.00733647
I1027 02:20:28.784881 37958 solver.cpp:221] Iteration 45320 (1.31666 iter/s, 30.3798s/40 iters), loss = 1.76466
I1027 02:20:28.785066 37958 solver.cpp:240]     Train net output #0: loss = 1.76466 (* 1 = 1.76466 loss)
I1027 02:20:28.785092 37958 sgd_solver.cpp:105] Iteration 45320, lr = 0.00733412
I1027 02:20:59.201472 37958 solver.cpp:221] Iteration 45360 (1.31513 iter/s, 30.4153s/40 iters), loss = 1.93982
I1027 02:20:59.201593 37958 solver.cpp:240]     Train net output #0: loss = 1.93982 (* 1 = 1.93982 loss)
I1027 02:20:59.201608 37958 sgd_solver.cpp:105] Iteration 45360, lr = 0.00733176
I1027 02:21:29.749238 37958 solver.cpp:221] Iteration 45400 (1.30948 iter/s, 30.5465s/40 iters), loss = 1.97852
I1027 02:21:29.749403 37958 solver.cpp:240]     Train net output #0: loss = 1.97852 (* 1 = 1.97852 loss)
I1027 02:21:29.749418 37958 sgd_solver.cpp:105] Iteration 45400, lr = 0.00732941
I1027 02:22:00.173146 37958 solver.cpp:221] Iteration 45440 (1.31481 iter/s, 30.4226s/40 iters), loss = 1.66848
I1027 02:22:00.173315 37958 solver.cpp:240]     Train net output #0: loss = 1.66848 (* 1 = 1.66848 loss)
I1027 02:22:00.173329 37958 sgd_solver.cpp:105] Iteration 45440, lr = 0.00732706
I1027 02:22:30.711161 37958 solver.cpp:221] Iteration 45480 (1.3099 iter/s, 30.5367s/40 iters), loss = 1.61558
I1027 02:22:30.711372 37958 solver.cpp:240]     Train net output #0: loss = 1.61558 (* 1 = 1.61558 loss)
I1027 02:22:30.711387 37958 sgd_solver.cpp:105] Iteration 45480, lr = 0.00732471
I1027 02:22:45.436868 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_45500.caffemodel
I1027 02:22:45.482914 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_45500.solverstate
I1027 02:22:45.508903 37958 solver.cpp:333] Iteration 45500, Testing net (#0)
I1027 02:23:16.243583 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 02:23:16.449543 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.5342
I1027 02:23:16.449592 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.7748
I1027 02:23:16.449604 37958 solver.cpp:400]     Test net output #2: loss = 2.09958 (* 1 = 2.09958 loss)
I1027 02:23:32.879694 37958 solver.cpp:221] Iteration 45520 (0.643439 iter/s, 62.166s/40 iters), loss = 1.62788
I1027 02:23:32.879758 37958 solver.cpp:240]     Train net output #0: loss = 1.62788 (* 1 = 1.62788 loss)
I1027 02:23:32.879771 37958 sgd_solver.cpp:105] Iteration 45520, lr = 0.00732235
I1027 02:24:04.504649 37958 solver.cpp:221] Iteration 45560 (1.26488 iter/s, 31.6237s/40 iters), loss = 1.97446
I1027 02:24:04.504921 37958 solver.cpp:240]     Train net output #0: loss = 1.97446 (* 1 = 1.97446 loss)
I1027 02:24:04.504941 37958 sgd_solver.cpp:105] Iteration 45560, lr = 0.00732
I1027 02:25:28.019686 37958 solver.cpp:221] Iteration 45600 (0.478975 iter/s, 83.5116s/40 iters), loss = 1.60986
I1027 02:25:28.019888 37958 solver.cpp:240]     Train net output #0: loss = 1.60986 (* 1 = 1.60986 loss)
I1027 02:25:28.019903 37958 sgd_solver.cpp:105] Iteration 45600, lr = 0.00731765
I1027 02:25:59.354419 37958 solver.cpp:221] Iteration 45640 (1.2766 iter/s, 31.3333s/40 iters), loss = 1.75363
I1027 02:25:59.354625 37958 solver.cpp:240]     Train net output #0: loss = 1.75363 (* 1 = 1.75363 loss)
I1027 02:25:59.354640 37958 sgd_solver.cpp:105] Iteration 45640, lr = 0.00731529
I1027 02:26:30.248757 37958 solver.cpp:221] Iteration 45680 (1.29479 iter/s, 30.893s/40 iters), loss = 1.71681
I1027 02:26:30.248951 37958 solver.cpp:240]     Train net output #0: loss = 1.71681 (* 1 = 1.71681 loss)
I1027 02:26:30.248966 37958 sgd_solver.cpp:105] Iteration 45680, lr = 0.00731294
I1027 02:27:01.229842 37958 solver.cpp:221] Iteration 45720 (1.29117 iter/s, 30.9797s/40 iters), loss = 1.58794
I1027 02:27:01.230047 37958 solver.cpp:240]     Train net output #0: loss = 1.58794 (* 1 = 1.58794 loss)
I1027 02:27:01.230065 37958 sgd_solver.cpp:105] Iteration 45720, lr = 0.00731059
I1027 02:27:32.149950 37958 solver.cpp:221] Iteration 45760 (1.29371 iter/s, 30.9187s/40 iters), loss = 1.87784
I1027 02:27:32.150183 37958 solver.cpp:240]     Train net output #0: loss = 1.87784 (* 1 = 1.87784 loss)
I1027 02:27:32.150205 37958 sgd_solver.cpp:105] Iteration 45760, lr = 0.00730823
I1027 02:28:03.382652 37958 solver.cpp:221] Iteration 45800 (1.28077 iter/s, 31.2313s/40 iters), loss = 1.68387
I1027 02:28:03.382948 37958 solver.cpp:240]     Train net output #0: loss = 1.68387 (* 1 = 1.68387 loss)
I1027 02:28:03.382979 37958 sgd_solver.cpp:105] Iteration 45800, lr = 0.00730588
I1027 02:28:33.847448 37958 solver.cpp:221] Iteration 45840 (1.31305 iter/s, 30.4633s/40 iters), loss = 2.04233
I1027 02:28:33.847604 37958 solver.cpp:240]     Train net output #0: loss = 2.04233 (* 1 = 2.04233 loss)
I1027 02:28:33.847617 37958 sgd_solver.cpp:105] Iteration 45840, lr = 0.00730353
I1027 02:29:04.629743 37958 solver.cpp:221] Iteration 45880 (1.2995 iter/s, 30.781s/40 iters), loss = 1.57716
I1027 02:29:04.629943 37958 solver.cpp:240]     Train net output #0: loss = 1.57716 (* 1 = 1.57716 loss)
I1027 02:29:04.629958 37958 sgd_solver.cpp:105] Iteration 45880, lr = 0.00730118
I1027 02:29:35.441193 37958 solver.cpp:221] Iteration 45920 (1.29828 iter/s, 30.8101s/40 iters), loss = 1.57799
I1027 02:29:35.441402 37958 solver.cpp:240]     Train net output #0: loss = 1.57799 (* 1 = 1.57799 loss)
I1027 02:29:35.441418 37958 sgd_solver.cpp:105] Iteration 45920, lr = 0.00729882
I1027 02:30:05.756925 37958 solver.cpp:221] Iteration 45960 (1.31951 iter/s, 30.3144s/40 iters), loss = 1.87594
I1027 02:30:05.757100 37958 solver.cpp:240]     Train net output #0: loss = 1.87594 (* 1 = 1.87594 loss)
I1027 02:30:05.757115 37958 sgd_solver.cpp:105] Iteration 45960, lr = 0.00729647
I1027 02:30:35.502893 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_46000.caffemodel
I1027 02:30:35.538125 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_46000.solverstate
I1027 02:30:35.560029 37958 solver.cpp:333] Iteration 46000, Testing net (#0)
I1027 02:31:06.721247 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53908
I1027 02:31:06.721444 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77832
I1027 02:31:06.721458 37958 solver.cpp:400]     Test net output #2: loss = 2.02932 (* 1 = 2.02932 loss)
I1027 02:31:07.491017 37958 solver.cpp:221] Iteration 46000 (0.647966 iter/s, 61.7316s/40 iters), loss = 1.69771
I1027 02:31:07.491076 37958 solver.cpp:240]     Train net output #0: loss = 1.69771 (* 1 = 1.69771 loss)
I1027 02:31:07.491091 37958 sgd_solver.cpp:105] Iteration 46000, lr = 0.00729412
I1027 02:31:38.040314 37958 solver.cpp:221] Iteration 46040 (1.30941 iter/s, 30.5481s/40 iters), loss = 1.99034
I1027 02:31:38.040534 37958 solver.cpp:240]     Train net output #0: loss = 1.99034 (* 1 = 1.99034 loss)
I1027 02:31:38.040549 37958 sgd_solver.cpp:105] Iteration 46040, lr = 0.00729176
I1027 02:32:08.550315 37958 solver.cpp:221] Iteration 46080 (1.31111 iter/s, 30.5086s/40 iters), loss = 1.86338
I1027 02:32:08.550493 37958 solver.cpp:240]     Train net output #0: loss = 1.86338 (* 1 = 1.86338 loss)
I1027 02:32:08.550508 37958 sgd_solver.cpp:105] Iteration 46080, lr = 0.00728941
I1027 02:32:39.060250 37958 solver.cpp:221] Iteration 46120 (1.31111 iter/s, 30.5086s/40 iters), loss = 1.95059
I1027 02:32:39.060436 37958 solver.cpp:240]     Train net output #0: loss = 1.95059 (* 1 = 1.95059 loss)
I1027 02:32:39.060451 37958 sgd_solver.cpp:105] Iteration 46120, lr = 0.00728706
I1027 02:33:09.293274 37958 solver.cpp:221] Iteration 46160 (1.32312 iter/s, 30.2317s/40 iters), loss = 1.90747
I1027 02:33:09.293418 37958 solver.cpp:240]     Train net output #0: loss = 1.90747 (* 1 = 1.90747 loss)
I1027 02:33:09.293433 37958 sgd_solver.cpp:105] Iteration 46160, lr = 0.00728471
I1027 02:33:39.626324 37958 solver.cpp:221] Iteration 46200 (1.31875 iter/s, 30.3317s/40 iters), loss = 1.81145
I1027 02:33:39.626471 37958 solver.cpp:240]     Train net output #0: loss = 1.81145 (* 1 = 1.81145 loss)
I1027 02:33:39.626487 37958 sgd_solver.cpp:105] Iteration 46200, lr = 0.00728235
I1027 02:34:10.019024 37958 solver.cpp:221] Iteration 46240 (1.31616 iter/s, 30.3914s/40 iters), loss = 1.6809
I1027 02:34:10.019230 37958 solver.cpp:240]     Train net output #0: loss = 1.6809 (* 1 = 1.6809 loss)
I1027 02:34:10.019245 37958 sgd_solver.cpp:105] Iteration 46240, lr = 0.00728
I1027 02:34:40.502387 37958 solver.cpp:221] Iteration 46280 (1.31225 iter/s, 30.482s/40 iters), loss = 1.49262
I1027 02:34:40.502581 37958 solver.cpp:240]     Train net output #0: loss = 1.49262 (* 1 = 1.49262 loss)
I1027 02:34:40.502595 37958 sgd_solver.cpp:105] Iteration 46280, lr = 0.00727765
I1027 02:35:10.910542 37958 solver.cpp:221] Iteration 46320 (1.31549 iter/s, 30.4068s/40 iters), loss = 1.37885
I1027 02:35:10.910692 37958 solver.cpp:240]     Train net output #0: loss = 1.37885 (* 1 = 1.37885 loss)
I1027 02:35:10.910707 37958 sgd_solver.cpp:105] Iteration 46320, lr = 0.00727529
I1027 02:35:41.340250 37958 solver.cpp:221] Iteration 46360 (1.31456 iter/s, 30.4284s/40 iters), loss = 1.80158
I1027 02:35:41.340394 37958 solver.cpp:240]     Train net output #0: loss = 1.80158 (* 1 = 1.80158 loss)
I1027 02:35:41.340407 37958 sgd_solver.cpp:105] Iteration 46360, lr = 0.00727294
I1027 02:36:12.830087 37958 solver.cpp:221] Iteration 46400 (1.27031 iter/s, 31.4885s/40 iters), loss = 1.75607
I1027 02:36:12.830308 37958 solver.cpp:240]     Train net output #0: loss = 1.75607 (* 1 = 1.75607 loss)
I1027 02:36:12.830327 37958 sgd_solver.cpp:105] Iteration 46400, lr = 0.00727059
I1027 02:36:43.685047 37958 solver.cpp:221] Iteration 46440 (1.29645 iter/s, 30.8536s/40 iters), loss = 2.03358
I1027 02:36:43.685225 37958 solver.cpp:240]     Train net output #0: loss = 2.03358 (* 1 = 2.03358 loss)
I1027 02:36:43.685241 37958 sgd_solver.cpp:105] Iteration 46440, lr = 0.00726824
I1027 02:37:14.671303 37958 solver.cpp:221] Iteration 46480 (1.29095 iter/s, 30.9849s/40 iters), loss = 1.75333
I1027 02:37:14.671473 37958 solver.cpp:240]     Train net output #0: loss = 1.75333 (* 1 = 1.75333 loss)
I1027 02:37:14.671489 37958 sgd_solver.cpp:105] Iteration 46480, lr = 0.00726588
I1027 02:37:29.480988 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_46500.caffemodel
I1027 02:37:29.512800 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_46500.solverstate
I1027 02:37:29.532227 37958 solver.cpp:333] Iteration 46500, Testing net (#0)
I1027 02:38:00.175748 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 02:38:00.383450 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.52844
I1027 02:38:00.383505 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77392
I1027 02:38:00.383517 37958 solver.cpp:400]     Test net output #2: loss = 2.08545 (* 1 = 2.08545 loss)
I1027 02:38:16.875654 37958 solver.cpp:221] Iteration 46520 (0.643068 iter/s, 62.2019s/40 iters), loss = 1.92247
I1027 02:38:16.875718 37958 solver.cpp:240]     Train net output #0: loss = 1.92247 (* 1 = 1.92247 loss)
I1027 02:38:16.875732 37958 sgd_solver.cpp:105] Iteration 46520, lr = 0.00726353
I1027 02:38:47.883304 37958 solver.cpp:221] Iteration 46560 (1.29006 iter/s, 31.0064s/40 iters), loss = 1.76072
I1027 02:38:47.883472 37958 solver.cpp:240]     Train net output #0: loss = 1.76072 (* 1 = 1.76072 loss)
I1027 02:38:47.883487 37958 sgd_solver.cpp:105] Iteration 46560, lr = 0.00726118
I1027 02:39:19.229446 37958 solver.cpp:221] Iteration 46600 (1.27613 iter/s, 31.3448s/40 iters), loss = 1.57847
I1027 02:39:19.229681 37958 solver.cpp:240]     Train net output #0: loss = 1.57847 (* 1 = 1.57847 loss)
I1027 02:39:19.229704 37958 sgd_solver.cpp:105] Iteration 46600, lr = 0.00725882
I1027 02:39:55.041890 37958 solver.cpp:221] Iteration 46640 (1.11698 iter/s, 35.8108s/40 iters), loss = 1.8799
I1027 02:39:55.042083 37958 solver.cpp:240]     Train net output #0: loss = 1.8799 (* 1 = 1.8799 loss)
I1027 02:39:55.042105 37958 sgd_solver.cpp:105] Iteration 46640, lr = 0.00725647
I1027 02:40:25.720511 37958 solver.cpp:221] Iteration 46680 (1.3039 iter/s, 30.6773s/40 iters), loss = 2.24551
I1027 02:40:25.720754 37958 solver.cpp:240]     Train net output #0: loss = 2.24551 (* 1 = 2.24551 loss)
I1027 02:40:25.720783 37958 sgd_solver.cpp:105] Iteration 46680, lr = 0.00725412
I1027 02:40:56.267915 37958 solver.cpp:221] Iteration 46720 (1.3095 iter/s, 30.546s/40 iters), loss = 1.30587
I1027 02:40:56.268098 37958 solver.cpp:240]     Train net output #0: loss = 1.30587 (* 1 = 1.30587 loss)
I1027 02:40:56.268115 37958 sgd_solver.cpp:105] Iteration 46720, lr = 0.00725176
I1027 02:41:27.071481 37958 solver.cpp:221] Iteration 46760 (1.29861 iter/s, 30.8022s/40 iters), loss = 1.58631
I1027 02:41:27.071760 37958 solver.cpp:240]     Train net output #0: loss = 1.58631 (* 1 = 1.58631 loss)
I1027 02:41:27.071784 37958 sgd_solver.cpp:105] Iteration 46760, lr = 0.00724941
I1027 02:41:58.524287 37958 solver.cpp:221] Iteration 46800 (1.27181 iter/s, 31.4513s/40 iters), loss = 1.71019
I1027 02:41:58.524462 37958 solver.cpp:240]     Train net output #0: loss = 1.71019 (* 1 = 1.71019 loss)
I1027 02:41:58.524477 37958 sgd_solver.cpp:105] Iteration 46800, lr = 0.00724706
I1027 02:42:29.318591 37958 solver.cpp:221] Iteration 46840 (1.299 iter/s, 30.793s/40 iters), loss = 1.59033
I1027 02:42:29.318784 37958 solver.cpp:240]     Train net output #0: loss = 1.59033 (* 1 = 1.59033 loss)
I1027 02:42:29.318799 37958 sgd_solver.cpp:105] Iteration 46840, lr = 0.00724471
I1027 02:42:59.981995 37958 solver.cpp:221] Iteration 46880 (1.30455 iter/s, 30.662s/40 iters), loss = 1.66785
I1027 02:42:59.982210 37958 solver.cpp:240]     Train net output #0: loss = 1.66785 (* 1 = 1.66785 loss)
I1027 02:42:59.982230 37958 sgd_solver.cpp:105] Iteration 46880, lr = 0.00724235
I1027 02:43:30.931754 37958 solver.cpp:221] Iteration 46920 (1.29248 iter/s, 30.9484s/40 iters), loss = 1.71432
I1027 02:43:30.932013 37958 solver.cpp:240]     Train net output #0: loss = 1.71432 (* 1 = 1.71432 loss)
I1027 02:43:30.932035 37958 sgd_solver.cpp:105] Iteration 46920, lr = 0.00724
I1027 02:44:01.644407 37958 solver.cpp:221] Iteration 46960 (1.30245 iter/s, 30.7112s/40 iters), loss = 1.82755
I1027 02:44:01.644593 37958 solver.cpp:240]     Train net output #0: loss = 1.82755 (* 1 = 1.82755 loss)
I1027 02:44:01.644608 37958 sgd_solver.cpp:105] Iteration 46960, lr = 0.00723765
I1027 02:44:31.365193 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_47000.caffemodel
I1027 02:44:31.399469 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_47000.solverstate
I1027 02:44:31.417206 37958 solver.cpp:333] Iteration 47000, Testing net (#0)
I1027 02:45:02.218845 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53908
I1027 02:45:02.219050 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.778199
I1027 02:45:02.219064 37958 solver.cpp:400]     Test net output #2: loss = 2.08273 (* 1 = 2.08273 loss)
I1027 02:45:02.988548 37958 solver.cpp:221] Iteration 47000 (0.652085 iter/s, 61.3417s/40 iters), loss = 1.6014
I1027 02:45:02.988607 37958 solver.cpp:240]     Train net output #0: loss = 1.6014 (* 1 = 1.6014 loss)
I1027 02:45:02.988622 37958 sgd_solver.cpp:105] Iteration 47000, lr = 0.00723529
I1027 02:45:34.268318 37958 solver.cpp:221] Iteration 47040 (1.27883 iter/s, 31.2785s/40 iters), loss = 2.13308
I1027 02:45:34.268519 37958 solver.cpp:240]     Train net output #0: loss = 2.13308 (* 1 = 2.13308 loss)
I1027 02:45:34.268534 37958 sgd_solver.cpp:105] Iteration 47040, lr = 0.00723294
I1027 02:46:05.234010 37958 solver.cpp:221] Iteration 47080 (1.29181 iter/s, 30.9643s/40 iters), loss = 2.0476
I1027 02:46:05.234227 37958 solver.cpp:240]     Train net output #0: loss = 2.0476 (* 1 = 2.0476 loss)
I1027 02:46:05.234242 37958 sgd_solver.cpp:105] Iteration 47080, lr = 0.00723059
I1027 02:46:37.485026 37958 solver.cpp:221] Iteration 47120 (1.24033 iter/s, 32.2496s/40 iters), loss = 1.69746
I1027 02:46:37.485225 37958 solver.cpp:240]     Train net output #0: loss = 1.69746 (* 1 = 1.69746 loss)
I1027 02:46:37.485244 37958 sgd_solver.cpp:105] Iteration 47120, lr = 0.00722823
I1027 02:47:08.313047 37958 solver.cpp:221] Iteration 47160 (1.29758 iter/s, 30.8267s/40 iters), loss = 1.96426
I1027 02:47:08.313310 37958 solver.cpp:240]     Train net output #0: loss = 1.96426 (* 1 = 1.96426 loss)
I1027 02:47:08.313328 37958 sgd_solver.cpp:105] Iteration 47160, lr = 0.00722588
I1027 02:47:38.991199 37958 solver.cpp:221] Iteration 47200 (1.30392 iter/s, 30.6767s/40 iters), loss = 1.76056
I1027 02:47:38.991554 37958 solver.cpp:240]     Train net output #0: loss = 1.76056 (* 1 = 1.76056 loss)
I1027 02:47:38.991569 37958 sgd_solver.cpp:105] Iteration 47200, lr = 0.00722353
I1027 02:48:10.036120 37958 solver.cpp:221] Iteration 47240 (1.28852 iter/s, 31.0434s/40 iters), loss = 1.84204
I1027 02:48:10.036309 37958 solver.cpp:240]     Train net output #0: loss = 1.84204 (* 1 = 1.84204 loss)
I1027 02:48:10.036325 37958 sgd_solver.cpp:105] Iteration 47240, lr = 0.00722118
I1027 02:48:41.081928 37958 solver.cpp:221] Iteration 47280 (1.28848 iter/s, 31.0444s/40 iters), loss = 1.97026
I1027 02:48:41.082139 37958 solver.cpp:240]     Train net output #0: loss = 1.97026 (* 1 = 1.97026 loss)
I1027 02:48:41.082154 37958 sgd_solver.cpp:105] Iteration 47280, lr = 0.00721882
I1027 02:49:11.904548 37958 solver.cpp:221] Iteration 47320 (1.29781 iter/s, 30.8212s/40 iters), loss = 1.78292
I1027 02:49:11.904731 37958 solver.cpp:240]     Train net output #0: loss = 1.78292 (* 1 = 1.78292 loss)
I1027 02:49:11.904747 37958 sgd_solver.cpp:105] Iteration 47320, lr = 0.00721647
I1027 02:49:43.411397 37958 solver.cpp:221] Iteration 47360 (1.26962 iter/s, 31.5055s/40 iters), loss = 1.45769
I1027 02:49:43.411577 37958 solver.cpp:240]     Train net output #0: loss = 1.45769 (* 1 = 1.45769 loss)
I1027 02:49:43.411592 37958 sgd_solver.cpp:105] Iteration 47360, lr = 0.00721412
I1027 02:50:13.877363 37958 solver.cpp:221] Iteration 47400 (1.313 iter/s, 30.4646s/40 iters), loss = 1.54171
I1027 02:50:13.877545 37958 solver.cpp:240]     Train net output #0: loss = 1.54171 (* 1 = 1.54171 loss)
I1027 02:50:13.877560 37958 sgd_solver.cpp:105] Iteration 47400, lr = 0.00721176
I1027 02:50:44.869552 37958 solver.cpp:221] Iteration 47440 (1.2907 iter/s, 30.9908s/40 iters), loss = 1.85933
I1027 02:50:44.869746 37958 solver.cpp:240]     Train net output #0: loss = 1.85933 (* 1 = 1.85933 loss)
I1027 02:50:44.869761 37958 sgd_solver.cpp:105] Iteration 47440, lr = 0.00720941
I1027 02:51:15.922757 37958 solver.cpp:221] Iteration 47480 (1.28817 iter/s, 31.0518s/40 iters), loss = 2.04645
I1027 02:51:15.922997 37958 solver.cpp:240]     Train net output #0: loss = 2.04645 (* 1 = 2.04645 loss)
I1027 02:51:15.923019 37958 sgd_solver.cpp:105] Iteration 47480, lr = 0.00720706
I1027 02:51:30.622628 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_47500.caffemodel
I1027 02:51:30.656235 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_47500.solverstate
I1027 02:51:30.674134 37958 solver.cpp:333] Iteration 47500, Testing net (#0)
I1027 02:52:01.317334 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 02:52:01.523490 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53652
I1027 02:52:01.523542 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77624
I1027 02:52:01.523555 37958 solver.cpp:400]     Test net output #2: loss = 2.09152 (* 1 = 2.09152 loss)
I1027 02:52:17.796962 37958 solver.cpp:221] Iteration 47520 (0.6465 iter/s, 61.8717s/40 iters), loss = 1.84318
I1027 02:52:17.797034 37958 solver.cpp:240]     Train net output #0: loss = 1.84318 (* 1 = 1.84318 loss)
I1027 02:52:17.797047 37958 sgd_solver.cpp:105] Iteration 47520, lr = 0.00720471
I1027 02:52:32.604887 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1027 02:52:48.760048 37958 solver.cpp:221] Iteration 47560 (1.29191 iter/s, 30.9618s/40 iters), loss = 1.76001
I1027 02:52:48.760119 37958 solver.cpp:240]     Train net output #0: loss = 1.76001 (* 1 = 1.76001 loss)
I1027 02:52:48.760133 37958 sgd_solver.cpp:105] Iteration 47560, lr = 0.00720235
I1027 02:53:19.732900 37958 solver.cpp:221] Iteration 47600 (1.29151 iter/s, 30.9716s/40 iters), loss = 1.74896
I1027 02:53:19.733222 37958 solver.cpp:240]     Train net output #0: loss = 1.74896 (* 1 = 1.74896 loss)
I1027 02:53:19.733247 37958 sgd_solver.cpp:105] Iteration 47600, lr = 0.0072
I1027 02:53:50.700278 37958 solver.cpp:221] Iteration 47640 (1.29174 iter/s, 30.9659s/40 iters), loss = 1.48092
I1027 02:53:50.700482 37958 solver.cpp:240]     Train net output #0: loss = 1.48092 (* 1 = 1.48092 loss)
I1027 02:53:50.700497 37958 sgd_solver.cpp:105] Iteration 47640, lr = 0.00719765
I1027 02:54:21.721540 37958 solver.cpp:221] Iteration 47680 (1.2895 iter/s, 31.0199s/40 iters), loss = 1.56484
I1027 02:54:21.721722 37958 solver.cpp:240]     Train net output #0: loss = 1.56484 (* 1 = 1.56484 loss)
I1027 02:54:21.721736 37958 sgd_solver.cpp:105] Iteration 47680, lr = 0.00719529
I1027 02:54:53.016981 37958 solver.cpp:221] Iteration 47720 (1.2782 iter/s, 31.2941s/40 iters), loss = 1.57606
I1027 02:54:53.017185 37958 solver.cpp:240]     Train net output #0: loss = 1.57606 (* 1 = 1.57606 loss)
I1027 02:54:53.017200 37958 sgd_solver.cpp:105] Iteration 47720, lr = 0.00719294
I1027 02:55:24.290799 37958 solver.cpp:221] Iteration 47760 (1.27908 iter/s, 31.2724s/40 iters), loss = 1.78165
I1027 02:55:24.290961 37958 solver.cpp:240]     Train net output #0: loss = 1.78165 (* 1 = 1.78165 loss)
I1027 02:55:24.290979 37958 sgd_solver.cpp:105] Iteration 47760, lr = 0.00719059
I1027 02:55:56.143081 37958 solver.cpp:221] Iteration 47800 (1.25585 iter/s, 31.8509s/40 iters), loss = 2.01954
I1027 02:55:56.143291 37958 solver.cpp:240]     Train net output #0: loss = 2.01954 (* 1 = 2.01954 loss)
I1027 02:55:56.143312 37958 sgd_solver.cpp:105] Iteration 47800, lr = 0.00718824
I1027 02:56:27.304944 37958 solver.cpp:221] Iteration 47840 (1.28368 iter/s, 31.1605s/40 iters), loss = 1.91967
I1027 02:56:27.305140 37958 solver.cpp:240]     Train net output #0: loss = 1.91967 (* 1 = 1.91967 loss)
I1027 02:56:27.305155 37958 sgd_solver.cpp:105] Iteration 47840, lr = 0.00718588
I1027 02:56:58.117920 37958 solver.cpp:221] Iteration 47880 (1.29821 iter/s, 30.8116s/40 iters), loss = 1.63629
I1027 02:56:58.118095 37958 solver.cpp:240]     Train net output #0: loss = 1.63629 (* 1 = 1.63629 loss)
I1027 02:56:58.118110 37958 sgd_solver.cpp:105] Iteration 47880, lr = 0.00718353
I1027 02:57:29.802461 37958 solver.cpp:221] Iteration 47920 (1.2625 iter/s, 31.6832s/40 iters), loss = 1.66501
I1027 02:57:29.802666 37958 solver.cpp:240]     Train net output #0: loss = 1.66501 (* 1 = 1.66501 loss)
I1027 02:57:29.802682 37958 sgd_solver.cpp:105] Iteration 47920, lr = 0.00718118
I1027 02:58:00.866420 37958 solver.cpp:221] Iteration 47960 (1.28772 iter/s, 31.0626s/40 iters), loss = 1.58615
I1027 02:58:00.866681 37958 solver.cpp:240]     Train net output #0: loss = 1.58615 (* 1 = 1.58615 loss)
I1027 02:58:00.866703 37958 sgd_solver.cpp:105] Iteration 47960, lr = 0.00717882
I1027 02:58:31.335571 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_48000.caffemodel
I1027 02:58:31.368268 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_48000.solverstate
I1027 02:58:31.386435 37958 solver.cpp:333] Iteration 48000, Testing net (#0)
I1027 02:59:02.261646 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53264
I1027 02:59:02.261833 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77472
I1027 02:59:02.261847 37958 solver.cpp:400]     Test net output #2: loss = 2.1 (* 1 = 2.1 loss)
I1027 02:59:03.018931 37958 solver.cpp:221] Iteration 48000 (0.643605 iter/s, 62.1499s/40 iters), loss = 1.93883
I1027 02:59:03.018995 37958 solver.cpp:240]     Train net output #0: loss = 1.93883 (* 1 = 1.93883 loss)
I1027 02:59:03.019007 37958 sgd_solver.cpp:105] Iteration 48000, lr = 0.00717647
I1027 02:59:33.612185 37958 solver.cpp:221] Iteration 48040 (1.30753 iter/s, 30.592s/40 iters), loss = 1.53423
I1027 02:59:33.612447 37958 solver.cpp:240]     Train net output #0: loss = 1.53423 (* 1 = 1.53423 loss)
I1027 02:59:33.612473 37958 sgd_solver.cpp:105] Iteration 48040, lr = 0.00717412
I1027 03:00:04.212453 37958 solver.cpp:221] Iteration 48080 (1.30724 iter/s, 30.5989s/40 iters), loss = 1.68758
I1027 03:00:04.212657 37958 solver.cpp:240]     Train net output #0: loss = 1.68758 (* 1 = 1.68758 loss)
I1027 03:00:04.212672 37958 sgd_solver.cpp:105] Iteration 48080, lr = 0.00717176
I1027 03:00:34.608587 37958 solver.cpp:221] Iteration 48120 (1.31602 iter/s, 30.3948s/40 iters), loss = 1.66734
I1027 03:00:34.608760 37958 solver.cpp:240]     Train net output #0: loss = 1.66734 (* 1 = 1.66734 loss)
I1027 03:00:34.608775 37958 sgd_solver.cpp:105] Iteration 48120, lr = 0.00716941
I1027 03:01:05.398281 37958 solver.cpp:221] Iteration 48160 (1.29919 iter/s, 30.7883s/40 iters), loss = 2.11078
I1027 03:01:05.398536 37958 solver.cpp:240]     Train net output #0: loss = 2.11078 (* 1 = 2.11078 loss)
I1027 03:01:05.398560 37958 sgd_solver.cpp:105] Iteration 48160, lr = 0.00716706
I1027 03:01:36.344400 37958 solver.cpp:221] Iteration 48200 (1.29263 iter/s, 30.9447s/40 iters), loss = 1.86259
I1027 03:01:36.344635 37958 solver.cpp:240]     Train net output #0: loss = 1.86259 (* 1 = 1.86259 loss)
I1027 03:01:36.344653 37958 sgd_solver.cpp:105] Iteration 48200, lr = 0.00716471
I1027 03:02:06.963629 37958 solver.cpp:221] Iteration 48240 (1.30643 iter/s, 30.6178s/40 iters), loss = 1.50649
I1027 03:02:06.963830 37958 solver.cpp:240]     Train net output #0: loss = 1.50649 (* 1 = 1.50649 loss)
I1027 03:02:06.963845 37958 sgd_solver.cpp:105] Iteration 48240, lr = 0.00716235
I1027 03:02:37.658190 37958 solver.cpp:221] Iteration 48280 (1.30322 iter/s, 30.6932s/40 iters), loss = 1.80551
I1027 03:02:37.658375 37958 solver.cpp:240]     Train net output #0: loss = 1.80551 (* 1 = 1.80551 loss)
I1027 03:02:37.658390 37958 sgd_solver.cpp:105] Iteration 48280, lr = 0.00716
I1027 03:03:08.078254 37958 solver.cpp:221] Iteration 48320 (1.31498 iter/s, 30.4187s/40 iters), loss = 1.92854
I1027 03:03:08.078433 37958 solver.cpp:240]     Train net output #0: loss = 1.92854 (* 1 = 1.92854 loss)
I1027 03:03:08.078447 37958 sgd_solver.cpp:105] Iteration 48320, lr = 0.00715765
I1027 03:03:38.386929 37958 solver.cpp:221] Iteration 48360 (1.31981 iter/s, 30.3074s/40 iters), loss = 2.05042
I1027 03:03:38.387115 37958 solver.cpp:240]     Train net output #0: loss = 2.05042 (* 1 = 2.05042 loss)
I1027 03:03:38.387128 37958 sgd_solver.cpp:105] Iteration 48360, lr = 0.00715529
I1027 03:04:09.422438 37958 solver.cpp:221] Iteration 48400 (1.2889 iter/s, 31.0342s/40 iters), loss = 1.91861
I1027 03:04:09.422629 37958 solver.cpp:240]     Train net output #0: loss = 1.91861 (* 1 = 1.91861 loss)
I1027 03:04:09.422643 37958 sgd_solver.cpp:105] Iteration 48400, lr = 0.00715294
I1027 03:04:40.267026 37958 solver.cpp:221] Iteration 48440 (1.29688 iter/s, 30.8432s/40 iters), loss = 1.85362
I1027 03:04:40.267230 37958 solver.cpp:240]     Train net output #0: loss = 1.85362 (* 1 = 1.85362 loss)
I1027 03:04:40.267244 37958 sgd_solver.cpp:105] Iteration 48440, lr = 0.00715059
I1027 03:05:11.323051 37958 solver.cpp:221] Iteration 48480 (1.28805 iter/s, 31.0547s/40 iters), loss = 2.12649
I1027 03:05:11.323227 37958 solver.cpp:240]     Train net output #0: loss = 2.12649 (* 1 = 2.12649 loss)
I1027 03:05:11.323241 37958 sgd_solver.cpp:105] Iteration 48480, lr = 0.00714824
I1027 03:05:25.879765 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_48500.caffemodel
I1027 03:05:25.912120 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_48500.solverstate
I1027 03:05:25.931293 37958 solver.cpp:333] Iteration 48500, Testing net (#0)
I1027 03:05:56.551487 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 03:05:56.759915 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53296
I1027 03:05:56.759973 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77468
I1027 03:05:56.759984 37958 solver.cpp:400]     Test net output #2: loss = 2.09594 (* 1 = 2.09594 loss)
I1027 03:06:12.980494 37958 solver.cpp:221] Iteration 48520 (0.648772 iter/s, 61.655s/40 iters), loss = 1.58551
I1027 03:06:12.980558 37958 solver.cpp:240]     Train net output #0: loss = 1.58551 (* 1 = 1.58551 loss)
I1027 03:06:12.980572 37958 sgd_solver.cpp:105] Iteration 48520, lr = 0.00714588
I1027 03:06:43.624615 37958 solver.cpp:221] Iteration 48560 (1.30536 iter/s, 30.6429s/40 iters), loss = 1.64497
I1027 03:06:43.624881 37958 solver.cpp:240]     Train net output #0: loss = 1.64497 (* 1 = 1.64497 loss)
I1027 03:06:43.624913 37958 sgd_solver.cpp:105] Iteration 48560, lr = 0.00714353
I1027 03:07:14.440254 37958 solver.cpp:221] Iteration 48600 (1.2981 iter/s, 30.8142s/40 iters), loss = 1.70421
I1027 03:07:14.440445 37958 solver.cpp:240]     Train net output #0: loss = 1.70421 (* 1 = 1.70421 loss)
I1027 03:07:14.440460 37958 sgd_solver.cpp:105] Iteration 48600, lr = 0.00714118
I1027 03:07:46.505267 37958 solver.cpp:221] Iteration 48640 (1.24752 iter/s, 32.0636s/40 iters), loss = 1.37205
I1027 03:07:46.505445 37958 solver.cpp:240]     Train net output #0: loss = 1.37205 (* 1 = 1.37205 loss)
I1027 03:07:46.505463 37958 sgd_solver.cpp:105] Iteration 48640, lr = 0.00713882
I1027 03:08:28.600772 37958 solver.cpp:221] Iteration 48680 (0.95026 iter/s, 42.0937s/40 iters), loss = 1.67494
I1027 03:08:28.600956 37958 solver.cpp:240]     Train net output #0: loss = 1.67494 (* 1 = 1.67494 loss)
I1027 03:08:28.600971 37958 sgd_solver.cpp:105] Iteration 48680, lr = 0.00713647
I1027 03:08:59.759582 37958 solver.cpp:221] Iteration 48720 (1.2838 iter/s, 31.1574s/40 iters), loss = 2.08586
I1027 03:08:59.759781 37958 solver.cpp:240]     Train net output #0: loss = 2.08586 (* 1 = 2.08586 loss)
I1027 03:08:59.759796 37958 sgd_solver.cpp:105] Iteration 48720, lr = 0.00713412
I1027 03:09:30.830395 37958 solver.cpp:221] Iteration 48760 (1.28744 iter/s, 31.0694s/40 iters), loss = 1.80715
I1027 03:09:30.830587 37958 solver.cpp:240]     Train net output #0: loss = 1.80715 (* 1 = 1.80715 loss)
I1027 03:09:30.830602 37958 sgd_solver.cpp:105] Iteration 48760, lr = 0.00713176
I1027 03:10:01.615360 37958 solver.cpp:221] Iteration 48800 (1.29939 iter/s, 30.7836s/40 iters), loss = 1.74002
I1027 03:10:01.615599 37958 solver.cpp:240]     Train net output #0: loss = 1.74002 (* 1 = 1.74002 loss)
I1027 03:10:01.615622 37958 sgd_solver.cpp:105] Iteration 48800, lr = 0.00712941
I1027 03:10:32.499167 37958 solver.cpp:221] Iteration 48840 (1.29524 iter/s, 30.8824s/40 iters), loss = 1.41606
I1027 03:10:32.499513 37958 solver.cpp:240]     Train net output #0: loss = 1.41606 (* 1 = 1.41606 loss)
I1027 03:10:32.499527 37958 sgd_solver.cpp:105] Iteration 48840, lr = 0.00712706
I1027 03:11:02.937894 37958 solver.cpp:221] Iteration 48880 (1.31418 iter/s, 30.4372s/40 iters), loss = 1.6698
I1027 03:11:02.938088 37958 solver.cpp:240]     Train net output #0: loss = 1.6698 (* 1 = 1.6698 loss)
I1027 03:11:02.938102 37958 sgd_solver.cpp:105] Iteration 48880, lr = 0.00712471
I1027 03:11:33.125517 37958 solver.cpp:221] Iteration 48920 (1.32511 iter/s, 30.1863s/40 iters), loss = 1.7634
I1027 03:11:33.125694 37958 solver.cpp:240]     Train net output #0: loss = 1.7634 (* 1 = 1.7634 loss)
I1027 03:11:33.125707 37958 sgd_solver.cpp:105] Iteration 48920, lr = 0.00712235
I1027 03:12:03.400527 37958 solver.cpp:221] Iteration 48960 (1.32128 iter/s, 30.2737s/40 iters), loss = 2.19662
I1027 03:12:03.400693 37958 solver.cpp:240]     Train net output #0: loss = 2.19662 (* 1 = 2.19662 loss)
I1027 03:12:03.400708 37958 sgd_solver.cpp:105] Iteration 48960, lr = 0.00712
I1027 03:12:33.145784 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_49000.caffemodel
I1027 03:12:33.189124 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_49000.solverstate
I1027 03:12:33.213536 37958 solver.cpp:333] Iteration 49000, Testing net (#0)
I1027 03:13:04.440609 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53808
I1027 03:13:04.440852 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77536
I1027 03:13:04.440877 37958 solver.cpp:400]     Test net output #2: loss = 2.08051 (* 1 = 2.08051 loss)
I1027 03:13:05.208015 37958 solver.cpp:221] Iteration 49000 (0.647197 iter/s, 61.805s/40 iters), loss = 1.64723
I1027 03:13:05.208072 37958 solver.cpp:240]     Train net output #0: loss = 1.64723 (* 1 = 1.64723 loss)
I1027 03:13:05.208086 37958 sgd_solver.cpp:105] Iteration 49000, lr = 0.00711765
I1027 03:13:35.593569 37958 solver.cpp:221] Iteration 49040 (1.31647 iter/s, 30.3843s/40 iters), loss = 2.02604
I1027 03:13:35.593741 37958 solver.cpp:240]     Train net output #0: loss = 2.02604 (* 1 = 2.02604 loss)
I1027 03:13:35.593765 37958 sgd_solver.cpp:105] Iteration 49040, lr = 0.00711529
I1027 03:14:07.179721 37958 solver.cpp:221] Iteration 49080 (1.26643 iter/s, 31.5848s/40 iters), loss = 1.81758
I1027 03:14:07.179893 37958 solver.cpp:240]     Train net output #0: loss = 1.81758 (* 1 = 1.81758 loss)
I1027 03:14:07.179908 37958 sgd_solver.cpp:105] Iteration 49080, lr = 0.00711294
I1027 03:14:37.971650 37958 solver.cpp:221] Iteration 49120 (1.2991 iter/s, 30.7906s/40 iters), loss = 1.98056
I1027 03:14:37.971843 37958 solver.cpp:240]     Train net output #0: loss = 1.98056 (* 1 = 1.98056 loss)
I1027 03:14:37.971860 37958 sgd_solver.cpp:105] Iteration 49120, lr = 0.00711059
I1027 03:15:08.799396 37958 solver.cpp:221] Iteration 49160 (1.29759 iter/s, 30.8264s/40 iters), loss = 1.31713
I1027 03:15:08.799576 37958 solver.cpp:240]     Train net output #0: loss = 1.31713 (* 1 = 1.31713 loss)
I1027 03:15:08.799590 37958 sgd_solver.cpp:105] Iteration 49160, lr = 0.00710824
I1027 03:15:39.944236 37958 solver.cpp:221] Iteration 49200 (1.28438 iter/s, 31.1435s/40 iters), loss = 1.77575
I1027 03:15:39.944422 37958 solver.cpp:240]     Train net output #0: loss = 1.77575 (* 1 = 1.77575 loss)
I1027 03:15:39.944437 37958 sgd_solver.cpp:105] Iteration 49200, lr = 0.00710588
I1027 03:16:10.878967 37958 solver.cpp:221] Iteration 49240 (1.2931 iter/s, 30.9334s/40 iters), loss = 1.95545
I1027 03:16:10.879142 37958 solver.cpp:240]     Train net output #0: loss = 1.95545 (* 1 = 1.95545 loss)
I1027 03:16:10.879158 37958 sgd_solver.cpp:105] Iteration 49240, lr = 0.00710353
I1027 03:16:41.545984 37958 solver.cpp:221] Iteration 49280 (1.30439 iter/s, 30.6657s/40 iters), loss = 1.88235
I1027 03:16:41.546175 37958 solver.cpp:240]     Train net output #0: loss = 1.88235 (* 1 = 1.88235 loss)
I1027 03:16:41.546190 37958 sgd_solver.cpp:105] Iteration 49280, lr = 0.00710118
I1027 03:17:12.631162 37958 solver.cpp:221] Iteration 49320 (1.28684 iter/s, 31.0838s/40 iters), loss = 2.11771
I1027 03:17:12.631490 37958 solver.cpp:240]     Train net output #0: loss = 2.11771 (* 1 = 2.11771 loss)
I1027 03:17:12.631510 37958 sgd_solver.cpp:105] Iteration 49320, lr = 0.00709882
I1027 03:17:44.120579 37958 solver.cpp:221] Iteration 49360 (1.27033 iter/s, 31.4879s/40 iters), loss = 1.93145
I1027 03:17:44.120777 37958 solver.cpp:240]     Train net output #0: loss = 1.93145 (* 1 = 1.93145 loss)
I1027 03:17:44.120792 37958 sgd_solver.cpp:105] Iteration 49360, lr = 0.00709647
I1027 03:18:15.595551 37958 solver.cpp:221] Iteration 49400 (1.27091 iter/s, 31.4736s/40 iters), loss = 1.97478
I1027 03:18:15.595754 37958 solver.cpp:240]     Train net output #0: loss = 1.97478 (* 1 = 1.97478 loss)
I1027 03:18:15.595769 37958 sgd_solver.cpp:105] Iteration 49400, lr = 0.00709412
I1027 03:18:47.129627 37958 solver.cpp:221] Iteration 49440 (1.26853 iter/s, 31.5327s/40 iters), loss = 2.04195
I1027 03:18:47.129830 37958 solver.cpp:240]     Train net output #0: loss = 2.04195 (* 1 = 2.04195 loss)
I1027 03:18:47.129845 37958 sgd_solver.cpp:105] Iteration 49440, lr = 0.00709176
I1027 03:19:18.547019 37958 solver.cpp:221] Iteration 49480 (1.27324 iter/s, 31.416s/40 iters), loss = 1.395
I1027 03:19:18.547238 37958 solver.cpp:240]     Train net output #0: loss = 1.395 (* 1 = 1.395 loss)
I1027 03:19:18.547253 37958 sgd_solver.cpp:105] Iteration 49480, lr = 0.00708941
I1027 03:19:33.158005 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_49500.caffemodel
I1027 03:19:33.192814 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_49500.solverstate
I1027 03:19:33.216773 37958 solver.cpp:333] Iteration 49500, Testing net (#0)
I1027 03:20:03.858984 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 03:20:04.064882 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53456
I1027 03:20:04.064936 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77848
I1027 03:20:04.064947 37958 solver.cpp:400]     Test net output #2: loss = 2.05075 (* 1 = 2.05075 loss)
I1027 03:20:20.560230 37958 solver.cpp:221] Iteration 49520 (0.64505 iter/s, 62.0107s/40 iters), loss = 1.63046
I1027 03:20:20.560303 37958 solver.cpp:240]     Train net output #0: loss = 1.63046 (* 1 = 1.63046 loss)
I1027 03:20:20.560319 37958 sgd_solver.cpp:105] Iteration 49520, lr = 0.00708706
I1027 03:20:51.884104 37958 solver.cpp:221] Iteration 49560 (1.27703 iter/s, 31.3226s/40 iters), loss = 1.78467
I1027 03:20:51.884347 37958 solver.cpp:240]     Train net output #0: loss = 1.78467 (* 1 = 1.78467 loss)
I1027 03:20:51.884371 37958 sgd_solver.cpp:105] Iteration 49560, lr = 0.00708471
I1027 03:21:22.988039 37958 solver.cpp:221] Iteration 49600 (1.28607 iter/s, 31.1025s/40 iters), loss = 1.66775
I1027 03:21:22.988211 37958 solver.cpp:240]     Train net output #0: loss = 1.66775 (* 1 = 1.66775 loss)
I1027 03:21:22.988226 37958 sgd_solver.cpp:105] Iteration 49600, lr = 0.00708235
I1027 03:21:54.957847 37958 solver.cpp:221] Iteration 49640 (1.25124 iter/s, 31.9684s/40 iters), loss = 1.86045
I1027 03:21:54.958034 37958 solver.cpp:240]     Train net output #0: loss = 1.86045 (* 1 = 1.86045 loss)
I1027 03:21:54.958048 37958 sgd_solver.cpp:105] Iteration 49640, lr = 0.00708
I1027 03:22:25.868335 37958 solver.cpp:221] Iteration 49680 (1.29412 iter/s, 30.9091s/40 iters), loss = 1.69998
I1027 03:22:25.868500 37958 solver.cpp:240]     Train net output #0: loss = 1.69998 (* 1 = 1.69998 loss)
I1027 03:22:25.868515 37958 sgd_solver.cpp:105] Iteration 49680, lr = 0.00707765
I1027 03:22:57.372696 37958 solver.cpp:221] Iteration 49720 (1.26972 iter/s, 31.503s/40 iters), loss = 1.83852
I1027 03:22:57.372894 37958 solver.cpp:240]     Train net output #0: loss = 1.83852 (* 1 = 1.83852 loss)
I1027 03:22:57.372907 37958 sgd_solver.cpp:105] Iteration 49720, lr = 0.00707529
I1027 03:23:28.222380 37958 solver.cpp:221] Iteration 49760 (1.29667 iter/s, 30.8483s/40 iters), loss = 1.50506
I1027 03:23:28.222560 37958 solver.cpp:240]     Train net output #0: loss = 1.50506 (* 1 = 1.50506 loss)
I1027 03:23:28.222575 37958 sgd_solver.cpp:105] Iteration 49760, lr = 0.00707294
I1027 03:23:59.071462 37958 solver.cpp:221] Iteration 49800 (1.29669 iter/s, 30.8477s/40 iters), loss = 1.71355
I1027 03:23:59.071672 37958 solver.cpp:240]     Train net output #0: loss = 1.71355 (* 1 = 1.71355 loss)
I1027 03:23:59.071689 37958 sgd_solver.cpp:105] Iteration 49800, lr = 0.00707059
I1027 03:24:30.172101 37958 solver.cpp:221] Iteration 49840 (1.28621 iter/s, 31.0992s/40 iters), loss = 1.5495
I1027 03:24:30.172345 37958 solver.cpp:240]     Train net output #0: loss = 1.5495 (* 1 = 1.5495 loss)
I1027 03:24:30.172366 37958 sgd_solver.cpp:105] Iteration 49840, lr = 0.00706823
I1027 03:25:01.517354 37958 solver.cpp:221] Iteration 49880 (1.27617 iter/s, 31.3438s/40 iters), loss = 1.88442
I1027 03:25:01.517567 37958 solver.cpp:240]     Train net output #0: loss = 1.88442 (* 1 = 1.88442 loss)
I1027 03:25:01.517582 37958 sgd_solver.cpp:105] Iteration 49880, lr = 0.00706588
I1027 03:25:32.520263 37958 solver.cpp:221] Iteration 49920 (1.29026 iter/s, 31.0015s/40 iters), loss = 1.97786
I1027 03:25:32.520473 37958 solver.cpp:240]     Train net output #0: loss = 1.97786 (* 1 = 1.97786 loss)
I1027 03:25:32.520489 37958 sgd_solver.cpp:105] Iteration 49920, lr = 0.00706353
I1027 03:26:03.399696 37958 solver.cpp:221] Iteration 49960 (1.29542 iter/s, 30.8781s/40 iters), loss = 2.09529
I1027 03:26:03.399921 37958 solver.cpp:240]     Train net output #0: loss = 2.09529 (* 1 = 2.09529 loss)
I1027 03:26:03.399948 37958 sgd_solver.cpp:105] Iteration 49960, lr = 0.00706118
I1027 03:26:33.702340 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_50000.caffemodel
I1027 03:26:33.735613 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_50000.solverstate
I1027 03:26:33.754750 37958 solver.cpp:333] Iteration 50000, Testing net (#0)
I1027 03:27:04.586196 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53832
I1027 03:27:04.586410 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.778199
I1027 03:27:04.586424 37958 solver.cpp:400]     Test net output #2: loss = 2.06889 (* 1 = 2.06889 loss)
I1027 03:27:05.348412 37958 solver.cpp:221] Iteration 50000 (0.645722 iter/s, 61.9462s/40 iters), loss = 1.5698
I1027 03:27:05.348470 37958 solver.cpp:240]     Train net output #0: loss = 1.5698 (* 1 = 1.5698 loss)
I1027 03:27:05.348484 37958 sgd_solver.cpp:105] Iteration 50000, lr = 0.00705882
I1027 03:27:36.480332 37958 solver.cpp:221] Iteration 50040 (1.28491 iter/s, 31.1307s/40 iters), loss = 2.04956
I1027 03:27:36.480556 37958 solver.cpp:240]     Train net output #0: loss = 2.04956 (* 1 = 2.04956 loss)
I1027 03:27:36.480571 37958 sgd_solver.cpp:105] Iteration 50040, lr = 0.00705647
I1027 03:27:37.561974 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1027 03:28:07.742965 37958 solver.cpp:221] Iteration 50080 (1.27954 iter/s, 31.2612s/40 iters), loss = 1.66199
I1027 03:28:07.743206 37958 solver.cpp:240]     Train net output #0: loss = 1.66199 (* 1 = 1.66199 loss)
I1027 03:28:07.743232 37958 sgd_solver.cpp:105] Iteration 50080, lr = 0.00705412
I1027 03:28:38.688519 37958 solver.cpp:221] Iteration 50120 (1.29265 iter/s, 30.9441s/40 iters), loss = 1.85695
I1027 03:28:38.688719 37958 solver.cpp:240]     Train net output #0: loss = 1.85695 (* 1 = 1.85695 loss)
I1027 03:28:38.688746 37958 sgd_solver.cpp:105] Iteration 50120, lr = 0.00705176
I1027 03:29:09.217952 37958 solver.cpp:221] Iteration 50160 (1.31027 iter/s, 30.5281s/40 iters), loss = 1.62966
I1027 03:29:09.218099 37958 solver.cpp:240]     Train net output #0: loss = 1.62966 (* 1 = 1.62966 loss)
I1027 03:29:09.218114 37958 sgd_solver.cpp:105] Iteration 50160, lr = 0.00704941
I1027 03:29:39.617534 37958 solver.cpp:221] Iteration 50200 (1.31586 iter/s, 30.3983s/40 iters), loss = 1.71512
I1027 03:29:39.617702 37958 solver.cpp:240]     Train net output #0: loss = 1.71512 (* 1 = 1.71512 loss)
I1027 03:29:39.617715 37958 sgd_solver.cpp:105] Iteration 50200, lr = 0.00704706
I1027 03:30:10.193893 37958 solver.cpp:221] Iteration 50240 (1.30826 iter/s, 30.575s/40 iters), loss = 1.60092
I1027 03:30:10.194070 37958 solver.cpp:240]     Train net output #0: loss = 1.60092 (* 1 = 1.60092 loss)
I1027 03:30:10.194085 37958 sgd_solver.cpp:105] Iteration 50240, lr = 0.00704471
I1027 03:30:40.763546 37958 solver.cpp:221] Iteration 50280 (1.30854 iter/s, 30.5683s/40 iters), loss = 1.71825
I1027 03:30:40.763728 37958 solver.cpp:240]     Train net output #0: loss = 1.71825 (* 1 = 1.71825 loss)
I1027 03:30:40.763743 37958 sgd_solver.cpp:105] Iteration 50280, lr = 0.00704235
I1027 03:31:11.202790 37958 solver.cpp:221] Iteration 50320 (1.31415 iter/s, 30.4379s/40 iters), loss = 1.55263
I1027 03:31:11.202965 37958 solver.cpp:240]     Train net output #0: loss = 1.55263 (* 1 = 1.55263 loss)
I1027 03:31:11.202986 37958 sgd_solver.cpp:105] Iteration 50320, lr = 0.00704
I1027 03:31:41.638244 37958 solver.cpp:221] Iteration 50360 (1.31431 iter/s, 30.4341s/40 iters), loss = 1.78457
I1027 03:31:41.638428 37958 solver.cpp:240]     Train net output #0: loss = 1.78457 (* 1 = 1.78457 loss)
I1027 03:31:41.638443 37958 sgd_solver.cpp:105] Iteration 50360, lr = 0.00703765
I1027 03:32:12.066799 37958 solver.cpp:221] Iteration 50400 (1.31461 iter/s, 30.4272s/40 iters), loss = 1.64142
I1027 03:32:12.067021 37958 solver.cpp:240]     Train net output #0: loss = 1.64142 (* 1 = 1.64142 loss)
I1027 03:32:12.067061 37958 sgd_solver.cpp:105] Iteration 50400, lr = 0.00703529
I1027 03:32:42.522228 37958 solver.cpp:221] Iteration 50440 (1.31345 iter/s, 30.4541s/40 iters), loss = 1.74731
I1027 03:32:42.522373 37958 solver.cpp:240]     Train net output #0: loss = 1.74731 (* 1 = 1.74731 loss)
I1027 03:32:42.522387 37958 sgd_solver.cpp:105] Iteration 50440, lr = 0.00703294
I1027 03:33:13.150269 37958 solver.cpp:221] Iteration 50480 (1.30605 iter/s, 30.6267s/40 iters), loss = 1.80851
I1027 03:33:13.150470 37958 solver.cpp:240]     Train net output #0: loss = 1.80851 (* 1 = 1.80851 loss)
I1027 03:33:13.150485 37958 sgd_solver.cpp:105] Iteration 50480, lr = 0.00703059
I1027 03:33:27.602780 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_50500.caffemodel
I1027 03:33:27.635756 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_50500.solverstate
I1027 03:33:27.653750 37958 solver.cpp:333] Iteration 50500, Testing net (#0)
I1027 03:33:58.290745 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 03:33:58.496229 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.5328
I1027 03:33:58.496282 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77548
I1027 03:33:58.496294 37958 solver.cpp:400]     Test net output #2: loss = 2.05902 (* 1 = 2.05902 loss)
I1027 03:34:14.502099 37958 solver.cpp:221] Iteration 50520 (0.652004 iter/s, 61.3493s/40 iters), loss = 1.90605
I1027 03:34:14.502164 37958 solver.cpp:240]     Train net output #0: loss = 1.90605 (* 1 = 1.90605 loss)
I1027 03:34:14.502178 37958 sgd_solver.cpp:105] Iteration 50520, lr = 0.00702824
I1027 03:34:45.044826 37958 solver.cpp:221] Iteration 50560 (1.30969 iter/s, 30.5415s/40 iters), loss = 1.5385
I1027 03:34:45.045013 37958 solver.cpp:240]     Train net output #0: loss = 1.5385 (* 1 = 1.5385 loss)
I1027 03:34:45.045028 37958 sgd_solver.cpp:105] Iteration 50560, lr = 0.00702588
I1027 03:35:15.616286 37958 solver.cpp:221] Iteration 50600 (1.30847 iter/s, 30.5701s/40 iters), loss = 2.11406
I1027 03:35:15.616446 37958 solver.cpp:240]     Train net output #0: loss = 2.11406 (* 1 = 2.11406 loss)
I1027 03:35:15.616461 37958 sgd_solver.cpp:105] Iteration 50600, lr = 0.00702353
I1027 03:35:46.075215 37958 solver.cpp:221] Iteration 50640 (1.3133 iter/s, 30.4576s/40 iters), loss = 2.20084
I1027 03:35:46.075374 37958 solver.cpp:240]     Train net output #0: loss = 2.20084 (* 1 = 2.20084 loss)
I1027 03:35:46.075389 37958 sgd_solver.cpp:105] Iteration 50640, lr = 0.00702118
I1027 03:36:16.375373 37958 solver.cpp:221] Iteration 50680 (1.32018 iter/s, 30.2989s/40 iters), loss = 1.42369
I1027 03:36:16.375535 37958 solver.cpp:240]     Train net output #0: loss = 1.42369 (* 1 = 1.42369 loss)
I1027 03:36:16.375550 37958 sgd_solver.cpp:105] Iteration 50680, lr = 0.00701882
I1027 03:36:46.561481 37958 solver.cpp:221] Iteration 50720 (1.32517 iter/s, 30.1848s/40 iters), loss = 1.54114
I1027 03:36:46.561643 37958 solver.cpp:240]     Train net output #0: loss = 1.54114 (* 1 = 1.54114 loss)
I1027 03:36:46.561657 37958 sgd_solver.cpp:105] Iteration 50720, lr = 0.00701647
I1027 03:37:17.296586 37958 solver.cpp:221] Iteration 50760 (1.3015 iter/s, 30.7338s/40 iters), loss = 2.17379
I1027 03:37:17.296789 37958 solver.cpp:240]     Train net output #0: loss = 2.17379 (* 1 = 2.17379 loss)
I1027 03:37:17.296805 37958 sgd_solver.cpp:105] Iteration 50760, lr = 0.00701412
I1027 03:37:48.185259 37958 solver.cpp:221] Iteration 50800 (1.29503 iter/s, 30.8873s/40 iters), loss = 1.57958
I1027 03:37:48.185468 37958 solver.cpp:240]     Train net output #0: loss = 1.57958 (* 1 = 1.57958 loss)
I1027 03:37:48.185483 37958 sgd_solver.cpp:105] Iteration 50800, lr = 0.00701176
I1027 03:38:19.045682 37958 solver.cpp:221] Iteration 50840 (1.29622 iter/s, 30.859s/40 iters), loss = 1.83187
I1027 03:38:19.045895 37958 solver.cpp:240]     Train net output #0: loss = 1.83187 (* 1 = 1.83187 loss)
I1027 03:38:19.045909 37958 sgd_solver.cpp:105] Iteration 50840, lr = 0.00700941
I1027 03:39:33.234730 37958 solver.cpp:221] Iteration 50880 (0.539185 iter/s, 74.1861s/40 iters), loss = 1.73536
I1027 03:39:33.235010 37958 solver.cpp:240]     Train net output #0: loss = 1.73536 (* 1 = 1.73536 loss)
I1027 03:39:33.235034 37958 sgd_solver.cpp:105] Iteration 50880, lr = 0.00700706
I1027 03:40:04.869869 37958 solver.cpp:221] Iteration 50920 (1.26448 iter/s, 31.6337s/40 iters), loss = 1.70212
I1027 03:40:04.870093 37958 solver.cpp:240]     Train net output #0: loss = 1.70212 (* 1 = 1.70212 loss)
I1027 03:40:04.870108 37958 sgd_solver.cpp:105] Iteration 50920, lr = 0.00700471
I1027 03:40:35.908553 37958 solver.cpp:221] Iteration 50960 (1.28877 iter/s, 31.0373s/40 iters), loss = 1.71509
I1027 03:40:35.908766 37958 solver.cpp:240]     Train net output #0: loss = 1.71509 (* 1 = 1.71509 loss)
I1027 03:40:35.908779 37958 sgd_solver.cpp:105] Iteration 50960, lr = 0.00700235
I1027 03:41:06.127310 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_51000.caffemodel
I1027 03:41:06.160044 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_51000.solverstate
I1027 03:41:06.177857 37958 solver.cpp:333] Iteration 51000, Testing net (#0)
I1027 03:41:36.987085 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.5396
I1027 03:41:36.987246 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.7764
I1027 03:41:36.987259 37958 solver.cpp:400]     Test net output #2: loss = 2.03832 (* 1 = 2.03832 loss)
I1027 03:41:37.757467 37958 solver.cpp:221] Iteration 51000 (0.646764 iter/s, 61.8464s/40 iters), loss = 1.6418
I1027 03:41:37.757524 37958 solver.cpp:240]     Train net output #0: loss = 1.6418 (* 1 = 1.6418 loss)
I1027 03:41:37.757539 37958 sgd_solver.cpp:105] Iteration 51000, lr = 0.007
I1027 03:42:09.341979 37958 solver.cpp:221] Iteration 51040 (1.26649 iter/s, 31.5833s/40 iters), loss = 1.80815
I1027 03:42:09.342203 37958 solver.cpp:240]     Train net output #0: loss = 1.80815 (* 1 = 1.80815 loss)
I1027 03:42:09.342218 37958 sgd_solver.cpp:105] Iteration 51040, lr = 0.00699765
I1027 03:42:46.297595 37958 solver.cpp:221] Iteration 51080 (1.08243 iter/s, 36.954s/40 iters), loss = 2.02422
I1027 03:42:46.297823 37958 solver.cpp:240]     Train net output #0: loss = 2.02422 (* 1 = 2.02422 loss)
I1027 03:42:46.297838 37958 sgd_solver.cpp:105] Iteration 51080, lr = 0.00699529
I1027 03:43:19.042901 37958 solver.cpp:221] Iteration 51120 (1.2216 iter/s, 32.7438s/40 iters), loss = 2.00908
I1027 03:43:19.043130 37958 solver.cpp:240]     Train net output #0: loss = 2.00908 (* 1 = 2.00908 loss)
I1027 03:43:19.043145 37958 sgd_solver.cpp:105] Iteration 51120, lr = 0.00699294
I1027 03:43:49.574760 37958 solver.cpp:221] Iteration 51160 (1.31017 iter/s, 30.5305s/40 iters), loss = 1.45304
I1027 03:43:49.574908 37958 solver.cpp:240]     Train net output #0: loss = 1.45304 (* 1 = 1.45304 loss)
I1027 03:43:49.574921 37958 sgd_solver.cpp:105] Iteration 51160, lr = 0.00699059
I1027 03:44:20.117499 37958 solver.cpp:221] Iteration 51200 (1.3097 iter/s, 30.5414s/40 iters), loss = 1.9698
I1027 03:44:20.117674 37958 solver.cpp:240]     Train net output #0: loss = 1.9698 (* 1 = 1.9698 loss)
I1027 03:44:20.117689 37958 sgd_solver.cpp:105] Iteration 51200, lr = 0.00698824
I1027 03:44:51.108338 37958 solver.cpp:221] Iteration 51240 (1.29076 iter/s, 30.9895s/40 iters), loss = 1.73101
I1027 03:44:51.108556 37958 solver.cpp:240]     Train net output #0: loss = 1.73101 (* 1 = 1.73101 loss)
I1027 03:44:51.108570 37958 sgd_solver.cpp:105] Iteration 51240, lr = 0.00698588
I1027 03:45:21.843333 37958 solver.cpp:221] Iteration 51280 (1.30151 iter/s, 30.7336s/40 iters), loss = 1.56974
I1027 03:45:21.843519 37958 solver.cpp:240]     Train net output #0: loss = 1.56974 (* 1 = 1.56974 loss)
I1027 03:45:21.843534 37958 sgd_solver.cpp:105] Iteration 51280, lr = 0.00698353
I1027 03:45:52.537994 37958 solver.cpp:221] Iteration 51320 (1.30322 iter/s, 30.6933s/40 iters), loss = 1.64542
I1027 03:45:52.538210 37958 solver.cpp:240]     Train net output #0: loss = 1.64542 (* 1 = 1.64542 loss)
I1027 03:45:52.538238 37958 sgd_solver.cpp:105] Iteration 51320, lr = 0.00698118
I1027 03:46:23.479799 37958 solver.cpp:221] Iteration 51360 (1.29281 iter/s, 30.9404s/40 iters), loss = 1.61964
I1027 03:46:23.479974 37958 solver.cpp:240]     Train net output #0: loss = 1.61964 (* 1 = 1.61964 loss)
I1027 03:46:23.479990 37958 sgd_solver.cpp:105] Iteration 51360, lr = 0.00697882
I1027 03:46:54.264706 37958 solver.cpp:221] Iteration 51400 (1.29939 iter/s, 30.7836s/40 iters), loss = 1.87436
I1027 03:46:54.264869 37958 solver.cpp:240]     Train net output #0: loss = 1.87436 (* 1 = 1.87436 loss)
I1027 03:46:54.264884 37958 sgd_solver.cpp:105] Iteration 51400, lr = 0.00697647
I1027 03:47:25.126410 37958 solver.cpp:221] Iteration 51440 (1.29616 iter/s, 30.8604s/40 iters), loss = 1.91642
I1027 03:47:25.126600 37958 solver.cpp:240]     Train net output #0: loss = 1.91642 (* 1 = 1.91642 loss)
I1027 03:47:25.126616 37958 sgd_solver.cpp:105] Iteration 51440, lr = 0.00697412
I1027 03:47:57.712702 37958 solver.cpp:221] Iteration 51480 (1.22756 iter/s, 32.5849s/40 iters), loss = 1.73137
I1027 03:47:57.712990 37958 solver.cpp:240]     Train net output #0: loss = 1.73137 (* 1 = 1.73137 loss)
I1027 03:47:57.713009 37958 sgd_solver.cpp:105] Iteration 51480, lr = 0.00697176
I1027 03:48:12.749521 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_51500.caffemodel
I1027 03:48:12.783015 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_51500.solverstate
I1027 03:48:12.801071 37958 solver.cpp:333] Iteration 51500, Testing net (#0)
I1027 03:48:43.424687 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 03:48:43.630128 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53432
I1027 03:48:43.630182 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77624
I1027 03:48:43.630193 37958 solver.cpp:400]     Test net output #2: loss = 2.07502 (* 1 = 2.07502 loss)
I1027 03:48:59.570017 37958 solver.cpp:221] Iteration 51520 (0.646677 iter/s, 61.8547s/40 iters), loss = 1.75931
I1027 03:48:59.570082 37958 solver.cpp:240]     Train net output #0: loss = 1.75931 (* 1 = 1.75931 loss)
I1027 03:48:59.570096 37958 sgd_solver.cpp:105] Iteration 51520, lr = 0.00696941
I1027 03:49:30.071739 37958 solver.cpp:221] Iteration 51560 (1.31145 iter/s, 30.5005s/40 iters), loss = 1.82816
I1027 03:49:30.071899 37958 solver.cpp:240]     Train net output #0: loss = 1.82816 (* 1 = 1.82816 loss)
I1027 03:49:30.071914 37958 sgd_solver.cpp:105] Iteration 51560, lr = 0.00696706
I1027 03:50:00.725028 37958 solver.cpp:221] Iteration 51600 (1.30497 iter/s, 30.652s/40 iters), loss = 1.61736
I1027 03:50:00.725222 37958 solver.cpp:240]     Train net output #0: loss = 1.61736 (* 1 = 1.61736 loss)
I1027 03:50:00.725237 37958 sgd_solver.cpp:105] Iteration 51600, lr = 0.00696471
I1027 03:50:31.148743 37958 solver.cpp:221] Iteration 51640 (1.31482 iter/s, 30.4224s/40 iters), loss = 1.55577
I1027 03:50:31.148937 37958 solver.cpp:240]     Train net output #0: loss = 1.55577 (* 1 = 1.55577 loss)
I1027 03:50:31.148952 37958 sgd_solver.cpp:105] Iteration 51640, lr = 0.00696235
I1027 03:51:01.443953 37958 solver.cpp:221] Iteration 51680 (1.3204 iter/s, 30.2939s/40 iters), loss = 1.97926
I1027 03:51:01.444123 37958 solver.cpp:240]     Train net output #0: loss = 1.97926 (* 1 = 1.97926 loss)
I1027 03:51:01.444138 37958 sgd_solver.cpp:105] Iteration 51680, lr = 0.00696
I1027 03:51:31.652220 37958 solver.cpp:221] Iteration 51720 (1.3242 iter/s, 30.2069s/40 iters), loss = 1.92747
I1027 03:51:31.652386 37958 solver.cpp:240]     Train net output #0: loss = 1.92747 (* 1 = 1.92747 loss)
I1027 03:51:31.652401 37958 sgd_solver.cpp:105] Iteration 51720, lr = 0.00695765
I1027 03:52:02.377809 37958 solver.cpp:221] Iteration 51760 (1.3019 iter/s, 30.7243s/40 iters), loss = 1.84393
I1027 03:52:02.378070 37958 solver.cpp:240]     Train net output #0: loss = 1.84393 (* 1 = 1.84393 loss)
I1027 03:52:02.378096 37958 sgd_solver.cpp:105] Iteration 51760, lr = 0.00695529
I1027 03:52:33.095191 37958 solver.cpp:221] Iteration 51800 (1.30225 iter/s, 30.716s/40 iters), loss = 1.43306
I1027 03:52:33.095506 37958 solver.cpp:240]     Train net output #0: loss = 1.43306 (* 1 = 1.43306 loss)
I1027 03:52:33.095521 37958 sgd_solver.cpp:105] Iteration 51800, lr = 0.00695294
I1027 03:53:03.951375 37958 solver.cpp:221] Iteration 51840 (1.2964 iter/s, 30.8547s/40 iters), loss = 1.72655
I1027 03:53:03.951558 37958 solver.cpp:240]     Train net output #0: loss = 1.72655 (* 1 = 1.72655 loss)
I1027 03:53:03.951572 37958 sgd_solver.cpp:105] Iteration 51840, lr = 0.00695059
I1027 03:53:34.327121 37958 solver.cpp:221] Iteration 51880 (1.3169 iter/s, 30.3744s/40 iters), loss = 1.47221
I1027 03:53:34.327286 37958 solver.cpp:240]     Train net output #0: loss = 1.47221 (* 1 = 1.47221 loss)
I1027 03:53:34.327306 37958 sgd_solver.cpp:105] Iteration 51880, lr = 0.00694823
I1027 03:54:05.199390 37958 solver.cpp:221] Iteration 51920 (1.29572 iter/s, 30.8709s/40 iters), loss = 1.5302
I1027 03:54:05.199625 37958 solver.cpp:240]     Train net output #0: loss = 1.5302 (* 1 = 1.5302 loss)
I1027 03:54:05.199647 37958 sgd_solver.cpp:105] Iteration 51920, lr = 0.00694588
I1027 03:54:36.500151 37958 solver.cpp:221] Iteration 51960 (1.27798 iter/s, 31.2993s/40 iters), loss = 2.00297
I1027 03:54:36.500459 37958 solver.cpp:240]     Train net output #0: loss = 2.00297 (* 1 = 2.00297 loss)
I1027 03:54:36.500474 37958 sgd_solver.cpp:105] Iteration 51960, lr = 0.00694353
I1027 03:55:06.662184 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_52000.caffemodel
I1027 03:55:06.696288 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_52000.solverstate
I1027 03:55:06.718045 37958 solver.cpp:333] Iteration 52000, Testing net (#0)
I1027 03:55:37.580299 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.54016
I1027 03:55:37.580467 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77832
I1027 03:55:37.580482 37958 solver.cpp:400]     Test net output #2: loss = 2.03274 (* 1 = 2.03274 loss)
I1027 03:55:38.348139 37958 solver.cpp:221] Iteration 52000 (0.646775 iter/s, 61.8454s/40 iters), loss = 1.84809
I1027 03:55:38.348196 37958 solver.cpp:240]     Train net output #0: loss = 1.84809 (* 1 = 1.84809 loss)
I1027 03:55:38.348211 37958 sgd_solver.cpp:105] Iteration 52000, lr = 0.00694118
I1027 03:56:10.741384 37958 solver.cpp:221] Iteration 52040 (1.23487 iter/s, 32.392s/40 iters), loss = 1.96218
I1027 03:56:10.741598 37958 solver.cpp:240]     Train net output #0: loss = 1.96218 (* 1 = 1.96218 loss)
I1027 03:56:10.741621 37958 sgd_solver.cpp:105] Iteration 52040, lr = 0.00693882
I1027 03:56:43.797636 37958 solver.cpp:221] Iteration 52080 (1.21011 iter/s, 33.0548s/40 iters), loss = 1.38846
I1027 03:56:43.797837 37958 solver.cpp:240]     Train net output #0: loss = 1.38846 (* 1 = 1.38846 loss)
I1027 03:56:43.797852 37958 sgd_solver.cpp:105] Iteration 52080, lr = 0.00693647
I1027 03:57:14.672157 37958 solver.cpp:221] Iteration 52120 (1.29562 iter/s, 30.8731s/40 iters), loss = 1.6604
I1027 03:57:14.672309 37958 solver.cpp:240]     Train net output #0: loss = 1.6604 (* 1 = 1.6604 loss)
I1027 03:57:14.672324 37958 sgd_solver.cpp:105] Iteration 52120, lr = 0.00693412
I1027 03:57:45.227545 37958 solver.cpp:221] Iteration 52160 (1.30915 iter/s, 30.5541s/40 iters), loss = 1.56066
I1027 03:57:45.227735 37958 solver.cpp:240]     Train net output #0: loss = 1.56066 (* 1 = 1.56066 loss)
I1027 03:57:45.227748 37958 sgd_solver.cpp:105] Iteration 52160, lr = 0.00693177
I1027 03:58:16.104638 37958 solver.cpp:221] Iteration 52200 (1.29552 iter/s, 30.8757s/40 iters), loss = 1.95624
I1027 03:58:16.104810 37958 solver.cpp:240]     Train net output #0: loss = 1.95624 (* 1 = 1.95624 loss)
I1027 03:58:16.104825 37958 sgd_solver.cpp:105] Iteration 52200, lr = 0.00692941
I1027 03:58:46.740397 37958 solver.cpp:221] Iteration 52240 (1.30572 iter/s, 30.6344s/40 iters), loss = 2.08061
I1027 03:58:46.740641 37958 solver.cpp:240]     Train net output #0: loss = 2.08061 (* 1 = 2.08061 loss)
I1027 03:58:46.740666 37958 sgd_solver.cpp:105] Iteration 52240, lr = 0.00692706
I1027 03:59:17.473583 37958 solver.cpp:221] Iteration 52280 (1.30158 iter/s, 30.7318s/40 iters), loss = 1.75526
I1027 03:59:17.473772 37958 solver.cpp:240]     Train net output #0: loss = 1.75526 (* 1 = 1.75526 loss)
I1027 03:59:17.473786 37958 sgd_solver.cpp:105] Iteration 52280, lr = 0.00692471
I1027 03:59:47.954349 37958 solver.cpp:221] Iteration 52320 (1.31236 iter/s, 30.4794s/40 iters), loss = 1.90355
I1027 03:59:47.954571 37958 solver.cpp:240]     Train net output #0: loss = 1.90355 (* 1 = 1.90355 loss)
I1027 03:59:47.954586 37958 sgd_solver.cpp:105] Iteration 52320, lr = 0.00692235
I1027 04:00:18.862385 37958 solver.cpp:221] Iteration 52360 (1.29422 iter/s, 30.9066s/40 iters), loss = 1.66969
I1027 04:00:18.862592 37958 solver.cpp:240]     Train net output #0: loss = 1.66969 (* 1 = 1.66969 loss)
I1027 04:00:18.862607 37958 sgd_solver.cpp:105] Iteration 52360, lr = 0.00692
I1027 04:00:49.744856 37958 solver.cpp:221] Iteration 52400 (1.29529 iter/s, 30.8811s/40 iters), loss = 1.93646
I1027 04:00:49.745034 37958 solver.cpp:240]     Train net output #0: loss = 1.93646 (* 1 = 1.93646 loss)
I1027 04:00:49.745049 37958 sgd_solver.cpp:105] Iteration 52400, lr = 0.00691765
I1027 04:01:20.414994 37958 solver.cpp:221] Iteration 52440 (1.30426 iter/s, 30.6688s/40 iters), loss = 1.65985
I1027 04:01:20.415174 37958 solver.cpp:240]     Train net output #0: loss = 1.65985 (* 1 = 1.65985 loss)
I1027 04:01:20.415189 37958 sgd_solver.cpp:105] Iteration 52440, lr = 0.00691529
I1027 04:01:50.999148 37958 solver.cpp:221] Iteration 52480 (1.30792 iter/s, 30.5828s/40 iters), loss = 1.66131
I1027 04:01:50.999536 37958 solver.cpp:240]     Train net output #0: loss = 1.66131 (* 1 = 1.66131 loss)
I1027 04:01:50.999550 37958 sgd_solver.cpp:105] Iteration 52480, lr = 0.00691294
I1027 04:02:05.444226 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_52500.caffemodel
I1027 04:02:05.484338 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_52500.solverstate
I1027 04:02:05.510010 37958 solver.cpp:333] Iteration 52500, Testing net (#0)
I1027 04:02:36.183939 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 04:02:36.389919 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53352
I1027 04:02:36.389972 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77396
I1027 04:02:36.389986 37958 solver.cpp:400]     Test net output #2: loss = 2.08003 (* 1 = 2.08003 loss)
I1027 04:02:52.276038 37958 solver.cpp:221] Iteration 52520 (0.652803 iter/s, 61.2742s/40 iters), loss = 1.85816
I1027 04:02:52.276108 37958 solver.cpp:240]     Train net output #0: loss = 1.85816 (* 1 = 1.85816 loss)
I1027 04:02:52.276123 37958 sgd_solver.cpp:105] Iteration 52520, lr = 0.00691059
I1027 04:03:09.780390 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1027 04:03:22.627101 37958 solver.cpp:221] Iteration 52560 (1.31796 iter/s, 30.3498s/40 iters), loss = 1.45284
I1027 04:03:22.627169 37958 solver.cpp:240]     Train net output #0: loss = 1.45284 (* 1 = 1.45284 loss)
I1027 04:03:22.627183 37958 sgd_solver.cpp:105] Iteration 52560, lr = 0.00690824
I1027 04:03:53.217576 37958 solver.cpp:221] Iteration 52600 (1.30765 iter/s, 30.5892s/40 iters), loss = 1.61116
I1027 04:03:53.217764 37958 solver.cpp:240]     Train net output #0: loss = 1.61116 (* 1 = 1.61116 loss)
I1027 04:03:53.217779 37958 sgd_solver.cpp:105] Iteration 52600, lr = 0.00690588
I1027 04:04:23.890794 37958 solver.cpp:221] Iteration 52640 (1.30413 iter/s, 30.6719s/40 iters), loss = 1.75329
I1027 04:04:23.890930 37958 solver.cpp:240]     Train net output #0: loss = 1.75329 (* 1 = 1.75329 loss)
I1027 04:04:23.890944 37958 sgd_solver.cpp:105] Iteration 52640, lr = 0.00690353
I1027 04:04:54.486510 37958 solver.cpp:221] Iteration 52680 (1.30743 iter/s, 30.5944s/40 iters), loss = 1.98749
I1027 04:04:54.486727 37958 solver.cpp:240]     Train net output #0: loss = 1.98749 (* 1 = 1.98749 loss)
I1027 04:04:54.486747 37958 sgd_solver.cpp:105] Iteration 52680, lr = 0.00690118
I1027 04:05:25.153935 37958 solver.cpp:221] Iteration 52720 (1.30437 iter/s, 30.666s/40 iters), loss = 1.5444
I1027 04:05:25.154160 37958 solver.cpp:240]     Train net output #0: loss = 1.5444 (* 1 = 1.5444 loss)
I1027 04:05:25.154175 37958 sgd_solver.cpp:105] Iteration 52720, lr = 0.00689882
I1027 04:05:55.631290 37958 solver.cpp:221] Iteration 52760 (1.31251 iter/s, 30.476s/40 iters), loss = 1.99646
I1027 04:05:55.631444 37958 solver.cpp:240]     Train net output #0: loss = 1.99646 (* 1 = 1.99646 loss)
I1027 04:05:55.631459 37958 sgd_solver.cpp:105] Iteration 52760, lr = 0.00689647
I1027 04:06:37.463367 37958 solver.cpp:221] Iteration 52800 (0.956244 iter/s, 41.8303s/40 iters), loss = 1.73074
I1027 04:06:37.463558 37958 solver.cpp:240]     Train net output #0: loss = 1.73074 (* 1 = 1.73074 loss)
I1027 04:06:37.463578 37958 sgd_solver.cpp:105] Iteration 52800, lr = 0.00689412
I1027 04:07:10.543604 37958 solver.cpp:221] Iteration 52840 (1.20923 iter/s, 33.0788s/40 iters), loss = 1.82353
I1027 04:07:10.543876 37958 solver.cpp:240]     Train net output #0: loss = 1.82353 (* 1 = 1.82353 loss)
I1027 04:07:10.543897 37958 sgd_solver.cpp:105] Iteration 52840, lr = 0.00689176
I1027 04:07:41.656967 37958 solver.cpp:221] Iteration 52880 (1.28568 iter/s, 31.1119s/40 iters), loss = 1.48137
I1027 04:07:41.657156 37958 solver.cpp:240]     Train net output #0: loss = 1.48137 (* 1 = 1.48137 loss)
I1027 04:07:41.657171 37958 sgd_solver.cpp:105] Iteration 52880, lr = 0.00688941
I1027 04:08:12.932325 37958 solver.cpp:221] Iteration 52920 (1.27902 iter/s, 31.274s/40 iters), loss = 1.61313
I1027 04:08:12.932533 37958 solver.cpp:240]     Train net output #0: loss = 1.61313 (* 1 = 1.61313 loss)
I1027 04:08:12.932548 37958 sgd_solver.cpp:105] Iteration 52920, lr = 0.00688706
I1027 04:08:44.126894 37958 solver.cpp:221] Iteration 52960 (1.28233 iter/s, 31.1932s/40 iters), loss = 1.5809
I1027 04:08:44.127127 37958 solver.cpp:240]     Train net output #0: loss = 1.5809 (* 1 = 1.5809 loss)
I1027 04:08:44.127148 37958 sgd_solver.cpp:105] Iteration 52960, lr = 0.00688471
I1027 04:09:14.413525 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_53000.caffemodel
I1027 04:09:14.447342 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_53000.solverstate
I1027 04:09:14.466809 37958 solver.cpp:333] Iteration 53000, Testing net (#0)
I1027 04:09:45.332079 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53168
I1027 04:09:45.332253 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77052
I1027 04:09:45.332268 37958 solver.cpp:400]     Test net output #2: loss = 2.09062 (* 1 = 2.09062 loss)
I1027 04:09:46.089079 37958 solver.cpp:221] Iteration 53000 (0.645582 iter/s, 61.9596s/40 iters), loss = 1.76149
I1027 04:09:46.089138 37958 solver.cpp:240]     Train net output #0: loss = 1.76149 (* 1 = 1.76149 loss)
I1027 04:09:46.089154 37958 sgd_solver.cpp:105] Iteration 53000, lr = 0.00688235
I1027 04:10:16.653102 37958 solver.cpp:221] Iteration 53040 (1.30878 iter/s, 30.5628s/40 iters), loss = 1.86166
I1027 04:10:16.653292 37958 solver.cpp:240]     Train net output #0: loss = 1.86166 (* 1 = 1.86166 loss)
I1027 04:10:16.653316 37958 sgd_solver.cpp:105] Iteration 53040, lr = 0.00688
I1027 04:10:47.127358 37958 solver.cpp:221] Iteration 53080 (1.31264 iter/s, 30.4729s/40 iters), loss = 1.47546
I1027 04:10:47.127517 37958 solver.cpp:240]     Train net output #0: loss = 1.47546 (* 1 = 1.47546 loss)
I1027 04:10:47.127540 37958 sgd_solver.cpp:105] Iteration 53080, lr = 0.00687765
I1027 04:11:17.680479 37958 solver.cpp:221] Iteration 53120 (1.30925 iter/s, 30.5518s/40 iters), loss = 2.30449
I1027 04:11:17.680721 37958 solver.cpp:240]     Train net output #0: loss = 2.30449 (* 1 = 2.30449 loss)
I1027 04:11:17.680744 37958 sgd_solver.cpp:105] Iteration 53120, lr = 0.00687529
I1027 04:11:48.153281 37958 solver.cpp:221] Iteration 53160 (1.31271 iter/s, 30.4714s/40 iters), loss = 1.76202
I1027 04:11:48.153496 37958 solver.cpp:240]     Train net output #0: loss = 1.76202 (* 1 = 1.76202 loss)
I1027 04:11:48.153515 37958 sgd_solver.cpp:105] Iteration 53160, lr = 0.00687294
I1027 04:12:19.146302 37958 solver.cpp:221] Iteration 53200 (1.29067 iter/s, 30.9916s/40 iters), loss = 1.61671
I1027 04:12:19.146471 37958 solver.cpp:240]     Train net output #0: loss = 1.61671 (* 1 = 1.61671 loss)
I1027 04:12:19.146486 37958 sgd_solver.cpp:105] Iteration 53200, lr = 0.00687059
I1027 04:12:49.978610 37958 solver.cpp:221] Iteration 53240 (1.2974 iter/s, 30.831s/40 iters), loss = 1.48464
I1027 04:12:49.978775 37958 solver.cpp:240]     Train net output #0: loss = 1.48464 (* 1 = 1.48464 loss)
I1027 04:12:49.978790 37958 sgd_solver.cpp:105] Iteration 53240, lr = 0.00686823
I1027 04:13:07.220211 37958 blocking_queue.cpp:49] Waiting for data
I1027 04:13:34.439535 37958 solver.cpp:221] Iteration 53280 (0.899704 iter/s, 44.4591s/40 iters), loss = 1.96863
I1027 04:13:34.439777 37958 solver.cpp:240]     Train net output #0: loss = 1.96863 (* 1 = 1.96863 loss)
I1027 04:13:34.439798 37958 sgd_solver.cpp:105] Iteration 53280, lr = 0.00686588
I1027 04:14:07.029461 37958 solver.cpp:221] Iteration 53320 (1.22743 iter/s, 32.5885s/40 iters), loss = 1.65603
I1027 04:14:07.029647 37958 solver.cpp:240]     Train net output #0: loss = 1.65603 (* 1 = 1.65603 loss)
I1027 04:14:07.029662 37958 sgd_solver.cpp:105] Iteration 53320, lr = 0.00686353
I1027 04:14:37.528208 37958 solver.cpp:221] Iteration 53360 (1.31159 iter/s, 30.4974s/40 iters), loss = 1.83174
I1027 04:14:37.528421 37958 solver.cpp:240]     Train net output #0: loss = 1.83174 (* 1 = 1.83174 loss)
I1027 04:14:37.528436 37958 sgd_solver.cpp:105] Iteration 53360, lr = 0.00686118
I1027 04:15:07.794571 37958 solver.cpp:221] Iteration 53400 (1.32166 iter/s, 30.265s/40 iters), loss = 1.65676
I1027 04:15:07.794733 37958 solver.cpp:240]     Train net output #0: loss = 1.65676 (* 1 = 1.65676 loss)
I1027 04:15:07.794746 37958 sgd_solver.cpp:105] Iteration 53400, lr = 0.00685882
I1027 04:15:38.621074 37958 solver.cpp:221] Iteration 53440 (1.29764 iter/s, 30.8252s/40 iters), loss = 1.97193
I1027 04:15:38.621269 37958 solver.cpp:240]     Train net output #0: loss = 1.97193 (* 1 = 1.97193 loss)
I1027 04:15:38.621284 37958 sgd_solver.cpp:105] Iteration 53440, lr = 0.00685647
I1027 04:16:09.227408 37958 solver.cpp:221] Iteration 53480 (1.30698 iter/s, 30.605s/40 iters), loss = 1.62872
I1027 04:16:09.227589 37958 solver.cpp:240]     Train net output #0: loss = 1.62872 (* 1 = 1.62872 loss)
I1027 04:16:09.227604 37958 sgd_solver.cpp:105] Iteration 53480, lr = 0.00685412
I1027 04:16:23.711729 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_53500.caffemodel
I1027 04:16:23.744628 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_53500.solverstate
I1027 04:16:23.764145 37958 solver.cpp:333] Iteration 53500, Testing net (#0)
I1027 04:16:54.406780 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 04:16:54.612104 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53248
I1027 04:16:54.612159 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77492
I1027 04:16:54.612169 37958 solver.cpp:400]     Test net output #2: loss = 2.0704 (* 1 = 2.0704 loss)
I1027 04:17:10.680089 37958 solver.cpp:221] Iteration 53520 (0.650934 iter/s, 61.4502s/40 iters), loss = 2.0927
I1027 04:17:10.680153 37958 solver.cpp:240]     Train net output #0: loss = 2.0927 (* 1 = 2.0927 loss)
I1027 04:17:10.680167 37958 sgd_solver.cpp:105] Iteration 53520, lr = 0.00685176
I1027 04:17:42.457147 37958 solver.cpp:221] Iteration 53560 (1.25882 iter/s, 31.7758s/40 iters), loss = 1.45498
I1027 04:17:42.457460 37958 solver.cpp:240]     Train net output #0: loss = 1.45498 (* 1 = 1.45498 loss)
I1027 04:17:42.457484 37958 sgd_solver.cpp:105] Iteration 53560, lr = 0.00684941
I1027 04:18:14.495978 37958 solver.cpp:221] Iteration 53600 (1.24854 iter/s, 32.0373s/40 iters), loss = 2.2681
I1027 04:18:14.496145 37958 solver.cpp:240]     Train net output #0: loss = 2.2681 (* 1 = 2.2681 loss)
I1027 04:18:14.496160 37958 sgd_solver.cpp:105] Iteration 53600, lr = 0.00684706
I1027 04:18:44.999269 37958 solver.cpp:221] Iteration 53640 (1.31139 iter/s, 30.502s/40 iters), loss = 1.50382
I1027 04:18:44.999414 37958 solver.cpp:240]     Train net output #0: loss = 1.50382 (* 1 = 1.50382 loss)
I1027 04:18:44.999429 37958 sgd_solver.cpp:105] Iteration 53640, lr = 0.00684471
I1027 04:19:15.541692 37958 solver.cpp:221] Iteration 53680 (1.30971 iter/s, 30.5411s/40 iters), loss = 1.84795
I1027 04:19:15.541860 37958 solver.cpp:240]     Train net output #0: loss = 1.84795 (* 1 = 1.84795 loss)
I1027 04:19:15.541874 37958 sgd_solver.cpp:105] Iteration 53680, lr = 0.00684235
I1027 04:19:45.969729 37958 solver.cpp:221] Iteration 53720 (1.31463 iter/s, 30.4267s/40 iters), loss = 1.85658
I1027 04:19:45.969880 37958 solver.cpp:240]     Train net output #0: loss = 1.85658 (* 1 = 1.85658 loss)
I1027 04:19:45.969895 37958 sgd_solver.cpp:105] Iteration 53720, lr = 0.00684
I1027 04:20:16.620918 37958 solver.cpp:221] Iteration 53760 (1.30506 iter/s, 30.6499s/40 iters), loss = 1.65267
I1027 04:20:16.621088 37958 solver.cpp:240]     Train net output #0: loss = 1.65267 (* 1 = 1.65267 loss)
I1027 04:20:16.621103 37958 sgd_solver.cpp:105] Iteration 53760, lr = 0.00683765
I1027 04:20:47.949728 37958 solver.cpp:221] Iteration 53800 (1.27684 iter/s, 31.3275s/40 iters), loss = 1.71632
I1027 04:20:47.949894 37958 solver.cpp:240]     Train net output #0: loss = 1.71632 (* 1 = 1.71632 loss)
I1027 04:20:47.949908 37958 sgd_solver.cpp:105] Iteration 53800, lr = 0.00683529
I1027 04:21:18.541132 37958 solver.cpp:221] Iteration 53840 (1.30761 iter/s, 30.5901s/40 iters), loss = 2.14764
I1027 04:21:18.541323 37958 solver.cpp:240]     Train net output #0: loss = 2.14764 (* 1 = 2.14764 loss)
I1027 04:21:18.541339 37958 sgd_solver.cpp:105] Iteration 53840, lr = 0.00683294
I1027 04:21:48.927793 37958 solver.cpp:221] Iteration 53880 (1.31643 iter/s, 30.3853s/40 iters), loss = 1.65641
I1027 04:21:48.927963 37958 solver.cpp:240]     Train net output #0: loss = 1.65641 (* 1 = 1.65641 loss)
I1027 04:21:48.927978 37958 sgd_solver.cpp:105] Iteration 53880, lr = 0.00683059
I1027 04:22:19.558529 37958 solver.cpp:221] Iteration 53920 (1.30593 iter/s, 30.6294s/40 iters), loss = 1.62653
I1027 04:22:19.558714 37958 solver.cpp:240]     Train net output #0: loss = 1.62653 (* 1 = 1.62653 loss)
I1027 04:22:19.558729 37958 sgd_solver.cpp:105] Iteration 53920, lr = 0.00682824
I1027 04:22:50.172003 37958 solver.cpp:221] Iteration 53960 (1.30667 iter/s, 30.6121s/40 iters), loss = 1.81504
I1027 04:22:50.172190 37958 solver.cpp:240]     Train net output #0: loss = 1.81504 (* 1 = 1.81504 loss)
I1027 04:22:50.172205 37958 sgd_solver.cpp:105] Iteration 53960, lr = 0.00682588
I1027 04:23:20.171782 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_54000.caffemodel
I1027 04:23:20.207990 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_54000.solverstate
I1027 04:23:20.231760 37958 solver.cpp:333] Iteration 54000, Testing net (#0)
I1027 04:23:51.162642 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.5412
I1027 04:23:51.162791 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77912
I1027 04:23:51.162804 37958 solver.cpp:400]     Test net output #2: loss = 2.07872 (* 1 = 2.07872 loss)
I1027 04:23:51.933176 37958 solver.cpp:221] Iteration 54000 (0.647682 iter/s, 61.7587s/40 iters), loss = 1.80033
I1027 04:23:51.933235 37958 solver.cpp:240]     Train net output #0: loss = 1.80033 (* 1 = 1.80033 loss)
I1027 04:23:51.933249 37958 sgd_solver.cpp:105] Iteration 54000, lr = 0.00682353
I1027 04:24:22.757344 37958 solver.cpp:221] Iteration 54040 (1.29773 iter/s, 30.823s/40 iters), loss = 2.09422
I1027 04:24:22.757593 37958 solver.cpp:240]     Train net output #0: loss = 2.09422 (* 1 = 2.09422 loss)
I1027 04:24:22.757608 37958 sgd_solver.cpp:105] Iteration 54040, lr = 0.00682118
I1027 04:24:53.151542 37958 solver.cpp:221] Iteration 54080 (1.3161 iter/s, 30.3928s/40 iters), loss = 1.75659
I1027 04:24:53.151696 37958 solver.cpp:240]     Train net output #0: loss = 1.75659 (* 1 = 1.75659 loss)
I1027 04:24:53.151710 37958 sgd_solver.cpp:105] Iteration 54080, lr = 0.00681882
I1027 04:25:23.525951 37958 solver.cpp:221] Iteration 54120 (1.31695 iter/s, 30.3731s/40 iters), loss = 1.65808
I1027 04:25:23.526099 37958 solver.cpp:240]     Train net output #0: loss = 1.65808 (* 1 = 1.65808 loss)
I1027 04:25:23.526114 37958 sgd_solver.cpp:105] Iteration 54120, lr = 0.00681647
I1027 04:25:53.865480 37958 solver.cpp:221] Iteration 54160 (1.31847 iter/s, 30.3382s/40 iters), loss = 2.21472
I1027 04:25:53.865630 37958 solver.cpp:240]     Train net output #0: loss = 2.21472 (* 1 = 2.21472 loss)
I1027 04:25:53.865645 37958 sgd_solver.cpp:105] Iteration 54160, lr = 0.00681412
I1027 04:26:24.286204 37958 solver.cpp:221] Iteration 54200 (1.31495 iter/s, 30.4194s/40 iters), loss = 1.48461
I1027 04:26:24.286396 37958 solver.cpp:240]     Train net output #0: loss = 1.48461 (* 1 = 1.48461 loss)
I1027 04:26:24.286411 37958 sgd_solver.cpp:105] Iteration 54200, lr = 0.00681176
I1027 04:26:55.155753 37958 solver.cpp:221] Iteration 54240 (1.29583 iter/s, 30.8682s/40 iters), loss = 2.07962
I1027 04:26:55.155959 37958 solver.cpp:240]     Train net output #0: loss = 2.07962 (* 1 = 2.07962 loss)
I1027 04:26:55.155974 37958 sgd_solver.cpp:105] Iteration 54240, lr = 0.00680941
I1027 04:27:25.617133 37958 solver.cpp:221] Iteration 54280 (1.3132 iter/s, 30.46s/40 iters), loss = 1.71786
I1027 04:27:25.617312 37958 solver.cpp:240]     Train net output #0: loss = 1.71786 (* 1 = 1.71786 loss)
I1027 04:27:25.617328 37958 sgd_solver.cpp:105] Iteration 54280, lr = 0.00680706
I1027 04:27:56.175755 37958 solver.cpp:221] Iteration 54320 (1.30902 iter/s, 30.5573s/40 iters), loss = 1.46567
I1027 04:27:56.175958 37958 solver.cpp:240]     Train net output #0: loss = 1.46567 (* 1 = 1.46567 loss)
I1027 04:27:56.175976 37958 sgd_solver.cpp:105] Iteration 54320, lr = 0.00680471
I1027 04:28:55.560624 37958 solver.cpp:221] Iteration 54360 (0.6736 iter/s, 59.3824s/40 iters), loss = 1.71128
I1027 04:28:55.560837 37958 solver.cpp:240]     Train net output #0: loss = 1.71128 (* 1 = 1.71128 loss)
I1027 04:28:55.560853 37958 sgd_solver.cpp:105] Iteration 54360, lr = 0.00680235
I1027 04:29:26.003842 37958 solver.cpp:221] Iteration 54400 (1.31398 iter/s, 30.4419s/40 iters), loss = 1.76096
I1027 04:29:26.004017 37958 solver.cpp:240]     Train net output #0: loss = 1.76096 (* 1 = 1.76096 loss)
I1027 04:29:26.004032 37958 sgd_solver.cpp:105] Iteration 54400, lr = 0.0068
I1027 04:29:56.994590 37958 solver.cpp:221] Iteration 54440 (1.29076 iter/s, 30.9894s/40 iters), loss = 1.87383
I1027 04:29:56.994778 37958 solver.cpp:240]     Train net output #0: loss = 1.87383 (* 1 = 1.87383 loss)
I1027 04:29:56.994792 37958 sgd_solver.cpp:105] Iteration 54440, lr = 0.00679765
I1027 04:30:27.752636 37958 solver.cpp:221] Iteration 54480 (1.30053 iter/s, 30.7567s/40 iters), loss = 1.78313
I1027 04:30:27.752826 37958 solver.cpp:240]     Train net output #0: loss = 1.78313 (* 1 = 1.78313 loss)
I1027 04:30:27.752840 37958 sgd_solver.cpp:105] Iteration 54480, lr = 0.00679529
I1027 04:30:42.295583 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_54500.caffemodel
I1027 04:30:42.329447 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_54500.solverstate
I1027 04:30:42.347524 37958 solver.cpp:333] Iteration 54500, Testing net (#0)
I1027 04:31:13.025177 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 04:31:13.229997 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53892
I1027 04:31:13.230051 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.7782
I1027 04:31:13.230077 37958 solver.cpp:400]     Test net output #2: loss = 2.0629 (* 1 = 2.0629 loss)
I1027 04:31:29.478021 37958 solver.cpp:221] Iteration 54520 (0.648058 iter/s, 61.7229s/40 iters), loss = 1.34998
I1027 04:31:29.478081 37958 solver.cpp:240]     Train net output #0: loss = 1.34998 (* 1 = 1.34998 loss)
I1027 04:31:29.478096 37958 sgd_solver.cpp:105] Iteration 54520, lr = 0.00679294
I1027 04:32:00.112831 37958 solver.cpp:221] Iteration 54560 (1.30576 iter/s, 30.6336s/40 iters), loss = 1.45374
I1027 04:32:00.113073 37958 solver.cpp:240]     Train net output #0: loss = 1.45374 (* 1 = 1.45374 loss)
I1027 04:32:00.113090 37958 sgd_solver.cpp:105] Iteration 54560, lr = 0.00679059
I1027 04:32:30.529273 37958 solver.cpp:221] Iteration 54600 (1.31514 iter/s, 30.415s/40 iters), loss = 1.55319
I1027 04:32:30.529474 37958 solver.cpp:240]     Train net output #0: loss = 1.55319 (* 1 = 1.55319 loss)
I1027 04:32:30.529489 37958 sgd_solver.cpp:105] Iteration 54600, lr = 0.00678824
I1027 04:33:01.240520 37958 solver.cpp:221] Iteration 54640 (1.30251 iter/s, 30.7099s/40 iters), loss = 1.6168
I1027 04:33:01.240702 37958 solver.cpp:240]     Train net output #0: loss = 1.6168 (* 1 = 1.6168 loss)
I1027 04:33:01.240716 37958 sgd_solver.cpp:105] Iteration 54640, lr = 0.00678588
I1027 04:33:32.248566 37958 solver.cpp:221] Iteration 54680 (1.29004 iter/s, 31.0067s/40 iters), loss = 2.0543
I1027 04:33:32.248740 37958 solver.cpp:240]     Train net output #0: loss = 2.0543 (* 1 = 2.0543 loss)
I1027 04:33:32.248755 37958 sgd_solver.cpp:105] Iteration 54680, lr = 0.00678353
I1027 04:34:03.033984 37958 solver.cpp:221] Iteration 54720 (1.29937 iter/s, 30.7841s/40 iters), loss = 1.71273
I1027 04:34:03.034131 37958 solver.cpp:240]     Train net output #0: loss = 1.71273 (* 1 = 1.71273 loss)
I1027 04:34:03.034144 37958 sgd_solver.cpp:105] Iteration 54720, lr = 0.00678118
I1027 04:34:33.499254 37958 solver.cpp:221] Iteration 54760 (1.31303 iter/s, 30.464s/40 iters), loss = 1.65755
I1027 04:34:33.499433 37958 solver.cpp:240]     Train net output #0: loss = 1.65755 (* 1 = 1.65755 loss)
I1027 04:34:33.499447 37958 sgd_solver.cpp:105] Iteration 54760, lr = 0.00677882
I1027 04:35:04.061337 37958 solver.cpp:221] Iteration 54800 (1.30887 iter/s, 30.5607s/40 iters), loss = 1.97202
I1027 04:35:04.061473 37958 solver.cpp:240]     Train net output #0: loss = 1.97202 (* 1 = 1.97202 loss)
I1027 04:35:04.061488 37958 sgd_solver.cpp:105] Iteration 54800, lr = 0.00677647
I1027 04:35:34.517613 37958 solver.cpp:221] Iteration 54840 (1.31341 iter/s, 30.455s/40 iters), loss = 1.7315
I1027 04:35:34.517772 37958 solver.cpp:240]     Train net output #0: loss = 1.7315 (* 1 = 1.7315 loss)
I1027 04:35:34.517786 37958 sgd_solver.cpp:105] Iteration 54840, lr = 0.00677412
I1027 04:36:05.197322 37958 solver.cpp:221] Iteration 54880 (1.30385 iter/s, 30.6784s/40 iters), loss = 1.69609
I1027 04:36:05.197507 37958 solver.cpp:240]     Train net output #0: loss = 1.69609 (* 1 = 1.69609 loss)
I1027 04:36:05.197522 37958 sgd_solver.cpp:105] Iteration 54880, lr = 0.00677176
I1027 04:36:36.048087 37958 solver.cpp:221] Iteration 54920 (1.29662 iter/s, 30.8494s/40 iters), loss = 1.69037
I1027 04:36:36.048266 37958 solver.cpp:240]     Train net output #0: loss = 1.69037 (* 1 = 1.69037 loss)
I1027 04:36:36.048281 37958 sgd_solver.cpp:105] Iteration 54920, lr = 0.00676941
I1027 04:37:06.776455 37958 solver.cpp:221] Iteration 54960 (1.30179 iter/s, 30.727s/40 iters), loss = 1.66834
I1027 04:37:06.776703 37958 solver.cpp:240]     Train net output #0: loss = 1.66834 (* 1 = 1.66834 loss)
I1027 04:37:06.776727 37958 sgd_solver.cpp:105] Iteration 54960, lr = 0.00676706
I1027 04:37:37.055200 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_55000.caffemodel
I1027 04:37:37.097493 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_55000.solverstate
I1027 04:37:37.121866 37958 solver.cpp:333] Iteration 55000, Testing net (#0)
I1027 04:38:08.120478 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53492
I1027 04:38:08.120707 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77736
I1027 04:38:08.120721 37958 solver.cpp:400]     Test net output #2: loss = 2.11117 (* 1 = 2.11117 loss)
I1027 04:38:08.883222 37958 solver.cpp:221] Iteration 55000 (0.644079 iter/s, 62.1042s/40 iters), loss = 1.89053
I1027 04:38:08.883285 37958 solver.cpp:240]     Train net output #0: loss = 1.89053 (* 1 = 1.89053 loss)
I1027 04:38:08.883302 37958 sgd_solver.cpp:105] Iteration 55000, lr = 0.00676471
I1027 04:38:40.419396 37958 solver.cpp:221] Iteration 55040 (1.26844 iter/s, 31.5349s/40 iters), loss = 2.06233
I1027 04:38:40.419602 37958 solver.cpp:240]     Train net output #0: loss = 2.06233 (* 1 = 2.06233 loss)
I1027 04:38:40.419617 37958 sgd_solver.cpp:105] Iteration 55040, lr = 0.00676235
I1027 04:38:45.074687 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1027 04:39:12.055868 37958 solver.cpp:221] Iteration 55080 (1.26442 iter/s, 31.635s/40 iters), loss = 1.67353
I1027 04:39:12.056135 37958 solver.cpp:240]     Train net output #0: loss = 1.67353 (* 1 = 1.67353 loss)
I1027 04:39:12.056161 37958 sgd_solver.cpp:105] Iteration 55080, lr = 0.00676
I1027 04:39:43.890167 37958 solver.cpp:221] Iteration 55120 (1.25656 iter/s, 31.8328s/40 iters), loss = 1.85914
I1027 04:39:43.890430 37958 solver.cpp:240]     Train net output #0: loss = 1.85914 (* 1 = 1.85914 loss)
I1027 04:39:43.890451 37958 sgd_solver.cpp:105] Iteration 55120, lr = 0.00675765
I1027 04:40:15.383153 37958 solver.cpp:221] Iteration 55160 (1.27018 iter/s, 31.4915s/40 iters), loss = 1.31617
I1027 04:40:15.383474 37958 solver.cpp:240]     Train net output #0: loss = 1.31617 (* 1 = 1.31617 loss)
I1027 04:40:15.383489 37958 sgd_solver.cpp:105] Iteration 55160, lr = 0.00675529
I1027 04:40:46.943573 37958 solver.cpp:221] Iteration 55200 (1.26747 iter/s, 31.5589s/40 iters), loss = 1.77472
I1027 04:40:46.943810 37958 solver.cpp:240]     Train net output #0: loss = 1.77472 (* 1 = 1.77472 loss)
I1027 04:40:46.943831 37958 sgd_solver.cpp:105] Iteration 55200, lr = 0.00675294
I1027 04:41:18.085389 37958 solver.cpp:221] Iteration 55240 (1.2845 iter/s, 31.1404s/40 iters), loss = 1.18934
I1027 04:41:18.085585 37958 solver.cpp:240]     Train net output #0: loss = 1.18934 (* 1 = 1.18934 loss)
I1027 04:41:18.085599 37958 sgd_solver.cpp:105] Iteration 55240, lr = 0.00675059
I1027 04:41:48.984269 37958 solver.cpp:221] Iteration 55280 (1.2946 iter/s, 30.8975s/40 iters), loss = 1.74421
I1027 04:41:48.984457 37958 solver.cpp:240]     Train net output #0: loss = 1.74421 (* 1 = 1.74421 loss)
I1027 04:41:48.984472 37958 sgd_solver.cpp:105] Iteration 55280, lr = 0.00674823
I1027 04:42:19.713728 37958 solver.cpp:221] Iteration 55320 (1.30174 iter/s, 30.7281s/40 iters), loss = 1.93193
I1027 04:42:19.713920 37958 solver.cpp:240]     Train net output #0: loss = 1.93193 (* 1 = 1.93193 loss)
I1027 04:42:19.713934 37958 sgd_solver.cpp:105] Iteration 55320, lr = 0.00674588
I1027 04:42:50.232576 37958 solver.cpp:221] Iteration 55360 (1.31072 iter/s, 30.5175s/40 iters), loss = 1.85113
I1027 04:42:50.232743 37958 solver.cpp:240]     Train net output #0: loss = 1.85113 (* 1 = 1.85113 loss)
I1027 04:42:50.232756 37958 sgd_solver.cpp:105] Iteration 55360, lr = 0.00674353
I1027 04:43:20.904717 37958 solver.cpp:221] Iteration 55400 (1.30417 iter/s, 30.6708s/40 iters), loss = 1.82582
I1027 04:43:20.904899 37958 solver.cpp:240]     Train net output #0: loss = 1.82582 (* 1 = 1.82582 loss)
I1027 04:43:20.904914 37958 sgd_solver.cpp:105] Iteration 55400, lr = 0.00674118
I1027 04:43:52.387665 37958 solver.cpp:221] Iteration 55440 (1.27058 iter/s, 31.4816s/40 iters), loss = 1.87742
I1027 04:43:52.387856 37958 solver.cpp:240]     Train net output #0: loss = 1.87742 (* 1 = 1.87742 loss)
I1027 04:43:52.387871 37958 sgd_solver.cpp:105] Iteration 55440, lr = 0.00673882
I1027 04:44:23.214228 37958 solver.cpp:221] Iteration 55480 (1.29764 iter/s, 30.8252s/40 iters), loss = 1.59839
I1027 04:44:23.214531 37958 solver.cpp:240]     Train net output #0: loss = 1.59839 (* 1 = 1.59839 loss)
I1027 04:44:23.214570 37958 sgd_solver.cpp:105] Iteration 55480, lr = 0.00673647
I1027 04:44:38.075600 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_55500.caffemodel
I1027 04:44:38.107796 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_55500.solverstate
I1027 04:44:38.128703 37958 solver.cpp:333] Iteration 55500, Testing net (#0)
I1027 04:45:09.004508 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 04:45:09.212080 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.5322
I1027 04:45:09.212133 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77268
I1027 04:45:09.212146 37958 solver.cpp:400]     Test net output #2: loss = 2.09249 (* 1 = 2.09249 loss)
I1027 04:45:25.605847 37958 solver.cpp:221] Iteration 55520 (0.641139 iter/s, 62.389s/40 iters), loss = 1.85578
I1027 04:45:25.605918 37958 solver.cpp:240]     Train net output #0: loss = 1.85578 (* 1 = 1.85578 loss)
I1027 04:45:25.605932 37958 sgd_solver.cpp:105] Iteration 55520, lr = 0.00673412
I1027 04:46:07.627764 37958 solver.cpp:221] Iteration 55560 (0.951922 iter/s, 42.0203s/40 iters), loss = 1.76643
I1027 04:46:07.627998 37958 solver.cpp:240]     Train net output #0: loss = 1.76643 (* 1 = 1.76643 loss)
I1027 04:46:07.628018 37958 sgd_solver.cpp:105] Iteration 55560, lr = 0.00673176
I1027 04:46:44.506026 37958 solver.cpp:221] Iteration 55600 (1.0847 iter/s, 36.8766s/40 iters), loss = 2.24579
I1027 04:46:44.506256 37958 solver.cpp:240]     Train net output #0: loss = 2.24579 (* 1 = 2.24579 loss)
I1027 04:46:44.506278 37958 sgd_solver.cpp:105] Iteration 55600, lr = 0.00672941
I1027 04:47:16.089591 37958 solver.cpp:221] Iteration 55640 (1.26654 iter/s, 31.5821s/40 iters), loss = 1.70353
I1027 04:47:16.089771 37958 solver.cpp:240]     Train net output #0: loss = 1.70353 (* 1 = 1.70353 loss)
I1027 04:47:16.089787 37958 sgd_solver.cpp:105] Iteration 55640, lr = 0.00672706
I1027 04:47:46.986423 37958 solver.cpp:221] Iteration 55680 (1.29469 iter/s, 30.8955s/40 iters), loss = 1.54501
I1027 04:47:46.986629 37958 solver.cpp:240]     Train net output #0: loss = 1.54501 (* 1 = 1.54501 loss)
I1027 04:47:46.986644 37958 sgd_solver.cpp:105] Iteration 55680, lr = 0.00672471
I1027 04:48:17.795328 37958 solver.cpp:221] Iteration 55720 (1.29838 iter/s, 30.8075s/40 iters), loss = 1.78094
I1027 04:48:17.795516 37958 solver.cpp:240]     Train net output #0: loss = 1.78094 (* 1 = 1.78094 loss)
I1027 04:48:17.795531 37958 sgd_solver.cpp:105] Iteration 55720, lr = 0.00672235
I1027 04:48:49.125939 37958 solver.cpp:221] Iteration 55760 (1.27676 iter/s, 31.3292s/40 iters), loss = 1.95097
I1027 04:48:49.126147 37958 solver.cpp:240]     Train net output #0: loss = 1.95097 (* 1 = 1.95097 loss)
I1027 04:48:49.126164 37958 sgd_solver.cpp:105] Iteration 55760, lr = 0.00672
I1027 04:49:20.050849 37958 solver.cpp:221] Iteration 55800 (1.29351 iter/s, 30.9235s/40 iters), loss = 1.82787
I1027 04:49:20.051048 37958 solver.cpp:240]     Train net output #0: loss = 1.82787 (* 1 = 1.82787 loss)
I1027 04:49:20.051064 37958 sgd_solver.cpp:105] Iteration 55800, lr = 0.00671765
I1027 04:49:50.533239 37958 solver.cpp:221] Iteration 55840 (1.31229 iter/s, 30.481s/40 iters), loss = 1.89925
I1027 04:49:50.533448 37958 solver.cpp:240]     Train net output #0: loss = 1.89925 (* 1 = 1.89925 loss)
I1027 04:49:50.533464 37958 sgd_solver.cpp:105] Iteration 55840, lr = 0.00671529
I1027 04:50:20.847519 37958 solver.cpp:221] Iteration 55880 (1.31957 iter/s, 30.3129s/40 iters), loss = 1.69342
I1027 04:50:20.847703 37958 solver.cpp:240]     Train net output #0: loss = 1.69342 (* 1 = 1.69342 loss)
I1027 04:50:20.847718 37958 sgd_solver.cpp:105] Iteration 55880, lr = 0.00671294
I1027 04:50:51.341747 37958 solver.cpp:221] Iteration 55920 (1.31178 iter/s, 30.4929s/40 iters), loss = 1.78364
I1027 04:50:51.341924 37958 solver.cpp:240]     Train net output #0: loss = 1.78364 (* 1 = 1.78364 loss)
I1027 04:50:51.341939 37958 sgd_solver.cpp:105] Iteration 55920, lr = 0.00671059
I1027 04:51:21.976382 37958 solver.cpp:221] Iteration 55960 (1.30577 iter/s, 30.6333s/40 iters), loss = 1.34556
I1027 04:51:21.976647 37958 solver.cpp:240]     Train net output #0: loss = 1.34556 (* 1 = 1.34556 loss)
I1027 04:51:21.976680 37958 sgd_solver.cpp:105] Iteration 55960, lr = 0.00670824
I1027 04:51:51.718474 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_56000.caffemodel
I1027 04:51:51.751430 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_56000.solverstate
I1027 04:51:51.769552 37958 solver.cpp:333] Iteration 56000, Testing net (#0)
I1027 04:52:22.612704 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.54164
I1027 04:52:22.612896 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77704
I1027 04:52:22.612910 37958 solver.cpp:400]     Test net output #2: loss = 2.07606 (* 1 = 2.07606 loss)
I1027 04:52:23.382990 37958 solver.cpp:221] Iteration 56000 (0.651423 iter/s, 61.4041s/40 iters), loss = 2.29809
I1027 04:52:23.383044 37958 solver.cpp:240]     Train net output #0: loss = 2.29809 (* 1 = 2.29809 loss)
I1027 04:52:23.383057 37958 sgd_solver.cpp:105] Iteration 56000, lr = 0.00670588
I1027 04:52:54.041518 37958 solver.cpp:221] Iteration 56040 (1.30475 iter/s, 30.6573s/40 iters), loss = 1.85267
I1027 04:52:54.041685 37958 solver.cpp:240]     Train net output #0: loss = 1.85267 (* 1 = 1.85267 loss)
I1027 04:52:54.041702 37958 sgd_solver.cpp:105] Iteration 56040, lr = 0.00670353
I1027 04:53:24.453939 37958 solver.cpp:221] Iteration 56080 (1.31531 iter/s, 30.4111s/40 iters), loss = 1.68848
I1027 04:53:24.454107 37958 solver.cpp:240]     Train net output #0: loss = 1.68848 (* 1 = 1.68848 loss)
I1027 04:53:24.454121 37958 sgd_solver.cpp:105] Iteration 56080, lr = 0.00670118
I1027 04:53:55.321800 37958 solver.cpp:221] Iteration 56120 (1.2959 iter/s, 30.8665s/40 iters), loss = 1.71587
I1027 04:53:55.321996 37958 solver.cpp:240]     Train net output #0: loss = 1.71587 (* 1 = 1.71587 loss)
I1027 04:53:55.322011 37958 sgd_solver.cpp:105] Iteration 56120, lr = 0.00669882
I1027 04:54:25.841277 37958 solver.cpp:221] Iteration 56160 (1.3107 iter/s, 30.5181s/40 iters), loss = 1.75224
I1027 04:54:25.841447 37958 solver.cpp:240]     Train net output #0: loss = 1.75224 (* 1 = 1.75224 loss)
I1027 04:54:25.841462 37958 sgd_solver.cpp:105] Iteration 56160, lr = 0.00669647
I1027 04:54:56.635308 37958 solver.cpp:221] Iteration 56200 (1.29901 iter/s, 30.7927s/40 iters), loss = 1.94466
I1027 04:54:56.635498 37958 solver.cpp:240]     Train net output #0: loss = 1.94466 (* 1 = 1.94466 loss)
I1027 04:54:56.635519 37958 sgd_solver.cpp:105] Iteration 56200, lr = 0.00669412
I1027 04:55:27.504761 37958 solver.cpp:221] Iteration 56240 (1.29584 iter/s, 30.8681s/40 iters), loss = 1.65994
I1027 04:55:27.504928 37958 solver.cpp:240]     Train net output #0: loss = 1.65994 (* 1 = 1.65994 loss)
I1027 04:55:27.504942 37958 sgd_solver.cpp:105] Iteration 56240, lr = 0.00669176
I1027 04:55:58.374765 37958 solver.cpp:221] Iteration 56280 (1.29581 iter/s, 30.8687s/40 iters), loss = 1.96235
I1027 04:55:58.374961 37958 solver.cpp:240]     Train net output #0: loss = 1.96235 (* 1 = 1.96235 loss)
I1027 04:55:58.374975 37958 sgd_solver.cpp:105] Iteration 56280, lr = 0.00668941
I1027 04:56:29.003175 37958 solver.cpp:221] Iteration 56320 (1.30603 iter/s, 30.6271s/40 iters), loss = 1.83104
I1027 04:56:29.003360 37958 solver.cpp:240]     Train net output #0: loss = 1.83104 (* 1 = 1.83104 loss)
I1027 04:56:29.003374 37958 sgd_solver.cpp:105] Iteration 56320, lr = 0.00668706
I1027 04:56:59.582026 37958 solver.cpp:221] Iteration 56360 (1.30815 iter/s, 30.5775s/40 iters), loss = 1.88067
I1027 04:56:59.582208 37958 solver.cpp:240]     Train net output #0: loss = 1.88067 (* 1 = 1.88067 loss)
I1027 04:56:59.582223 37958 sgd_solver.cpp:105] Iteration 56360, lr = 0.00668471
I1027 04:57:30.393391 37958 solver.cpp:221] Iteration 56400 (1.29828 iter/s, 30.81s/40 iters), loss = 1.80434
I1027 04:57:30.393652 37958 solver.cpp:240]     Train net output #0: loss = 1.80434 (* 1 = 1.80434 loss)
I1027 04:57:30.393668 37958 sgd_solver.cpp:105] Iteration 56400, lr = 0.00668235
I1027 04:58:02.335785 37958 solver.cpp:221] Iteration 56440 (1.25231 iter/s, 31.9409s/40 iters), loss = 1.69905
I1027 04:58:02.335979 37958 solver.cpp:240]     Train net output #0: loss = 1.69905 (* 1 = 1.69905 loss)
I1027 04:58:02.335994 37958 sgd_solver.cpp:105] Iteration 56440, lr = 0.00668
I1027 04:58:33.751663 37958 solver.cpp:221] Iteration 56480 (1.2733 iter/s, 31.4145s/40 iters), loss = 1.73933
I1027 04:58:33.751915 37958 solver.cpp:240]     Train net output #0: loss = 1.73933 (* 1 = 1.73933 loss)
I1027 04:58:33.751937 37958 sgd_solver.cpp:105] Iteration 56480, lr = 0.00667765
I1027 04:58:48.616325 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_56500.caffemodel
I1027 04:58:48.656329 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_56500.solverstate
I1027 04:58:48.674307 37958 solver.cpp:333] Iteration 56500, Testing net (#0)
I1027 04:59:19.314570 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 04:59:19.520898 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.54056
I1027 04:59:19.520953 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.7786
I1027 04:59:19.520964 37958 solver.cpp:400]     Test net output #2: loss = 2.04311 (* 1 = 2.04311 loss)
I1027 04:59:35.930557 37958 solver.cpp:221] Iteration 56520 (0.643332 iter/s, 62.1763s/40 iters), loss = 1.83602
I1027 04:59:35.930621 37958 solver.cpp:240]     Train net output #0: loss = 1.83602 (* 1 = 1.83602 loss)
I1027 04:59:35.930634 37958 sgd_solver.cpp:105] Iteration 56520, lr = 0.00667529
I1027 05:00:06.645334 37958 solver.cpp:221] Iteration 56560 (1.30236 iter/s, 30.7136s/40 iters), loss = 1.64812
I1027 05:00:06.645529 37958 solver.cpp:240]     Train net output #0: loss = 1.64812 (* 1 = 1.64812 loss)
I1027 05:00:06.645543 37958 sgd_solver.cpp:105] Iteration 56560, lr = 0.00667294
I1027 05:00:37.722303 37958 solver.cpp:221] Iteration 56600 (1.28718 iter/s, 31.0756s/40 iters), loss = 1.65583
I1027 05:00:37.722503 37958 solver.cpp:240]     Train net output #0: loss = 1.65583 (* 1 = 1.65583 loss)
I1027 05:00:37.722519 37958 sgd_solver.cpp:105] Iteration 56600, lr = 0.00667059
I1027 05:01:08.682211 37958 solver.cpp:221] Iteration 56640 (1.29205 iter/s, 30.9585s/40 iters), loss = 1.8412
I1027 05:01:08.682409 37958 solver.cpp:240]     Train net output #0: loss = 1.8412 (* 1 = 1.8412 loss)
I1027 05:01:08.682423 37958 sgd_solver.cpp:105] Iteration 56640, lr = 0.00666823
I1027 05:01:39.099041 37958 solver.cpp:221] Iteration 56680 (1.31512 iter/s, 30.4155s/40 iters), loss = 1.76632
I1027 05:01:39.099237 37958 solver.cpp:240]     Train net output #0: loss = 1.76632 (* 1 = 1.76632 loss)
I1027 05:01:39.099252 37958 sgd_solver.cpp:105] Iteration 56680, lr = 0.00666588
I1027 05:02:09.584892 37958 solver.cpp:221] Iteration 56720 (1.31214 iter/s, 30.4845s/40 iters), loss = 1.97738
I1027 05:02:09.585084 37958 solver.cpp:240]     Train net output #0: loss = 1.97738 (* 1 = 1.97738 loss)
I1027 05:02:09.585099 37958 sgd_solver.cpp:105] Iteration 56720, lr = 0.00666353
I1027 05:02:39.823377 37958 solver.cpp:221] Iteration 56760 (1.32288 iter/s, 30.2371s/40 iters), loss = 1.81275
I1027 05:02:39.823578 37958 solver.cpp:240]     Train net output #0: loss = 1.81275 (* 1 = 1.81275 loss)
I1027 05:02:39.823593 37958 sgd_solver.cpp:105] Iteration 56760, lr = 0.00666118
I1027 05:03:10.218993 37958 solver.cpp:221] Iteration 56800 (1.31604 iter/s, 30.3943s/40 iters), loss = 1.75556
I1027 05:03:10.219202 37958 solver.cpp:240]     Train net output #0: loss = 1.75556 (* 1 = 1.75556 loss)
I1027 05:03:10.219218 37958 sgd_solver.cpp:105] Iteration 56800, lr = 0.00665882
I1027 05:03:41.055100 37958 solver.cpp:221] Iteration 56840 (1.29724 iter/s, 30.8347s/40 iters), loss = 1.50548
I1027 05:03:41.055338 37958 solver.cpp:240]     Train net output #0: loss = 1.50548 (* 1 = 1.50548 loss)
I1027 05:03:41.055374 37958 sgd_solver.cpp:105] Iteration 56840, lr = 0.00665647
I1027 05:04:11.570730 37958 solver.cpp:221] Iteration 56880 (1.31086 iter/s, 30.5142s/40 iters), loss = 1.61957
I1027 05:04:11.570917 37958 solver.cpp:240]     Train net output #0: loss = 1.61957 (* 1 = 1.61957 loss)
I1027 05:04:11.570935 37958 sgd_solver.cpp:105] Iteration 56880, lr = 0.00665412
I1027 05:04:42.094427 37958 solver.cpp:221] Iteration 56920 (1.31051 iter/s, 30.5224s/40 iters), loss = 1.69746
I1027 05:04:42.094641 37958 solver.cpp:240]     Train net output #0: loss = 1.69746 (* 1 = 1.69746 loss)
I1027 05:04:42.094660 37958 sgd_solver.cpp:105] Iteration 56920, lr = 0.00665176
I1027 05:05:12.597173 37958 solver.cpp:221] Iteration 56960 (1.31142 iter/s, 30.5014s/40 iters), loss = 2.02873
I1027 05:05:12.597517 37958 solver.cpp:240]     Train net output #0: loss = 2.02873 (* 1 = 2.02873 loss)
I1027 05:05:12.597533 37958 sgd_solver.cpp:105] Iteration 56960, lr = 0.00664941
I1027 05:05:42.260666 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_57000.caffemodel
I1027 05:05:42.300592 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_57000.solverstate
I1027 05:05:42.325189 37958 solver.cpp:333] Iteration 57000, Testing net (#0)
I1027 05:06:13.766983 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.54256
I1027 05:06:13.767148 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.78244
I1027 05:06:13.767164 37958 solver.cpp:400]     Test net output #2: loss = 2.01403 (* 1 = 2.01403 loss)
I1027 05:06:14.535074 37958 solver.cpp:221] Iteration 57000 (0.645836 iter/s, 61.9352s/40 iters), loss = 1.97842
I1027 05:06:14.535140 37958 solver.cpp:240]     Train net output #0: loss = 1.97842 (* 1 = 1.97842 loss)
I1027 05:06:14.535158 37958 sgd_solver.cpp:105] Iteration 57000, lr = 0.00664706
I1027 05:06:45.170012 37958 solver.cpp:221] Iteration 57040 (1.30575 iter/s, 30.6337s/40 iters), loss = 1.46189
I1027 05:06:45.170253 37958 solver.cpp:240]     Train net output #0: loss = 1.46189 (* 1 = 1.46189 loss)
I1027 05:06:45.170275 37958 sgd_solver.cpp:105] Iteration 57040, lr = 0.00664471
I1027 05:07:18.287966 37958 solver.cpp:221] Iteration 57080 (1.20786 iter/s, 33.1164s/40 iters), loss = 1.63675
I1027 05:07:18.288235 37958 solver.cpp:240]     Train net output #0: loss = 1.63675 (* 1 = 1.63675 loss)
I1027 05:07:18.288260 37958 sgd_solver.cpp:105] Iteration 57080, lr = 0.00664235
I1027 05:07:55.485887 37958 solver.cpp:221] Iteration 57120 (1.07538 iter/s, 37.1962s/40 iters), loss = 1.73316
I1027 05:07:55.486091 37958 solver.cpp:240]     Train net output #0: loss = 1.73316 (* 1 = 1.73316 loss)
I1027 05:07:55.486109 37958 sgd_solver.cpp:105] Iteration 57120, lr = 0.00664
I1027 05:08:26.720521 37958 solver.cpp:221] Iteration 57160 (1.28069 iter/s, 31.2332s/40 iters), loss = 1.82873
I1027 05:08:26.720726 37958 solver.cpp:240]     Train net output #0: loss = 1.82873 (* 1 = 1.82873 loss)
I1027 05:08:26.720743 37958 sgd_solver.cpp:105] Iteration 57160, lr = 0.00663765
I1027 05:08:57.494644 37958 solver.cpp:221] Iteration 57200 (1.29985 iter/s, 30.7728s/40 iters), loss = 1.81446
I1027 05:08:57.494823 37958 solver.cpp:240]     Train net output #0: loss = 1.81446 (* 1 = 1.81446 loss)
I1027 05:08:57.494839 37958 sgd_solver.cpp:105] Iteration 57200, lr = 0.00663529
I1027 05:09:28.286824 37958 solver.cpp:221] Iteration 57240 (1.29909 iter/s, 30.7908s/40 iters), loss = 1.71107
I1027 05:09:28.287024 37958 solver.cpp:240]     Train net output #0: loss = 1.71107 (* 1 = 1.71107 loss)
I1027 05:09:28.287044 37958 sgd_solver.cpp:105] Iteration 57240, lr = 0.00663294
I1027 05:09:59.111773 37958 solver.cpp:221] Iteration 57280 (1.29771 iter/s, 30.8236s/40 iters), loss = 1.89296
I1027 05:09:59.111989 37958 solver.cpp:240]     Train net output #0: loss = 1.89296 (* 1 = 1.89296 loss)
I1027 05:09:59.112004 37958 sgd_solver.cpp:105] Iteration 57280, lr = 0.00663059
I1027 05:10:29.805205 37958 solver.cpp:221] Iteration 57320 (1.30327 iter/s, 30.6921s/40 iters), loss = 1.68218
I1027 05:10:29.805486 37958 solver.cpp:240]     Train net output #0: loss = 1.68218 (* 1 = 1.68218 loss)
I1027 05:10:29.805510 37958 sgd_solver.cpp:105] Iteration 57320, lr = 0.00662824
I1027 05:11:00.676319 37958 solver.cpp:221] Iteration 57360 (1.29577 iter/s, 30.8697s/40 iters), loss = 1.89122
I1027 05:11:00.676492 37958 solver.cpp:240]     Train net output #0: loss = 1.89122 (* 1 = 1.89122 loss)
I1027 05:11:00.676509 37958 sgd_solver.cpp:105] Iteration 57360, lr = 0.00662588
I1027 05:11:32.053447 37958 solver.cpp:221] Iteration 57400 (1.27487 iter/s, 31.3758s/40 iters), loss = 1.95637
I1027 05:11:32.053681 37958 solver.cpp:240]     Train net output #0: loss = 1.95637 (* 1 = 1.95637 loss)
I1027 05:11:32.053707 37958 sgd_solver.cpp:105] Iteration 57400, lr = 0.00662353
I1027 05:12:03.692659 37958 solver.cpp:221] Iteration 57440 (1.26431 iter/s, 31.6378s/40 iters), loss = 1.76652
I1027 05:12:03.692899 37958 solver.cpp:240]     Train net output #0: loss = 1.76652 (* 1 = 1.76652 loss)
I1027 05:12:03.692916 37958 sgd_solver.cpp:105] Iteration 57440, lr = 0.00662118
I1027 05:12:34.429745 37958 solver.cpp:221] Iteration 57480 (1.30142 iter/s, 30.7357s/40 iters), loss = 1.69849
I1027 05:12:34.430009 37958 solver.cpp:240]     Train net output #0: loss = 1.69849 (* 1 = 1.69849 loss)
I1027 05:12:34.430037 37958 sgd_solver.cpp:105] Iteration 57480, lr = 0.00661882
I1027 05:12:48.998888 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_57500.caffemodel
I1027 05:12:49.030875 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_57500.solverstate
I1027 05:12:49.048557 37958 solver.cpp:333] Iteration 57500, Testing net (#0)
I1027 05:13:19.705224 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 05:13:19.911561 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.54068
I1027 05:13:19.911619 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.78092
I1027 05:13:19.911634 37958 solver.cpp:400]     Test net output #2: loss = 2.02874 (* 1 = 2.02874 loss)
I1027 05:13:36.322801 37958 solver.cpp:221] Iteration 57520 (0.646303 iter/s, 61.8905s/40 iters), loss = 2.21138
I1027 05:13:36.322887 37958 solver.cpp:240]     Train net output #0: loss = 2.21138 (* 1 = 2.21138 loss)
I1027 05:13:36.322906 37958 sgd_solver.cpp:105] Iteration 57520, lr = 0.00661647
I1027 05:13:58.482756 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1027 05:14:07.826282 37958 solver.cpp:221] Iteration 57560 (1.26975 iter/s, 31.5022s/40 iters), loss = 1.39977
I1027 05:14:07.826362 37958 solver.cpp:240]     Train net output #0: loss = 1.39977 (* 1 = 1.39977 loss)
I1027 05:14:07.826377 37958 sgd_solver.cpp:105] Iteration 57560, lr = 0.00661412
I1027 05:14:38.963364 37958 solver.cpp:221] Iteration 57600 (1.28469 iter/s, 31.1358s/40 iters), loss = 1.49762
I1027 05:14:38.963569 37958 solver.cpp:240]     Train net output #0: loss = 1.49762 (* 1 = 1.49762 loss)
I1027 05:14:38.963587 37958 sgd_solver.cpp:105] Iteration 57600, lr = 0.00661176
I1027 05:15:10.383368 37958 solver.cpp:221] Iteration 57640 (1.27313 iter/s, 31.4186s/40 iters), loss = 1.8367
I1027 05:15:10.383563 37958 solver.cpp:240]     Train net output #0: loss = 1.8367 (* 1 = 1.8367 loss)
I1027 05:15:10.383579 37958 sgd_solver.cpp:105] Iteration 57640, lr = 0.00660941
I1027 05:15:41.492456 37958 solver.cpp:221] Iteration 57680 (1.28585 iter/s, 31.1077s/40 iters), loss = 1.84841
I1027 05:15:41.492666 37958 solver.cpp:240]     Train net output #0: loss = 1.84841 (* 1 = 1.84841 loss)
I1027 05:15:41.492682 37958 sgd_solver.cpp:105] Iteration 57680, lr = 0.00660706
I1027 05:16:12.949187 37958 solver.cpp:221] Iteration 57720 (1.27164 iter/s, 31.4553s/40 iters), loss = 1.62968
I1027 05:16:12.949386 37958 solver.cpp:240]     Train net output #0: loss = 1.62968 (* 1 = 1.62968 loss)
I1027 05:16:12.949404 37958 sgd_solver.cpp:105] Iteration 57720, lr = 0.00660471
I1027 05:16:44.850870 37958 solver.cpp:221] Iteration 57760 (1.25391 iter/s, 31.9003s/40 iters), loss = 1.66055
I1027 05:16:44.851127 37958 solver.cpp:240]     Train net output #0: loss = 1.66055 (* 1 = 1.66055 loss)
I1027 05:16:44.851163 37958 sgd_solver.cpp:105] Iteration 57760, lr = 0.00660235
I1027 05:17:15.530536 37958 solver.cpp:221] Iteration 57800 (1.30385 iter/s, 30.6783s/40 iters), loss = 1.89922
I1027 05:17:15.530737 37958 solver.cpp:240]     Train net output #0: loss = 1.89922 (* 1 = 1.89922 loss)
I1027 05:17:15.530753 37958 sgd_solver.cpp:105] Iteration 57800, lr = 0.0066
I1027 05:17:46.357961 37958 solver.cpp:221] Iteration 57840 (1.2976 iter/s, 30.8261s/40 iters), loss = 1.52615
I1027 05:17:46.358177 37958 solver.cpp:240]     Train net output #0: loss = 1.52615 (* 1 = 1.52615 loss)
I1027 05:17:46.358196 37958 sgd_solver.cpp:105] Iteration 57840, lr = 0.00659765
I1027 05:18:17.230965 37958 solver.cpp:221] Iteration 57880 (1.29569 iter/s, 30.8716s/40 iters), loss = 1.53398
I1027 05:18:17.231173 37958 solver.cpp:240]     Train net output #0: loss = 1.53398 (* 1 = 1.53398 loss)
I1027 05:18:17.231189 37958 sgd_solver.cpp:105] Iteration 57880, lr = 0.00659529
I1027 05:18:48.163671 37958 solver.cpp:221] Iteration 57920 (1.29319 iter/s, 30.9313s/40 iters), loss = 1.70942
I1027 05:18:48.163859 37958 solver.cpp:240]     Train net output #0: loss = 1.70942 (* 1 = 1.70942 loss)
I1027 05:18:48.163887 37958 sgd_solver.cpp:105] Iteration 57920, lr = 0.00659294
I1027 05:19:19.153105 37958 solver.cpp:221] Iteration 57960 (1.29082 iter/s, 30.9881s/40 iters), loss = 1.4474
I1027 05:19:19.153291 37958 solver.cpp:240]     Train net output #0: loss = 1.4474 (* 1 = 1.4474 loss)
I1027 05:19:19.153312 37958 sgd_solver.cpp:105] Iteration 57960, lr = 0.00659059
I1027 05:19:49.250463 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_58000.caffemodel
I1027 05:19:49.282708 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_58000.solverstate
I1027 05:19:49.300870 37958 solver.cpp:333] Iteration 58000, Testing net (#0)
I1027 05:20:20.154093 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53732
I1027 05:20:20.154270 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77696
I1027 05:20:20.154285 37958 solver.cpp:400]     Test net output #2: loss = 2.05215 (* 1 = 2.05215 loss)
I1027 05:20:20.916630 37958 solver.cpp:221] Iteration 58000 (0.647658 iter/s, 61.761s/40 iters), loss = 1.84303
I1027 05:20:20.916695 37958 solver.cpp:240]     Train net output #0: loss = 1.84303 (* 1 = 1.84303 loss)
I1027 05:20:20.916710 37958 sgd_solver.cpp:105] Iteration 58000, lr = 0.00658823
I1027 05:20:51.926717 37958 solver.cpp:221] Iteration 58040 (1.28995 iter/s, 31.0088s/40 iters), loss = 1.97345
I1027 05:20:51.926942 37958 solver.cpp:240]     Train net output #0: loss = 1.97345 (* 1 = 1.97345 loss)
I1027 05:20:51.926959 37958 sgd_solver.cpp:105] Iteration 58040, lr = 0.00658588
I1027 05:21:22.325759 37958 solver.cpp:221] Iteration 58080 (1.31589 iter/s, 30.3977s/40 iters), loss = 1.70556
I1027 05:21:22.325953 37958 solver.cpp:240]     Train net output #0: loss = 1.70556 (* 1 = 1.70556 loss)
I1027 05:21:22.325970 37958 sgd_solver.cpp:105] Iteration 58080, lr = 0.00658353
I1027 05:21:52.968201 37958 solver.cpp:221] Iteration 58120 (1.30544 iter/s, 30.6411s/40 iters), loss = 1.62679
I1027 05:21:52.968406 37958 solver.cpp:240]     Train net output #0: loss = 1.62679 (* 1 = 1.62679 loss)
I1027 05:21:52.968423 37958 sgd_solver.cpp:105] Iteration 58120, lr = 0.00658118
I1027 05:22:24.044358 37958 solver.cpp:221] Iteration 58160 (1.28722 iter/s, 31.0748s/40 iters), loss = 1.7148
I1027 05:22:24.044564 37958 solver.cpp:240]     Train net output #0: loss = 1.7148 (* 1 = 1.7148 loss)
I1027 05:22:24.044579 37958 sgd_solver.cpp:105] Iteration 58160, lr = 0.00657882
I1027 05:22:54.795258 37958 solver.cpp:221] Iteration 58200 (1.30083 iter/s, 30.7495s/40 iters), loss = 2.23961
I1027 05:22:54.795584 37958 solver.cpp:240]     Train net output #0: loss = 2.23961 (* 1 = 2.23961 loss)
I1027 05:22:54.795636 37958 sgd_solver.cpp:105] Iteration 58200, lr = 0.00657647
I1027 05:23:26.131502 37958 solver.cpp:221] Iteration 58240 (1.27654 iter/s, 31.3347s/40 iters), loss = 1.96848
I1027 05:23:26.131688 37958 solver.cpp:240]     Train net output #0: loss = 1.96848 (* 1 = 1.96848 loss)
I1027 05:23:26.131705 37958 sgd_solver.cpp:105] Iteration 58240, lr = 0.00657412
I1027 05:23:56.507184 37958 solver.cpp:221] Iteration 58280 (1.3169 iter/s, 30.3743s/40 iters), loss = 1.71352
I1027 05:23:56.507380 37958 solver.cpp:240]     Train net output #0: loss = 1.71352 (* 1 = 1.71352 loss)
I1027 05:23:56.507395 37958 sgd_solver.cpp:105] Iteration 58280, lr = 0.00657176
I1027 05:24:26.690043 37958 solver.cpp:221] Iteration 58320 (1.32531 iter/s, 30.1815s/40 iters), loss = 2.05151
I1027 05:24:26.690217 37958 solver.cpp:240]     Train net output #0: loss = 2.05151 (* 1 = 2.05151 loss)
I1027 05:24:26.690232 37958 sgd_solver.cpp:105] Iteration 58320, lr = 0.00656941
I1027 05:24:56.812194 37958 solver.cpp:221] Iteration 58360 (1.32798 iter/s, 30.1208s/40 iters), loss = 1.61775
I1027 05:24:56.812405 37958 solver.cpp:240]     Train net output #0: loss = 1.61775 (* 1 = 1.61775 loss)
I1027 05:24:56.812432 37958 sgd_solver.cpp:105] Iteration 58360, lr = 0.00656706
I1027 05:25:27.061027 37958 solver.cpp:221] Iteration 58400 (1.32242 iter/s, 30.2475s/40 iters), loss = 1.63919
I1027 05:25:27.061224 37958 solver.cpp:240]     Train net output #0: loss = 1.63919 (* 1 = 1.63919 loss)
I1027 05:25:27.061241 37958 sgd_solver.cpp:105] Iteration 58400, lr = 0.00656471
I1027 05:25:57.735683 37958 solver.cpp:221] Iteration 58440 (1.30407 iter/s, 30.6733s/40 iters), loss = 2.00272
I1027 05:25:57.735863 37958 solver.cpp:240]     Train net output #0: loss = 2.00272 (* 1 = 2.00272 loss)
I1027 05:25:57.735880 37958 sgd_solver.cpp:105] Iteration 58440, lr = 0.00656235
I1027 05:26:28.353006 37958 solver.cpp:221] Iteration 58480 (1.30651 iter/s, 30.616s/40 iters), loss = 1.86082
I1027 05:26:28.353197 37958 solver.cpp:240]     Train net output #0: loss = 1.86082 (* 1 = 1.86082 loss)
I1027 05:26:28.353214 37958 sgd_solver.cpp:105] Iteration 58480, lr = 0.00656
I1027 05:26:43.102917 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_58500.caffemodel
I1027 05:26:43.137445 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_58500.solverstate
I1027 05:26:43.157415 37958 solver.cpp:333] Iteration 58500, Testing net (#0)
I1027 05:27:13.789710 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 05:27:13.994850 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53576
I1027 05:27:13.994912 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.777519
I1027 05:27:13.994926 37958 solver.cpp:400]     Test net output #2: loss = 2.07742 (* 1 = 2.07742 loss)
I1027 05:27:30.207051 37958 solver.cpp:221] Iteration 58520 (0.64671 iter/s, 61.8516s/40 iters), loss = 1.73449
I1027 05:27:30.207121 37958 solver.cpp:240]     Train net output #0: loss = 1.73449 (* 1 = 1.73449 loss)
I1027 05:27:30.207136 37958 sgd_solver.cpp:105] Iteration 58520, lr = 0.00655765
I1027 05:28:01.418612 37958 solver.cpp:221] Iteration 58560 (1.28163 iter/s, 31.2103s/40 iters), loss = 2.02061
I1027 05:28:01.418813 37958 solver.cpp:240]     Train net output #0: loss = 2.02061 (* 1 = 2.02061 loss)
I1027 05:28:01.418830 37958 sgd_solver.cpp:105] Iteration 58560, lr = 0.00655529
I1027 05:28:32.216085 37958 solver.cpp:221] Iteration 58600 (1.29887 iter/s, 30.7961s/40 iters), loss = 1.7106
I1027 05:28:32.216308 37958 solver.cpp:240]     Train net output #0: loss = 1.7106 (* 1 = 1.7106 loss)
I1027 05:28:32.216327 37958 sgd_solver.cpp:105] Iteration 58600, lr = 0.00655294
I1027 05:29:03.000946 37958 solver.cpp:221] Iteration 58640 (1.2994 iter/s, 30.7835s/40 iters), loss = 1.94634
I1027 05:29:03.001127 37958 solver.cpp:240]     Train net output #0: loss = 1.94634 (* 1 = 1.94634 loss)
I1027 05:29:03.001143 37958 sgd_solver.cpp:105] Iteration 58640, lr = 0.00655059
I1027 05:29:33.368793 37958 solver.cpp:221] Iteration 58680 (1.31724 iter/s, 30.3665s/40 iters), loss = 1.82986
I1027 05:29:33.368988 37958 solver.cpp:240]     Train net output #0: loss = 1.82986 (* 1 = 1.82986 loss)
I1027 05:29:33.369005 37958 sgd_solver.cpp:105] Iteration 58680, lr = 0.00654824
I1027 05:30:03.809674 37958 solver.cpp:221] Iteration 58720 (1.31408 iter/s, 30.4395s/40 iters), loss = 1.80645
I1027 05:30:03.809862 37958 solver.cpp:240]     Train net output #0: loss = 1.80645 (* 1 = 1.80645 loss)
I1027 05:30:03.809880 37958 sgd_solver.cpp:105] Iteration 58720, lr = 0.00654588
I1027 05:30:34.249101 37958 solver.cpp:221] Iteration 58760 (1.31414 iter/s, 30.4381s/40 iters), loss = 1.90417
I1027 05:30:34.249275 37958 solver.cpp:240]     Train net output #0: loss = 1.90417 (* 1 = 1.90417 loss)
I1027 05:30:34.249291 37958 sgd_solver.cpp:105] Iteration 58760, lr = 0.00654353
I1027 05:31:04.784373 37958 solver.cpp:221] Iteration 58800 (1.31002 iter/s, 30.5339s/40 iters), loss = 2.09483
I1027 05:31:04.784600 37958 solver.cpp:240]     Train net output #0: loss = 2.09483 (* 1 = 2.09483 loss)
I1027 05:31:04.784623 37958 sgd_solver.cpp:105] Iteration 58800, lr = 0.00654118
I1027 05:31:36.281635 37958 solver.cpp:221] Iteration 58840 (1.27001 iter/s, 31.4958s/40 iters), loss = 1.6542
I1027 05:31:36.281836 37958 solver.cpp:240]     Train net output #0: loss = 1.6542 (* 1 = 1.6542 loss)
I1027 05:31:36.281852 37958 sgd_solver.cpp:105] Iteration 58840, lr = 0.00653882
I1027 05:32:07.391605 37958 solver.cpp:221] Iteration 58880 (1.28582 iter/s, 31.1086s/40 iters), loss = 1.73866
I1027 05:32:07.391814 37958 solver.cpp:240]     Train net output #0: loss = 1.73866 (* 1 = 1.73866 loss)
I1027 05:32:07.391831 37958 sgd_solver.cpp:105] Iteration 58880, lr = 0.00653647
I1027 05:32:38.243865 37958 solver.cpp:221] Iteration 58920 (1.29656 iter/s, 30.8509s/40 iters), loss = 2.08799
I1027 05:32:38.244079 37958 solver.cpp:240]     Train net output #0: loss = 2.08799 (* 1 = 2.08799 loss)
I1027 05:32:38.244104 37958 sgd_solver.cpp:105] Iteration 58920, lr = 0.00653412
I1027 05:33:08.929666 37958 solver.cpp:221] Iteration 58960 (1.30359 iter/s, 30.6844s/40 iters), loss = 2.01238
I1027 05:33:08.929880 37958 solver.cpp:240]     Train net output #0: loss = 2.01238 (* 1 = 2.01238 loss)
I1027 05:33:08.929896 37958 sgd_solver.cpp:105] Iteration 58960, lr = 0.00653176
I1027 05:33:38.872980 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_59000.caffemodel
I1027 05:33:38.913355 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_59000.solverstate
I1027 05:33:38.940430 37958 solver.cpp:333] Iteration 59000, Testing net (#0)
I1027 05:34:09.814908 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53892
I1027 05:34:09.815078 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77852
I1027 05:34:09.815093 37958 solver.cpp:400]     Test net output #2: loss = 2.03183 (* 1 = 2.03183 loss)
I1027 05:34:10.580430 37958 solver.cpp:221] Iteration 59000 (0.648843 iter/s, 61.6482s/40 iters), loss = 2.21311
I1027 05:34:10.580497 37958 solver.cpp:240]     Train net output #0: loss = 2.21311 (* 1 = 2.21311 loss)
I1027 05:34:10.580513 37958 sgd_solver.cpp:105] Iteration 59000, lr = 0.00652941
I1027 05:34:41.992065 37958 solver.cpp:221] Iteration 59040 (1.27346 iter/s, 31.4104s/40 iters), loss = 1.55399
I1027 05:34:41.992282 37958 solver.cpp:240]     Train net output #0: loss = 1.55399 (* 1 = 1.55399 loss)
I1027 05:34:41.992305 37958 sgd_solver.cpp:105] Iteration 59040, lr = 0.00652706
I1027 05:35:12.500035 37958 solver.cpp:221] Iteration 59080 (1.31119 iter/s, 30.5066s/40 iters), loss = 1.77446
I1027 05:35:12.500270 37958 solver.cpp:240]     Train net output #0: loss = 1.77446 (* 1 = 1.77446 loss)
I1027 05:35:12.500288 37958 sgd_solver.cpp:105] Iteration 59080, lr = 0.00652471
I1027 05:35:42.908869 37958 solver.cpp:221] Iteration 59120 (1.31547 iter/s, 30.4074s/40 iters), loss = 1.70943
I1027 05:35:42.909096 37958 solver.cpp:240]     Train net output #0: loss = 1.70943 (* 1 = 1.70943 loss)
I1027 05:35:42.909116 37958 sgd_solver.cpp:105] Iteration 59120, lr = 0.00652235
I1027 05:36:13.382516 37958 solver.cpp:221] Iteration 59160 (1.31267 iter/s, 30.4722s/40 iters), loss = 1.90734
I1027 05:36:13.382695 37958 solver.cpp:240]     Train net output #0: loss = 1.90734 (* 1 = 1.90734 loss)
I1027 05:36:13.382711 37958 sgd_solver.cpp:105] Iteration 59160, lr = 0.00652
I1027 05:37:18.219604 37958 solver.cpp:221] Iteration 59200 (0.616956 iter/s, 64.8345s/40 iters), loss = 1.66536
I1027 05:37:18.219825 37958 solver.cpp:240]     Train net output #0: loss = 1.66536 (* 1 = 1.66536 loss)
I1027 05:37:18.219843 37958 sgd_solver.cpp:105] Iteration 59200, lr = 0.00651765
I1027 05:37:49.142230 37958 solver.cpp:221] Iteration 59240 (1.29361 iter/s, 30.9212s/40 iters), loss = 1.70602
I1027 05:37:49.142441 37958 solver.cpp:240]     Train net output #0: loss = 1.70602 (* 1 = 1.70602 loss)
I1027 05:37:49.142457 37958 sgd_solver.cpp:105] Iteration 59240, lr = 0.00651529
I1027 05:38:20.070741 37958 solver.cpp:221] Iteration 59280 (1.29336 iter/s, 30.9271s/40 iters), loss = 1.91284
I1027 05:38:20.070940 37958 solver.cpp:240]     Train net output #0: loss = 1.91284 (* 1 = 1.91284 loss)
I1027 05:38:20.070957 37958 sgd_solver.cpp:105] Iteration 59280, lr = 0.00651294
I1027 05:38:50.947643 37958 solver.cpp:221] Iteration 59320 (1.29552 iter/s, 30.8755s/40 iters), loss = 1.67607
I1027 05:38:50.947815 37958 solver.cpp:240]     Train net output #0: loss = 1.67607 (* 1 = 1.67607 loss)
I1027 05:38:50.947831 37958 sgd_solver.cpp:105] Iteration 59320, lr = 0.00651059
I1027 05:39:21.949486 37958 solver.cpp:221] Iteration 59360 (1.2903 iter/s, 31.0005s/40 iters), loss = 1.61649
I1027 05:39:21.949669 37958 solver.cpp:240]     Train net output #0: loss = 1.61649 (* 1 = 1.61649 loss)
I1027 05:39:21.949687 37958 sgd_solver.cpp:105] Iteration 59360, lr = 0.00650824
I1027 05:39:52.823539 37958 solver.cpp:221] Iteration 59400 (1.29564 iter/s, 30.8727s/40 iters), loss = 1.85959
I1027 05:39:52.823721 37958 solver.cpp:240]     Train net output #0: loss = 1.85959 (* 1 = 1.85959 loss)
I1027 05:39:52.823737 37958 sgd_solver.cpp:105] Iteration 59400, lr = 0.00650588
I1027 05:40:24.026747 37958 solver.cpp:221] Iteration 59440 (1.28198 iter/s, 31.2018s/40 iters), loss = 1.83876
I1027 05:40:24.026943 37958 solver.cpp:240]     Train net output #0: loss = 1.83876 (* 1 = 1.83876 loss)
I1027 05:40:24.026960 37958 sgd_solver.cpp:105] Iteration 59440, lr = 0.00650353
I1027 05:40:55.004155 37958 solver.cpp:221] Iteration 59480 (1.29132 iter/s, 30.976s/40 iters), loss = 1.76002
I1027 05:40:55.004606 37958 solver.cpp:240]     Train net output #0: loss = 1.76002 (* 1 = 1.76002 loss)
I1027 05:40:55.004622 37958 sgd_solver.cpp:105] Iteration 59480, lr = 0.00650118
I1027 05:41:09.582332 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_59500.caffemodel
I1027 05:41:09.614550 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_59500.solverstate
I1027 05:41:09.632725 37958 solver.cpp:333] Iteration 59500, Testing net (#0)
I1027 05:41:40.236079 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 05:41:40.442183 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.54064
I1027 05:41:40.442246 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.778119
I1027 05:41:40.442260 37958 solver.cpp:400]     Test net output #2: loss = 2.03406 (* 1 = 2.03406 loss)
I1027 05:41:56.527976 37958 solver.cpp:221] Iteration 59520 (0.650184 iter/s, 61.5211s/40 iters), loss = 2.00918
I1027 05:41:56.528044 37958 solver.cpp:240]     Train net output #0: loss = 2.00918 (* 1 = 2.00918 loss)
I1027 05:41:56.528059 37958 sgd_solver.cpp:105] Iteration 59520, lr = 0.00649882
I1027 05:42:28.422994 37958 solver.cpp:221] Iteration 59560 (1.25416 iter/s, 31.8937s/40 iters), loss = 1.76054
I1027 05:42:28.423379 37958 solver.cpp:240]     Train net output #0: loss = 1.76054 (* 1 = 1.76054 loss)
I1027 05:42:28.423462 37958 sgd_solver.cpp:105] Iteration 59560, lr = 0.00649647
I1027 05:42:59.931679 37958 solver.cpp:221] Iteration 59600 (1.26955 iter/s, 31.5071s/40 iters), loss = 1.26906
I1027 05:42:59.931877 37958 solver.cpp:240]     Train net output #0: loss = 1.26906 (* 1 = 1.26906 loss)
I1027 05:42:59.931893 37958 sgd_solver.cpp:105] Iteration 59600, lr = 0.00649412
I1027 05:43:30.545492 37958 solver.cpp:221] Iteration 59640 (1.30666 iter/s, 30.6125s/40 iters), loss = 1.62733
I1027 05:43:30.545693 37958 solver.cpp:240]     Train net output #0: loss = 1.62733 (* 1 = 1.62733 loss)
I1027 05:43:30.545711 37958 sgd_solver.cpp:105] Iteration 59640, lr = 0.00649176
I1027 05:44:01.251653 37958 solver.cpp:221] Iteration 59680 (1.30273 iter/s, 30.7048s/40 iters), loss = 1.64037
I1027 05:44:01.251894 37958 solver.cpp:240]     Train net output #0: loss = 1.64037 (* 1 = 1.64037 loss)
I1027 05:44:01.251919 37958 sgd_solver.cpp:105] Iteration 59680, lr = 0.00648941
I1027 05:44:32.181710 37958 solver.cpp:221] Iteration 59720 (1.2933 iter/s, 30.9286s/40 iters), loss = 1.42252
I1027 05:44:32.181938 37958 solver.cpp:240]     Train net output #0: loss = 1.42252 (* 1 = 1.42252 loss)
I1027 05:44:32.181957 37958 sgd_solver.cpp:105] Iteration 59720, lr = 0.00648706
I1027 05:45:03.656026 37958 solver.cpp:221] Iteration 59760 (1.27093 iter/s, 31.4729s/40 iters), loss = 1.59656
I1027 05:45:03.656260 37958 solver.cpp:240]     Train net output #0: loss = 1.59656 (* 1 = 1.59656 loss)
I1027 05:45:03.656288 37958 sgd_solver.cpp:105] Iteration 59760, lr = 0.00648471
I1027 05:45:35.337254 37958 solver.cpp:221] Iteration 59800 (1.26263 iter/s, 31.6798s/40 iters), loss = 1.84122
I1027 05:45:35.337460 37958 solver.cpp:240]     Train net output #0: loss = 1.84122 (* 1 = 1.84122 loss)
I1027 05:45:35.337477 37958 sgd_solver.cpp:105] Iteration 59800, lr = 0.00648235
I1027 05:46:07.575819 37958 solver.cpp:221] Iteration 59840 (1.2408 iter/s, 32.2371s/40 iters), loss = 1.87897
I1027 05:46:07.576014 37958 solver.cpp:240]     Train net output #0: loss = 1.87897 (* 1 = 1.87897 loss)
I1027 05:46:07.576030 37958 sgd_solver.cpp:105] Iteration 59840, lr = 0.00648
I1027 05:46:38.261344 37958 solver.cpp:221] Iteration 59880 (1.3036 iter/s, 30.6842s/40 iters), loss = 1.70138
I1027 05:46:38.261556 37958 solver.cpp:240]     Train net output #0: loss = 1.70138 (* 1 = 1.70138 loss)
I1027 05:46:38.261576 37958 sgd_solver.cpp:105] Iteration 59880, lr = 0.00647765
I1027 05:47:11.875785 37958 solver.cpp:221] Iteration 59920 (1.19002 iter/s, 33.613s/40 iters), loss = 1.8695
I1027 05:47:11.876004 37958 solver.cpp:240]     Train net output #0: loss = 1.8695 (* 1 = 1.8695 loss)
I1027 05:47:11.876022 37958 sgd_solver.cpp:105] Iteration 59920, lr = 0.00647529
I1027 05:47:45.588510 37958 solver.cpp:221] Iteration 59960 (1.18655 iter/s, 33.7112s/40 iters), loss = 1.49091
I1027 05:47:45.588747 37958 solver.cpp:240]     Train net output #0: loss = 1.49091 (* 1 = 1.49091 loss)
I1027 05:47:45.588766 37958 sgd_solver.cpp:105] Iteration 59960, lr = 0.00647294
I1027 05:48:15.728981 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_60000.caffemodel
I1027 05:48:15.761461 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_60000.solverstate
I1027 05:48:15.780840 37958 solver.cpp:333] Iteration 60000, Testing net (#0)
I1027 05:48:46.621695 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53936
I1027 05:48:46.621884 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.7804
I1027 05:48:46.621899 37958 solver.cpp:400]     Test net output #2: loss = 2.0299 (* 1 = 2.0299 loss)
I1027 05:48:47.379629 37958 solver.cpp:221] Iteration 60000 (0.647369 iter/s, 61.7886s/40 iters), loss = 2.00944
I1027 05:48:47.379691 37958 solver.cpp:240]     Train net output #0: loss = 2.00944 (* 1 = 2.00944 loss)
I1027 05:48:47.379706 37958 sgd_solver.cpp:105] Iteration 60000, lr = 0.00647059
I1027 05:49:18.330916 37958 solver.cpp:221] Iteration 60040 (1.29241 iter/s, 30.95s/40 iters), loss = 1.31986
I1027 05:49:18.331202 37958 solver.cpp:240]     Train net output #0: loss = 1.31986 (* 1 = 1.31986 loss)
I1027 05:49:18.331221 37958 sgd_solver.cpp:105] Iteration 60040, lr = 0.00646824
I1027 05:49:26.439625 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1027 05:49:49.346586 37958 solver.cpp:221] Iteration 60080 (1.28973 iter/s, 31.0142s/40 iters), loss = 1.76054
I1027 05:49:49.346798 37958 solver.cpp:240]     Train net output #0: loss = 1.76054 (* 1 = 1.76054 loss)
I1027 05:49:49.346813 37958 sgd_solver.cpp:105] Iteration 60080, lr = 0.00646588
I1027 05:50:19.706037 37958 solver.cpp:221] Iteration 60120 (1.31761 iter/s, 30.3581s/40 iters), loss = 1.80914
I1027 05:50:19.706228 37958 solver.cpp:240]     Train net output #0: loss = 1.80914 (* 1 = 1.80914 loss)
I1027 05:50:19.706244 37958 sgd_solver.cpp:105] Iteration 60120, lr = 0.00646353
I1027 05:50:50.441516 37958 solver.cpp:221] Iteration 60160 (1.30148 iter/s, 30.7341s/40 iters), loss = 1.53287
I1027 05:50:50.441686 37958 solver.cpp:240]     Train net output #0: loss = 1.53287 (* 1 = 1.53287 loss)
I1027 05:50:50.441702 37958 sgd_solver.cpp:105] Iteration 60160, lr = 0.00646118
I1027 05:51:21.347585 37958 solver.cpp:221] Iteration 60200 (1.2943 iter/s, 30.9047s/40 iters), loss = 1.81327
I1027 05:51:21.347781 37958 solver.cpp:240]     Train net output #0: loss = 1.81327 (* 1 = 1.81327 loss)
I1027 05:51:21.347798 37958 sgd_solver.cpp:105] Iteration 60200, lr = 0.00645882
I1027 05:51:52.211802 37958 solver.cpp:221] Iteration 60240 (1.29606 iter/s, 30.8629s/40 iters), loss = 1.60495
I1027 05:51:52.211992 37958 solver.cpp:240]     Train net output #0: loss = 1.60495 (* 1 = 1.60495 loss)
I1027 05:51:52.212009 37958 sgd_solver.cpp:105] Iteration 60240, lr = 0.00645647
I1027 05:52:22.874159 37958 solver.cpp:221] Iteration 60280 (1.30459 iter/s, 30.661s/40 iters), loss = 1.82241
I1027 05:52:22.874634 37958 solver.cpp:240]     Train net output #0: loss = 1.82241 (* 1 = 1.82241 loss)
I1027 05:52:22.874650 37958 sgd_solver.cpp:105] Iteration 60280, lr = 0.00645412
I1027 05:52:53.514968 37958 solver.cpp:221] Iteration 60320 (1.30552 iter/s, 30.6392s/40 iters), loss = 1.88939
I1027 05:52:53.515161 37958 solver.cpp:240]     Train net output #0: loss = 1.88939 (* 1 = 1.88939 loss)
I1027 05:52:53.515177 37958 sgd_solver.cpp:105] Iteration 60320, lr = 0.00645176
I1027 05:53:24.595263 37958 solver.cpp:221] Iteration 60360 (1.28705 iter/s, 31.0789s/40 iters), loss = 1.47691
I1027 05:53:24.595438 37958 solver.cpp:240]     Train net output #0: loss = 1.47691 (* 1 = 1.47691 loss)
I1027 05:53:24.595453 37958 sgd_solver.cpp:105] Iteration 60360, lr = 0.00644941
I1027 05:53:55.207653 37958 solver.cpp:221] Iteration 60400 (1.30672 iter/s, 30.6111s/40 iters), loss = 1.72145
I1027 05:53:55.207823 37958 solver.cpp:240]     Train net output #0: loss = 1.72145 (* 1 = 1.72145 loss)
I1027 05:53:55.207840 37958 sgd_solver.cpp:105] Iteration 60400, lr = 0.00644706
I1027 05:54:25.768908 37958 solver.cpp:221] Iteration 60440 (1.3089 iter/s, 30.5599s/40 iters), loss = 1.37681
I1027 05:54:25.769083 37958 solver.cpp:240]     Train net output #0: loss = 1.37681 (* 1 = 1.37681 loss)
I1027 05:54:25.769100 37958 sgd_solver.cpp:105] Iteration 60440, lr = 0.00644471
I1027 05:54:56.388196 37958 solver.cpp:221] Iteration 60480 (1.30642 iter/s, 30.618s/40 iters), loss = 1.76159
I1027 05:54:56.388376 37958 solver.cpp:240]     Train net output #0: loss = 1.76159 (* 1 = 1.76159 loss)
I1027 05:54:56.388393 37958 sgd_solver.cpp:105] Iteration 60480, lr = 0.00644235
I1027 05:55:10.864917 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_60500.caffemodel
I1027 05:55:10.900548 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_60500.solverstate
I1027 05:55:10.925443 37958 solver.cpp:333] Iteration 60500, Testing net (#0)
I1027 05:55:41.706677 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 05:55:41.914211 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53804
I1027 05:55:41.914268 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77672
I1027 05:55:41.914281 37958 solver.cpp:400]     Test net output #2: loss = 2.04404 (* 1 = 2.04404 loss)
I1027 05:55:57.821768 37958 solver.cpp:221] Iteration 60520 (0.651136 iter/s, 61.4311s/40 iters), loss = 1.77006
I1027 05:55:57.821835 37958 solver.cpp:240]     Train net output #0: loss = 1.77006 (* 1 = 1.77006 loss)
I1027 05:55:57.821851 37958 sgd_solver.cpp:105] Iteration 60520, lr = 0.00644
I1027 05:56:28.559351 37958 solver.cpp:221] Iteration 60560 (1.30139 iter/s, 30.7363s/40 iters), loss = 1.84037
I1027 05:56:28.559541 37958 solver.cpp:240]     Train net output #0: loss = 1.84037 (* 1 = 1.84037 loss)
I1027 05:56:28.559559 37958 sgd_solver.cpp:105] Iteration 60560, lr = 0.00643765
I1027 05:56:59.821651 37958 solver.cpp:221] Iteration 60600 (1.27955 iter/s, 31.2609s/40 iters), loss = 1.64741
I1027 05:56:59.821900 37958 solver.cpp:240]     Train net output #0: loss = 1.64741 (* 1 = 1.64741 loss)
I1027 05:56:59.821923 37958 sgd_solver.cpp:105] Iteration 60600, lr = 0.00643529
I1027 05:57:31.358413 37958 solver.cpp:221] Iteration 60640 (1.26842 iter/s, 31.5353s/40 iters), loss = 1.58843
I1027 05:57:31.358577 37958 solver.cpp:240]     Train net output #0: loss = 1.58843 (* 1 = 1.58843 loss)
I1027 05:57:31.358593 37958 sgd_solver.cpp:105] Iteration 60640, lr = 0.00643294
I1027 05:58:03.002671 37958 solver.cpp:221] Iteration 60680 (1.26411 iter/s, 31.6429s/40 iters), loss = 2.05292
I1027 05:58:03.002881 37958 solver.cpp:240]     Train net output #0: loss = 2.05292 (* 1 = 2.05292 loss)
I1027 05:58:03.002910 37958 sgd_solver.cpp:105] Iteration 60680, lr = 0.00643059
I1027 05:58:34.408159 37958 solver.cpp:221] Iteration 60720 (1.27372 iter/s, 31.4041s/40 iters), loss = 1.917
I1027 05:58:34.408403 37958 solver.cpp:240]     Train net output #0: loss = 1.917 (* 1 = 1.917 loss)
I1027 05:58:34.408432 37958 sgd_solver.cpp:105] Iteration 60720, lr = 0.00642824
I1027 05:59:05.893568 37958 solver.cpp:221] Iteration 60760 (1.27049 iter/s, 31.484s/40 iters), loss = 1.60082
I1027 05:59:05.893795 37958 solver.cpp:240]     Train net output #0: loss = 1.60082 (* 1 = 1.60082 loss)
I1027 05:59:05.893811 37958 sgd_solver.cpp:105] Iteration 60760, lr = 0.00642588
I1027 05:59:36.834537 37958 solver.cpp:221] Iteration 60800 (1.29284 iter/s, 30.9396s/40 iters), loss = 1.66325
I1027 05:59:36.834764 37958 solver.cpp:240]     Train net output #0: loss = 1.66325 (* 1 = 1.66325 loss)
I1027 05:59:36.834782 37958 sgd_solver.cpp:105] Iteration 60800, lr = 0.00642353
I1027 06:00:07.633031 37958 solver.cpp:221] Iteration 60840 (1.29882 iter/s, 30.7971s/40 iters), loss = 1.83265
I1027 06:00:07.633244 37958 solver.cpp:240]     Train net output #0: loss = 1.83265 (* 1 = 1.83265 loss)
I1027 06:00:07.633260 37958 sgd_solver.cpp:105] Iteration 60840, lr = 0.00642118
I1027 06:00:38.306601 37958 solver.cpp:221] Iteration 60880 (1.30411 iter/s, 30.6722s/40 iters), loss = 1.54385
I1027 06:00:38.306789 37958 solver.cpp:240]     Train net output #0: loss = 1.54385 (* 1 = 1.54385 loss)
I1027 06:00:38.306805 37958 sgd_solver.cpp:105] Iteration 60880, lr = 0.00641882
I1027 06:01:08.814872 37958 solver.cpp:221] Iteration 60920 (1.31118 iter/s, 30.5069s/40 iters), loss = 1.7737
I1027 06:01:08.815057 37958 solver.cpp:240]     Train net output #0: loss = 1.7737 (* 1 = 1.7737 loss)
I1027 06:01:08.815074 37958 sgd_solver.cpp:105] Iteration 60920, lr = 0.00641647
I1027 06:01:39.476052 37958 solver.cpp:221] Iteration 60960 (1.30464 iter/s, 30.6598s/40 iters), loss = 1.70924
I1027 06:01:39.476246 37958 solver.cpp:240]     Train net output #0: loss = 1.70924 (* 1 = 1.70924 loss)
I1027 06:01:39.476263 37958 sgd_solver.cpp:105] Iteration 60960, lr = 0.00641412
I1027 06:02:09.421631 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_61000.caffemodel
I1027 06:02:09.455744 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_61000.solverstate
I1027 06:02:09.473753 37958 solver.cpp:333] Iteration 61000, Testing net (#0)
I1027 06:02:40.420770 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53136
I1027 06:02:40.421039 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.7728
I1027 06:02:40.421074 37958 solver.cpp:400]     Test net output #2: loss = 2.06776 (* 1 = 2.06776 loss)
I1027 06:02:41.186370 37958 solver.cpp:221] Iteration 61000 (0.648216 iter/s, 61.7078s/40 iters), loss = 1.51559
I1027 06:02:41.186434 37958 solver.cpp:240]     Train net output #0: loss = 1.51559 (* 1 = 1.51559 loss)
I1027 06:02:41.186449 37958 sgd_solver.cpp:105] Iteration 61000, lr = 0.00641176
I1027 06:03:11.880690 37958 solver.cpp:221] Iteration 61040 (1.30323 iter/s, 30.6931s/40 iters), loss = 1.72348
I1027 06:03:11.880853 37958 solver.cpp:240]     Train net output #0: loss = 1.72348 (* 1 = 1.72348 loss)
I1027 06:03:11.880868 37958 sgd_solver.cpp:105] Iteration 61040, lr = 0.00640941
I1027 06:03:42.380071 37958 solver.cpp:221] Iteration 61080 (1.31156 iter/s, 30.4981s/40 iters), loss = 1.76117
I1027 06:03:42.380259 37958 solver.cpp:240]     Train net output #0: loss = 1.76117 (* 1 = 1.76117 loss)
I1027 06:03:42.380275 37958 sgd_solver.cpp:105] Iteration 61080, lr = 0.00640706
I1027 06:04:13.049603 37958 solver.cpp:221] Iteration 61120 (1.30428 iter/s, 30.6682s/40 iters), loss = 1.91071
I1027 06:04:13.049779 37958 solver.cpp:240]     Train net output #0: loss = 1.91071 (* 1 = 1.91071 loss)
I1027 06:04:13.049795 37958 sgd_solver.cpp:105] Iteration 61120, lr = 0.00640471
I1027 06:04:43.767654 37958 solver.cpp:221] Iteration 61160 (1.30222 iter/s, 30.7167s/40 iters), loss = 1.64498
I1027 06:04:43.767834 37958 solver.cpp:240]     Train net output #0: loss = 1.64498 (* 1 = 1.64498 loss)
I1027 06:04:43.767850 37958 sgd_solver.cpp:105] Iteration 61160, lr = 0.00640235
I1027 06:05:15.531038 37958 solver.cpp:221] Iteration 61200 (1.25937 iter/s, 31.762s/40 iters), loss = 1.9006
I1027 06:05:15.531239 37958 solver.cpp:240]     Train net output #0: loss = 1.9006 (* 1 = 1.9006 loss)
I1027 06:05:15.531255 37958 sgd_solver.cpp:105] Iteration 61200, lr = 0.0064
I1027 06:05:46.504452 37958 solver.cpp:221] Iteration 61240 (1.29149 iter/s, 30.972s/40 iters), loss = 1.79474
I1027 06:05:46.504668 37958 solver.cpp:240]     Train net output #0: loss = 1.79474 (* 1 = 1.79474 loss)
I1027 06:05:46.504685 37958 sgd_solver.cpp:105] Iteration 61240, lr = 0.00639765
I1027 06:06:17.359959 37958 solver.cpp:221] Iteration 61280 (1.29642 iter/s, 30.8541s/40 iters), loss = 1.58993
I1027 06:06:17.360169 37958 solver.cpp:240]     Train net output #0: loss = 1.58993 (* 1 = 1.58993 loss)
I1027 06:06:17.360193 37958 sgd_solver.cpp:105] Iteration 61280, lr = 0.00639529
I1027 06:06:47.915228 37958 solver.cpp:221] Iteration 61320 (1.30916 iter/s, 30.5539s/40 iters), loss = 1.71787
I1027 06:06:47.915423 37958 solver.cpp:240]     Train net output #0: loss = 1.71787 (* 1 = 1.71787 loss)
I1027 06:06:47.915446 37958 sgd_solver.cpp:105] Iteration 61320, lr = 0.00639294
I1027 06:07:18.560895 37958 solver.cpp:221] Iteration 61360 (1.3053 iter/s, 30.6443s/40 iters), loss = 1.60803
I1027 06:07:18.561086 37958 solver.cpp:240]     Train net output #0: loss = 1.60803 (* 1 = 1.60803 loss)
I1027 06:07:18.561105 37958 sgd_solver.cpp:105] Iteration 61360, lr = 0.00639059
I1027 06:07:49.350000 37958 solver.cpp:221] Iteration 61400 (1.29922 iter/s, 30.7878s/40 iters), loss = 1.82043
I1027 06:07:49.350209 37958 solver.cpp:240]     Train net output #0: loss = 1.82043 (* 1 = 1.82043 loss)
I1027 06:07:49.350226 37958 sgd_solver.cpp:105] Iteration 61400, lr = 0.00638823
I1027 06:08:20.567343 37958 solver.cpp:221] Iteration 61440 (1.2814 iter/s, 31.2159s/40 iters), loss = 1.85434
I1027 06:08:20.567606 37958 solver.cpp:240]     Train net output #0: loss = 1.85434 (* 1 = 1.85434 loss)
I1027 06:08:20.567634 37958 sgd_solver.cpp:105] Iteration 61440, lr = 0.00638588
I1027 06:08:51.784793 37958 solver.cpp:221] Iteration 61480 (1.28139 iter/s, 31.216s/40 iters), loss = 1.57238
I1027 06:08:51.785049 37958 solver.cpp:240]     Train net output #0: loss = 1.57238 (* 1 = 1.57238 loss)
I1027 06:08:51.785073 37958 sgd_solver.cpp:105] Iteration 61480, lr = 0.00638353
I1027 06:09:18.919401 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_61500.caffemodel
I1027 06:09:18.963008 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_61500.solverstate
I1027 06:09:18.985767 37958 solver.cpp:333] Iteration 61500, Testing net (#0)
I1027 06:09:49.721647 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 06:09:49.927542 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.54116
I1027 06:09:49.927605 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.78028
I1027 06:09:49.927619 37958 solver.cpp:400]     Test net output #2: loss = 2.06423 (* 1 = 2.06423 loss)
I1027 06:10:07.918284 37958 solver.cpp:221] Iteration 61520 (0.525414 iter/s, 76.1304s/40 iters), loss = 1.53329
I1027 06:10:07.918385 37958 solver.cpp:240]     Train net output #0: loss = 1.53329 (* 1 = 1.53329 loss)
I1027 06:10:07.918409 37958 sgd_solver.cpp:105] Iteration 61520, lr = 0.00638118
I1027 06:10:39.319221 37958 solver.cpp:221] Iteration 61560 (1.2739 iter/s, 31.3996s/40 iters), loss = 1.78614
I1027 06:10:39.319453 37958 solver.cpp:240]     Train net output #0: loss = 1.78614 (* 1 = 1.78614 loss)
I1027 06:10:39.319469 37958 sgd_solver.cpp:105] Iteration 61560, lr = 0.00637882
I1027 06:11:10.622016 37958 solver.cpp:221] Iteration 61600 (1.2779 iter/s, 31.3013s/40 iters), loss = 1.78169
I1027 06:11:10.622311 37958 solver.cpp:240]     Train net output #0: loss = 1.78169 (* 1 = 1.78169 loss)
I1027 06:11:10.622339 37958 sgd_solver.cpp:105] Iteration 61600, lr = 0.00637647
I1027 06:11:42.323689 37958 solver.cpp:221] Iteration 61640 (1.26182 iter/s, 31.7002s/40 iters), loss = 2.02956
I1027 06:11:42.323887 37958 solver.cpp:240]     Train net output #0: loss = 2.02956 (* 1 = 2.02956 loss)
I1027 06:11:42.323905 37958 sgd_solver.cpp:105] Iteration 61640, lr = 0.00637412
I1027 06:12:13.298141 37958 solver.cpp:221] Iteration 61680 (1.29144 iter/s, 30.9731s/40 iters), loss = 1.70537
I1027 06:12:13.298418 37958 solver.cpp:240]     Train net output #0: loss = 1.70537 (* 1 = 1.70537 loss)
I1027 06:12:13.298436 37958 sgd_solver.cpp:105] Iteration 61680, lr = 0.00637176
I1027 06:12:44.014187 37958 solver.cpp:221] Iteration 61720 (1.30231 iter/s, 30.7146s/40 iters), loss = 1.62791
I1027 06:12:44.014371 37958 solver.cpp:240]     Train net output #0: loss = 1.62791 (* 1 = 1.62791 loss)
I1027 06:12:44.014387 37958 sgd_solver.cpp:105] Iteration 61720, lr = 0.00636941
I1027 06:13:15.276654 37958 solver.cpp:221] Iteration 61760 (1.27955 iter/s, 31.2611s/40 iters), loss = 1.66629
I1027 06:13:15.276857 37958 solver.cpp:240]     Train net output #0: loss = 1.66629 (* 1 = 1.66629 loss)
I1027 06:13:15.276880 37958 sgd_solver.cpp:105] Iteration 61760, lr = 0.00636706
I1027 06:13:46.374377 37958 solver.cpp:221] Iteration 61800 (1.28632 iter/s, 31.0963s/40 iters), loss = 2.11674
I1027 06:13:46.374569 37958 solver.cpp:240]     Train net output #0: loss = 2.11674 (* 1 = 2.11674 loss)
I1027 06:13:46.374586 37958 sgd_solver.cpp:105] Iteration 61800, lr = 0.00636471
I1027 06:14:17.524161 37958 solver.cpp:221] Iteration 61840 (1.28417 iter/s, 31.1484s/40 iters), loss = 1.64518
I1027 06:14:17.524380 37958 solver.cpp:240]     Train net output #0: loss = 1.64518 (* 1 = 1.64518 loss)
I1027 06:14:17.524399 37958 sgd_solver.cpp:105] Iteration 61840, lr = 0.00636235
I1027 06:14:48.565068 37958 solver.cpp:221] Iteration 61880 (1.28868 iter/s, 31.0395s/40 iters), loss = 1.49567
I1027 06:14:48.565270 37958 solver.cpp:240]     Train net output #0: loss = 1.49567 (* 1 = 1.49567 loss)
I1027 06:14:48.565287 37958 sgd_solver.cpp:105] Iteration 61880, lr = 0.00636
I1027 06:15:19.493803 37958 solver.cpp:221] Iteration 61920 (1.29335 iter/s, 30.9274s/40 iters), loss = 1.74922
I1027 06:15:19.494078 37958 solver.cpp:240]     Train net output #0: loss = 1.74922 (* 1 = 1.74922 loss)
I1027 06:15:19.494132 37958 sgd_solver.cpp:105] Iteration 61920, lr = 0.00635765
I1027 06:15:50.243007 37958 solver.cpp:221] Iteration 61960 (1.30091 iter/s, 30.7478s/40 iters), loss = 1.95522
I1027 06:15:50.243211 37958 solver.cpp:240]     Train net output #0: loss = 1.95522 (* 1 = 1.95522 loss)
I1027 06:15:50.243229 37958 sgd_solver.cpp:105] Iteration 61960, lr = 0.00635529
I1027 06:16:20.562640 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_62000.caffemodel
I1027 06:16:20.597419 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_62000.solverstate
I1027 06:16:20.617267 37958 solver.cpp:333] Iteration 62000, Testing net (#0)
I1027 06:16:51.561666 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53736
I1027 06:16:51.561836 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77912
I1027 06:16:51.561852 37958 solver.cpp:400]     Test net output #2: loss = 2.0316 (* 1 = 2.0316 loss)
I1027 06:16:52.328811 37958 solver.cpp:221] Iteration 62000 (0.644296 iter/s, 62.0833s/40 iters), loss = 1.51926
I1027 06:16:52.328877 37958 solver.cpp:240]     Train net output #0: loss = 1.51926 (* 1 = 1.51926 loss)
I1027 06:16:52.328896 37958 sgd_solver.cpp:105] Iteration 62000, lr = 0.00635294
I1027 06:17:23.290210 37958 solver.cpp:221] Iteration 62040 (1.29198 iter/s, 30.9602s/40 iters), loss = 1.98608
I1027 06:17:23.290426 37958 solver.cpp:240]     Train net output #0: loss = 1.98608 (* 1 = 1.98608 loss)
I1027 06:17:23.290442 37958 sgd_solver.cpp:105] Iteration 62040, lr = 0.00635059
I1027 06:17:53.979600 37958 solver.cpp:221] Iteration 62080 (1.30344 iter/s, 30.688s/40 iters), loss = 1.95309
I1027 06:17:53.979822 37958 solver.cpp:240]     Train net output #0: loss = 1.95309 (* 1 = 1.95309 loss)
I1027 06:17:53.979838 37958 sgd_solver.cpp:105] Iteration 62080, lr = 0.00634824
I1027 06:18:24.975600 37958 solver.cpp:221] Iteration 62120 (1.29055 iter/s, 30.9946s/40 iters), loss = 1.76076
I1027 06:18:24.975775 37958 solver.cpp:240]     Train net output #0: loss = 1.76076 (* 1 = 1.76076 loss)
I1027 06:18:24.975790 37958 sgd_solver.cpp:105] Iteration 62120, lr = 0.00634588
I1027 06:18:55.694584 37958 solver.cpp:221] Iteration 62160 (1.30218 iter/s, 30.7177s/40 iters), loss = 1.82824
I1027 06:18:55.694769 37958 solver.cpp:240]     Train net output #0: loss = 1.82824 (* 1 = 1.82824 loss)
I1027 06:18:55.694787 37958 sgd_solver.cpp:105] Iteration 62160, lr = 0.00634353
I1027 06:19:26.368026 37958 solver.cpp:221] Iteration 62200 (1.30412 iter/s, 30.6721s/40 iters), loss = 1.63145
I1027 06:19:26.368221 37958 solver.cpp:240]     Train net output #0: loss = 1.63145 (* 1 = 1.63145 loss)
I1027 06:19:26.368238 37958 sgd_solver.cpp:105] Iteration 62200, lr = 0.00634118
I1027 06:19:57.129449 37958 solver.cpp:221] Iteration 62240 (1.30039 iter/s, 30.7601s/40 iters), loss = 1.72526
I1027 06:19:57.129631 37958 solver.cpp:240]     Train net output #0: loss = 1.72526 (* 1 = 1.72526 loss)
I1027 06:19:57.129649 37958 sgd_solver.cpp:105] Iteration 62240, lr = 0.00633882
I1027 06:20:27.875346 37958 solver.cpp:221] Iteration 62280 (1.30104 iter/s, 30.7445s/40 iters), loss = 1.85692
I1027 06:20:27.875573 37958 solver.cpp:240]     Train net output #0: loss = 1.85692 (* 1 = 1.85692 loss)
I1027 06:20:27.875591 37958 sgd_solver.cpp:105] Iteration 62280, lr = 0.00633647
I1027 06:20:59.873137 37958 solver.cpp:221] Iteration 62320 (1.25014 iter/s, 31.9963s/40 iters), loss = 1.75507
I1027 06:20:59.873348 37958 solver.cpp:240]     Train net output #0: loss = 1.75507 (* 1 = 1.75507 loss)
I1027 06:20:59.873373 37958 sgd_solver.cpp:105] Iteration 62320, lr = 0.00633412
I1027 06:21:31.812284 37958 solver.cpp:221] Iteration 62360 (1.25244 iter/s, 31.9377s/40 iters), loss = 1.7951
I1027 06:21:31.812528 37958 solver.cpp:240]     Train net output #0: loss = 1.7951 (* 1 = 1.7951 loss)
I1027 06:21:31.812546 37958 sgd_solver.cpp:105] Iteration 62360, lr = 0.00633176
I1027 06:22:02.398488 37958 solver.cpp:221] Iteration 62400 (1.30784 iter/s, 30.5848s/40 iters), loss = 1.81791
I1027 06:22:02.398730 37958 solver.cpp:240]     Train net output #0: loss = 1.81791 (* 1 = 1.81791 loss)
I1027 06:22:02.398748 37958 sgd_solver.cpp:105] Iteration 62400, lr = 0.00632941
I1027 06:22:32.804471 37958 solver.cpp:221] Iteration 62440 (1.31559 iter/s, 30.4046s/40 iters), loss = 1.81121
I1027 06:22:32.804656 37958 solver.cpp:240]     Train net output #0: loss = 1.81121 (* 1 = 1.81121 loss)
I1027 06:22:32.804672 37958 sgd_solver.cpp:105] Iteration 62440, lr = 0.00632706
I1027 06:23:03.269755 37958 solver.cpp:221] Iteration 62480 (1.31303 iter/s, 30.4639s/40 iters), loss = 1.8968
I1027 06:23:03.269948 37958 solver.cpp:240]     Train net output #0: loss = 1.8968 (* 1 = 1.8968 loss)
I1027 06:23:03.269963 37958 sgd_solver.cpp:105] Iteration 62480, lr = 0.00632471
I1027 06:23:17.771672 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_62500.caffemodel
I1027 06:23:17.808102 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_62500.solverstate
I1027 06:23:17.831670 37958 solver.cpp:333] Iteration 62500, Testing net (#0)
I1027 06:23:48.482064 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 06:23:48.677917 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53556
I1027 06:23:48.677973 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77948
I1027 06:23:48.677986 37958 solver.cpp:400]     Test net output #2: loss = 2.09428 (* 1 = 2.09428 loss)
I1027 06:24:04.836602 37958 solver.cpp:221] Iteration 62520 (0.649727 iter/s, 61.5643s/40 iters), loss = 1.53405
I1027 06:24:04.836668 37958 solver.cpp:240]     Train net output #0: loss = 1.53405 (* 1 = 1.53405 loss)
I1027 06:24:04.836683 37958 sgd_solver.cpp:105] Iteration 62520, lr = 0.00632235
I1027 06:24:29.220175 38009 data_layer.cpp:73] Restarting data prefetching from start.
I1027 06:24:35.286911 37958 solver.cpp:221] Iteration 62560 (1.31367 iter/s, 30.4491s/40 iters), loss = 1.87188
I1027 06:24:35.286976 37958 solver.cpp:240]     Train net output #0: loss = 1.87188 (* 1 = 1.87188 loss)
I1027 06:24:35.286991 37958 sgd_solver.cpp:105] Iteration 62560, lr = 0.00632
I1027 06:25:05.921398 37958 solver.cpp:221] Iteration 62600 (1.30577 iter/s, 30.6333s/40 iters), loss = 1.84008
I1027 06:25:05.921598 37958 solver.cpp:240]     Train net output #0: loss = 1.84008 (* 1 = 1.84008 loss)
I1027 06:25:05.921614 37958 sgd_solver.cpp:105] Iteration 62600, lr = 0.00631765
I1027 06:25:36.333029 37958 solver.cpp:221] Iteration 62640 (1.31535 iter/s, 30.4103s/40 iters), loss = 1.72349
I1027 06:25:36.333217 37958 solver.cpp:240]     Train net output #0: loss = 1.72349 (* 1 = 1.72349 loss)
I1027 06:25:36.333233 37958 sgd_solver.cpp:105] Iteration 62640, lr = 0.00631529
I1027 06:26:06.641733 37958 solver.cpp:221] Iteration 62680 (1.31981 iter/s, 30.3074s/40 iters), loss = 1.785
I1027 06:26:06.641911 37958 solver.cpp:240]     Train net output #0: loss = 1.785 (* 1 = 1.785 loss)
I1027 06:26:06.641927 37958 sgd_solver.cpp:105] Iteration 62680, lr = 0.00631294
I1027 06:26:37.070752 37958 solver.cpp:221] Iteration 62720 (1.31459 iter/s, 30.4277s/40 iters), loss = 1.70853
I1027 06:26:37.070947 37958 solver.cpp:240]     Train net output #0: loss = 1.70853 (* 1 = 1.70853 loss)
I1027 06:26:37.070964 37958 sgd_solver.cpp:105] Iteration 62720, lr = 0.00631059
I1027 06:27:07.727280 37958 solver.cpp:221] Iteration 62760 (1.30484 iter/s, 30.6552s/40 iters), loss = 1.77722
I1027 06:27:07.727466 37958 solver.cpp:240]     Train net output #0: loss = 1.77722 (* 1 = 1.77722 loss)
I1027 06:27:07.727483 37958 sgd_solver.cpp:105] Iteration 62760, lr = 0.00630823
I1027 06:27:39.158663 37958 solver.cpp:221] Iteration 62800 (1.27267 iter/s, 31.43s/40 iters), loss = 1.5286
I1027 06:27:39.158903 37958 solver.cpp:240]     Train net output #0: loss = 1.5286 (* 1 = 1.5286 loss)
I1027 06:27:39.158927 37958 sgd_solver.cpp:105] Iteration 62800, lr = 0.00630588
I1027 06:28:11.706018 37958 solver.cpp:221] Iteration 62840 (1.22903 iter/s, 32.5459s/40 iters), loss = 1.65015
I1027 06:28:11.706322 37958 solver.cpp:240]     Train net output #0: loss = 1.65015 (* 1 = 1.65015 loss)
I1027 06:28:11.706349 37958 sgd_solver.cpp:105] Iteration 62840, lr = 0.00630353
I1027 06:28:43.509405 37958 solver.cpp:221] Iteration 62880 (1.25779 iter/s, 31.8019s/40 iters), loss = 1.74269
I1027 06:28:43.509613 37958 solver.cpp:240]     Train net output #0: loss = 1.74269 (* 1 = 1.74269 loss)
I1027 06:28:43.509630 37958 sgd_solver.cpp:105] Iteration 62880, lr = 0.00630118
I1027 06:29:14.908768 37958 solver.cpp:221] Iteration 62920 (1.27397 iter/s, 31.398s/40 iters), loss = 1.76939
I1027 06:29:14.909013 37958 solver.cpp:240]     Train net output #0: loss = 1.76939 (* 1 = 1.76939 loss)
I1027 06:29:14.909035 37958 sgd_solver.cpp:105] Iteration 62920, lr = 0.00629882
I1027 06:29:45.958133 37958 solver.cpp:221] Iteration 62960 (1.28833 iter/s, 31.0479s/40 iters), loss = 1.68562
I1027 06:29:45.958326 37958 solver.cpp:240]     Train net output #0: loss = 1.68562 (* 1 = 1.68562 loss)
I1027 06:29:45.958345 37958 sgd_solver.cpp:105] Iteration 62960, lr = 0.00629647
I1027 06:30:16.530383 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_63000.caffemodel
I1027 06:30:16.564901 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_63000.solverstate
I1027 06:30:16.584414 37958 solver.cpp:333] Iteration 63000, Testing net (#0)
I1027 06:30:47.493841 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53832
I1027 06:30:47.494015 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77568
I1027 06:30:47.494030 37958 solver.cpp:400]     Test net output #2: loss = 2.04777 (* 1 = 2.04777 loss)
I1027 06:30:48.252111 37958 solver.cpp:221] Iteration 63000 (0.642143 iter/s, 62.2915s/40 iters), loss = 1.66318
I1027 06:30:48.252172 37958 solver.cpp:240]     Train net output #0: loss = 1.66318 (* 1 = 1.66318 loss)
I1027 06:30:48.252189 37958 sgd_solver.cpp:105] Iteration 63000, lr = 0.00629412
I1027 06:31:19.412314 37958 solver.cpp:221] Iteration 63040 (1.28374 iter/s, 31.159s/40 iters), loss = 1.69343
I1027 06:31:19.412518 37958 solver.cpp:240]     Train net output #0: loss = 1.69343 (* 1 = 1.69343 loss)
I1027 06:31:19.412534 37958 sgd_solver.cpp:105] Iteration 63040, lr = 0.00629176
I1027 06:31:50.933223 37958 solver.cpp:221] Iteration 63080 (1.26906 iter/s, 31.5195s/40 iters), loss = 1.7902
I1027 06:31:50.933437 37958 solver.cpp:240]     Train net output #0: loss = 1.7902 (* 1 = 1.7902 loss)
I1027 06:31:50.933454 37958 sgd_solver.cpp:105] Iteration 63080, lr = 0.00628941
I1027 06:32:21.424463 37958 solver.cpp:221] Iteration 63120 (1.31191 iter/s, 30.4899s/40 iters), loss = 2.01222
I1027 06:32:21.424654 37958 solver.cpp:240]     Train net output #0: loss = 2.01222 (* 1 = 2.01222 loss)
I1027 06:32:21.424670 37958 sgd_solver.cpp:105] Iteration 63120, lr = 0.00628706
I1027 06:32:51.930819 37958 solver.cpp:221] Iteration 63160 (1.31126 iter/s, 30.505s/40 iters), loss = 1.42734
I1027 06:32:51.931030 37958 solver.cpp:240]     Train net output #0: loss = 1.42734 (* 1 = 1.42734 loss)
I1027 06:32:51.931047 37958 sgd_solver.cpp:105] Iteration 63160, lr = 0.00628471
I1027 06:33:23.149567 37958 solver.cpp:221] Iteration 63200 (1.28134 iter/s, 31.2174s/40 iters), loss = 1.68329
I1027 06:33:23.149771 37958 solver.cpp:240]     Train net output #0: loss = 1.68329 (* 1 = 1.68329 loss)
I1027 06:33:23.149787 37958 sgd_solver.cpp:105] Iteration 63200, lr = 0.00628235
I1027 06:33:54.124208 37958 solver.cpp:221] Iteration 63240 (1.29144 iter/s, 30.9733s/40 iters), loss = 1.94986
I1027 06:33:54.124416 37958 solver.cpp:240]     Train net output #0: loss = 1.94986 (* 1 = 1.94986 loss)
I1027 06:33:54.124433 37958 sgd_solver.cpp:105] Iteration 63240, lr = 0.00628
I1027 06:34:51.347461 37958 solver.cpp:221] Iteration 63280 (0.699045 iter/s, 57.2209s/40 iters), loss = 2.12412
I1027 06:34:51.347726 37958 solver.cpp:240]     Train net output #0: loss = 2.12412 (* 1 = 2.12412 loss)
I1027 06:34:51.347759 37958 sgd_solver.cpp:105] Iteration 63280, lr = 0.00627765
I1027 06:35:21.775058 37958 solver.cpp:221] Iteration 63320 (1.31466 iter/s, 30.4262s/40 iters), loss = 1.61473
I1027 06:35:21.775269 37958 solver.cpp:240]     Train net output #0: loss = 1.61473 (* 1 = 1.61473 loss)
I1027 06:35:21.775285 37958 sgd_solver.cpp:105] Iteration 63320, lr = 0.00627529
I1027 06:35:53.469563 37958 solver.cpp:221] Iteration 63360 (1.2621 iter/s, 31.6931s/40 iters), loss = 1.73852
I1027 06:35:53.478401 37958 solver.cpp:240]     Train net output #0: loss = 1.73852 (* 1 = 1.73852 loss)
I1027 06:35:53.478438 37958 sgd_solver.cpp:105] Iteration 63360, lr = 0.00627294
I1027 06:36:43.559247 37958 solver.cpp:221] Iteration 63400 (0.798739 iter/s, 50.079s/40 iters), loss = 1.58101
I1027 06:36:43.560016 37958 solver.cpp:240]     Train net output #0: loss = 1.58101 (* 1 = 1.58101 loss)
I1027 06:36:43.560062 37958 sgd_solver.cpp:105] Iteration 63400, lr = 0.00627059
I1027 06:37:14.461026 37958 solver.cpp:221] Iteration 63440 (1.2945 iter/s, 30.8999s/40 iters), loss = 1.81972
I1027 06:37:14.461242 37958 solver.cpp:240]     Train net output #0: loss = 1.81972 (* 1 = 1.81972 loss)
I1027 06:37:14.461258 37958 sgd_solver.cpp:105] Iteration 63440, lr = 0.00626824
I1027 06:37:44.812155 37958 solver.cpp:221] Iteration 63480 (1.31797 iter/s, 30.3498s/40 iters), loss = 1.50866
I1027 06:37:44.812391 37958 solver.cpp:240]     Train net output #0: loss = 1.50866 (* 1 = 1.50866 loss)
I1027 06:37:44.812407 37958 sgd_solver.cpp:105] Iteration 63480, lr = 0.00626588
I1027 06:37:59.473475 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_63500.caffemodel
I1027 06:37:59.722015 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_63500.solverstate
I1027 06:37:59.741047 37958 solver.cpp:333] Iteration 63500, Testing net (#0)
I1027 06:38:30.340821 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 06:38:30.547098 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53516
I1027 06:38:30.547158 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77836
I1027 06:38:30.547178 37958 solver.cpp:400]     Test net output #2: loss = 2.06936 (* 1 = 2.06936 loss)
I1027 06:38:46.694288 37958 solver.cpp:221] Iteration 63520 (0.646417 iter/s, 61.8796s/40 iters), loss = 1.83632
I1027 06:38:46.694365 37958 solver.cpp:240]     Train net output #0: loss = 1.83632 (* 1 = 1.83632 loss)
I1027 06:38:46.694380 37958 sgd_solver.cpp:105] Iteration 63520, lr = 0.00626353
I1027 06:39:17.005511 37958 solver.cpp:221] Iteration 63560 (1.3197 iter/s, 30.31s/40 iters), loss = 1.47251
I1027 06:39:17.005712 37958 solver.cpp:240]     Train net output #0: loss = 1.47251 (* 1 = 1.47251 loss)
I1027 06:39:17.005728 37958 sgd_solver.cpp:105] Iteration 63560, lr = 0.00626118
I1027 06:39:47.386250 37958 solver.cpp:221] Iteration 63600 (1.31668 iter/s, 30.3794s/40 iters), loss = 1.90927
I1027 06:39:47.386420 37958 solver.cpp:240]     Train net output #0: loss = 1.90927 (* 1 = 1.90927 loss)
I1027 06:39:47.386435 37958 sgd_solver.cpp:105] Iteration 63600, lr = 0.00625882
I1027 06:40:17.883512 37958 solver.cpp:221] Iteration 63640 (1.31165 iter/s, 30.4959s/40 iters), loss = 1.7873
I1027 06:40:17.883720 37958 solver.cpp:240]     Train net output #0: loss = 1.7873 (* 1 = 1.7873 loss)
I1027 06:40:17.883736 37958 sgd_solver.cpp:105] Iteration 63640, lr = 0.00625647
I1027 06:40:48.262030 37958 solver.cpp:221] Iteration 63680 (1.31678 iter/s, 30.3772s/40 iters), loss = 1.51615
I1027 06:40:48.262255 37958 solver.cpp:240]     Train net output #0: loss = 1.51615 (* 1 = 1.51615 loss)
I1027 06:40:48.262270 37958 sgd_solver.cpp:105] Iteration 63680, lr = 0.00625412
I1027 06:41:19.158051 37958 solver.cpp:221] Iteration 63720 (1.29472 iter/s, 30.8946s/40 iters), loss = 1.62064
I1027 06:41:19.158231 37958 solver.cpp:240]     Train net output #0: loss = 1.62064 (* 1 = 1.62064 loss)
I1027 06:41:19.158247 37958 sgd_solver.cpp:105] Iteration 63720, lr = 0.00625176
I1027 06:41:50.104670 37958 solver.cpp:221] Iteration 63760 (1.2926 iter/s, 30.9453s/40 iters), loss = 1.8201
I1027 06:41:50.104920 37958 solver.cpp:240]     Train net output #0: loss = 1.8201 (* 1 = 1.8201 loss)
I1027 06:41:50.104938 37958 sgd_solver.cpp:105] Iteration 63760, lr = 0.00624941
I1027 06:42:28.514680 37958 solver.cpp:221] Iteration 63800 (1.04144 iter/s, 38.4083s/40 iters), loss = 1.8165
I1027 06:42:28.514891 37958 solver.cpp:240]     Train net output #0: loss = 1.8165 (* 1 = 1.8165 loss)
I1027 06:42:28.514907 37958 sgd_solver.cpp:105] Iteration 63800, lr = 0.00624706
I1027 06:42:59.642756 37958 solver.cpp:221] Iteration 63840 (1.28507 iter/s, 31.1267s/40 iters), loss = 2.3212
I1027 06:42:59.642988 37958 solver.cpp:240]     Train net output #0: loss = 2.3212 (* 1 = 2.3212 loss)
I1027 06:42:59.643020 37958 sgd_solver.cpp:105] Iteration 63840, lr = 0.00624471
I1027 06:43:30.146212 37958 solver.cpp:221] Iteration 63880 (1.31139 iter/s, 30.5021s/40 iters), loss = 1.73728
I1027 06:43:30.146409 37958 solver.cpp:240]     Train net output #0: loss = 1.73728 (* 1 = 1.73728 loss)
I1027 06:43:30.146425 37958 sgd_solver.cpp:105] Iteration 63880, lr = 0.00624235
I1027 06:44:00.855810 37958 solver.cpp:221] Iteration 63920 (1.30258 iter/s, 30.7082s/40 iters), loss = 1.47533
I1027 06:44:00.856024 37958 solver.cpp:240]     Train net output #0: loss = 1.47533 (* 1 = 1.47533 loss)
I1027 06:44:00.856040 37958 sgd_solver.cpp:105] Iteration 63920, lr = 0.00624
I1027 06:44:31.401233 37958 solver.cpp:221] Iteration 63960 (1.30958 iter/s, 30.5441s/40 iters), loss = 1.45297
I1027 06:44:31.401428 37958 solver.cpp:240]     Train net output #0: loss = 1.45297 (* 1 = 1.45297 loss)
I1027 06:44:31.401518 37958 sgd_solver.cpp:105] Iteration 63960, lr = 0.00623765
I1027 06:45:01.318440 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_64000.caffemodel
I1027 06:45:01.352079 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_64000.solverstate
I1027 06:45:01.370115 37958 solver.cpp:333] Iteration 64000, Testing net (#0)
I1027 06:45:32.198168 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53496
I1027 06:45:32.198381 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77708
I1027 06:45:32.198396 37958 solver.cpp:400]     Test net output #2: loss = 2.06316 (* 1 = 2.06316 loss)
I1027 06:45:32.954990 37958 solver.cpp:221] Iteration 64000 (0.649865 iter/s, 61.5513s/40 iters), loss = 1.56062
I1027 06:45:32.955050 37958 solver.cpp:240]     Train net output #0: loss = 1.56062 (* 1 = 1.56062 loss)
I1027 06:45:32.955065 37958 sgd_solver.cpp:105] Iteration 64000, lr = 0.00623529
I1027 06:46:03.694406 37958 solver.cpp:221] Iteration 64040 (1.30131 iter/s, 30.7382s/40 iters), loss = 1.58688
I1027 06:46:03.694607 37958 solver.cpp:240]     Train net output #0: loss = 1.58688 (* 1 = 1.58688 loss)
I1027 06:46:03.694622 37958 sgd_solver.cpp:105] Iteration 64040, lr = 0.00623294
I1027 06:46:34.361287 37958 solver.cpp:221] Iteration 64080 (1.3044 iter/s, 30.6655s/40 iters), loss = 1.82718
I1027 06:46:34.361534 37958 solver.cpp:240]     Train net output #0: loss = 1.82718 (* 1 = 1.82718 loss)
I1027 06:46:34.361562 37958 sgd_solver.cpp:105] Iteration 64080, lr = 0.00623059
I1027 06:47:05.877358 37958 solver.cpp:221] Iteration 64120 (1.26925 iter/s, 31.5146s/40 iters), loss = 1.4383
I1027 06:47:05.877540 37958 solver.cpp:240]     Train net output #0: loss = 1.4383 (* 1 = 1.4383 loss)
I1027 06:47:05.877557 37958 sgd_solver.cpp:105] Iteration 64120, lr = 0.00622824
I1027 06:47:36.714464 37958 solver.cpp:221] Iteration 64160 (1.2972 iter/s, 30.8358s/40 iters), loss = 1.45571
I1027 06:47:36.714658 37958 solver.cpp:240]     Train net output #0: loss = 1.45571 (* 1 = 1.45571 loss)
I1027 06:47:36.714675 37958 sgd_solver.cpp:105] Iteration 64160, lr = 0.00622588
I1027 06:48:08.287015 37958 solver.cpp:221] Iteration 64200 (1.26698 iter/s, 31.5712s/40 iters), loss = 1.58441
I1027 06:48:08.287292 37958 solver.cpp:240]     Train net output #0: loss = 1.58441 (* 1 = 1.58441 loss)
I1027 06:48:08.287328 37958 sgd_solver.cpp:105] Iteration 64200, lr = 0.00622353
I1027 06:48:38.754309 37958 solver.cpp:221] Iteration 64240 (1.31294 iter/s, 30.4659s/40 iters), loss = 1.92983
I1027 06:48:38.754488 37958 solver.cpp:240]     Train net output #0: loss = 1.92983 (* 1 = 1.92983 loss)
I1027 06:48:38.754504 37958 sgd_solver.cpp:105] Iteration 64240, lr = 0.00622118
I1027 06:49:09.629938 37958 solver.cpp:221] Iteration 64280 (1.29558 iter/s, 30.8743s/40 iters), loss = 1.93988
I1027 06:49:09.630128 37958 solver.cpp:240]     Train net output #0: loss = 1.93988 (* 1 = 1.93988 loss)
I1027 06:49:09.630146 37958 sgd_solver.cpp:105] Iteration 64280, lr = 0.00621882
I1027 06:49:40.431825 37958 solver.cpp:221] Iteration 64320 (1.29868 iter/s, 30.8005s/40 iters), loss = 1.5481
I1027 06:49:40.432041 37958 solver.cpp:240]     Train net output #0: loss = 1.5481 (* 1 = 1.5481 loss)
I1027 06:49:40.432059 37958 sgd_solver.cpp:105] Iteration 64320, lr = 0.00621647
I1027 06:50:10.891269 37958 solver.cpp:221] Iteration 64360 (1.31328 iter/s, 30.4581s/40 iters), loss = 1.86318
I1027 06:50:10.891451 37958 solver.cpp:240]     Train net output #0: loss = 1.86318 (* 1 = 1.86318 loss)
I1027 06:50:10.891469 37958 sgd_solver.cpp:105] Iteration 64360, lr = 0.00621412
I1027 06:50:41.721062 37958 solver.cpp:221] Iteration 64400 (1.2975 iter/s, 30.8284s/40 iters), loss = 1.71129
I1027 06:50:41.721246 37958 solver.cpp:240]     Train net output #0: loss = 1.71129 (* 1 = 1.71129 loss)
I1027 06:50:41.721262 37958 sgd_solver.cpp:105] Iteration 64400, lr = 0.00621176
I1027 06:51:13.083101 37958 solver.cpp:221] Iteration 64440 (1.27548 iter/s, 31.3607s/40 iters), loss = 1.80237
I1027 06:51:13.083278 37958 solver.cpp:240]     Train net output #0: loss = 1.80237 (* 1 = 1.80237 loss)
I1027 06:51:13.083295 37958 sgd_solver.cpp:105] Iteration 64440, lr = 0.00620941
I1027 06:51:43.915343 37958 solver.cpp:221] Iteration 64480 (1.2974 iter/s, 30.8309s/40 iters), loss = 1.6388
I1027 06:51:43.915522 37958 solver.cpp:240]     Train net output #0: loss = 1.6388 (* 1 = 1.6388 loss)
I1027 06:51:43.915539 37958 sgd_solver.cpp:105] Iteration 64480, lr = 0.00620706
I1027 06:51:58.398190 37958 solver.cpp:450] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_64500.caffemodel
I1027 06:51:58.431171 37958 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_64500.solverstate
I1027 06:51:58.448984 37958 solver.cpp:333] Iteration 64500, Testing net (#0)
I1027 06:52:29.323565 38010 data_layer.cpp:73] Restarting data prefetching from start.
I1027 06:52:29.530766 37958 solver.cpp:400]     Test net output #0: accuracy_top1 = 0.53964
I1027 06:52:29.530817 37958 solver.cpp:400]     Test net output #1: accuracy_top5 = 0.77924
I1027 06:52:29.530831 37958 solver.cpp:400]     Test net output #2: loss = 2.04363 (* 1 = 2.04363 loss)
I1027 06:52:45.694839 37958 solver.cpp:221] Iteration 64520 (0.64749 iter/s, 61.777s/40 iters), loss = 1.58676
I1027 06:52:45.694901 37958 solver.cpp:240]     Train net output #0: loss = 1.58676 (* 1 = 1.58676 loss)
I1027 06:52:45.694916 37958 sgd_solver.cpp:105] Iteration 64520, lr = 0.00620471
I1027 06:53:16.538455 37958 solver.cpp:221] Iteration 64560 (1.29692 iter/s, 30.8424s/40 iters), loss = 1.72315
I1027 06:53:16.538638 37958 solver.cpp:240]     Train net output #0: loss = 1.72315 (* 1 = 1.72315 loss)
I1027 06:53:16.538655 37958 sgd_solver.cpp:105] Iteration 64560, lr = 0.00620235
I1027 06:53:47.663614 37958 solver.cpp:221] Iteration 64600 (1.28519 iter/s, 31.1238s/40 iters), loss = 1.94129
I1027 06:53:47.663794 37958 solver.cpp:240]     Train net output #0: loss = 1.94129 (* 1 = 1.94129 loss)
I1027 06:53:47.663810 37958 sgd_solver.cpp:105] Iteration 64600, lr = 0.0062
I1027 06:54:18.841823 37958 solver.cpp:221] Iteration 64640 (1.283 iter/s, 31.1768s/40 iters), loss = 1.68738
I1027 06:54:18.842047 37958 solver.cpp:240]     Train net output #0: loss = 1.68738 (* 1 = 1.68738 loss)
I1027 06:54:18.842077 37958 sgd_solver.cpp:105] Iteration 64640, lr = 0.00619765
I1027 06:54:52.230667 37958 solver.cpp:221] Iteration 64680 (1.19806 iter/s, 33.3874s/40 iters), loss = 2.23332
I1027 06:54:52.230901 37958 solver.cpp:240]     Train net output #0: loss = 2.23332 (* 1 = 2.23332 loss)
I1027 06:54:52.230923 37958 sgd_solver.cpp:105] Iteration 64680, lr = 0.00619529
I1027 06:55:23.022893 37958 solver.cpp:221] Iteration 64720 (1.29909 iter/s, 30.7908s/40 iters), loss = 1.70021
I1027 06:55:23.023075 37958 solver.cpp:240]     Train net output #0: loss = 1.70021 (* 1 = 1.70021 loss)
I1027 06:55:23.023092 37958 sgd_solver.cpp:105] Iteration 64720, lr = 0.00619294
I1027 06:55:55.047425 37958 solver.cpp:221] Iteration 64760 (1.2491 iter/s, 32.0231s/40 iters), loss = 1.9562
I1027 06:55:55.047612 37958 solver.cpp:240]     Train net output #0: loss = 1.9562 (* 1 = 1.9562 loss)
I1027 06:55:55.047626 37958 sgd_solver.cpp:105] Iteration 64760, lr = 0.00619059
*** Aborted at 1509101760 (unix time) try "date -d @1509101760" if you are using GNU date ***
PC: @     0x7f22dc657f7d __lll_lock_wait
*** SIGTERM (@0x3ed00000df1) received by PID 37958 (TID 0x7f22ef6d0740) from PID 3569; stack trace: ***
    @     0x7f22dc659130 (unknown)
    @     0x7f22dc657f7d __lll_lock_wait
    @     0x7f22dc653d4d _L_lock_840
    @     0x7f22dc653c6a __GI___pthread_mutex_lock
    @     0x7f22ebd4bb40 (unknown)
    @     0x7f22ebd2ccd3 (unknown)
    @     0x7f22ebd60c5c (unknown)
    @     0x7f22ebc3aca5 (unknown)
    @     0x7f22ebaeb3d0 (unknown)
    @     0x7f22eea16a07 (unknown)
    @     0x7f22ee94628d (unknown)
    @     0x7f22ee9d96df (unknown)
    @     0x7f22ee982085 (unknown)
    @     0x7f22ee9821d1 (unknown)
    @     0x7f22ee85d0ba (unknown)
    @     0x7f22ee85d8df (unknown)
    @     0x7f22ee9ad5f3 (unknown)
    @           0x40adef train()
    @           0x4082ec main
    @     0x7f22dc2aaaf5 __libc_start_main
    @           0x408bf5 (unknown)
nohup: ignoring input
I1027 10:01:59.363729 40837 caffe.cpp:218] Using GPUs 0, 1, 2, 3
I1027 10:01:59.364524 40837 caffe.cpp:223] GPU 0: Tesla P40
I1027 10:01:59.364938 40837 caffe.cpp:223] GPU 1: Tesla P40
I1027 10:01:59.365340 40837 caffe.cpp:223] GPU 2: Tesla P40
I1027 10:01:59.365725 40837 caffe.cpp:223] GPU 3: Tesla P40
I1027 10:02:00.050009 40837 solver.cpp:44] Initializing solver from parameters: 
test_iter: 500
test_interval: 500
base_lr: 0.01
display: 40
max_iter: 170000
lr_policy: "poly"
power: 1.2
momentum: 0.9
weight_decay: 0.0002
snapshot: 1000
snapshot_prefix: "SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20"
solver_mode: GPU
device_id: 0
random_seed: 42
net: "SqueezeNet/SqueezeNet_v1.1/train_val_inq_0.prototxt"
train_state {
  level: 0
  stage: ""
}
I1027 10:02:00.050431 40837 solver.cpp:87] Creating training net from net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_0.prototxt
I1027 10:02:00.052415 40837 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1027 10:02:00.052484 40837 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top1
I1027 10:02:00.052497 40837 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top5
I1027 10:02:00.053190 40837 net.cpp:51] Initializing net from parameters: 
name: "SqueezeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/data/caffe-imagenet/ilsvrc12_train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "INQConvolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "fire3/concat"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire4/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool3"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "fire5/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire4/concat"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "fire5/concat"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire6/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool5"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "fire9/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire8/concat"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "INQConvolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "pool10"
  bottom: "label"
  top: "loss"
}
I1027 10:02:00.053627 40837 layer_factory.hpp:77] Creating layer data
I1027 10:02:00.053799 40837 db_lmdb.cpp:35] Opened lmdb /home/data/caffe-imagenet/ilsvrc12_train_lmdb
I1027 10:02:00.053855 40837 net.cpp:84] Creating Layer data
I1027 10:02:00.053869 40837 net.cpp:387] data -> data
I1027 10:02:00.053903 40837 net.cpp:387] data -> label
I1027 10:02:00.055747 40837 data_layer.cpp:45] output data size: 128,3,227,227
I1027 10:02:00.261940 40837 net.cpp:127] Setting up data
I1027 10:02:00.261994 40837 net.cpp:136] Top shape: 128 3 227 227 (19787136)
I1027 10:02:00.262003 40837 net.cpp:136] Top shape: 128 (128)
I1027 10:02:00.262014 40837 net.cpp:144] Memory required for data: 79149056
I1027 10:02:00.262032 40837 layer_factory.hpp:77] Creating layer conv1
I1027 10:02:00.262059 40837 net.cpp:84] Creating Layer conv1
I1027 10:02:00.262073 40837 net.cpp:413] conv1 <- data
I1027 10:02:00.262094 40837 net.cpp:387] conv1 -> conv1
I1027 10:02:00.265209 40837 net.cpp:127] Setting up conv1
I1027 10:02:00.265231 40837 net.cpp:136] Top shape: 128 64 113 113 (104603648)
I1027 10:02:00.265238 40837 net.cpp:144] Memory required for data: 497563648
I1027 10:02:00.265259 40837 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1027 10:02:00.265272 40837 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1027 10:02:00.265285 40837 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1027 10:02:00.265293 40837 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1027 10:02:00.265305 40837 layer_factory.hpp:77] Creating layer relu_conv1
I1027 10:02:00.265322 40837 net.cpp:84] Creating Layer relu_conv1
I1027 10:02:00.265329 40837 net.cpp:413] relu_conv1 <- conv1
I1027 10:02:00.265338 40837 net.cpp:374] relu_conv1 -> conv1 (in-place)
I1027 10:02:00.652735 40837 net.cpp:127] Setting up relu_conv1
I1027 10:02:00.652798 40837 net.cpp:136] Top shape: 128 64 113 113 (104603648)
I1027 10:02:00.652806 40837 net.cpp:144] Memory required for data: 915978240
I1027 10:02:00.652837 40837 layer_factory.hpp:77] Creating layer pool1
I1027 10:02:00.652874 40837 net.cpp:84] Creating Layer pool1
I1027 10:02:00.652895 40837 net.cpp:413] pool1 <- conv1
I1027 10:02:00.652916 40837 net.cpp:387] pool1 -> pool1
I1027 10:02:00.653070 40837 net.cpp:127] Setting up pool1
I1027 10:02:00.653082 40837 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 10:02:00.653089 40837 net.cpp:144] Memory required for data: 1018738688
I1027 10:02:00.653128 40837 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I1027 10:02:00.653163 40837 net.cpp:84] Creating Layer fire2/squeeze1x1
I1027 10:02:00.653172 40837 net.cpp:413] fire2/squeeze1x1 <- pool1
I1027 10:02:00.653190 40837 net.cpp:387] fire2/squeeze1x1 -> fire2/squeeze1x1
I1027 10:02:00.655244 40837 net.cpp:127] Setting up fire2/squeeze1x1
I1027 10:02:00.655267 40837 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1027 10:02:00.655273 40837 net.cpp:144] Memory required for data: 1044428800
I1027 10:02:00.655285 40837 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1027 10:02:00.655303 40837 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1027 10:02:00.655313 40837 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1027 10:02:00.655319 40837 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1027 10:02:00.655333 40837 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I1027 10:02:00.655349 40837 net.cpp:84] Creating Layer fire2/relu_squeeze1x1
I1027 10:02:00.655355 40837 net.cpp:413] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I1027 10:02:00.655364 40837 net.cpp:374] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I1027 10:02:00.656847 40837 net.cpp:127] Setting up fire2/relu_squeeze1x1
I1027 10:02:00.656867 40837 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1027 10:02:00.656874 40837 net.cpp:144] Memory required for data: 1070118912
I1027 10:02:00.656882 40837 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1027 10:02:00.656894 40837 net.cpp:84] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1027 10:02:00.656903 40837 net.cpp:413] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I1027 10:02:00.656910 40837 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1027 10:02:00.656922 40837 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1027 10:02:00.656989 40837 net.cpp:127] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1027 10:02:00.657001 40837 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1027 10:02:00.657007 40837 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1027 10:02:00.657012 40837 net.cpp:144] Memory required for data: 1121499136
I1027 10:02:00.657017 40837 layer_factory.hpp:77] Creating layer fire2/expand1x1
I1027 10:02:00.657028 40837 net.cpp:84] Creating Layer fire2/expand1x1
I1027 10:02:00.657037 40837 net.cpp:413] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1027 10:02:00.657047 40837 net.cpp:387] fire2/expand1x1 -> fire2/expand1x1
I1027 10:02:00.657388 40837 net.cpp:127] Setting up fire2/expand1x1
I1027 10:02:00.657402 40837 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 10:02:00.657408 40837 net.cpp:144] Memory required for data: 1224259584
I1027 10:02:00.657419 40837 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1027 10:02:00.657429 40837 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1027 10:02:00.657438 40837 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1027 10:02:00.657444 40837 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1027 10:02:00.657449 40837 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I1027 10:02:00.657470 40837 net.cpp:84] Creating Layer fire2/relu_expand1x1
I1027 10:02:00.657477 40837 net.cpp:413] fire2/relu_expand1x1 <- fire2/expand1x1
I1027 10:02:00.657485 40837 net.cpp:374] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I1027 10:02:00.657696 40837 net.cpp:127] Setting up fire2/relu_expand1x1
I1027 10:02:00.657708 40837 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 10:02:00.657714 40837 net.cpp:144] Memory required for data: 1327020032
I1027 10:02:00.657721 40837 layer_factory.hpp:77] Creating layer fire2/expand3x3
I1027 10:02:00.657747 40837 net.cpp:84] Creating Layer fire2/expand3x3
I1027 10:02:00.657754 40837 net.cpp:413] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1027 10:02:00.657763 40837 net.cpp:387] fire2/expand3x3 -> fire2/expand3x3
I1027 10:02:00.658215 40837 net.cpp:127] Setting up fire2/expand3x3
I1027 10:02:00.658228 40837 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 10:02:00.658233 40837 net.cpp:144] Memory required for data: 1429780480
I1027 10:02:00.658241 40837 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1027 10:02:00.658246 40837 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1027 10:02:00.658252 40837 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1027 10:02:00.658258 40837 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1027 10:02:00.658280 40837 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I1027 10:02:00.658293 40837 net.cpp:84] Creating Layer fire2/relu_expand3x3
I1027 10:02:00.658305 40837 net.cpp:413] fire2/relu_expand3x3 <- fire2/expand3x3
I1027 10:02:00.658313 40837 net.cpp:374] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I1027 10:02:00.658555 40837 net.cpp:127] Setting up fire2/relu_expand3x3
I1027 10:02:00.658569 40837 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 10:02:00.658576 40837 net.cpp:144] Memory required for data: 1532540928
I1027 10:02:00.658581 40837 layer_factory.hpp:77] Creating layer fire2/concat
I1027 10:02:00.658603 40837 net.cpp:84] Creating Layer fire2/concat
I1027 10:02:00.658614 40837 net.cpp:413] fire2/concat <- fire2/expand1x1
I1027 10:02:00.658620 40837 net.cpp:413] fire2/concat <- fire2/expand3x3
I1027 10:02:00.658627 40837 net.cpp:387] fire2/concat -> fire2/concat
I1027 10:02:00.658687 40837 net.cpp:127] Setting up fire2/concat
I1027 10:02:00.658699 40837 net.cpp:136] Top shape: 128 128 56 56 (51380224)
I1027 10:02:00.658704 40837 net.cpp:144] Memory required for data: 1738061824
I1027 10:02:00.658718 40837 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I1027 10:02:00.658730 40837 net.cpp:84] Creating Layer fire3/squeeze1x1
I1027 10:02:00.658735 40837 net.cpp:413] fire3/squeeze1x1 <- fire2/concat
I1027 10:02:00.658742 40837 net.cpp:387] fire3/squeeze1x1 -> fire3/squeeze1x1
I1027 10:02:00.659096 40837 net.cpp:127] Setting up fire3/squeeze1x1
I1027 10:02:00.659109 40837 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1027 10:02:00.659114 40837 net.cpp:144] Memory required for data: 1763751936
I1027 10:02:00.659126 40837 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1027 10:02:00.659133 40837 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1027 10:02:00.659140 40837 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1027 10:02:00.659147 40837 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1027 10:02:00.659152 40837 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I1027 10:02:00.659165 40837 net.cpp:84] Creating Layer fire3/relu_squeeze1x1
I1027 10:02:00.659171 40837 net.cpp:413] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I1027 10:02:00.659179 40837 net.cpp:374] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I1027 10:02:00.660557 40837 net.cpp:127] Setting up fire3/relu_squeeze1x1
I1027 10:02:00.660578 40837 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1027 10:02:00.660583 40837 net.cpp:144] Memory required for data: 1789442048
I1027 10:02:00.660599 40837 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1027 10:02:00.660609 40837 net.cpp:84] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1027 10:02:00.660614 40837 net.cpp:413] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I1027 10:02:00.660625 40837 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1027 10:02:00.660635 40837 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1027 10:02:00.660720 40837 net.cpp:127] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1027 10:02:00.660734 40837 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1027 10:02:00.660742 40837 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1027 10:02:00.660746 40837 net.cpp:144] Memory required for data: 1840822272
I1027 10:02:00.660751 40837 layer_factory.hpp:77] Creating layer fire3/expand1x1
I1027 10:02:00.660776 40837 net.cpp:84] Creating Layer fire3/expand1x1
I1027 10:02:00.660782 40837 net.cpp:413] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1027 10:02:00.660791 40837 net.cpp:387] fire3/expand1x1 -> fire3/expand1x1
I1027 10:02:00.661157 40837 net.cpp:127] Setting up fire3/expand1x1
I1027 10:02:00.661171 40837 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 10:02:00.661176 40837 net.cpp:144] Memory required for data: 1943582720
I1027 10:02:00.661196 40837 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1027 10:02:00.661207 40837 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1027 10:02:00.661213 40837 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1027 10:02:00.661219 40837 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1027 10:02:00.661223 40837 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I1027 10:02:00.661237 40837 net.cpp:84] Creating Layer fire3/relu_expand1x1
I1027 10:02:00.661244 40837 net.cpp:413] fire3/relu_expand1x1 <- fire3/expand1x1
I1027 10:02:00.661252 40837 net.cpp:374] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I1027 10:02:00.661495 40837 net.cpp:127] Setting up fire3/relu_expand1x1
I1027 10:02:00.661511 40837 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 10:02:00.661516 40837 net.cpp:144] Memory required for data: 2046343168
I1027 10:02:00.661522 40837 layer_factory.hpp:77] Creating layer fire3/expand3x3
I1027 10:02:00.661567 40837 net.cpp:84] Creating Layer fire3/expand3x3
I1027 10:02:00.661576 40837 net.cpp:413] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1027 10:02:00.661583 40837 net.cpp:387] fire3/expand3x3 -> fire3/expand3x3
I1027 10:02:00.662020 40837 net.cpp:127] Setting up fire3/expand3x3
I1027 10:02:00.662034 40837 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 10:02:00.662039 40837 net.cpp:144] Memory required for data: 2149103616
I1027 10:02:00.662046 40837 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1027 10:02:00.662053 40837 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1027 10:02:00.662058 40837 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1027 10:02:00.662067 40837 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1027 10:02:00.662073 40837 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I1027 10:02:00.662082 40837 net.cpp:84] Creating Layer fire3/relu_expand3x3
I1027 10:02:00.662087 40837 net.cpp:413] fire3/relu_expand3x3 <- fire3/expand3x3
I1027 10:02:00.662094 40837 net.cpp:374] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I1027 10:02:00.662323 40837 net.cpp:127] Setting up fire3/relu_expand3x3
I1027 10:02:00.662338 40837 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 10:02:00.662344 40837 net.cpp:144] Memory required for data: 2251864064
I1027 10:02:00.662350 40837 layer_factory.hpp:77] Creating layer fire3/concat
I1027 10:02:00.662360 40837 net.cpp:84] Creating Layer fire3/concat
I1027 10:02:00.662377 40837 net.cpp:413] fire3/concat <- fire3/expand1x1
I1027 10:02:00.662384 40837 net.cpp:413] fire3/concat <- fire3/expand3x3
I1027 10:02:00.662391 40837 net.cpp:387] fire3/concat -> fire3/concat
I1027 10:02:00.662425 40837 net.cpp:127] Setting up fire3/concat
I1027 10:02:00.662433 40837 net.cpp:136] Top shape: 128 128 56 56 (51380224)
I1027 10:02:00.662437 40837 net.cpp:144] Memory required for data: 2457384960
I1027 10:02:00.662457 40837 layer_factory.hpp:77] Creating layer pool3
I1027 10:02:00.662467 40837 net.cpp:84] Creating Layer pool3
I1027 10:02:00.662472 40837 net.cpp:413] pool3 <- fire3/concat
I1027 10:02:00.662482 40837 net.cpp:387] pool3 -> pool3
I1027 10:02:00.662529 40837 net.cpp:127] Setting up pool3
I1027 10:02:00.662539 40837 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 10:02:00.662545 40837 net.cpp:144] Memory required for data: 2508765184
I1027 10:02:00.662550 40837 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I1027 10:02:00.662578 40837 net.cpp:84] Creating Layer fire4/squeeze1x1
I1027 10:02:00.662585 40837 net.cpp:413] fire4/squeeze1x1 <- pool3
I1027 10:02:00.662593 40837 net.cpp:387] fire4/squeeze1x1 -> fire4/squeeze1x1
I1027 10:02:00.663033 40837 net.cpp:127] Setting up fire4/squeeze1x1
I1027 10:02:00.663045 40837 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1027 10:02:00.663050 40837 net.cpp:144] Memory required for data: 2521610240
I1027 10:02:00.663058 40837 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1027 10:02:00.663064 40837 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1027 10:02:00.663069 40837 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1027 10:02:00.663075 40837 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1027 10:02:00.663080 40837 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I1027 10:02:00.663089 40837 net.cpp:84] Creating Layer fire4/relu_squeeze1x1
I1027 10:02:00.663094 40837 net.cpp:413] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I1027 10:02:00.663101 40837 net.cpp:374] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I1027 10:02:00.663336 40837 net.cpp:127] Setting up fire4/relu_squeeze1x1
I1027 10:02:00.663352 40837 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1027 10:02:00.663357 40837 net.cpp:144] Memory required for data: 2534455296
I1027 10:02:00.663363 40837 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1027 10:02:00.663380 40837 net.cpp:84] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1027 10:02:00.663386 40837 net.cpp:413] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I1027 10:02:00.663393 40837 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1027 10:02:00.663406 40837 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1027 10:02:00.663462 40837 net.cpp:127] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1027 10:02:00.663472 40837 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1027 10:02:00.663478 40837 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1027 10:02:00.663483 40837 net.cpp:144] Memory required for data: 2560145408
I1027 10:02:00.663488 40837 layer_factory.hpp:77] Creating layer fire4/expand1x1
I1027 10:02:00.663509 40837 net.cpp:84] Creating Layer fire4/expand1x1
I1027 10:02:00.663517 40837 net.cpp:413] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1027 10:02:00.663527 40837 net.cpp:387] fire4/expand1x1 -> fire4/expand1x1
I1027 10:02:00.663878 40837 net.cpp:127] Setting up fire4/expand1x1
I1027 10:02:00.663892 40837 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 10:02:00.663897 40837 net.cpp:144] Memory required for data: 2611525632
I1027 10:02:00.663908 40837 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1027 10:02:00.663920 40837 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1027 10:02:00.663928 40837 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1027 10:02:00.663934 40837 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1027 10:02:00.663949 40837 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I1027 10:02:00.663957 40837 net.cpp:84] Creating Layer fire4/relu_expand1x1
I1027 10:02:00.663976 40837 net.cpp:413] fire4/relu_expand1x1 <- fire4/expand1x1
I1027 10:02:00.663985 40837 net.cpp:374] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I1027 10:02:00.665354 40837 net.cpp:127] Setting up fire4/relu_expand1x1
I1027 10:02:00.665376 40837 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 10:02:00.665381 40837 net.cpp:144] Memory required for data: 2662905856
I1027 10:02:00.665405 40837 layer_factory.hpp:77] Creating layer fire4/expand3x3
I1027 10:02:00.665421 40837 net.cpp:84] Creating Layer fire4/expand3x3
I1027 10:02:00.665428 40837 net.cpp:413] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1027 10:02:00.665439 40837 net.cpp:387] fire4/expand3x3 -> fire4/expand3x3
I1027 10:02:00.667556 40837 net.cpp:127] Setting up fire4/expand3x3
I1027 10:02:00.667588 40837 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 10:02:00.667598 40837 net.cpp:144] Memory required for data: 2714286080
I1027 10:02:00.667606 40837 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1027 10:02:00.667614 40837 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1027 10:02:00.667620 40837 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1027 10:02:00.667628 40837 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1027 10:02:00.667632 40837 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I1027 10:02:00.667654 40837 net.cpp:84] Creating Layer fire4/relu_expand3x3
I1027 10:02:00.667663 40837 net.cpp:413] fire4/relu_expand3x3 <- fire4/expand3x3
I1027 10:02:00.667675 40837 net.cpp:374] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I1027 10:02:00.667913 40837 net.cpp:127] Setting up fire4/relu_expand3x3
I1027 10:02:00.667928 40837 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 10:02:00.667933 40837 net.cpp:144] Memory required for data: 2765666304
I1027 10:02:00.667939 40837 layer_factory.hpp:77] Creating layer fire4/concat
I1027 10:02:00.667956 40837 net.cpp:84] Creating Layer fire4/concat
I1027 10:02:00.667961 40837 net.cpp:413] fire4/concat <- fire4/expand1x1
I1027 10:02:00.667968 40837 net.cpp:413] fire4/concat <- fire4/expand3x3
I1027 10:02:00.667978 40837 net.cpp:387] fire4/concat -> fire4/concat
I1027 10:02:00.668010 40837 net.cpp:127] Setting up fire4/concat
I1027 10:02:00.668020 40837 net.cpp:136] Top shape: 128 256 28 28 (25690112)
I1027 10:02:00.668025 40837 net.cpp:144] Memory required for data: 2868426752
I1027 10:02:00.668041 40837 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I1027 10:02:00.668054 40837 net.cpp:84] Creating Layer fire5/squeeze1x1
I1027 10:02:00.668062 40837 net.cpp:413] fire5/squeeze1x1 <- fire4/concat
I1027 10:02:00.668071 40837 net.cpp:387] fire5/squeeze1x1 -> fire5/squeeze1x1
I1027 10:02:00.668493 40837 net.cpp:127] Setting up fire5/squeeze1x1
I1027 10:02:00.668509 40837 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1027 10:02:00.668514 40837 net.cpp:144] Memory required for data: 2881271808
I1027 10:02:00.668532 40837 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1027 10:02:00.668540 40837 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1027 10:02:00.668546 40837 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1027 10:02:00.668553 40837 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1027 10:02:00.668558 40837 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I1027 10:02:00.668576 40837 net.cpp:84] Creating Layer fire5/relu_squeeze1x1
I1027 10:02:00.668583 40837 net.cpp:413] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I1027 10:02:00.668591 40837 net.cpp:374] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I1027 10:02:00.668818 40837 net.cpp:127] Setting up fire5/relu_squeeze1x1
I1027 10:02:00.668834 40837 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1027 10:02:00.668840 40837 net.cpp:144] Memory required for data: 2894116864
I1027 10:02:00.668845 40837 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1027 10:02:00.668871 40837 net.cpp:84] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1027 10:02:00.668877 40837 net.cpp:413] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I1027 10:02:00.668885 40837 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1027 10:02:00.668903 40837 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1027 10:02:00.668954 40837 net.cpp:127] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1027 10:02:00.668964 40837 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1027 10:02:00.668970 40837 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1027 10:02:00.668975 40837 net.cpp:144] Memory required for data: 2919806976
I1027 10:02:00.668992 40837 layer_factory.hpp:77] Creating layer fire5/expand1x1
I1027 10:02:00.669008 40837 net.cpp:84] Creating Layer fire5/expand1x1
I1027 10:02:00.669014 40837 net.cpp:413] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1027 10:02:00.669023 40837 net.cpp:387] fire5/expand1x1 -> fire5/expand1x1
I1027 10:02:00.669378 40837 net.cpp:127] Setting up fire5/expand1x1
I1027 10:02:00.669391 40837 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 10:02:00.669396 40837 net.cpp:144] Memory required for data: 2971187200
I1027 10:02:00.669407 40837 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1027 10:02:00.669414 40837 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1027 10:02:00.669420 40837 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1027 10:02:00.669425 40837 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1027 10:02:00.669431 40837 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I1027 10:02:00.669438 40837 net.cpp:84] Creating Layer fire5/relu_expand1x1
I1027 10:02:00.669451 40837 net.cpp:413] fire5/relu_expand1x1 <- fire5/expand1x1
I1027 10:02:00.669459 40837 net.cpp:374] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I1027 10:02:00.669693 40837 net.cpp:127] Setting up fire5/relu_expand1x1
I1027 10:02:00.669708 40837 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 10:02:00.669713 40837 net.cpp:144] Memory required for data: 3022567424
I1027 10:02:00.669718 40837 layer_factory.hpp:77] Creating layer fire5/expand3x3
I1027 10:02:00.669740 40837 net.cpp:84] Creating Layer fire5/expand3x3
I1027 10:02:00.669749 40837 net.cpp:413] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1027 10:02:00.669759 40837 net.cpp:387] fire5/expand3x3 -> fire5/expand3x3
I1027 10:02:00.670397 40837 net.cpp:127] Setting up fire5/expand3x3
I1027 10:02:00.670411 40837 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 10:02:00.670419 40837 net.cpp:144] Memory required for data: 3073947648
I1027 10:02:00.670426 40837 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1027 10:02:00.670435 40837 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1027 10:02:00.670441 40837 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1027 10:02:00.670446 40837 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1027 10:02:00.670451 40837 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I1027 10:02:00.670457 40837 net.cpp:84] Creating Layer fire5/relu_expand3x3
I1027 10:02:00.670464 40837 net.cpp:413] fire5/relu_expand3x3 <- fire5/expand3x3
I1027 10:02:00.670475 40837 net.cpp:374] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I1027 10:02:00.671883 40837 net.cpp:127] Setting up fire5/relu_expand3x3
I1027 10:02:00.671905 40837 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 10:02:00.671910 40837 net.cpp:144] Memory required for data: 3125327872
I1027 10:02:00.671926 40837 layer_factory.hpp:77] Creating layer fire5/concat
I1027 10:02:00.671950 40837 net.cpp:84] Creating Layer fire5/concat
I1027 10:02:00.671957 40837 net.cpp:413] fire5/concat <- fire5/expand1x1
I1027 10:02:00.671963 40837 net.cpp:413] fire5/concat <- fire5/expand3x3
I1027 10:02:00.671972 40837 net.cpp:387] fire5/concat -> fire5/concat
I1027 10:02:00.672008 40837 net.cpp:127] Setting up fire5/concat
I1027 10:02:00.672024 40837 net.cpp:136] Top shape: 128 256 28 28 (25690112)
I1027 10:02:00.672029 40837 net.cpp:144] Memory required for data: 3228088320
I1027 10:02:00.672034 40837 layer_factory.hpp:77] Creating layer pool5
I1027 10:02:00.672050 40837 net.cpp:84] Creating Layer pool5
I1027 10:02:00.672057 40837 net.cpp:413] pool5 <- fire5/concat
I1027 10:02:00.672065 40837 net.cpp:387] pool5 -> pool5
I1027 10:02:00.672114 40837 net.cpp:127] Setting up pool5
I1027 10:02:00.672124 40837 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 10:02:00.672128 40837 net.cpp:144] Memory required for data: 3253778432
I1027 10:02:00.672133 40837 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I1027 10:02:00.672145 40837 net.cpp:84] Creating Layer fire6/squeeze1x1
I1027 10:02:00.672152 40837 net.cpp:413] fire6/squeeze1x1 <- pool5
I1027 10:02:00.672161 40837 net.cpp:387] fire6/squeeze1x1 -> fire6/squeeze1x1
I1027 10:02:00.672667 40837 net.cpp:127] Setting up fire6/squeeze1x1
I1027 10:02:00.672682 40837 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1027 10:02:00.672686 40837 net.cpp:144] Memory required for data: 3258595328
I1027 10:02:00.672695 40837 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1027 10:02:00.672703 40837 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1027 10:02:00.672708 40837 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1027 10:02:00.672714 40837 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1027 10:02:00.672729 40837 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I1027 10:02:00.672749 40837 net.cpp:84] Creating Layer fire6/relu_squeeze1x1
I1027 10:02:00.672760 40837 net.cpp:413] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I1027 10:02:00.672767 40837 net.cpp:374] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I1027 10:02:00.672986 40837 net.cpp:127] Setting up fire6/relu_squeeze1x1
I1027 10:02:00.672999 40837 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1027 10:02:00.673005 40837 net.cpp:144] Memory required for data: 3263412224
I1027 10:02:00.673010 40837 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1027 10:02:00.673017 40837 net.cpp:84] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1027 10:02:00.673024 40837 net.cpp:413] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I1027 10:02:00.673033 40837 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1027 10:02:00.673043 40837 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1027 10:02:00.673264 40837 net.cpp:127] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1027 10:02:00.673277 40837 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1027 10:02:00.673303 40837 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1027 10:02:00.673310 40837 net.cpp:144] Memory required for data: 3273046016
I1027 10:02:00.673316 40837 layer_factory.hpp:77] Creating layer fire6/expand1x1
I1027 10:02:00.673327 40837 net.cpp:84] Creating Layer fire6/expand1x1
I1027 10:02:00.673333 40837 net.cpp:413] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1027 10:02:00.673343 40837 net.cpp:387] fire6/expand1x1 -> fire6/expand1x1
I1027 10:02:00.673771 40837 net.cpp:127] Setting up fire6/expand1x1
I1027 10:02:00.673784 40837 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1027 10:02:00.673789 40837 net.cpp:144] Memory required for data: 3292313600
I1027 10:02:00.673796 40837 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1027 10:02:00.673804 40837 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1027 10:02:00.673823 40837 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1027 10:02:00.673830 40837 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1027 10:02:00.673835 40837 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I1027 10:02:00.673846 40837 net.cpp:84] Creating Layer fire6/relu_expand1x1
I1027 10:02:00.673861 40837 net.cpp:413] fire6/relu_expand1x1 <- fire6/expand1x1
I1027 10:02:00.673872 40837 net.cpp:374] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I1027 10:02:00.674083 40837 net.cpp:127] Setting up fire6/relu_expand1x1
I1027 10:02:00.674095 40837 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1027 10:02:00.674101 40837 net.cpp:144] Memory required for data: 3311581184
I1027 10:02:00.674118 40837 layer_factory.hpp:77] Creating layer fire6/expand3x3
I1027 10:02:00.674139 40837 net.cpp:84] Creating Layer fire6/expand3x3
I1027 10:02:00.674146 40837 net.cpp:413] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1027 10:02:00.674156 40837 net.cpp:387] fire6/expand3x3 -> fire6/expand3x3
I1027 10:02:00.676592 40837 net.cpp:127] Setting up fire6/expand3x3
I1027 10:02:00.676614 40837 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1027 10:02:00.676622 40837 net.cpp:144] Memory required for data: 3330848768
I1027 10:02:00.676630 40837 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1027 10:02:00.676638 40837 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1027 10:02:00.676645 40837 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1027 10:02:00.676650 40837 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1027 10:02:00.676654 40837 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I1027 10:02:00.676663 40837 net.cpp:84] Creating Layer fire6/relu_expand3x3
I1027 10:02:00.676678 40837 net.cpp:413] fire6/relu_expand3x3 <- fire6/expand3x3
I1027 10:02:00.676686 40837 net.cpp:374] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I1027 10:02:00.676942 40837 net.cpp:127] Setting up fire6/relu_expand3x3
I1027 10:02:00.676957 40837 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1027 10:02:00.676964 40837 net.cpp:144] Memory required for data: 3350116352
I1027 10:02:00.676968 40837 layer_factory.hpp:77] Creating layer fire6/concat
I1027 10:02:00.676976 40837 net.cpp:84] Creating Layer fire6/concat
I1027 10:02:00.676983 40837 net.cpp:413] fire6/concat <- fire6/expand1x1
I1027 10:02:00.676990 40837 net.cpp:413] fire6/concat <- fire6/expand3x3
I1027 10:02:00.676998 40837 net.cpp:387] fire6/concat -> fire6/concat
I1027 10:02:00.677033 40837 net.cpp:127] Setting up fire6/concat
I1027 10:02:00.677045 40837 net.cpp:136] Top shape: 128 384 14 14 (9633792)
I1027 10:02:00.677050 40837 net.cpp:144] Memory required for data: 3388651520
I1027 10:02:00.677078 40837 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I1027 10:02:00.677099 40837 net.cpp:84] Creating Layer fire7/squeeze1x1
I1027 10:02:00.677119 40837 net.cpp:413] fire7/squeeze1x1 <- fire6/concat
I1027 10:02:00.677129 40837 net.cpp:387] fire7/squeeze1x1 -> fire7/squeeze1x1
I1027 10:02:00.677645 40837 net.cpp:127] Setting up fire7/squeeze1x1
I1027 10:02:00.677660 40837 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1027 10:02:00.677665 40837 net.cpp:144] Memory required for data: 3393468416
I1027 10:02:00.677681 40837 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1027 10:02:00.677705 40837 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1027 10:02:00.677712 40837 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1027 10:02:00.677718 40837 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1027 10:02:00.677724 40837 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I1027 10:02:00.677731 40837 net.cpp:84] Creating Layer fire7/relu_squeeze1x1
I1027 10:02:00.677754 40837 net.cpp:413] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I1027 10:02:00.677762 40837 net.cpp:374] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I1027 10:02:00.679142 40837 net.cpp:127] Setting up fire7/relu_squeeze1x1
I1027 10:02:00.679162 40837 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1027 10:02:00.679170 40837 net.cpp:144] Memory required for data: 3398285312
I1027 10:02:00.679177 40837 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1027 10:02:00.679184 40837 net.cpp:84] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1027 10:02:00.679189 40837 net.cpp:413] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I1027 10:02:00.679199 40837 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1027 10:02:00.679209 40837 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1027 10:02:00.679263 40837 net.cpp:127] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1027 10:02:00.679273 40837 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1027 10:02:00.679280 40837 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1027 10:02:00.679285 40837 net.cpp:144] Memory required for data: 3407919104
I1027 10:02:00.679289 40837 layer_factory.hpp:77] Creating layer fire7/expand1x1
I1027 10:02:00.679306 40837 net.cpp:84] Creating Layer fire7/expand1x1
I1027 10:02:00.679313 40837 net.cpp:413] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1027 10:02:00.679322 40837 net.cpp:387] fire7/expand1x1 -> fire7/expand1x1
I1027 10:02:00.679731 40837 net.cpp:127] Setting up fire7/expand1x1
I1027 10:02:00.679744 40837 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1027 10:02:00.679749 40837 net.cpp:144] Memory required for data: 3427186688
I1027 10:02:00.679757 40837 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1027 10:02:00.679775 40837 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1027 10:02:00.679782 40837 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1027 10:02:00.679787 40837 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1027 10:02:00.679803 40837 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I1027 10:02:00.679821 40837 net.cpp:84] Creating Layer fire7/relu_expand1x1
I1027 10:02:00.679828 40837 net.cpp:413] fire7/relu_expand1x1 <- fire7/expand1x1
I1027 10:02:00.679836 40837 net.cpp:374] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I1027 10:02:00.680045 40837 net.cpp:127] Setting up fire7/relu_expand1x1
I1027 10:02:00.680058 40837 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1027 10:02:00.680063 40837 net.cpp:144] Memory required for data: 3446454272
I1027 10:02:00.680068 40837 layer_factory.hpp:77] Creating layer fire7/expand3x3
I1027 10:02:00.680081 40837 net.cpp:84] Creating Layer fire7/expand3x3
I1027 10:02:00.680088 40837 net.cpp:413] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1027 10:02:00.680095 40837 net.cpp:387] fire7/expand3x3 -> fire7/expand3x3
I1027 10:02:00.681089 40837 net.cpp:127] Setting up fire7/expand3x3
I1027 10:02:00.681103 40837 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1027 10:02:00.681108 40837 net.cpp:144] Memory required for data: 3465721856
I1027 10:02:00.681116 40837 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1027 10:02:00.681123 40837 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1027 10:02:00.681128 40837 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1027 10:02:00.681133 40837 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1027 10:02:00.681138 40837 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I1027 10:02:00.681147 40837 net.cpp:84] Creating Layer fire7/relu_expand3x3
I1027 10:02:00.681154 40837 net.cpp:413] fire7/relu_expand3x3 <- fire7/expand3x3
I1027 10:02:00.681172 40837 net.cpp:374] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I1027 10:02:00.681393 40837 net.cpp:127] Setting up fire7/relu_expand3x3
I1027 10:02:00.681411 40837 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1027 10:02:00.681418 40837 net.cpp:144] Memory required for data: 3484989440
I1027 10:02:00.681433 40837 layer_factory.hpp:77] Creating layer fire7/concat
I1027 10:02:00.681454 40837 net.cpp:84] Creating Layer fire7/concat
I1027 10:02:00.681460 40837 net.cpp:413] fire7/concat <- fire7/expand1x1
I1027 10:02:00.681466 40837 net.cpp:413] fire7/concat <- fire7/expand3x3
I1027 10:02:00.681473 40837 net.cpp:387] fire7/concat -> fire7/concat
I1027 10:02:00.681507 40837 net.cpp:127] Setting up fire7/concat
I1027 10:02:00.681516 40837 net.cpp:136] Top shape: 128 384 14 14 (9633792)
I1027 10:02:00.681521 40837 net.cpp:144] Memory required for data: 3523524608
I1027 10:02:00.681526 40837 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I1027 10:02:00.681536 40837 net.cpp:84] Creating Layer fire8/squeeze1x1
I1027 10:02:00.681541 40837 net.cpp:413] fire8/squeeze1x1 <- fire7/concat
I1027 10:02:00.681550 40837 net.cpp:387] fire8/squeeze1x1 -> fire8/squeeze1x1
I1027 10:02:00.682066 40837 net.cpp:127] Setting up fire8/squeeze1x1
I1027 10:02:00.682078 40837 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1027 10:02:00.682083 40837 net.cpp:144] Memory required for data: 3529947136
I1027 10:02:00.682090 40837 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1027 10:02:00.682097 40837 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1027 10:02:00.682103 40837 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1027 10:02:00.682108 40837 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1027 10:02:00.682113 40837 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I1027 10:02:00.682121 40837 net.cpp:84] Creating Layer fire8/relu_squeeze1x1
I1027 10:02:00.682132 40837 net.cpp:413] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I1027 10:02:00.682138 40837 net.cpp:374] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I1027 10:02:00.683590 40837 net.cpp:127] Setting up fire8/relu_squeeze1x1
I1027 10:02:00.683611 40837 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1027 10:02:00.683617 40837 net.cpp:144] Memory required for data: 3536369664
I1027 10:02:00.683634 40837 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1027 10:02:00.683642 40837 net.cpp:84] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1027 10:02:00.683648 40837 net.cpp:413] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I1027 10:02:00.683668 40837 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1027 10:02:00.683678 40837 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1027 10:02:00.683730 40837 net.cpp:127] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1027 10:02:00.683743 40837 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1027 10:02:00.683748 40837 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1027 10:02:00.683753 40837 net.cpp:144] Memory required for data: 3549214720
I1027 10:02:00.683768 40837 layer_factory.hpp:77] Creating layer fire8/expand1x1
I1027 10:02:00.683785 40837 net.cpp:84] Creating Layer fire8/expand1x1
I1027 10:02:00.683791 40837 net.cpp:413] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1027 10:02:00.683800 40837 net.cpp:387] fire8/expand1x1 -> fire8/expand1x1
I1027 10:02:00.684294 40837 net.cpp:127] Setting up fire8/expand1x1
I1027 10:02:00.684314 40837 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 10:02:00.684320 40837 net.cpp:144] Memory required for data: 3574904832
I1027 10:02:00.684329 40837 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1027 10:02:00.684350 40837 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1027 10:02:00.684355 40837 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1027 10:02:00.684361 40837 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1027 10:02:00.684366 40837 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I1027 10:02:00.684376 40837 net.cpp:84] Creating Layer fire8/relu_expand1x1
I1027 10:02:00.684381 40837 net.cpp:413] fire8/relu_expand1x1 <- fire8/expand1x1
I1027 10:02:00.684388 40837 net.cpp:374] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I1027 10:02:00.684612 40837 net.cpp:127] Setting up fire8/relu_expand1x1
I1027 10:02:00.684631 40837 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 10:02:00.684638 40837 net.cpp:144] Memory required for data: 3600594944
I1027 10:02:00.684643 40837 layer_factory.hpp:77] Creating layer fire8/expand3x3
I1027 10:02:00.684666 40837 net.cpp:84] Creating Layer fire8/expand3x3
I1027 10:02:00.684672 40837 net.cpp:413] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1027 10:02:00.684680 40837 net.cpp:387] fire8/expand3x3 -> fire8/expand3x3
I1027 10:02:00.687598 40837 net.cpp:127] Setting up fire8/expand3x3
I1027 10:02:00.687619 40837 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 10:02:00.687624 40837 net.cpp:144] Memory required for data: 3626285056
I1027 10:02:00.687633 40837 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1027 10:02:00.687639 40837 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1027 10:02:00.687645 40837 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1027 10:02:00.687651 40837 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1027 10:02:00.687655 40837 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I1027 10:02:00.687676 40837 net.cpp:84] Creating Layer fire8/relu_expand3x3
I1027 10:02:00.687691 40837 net.cpp:413] fire8/relu_expand3x3 <- fire8/expand3x3
I1027 10:02:00.687698 40837 net.cpp:374] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I1027 10:02:00.687925 40837 net.cpp:127] Setting up fire8/relu_expand3x3
I1027 10:02:00.687938 40837 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 10:02:00.687943 40837 net.cpp:144] Memory required for data: 3651975168
I1027 10:02:00.687949 40837 layer_factory.hpp:77] Creating layer fire8/concat
I1027 10:02:00.687958 40837 net.cpp:84] Creating Layer fire8/concat
I1027 10:02:00.687963 40837 net.cpp:413] fire8/concat <- fire8/expand1x1
I1027 10:02:00.687970 40837 net.cpp:413] fire8/concat <- fire8/expand3x3
I1027 10:02:00.687976 40837 net.cpp:387] fire8/concat -> fire8/concat
I1027 10:02:00.688012 40837 net.cpp:127] Setting up fire8/concat
I1027 10:02:00.688021 40837 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1027 10:02:00.688026 40837 net.cpp:144] Memory required for data: 3703355392
I1027 10:02:00.688030 40837 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I1027 10:02:00.688056 40837 net.cpp:84] Creating Layer fire9/squeeze1x1
I1027 10:02:00.688076 40837 net.cpp:413] fire9/squeeze1x1 <- fire8/concat
I1027 10:02:00.688084 40837 net.cpp:387] fire9/squeeze1x1 -> fire9/squeeze1x1
I1027 10:02:00.688688 40837 net.cpp:127] Setting up fire9/squeeze1x1
I1027 10:02:00.688701 40837 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1027 10:02:00.688706 40837 net.cpp:144] Memory required for data: 3709777920
I1027 10:02:00.688714 40837 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1027 10:02:00.688719 40837 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1027 10:02:00.688726 40837 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1027 10:02:00.688731 40837 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1027 10:02:00.688736 40837 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I1027 10:02:00.688745 40837 net.cpp:84] Creating Layer fire9/relu_squeeze1x1
I1027 10:02:00.688766 40837 net.cpp:413] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I1027 10:02:00.688773 40837 net.cpp:374] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I1027 10:02:00.688987 40837 net.cpp:127] Setting up fire9/relu_squeeze1x1
I1027 10:02:00.689000 40837 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1027 10:02:00.689005 40837 net.cpp:144] Memory required for data: 3716200448
I1027 10:02:00.689012 40837 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1027 10:02:00.689028 40837 net.cpp:84] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1027 10:02:00.689033 40837 net.cpp:413] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I1027 10:02:00.689040 40837 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1027 10:02:00.689049 40837 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1027 10:02:00.689098 40837 net.cpp:127] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1027 10:02:00.689108 40837 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1027 10:02:00.689115 40837 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1027 10:02:00.689118 40837 net.cpp:144] Memory required for data: 3729045504
I1027 10:02:00.689124 40837 layer_factory.hpp:77] Creating layer fire9/expand1x1
I1027 10:02:00.689134 40837 net.cpp:84] Creating Layer fire9/expand1x1
I1027 10:02:00.689151 40837 net.cpp:413] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1027 10:02:00.689160 40837 net.cpp:387] fire9/expand1x1 -> fire9/expand1x1
I1027 10:02:00.689637 40837 net.cpp:127] Setting up fire9/expand1x1
I1027 10:02:00.689651 40837 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 10:02:00.689656 40837 net.cpp:144] Memory required for data: 3754735616
I1027 10:02:00.689662 40837 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1027 10:02:00.689677 40837 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1027 10:02:00.689685 40837 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1027 10:02:00.689692 40837 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1027 10:02:00.689695 40837 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I1027 10:02:00.689712 40837 net.cpp:84] Creating Layer fire9/relu_expand1x1
I1027 10:02:00.689720 40837 net.cpp:413] fire9/relu_expand1x1 <- fire9/expand1x1
I1027 10:02:00.689726 40837 net.cpp:374] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I1027 10:02:00.691159 40837 net.cpp:127] Setting up fire9/relu_expand1x1
I1027 10:02:00.691187 40837 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 10:02:00.691195 40837 net.cpp:144] Memory required for data: 3780425728
I1027 10:02:00.691200 40837 layer_factory.hpp:77] Creating layer fire9/expand3x3
I1027 10:02:00.691213 40837 net.cpp:84] Creating Layer fire9/expand3x3
I1027 10:02:00.691220 40837 net.cpp:413] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1027 10:02:00.691231 40837 net.cpp:387] fire9/expand3x3 -> fire9/expand3x3
I1027 10:02:00.692750 40837 net.cpp:127] Setting up fire9/expand3x3
I1027 10:02:00.692765 40837 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 10:02:00.692770 40837 net.cpp:144] Memory required for data: 3806115840
I1027 10:02:00.692780 40837 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1027 10:02:00.692785 40837 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1027 10:02:00.692791 40837 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1027 10:02:00.692796 40837 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1027 10:02:00.692802 40837 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I1027 10:02:00.692811 40837 net.cpp:84] Creating Layer fire9/relu_expand3x3
I1027 10:02:00.692829 40837 net.cpp:413] fire9/relu_expand3x3 <- fire9/expand3x3
I1027 10:02:00.692836 40837 net.cpp:374] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I1027 10:02:00.693053 40837 net.cpp:127] Setting up fire9/relu_expand3x3
I1027 10:02:00.693068 40837 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 10:02:00.693073 40837 net.cpp:144] Memory required for data: 3831805952
I1027 10:02:00.693078 40837 layer_factory.hpp:77] Creating layer fire9/concat
I1027 10:02:00.693095 40837 net.cpp:84] Creating Layer fire9/concat
I1027 10:02:00.693102 40837 net.cpp:413] fire9/concat <- fire9/expand1x1
I1027 10:02:00.693109 40837 net.cpp:413] fire9/concat <- fire9/expand3x3
I1027 10:02:00.693115 40837 net.cpp:387] fire9/concat -> fire9/concat
I1027 10:02:00.693155 40837 net.cpp:127] Setting up fire9/concat
I1027 10:02:00.693164 40837 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1027 10:02:00.693169 40837 net.cpp:144] Memory required for data: 3883186176
I1027 10:02:00.693173 40837 layer_factory.hpp:77] Creating layer drop9
I1027 10:02:00.693184 40837 net.cpp:84] Creating Layer drop9
I1027 10:02:00.693189 40837 net.cpp:413] drop9 <- fire9/concat
I1027 10:02:00.693197 40837 net.cpp:374] drop9 -> fire9/concat (in-place)
I1027 10:02:00.693230 40837 net.cpp:127] Setting up drop9
I1027 10:02:00.693239 40837 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1027 10:02:00.693243 40837 net.cpp:144] Memory required for data: 3934566400
I1027 10:02:00.693251 40837 layer_factory.hpp:77] Creating layer conv10
I1027 10:02:00.693265 40837 net.cpp:84] Creating Layer conv10
I1027 10:02:00.693270 40837 net.cpp:413] conv10 <- fire9/concat
I1027 10:02:00.693277 40837 net.cpp:387] conv10 -> conv10
I1027 10:02:00.703115 40837 net.cpp:127] Setting up conv10
I1027 10:02:00.703138 40837 net.cpp:136] Top shape: 128 1000 14 14 (25088000)
I1027 10:02:00.703145 40837 net.cpp:144] Memory required for data: 4034918400
I1027 10:02:00.703152 40837 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1027 10:02:00.703171 40837 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1027 10:02:00.703177 40837 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1027 10:02:00.703183 40837 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1027 10:02:00.703188 40837 layer_factory.hpp:77] Creating layer relu_conv10
I1027 10:02:00.703210 40837 net.cpp:84] Creating Layer relu_conv10
I1027 10:02:00.703217 40837 net.cpp:413] relu_conv10 <- conv10
I1027 10:02:00.703227 40837 net.cpp:374] relu_conv10 -> conv10 (in-place)
I1027 10:02:00.703467 40837 net.cpp:127] Setting up relu_conv10
I1027 10:02:00.703482 40837 net.cpp:136] Top shape: 128 1000 14 14 (25088000)
I1027 10:02:00.703488 40837 net.cpp:144] Memory required for data: 4135270400
I1027 10:02:00.703493 40837 layer_factory.hpp:77] Creating layer pool10
I1027 10:02:00.703502 40837 net.cpp:84] Creating Layer pool10
I1027 10:02:00.703507 40837 net.cpp:413] pool10 <- conv10
I1027 10:02:00.703516 40837 net.cpp:387] pool10 -> pool10
I1027 10:02:00.703758 40837 net.cpp:127] Setting up pool10
I1027 10:02:00.703771 40837 net.cpp:136] Top shape: 128 1000 1 1 (128000)
I1027 10:02:00.703776 40837 net.cpp:144] Memory required for data: 4135782400
I1027 10:02:00.703783 40837 layer_factory.hpp:77] Creating layer loss
I1027 10:02:00.703794 40837 net.cpp:84] Creating Layer loss
I1027 10:02:00.703799 40837 net.cpp:413] loss <- pool10
I1027 10:02:00.703807 40837 net.cpp:413] loss <- label
I1027 10:02:00.703824 40837 net.cpp:387] loss -> loss
I1027 10:02:00.703841 40837 layer_factory.hpp:77] Creating layer loss
I1027 10:02:00.706953 40837 net.cpp:127] Setting up loss
I1027 10:02:00.706974 40837 net.cpp:136] Top shape: (1)
I1027 10:02:00.706979 40837 net.cpp:139]     with loss weight 1
I1027 10:02:00.707010 40837 net.cpp:144] Memory required for data: 4135782404
I1027 10:02:00.707015 40837 net.cpp:205] loss needs backward computation.
I1027 10:02:00.707022 40837 net.cpp:205] pool10 needs backward computation.
I1027 10:02:00.707027 40837 net.cpp:205] relu_conv10 needs backward computation.
I1027 10:02:00.707046 40837 net.cpp:205] conv10 needs backward computation.
I1027 10:02:00.707051 40837 net.cpp:205] drop9 needs backward computation.
I1027 10:02:00.707054 40837 net.cpp:205] fire9/concat needs backward computation.
I1027 10:02:00.707060 40837 net.cpp:205] fire9/relu_expand3x3 needs backward computation.
I1027 10:02:00.707067 40837 net.cpp:205] fire9/expand3x3 needs backward computation.
I1027 10:02:00.707072 40837 net.cpp:205] fire9/relu_expand1x1 needs backward computation.
I1027 10:02:00.707077 40837 net.cpp:205] fire9/expand1x1 needs backward computation.
I1027 10:02:00.707082 40837 net.cpp:205] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I1027 10:02:00.707087 40837 net.cpp:205] fire9/relu_squeeze1x1 needs backward computation.
I1027 10:02:00.707092 40837 net.cpp:205] fire9/squeeze1x1 needs backward computation.
I1027 10:02:00.707096 40837 net.cpp:205] fire8/concat needs backward computation.
I1027 10:02:00.707101 40837 net.cpp:205] fire8/relu_expand3x3 needs backward computation.
I1027 10:02:00.707106 40837 net.cpp:205] fire8/expand3x3 needs backward computation.
I1027 10:02:00.707110 40837 net.cpp:205] fire8/relu_expand1x1 needs backward computation.
I1027 10:02:00.707115 40837 net.cpp:205] fire8/expand1x1 needs backward computation.
I1027 10:02:00.707120 40837 net.cpp:205] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I1027 10:02:00.707124 40837 net.cpp:205] fire8/relu_squeeze1x1 needs backward computation.
I1027 10:02:00.707129 40837 net.cpp:205] fire8/squeeze1x1 needs backward computation.
I1027 10:02:00.707134 40837 net.cpp:205] fire7/concat needs backward computation.
I1027 10:02:00.707139 40837 net.cpp:205] fire7/relu_expand3x3 needs backward computation.
I1027 10:02:00.707144 40837 net.cpp:205] fire7/expand3x3 needs backward computation.
I1027 10:02:00.707147 40837 net.cpp:205] fire7/relu_expand1x1 needs backward computation.
I1027 10:02:00.707151 40837 net.cpp:205] fire7/expand1x1 needs backward computation.
I1027 10:02:00.707167 40837 net.cpp:205] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I1027 10:02:00.707173 40837 net.cpp:205] fire7/relu_squeeze1x1 needs backward computation.
I1027 10:02:00.707178 40837 net.cpp:205] fire7/squeeze1x1 needs backward computation.
I1027 10:02:00.707183 40837 net.cpp:205] fire6/concat needs backward computation.
I1027 10:02:00.707193 40837 net.cpp:205] fire6/relu_expand3x3 needs backward computation.
I1027 10:02:00.707198 40837 net.cpp:205] fire6/expand3x3 needs backward computation.
I1027 10:02:00.707203 40837 net.cpp:205] fire6/relu_expand1x1 needs backward computation.
I1027 10:02:00.707207 40837 net.cpp:205] fire6/expand1x1 needs backward computation.
I1027 10:02:00.707212 40837 net.cpp:205] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I1027 10:02:00.707216 40837 net.cpp:205] fire6/relu_squeeze1x1 needs backward computation.
I1027 10:02:00.707221 40837 net.cpp:205] fire6/squeeze1x1 needs backward computation.
I1027 10:02:00.707226 40837 net.cpp:205] pool5 needs backward computation.
I1027 10:02:00.707231 40837 net.cpp:205] fire5/concat needs backward computation.
I1027 10:02:00.707237 40837 net.cpp:205] fire5/relu_expand3x3 needs backward computation.
I1027 10:02:00.707242 40837 net.cpp:205] fire5/expand3x3 needs backward computation.
I1027 10:02:00.707245 40837 net.cpp:205] fire5/relu_expand1x1 needs backward computation.
I1027 10:02:00.707249 40837 net.cpp:205] fire5/expand1x1 needs backward computation.
I1027 10:02:00.707254 40837 net.cpp:205] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I1027 10:02:00.707259 40837 net.cpp:205] fire5/relu_squeeze1x1 needs backward computation.
I1027 10:02:00.707263 40837 net.cpp:205] fire5/squeeze1x1 needs backward computation.
I1027 10:02:00.707268 40837 net.cpp:205] fire4/concat needs backward computation.
I1027 10:02:00.707273 40837 net.cpp:205] fire4/relu_expand3x3 needs backward computation.
I1027 10:02:00.707278 40837 net.cpp:205] fire4/expand3x3 needs backward computation.
I1027 10:02:00.707288 40837 net.cpp:205] fire4/relu_expand1x1 needs backward computation.
I1027 10:02:00.707293 40837 net.cpp:205] fire4/expand1x1 needs backward computation.
I1027 10:02:00.707304 40837 net.cpp:205] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I1027 10:02:00.707309 40837 net.cpp:205] fire4/relu_squeeze1x1 needs backward computation.
I1027 10:02:00.707314 40837 net.cpp:205] fire4/squeeze1x1 needs backward computation.
I1027 10:02:00.707319 40837 net.cpp:205] pool3 needs backward computation.
I1027 10:02:00.707324 40837 net.cpp:205] fire3/concat needs backward computation.
I1027 10:02:00.707329 40837 net.cpp:205] fire3/relu_expand3x3 needs backward computation.
I1027 10:02:00.707332 40837 net.cpp:205] fire3/expand3x3 needs backward computation.
I1027 10:02:00.707337 40837 net.cpp:205] fire3/relu_expand1x1 needs backward computation.
I1027 10:02:00.707341 40837 net.cpp:205] fire3/expand1x1 needs backward computation.
I1027 10:02:00.707346 40837 net.cpp:205] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I1027 10:02:00.707351 40837 net.cpp:205] fire3/relu_squeeze1x1 needs backward computation.
I1027 10:02:00.707356 40837 net.cpp:205] fire3/squeeze1x1 needs backward computation.
I1027 10:02:00.707360 40837 net.cpp:205] fire2/concat needs backward computation.
I1027 10:02:00.707365 40837 net.cpp:205] fire2/relu_expand3x3 needs backward computation.
I1027 10:02:00.707370 40837 net.cpp:205] fire2/expand3x3 needs backward computation.
I1027 10:02:00.707375 40837 net.cpp:205] fire2/relu_expand1x1 needs backward computation.
I1027 10:02:00.707378 40837 net.cpp:205] fire2/expand1x1 needs backward computation.
I1027 10:02:00.707383 40837 net.cpp:205] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I1027 10:02:00.707389 40837 net.cpp:205] fire2/relu_squeeze1x1 needs backward computation.
I1027 10:02:00.707393 40837 net.cpp:205] fire2/squeeze1x1 needs backward computation.
I1027 10:02:00.707404 40837 net.cpp:205] pool1 needs backward computation.
I1027 10:02:00.707409 40837 net.cpp:205] relu_conv1 needs backward computation.
I1027 10:02:00.707414 40837 net.cpp:205] conv1 needs backward computation.
I1027 10:02:00.707420 40837 net.cpp:207] data does not need backward computation.
I1027 10:02:00.707429 40837 net.cpp:249] This network produces output loss
I1027 10:02:00.707484 40837 net.cpp:262] Network initialization done.
I1027 10:02:00.709506 40837 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_0.prototxt
I1027 10:02:00.709635 40837 net.cpp:301] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1027 10:02:00.710402 40837 net.cpp:51] Initializing net from parameters: 
name: "SqueezeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/data/caffe-imagenet/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "INQConvolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "fire3/concat"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire4/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool3"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "fire5/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire4/concat"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "fire5/concat"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire6/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool5"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "fire9/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire8/concat"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "INQConvolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "pool10"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy_top1"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy_top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy_top5"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy_top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I1027 10:02:00.710791 40837 layer_factory.hpp:77] Creating layer data
I1027 10:02:00.710881 40837 db_lmdb.cpp:35] Opened lmdb /home/data/caffe-imagenet/ilsvrc12_val_lmdb
I1027 10:02:00.710904 40837 net.cpp:84] Creating Layer data
I1027 10:02:00.710916 40837 net.cpp:387] data -> data
I1027 10:02:00.710927 40837 net.cpp:387] data -> label
I1027 10:02:00.711382 40837 data_layer.cpp:45] output data size: 50,3,227,227
I1027 10:02:00.799559 40837 net.cpp:127] Setting up data
I1027 10:02:00.799607 40837 net.cpp:136] Top shape: 50 3 227 227 (7729350)
I1027 10:02:00.799623 40837 net.cpp:136] Top shape: 50 (50)
I1027 10:02:00.799654 40837 net.cpp:144] Memory required for data: 30917600
I1027 10:02:00.799665 40837 layer_factory.hpp:77] Creating layer label_data_1_split
I1027 10:02:00.799684 40837 net.cpp:84] Creating Layer label_data_1_split
I1027 10:02:00.799690 40837 net.cpp:413] label_data_1_split <- label
I1027 10:02:00.799700 40837 net.cpp:387] label_data_1_split -> label_data_1_split_0
I1027 10:02:00.799715 40837 net.cpp:387] label_data_1_split -> label_data_1_split_1
I1027 10:02:00.799722 40837 net.cpp:387] label_data_1_split -> label_data_1_split_2
I1027 10:02:00.799818 40837 net.cpp:127] Setting up label_data_1_split
I1027 10:02:00.799829 40837 net.cpp:136] Top shape: 50 (50)
I1027 10:02:00.799834 40837 net.cpp:136] Top shape: 50 (50)
I1027 10:02:00.799840 40837 net.cpp:136] Top shape: 50 (50)
I1027 10:02:00.799845 40837 net.cpp:144] Memory required for data: 30918200
I1027 10:02:00.799850 40837 layer_factory.hpp:77] Creating layer conv1
I1027 10:02:00.799866 40837 net.cpp:84] Creating Layer conv1
I1027 10:02:00.799872 40837 net.cpp:413] conv1 <- data
I1027 10:02:00.799881 40837 net.cpp:387] conv1 -> conv1
I1027 10:02:00.800356 40837 net.cpp:127] Setting up conv1
I1027 10:02:00.800372 40837 net.cpp:136] Top shape: 50 64 113 113 (40860800)
I1027 10:02:00.800379 40837 net.cpp:144] Memory required for data: 194361400
I1027 10:02:00.800388 40837 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1027 10:02:00.800400 40837 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1027 10:02:00.800410 40837 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1027 10:02:00.800420 40837 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1027 10:02:00.800424 40837 layer_factory.hpp:77] Creating layer relu_conv1
I1027 10:02:00.800434 40837 net.cpp:84] Creating Layer relu_conv1
I1027 10:02:00.800441 40837 net.cpp:413] relu_conv1 <- conv1
I1027 10:02:00.800448 40837 net.cpp:374] relu_conv1 -> conv1 (in-place)
I1027 10:02:00.800736 40837 net.cpp:127] Setting up relu_conv1
I1027 10:02:00.800761 40837 net.cpp:136] Top shape: 50 64 113 113 (40860800)
I1027 10:02:00.800767 40837 net.cpp:144] Memory required for data: 357804600
I1027 10:02:00.800773 40837 layer_factory.hpp:77] Creating layer pool1
I1027 10:02:00.800786 40837 net.cpp:84] Creating Layer pool1
I1027 10:02:00.800792 40837 net.cpp:413] pool1 <- conv1
I1027 10:02:00.800801 40837 net.cpp:387] pool1 -> pool1
I1027 10:02:00.800855 40837 net.cpp:127] Setting up pool1
I1027 10:02:00.800879 40837 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 10:02:00.800884 40837 net.cpp:144] Memory required for data: 397945400
I1027 10:02:00.800889 40837 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I1027 10:02:00.800900 40837 net.cpp:84] Creating Layer fire2/squeeze1x1
I1027 10:02:00.800906 40837 net.cpp:413] fire2/squeeze1x1 <- pool1
I1027 10:02:00.800915 40837 net.cpp:387] fire2/squeeze1x1 -> fire2/squeeze1x1
I1027 10:02:00.801525 40837 net.cpp:127] Setting up fire2/squeeze1x1
I1027 10:02:00.801550 40837 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1027 10:02:00.801559 40837 net.cpp:144] Memory required for data: 407980600
I1027 10:02:00.801574 40837 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1027 10:02:00.801589 40837 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1027 10:02:00.801601 40837 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1027 10:02:00.801611 40837 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1027 10:02:00.801623 40837 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I1027 10:02:00.801636 40837 net.cpp:84] Creating Layer fire2/relu_squeeze1x1
I1027 10:02:00.801651 40837 net.cpp:413] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I1027 10:02:00.801662 40837 net.cpp:374] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I1027 10:02:00.801940 40837 net.cpp:127] Setting up fire2/relu_squeeze1x1
I1027 10:02:00.801956 40837 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1027 10:02:00.801975 40837 net.cpp:144] Memory required for data: 418015800
I1027 10:02:00.801981 40837 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1027 10:02:00.801990 40837 net.cpp:84] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1027 10:02:00.801995 40837 net.cpp:413] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I1027 10:02:00.802003 40837 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1027 10:02:00.802014 40837 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1027 10:02:00.804414 40837 net.cpp:127] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1027 10:02:00.804433 40837 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1027 10:02:00.804441 40837 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1027 10:02:00.804446 40837 net.cpp:144] Memory required for data: 438086200
I1027 10:02:00.804452 40837 layer_factory.hpp:77] Creating layer fire2/expand1x1
I1027 10:02:00.804466 40837 net.cpp:84] Creating Layer fire2/expand1x1
I1027 10:02:00.804473 40837 net.cpp:413] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1027 10:02:00.804483 40837 net.cpp:387] fire2/expand1x1 -> fire2/expand1x1
I1027 10:02:00.804848 40837 net.cpp:127] Setting up fire2/expand1x1
I1027 10:02:00.804860 40837 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 10:02:00.804865 40837 net.cpp:144] Memory required for data: 478227000
I1027 10:02:00.804874 40837 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1027 10:02:00.804884 40837 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1027 10:02:00.804891 40837 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1027 10:02:00.804896 40837 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1027 10:02:00.804909 40837 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I1027 10:02:00.804919 40837 net.cpp:84] Creating Layer fire2/relu_expand1x1
I1027 10:02:00.804924 40837 net.cpp:413] fire2/relu_expand1x1 <- fire2/expand1x1
I1027 10:02:00.804931 40837 net.cpp:374] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I1027 10:02:00.806481 40837 net.cpp:127] Setting up fire2/relu_expand1x1
I1027 10:02:00.806501 40837 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 10:02:00.806507 40837 net.cpp:144] Memory required for data: 518367800
I1027 10:02:00.806514 40837 layer_factory.hpp:77] Creating layer fire2/expand3x3
I1027 10:02:00.806527 40837 net.cpp:84] Creating Layer fire2/expand3x3
I1027 10:02:00.806545 40837 net.cpp:413] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1027 10:02:00.806555 40837 net.cpp:387] fire2/expand3x3 -> fire2/expand3x3
I1027 10:02:00.807003 40837 net.cpp:127] Setting up fire2/expand3x3
I1027 10:02:00.807015 40837 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 10:02:00.807020 40837 net.cpp:144] Memory required for data: 558508600
I1027 10:02:00.807027 40837 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1027 10:02:00.807034 40837 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1027 10:02:00.807040 40837 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1027 10:02:00.807045 40837 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1027 10:02:00.807049 40837 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I1027 10:02:00.807059 40837 net.cpp:84] Creating Layer fire2/relu_expand3x3
I1027 10:02:00.807063 40837 net.cpp:413] fire2/relu_expand3x3 <- fire2/expand3x3
I1027 10:02:00.807071 40837 net.cpp:374] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I1027 10:02:00.807291 40837 net.cpp:127] Setting up fire2/relu_expand3x3
I1027 10:02:00.807322 40837 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 10:02:00.807328 40837 net.cpp:144] Memory required for data: 598649400
I1027 10:02:00.807346 40837 layer_factory.hpp:77] Creating layer fire2/concat
I1027 10:02:00.807358 40837 net.cpp:84] Creating Layer fire2/concat
I1027 10:02:00.807363 40837 net.cpp:413] fire2/concat <- fire2/expand1x1
I1027 10:02:00.807370 40837 net.cpp:413] fire2/concat <- fire2/expand3x3
I1027 10:02:00.807377 40837 net.cpp:387] fire2/concat -> fire2/concat
I1027 10:02:00.807412 40837 net.cpp:127] Setting up fire2/concat
I1027 10:02:00.807422 40837 net.cpp:136] Top shape: 50 128 56 56 (20070400)
I1027 10:02:00.807427 40837 net.cpp:144] Memory required for data: 678931000
I1027 10:02:00.807431 40837 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I1027 10:02:00.807443 40837 net.cpp:84] Creating Layer fire3/squeeze1x1
I1027 10:02:00.807448 40837 net.cpp:413] fire3/squeeze1x1 <- fire2/concat
I1027 10:02:00.807456 40837 net.cpp:387] fire3/squeeze1x1 -> fire3/squeeze1x1
I1027 10:02:00.807842 40837 net.cpp:127] Setting up fire3/squeeze1x1
I1027 10:02:00.807855 40837 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1027 10:02:00.807860 40837 net.cpp:144] Memory required for data: 688966200
I1027 10:02:00.807873 40837 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1027 10:02:00.807883 40837 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1027 10:02:00.807889 40837 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1027 10:02:00.807895 40837 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1027 10:02:00.807900 40837 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I1027 10:02:00.807907 40837 net.cpp:84] Creating Layer fire3/relu_squeeze1x1
I1027 10:02:00.807912 40837 net.cpp:413] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I1027 10:02:00.807924 40837 net.cpp:374] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I1027 10:02:00.808132 40837 net.cpp:127] Setting up fire3/relu_squeeze1x1
I1027 10:02:00.808145 40837 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1027 10:02:00.808157 40837 net.cpp:144] Memory required for data: 699001400
I1027 10:02:00.808162 40837 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1027 10:02:00.808171 40837 net.cpp:84] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1027 10:02:00.808176 40837 net.cpp:413] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I1027 10:02:00.808183 40837 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1027 10:02:00.808192 40837 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1027 10:02:00.808241 40837 net.cpp:127] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1027 10:02:00.808253 40837 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1027 10:02:00.808259 40837 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1027 10:02:00.808264 40837 net.cpp:144] Memory required for data: 719071800
I1027 10:02:00.808269 40837 layer_factory.hpp:77] Creating layer fire3/expand1x1
I1027 10:02:00.808281 40837 net.cpp:84] Creating Layer fire3/expand1x1
I1027 10:02:00.808286 40837 net.cpp:413] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1027 10:02:00.808302 40837 net.cpp:387] fire3/expand1x1 -> fire3/expand1x1
I1027 10:02:00.808660 40837 net.cpp:127] Setting up fire3/expand1x1
I1027 10:02:00.808671 40837 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 10:02:00.808681 40837 net.cpp:144] Memory required for data: 759212600
I1027 10:02:00.808688 40837 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1027 10:02:00.808697 40837 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1027 10:02:00.808703 40837 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1027 10:02:00.808709 40837 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1027 10:02:00.808713 40837 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I1027 10:02:00.808733 40837 net.cpp:84] Creating Layer fire3/relu_expand1x1
I1027 10:02:00.808739 40837 net.cpp:413] fire3/relu_expand1x1 <- fire3/expand1x1
I1027 10:02:00.808746 40837 net.cpp:374] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I1027 10:02:00.808966 40837 net.cpp:127] Setting up fire3/relu_expand1x1
I1027 10:02:00.808979 40837 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 10:02:00.808984 40837 net.cpp:144] Memory required for data: 799353400
I1027 10:02:00.808989 40837 layer_factory.hpp:77] Creating layer fire3/expand3x3
I1027 10:02:00.809000 40837 net.cpp:84] Creating Layer fire3/expand3x3
I1027 10:02:00.809006 40837 net.cpp:413] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1027 10:02:00.809015 40837 net.cpp:387] fire3/expand3x3 -> fire3/expand3x3
I1027 10:02:00.809464 40837 net.cpp:127] Setting up fire3/expand3x3
I1027 10:02:00.809478 40837 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 10:02:00.809484 40837 net.cpp:144] Memory required for data: 839494200
I1027 10:02:00.809490 40837 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1027 10:02:00.809497 40837 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1027 10:02:00.809504 40837 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1027 10:02:00.809509 40837 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1027 10:02:00.809514 40837 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I1027 10:02:00.809520 40837 net.cpp:84] Creating Layer fire3/relu_expand3x3
I1027 10:02:00.809526 40837 net.cpp:413] fire3/relu_expand3x3 <- fire3/expand3x3
I1027 10:02:00.809532 40837 net.cpp:374] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I1027 10:02:00.810940 40837 net.cpp:127] Setting up fire3/relu_expand3x3
I1027 10:02:00.810961 40837 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 10:02:00.810966 40837 net.cpp:144] Memory required for data: 879635000
I1027 10:02:00.810978 40837 layer_factory.hpp:77] Creating layer fire3/concat
I1027 10:02:00.810989 40837 net.cpp:84] Creating Layer fire3/concat
I1027 10:02:00.810995 40837 net.cpp:413] fire3/concat <- fire3/expand1x1
I1027 10:02:00.811002 40837 net.cpp:413] fire3/concat <- fire3/expand3x3
I1027 10:02:00.811008 40837 net.cpp:387] fire3/concat -> fire3/concat
I1027 10:02:00.811046 40837 net.cpp:127] Setting up fire3/concat
I1027 10:02:00.811055 40837 net.cpp:136] Top shape: 50 128 56 56 (20070400)
I1027 10:02:00.811059 40837 net.cpp:144] Memory required for data: 959916600
I1027 10:02:00.811064 40837 layer_factory.hpp:77] Creating layer pool3
I1027 10:02:00.811074 40837 net.cpp:84] Creating Layer pool3
I1027 10:02:00.811079 40837 net.cpp:413] pool3 <- fire3/concat
I1027 10:02:00.811085 40837 net.cpp:387] pool3 -> pool3
I1027 10:02:00.811133 40837 net.cpp:127] Setting up pool3
I1027 10:02:00.811143 40837 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 10:02:00.811147 40837 net.cpp:144] Memory required for data: 979987000
I1027 10:02:00.811152 40837 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I1027 10:02:00.811164 40837 net.cpp:84] Creating Layer fire4/squeeze1x1
I1027 10:02:00.811169 40837 net.cpp:413] fire4/squeeze1x1 <- pool3
I1027 10:02:00.811177 40837 net.cpp:387] fire4/squeeze1x1 -> fire4/squeeze1x1
I1027 10:02:00.811581 40837 net.cpp:127] Setting up fire4/squeeze1x1
I1027 10:02:00.811594 40837 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1027 10:02:00.811599 40837 net.cpp:144] Memory required for data: 985004600
I1027 10:02:00.811607 40837 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1027 10:02:00.811614 40837 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1027 10:02:00.811620 40837 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1027 10:02:00.811626 40837 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1027 10:02:00.811631 40837 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I1027 10:02:00.811655 40837 net.cpp:84] Creating Layer fire4/relu_squeeze1x1
I1027 10:02:00.811661 40837 net.cpp:413] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I1027 10:02:00.811668 40837 net.cpp:374] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I1027 10:02:00.811879 40837 net.cpp:127] Setting up fire4/relu_squeeze1x1
I1027 10:02:00.811892 40837 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1027 10:02:00.811897 40837 net.cpp:144] Memory required for data: 990022200
I1027 10:02:00.811902 40837 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1027 10:02:00.811914 40837 net.cpp:84] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1027 10:02:00.811920 40837 net.cpp:413] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I1027 10:02:00.811928 40837 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1027 10:02:00.811939 40837 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1027 10:02:00.811988 40837 net.cpp:127] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1027 10:02:00.811997 40837 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1027 10:02:00.812005 40837 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1027 10:02:00.812010 40837 net.cpp:144] Memory required for data: 1000057400
I1027 10:02:00.812013 40837 layer_factory.hpp:77] Creating layer fire4/expand1x1
I1027 10:02:00.812026 40837 net.cpp:84] Creating Layer fire4/expand1x1
I1027 10:02:00.812031 40837 net.cpp:413] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1027 10:02:00.812041 40837 net.cpp:387] fire4/expand1x1 -> fire4/expand1x1
I1027 10:02:00.812413 40837 net.cpp:127] Setting up fire4/expand1x1
I1027 10:02:00.812425 40837 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 10:02:00.812432 40837 net.cpp:144] Memory required for data: 1020127800
I1027 10:02:00.812449 40837 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1027 10:02:00.812461 40837 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1027 10:02:00.812469 40837 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1027 10:02:00.812474 40837 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1027 10:02:00.812479 40837 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I1027 10:02:00.812487 40837 net.cpp:84] Creating Layer fire4/relu_expand1x1
I1027 10:02:00.812494 40837 net.cpp:413] fire4/relu_expand1x1 <- fire4/expand1x1
I1027 10:02:00.812500 40837 net.cpp:374] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I1027 10:02:00.812714 40837 net.cpp:127] Setting up fire4/relu_expand1x1
I1027 10:02:00.812728 40837 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 10:02:00.812734 40837 net.cpp:144] Memory required for data: 1040198200
I1027 10:02:00.812739 40837 layer_factory.hpp:77] Creating layer fire4/expand3x3
I1027 10:02:00.812749 40837 net.cpp:84] Creating Layer fire4/expand3x3
I1027 10:02:00.812754 40837 net.cpp:413] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1027 10:02:00.812764 40837 net.cpp:387] fire4/expand3x3 -> fire4/expand3x3
I1027 10:02:00.813475 40837 net.cpp:127] Setting up fire4/expand3x3
I1027 10:02:00.813496 40837 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 10:02:00.813503 40837 net.cpp:144] Memory required for data: 1060268600
I1027 10:02:00.813510 40837 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1027 10:02:00.813518 40837 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1027 10:02:00.813522 40837 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1027 10:02:00.813529 40837 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1027 10:02:00.813534 40837 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I1027 10:02:00.813556 40837 net.cpp:84] Creating Layer fire4/relu_expand3x3
I1027 10:02:00.813563 40837 net.cpp:413] fire4/relu_expand3x3 <- fire4/expand3x3
I1027 10:02:00.813570 40837 net.cpp:374] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I1027 10:02:00.813798 40837 net.cpp:127] Setting up fire4/relu_expand3x3
I1027 10:02:00.813812 40837 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 10:02:00.813817 40837 net.cpp:144] Memory required for data: 1080339000
I1027 10:02:00.813822 40837 layer_factory.hpp:77] Creating layer fire4/concat
I1027 10:02:00.813832 40837 net.cpp:84] Creating Layer fire4/concat
I1027 10:02:00.813838 40837 net.cpp:413] fire4/concat <- fire4/expand1x1
I1027 10:02:00.813844 40837 net.cpp:413] fire4/concat <- fire4/expand3x3
I1027 10:02:00.813854 40837 net.cpp:387] fire4/concat -> fire4/concat
I1027 10:02:00.813887 40837 net.cpp:127] Setting up fire4/concat
I1027 10:02:00.813896 40837 net.cpp:136] Top shape: 50 256 28 28 (10035200)
I1027 10:02:00.813901 40837 net.cpp:144] Memory required for data: 1120479800
I1027 10:02:00.813905 40837 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I1027 10:02:00.813917 40837 net.cpp:84] Creating Layer fire5/squeeze1x1
I1027 10:02:00.813922 40837 net.cpp:413] fire5/squeeze1x1 <- fire4/concat
I1027 10:02:00.813932 40837 net.cpp:387] fire5/squeeze1x1 -> fire5/squeeze1x1
I1027 10:02:00.814368 40837 net.cpp:127] Setting up fire5/squeeze1x1
I1027 10:02:00.814379 40837 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1027 10:02:00.814385 40837 net.cpp:144] Memory required for data: 1125497400
I1027 10:02:00.814393 40837 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1027 10:02:00.814399 40837 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1027 10:02:00.814404 40837 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1027 10:02:00.814410 40837 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1027 10:02:00.814414 40837 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I1027 10:02:00.814429 40837 net.cpp:84] Creating Layer fire5/relu_squeeze1x1
I1027 10:02:00.814436 40837 net.cpp:413] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I1027 10:02:00.814445 40837 net.cpp:374] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I1027 10:02:00.815896 40837 net.cpp:127] Setting up fire5/relu_squeeze1x1
I1027 10:02:00.815925 40837 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1027 10:02:00.815932 40837 net.cpp:144] Memory required for data: 1130515000
I1027 10:02:00.815939 40837 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1027 10:02:00.815953 40837 net.cpp:84] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1027 10:02:00.815959 40837 net.cpp:413] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I1027 10:02:00.815968 40837 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1027 10:02:00.815976 40837 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1027 10:02:00.816033 40837 net.cpp:127] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1027 10:02:00.816043 40837 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1027 10:02:00.816049 40837 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1027 10:02:00.816054 40837 net.cpp:144] Memory required for data: 1140550200
I1027 10:02:00.816059 40837 layer_factory.hpp:77] Creating layer fire5/expand1x1
I1027 10:02:00.816071 40837 net.cpp:84] Creating Layer fire5/expand1x1
I1027 10:02:00.816076 40837 net.cpp:413] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1027 10:02:00.816087 40837 net.cpp:387] fire5/expand1x1 -> fire5/expand1x1
I1027 10:02:00.816471 40837 net.cpp:127] Setting up fire5/expand1x1
I1027 10:02:00.816483 40837 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 10:02:00.816489 40837 net.cpp:144] Memory required for data: 1160620600
I1027 10:02:00.816496 40837 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1027 10:02:00.816516 40837 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1027 10:02:00.816524 40837 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1027 10:02:00.816529 40837 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1027 10:02:00.816534 40837 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I1027 10:02:00.816545 40837 net.cpp:84] Creating Layer fire5/relu_expand1x1
I1027 10:02:00.816550 40837 net.cpp:413] fire5/relu_expand1x1 <- fire5/expand1x1
I1027 10:02:00.816557 40837 net.cpp:374] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I1027 10:02:00.816771 40837 net.cpp:127] Setting up fire5/relu_expand1x1
I1027 10:02:00.816783 40837 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 10:02:00.816788 40837 net.cpp:144] Memory required for data: 1180691000
I1027 10:02:00.816793 40837 layer_factory.hpp:77] Creating layer fire5/expand3x3
I1027 10:02:00.816805 40837 net.cpp:84] Creating Layer fire5/expand3x3
I1027 10:02:00.816810 40837 net.cpp:413] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1027 10:02:00.816820 40837 net.cpp:387] fire5/expand3x3 -> fire5/expand3x3
I1027 10:02:00.817512 40837 net.cpp:127] Setting up fire5/expand3x3
I1027 10:02:00.817528 40837 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 10:02:00.817533 40837 net.cpp:144] Memory required for data: 1200761400
I1027 10:02:00.817541 40837 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1027 10:02:00.817548 40837 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1027 10:02:00.817553 40837 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1027 10:02:00.817559 40837 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1027 10:02:00.817564 40837 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I1027 10:02:00.817579 40837 net.cpp:84] Creating Layer fire5/relu_expand3x3
I1027 10:02:00.817585 40837 net.cpp:413] fire5/relu_expand3x3 <- fire5/expand3x3
I1027 10:02:00.817592 40837 net.cpp:374] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I1027 10:02:00.817808 40837 net.cpp:127] Setting up fire5/relu_expand3x3
I1027 10:02:00.817821 40837 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 10:02:00.817826 40837 net.cpp:144] Memory required for data: 1220831800
I1027 10:02:00.817831 40837 layer_factory.hpp:77] Creating layer fire5/concat
I1027 10:02:00.817840 40837 net.cpp:84] Creating Layer fire5/concat
I1027 10:02:00.817847 40837 net.cpp:413] fire5/concat <- fire5/expand1x1
I1027 10:02:00.817852 40837 net.cpp:413] fire5/concat <- fire5/expand3x3
I1027 10:02:00.817859 40837 net.cpp:387] fire5/concat -> fire5/concat
I1027 10:02:00.817893 40837 net.cpp:127] Setting up fire5/concat
I1027 10:02:00.817903 40837 net.cpp:136] Top shape: 50 256 28 28 (10035200)
I1027 10:02:00.817906 40837 net.cpp:144] Memory required for data: 1260972600
I1027 10:02:00.817911 40837 layer_factory.hpp:77] Creating layer pool5
I1027 10:02:00.817919 40837 net.cpp:84] Creating Layer pool5
I1027 10:02:00.817924 40837 net.cpp:413] pool5 <- fire5/concat
I1027 10:02:00.817934 40837 net.cpp:387] pool5 -> pool5
I1027 10:02:00.817984 40837 net.cpp:127] Setting up pool5
I1027 10:02:00.817994 40837 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 10:02:00.817998 40837 net.cpp:144] Memory required for data: 1271007800
I1027 10:02:00.818003 40837 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I1027 10:02:00.818017 40837 net.cpp:84] Creating Layer fire6/squeeze1x1
I1027 10:02:00.818022 40837 net.cpp:413] fire6/squeeze1x1 <- pool5
I1027 10:02:00.818030 40837 net.cpp:387] fire6/squeeze1x1 -> fire6/squeeze1x1
I1027 10:02:00.818506 40837 net.cpp:127] Setting up fire6/squeeze1x1
I1027 10:02:00.818517 40837 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1027 10:02:00.818522 40837 net.cpp:144] Memory required for data: 1272889400
I1027 10:02:00.818531 40837 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1027 10:02:00.818548 40837 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1027 10:02:00.818554 40837 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1027 10:02:00.818560 40837 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1027 10:02:00.818564 40837 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I1027 10:02:00.818572 40837 net.cpp:84] Creating Layer fire6/relu_squeeze1x1
I1027 10:02:00.818578 40837 net.cpp:413] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I1027 10:02:00.818586 40837 net.cpp:374] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I1027 10:02:00.818795 40837 net.cpp:127] Setting up fire6/relu_squeeze1x1
I1027 10:02:00.818807 40837 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1027 10:02:00.818812 40837 net.cpp:144] Memory required for data: 1274771000
I1027 10:02:00.818817 40837 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1027 10:02:00.818825 40837 net.cpp:84] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1027 10:02:00.818830 40837 net.cpp:413] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I1027 10:02:00.818840 40837 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1027 10:02:00.818847 40837 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1027 10:02:00.818904 40837 net.cpp:127] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1027 10:02:00.818917 40837 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1027 10:02:00.818922 40837 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1027 10:02:00.818928 40837 net.cpp:144] Memory required for data: 1278534200
I1027 10:02:00.818933 40837 layer_factory.hpp:77] Creating layer fire6/expand1x1
I1027 10:02:00.818941 40837 net.cpp:84] Creating Layer fire6/expand1x1
I1027 10:02:00.818954 40837 net.cpp:413] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1027 10:02:00.818964 40837 net.cpp:387] fire6/expand1x1 -> fire6/expand1x1
I1027 10:02:00.819392 40837 net.cpp:127] Setting up fire6/expand1x1
I1027 10:02:00.819404 40837 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1027 10:02:00.819409 40837 net.cpp:144] Memory required for data: 1286060600
I1027 10:02:00.819416 40837 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1027 10:02:00.819423 40837 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1027 10:02:00.819430 40837 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1027 10:02:00.819435 40837 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1027 10:02:00.819440 40837 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I1027 10:02:00.819449 40837 net.cpp:84] Creating Layer fire6/relu_expand1x1
I1027 10:02:00.819455 40837 net.cpp:413] fire6/relu_expand1x1 <- fire6/expand1x1
I1027 10:02:00.819463 40837 net.cpp:374] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I1027 10:02:00.820904 40837 net.cpp:127] Setting up fire6/relu_expand1x1
I1027 10:02:00.820924 40837 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1027 10:02:00.820930 40837 net.cpp:144] Memory required for data: 1293587000
I1027 10:02:00.820935 40837 layer_factory.hpp:77] Creating layer fire6/expand3x3
I1027 10:02:00.820947 40837 net.cpp:84] Creating Layer fire6/expand3x3
I1027 10:02:00.820955 40837 net.cpp:413] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1027 10:02:00.820966 40837 net.cpp:387] fire6/expand3x3 -> fire6/expand3x3
I1027 10:02:00.822129 40837 net.cpp:127] Setting up fire6/expand3x3
I1027 10:02:00.822145 40837 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1027 10:02:00.822150 40837 net.cpp:144] Memory required for data: 1301113400
I1027 10:02:00.822160 40837 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1027 10:02:00.822185 40837 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1027 10:02:00.822190 40837 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1027 10:02:00.822196 40837 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1027 10:02:00.822201 40837 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I1027 10:02:00.822208 40837 net.cpp:84] Creating Layer fire6/relu_expand3x3
I1027 10:02:00.822214 40837 net.cpp:413] fire6/relu_expand3x3 <- fire6/expand3x3
I1027 10:02:00.822223 40837 net.cpp:374] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I1027 10:02:00.822484 40837 net.cpp:127] Setting up fire6/relu_expand3x3
I1027 10:02:00.822499 40837 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1027 10:02:00.822505 40837 net.cpp:144] Memory required for data: 1308639800
I1027 10:02:00.822511 40837 layer_factory.hpp:77] Creating layer fire6/concat
I1027 10:02:00.822526 40837 net.cpp:84] Creating Layer fire6/concat
I1027 10:02:00.822532 40837 net.cpp:413] fire6/concat <- fire6/expand1x1
I1027 10:02:00.822540 40837 net.cpp:413] fire6/concat <- fire6/expand3x3
I1027 10:02:00.822552 40837 net.cpp:387] fire6/concat -> fire6/concat
I1027 10:02:00.822594 40837 net.cpp:127] Setting up fire6/concat
I1027 10:02:00.822613 40837 net.cpp:136] Top shape: 50 384 14 14 (3763200)
I1027 10:02:00.822618 40837 net.cpp:144] Memory required for data: 1323692600
I1027 10:02:00.822623 40837 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I1027 10:02:00.822634 40837 net.cpp:84] Creating Layer fire7/squeeze1x1
I1027 10:02:00.822640 40837 net.cpp:413] fire7/squeeze1x1 <- fire6/concat
I1027 10:02:00.822649 40837 net.cpp:387] fire7/squeeze1x1 -> fire7/squeeze1x1
I1027 10:02:00.823164 40837 net.cpp:127] Setting up fire7/squeeze1x1
I1027 10:02:00.823176 40837 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1027 10:02:00.823181 40837 net.cpp:144] Memory required for data: 1325574200
I1027 10:02:00.823195 40837 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1027 10:02:00.823216 40837 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1027 10:02:00.823225 40837 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1027 10:02:00.823231 40837 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1027 10:02:00.823236 40837 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I1027 10:02:00.823243 40837 net.cpp:84] Creating Layer fire7/relu_squeeze1x1
I1027 10:02:00.823249 40837 net.cpp:413] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I1027 10:02:00.823256 40837 net.cpp:374] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I1027 10:02:00.823488 40837 net.cpp:127] Setting up fire7/relu_squeeze1x1
I1027 10:02:00.823504 40837 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1027 10:02:00.823510 40837 net.cpp:144] Memory required for data: 1327455800
I1027 10:02:00.823516 40837 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1027 10:02:00.823523 40837 net.cpp:84] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1027 10:02:00.823529 40837 net.cpp:413] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I1027 10:02:00.823535 40837 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1027 10:02:00.823544 40837 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1027 10:02:00.823598 40837 net.cpp:127] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1027 10:02:00.823617 40837 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1027 10:02:00.823624 40837 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1027 10:02:00.823628 40837 net.cpp:144] Memory required for data: 1331219000
I1027 10:02:00.823633 40837 layer_factory.hpp:77] Creating layer fire7/expand1x1
I1027 10:02:00.823644 40837 net.cpp:84] Creating Layer fire7/expand1x1
I1027 10:02:00.823663 40837 net.cpp:413] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1027 10:02:00.823674 40837 net.cpp:387] fire7/expand1x1 -> fire7/expand1x1
I1027 10:02:00.824115 40837 net.cpp:127] Setting up fire7/expand1x1
I1027 10:02:00.824126 40837 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1027 10:02:00.824131 40837 net.cpp:144] Memory required for data: 1338745400
I1027 10:02:00.824138 40837 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1027 10:02:00.824144 40837 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1027 10:02:00.824151 40837 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1027 10:02:00.824156 40837 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1027 10:02:00.824160 40837 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I1027 10:02:00.824168 40837 net.cpp:84] Creating Layer fire7/relu_expand1x1
I1027 10:02:00.824174 40837 net.cpp:413] fire7/relu_expand1x1 <- fire7/expand1x1
I1027 10:02:00.824180 40837 net.cpp:374] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I1027 10:02:00.825659 40837 net.cpp:127] Setting up fire7/relu_expand1x1
I1027 10:02:00.825680 40837 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1027 10:02:00.825686 40837 net.cpp:144] Memory required for data: 1346271800
I1027 10:02:00.825693 40837 layer_factory.hpp:77] Creating layer fire7/expand3x3
I1027 10:02:00.825706 40837 net.cpp:84] Creating Layer fire7/expand3x3
I1027 10:02:00.825712 40837 net.cpp:413] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1027 10:02:00.825723 40837 net.cpp:387] fire7/expand3x3 -> fire7/expand3x3
I1027 10:02:00.826813 40837 net.cpp:127] Setting up fire7/expand3x3
I1027 10:02:00.826829 40837 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1027 10:02:00.826834 40837 net.cpp:144] Memory required for data: 1353798200
I1027 10:02:00.826841 40837 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1027 10:02:00.826858 40837 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1027 10:02:00.826865 40837 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1027 10:02:00.826871 40837 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1027 10:02:00.826877 40837 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I1027 10:02:00.826887 40837 net.cpp:84] Creating Layer fire7/relu_expand3x3
I1027 10:02:00.826894 40837 net.cpp:413] fire7/relu_expand3x3 <- fire7/expand3x3
I1027 10:02:00.826902 40837 net.cpp:374] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I1027 10:02:00.827117 40837 net.cpp:127] Setting up fire7/relu_expand3x3
I1027 10:02:00.827129 40837 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1027 10:02:00.827136 40837 net.cpp:144] Memory required for data: 1361324600
I1027 10:02:00.827141 40837 layer_factory.hpp:77] Creating layer fire7/concat
I1027 10:02:00.827165 40837 net.cpp:84] Creating Layer fire7/concat
I1027 10:02:00.827173 40837 net.cpp:413] fire7/concat <- fire7/expand1x1
I1027 10:02:00.827180 40837 net.cpp:413] fire7/concat <- fire7/expand3x3
I1027 10:02:00.827189 40837 net.cpp:387] fire7/concat -> fire7/concat
I1027 10:02:00.827227 40837 net.cpp:127] Setting up fire7/concat
I1027 10:02:00.827236 40837 net.cpp:136] Top shape: 50 384 14 14 (3763200)
I1027 10:02:00.827241 40837 net.cpp:144] Memory required for data: 1376377400
I1027 10:02:00.827249 40837 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I1027 10:02:00.827260 40837 net.cpp:84] Creating Layer fire8/squeeze1x1
I1027 10:02:00.827266 40837 net.cpp:413] fire8/squeeze1x1 <- fire7/concat
I1027 10:02:00.827275 40837 net.cpp:387] fire8/squeeze1x1 -> fire8/squeeze1x1
I1027 10:02:00.829365 40837 net.cpp:127] Setting up fire8/squeeze1x1
I1027 10:02:00.829385 40837 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1027 10:02:00.829391 40837 net.cpp:144] Memory required for data: 1378886200
I1027 10:02:00.829399 40837 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1027 10:02:00.829419 40837 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1027 10:02:00.829427 40837 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1027 10:02:00.829432 40837 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1027 10:02:00.829435 40837 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I1027 10:02:00.829447 40837 net.cpp:84] Creating Layer fire8/relu_squeeze1x1
I1027 10:02:00.829452 40837 net.cpp:413] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I1027 10:02:00.829459 40837 net.cpp:374] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I1027 10:02:00.829694 40837 net.cpp:127] Setting up fire8/relu_squeeze1x1
I1027 10:02:00.829705 40837 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1027 10:02:00.829711 40837 net.cpp:144] Memory required for data: 1381395000
I1027 10:02:00.829717 40837 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1027 10:02:00.829726 40837 net.cpp:84] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1027 10:02:00.829731 40837 net.cpp:413] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I1027 10:02:00.829738 40837 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1027 10:02:00.829747 40837 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1027 10:02:00.829802 40837 net.cpp:127] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1027 10:02:00.829810 40837 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1027 10:02:00.829816 40837 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1027 10:02:00.829821 40837 net.cpp:144] Memory required for data: 1386412600
I1027 10:02:00.829825 40837 layer_factory.hpp:77] Creating layer fire8/expand1x1
I1027 10:02:00.829838 40837 net.cpp:84] Creating Layer fire8/expand1x1
I1027 10:02:00.829849 40837 net.cpp:413] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1027 10:02:00.829857 40837 net.cpp:387] fire8/expand1x1 -> fire8/expand1x1
I1027 10:02:00.830359 40837 net.cpp:127] Setting up fire8/expand1x1
I1027 10:02:00.830373 40837 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 10:02:00.830379 40837 net.cpp:144] Memory required for data: 1396447800
I1027 10:02:00.830386 40837 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1027 10:02:00.830394 40837 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1027 10:02:00.830399 40837 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1027 10:02:00.830404 40837 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1027 10:02:00.830410 40837 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I1027 10:02:00.830417 40837 net.cpp:84] Creating Layer fire8/relu_expand1x1
I1027 10:02:00.830425 40837 net.cpp:413] fire8/relu_expand1x1 <- fire8/expand1x1
I1027 10:02:00.830431 40837 net.cpp:374] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I1027 10:02:00.830653 40837 net.cpp:127] Setting up fire8/relu_expand1x1
I1027 10:02:00.830665 40837 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 10:02:00.830672 40837 net.cpp:144] Memory required for data: 1406483000
I1027 10:02:00.830677 40837 layer_factory.hpp:77] Creating layer fire8/expand3x3
I1027 10:02:00.830689 40837 net.cpp:84] Creating Layer fire8/expand3x3
I1027 10:02:00.830694 40837 net.cpp:413] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1027 10:02:00.830704 40837 net.cpp:387] fire8/expand3x3 -> fire8/expand3x3
I1027 10:02:00.833669 40837 net.cpp:127] Setting up fire8/expand3x3
I1027 10:02:00.833690 40837 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 10:02:00.833696 40837 net.cpp:144] Memory required for data: 1416518200
I1027 10:02:00.833704 40837 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1027 10:02:00.833724 40837 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1027 10:02:00.833731 40837 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1027 10:02:00.833737 40837 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1027 10:02:00.833742 40837 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I1027 10:02:00.833750 40837 net.cpp:84] Creating Layer fire8/relu_expand3x3
I1027 10:02:00.833756 40837 net.cpp:413] fire8/relu_expand3x3 <- fire8/expand3x3
I1027 10:02:00.833763 40837 net.cpp:374] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I1027 10:02:00.835189 40837 net.cpp:127] Setting up fire8/relu_expand3x3
I1027 10:02:00.835209 40837 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 10:02:00.835216 40837 net.cpp:144] Memory required for data: 1426553400
I1027 10:02:00.835223 40837 layer_factory.hpp:77] Creating layer fire8/concat
I1027 10:02:00.835234 40837 net.cpp:84] Creating Layer fire8/concat
I1027 10:02:00.835240 40837 net.cpp:413] fire8/concat <- fire8/expand1x1
I1027 10:02:00.835247 40837 net.cpp:413] fire8/concat <- fire8/expand3x3
I1027 10:02:00.835256 40837 net.cpp:387] fire8/concat -> fire8/concat
I1027 10:02:00.835294 40837 net.cpp:127] Setting up fire8/concat
I1027 10:02:00.835310 40837 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1027 10:02:00.835315 40837 net.cpp:144] Memory required for data: 1446623800
I1027 10:02:00.835320 40837 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I1027 10:02:00.835332 40837 net.cpp:84] Creating Layer fire9/squeeze1x1
I1027 10:02:00.835337 40837 net.cpp:413] fire9/squeeze1x1 <- fire8/concat
I1027 10:02:00.835350 40837 net.cpp:387] fire9/squeeze1x1 -> fire9/squeeze1x1
I1027 10:02:00.835975 40837 net.cpp:127] Setting up fire9/squeeze1x1
I1027 10:02:00.835988 40837 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1027 10:02:00.835992 40837 net.cpp:144] Memory required for data: 1449132600
I1027 10:02:00.835999 40837 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1027 10:02:00.836012 40837 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1027 10:02:00.836019 40837 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1027 10:02:00.836024 40837 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1027 10:02:00.836030 40837 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I1027 10:02:00.836045 40837 net.cpp:84] Creating Layer fire9/relu_squeeze1x1
I1027 10:02:00.836051 40837 net.cpp:413] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I1027 10:02:00.836061 40837 net.cpp:374] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I1027 10:02:00.836280 40837 net.cpp:127] Setting up fire9/relu_squeeze1x1
I1027 10:02:00.836292 40837 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1027 10:02:00.836303 40837 net.cpp:144] Memory required for data: 1451641400
I1027 10:02:00.836310 40837 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1027 10:02:00.836320 40837 net.cpp:84] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1027 10:02:00.836325 40837 net.cpp:413] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I1027 10:02:00.836334 40837 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1027 10:02:00.836344 40837 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1027 10:02:00.836397 40837 net.cpp:127] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1027 10:02:00.836408 40837 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1027 10:02:00.836414 40837 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1027 10:02:00.836419 40837 net.cpp:144] Memory required for data: 1456659000
I1027 10:02:00.836424 40837 layer_factory.hpp:77] Creating layer fire9/expand1x1
I1027 10:02:00.836433 40837 net.cpp:84] Creating Layer fire9/expand1x1
I1027 10:02:00.836438 40837 net.cpp:413] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1027 10:02:00.836460 40837 net.cpp:387] fire9/expand1x1 -> fire9/expand1x1
I1027 10:02:00.836977 40837 net.cpp:127] Setting up fire9/expand1x1
I1027 10:02:00.836992 40837 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 10:02:00.836997 40837 net.cpp:144] Memory required for data: 1466694200
I1027 10:02:00.837015 40837 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1027 10:02:00.837024 40837 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1027 10:02:00.837030 40837 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1027 10:02:00.837036 40837 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1027 10:02:00.837041 40837 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I1027 10:02:00.837051 40837 net.cpp:84] Creating Layer fire9/relu_expand1x1
I1027 10:02:00.837057 40837 net.cpp:413] fire9/relu_expand1x1 <- fire9/expand1x1
I1027 10:02:00.837064 40837 net.cpp:374] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I1027 10:02:00.837308 40837 net.cpp:127] Setting up fire9/relu_expand1x1
I1027 10:02:00.837322 40837 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 10:02:00.837329 40837 net.cpp:144] Memory required for data: 1476729400
I1027 10:02:00.837335 40837 layer_factory.hpp:77] Creating layer fire9/expand3x3
I1027 10:02:00.837348 40837 net.cpp:84] Creating Layer fire9/expand3x3
I1027 10:02:00.837355 40837 net.cpp:413] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1027 10:02:00.837363 40837 net.cpp:387] fire9/expand3x3 -> fire9/expand3x3
I1027 10:02:00.840334 40837 net.cpp:127] Setting up fire9/expand3x3
I1027 10:02:00.840355 40837 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 10:02:00.840361 40837 net.cpp:144] Memory required for data: 1486764600
I1027 10:02:00.840368 40837 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1027 10:02:00.840384 40837 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1027 10:02:00.840390 40837 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1027 10:02:00.840396 40837 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1027 10:02:00.840400 40837 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I1027 10:02:00.840409 40837 net.cpp:84] Creating Layer fire9/relu_expand3x3
I1027 10:02:00.840418 40837 net.cpp:413] fire9/relu_expand3x3 <- fire9/expand3x3
I1027 10:02:00.840425 40837 net.cpp:374] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I1027 10:02:00.840657 40837 net.cpp:127] Setting up fire9/relu_expand3x3
I1027 10:02:00.840670 40837 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 10:02:00.840677 40837 net.cpp:144] Memory required for data: 1496799800
I1027 10:02:00.840682 40837 layer_factory.hpp:77] Creating layer fire9/concat
I1027 10:02:00.840692 40837 net.cpp:84] Creating Layer fire9/concat
I1027 10:02:00.840697 40837 net.cpp:413] fire9/concat <- fire9/expand1x1
I1027 10:02:00.840703 40837 net.cpp:413] fire9/concat <- fire9/expand3x3
I1027 10:02:00.840710 40837 net.cpp:387] fire9/concat -> fire9/concat
I1027 10:02:00.840749 40837 net.cpp:127] Setting up fire9/concat
I1027 10:02:00.840770 40837 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1027 10:02:00.840773 40837 net.cpp:144] Memory required for data: 1516870200
I1027 10:02:00.840778 40837 layer_factory.hpp:77] Creating layer drop9
I1027 10:02:00.840786 40837 net.cpp:84] Creating Layer drop9
I1027 10:02:00.840792 40837 net.cpp:413] drop9 <- fire9/concat
I1027 10:02:00.840801 40837 net.cpp:374] drop9 -> fire9/concat (in-place)
I1027 10:02:00.840829 40837 net.cpp:127] Setting up drop9
I1027 10:02:00.840837 40837 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1027 10:02:00.840842 40837 net.cpp:144] Memory required for data: 1536940600
I1027 10:02:00.840847 40837 layer_factory.hpp:77] Creating layer conv10
I1027 10:02:00.840865 40837 net.cpp:84] Creating Layer conv10
I1027 10:02:00.840888 40837 net.cpp:413] conv10 <- fire9/concat
I1027 10:02:00.840898 40837 net.cpp:387] conv10 -> conv10
I1027 10:02:00.850642 40837 net.cpp:127] Setting up conv10
I1027 10:02:00.850667 40837 net.cpp:136] Top shape: 50 1000 14 14 (9800000)
I1027 10:02:00.850674 40837 net.cpp:144] Memory required for data: 1576140600
I1027 10:02:00.850683 40837 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1027 10:02:00.850690 40837 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1027 10:02:00.850697 40837 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1027 10:02:00.850702 40837 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1027 10:02:00.850706 40837 layer_factory.hpp:77] Creating layer relu_conv10
I1027 10:02:00.850718 40837 net.cpp:84] Creating Layer relu_conv10
I1027 10:02:00.850724 40837 net.cpp:413] relu_conv10 <- conv10
I1027 10:02:00.850731 40837 net.cpp:374] relu_conv10 -> conv10 (in-place)
I1027 10:02:00.852144 40837 net.cpp:127] Setting up relu_conv10
I1027 10:02:00.852167 40837 net.cpp:136] Top shape: 50 1000 14 14 (9800000)
I1027 10:02:00.852174 40837 net.cpp:144] Memory required for data: 1615340600
I1027 10:02:00.852180 40837 layer_factory.hpp:77] Creating layer pool10
I1027 10:02:00.852190 40837 net.cpp:84] Creating Layer pool10
I1027 10:02:00.852195 40837 net.cpp:413] pool10 <- conv10
I1027 10:02:00.852202 40837 net.cpp:387] pool10 -> pool10
I1027 10:02:00.852458 40837 net.cpp:127] Setting up pool10
I1027 10:02:00.852473 40837 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1027 10:02:00.852478 40837 net.cpp:144] Memory required for data: 1615540600
I1027 10:02:00.852484 40837 layer_factory.hpp:77] Creating layer pool10_pool10_0_split
I1027 10:02:00.852493 40837 net.cpp:84] Creating Layer pool10_pool10_0_split
I1027 10:02:00.852497 40837 net.cpp:413] pool10_pool10_0_split <- pool10
I1027 10:02:00.852507 40837 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_0
I1027 10:02:00.852522 40837 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_1
I1027 10:02:00.852530 40837 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_2
I1027 10:02:00.852597 40837 net.cpp:127] Setting up pool10_pool10_0_split
I1027 10:02:00.852607 40837 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1027 10:02:00.852617 40837 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1027 10:02:00.852622 40837 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1027 10:02:00.852627 40837 net.cpp:144] Memory required for data: 1616140600
I1027 10:02:00.852630 40837 layer_factory.hpp:77] Creating layer loss
I1027 10:02:00.852640 40837 net.cpp:84] Creating Layer loss
I1027 10:02:00.852645 40837 net.cpp:413] loss <- pool10_pool10_0_split_0
I1027 10:02:00.852653 40837 net.cpp:413] loss <- label_data_1_split_0
I1027 10:02:00.852658 40837 net.cpp:387] loss -> loss
I1027 10:02:00.852669 40837 layer_factory.hpp:77] Creating layer loss
I1027 10:02:00.853041 40837 net.cpp:127] Setting up loss
I1027 10:02:00.853055 40837 net.cpp:136] Top shape: (1)
I1027 10:02:00.853060 40837 net.cpp:139]     with loss weight 1
I1027 10:02:00.853072 40837 net.cpp:144] Memory required for data: 1616140604
I1027 10:02:00.853077 40837 layer_factory.hpp:77] Creating layer accuracy_top1
I1027 10:02:00.853096 40837 net.cpp:84] Creating Layer accuracy_top1
I1027 10:02:00.853101 40837 net.cpp:413] accuracy_top1 <- pool10_pool10_0_split_1
I1027 10:02:00.853108 40837 net.cpp:413] accuracy_top1 <- label_data_1_split_1
I1027 10:02:00.853116 40837 net.cpp:387] accuracy_top1 -> accuracy_top1
I1027 10:02:00.853129 40837 net.cpp:127] Setting up accuracy_top1
I1027 10:02:00.853135 40837 net.cpp:136] Top shape: (1)
I1027 10:02:00.853140 40837 net.cpp:144] Memory required for data: 1616140608
I1027 10:02:00.853145 40837 layer_factory.hpp:77] Creating layer accuracy_top5
I1027 10:02:00.853155 40837 net.cpp:84] Creating Layer accuracy_top5
I1027 10:02:00.853160 40837 net.cpp:413] accuracy_top5 <- pool10_pool10_0_split_2
I1027 10:02:00.853166 40837 net.cpp:413] accuracy_top5 <- label_data_1_split_2
I1027 10:02:00.853191 40837 net.cpp:387] accuracy_top5 -> accuracy_top5
I1027 10:02:00.853210 40837 net.cpp:127] Setting up accuracy_top5
I1027 10:02:00.853224 40837 net.cpp:136] Top shape: (1)
I1027 10:02:00.853229 40837 net.cpp:144] Memory required for data: 1616140612
I1027 10:02:00.853235 40837 net.cpp:207] accuracy_top5 does not need backward computation.
I1027 10:02:00.853240 40837 net.cpp:207] accuracy_top1 does not need backward computation.
I1027 10:02:00.853245 40837 net.cpp:205] loss needs backward computation.
I1027 10:02:00.853250 40837 net.cpp:205] pool10_pool10_0_split needs backward computation.
I1027 10:02:00.853255 40837 net.cpp:205] pool10 needs backward computation.
I1027 10:02:00.853260 40837 net.cpp:205] relu_conv10 needs backward computation.
I1027 10:02:00.853266 40837 net.cpp:205] conv10 needs backward computation.
I1027 10:02:00.853271 40837 net.cpp:205] drop9 needs backward computation.
I1027 10:02:00.853274 40837 net.cpp:205] fire9/concat needs backward computation.
I1027 10:02:00.853281 40837 net.cpp:205] fire9/relu_expand3x3 needs backward computation.
I1027 10:02:00.853286 40837 net.cpp:205] fire9/expand3x3 needs backward computation.
I1027 10:02:00.853291 40837 net.cpp:205] fire9/relu_expand1x1 needs backward computation.
I1027 10:02:00.853294 40837 net.cpp:205] fire9/expand1x1 needs backward computation.
I1027 10:02:00.853307 40837 net.cpp:205] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I1027 10:02:00.853312 40837 net.cpp:205] fire9/relu_squeeze1x1 needs backward computation.
I1027 10:02:00.853317 40837 net.cpp:205] fire9/squeeze1x1 needs backward computation.
I1027 10:02:00.853322 40837 net.cpp:205] fire8/concat needs backward computation.
I1027 10:02:00.853328 40837 net.cpp:205] fire8/relu_expand3x3 needs backward computation.
I1027 10:02:00.853332 40837 net.cpp:205] fire8/expand3x3 needs backward computation.
I1027 10:02:00.853338 40837 net.cpp:205] fire8/relu_expand1x1 needs backward computation.
I1027 10:02:00.853348 40837 net.cpp:205] fire8/expand1x1 needs backward computation.
I1027 10:02:00.853353 40837 net.cpp:205] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I1027 10:02:00.853358 40837 net.cpp:205] fire8/relu_squeeze1x1 needs backward computation.
I1027 10:02:00.853363 40837 net.cpp:205] fire8/squeeze1x1 needs backward computation.
I1027 10:02:00.853368 40837 net.cpp:205] fire7/concat needs backward computation.
I1027 10:02:00.853373 40837 net.cpp:205] fire7/relu_expand3x3 needs backward computation.
I1027 10:02:00.853377 40837 net.cpp:205] fire7/expand3x3 needs backward computation.
I1027 10:02:00.853382 40837 net.cpp:205] fire7/relu_expand1x1 needs backward computation.
I1027 10:02:00.853386 40837 net.cpp:205] fire7/expand1x1 needs backward computation.
I1027 10:02:00.853391 40837 net.cpp:205] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I1027 10:02:00.853396 40837 net.cpp:205] fire7/relu_squeeze1x1 needs backward computation.
I1027 10:02:00.853400 40837 net.cpp:205] fire7/squeeze1x1 needs backward computation.
I1027 10:02:00.853405 40837 net.cpp:205] fire6/concat needs backward computation.
I1027 10:02:00.853410 40837 net.cpp:205] fire6/relu_expand3x3 needs backward computation.
I1027 10:02:00.853415 40837 net.cpp:205] fire6/expand3x3 needs backward computation.
I1027 10:02:00.853420 40837 net.cpp:205] fire6/relu_expand1x1 needs backward computation.
I1027 10:02:00.853425 40837 net.cpp:205] fire6/expand1x1 needs backward computation.
I1027 10:02:00.853430 40837 net.cpp:205] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I1027 10:02:00.853433 40837 net.cpp:205] fire6/relu_squeeze1x1 needs backward computation.
I1027 10:02:00.853438 40837 net.cpp:205] fire6/squeeze1x1 needs backward computation.
I1027 10:02:00.853443 40837 net.cpp:205] pool5 needs backward computation.
I1027 10:02:00.853447 40837 net.cpp:205] fire5/concat needs backward computation.
I1027 10:02:00.853452 40837 net.cpp:205] fire5/relu_expand3x3 needs backward computation.
I1027 10:02:00.853464 40837 net.cpp:205] fire5/expand3x3 needs backward computation.
I1027 10:02:00.853469 40837 net.cpp:205] fire5/relu_expand1x1 needs backward computation.
I1027 10:02:00.853474 40837 net.cpp:205] fire5/expand1x1 needs backward computation.
I1027 10:02:00.853479 40837 net.cpp:205] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I1027 10:02:00.853484 40837 net.cpp:205] fire5/relu_squeeze1x1 needs backward computation.
I1027 10:02:00.853488 40837 net.cpp:205] fire5/squeeze1x1 needs backward computation.
I1027 10:02:00.853493 40837 net.cpp:205] fire4/concat needs backward computation.
I1027 10:02:00.853498 40837 net.cpp:205] fire4/relu_expand3x3 needs backward computation.
I1027 10:02:00.853503 40837 net.cpp:205] fire4/expand3x3 needs backward computation.
I1027 10:02:00.853507 40837 net.cpp:205] fire4/relu_expand1x1 needs backward computation.
I1027 10:02:00.853513 40837 net.cpp:205] fire4/expand1x1 needs backward computation.
I1027 10:02:00.853516 40837 net.cpp:205] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I1027 10:02:00.853521 40837 net.cpp:205] fire4/relu_squeeze1x1 needs backward computation.
I1027 10:02:00.853526 40837 net.cpp:205] fire4/squeeze1x1 needs backward computation.
I1027 10:02:00.853531 40837 net.cpp:205] pool3 needs backward computation.
I1027 10:02:00.853535 40837 net.cpp:205] fire3/concat needs backward computation.
I1027 10:02:00.853540 40837 net.cpp:205] fire3/relu_expand3x3 needs backward computation.
I1027 10:02:00.853545 40837 net.cpp:205] fire3/expand3x3 needs backward computation.
I1027 10:02:00.853550 40837 net.cpp:205] fire3/relu_expand1x1 needs backward computation.
I1027 10:02:00.853554 40837 net.cpp:205] fire3/expand1x1 needs backward computation.
I1027 10:02:00.853559 40837 net.cpp:205] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I1027 10:02:00.853564 40837 net.cpp:205] fire3/relu_squeeze1x1 needs backward computation.
I1027 10:02:00.853569 40837 net.cpp:205] fire3/squeeze1x1 needs backward computation.
I1027 10:02:00.853583 40837 net.cpp:205] fire2/concat needs backward computation.
I1027 10:02:00.853590 40837 net.cpp:205] fire2/relu_expand3x3 needs backward computation.
I1027 10:02:00.853593 40837 net.cpp:205] fire2/expand3x3 needs backward computation.
I1027 10:02:00.853598 40837 net.cpp:205] fire2/relu_expand1x1 needs backward computation.
I1027 10:02:00.853603 40837 net.cpp:205] fire2/expand1x1 needs backward computation.
I1027 10:02:00.853608 40837 net.cpp:205] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I1027 10:02:00.853613 40837 net.cpp:205] fire2/relu_squeeze1x1 needs backward computation.
I1027 10:02:00.853617 40837 net.cpp:205] fire2/squeeze1x1 needs backward computation.
I1027 10:02:00.853622 40837 net.cpp:205] pool1 needs backward computation.
I1027 10:02:00.853627 40837 net.cpp:205] relu_conv1 needs backward computation.
I1027 10:02:00.853631 40837 net.cpp:205] conv1 needs backward computation.
I1027 10:02:00.853638 40837 net.cpp:207] label_data_1_split does not need backward computation.
I1027 10:02:00.853643 40837 net.cpp:207] data does not need backward computation.
I1027 10:02:00.853648 40837 net.cpp:249] This network produces output accuracy_top1
I1027 10:02:00.853653 40837 net.cpp:249] This network produces output accuracy_top5
I1027 10:02:00.853658 40837 net.cpp:249] This network produces output loss
I1027 10:02:00.853714 40837 net.cpp:262] Network initialization done.
I1027 10:02:00.853976 40837 solver.cpp:56] Solver scaffolding done.
I1027 10:02:00.858681 40837 caffe.cpp:242] Resuming from SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_64500.solverstate
I1027 10:02:00.880089 40837 sgd_solver.cpp:372] SGDSolver: restoring history
I1027 10:02:00.892385 40837 caffe.cpp:248] Starting Optimization
I1027 10:02:04.752377 43021 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_0.prototxt
I1027 10:02:04.753240 43024 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_0.prototxt
I1027 10:02:04.761855 43022 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_0.prototxt
I1027 10:02:05.405656 43021 sgd_solver.cpp:372] SGDSolver: restoring history
I1027 10:02:05.405722 43022 sgd_solver.cpp:372] SGDSolver: restoring history
I1027 10:02:05.405725 43024 sgd_solver.cpp:372] SGDSolver: restoring history
I1027 10:02:05.657824 40837 solver.cpp:276] Solving SqueezeNet
I1027 10:02:05.657879 40837 solver.cpp:277] Learning Rate Policy: poly
I1027 10:02:05.658355 40837 solver.cpp:334] Iteration 64500, Testing net (#0)
I1027 10:02:37.139999 40837 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54216
I1027 10:02:37.140192 40837 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77984
I1027 10:02:37.140208 40837 solver.cpp:401]     Test net output #2: loss = 2.05084 (* 1 = 2.05084 loss)
I1027 10:02:52.930402 40837 solver.cpp:222] Iteration 64520 (1364.94 iter/s, 47.2697s/40 iters), loss = 1.54545
I1027 10:02:52.930474 40837 solver.cpp:241]     Train net output #0: loss = 1.54545 (* 1 = 1.54545 loss)
I1027 10:02:52.930490 40837 sgd_solver.cpp:105] Iteration 64520, lr = 0.00563982
I1027 10:03:22.298666 40837 solver.cpp:222] Iteration 64560 (1.36207 iter/s, 29.3671s/40 iters), loss = 1.42419
I1027 10:03:22.298904 40837 solver.cpp:241]     Train net output #0: loss = 1.42419 (* 1 = 1.42419 loss)
I1027 10:03:22.298923 40837 sgd_solver.cpp:105] Iteration 64560, lr = 0.00563726
I1027 10:03:51.770043 40837 solver.cpp:222] Iteration 64600 (1.35731 iter/s, 29.47s/40 iters), loss = 1.77421
I1027 10:03:51.770113 40837 solver.cpp:241]     Train net output #0: loss = 1.77421 (* 1 = 1.77421 loss)
I1027 10:03:51.770129 40837 sgd_solver.cpp:105] Iteration 64600, lr = 0.00563469
I1027 10:04:21.240316 40837 solver.cpp:222] Iteration 64640 (1.35735 iter/s, 29.4691s/40 iters), loss = 1.73137
I1027 10:04:21.240504 40837 solver.cpp:241]     Train net output #0: loss = 1.73137 (* 1 = 1.73137 loss)
I1027 10:04:21.240546 40837 sgd_solver.cpp:105] Iteration 64640, lr = 0.00563212
I1027 10:04:50.720326 40837 solver.cpp:222] Iteration 64680 (1.35691 iter/s, 29.4787s/40 iters), loss = 2.13066
I1027 10:04:50.720394 40837 solver.cpp:241]     Train net output #0: loss = 2.13066 (* 1 = 2.13066 loss)
I1027 10:04:50.720412 40837 sgd_solver.cpp:105] Iteration 64680, lr = 0.00562956
I1027 10:05:20.130581 40837 solver.cpp:222] Iteration 64720 (1.36012 iter/s, 29.4091s/40 iters), loss = 1.75645
I1027 10:05:20.130744 40837 solver.cpp:241]     Train net output #0: loss = 1.75645 (* 1 = 1.75645 loss)
I1027 10:05:20.130762 40837 sgd_solver.cpp:105] Iteration 64720, lr = 0.00562699
I1027 10:05:49.560652 40837 solver.cpp:222] Iteration 64760 (1.35921 iter/s, 29.4288s/40 iters), loss = 1.86828
I1027 10:05:49.560732 40837 solver.cpp:241]     Train net output #0: loss = 1.86828 (* 1 = 1.86828 loss)
I1027 10:05:49.560748 40837 sgd_solver.cpp:105] Iteration 64760, lr = 0.00562443
I1027 10:06:18.961416 40837 solver.cpp:222] Iteration 64800 (1.36056 iter/s, 29.3996s/40 iters), loss = 1.86407
I1027 10:06:18.961607 40837 solver.cpp:241]     Train net output #0: loss = 1.86407 (* 1 = 1.86407 loss)
I1027 10:06:18.961627 40837 sgd_solver.cpp:105] Iteration 64800, lr = 0.00562186
I1027 10:06:48.375000 40837 solver.cpp:222] Iteration 64840 (1.35998 iter/s, 29.4123s/40 iters), loss = 1.64247
I1027 10:06:48.375066 40837 solver.cpp:241]     Train net output #0: loss = 1.64247 (* 1 = 1.64247 loss)
I1027 10:06:48.375082 40837 sgd_solver.cpp:105] Iteration 64840, lr = 0.0056193
I1027 10:07:17.778105 40837 solver.cpp:222] Iteration 64880 (1.36046 iter/s, 29.4019s/40 iters), loss = 1.89891
I1027 10:07:17.778327 40837 solver.cpp:241]     Train net output #0: loss = 1.89891 (* 1 = 1.89891 loss)
I1027 10:07:17.778352 40837 sgd_solver.cpp:105] Iteration 64880, lr = 0.00561673
I1027 10:07:47.221030 40837 solver.cpp:222] Iteration 64920 (1.35862 iter/s, 29.4416s/40 iters), loss = 1.78836
I1027 10:07:47.221096 40837 solver.cpp:241]     Train net output #0: loss = 1.78836 (* 1 = 1.78836 loss)
I1027 10:07:47.221112 40837 sgd_solver.cpp:105] Iteration 64920, lr = 0.00561417
I1027 10:08:16.817450 40837 solver.cpp:222] Iteration 64960 (1.35157 iter/s, 29.5952s/40 iters), loss = 1.87411
I1027 10:08:16.817739 40837 solver.cpp:241]     Train net output #0: loss = 1.87411 (* 1 = 1.87411 loss)
I1027 10:08:16.817759 40837 sgd_solver.cpp:105] Iteration 64960, lr = 0.0056116
I1027 10:08:45.494829 40837 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_65000.caffemodel
I1027 10:08:45.551216 40837 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_65000.solverstate
I1027 10:08:45.569661 40837 solver.cpp:334] Iteration 65000, Testing net (#0)
I1027 10:09:16.536705 42906 data_layer.cpp:73] Restarting data prefetching from start.
I1027 10:09:16.742053 40837 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53568
I1027 10:09:16.742107 40837 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77512
I1027 10:09:16.742120 40837 solver.cpp:401]     Test net output #2: loss = 2.05976 (* 1 = 2.05976 loss)
I1027 10:09:17.484577 40837 solver.cpp:222] Iteration 65000 (0.659364 iter/s, 60.6646s/40 iters), loss = 1.67862
I1027 10:09:17.484619 40837 solver.cpp:241]     Train net output #0: loss = 1.67862 (* 1 = 1.67862 loss)
I1027 10:09:17.484637 40837 sgd_solver.cpp:105] Iteration 65000, lr = 0.00560904
I1027 10:09:46.922425 40837 solver.cpp:222] Iteration 65040 (1.35885 iter/s, 29.4367s/40 iters), loss = 1.82008
I1027 10:09:46.922610 40837 solver.cpp:241]     Train net output #0: loss = 1.82008 (* 1 = 1.82008 loss)
I1027 10:09:46.922626 40837 sgd_solver.cpp:105] Iteration 65040, lr = 0.00560647
I1027 10:09:48.385656 40837 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_65043.caffemodel
I1027 10:09:48.424814 40837 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_65043.solverstate
I1027 10:09:48.441500 40837 solver.cpp:298] Optimization stopped early.
nohup: ignoring input
I1027 13:10:17.886576  9023 caffe.cpp:218] Using GPUs 0, 1, 2, 3
I1027 13:10:17.887739  9023 caffe.cpp:223] GPU 0: Tesla P40
I1027 13:10:17.888150  9023 caffe.cpp:223] GPU 1: Tesla P40
I1027 13:10:17.888547  9023 caffe.cpp:223] GPU 2: Tesla P40
I1027 13:10:17.888942  9023 caffe.cpp:223] GPU 3: Tesla P40
I1027 13:10:18.528208  9023 solver.cpp:44] Initializing solver from parameters: 
test_iter: 500
test_interval: 500
base_lr: 0.01
display: 40
max_iter: 170000
lr_policy: "poly"
power: 1.2
momentum: 0.9
weight_decay: 0.0002
snapshot: 1000
snapshot_prefix: "SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20"
solver_mode: GPU
device_id: 0
random_seed: 42
net: "SqueezeNet/SqueezeNet_v1.1/train_val_inq_0.prototxt"
train_state {
  level: 0
  stage: ""
}
I1027 13:10:18.528641  9023 solver.cpp:87] Creating training net from net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_0.prototxt
I1027 13:10:18.542604  9023 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1027 13:10:18.542673  9023 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top1
I1027 13:10:18.542683  9023 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top5
I1027 13:10:18.543395  9023 net.cpp:51] Initializing net from parameters: 
name: "SqueezeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/data/caffe-imagenet/ilsvrc12_train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "INQConvolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "fire3/concat"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire4/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool3"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "fire5/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire4/concat"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "fire5/concat"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire6/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool5"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "fire9/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire8/concat"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "INQConvolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "pool10"
  bottom: "label"
  top: "loss"
}
I1027 13:10:18.543820  9023 layer_factory.hpp:77] Creating layer data
I1027 13:10:18.544179  9023 db_lmdb.cpp:35] Opened lmdb /home/data/caffe-imagenet/ilsvrc12_train_lmdb
I1027 13:10:18.544229  9023 net.cpp:84] Creating Layer data
I1027 13:10:18.544243  9023 net.cpp:387] data -> data
I1027 13:10:18.544273  9023 net.cpp:387] data -> label
I1027 13:10:18.546067  9023 data_layer.cpp:45] output data size: 128,3,227,227
I1027 13:10:18.747879  9023 net.cpp:127] Setting up data
I1027 13:10:18.747949  9023 net.cpp:136] Top shape: 128 3 227 227 (19787136)
I1027 13:10:18.747959  9023 net.cpp:136] Top shape: 128 (128)
I1027 13:10:18.747972  9023 net.cpp:144] Memory required for data: 79149056
I1027 13:10:18.747987  9023 layer_factory.hpp:77] Creating layer conv1
I1027 13:10:18.748018  9023 net.cpp:84] Creating Layer conv1
I1027 13:10:18.748028  9023 net.cpp:413] conv1 <- data
I1027 13:10:18.748047  9023 net.cpp:387] conv1 -> conv1
I1027 13:10:18.751205  9023 net.cpp:127] Setting up conv1
I1027 13:10:18.751226  9023 net.cpp:136] Top shape: 128 64 113 113 (104603648)
I1027 13:10:18.751232  9023 net.cpp:144] Memory required for data: 497563648
I1027 13:10:18.751252  9023 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1027 13:10:18.751266  9023 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1027 13:10:18.751276  9023 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1027 13:10:18.751286  9023 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1027 13:10:18.751292  9023 layer_factory.hpp:77] Creating layer relu_conv1
I1027 13:10:18.751314  9023 net.cpp:84] Creating Layer relu_conv1
I1027 13:10:18.751322  9023 net.cpp:413] relu_conv1 <- conv1
I1027 13:10:18.751329  9023 net.cpp:374] relu_conv1 -> conv1 (in-place)
I1027 13:10:19.136052  9023 net.cpp:127] Setting up relu_conv1
I1027 13:10:19.136106  9023 net.cpp:136] Top shape: 128 64 113 113 (104603648)
I1027 13:10:19.136111  9023 net.cpp:144] Memory required for data: 915978240
I1027 13:10:19.136121  9023 layer_factory.hpp:77] Creating layer pool1
I1027 13:10:19.136142  9023 net.cpp:84] Creating Layer pool1
I1027 13:10:19.136149  9023 net.cpp:413] pool1 <- conv1
I1027 13:10:19.136162  9023 net.cpp:387] pool1 -> pool1
I1027 13:10:19.136262  9023 net.cpp:127] Setting up pool1
I1027 13:10:19.136276  9023 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 13:10:19.136283  9023 net.cpp:144] Memory required for data: 1018738688
I1027 13:10:19.136343  9023 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I1027 13:10:19.136361  9023 net.cpp:84] Creating Layer fire2/squeeze1x1
I1027 13:10:19.136368  9023 net.cpp:413] fire2/squeeze1x1 <- pool1
I1027 13:10:19.136375  9023 net.cpp:387] fire2/squeeze1x1 -> fire2/squeeze1x1
I1027 13:10:19.138133  9023 net.cpp:127] Setting up fire2/squeeze1x1
I1027 13:10:19.138154  9023 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1027 13:10:19.138160  9023 net.cpp:144] Memory required for data: 1044428800
I1027 13:10:19.138171  9023 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1027 13:10:19.138181  9023 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1027 13:10:19.138190  9023 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1027 13:10:19.138197  9023 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1027 13:10:19.138203  9023 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I1027 13:10:19.138213  9023 net.cpp:84] Creating Layer fire2/relu_squeeze1x1
I1027 13:10:19.138219  9023 net.cpp:413] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I1027 13:10:19.138226  9023 net.cpp:374] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I1027 13:10:19.139549  9023 net.cpp:127] Setting up fire2/relu_squeeze1x1
I1027 13:10:19.139569  9023 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1027 13:10:19.139575  9023 net.cpp:144] Memory required for data: 1070118912
I1027 13:10:19.139581  9023 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1027 13:10:19.139593  9023 net.cpp:84] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1027 13:10:19.139598  9023 net.cpp:413] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I1027 13:10:19.139606  9023 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1027 13:10:19.139618  9023 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1027 13:10:19.139668  9023 net.cpp:127] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1027 13:10:19.139678  9023 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1027 13:10:19.139685  9023 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1027 13:10:19.139691  9023 net.cpp:144] Memory required for data: 1121499136
I1027 13:10:19.139698  9023 layer_factory.hpp:77] Creating layer fire2/expand1x1
I1027 13:10:19.139710  9023 net.cpp:84] Creating Layer fire2/expand1x1
I1027 13:10:19.139719  9023 net.cpp:413] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1027 13:10:19.139726  9023 net.cpp:387] fire2/expand1x1 -> fire2/expand1x1
I1027 13:10:19.140033  9023 net.cpp:127] Setting up fire2/expand1x1
I1027 13:10:19.140044  9023 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 13:10:19.140049  9023 net.cpp:144] Memory required for data: 1224259584
I1027 13:10:19.140060  9023 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1027 13:10:19.140072  9023 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1027 13:10:19.140079  9023 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1027 13:10:19.140084  9023 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1027 13:10:19.140089  9023 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I1027 13:10:19.140099  9023 net.cpp:84] Creating Layer fire2/relu_expand1x1
I1027 13:10:19.140103  9023 net.cpp:413] fire2/relu_expand1x1 <- fire2/expand1x1
I1027 13:10:19.140111  9023 net.cpp:374] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I1027 13:10:19.140306  9023 net.cpp:127] Setting up fire2/relu_expand1x1
I1027 13:10:19.140321  9023 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 13:10:19.140333  9023 net.cpp:144] Memory required for data: 1327020032
I1027 13:10:19.140339  9023 layer_factory.hpp:77] Creating layer fire2/expand3x3
I1027 13:10:19.140367  9023 net.cpp:84] Creating Layer fire2/expand3x3
I1027 13:10:19.140375  9023 net.cpp:413] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1027 13:10:19.140384  9023 net.cpp:387] fire2/expand3x3 -> fire2/expand3x3
I1027 13:10:19.140769  9023 net.cpp:127] Setting up fire2/expand3x3
I1027 13:10:19.140782  9023 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 13:10:19.140787  9023 net.cpp:144] Memory required for data: 1429780480
I1027 13:10:19.140794  9023 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1027 13:10:19.140801  9023 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1027 13:10:19.140807  9023 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1027 13:10:19.140816  9023 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1027 13:10:19.140821  9023 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I1027 13:10:19.140830  9023 net.cpp:84] Creating Layer fire2/relu_expand3x3
I1027 13:10:19.140835  9023 net.cpp:413] fire2/relu_expand3x3 <- fire2/expand3x3
I1027 13:10:19.140841  9023 net.cpp:374] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I1027 13:10:19.141026  9023 net.cpp:127] Setting up fire2/relu_expand3x3
I1027 13:10:19.141038  9023 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 13:10:19.141043  9023 net.cpp:144] Memory required for data: 1532540928
I1027 13:10:19.141049  9023 layer_factory.hpp:77] Creating layer fire2/concat
I1027 13:10:19.141063  9023 net.cpp:84] Creating Layer fire2/concat
I1027 13:10:19.141073  9023 net.cpp:413] fire2/concat <- fire2/expand1x1
I1027 13:10:19.141080  9023 net.cpp:413] fire2/concat <- fire2/expand3x3
I1027 13:10:19.141088  9023 net.cpp:387] fire2/concat -> fire2/concat
I1027 13:10:19.141120  9023 net.cpp:127] Setting up fire2/concat
I1027 13:10:19.141129  9023 net.cpp:136] Top shape: 128 128 56 56 (51380224)
I1027 13:10:19.141134  9023 net.cpp:144] Memory required for data: 1738061824
I1027 13:10:19.141139  9023 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I1027 13:10:19.141149  9023 net.cpp:84] Creating Layer fire3/squeeze1x1
I1027 13:10:19.141157  9023 net.cpp:413] fire3/squeeze1x1 <- fire2/concat
I1027 13:10:19.141165  9023 net.cpp:387] fire3/squeeze1x1 -> fire3/squeeze1x1
I1027 13:10:19.141486  9023 net.cpp:127] Setting up fire3/squeeze1x1
I1027 13:10:19.141499  9023 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1027 13:10:19.141505  9023 net.cpp:144] Memory required for data: 1763751936
I1027 13:10:19.141515  9023 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1027 13:10:19.141522  9023 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1027 13:10:19.141528  9023 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1027 13:10:19.141535  9023 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1027 13:10:19.141541  9023 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I1027 13:10:19.141548  9023 net.cpp:84] Creating Layer fire3/relu_squeeze1x1
I1027 13:10:19.141554  9023 net.cpp:413] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I1027 13:10:19.141562  9023 net.cpp:374] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I1027 13:10:19.142889  9023 net.cpp:127] Setting up fire3/relu_squeeze1x1
I1027 13:10:19.142907  9023 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1027 13:10:19.142913  9023 net.cpp:144] Memory required for data: 1789442048
I1027 13:10:19.142920  9023 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1027 13:10:19.142928  9023 net.cpp:84] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1027 13:10:19.142935  9023 net.cpp:413] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I1027 13:10:19.142953  9023 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1027 13:10:19.142964  9023 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1027 13:10:19.143024  9023 net.cpp:127] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1027 13:10:19.143034  9023 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1027 13:10:19.143043  9023 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1027 13:10:19.143049  9023 net.cpp:144] Memory required for data: 1840822272
I1027 13:10:19.143054  9023 layer_factory.hpp:77] Creating layer fire3/expand1x1
I1027 13:10:19.143064  9023 net.cpp:84] Creating Layer fire3/expand1x1
I1027 13:10:19.143069  9023 net.cpp:413] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1027 13:10:19.143076  9023 net.cpp:387] fire3/expand1x1 -> fire3/expand1x1
I1027 13:10:19.143378  9023 net.cpp:127] Setting up fire3/expand1x1
I1027 13:10:19.143390  9023 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 13:10:19.143396  9023 net.cpp:144] Memory required for data: 1943582720
I1027 13:10:19.143409  9023 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1027 13:10:19.143417  9023 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1027 13:10:19.143424  9023 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1027 13:10:19.143435  9023 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1027 13:10:19.143452  9023 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I1027 13:10:19.143461  9023 net.cpp:84] Creating Layer fire3/relu_expand1x1
I1027 13:10:19.143467  9023 net.cpp:413] fire3/relu_expand1x1 <- fire3/expand1x1
I1027 13:10:19.143473  9023 net.cpp:374] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I1027 13:10:19.143653  9023 net.cpp:127] Setting up fire3/relu_expand1x1
I1027 13:10:19.143666  9023 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 13:10:19.143671  9023 net.cpp:144] Memory required for data: 2046343168
I1027 13:10:19.143677  9023 layer_factory.hpp:77] Creating layer fire3/expand3x3
I1027 13:10:19.143689  9023 net.cpp:84] Creating Layer fire3/expand3x3
I1027 13:10:19.143695  9023 net.cpp:413] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1027 13:10:19.143703  9023 net.cpp:387] fire3/expand3x3 -> fire3/expand3x3
I1027 13:10:19.144070  9023 net.cpp:127] Setting up fire3/expand3x3
I1027 13:10:19.144081  9023 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 13:10:19.144088  9023 net.cpp:144] Memory required for data: 2149103616
I1027 13:10:19.144094  9023 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1027 13:10:19.144101  9023 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1027 13:10:19.144106  9023 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1027 13:10:19.144112  9023 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1027 13:10:19.144117  9023 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I1027 13:10:19.144125  9023 net.cpp:84] Creating Layer fire3/relu_expand3x3
I1027 13:10:19.144131  9023 net.cpp:413] fire3/relu_expand3x3 <- fire3/expand3x3
I1027 13:10:19.144138  9023 net.cpp:374] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I1027 13:10:19.144325  9023 net.cpp:127] Setting up fire3/relu_expand3x3
I1027 13:10:19.144338  9023 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1027 13:10:19.144343  9023 net.cpp:144] Memory required for data: 2251864064
I1027 13:10:19.144351  9023 layer_factory.hpp:77] Creating layer fire3/concat
I1027 13:10:19.144359  9023 net.cpp:84] Creating Layer fire3/concat
I1027 13:10:19.144364  9023 net.cpp:413] fire3/concat <- fire3/expand1x1
I1027 13:10:19.144373  9023 net.cpp:413] fire3/concat <- fire3/expand3x3
I1027 13:10:19.144381  9023 net.cpp:387] fire3/concat -> fire3/concat
I1027 13:10:19.144419  9023 net.cpp:127] Setting up fire3/concat
I1027 13:10:19.144429  9023 net.cpp:136] Top shape: 128 128 56 56 (51380224)
I1027 13:10:19.144434  9023 net.cpp:144] Memory required for data: 2457384960
I1027 13:10:19.144453  9023 layer_factory.hpp:77] Creating layer pool3
I1027 13:10:19.144461  9023 net.cpp:84] Creating Layer pool3
I1027 13:10:19.144466  9023 net.cpp:413] pool3 <- fire3/concat
I1027 13:10:19.144472  9023 net.cpp:387] pool3 -> pool3
I1027 13:10:19.144515  9023 net.cpp:127] Setting up pool3
I1027 13:10:19.144524  9023 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 13:10:19.144529  9023 net.cpp:144] Memory required for data: 2508765184
I1027 13:10:19.144534  9023 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I1027 13:10:19.144543  9023 net.cpp:84] Creating Layer fire4/squeeze1x1
I1027 13:10:19.144548  9023 net.cpp:413] fire4/squeeze1x1 <- pool3
I1027 13:10:19.144556  9023 net.cpp:387] fire4/squeeze1x1 -> fire4/squeeze1x1
I1027 13:10:19.144881  9023 net.cpp:127] Setting up fire4/squeeze1x1
I1027 13:10:19.144892  9023 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1027 13:10:19.144897  9023 net.cpp:144] Memory required for data: 2521610240
I1027 13:10:19.144904  9023 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1027 13:10:19.144911  9023 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1027 13:10:19.144917  9023 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1027 13:10:19.144922  9023 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1027 13:10:19.144927  9023 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I1027 13:10:19.144933  9023 net.cpp:84] Creating Layer fire4/relu_squeeze1x1
I1027 13:10:19.144940  9023 net.cpp:413] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I1027 13:10:19.144948  9023 net.cpp:374] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I1027 13:10:19.145129  9023 net.cpp:127] Setting up fire4/relu_squeeze1x1
I1027 13:10:19.145140  9023 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1027 13:10:19.145146  9023 net.cpp:144] Memory required for data: 2534455296
I1027 13:10:19.145153  9023 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1027 13:10:19.145159  9023 net.cpp:84] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1027 13:10:19.145166  9023 net.cpp:413] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I1027 13:10:19.145174  9023 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1027 13:10:19.145185  9023 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1027 13:10:19.145226  9023 net.cpp:127] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1027 13:10:19.145236  9023 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1027 13:10:19.145242  9023 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1027 13:10:19.145246  9023 net.cpp:144] Memory required for data: 2560145408
I1027 13:10:19.145251  9023 layer_factory.hpp:77] Creating layer fire4/expand1x1
I1027 13:10:19.145259  9023 net.cpp:84] Creating Layer fire4/expand1x1
I1027 13:10:19.145265  9023 net.cpp:413] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1027 13:10:19.145272  9023 net.cpp:387] fire4/expand1x1 -> fire4/expand1x1
I1027 13:10:19.145591  9023 net.cpp:127] Setting up fire4/expand1x1
I1027 13:10:19.145604  9023 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 13:10:19.145611  9023 net.cpp:144] Memory required for data: 2611525632
I1027 13:10:19.145622  9023 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1027 13:10:19.145632  9023 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1027 13:10:19.145639  9023 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1027 13:10:19.145645  9023 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1027 13:10:19.145656  9023 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I1027 13:10:19.145663  9023 net.cpp:84] Creating Layer fire4/relu_expand1x1
I1027 13:10:19.145680  9023 net.cpp:413] fire4/relu_expand1x1 <- fire4/expand1x1
I1027 13:10:19.145689  9023 net.cpp:374] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I1027 13:10:19.147011  9023 net.cpp:127] Setting up fire4/relu_expand1x1
I1027 13:10:19.147030  9023 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 13:10:19.147037  9023 net.cpp:144] Memory required for data: 2662905856
I1027 13:10:19.147042  9023 layer_factory.hpp:77] Creating layer fire4/expand3x3
I1027 13:10:19.147053  9023 net.cpp:84] Creating Layer fire4/expand3x3
I1027 13:10:19.147059  9023 net.cpp:413] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1027 13:10:19.147069  9023 net.cpp:387] fire4/expand3x3 -> fire4/expand3x3
I1027 13:10:19.148965  9023 net.cpp:127] Setting up fire4/expand3x3
I1027 13:10:19.148985  9023 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 13:10:19.148991  9023 net.cpp:144] Memory required for data: 2714286080
I1027 13:10:19.148999  9023 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1027 13:10:19.149008  9023 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1027 13:10:19.149013  9023 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1027 13:10:19.149021  9023 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1027 13:10:19.149026  9023 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I1027 13:10:19.149036  9023 net.cpp:84] Creating Layer fire4/relu_expand3x3
I1027 13:10:19.149044  9023 net.cpp:413] fire4/relu_expand3x3 <- fire4/expand3x3
I1027 13:10:19.149050  9023 net.cpp:374] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I1027 13:10:19.149238  9023 net.cpp:127] Setting up fire4/relu_expand3x3
I1027 13:10:19.149251  9023 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 13:10:19.149256  9023 net.cpp:144] Memory required for data: 2765666304
I1027 13:10:19.149262  9023 layer_factory.hpp:77] Creating layer fire4/concat
I1027 13:10:19.149271  9023 net.cpp:84] Creating Layer fire4/concat
I1027 13:10:19.149278  9023 net.cpp:413] fire4/concat <- fire4/expand1x1
I1027 13:10:19.149286  9023 net.cpp:413] fire4/concat <- fire4/expand3x3
I1027 13:10:19.149291  9023 net.cpp:387] fire4/concat -> fire4/concat
I1027 13:10:19.149332  9023 net.cpp:127] Setting up fire4/concat
I1027 13:10:19.149343  9023 net.cpp:136] Top shape: 128 256 28 28 (25690112)
I1027 13:10:19.149349  9023 net.cpp:144] Memory required for data: 2868426752
I1027 13:10:19.149356  9023 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I1027 13:10:19.149366  9023 net.cpp:84] Creating Layer fire5/squeeze1x1
I1027 13:10:19.149374  9023 net.cpp:413] fire5/squeeze1x1 <- fire4/concat
I1027 13:10:19.149381  9023 net.cpp:387] fire5/squeeze1x1 -> fire5/squeeze1x1
I1027 13:10:19.149740  9023 net.cpp:127] Setting up fire5/squeeze1x1
I1027 13:10:19.149754  9023 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1027 13:10:19.149758  9023 net.cpp:144] Memory required for data: 2881271808
I1027 13:10:19.149766  9023 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1027 13:10:19.149775  9023 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1027 13:10:19.149783  9023 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1027 13:10:19.149790  9023 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1027 13:10:19.149793  9023 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I1027 13:10:19.149801  9023 net.cpp:84] Creating Layer fire5/relu_squeeze1x1
I1027 13:10:19.149806  9023 net.cpp:413] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I1027 13:10:19.149812  9023 net.cpp:374] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I1027 13:10:19.149997  9023 net.cpp:127] Setting up fire5/relu_squeeze1x1
I1027 13:10:19.150015  9023 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1027 13:10:19.150022  9023 net.cpp:144] Memory required for data: 2894116864
I1027 13:10:19.150029  9023 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1027 13:10:19.150050  9023 net.cpp:84] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1027 13:10:19.150058  9023 net.cpp:413] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I1027 13:10:19.150068  9023 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1027 13:10:19.150075  9023 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1027 13:10:19.150120  9023 net.cpp:127] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1027 13:10:19.150128  9023 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1027 13:10:19.150135  9023 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1027 13:10:19.150142  9023 net.cpp:144] Memory required for data: 2919806976
I1027 13:10:19.150148  9023 layer_factory.hpp:77] Creating layer fire5/expand1x1
I1027 13:10:19.150161  9023 net.cpp:84] Creating Layer fire5/expand1x1
I1027 13:10:19.150166  9023 net.cpp:413] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1027 13:10:19.150173  9023 net.cpp:387] fire5/expand1x1 -> fire5/expand1x1
I1027 13:10:19.150506  9023 net.cpp:127] Setting up fire5/expand1x1
I1027 13:10:19.150517  9023 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 13:10:19.150522  9023 net.cpp:144] Memory required for data: 2971187200
I1027 13:10:19.150529  9023 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1027 13:10:19.150537  9023 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1027 13:10:19.150542  9023 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1027 13:10:19.150547  9023 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1027 13:10:19.150552  9023 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I1027 13:10:19.150559  9023 net.cpp:84] Creating Layer fire5/relu_expand1x1
I1027 13:10:19.150568  9023 net.cpp:413] fire5/relu_expand1x1 <- fire5/expand1x1
I1027 13:10:19.150574  9023 net.cpp:374] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I1027 13:10:19.150756  9023 net.cpp:127] Setting up fire5/relu_expand1x1
I1027 13:10:19.150768  9023 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 13:10:19.150774  9023 net.cpp:144] Memory required for data: 3022567424
I1027 13:10:19.150779  9023 layer_factory.hpp:77] Creating layer fire5/expand3x3
I1027 13:10:19.150790  9023 net.cpp:84] Creating Layer fire5/expand3x3
I1027 13:10:19.150799  9023 net.cpp:413] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1027 13:10:19.150806  9023 net.cpp:387] fire5/expand3x3 -> fire5/expand3x3
I1027 13:10:19.151382  9023 net.cpp:127] Setting up fire5/expand3x3
I1027 13:10:19.151396  9023 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 13:10:19.151401  9023 net.cpp:144] Memory required for data: 3073947648
I1027 13:10:19.151407  9023 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1027 13:10:19.151414  9023 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1027 13:10:19.151420  9023 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1027 13:10:19.151425  9023 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1027 13:10:19.151432  9023 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I1027 13:10:19.151438  9023 net.cpp:84] Creating Layer fire5/relu_expand3x3
I1027 13:10:19.151448  9023 net.cpp:413] fire5/relu_expand3x3 <- fire5/expand3x3
I1027 13:10:19.151455  9023 net.cpp:374] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I1027 13:10:19.152776  9023 net.cpp:127] Setting up fire5/relu_expand3x3
I1027 13:10:19.152796  9023 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1027 13:10:19.152807  9023 net.cpp:144] Memory required for data: 3125327872
I1027 13:10:19.152813  9023 layer_factory.hpp:77] Creating layer fire5/concat
I1027 13:10:19.152835  9023 net.cpp:84] Creating Layer fire5/concat
I1027 13:10:19.152843  9023 net.cpp:413] fire5/concat <- fire5/expand1x1
I1027 13:10:19.152851  9023 net.cpp:413] fire5/concat <- fire5/expand3x3
I1027 13:10:19.152858  9023 net.cpp:387] fire5/concat -> fire5/concat
I1027 13:10:19.152892  9023 net.cpp:127] Setting up fire5/concat
I1027 13:10:19.152902  9023 net.cpp:136] Top shape: 128 256 28 28 (25690112)
I1027 13:10:19.152909  9023 net.cpp:144] Memory required for data: 3228088320
I1027 13:10:19.152914  9023 layer_factory.hpp:77] Creating layer pool5
I1027 13:10:19.152922  9023 net.cpp:84] Creating Layer pool5
I1027 13:10:19.152930  9023 net.cpp:413] pool5 <- fire5/concat
I1027 13:10:19.152937  9023 net.cpp:387] pool5 -> pool5
I1027 13:10:19.152976  9023 net.cpp:127] Setting up pool5
I1027 13:10:19.152984  9023 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 13:10:19.152989  9023 net.cpp:144] Memory required for data: 3253778432
I1027 13:10:19.152994  9023 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I1027 13:10:19.153005  9023 net.cpp:84] Creating Layer fire6/squeeze1x1
I1027 13:10:19.153013  9023 net.cpp:413] fire6/squeeze1x1 <- pool5
I1027 13:10:19.153022  9023 net.cpp:387] fire6/squeeze1x1 -> fire6/squeeze1x1
I1027 13:10:19.153430  9023 net.cpp:127] Setting up fire6/squeeze1x1
I1027 13:10:19.153443  9023 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1027 13:10:19.153450  9023 net.cpp:144] Memory required for data: 3258595328
I1027 13:10:19.153456  9023 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1027 13:10:19.153463  9023 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1027 13:10:19.153470  9023 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1027 13:10:19.153475  9023 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1027 13:10:19.153482  9023 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I1027 13:10:19.153491  9023 net.cpp:84] Creating Layer fire6/relu_squeeze1x1
I1027 13:10:19.153496  9023 net.cpp:413] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I1027 13:10:19.153506  9023 net.cpp:374] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I1027 13:10:19.153687  9023 net.cpp:127] Setting up fire6/relu_squeeze1x1
I1027 13:10:19.153698  9023 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1027 13:10:19.153703  9023 net.cpp:144] Memory required for data: 3263412224
I1027 13:10:19.153709  9023 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1027 13:10:19.153717  9023 net.cpp:84] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1027 13:10:19.153724  9023 net.cpp:413] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I1027 13:10:19.153733  9023 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1027 13:10:19.153743  9023 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1027 13:10:19.153794  9023 net.cpp:127] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1027 13:10:19.153802  9023 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1027 13:10:19.153811  9023 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1027 13:10:19.153817  9023 net.cpp:144] Memory required for data: 3273046016
I1027 13:10:19.153825  9023 layer_factory.hpp:77] Creating layer fire6/expand1x1
I1027 13:10:19.153836  9023 net.cpp:84] Creating Layer fire6/expand1x1
I1027 13:10:19.153843  9023 net.cpp:413] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1027 13:10:19.153851  9023 net.cpp:387] fire6/expand1x1 -> fire6/expand1x1
I1027 13:10:19.154208  9023 net.cpp:127] Setting up fire6/expand1x1
I1027 13:10:19.154219  9023 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1027 13:10:19.154232  9023 net.cpp:144] Memory required for data: 3292313600
I1027 13:10:19.154238  9023 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1027 13:10:19.154244  9023 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1027 13:10:19.154261  9023 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1027 13:10:19.154268  9023 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1027 13:10:19.154273  9023 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I1027 13:10:19.154279  9023 net.cpp:84] Creating Layer fire6/relu_expand1x1
I1027 13:10:19.154285  9023 net.cpp:413] fire6/relu_expand1x1 <- fire6/expand1x1
I1027 13:10:19.154294  9023 net.cpp:374] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I1027 13:10:19.154479  9023 net.cpp:127] Setting up fire6/relu_expand1x1
I1027 13:10:19.154492  9023 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1027 13:10:19.154497  9023 net.cpp:144] Memory required for data: 3311581184
I1027 13:10:19.154503  9023 layer_factory.hpp:77] Creating layer fire6/expand3x3
I1027 13:10:19.154516  9023 net.cpp:84] Creating Layer fire6/expand3x3
I1027 13:10:19.154525  9023 net.cpp:413] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1027 13:10:19.154532  9023 net.cpp:387] fire6/expand3x3 -> fire6/expand3x3
I1027 13:10:19.156802  9023 net.cpp:127] Setting up fire6/expand3x3
I1027 13:10:19.156822  9023 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1027 13:10:19.156829  9023 net.cpp:144] Memory required for data: 3330848768
I1027 13:10:19.156838  9023 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1027 13:10:19.156847  9023 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1027 13:10:19.156855  9023 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1027 13:10:19.156864  9023 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1027 13:10:19.156869  9023 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I1027 13:10:19.156877  9023 net.cpp:84] Creating Layer fire6/relu_expand3x3
I1027 13:10:19.156883  9023 net.cpp:413] fire6/relu_expand3x3 <- fire6/expand3x3
I1027 13:10:19.156890  9023 net.cpp:374] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I1027 13:10:19.157085  9023 net.cpp:127] Setting up fire6/relu_expand3x3
I1027 13:10:19.157097  9023 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1027 13:10:19.157104  9023 net.cpp:144] Memory required for data: 3350116352
I1027 13:10:19.157110  9023 layer_factory.hpp:77] Creating layer fire6/concat
I1027 13:10:19.157120  9023 net.cpp:84] Creating Layer fire6/concat
I1027 13:10:19.157125  9023 net.cpp:413] fire6/concat <- fire6/expand1x1
I1027 13:10:19.157132  9023 net.cpp:413] fire6/concat <- fire6/expand3x3
I1027 13:10:19.157138  9023 net.cpp:387] fire6/concat -> fire6/concat
I1027 13:10:19.157169  9023 net.cpp:127] Setting up fire6/concat
I1027 13:10:19.157177  9023 net.cpp:136] Top shape: 128 384 14 14 (9633792)
I1027 13:10:19.157182  9023 net.cpp:144] Memory required for data: 3388651520
I1027 13:10:19.157186  9023 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I1027 13:10:19.157196  9023 net.cpp:84] Creating Layer fire7/squeeze1x1
I1027 13:10:19.157202  9023 net.cpp:413] fire7/squeeze1x1 <- fire6/concat
I1027 13:10:19.157210  9023 net.cpp:387] fire7/squeeze1x1 -> fire7/squeeze1x1
I1027 13:10:19.157655  9023 net.cpp:127] Setting up fire7/squeeze1x1
I1027 13:10:19.157668  9023 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1027 13:10:19.157675  9023 net.cpp:144] Memory required for data: 3393468416
I1027 13:10:19.157686  9023 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1027 13:10:19.157696  9023 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1027 13:10:19.157702  9023 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1027 13:10:19.157709  9023 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1027 13:10:19.157724  9023 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I1027 13:10:19.157732  9023 net.cpp:84] Creating Layer fire7/relu_squeeze1x1
I1027 13:10:19.157755  9023 net.cpp:413] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I1027 13:10:19.157763  9023 net.cpp:374] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I1027 13:10:19.159092  9023 net.cpp:127] Setting up fire7/relu_squeeze1x1
I1027 13:10:19.159111  9023 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1027 13:10:19.159117  9023 net.cpp:144] Memory required for data: 3398285312
I1027 13:10:19.159123  9023 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1027 13:10:19.159132  9023 net.cpp:84] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1027 13:10:19.159137  9023 net.cpp:413] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I1027 13:10:19.159144  9023 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1027 13:10:19.159154  9023 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1027 13:10:19.159204  9023 net.cpp:127] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1027 13:10:19.159211  9023 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1027 13:10:19.159217  9023 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1027 13:10:19.159222  9023 net.cpp:144] Memory required for data: 3407919104
I1027 13:10:19.159227  9023 layer_factory.hpp:77] Creating layer fire7/expand1x1
I1027 13:10:19.159237  9023 net.cpp:84] Creating Layer fire7/expand1x1
I1027 13:10:19.159242  9023 net.cpp:413] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1027 13:10:19.159250  9023 net.cpp:387] fire7/expand1x1 -> fire7/expand1x1
I1027 13:10:19.159624  9023 net.cpp:127] Setting up fire7/expand1x1
I1027 13:10:19.159637  9023 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1027 13:10:19.159642  9023 net.cpp:144] Memory required for data: 3427186688
I1027 13:10:19.159649  9023 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1027 13:10:19.159657  9023 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1027 13:10:19.159662  9023 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1027 13:10:19.159668  9023 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1027 13:10:19.159673  9023 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I1027 13:10:19.159682  9023 net.cpp:84] Creating Layer fire7/relu_expand1x1
I1027 13:10:19.159688  9023 net.cpp:413] fire7/relu_expand1x1 <- fire7/expand1x1
I1027 13:10:19.159694  9023 net.cpp:374] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I1027 13:10:19.159874  9023 net.cpp:127] Setting up fire7/relu_expand1x1
I1027 13:10:19.159886  9023 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1027 13:10:19.159891  9023 net.cpp:144] Memory required for data: 3446454272
I1027 13:10:19.159898  9023 layer_factory.hpp:77] Creating layer fire7/expand3x3
I1027 13:10:19.159909  9023 net.cpp:84] Creating Layer fire7/expand3x3
I1027 13:10:19.159914  9023 net.cpp:413] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1027 13:10:19.159921  9023 net.cpp:387] fire7/expand3x3 -> fire7/expand3x3
I1027 13:10:19.160876  9023 net.cpp:127] Setting up fire7/expand3x3
I1027 13:10:19.160889  9023 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1027 13:10:19.160894  9023 net.cpp:144] Memory required for data: 3465721856
I1027 13:10:19.160902  9023 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1027 13:10:19.160908  9023 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1027 13:10:19.160913  9023 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1027 13:10:19.160919  9023 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1027 13:10:19.160931  9023 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I1027 13:10:19.160943  9023 net.cpp:84] Creating Layer fire7/relu_expand3x3
I1027 13:10:19.160950  9023 net.cpp:413] fire7/relu_expand3x3 <- fire7/expand3x3
I1027 13:10:19.160969  9023 net.cpp:374] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I1027 13:10:19.161150  9023 net.cpp:127] Setting up fire7/relu_expand3x3
I1027 13:10:19.161162  9023 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1027 13:10:19.161167  9023 net.cpp:144] Memory required for data: 3484989440
I1027 13:10:19.161173  9023 layer_factory.hpp:77] Creating layer fire7/concat
I1027 13:10:19.161181  9023 net.cpp:84] Creating Layer fire7/concat
I1027 13:10:19.161186  9023 net.cpp:413] fire7/concat <- fire7/expand1x1
I1027 13:10:19.161192  9023 net.cpp:413] fire7/concat <- fire7/expand3x3
I1027 13:10:19.161200  9023 net.cpp:387] fire7/concat -> fire7/concat
I1027 13:10:19.161228  9023 net.cpp:127] Setting up fire7/concat
I1027 13:10:19.161237  9023 net.cpp:136] Top shape: 128 384 14 14 (9633792)
I1027 13:10:19.161243  9023 net.cpp:144] Memory required for data: 3523524608
I1027 13:10:19.161248  9023 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I1027 13:10:19.161257  9023 net.cpp:84] Creating Layer fire8/squeeze1x1
I1027 13:10:19.161262  9023 net.cpp:413] fire8/squeeze1x1 <- fire7/concat
I1027 13:10:19.161272  9023 net.cpp:387] fire8/squeeze1x1 -> fire8/squeeze1x1
I1027 13:10:19.161756  9023 net.cpp:127] Setting up fire8/squeeze1x1
I1027 13:10:19.161769  9023 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1027 13:10:19.161774  9023 net.cpp:144] Memory required for data: 3529947136
I1027 13:10:19.161782  9023 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1027 13:10:19.161787  9023 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1027 13:10:19.161793  9023 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1027 13:10:19.161799  9023 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1027 13:10:19.161804  9023 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I1027 13:10:19.161813  9023 net.cpp:84] Creating Layer fire8/relu_squeeze1x1
I1027 13:10:19.161818  9023 net.cpp:413] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I1027 13:10:19.161825  9023 net.cpp:374] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I1027 13:10:19.163164  9023 net.cpp:127] Setting up fire8/relu_squeeze1x1
I1027 13:10:19.163183  9023 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1027 13:10:19.163189  9023 net.cpp:144] Memory required for data: 3536369664
I1027 13:10:19.163195  9023 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1027 13:10:19.163203  9023 net.cpp:84] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1027 13:10:19.163209  9023 net.cpp:413] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I1027 13:10:19.163216  9023 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1027 13:10:19.163226  9023 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1027 13:10:19.163275  9023 net.cpp:127] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1027 13:10:19.163282  9023 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1027 13:10:19.163288  9023 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1027 13:10:19.163292  9023 net.cpp:144] Memory required for data: 3549214720
I1027 13:10:19.163305  9023 layer_factory.hpp:77] Creating layer fire8/expand1x1
I1027 13:10:19.163316  9023 net.cpp:84] Creating Layer fire8/expand1x1
I1027 13:10:19.163321  9023 net.cpp:413] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1027 13:10:19.163327  9023 net.cpp:387] fire8/expand1x1 -> fire8/expand1x1
I1027 13:10:19.163748  9023 net.cpp:127] Setting up fire8/expand1x1
I1027 13:10:19.163760  9023 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 13:10:19.163772  9023 net.cpp:144] Memory required for data: 3574904832
I1027 13:10:19.163779  9023 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1027 13:10:19.163800  9023 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1027 13:10:19.163806  9023 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1027 13:10:19.163812  9023 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1027 13:10:19.163816  9023 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I1027 13:10:19.163823  9023 net.cpp:84] Creating Layer fire8/relu_expand1x1
I1027 13:10:19.163830  9023 net.cpp:413] fire8/relu_expand1x1 <- fire8/expand1x1
I1027 13:10:19.163836  9023 net.cpp:374] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I1027 13:10:19.164016  9023 net.cpp:127] Setting up fire8/relu_expand1x1
I1027 13:10:19.164027  9023 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 13:10:19.164033  9023 net.cpp:144] Memory required for data: 3600594944
I1027 13:10:19.164039  9023 layer_factory.hpp:77] Creating layer fire8/expand3x3
I1027 13:10:19.164048  9023 net.cpp:84] Creating Layer fire8/expand3x3
I1027 13:10:19.164054  9023 net.cpp:413] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1027 13:10:19.164062  9023 net.cpp:387] fire8/expand3x3 -> fire8/expand3x3
I1027 13:10:19.166831  9023 net.cpp:127] Setting up fire8/expand3x3
I1027 13:10:19.166851  9023 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 13:10:19.166857  9023 net.cpp:144] Memory required for data: 3626285056
I1027 13:10:19.166865  9023 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1027 13:10:19.166872  9023 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1027 13:10:19.166878  9023 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1027 13:10:19.166883  9023 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1027 13:10:19.166888  9023 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I1027 13:10:19.166898  9023 net.cpp:84] Creating Layer fire8/relu_expand3x3
I1027 13:10:19.166905  9023 net.cpp:413] fire8/relu_expand3x3 <- fire8/expand3x3
I1027 13:10:19.166913  9023 net.cpp:374] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I1027 13:10:19.167104  9023 net.cpp:127] Setting up fire8/relu_expand3x3
I1027 13:10:19.167116  9023 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 13:10:19.167121  9023 net.cpp:144] Memory required for data: 3651975168
I1027 13:10:19.167129  9023 layer_factory.hpp:77] Creating layer fire8/concat
I1027 13:10:19.167135  9023 net.cpp:84] Creating Layer fire8/concat
I1027 13:10:19.167140  9023 net.cpp:413] fire8/concat <- fire8/expand1x1
I1027 13:10:19.167147  9023 net.cpp:413] fire8/concat <- fire8/expand3x3
I1027 13:10:19.167155  9023 net.cpp:387] fire8/concat -> fire8/concat
I1027 13:10:19.167186  9023 net.cpp:127] Setting up fire8/concat
I1027 13:10:19.167194  9023 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1027 13:10:19.167199  9023 net.cpp:144] Memory required for data: 3703355392
I1027 13:10:19.167204  9023 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I1027 13:10:19.167214  9023 net.cpp:84] Creating Layer fire9/squeeze1x1
I1027 13:10:19.167219  9023 net.cpp:413] fire9/squeeze1x1 <- fire8/concat
I1027 13:10:19.167227  9023 net.cpp:387] fire9/squeeze1x1 -> fire9/squeeze1x1
I1027 13:10:19.167785  9023 net.cpp:127] Setting up fire9/squeeze1x1
I1027 13:10:19.167799  9023 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1027 13:10:19.167805  9023 net.cpp:144] Memory required for data: 3709777920
I1027 13:10:19.167812  9023 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1027 13:10:19.167819  9023 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1027 13:10:19.167824  9023 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1027 13:10:19.167830  9023 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1027 13:10:19.167842  9023 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I1027 13:10:19.167855  9023 net.cpp:84] Creating Layer fire9/relu_squeeze1x1
I1027 13:10:19.167876  9023 net.cpp:413] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I1027 13:10:19.167884  9023 net.cpp:374] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I1027 13:10:19.168071  9023 net.cpp:127] Setting up fire9/relu_squeeze1x1
I1027 13:10:19.168083  9023 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1027 13:10:19.168088  9023 net.cpp:144] Memory required for data: 3716200448
I1027 13:10:19.168094  9023 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1027 13:10:19.168107  9023 net.cpp:84] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1027 13:10:19.168113  9023 net.cpp:413] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I1027 13:10:19.168120  9023 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1027 13:10:19.168128  9023 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1027 13:10:19.168174  9023 net.cpp:127] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1027 13:10:19.168184  9023 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1027 13:10:19.168190  9023 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1027 13:10:19.168195  9023 net.cpp:144] Memory required for data: 3729045504
I1027 13:10:19.168200  9023 layer_factory.hpp:77] Creating layer fire9/expand1x1
I1027 13:10:19.168210  9023 net.cpp:84] Creating Layer fire9/expand1x1
I1027 13:10:19.168215  9023 net.cpp:413] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1027 13:10:19.168222  9023 net.cpp:387] fire9/expand1x1 -> fire9/expand1x1
I1027 13:10:19.168648  9023 net.cpp:127] Setting up fire9/expand1x1
I1027 13:10:19.168660  9023 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 13:10:19.168665  9023 net.cpp:144] Memory required for data: 3754735616
I1027 13:10:19.168673  9023 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1027 13:10:19.168680  9023 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1027 13:10:19.168686  9023 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1027 13:10:19.168691  9023 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1027 13:10:19.168696  9023 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I1027 13:10:19.168704  9023 net.cpp:84] Creating Layer fire9/relu_expand1x1
I1027 13:10:19.168712  9023 net.cpp:413] fire9/relu_expand1x1 <- fire9/expand1x1
I1027 13:10:19.168718  9023 net.cpp:374] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I1027 13:10:19.170059  9023 net.cpp:127] Setting up fire9/relu_expand1x1
I1027 13:10:19.170078  9023 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 13:10:19.170084  9023 net.cpp:144] Memory required for data: 3780425728
I1027 13:10:19.170090  9023 layer_factory.hpp:77] Creating layer fire9/expand3x3
I1027 13:10:19.170101  9023 net.cpp:84] Creating Layer fire9/expand3x3
I1027 13:10:19.170106  9023 net.cpp:413] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1027 13:10:19.170117  9023 net.cpp:387] fire9/expand3x3 -> fire9/expand3x3
I1027 13:10:19.171582  9023 net.cpp:127] Setting up fire9/expand3x3
I1027 13:10:19.171597  9023 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 13:10:19.171602  9023 net.cpp:144] Memory required for data: 3806115840
I1027 13:10:19.171608  9023 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1027 13:10:19.171615  9023 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1027 13:10:19.171622  9023 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1027 13:10:19.171627  9023 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1027 13:10:19.171646  9023 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I1027 13:10:19.171655  9023 net.cpp:84] Creating Layer fire9/relu_expand3x3
I1027 13:10:19.171674  9023 net.cpp:413] fire9/relu_expand3x3 <- fire9/expand3x3
I1027 13:10:19.171681  9023 net.cpp:374] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I1027 13:10:19.171862  9023 net.cpp:127] Setting up fire9/relu_expand3x3
I1027 13:10:19.171875  9023 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1027 13:10:19.171880  9023 net.cpp:144] Memory required for data: 3831805952
I1027 13:10:19.171886  9023 layer_factory.hpp:77] Creating layer fire9/concat
I1027 13:10:19.171893  9023 net.cpp:84] Creating Layer fire9/concat
I1027 13:10:19.171898  9023 net.cpp:413] fire9/concat <- fire9/expand1x1
I1027 13:10:19.171905  9023 net.cpp:413] fire9/concat <- fire9/expand3x3
I1027 13:10:19.171912  9023 net.cpp:387] fire9/concat -> fire9/concat
I1027 13:10:19.171942  9023 net.cpp:127] Setting up fire9/concat
I1027 13:10:19.171950  9023 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1027 13:10:19.171955  9023 net.cpp:144] Memory required for data: 3883186176
I1027 13:10:19.171960  9023 layer_factory.hpp:77] Creating layer drop9
I1027 13:10:19.171972  9023 net.cpp:84] Creating Layer drop9
I1027 13:10:19.171977  9023 net.cpp:413] drop9 <- fire9/concat
I1027 13:10:19.171984  9023 net.cpp:374] drop9 -> fire9/concat (in-place)
I1027 13:10:19.172015  9023 net.cpp:127] Setting up drop9
I1027 13:10:19.172026  9023 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1027 13:10:19.172031  9023 net.cpp:144] Memory required for data: 3934566400
I1027 13:10:19.172037  9023 layer_factory.hpp:77] Creating layer conv10
I1027 13:10:19.172046  9023 net.cpp:84] Creating Layer conv10
I1027 13:10:19.172051  9023 net.cpp:413] conv10 <- fire9/concat
I1027 13:10:19.172060  9023 net.cpp:387] conv10 -> conv10
I1027 13:10:19.181507  9023 net.cpp:127] Setting up conv10
I1027 13:10:19.181529  9023 net.cpp:136] Top shape: 128 1000 14 14 (25088000)
I1027 13:10:19.181535  9023 net.cpp:144] Memory required for data: 4034918400
I1027 13:10:19.181542  9023 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1027 13:10:19.181550  9023 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1027 13:10:19.181555  9023 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1027 13:10:19.181562  9023 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1027 13:10:19.181568  9023 layer_factory.hpp:77] Creating layer relu_conv10
I1027 13:10:19.181581  9023 net.cpp:84] Creating Layer relu_conv10
I1027 13:10:19.181587  9023 net.cpp:413] relu_conv10 <- conv10
I1027 13:10:19.181594  9023 net.cpp:374] relu_conv10 -> conv10 (in-place)
I1027 13:10:19.181790  9023 net.cpp:127] Setting up relu_conv10
I1027 13:10:19.181803  9023 net.cpp:136] Top shape: 128 1000 14 14 (25088000)
I1027 13:10:19.181808  9023 net.cpp:144] Memory required for data: 4135270400
I1027 13:10:19.181814  9023 layer_factory.hpp:77] Creating layer pool10
I1027 13:10:19.181823  9023 net.cpp:84] Creating Layer pool10
I1027 13:10:19.181828  9023 net.cpp:413] pool10 <- conv10
I1027 13:10:19.181836  9023 net.cpp:387] pool10 -> pool10
I1027 13:10:19.182047  9023 net.cpp:127] Setting up pool10
I1027 13:10:19.182060  9023 net.cpp:136] Top shape: 128 1000 1 1 (128000)
I1027 13:10:19.182067  9023 net.cpp:144] Memory required for data: 4135782400
I1027 13:10:19.182073  9023 layer_factory.hpp:77] Creating layer loss
I1027 13:10:19.182083  9023 net.cpp:84] Creating Layer loss
I1027 13:10:19.182090  9023 net.cpp:413] loss <- pool10
I1027 13:10:19.182096  9023 net.cpp:413] loss <- label
I1027 13:10:19.182103  9023 net.cpp:387] loss -> loss
I1027 13:10:19.182118  9023 layer_factory.hpp:77] Creating layer loss
I1027 13:10:19.184990  9023 net.cpp:127] Setting up loss
I1027 13:10:19.185010  9023 net.cpp:136] Top shape: (1)
I1027 13:10:19.185016  9023 net.cpp:139]     with loss weight 1
I1027 13:10:19.185045  9023 net.cpp:144] Memory required for data: 4135782404
I1027 13:10:19.185060  9023 net.cpp:205] loss needs backward computation.
I1027 13:10:19.185068  9023 net.cpp:205] pool10 needs backward computation.
I1027 13:10:19.185075  9023 net.cpp:205] relu_conv10 needs backward computation.
I1027 13:10:19.185091  9023 net.cpp:205] conv10 needs backward computation.
I1027 13:10:19.185096  9023 net.cpp:205] drop9 needs backward computation.
I1027 13:10:19.185101  9023 net.cpp:205] fire9/concat needs backward computation.
I1027 13:10:19.185106  9023 net.cpp:205] fire9/relu_expand3x3 needs backward computation.
I1027 13:10:19.185111  9023 net.cpp:205] fire9/expand3x3 needs backward computation.
I1027 13:10:19.185117  9023 net.cpp:205] fire9/relu_expand1x1 needs backward computation.
I1027 13:10:19.185122  9023 net.cpp:205] fire9/expand1x1 needs backward computation.
I1027 13:10:19.185127  9023 net.cpp:205] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I1027 13:10:19.185132  9023 net.cpp:205] fire9/relu_squeeze1x1 needs backward computation.
I1027 13:10:19.185137  9023 net.cpp:205] fire9/squeeze1x1 needs backward computation.
I1027 13:10:19.185142  9023 net.cpp:205] fire8/concat needs backward computation.
I1027 13:10:19.185147  9023 net.cpp:205] fire8/relu_expand3x3 needs backward computation.
I1027 13:10:19.185150  9023 net.cpp:205] fire8/expand3x3 needs backward computation.
I1027 13:10:19.185156  9023 net.cpp:205] fire8/relu_expand1x1 needs backward computation.
I1027 13:10:19.185160  9023 net.cpp:205] fire8/expand1x1 needs backward computation.
I1027 13:10:19.185165  9023 net.cpp:205] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I1027 13:10:19.185171  9023 net.cpp:205] fire8/relu_squeeze1x1 needs backward computation.
I1027 13:10:19.185175  9023 net.cpp:205] fire8/squeeze1x1 needs backward computation.
I1027 13:10:19.185180  9023 net.cpp:205] fire7/concat needs backward computation.
I1027 13:10:19.185185  9023 net.cpp:205] fire7/relu_expand3x3 needs backward computation.
I1027 13:10:19.185190  9023 net.cpp:205] fire7/expand3x3 needs backward computation.
I1027 13:10:19.185194  9023 net.cpp:205] fire7/relu_expand1x1 needs backward computation.
I1027 13:10:19.185199  9023 net.cpp:205] fire7/expand1x1 needs backward computation.
I1027 13:10:19.185204  9023 net.cpp:205] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I1027 13:10:19.185209  9023 net.cpp:205] fire7/relu_squeeze1x1 needs backward computation.
I1027 13:10:19.185214  9023 net.cpp:205] fire7/squeeze1x1 needs backward computation.
I1027 13:10:19.185217  9023 net.cpp:205] fire6/concat needs backward computation.
I1027 13:10:19.185223  9023 net.cpp:205] fire6/relu_expand3x3 needs backward computation.
I1027 13:10:19.185227  9023 net.cpp:205] fire6/expand3x3 needs backward computation.
I1027 13:10:19.185232  9023 net.cpp:205] fire6/relu_expand1x1 needs backward computation.
I1027 13:10:19.185236  9023 net.cpp:205] fire6/expand1x1 needs backward computation.
I1027 13:10:19.185241  9023 net.cpp:205] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I1027 13:10:19.185245  9023 net.cpp:205] fire6/relu_squeeze1x1 needs backward computation.
I1027 13:10:19.185251  9023 net.cpp:205] fire6/squeeze1x1 needs backward computation.
I1027 13:10:19.185256  9023 net.cpp:205] pool5 needs backward computation.
I1027 13:10:19.185261  9023 net.cpp:205] fire5/concat needs backward computation.
I1027 13:10:19.185266  9023 net.cpp:205] fire5/relu_expand3x3 needs backward computation.
I1027 13:10:19.185271  9023 net.cpp:205] fire5/expand3x3 needs backward computation.
I1027 13:10:19.185276  9023 net.cpp:205] fire5/relu_expand1x1 needs backward computation.
I1027 13:10:19.185281  9023 net.cpp:205] fire5/expand1x1 needs backward computation.
I1027 13:10:19.185284  9023 net.cpp:205] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I1027 13:10:19.185289  9023 net.cpp:205] fire5/relu_squeeze1x1 needs backward computation.
I1027 13:10:19.185293  9023 net.cpp:205] fire5/squeeze1x1 needs backward computation.
I1027 13:10:19.185307  9023 net.cpp:205] fire4/concat needs backward computation.
I1027 13:10:19.185313  9023 net.cpp:205] fire4/relu_expand3x3 needs backward computation.
I1027 13:10:19.185318  9023 net.cpp:205] fire4/expand3x3 needs backward computation.
I1027 13:10:19.185329  9023 net.cpp:205] fire4/relu_expand1x1 needs backward computation.
I1027 13:10:19.185334  9023 net.cpp:205] fire4/expand1x1 needs backward computation.
I1027 13:10:19.185339  9023 net.cpp:205] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I1027 13:10:19.185343  9023 net.cpp:205] fire4/relu_squeeze1x1 needs backward computation.
I1027 13:10:19.185348  9023 net.cpp:205] fire4/squeeze1x1 needs backward computation.
I1027 13:10:19.185353  9023 net.cpp:205] pool3 needs backward computation.
I1027 13:10:19.185358  9023 net.cpp:205] fire3/concat needs backward computation.
I1027 13:10:19.185362  9023 net.cpp:205] fire3/relu_expand3x3 needs backward computation.
I1027 13:10:19.185367  9023 net.cpp:205] fire3/expand3x3 needs backward computation.
I1027 13:10:19.185371  9023 net.cpp:205] fire3/relu_expand1x1 needs backward computation.
I1027 13:10:19.185376  9023 net.cpp:205] fire3/expand1x1 needs backward computation.
I1027 13:10:19.185380  9023 net.cpp:205] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I1027 13:10:19.185385  9023 net.cpp:205] fire3/relu_squeeze1x1 needs backward computation.
I1027 13:10:19.185389  9023 net.cpp:205] fire3/squeeze1x1 needs backward computation.
I1027 13:10:19.185395  9023 net.cpp:205] fire2/concat needs backward computation.
I1027 13:10:19.185400  9023 net.cpp:205] fire2/relu_expand3x3 needs backward computation.
I1027 13:10:19.185403  9023 net.cpp:205] fire2/expand3x3 needs backward computation.
I1027 13:10:19.185408  9023 net.cpp:205] fire2/relu_expand1x1 needs backward computation.
I1027 13:10:19.185412  9023 net.cpp:205] fire2/expand1x1 needs backward computation.
I1027 13:10:19.185420  9023 net.cpp:205] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I1027 13:10:19.185425  9023 net.cpp:205] fire2/relu_squeeze1x1 needs backward computation.
I1027 13:10:19.185430  9023 net.cpp:205] fire2/squeeze1x1 needs backward computation.
I1027 13:10:19.185434  9023 net.cpp:205] pool1 needs backward computation.
I1027 13:10:19.185439  9023 net.cpp:205] relu_conv1 needs backward computation.
I1027 13:10:19.185444  9023 net.cpp:205] conv1 needs backward computation.
I1027 13:10:19.185451  9023 net.cpp:207] data does not need backward computation.
I1027 13:10:19.185454  9023 net.cpp:249] This network produces output loss
I1027 13:10:19.185503  9023 net.cpp:262] Network initialization done.
I1027 13:10:19.187276  9023 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_0.prototxt
I1027 13:10:19.187383  9023 net.cpp:301] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1027 13:10:19.188114  9023 net.cpp:51] Initializing net from parameters: 
name: "SqueezeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/data/caffe-imagenet/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "INQConvolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "fire3/concat"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire4/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool3"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "fire5/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire4/concat"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "fire5/concat"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire6/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool5"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "fire9/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire8/concat"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "INQConvolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
  inq_convolution_param {
    portion: 0
    portion: 0
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "pool10"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy_top1"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy_top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy_top5"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy_top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I1027 13:10:19.188480  9023 layer_factory.hpp:77] Creating layer data
I1027 13:10:19.188560  9023 db_lmdb.cpp:35] Opened lmdb /home/data/caffe-imagenet/ilsvrc12_val_lmdb
I1027 13:10:19.188585  9023 net.cpp:84] Creating Layer data
I1027 13:10:19.188596  9023 net.cpp:387] data -> data
I1027 13:10:19.188606  9023 net.cpp:387] data -> label
I1027 13:10:19.189030  9023 data_layer.cpp:45] output data size: 50,3,227,227
I1027 13:10:19.272876  9023 net.cpp:127] Setting up data
I1027 13:10:19.272927  9023 net.cpp:136] Top shape: 50 3 227 227 (7729350)
I1027 13:10:19.272936  9023 net.cpp:136] Top shape: 50 (50)
I1027 13:10:19.272984  9023 net.cpp:144] Memory required for data: 30917600
I1027 13:10:19.272995  9023 layer_factory.hpp:77] Creating layer label_data_1_split
I1027 13:10:19.273013  9023 net.cpp:84] Creating Layer label_data_1_split
I1027 13:10:19.273020  9023 net.cpp:413] label_data_1_split <- label
I1027 13:10:19.273031  9023 net.cpp:387] label_data_1_split -> label_data_1_split_0
I1027 13:10:19.273043  9023 net.cpp:387] label_data_1_split -> label_data_1_split_1
I1027 13:10:19.273052  9023 net.cpp:387] label_data_1_split -> label_data_1_split_2
I1027 13:10:19.273214  9023 net.cpp:127] Setting up label_data_1_split
I1027 13:10:19.273226  9023 net.cpp:136] Top shape: 50 (50)
I1027 13:10:19.273232  9023 net.cpp:136] Top shape: 50 (50)
I1027 13:10:19.273239  9023 net.cpp:136] Top shape: 50 (50)
I1027 13:10:19.273243  9023 net.cpp:144] Memory required for data: 30918200
I1027 13:10:19.273248  9023 layer_factory.hpp:77] Creating layer conv1
I1027 13:10:19.273264  9023 net.cpp:84] Creating Layer conv1
I1027 13:10:19.273269  9023 net.cpp:413] conv1 <- data
I1027 13:10:19.273278  9023 net.cpp:387] conv1 -> conv1
I1027 13:10:19.273699  9023 net.cpp:127] Setting up conv1
I1027 13:10:19.273711  9023 net.cpp:136] Top shape: 50 64 113 113 (40860800)
I1027 13:10:19.273716  9023 net.cpp:144] Memory required for data: 194361400
I1027 13:10:19.273727  9023 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1027 13:10:19.273737  9023 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1027 13:10:19.273746  9023 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1027 13:10:19.273753  9023 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1027 13:10:19.273761  9023 layer_factory.hpp:77] Creating layer relu_conv1
I1027 13:10:19.273771  9023 net.cpp:84] Creating Layer relu_conv1
I1027 13:10:19.273777  9023 net.cpp:413] relu_conv1 <- conv1
I1027 13:10:19.273783  9023 net.cpp:374] relu_conv1 -> conv1 (in-place)
I1027 13:10:19.274029  9023 net.cpp:127] Setting up relu_conv1
I1027 13:10:19.274042  9023 net.cpp:136] Top shape: 50 64 113 113 (40860800)
I1027 13:10:19.274047  9023 net.cpp:144] Memory required for data: 357804600
I1027 13:10:19.274054  9023 layer_factory.hpp:77] Creating layer pool1
I1027 13:10:19.274065  9023 net.cpp:84] Creating Layer pool1
I1027 13:10:19.274071  9023 net.cpp:413] pool1 <- conv1
I1027 13:10:19.274078  9023 net.cpp:387] pool1 -> pool1
I1027 13:10:19.274129  9023 net.cpp:127] Setting up pool1
I1027 13:10:19.274139  9023 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 13:10:19.274144  9023 net.cpp:144] Memory required for data: 397945400
I1027 13:10:19.274150  9023 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I1027 13:10:19.274160  9023 net.cpp:84] Creating Layer fire2/squeeze1x1
I1027 13:10:19.274165  9023 net.cpp:413] fire2/squeeze1x1 <- pool1
I1027 13:10:19.274174  9023 net.cpp:387] fire2/squeeze1x1 -> fire2/squeeze1x1
I1027 13:10:19.277133  9023 net.cpp:127] Setting up fire2/squeeze1x1
I1027 13:10:19.277153  9023 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1027 13:10:19.277159  9023 net.cpp:144] Memory required for data: 407980600
I1027 13:10:19.277173  9023 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1027 13:10:19.277181  9023 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1027 13:10:19.277189  9023 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1027 13:10:19.277197  9023 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1027 13:10:19.277206  9023 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I1027 13:10:19.277223  9023 net.cpp:84] Creating Layer fire2/relu_squeeze1x1
I1027 13:10:19.277230  9023 net.cpp:413] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I1027 13:10:19.277249  9023 net.cpp:374] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I1027 13:10:19.280030  9023 net.cpp:127] Setting up fire2/relu_squeeze1x1
I1027 13:10:19.280046  9023 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1027 13:10:19.280064  9023 net.cpp:144] Memory required for data: 418015800
I1027 13:10:19.280071  9023 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1027 13:10:19.280079  9023 net.cpp:84] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1027 13:10:19.280086  9023 net.cpp:413] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I1027 13:10:19.280095  9023 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1027 13:10:19.280108  9023 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1027 13:10:19.280160  9023 net.cpp:127] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1027 13:10:19.280169  9023 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1027 13:10:19.280175  9023 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1027 13:10:19.280180  9023 net.cpp:144] Memory required for data: 438086200
I1027 13:10:19.280185  9023 layer_factory.hpp:77] Creating layer fire2/expand1x1
I1027 13:10:19.280202  9023 net.cpp:84] Creating Layer fire2/expand1x1
I1027 13:10:19.280207  9023 net.cpp:413] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1027 13:10:19.280218  9023 net.cpp:387] fire2/expand1x1 -> fire2/expand1x1
I1027 13:10:19.280562  9023 net.cpp:127] Setting up fire2/expand1x1
I1027 13:10:19.280575  9023 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 13:10:19.280580  9023 net.cpp:144] Memory required for data: 478227000
I1027 13:10:19.280589  9023 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1027 13:10:19.280598  9023 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1027 13:10:19.280604  9023 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1027 13:10:19.280611  9023 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1027 13:10:19.280618  9023 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I1027 13:10:19.280632  9023 net.cpp:84] Creating Layer fire2/relu_expand1x1
I1027 13:10:19.280637  9023 net.cpp:413] fire2/relu_expand1x1 <- fire2/expand1x1
I1027 13:10:19.280644  9023 net.cpp:374] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I1027 13:10:19.282193  9023 net.cpp:127] Setting up fire2/relu_expand1x1
I1027 13:10:19.282213  9023 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 13:10:19.282219  9023 net.cpp:144] Memory required for data: 518367800
I1027 13:10:19.282224  9023 layer_factory.hpp:77] Creating layer fire2/expand3x3
I1027 13:10:19.282240  9023 net.cpp:84] Creating Layer fire2/expand3x3
I1027 13:10:19.282248  9023 net.cpp:413] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1027 13:10:19.282260  9023 net.cpp:387] fire2/expand3x3 -> fire2/expand3x3
I1027 13:10:19.282716  9023 net.cpp:127] Setting up fire2/expand3x3
I1027 13:10:19.282730  9023 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 13:10:19.282735  9023 net.cpp:144] Memory required for data: 558508600
I1027 13:10:19.282742  9023 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1027 13:10:19.282749  9023 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1027 13:10:19.282755  9023 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1027 13:10:19.282760  9023 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1027 13:10:19.282766  9023 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I1027 13:10:19.282775  9023 net.cpp:84] Creating Layer fire2/relu_expand3x3
I1027 13:10:19.282783  9023 net.cpp:413] fire2/relu_expand3x3 <- fire2/expand3x3
I1027 13:10:19.282790  9023 net.cpp:374] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I1027 13:10:19.283006  9023 net.cpp:127] Setting up fire2/relu_expand3x3
I1027 13:10:19.283018  9023 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 13:10:19.283025  9023 net.cpp:144] Memory required for data: 598649400
I1027 13:10:19.283042  9023 layer_factory.hpp:77] Creating layer fire2/concat
I1027 13:10:19.283053  9023 net.cpp:84] Creating Layer fire2/concat
I1027 13:10:19.283059  9023 net.cpp:413] fire2/concat <- fire2/expand1x1
I1027 13:10:19.283068  9023 net.cpp:413] fire2/concat <- fire2/expand3x3
I1027 13:10:19.283077  9023 net.cpp:387] fire2/concat -> fire2/concat
I1027 13:10:19.283110  9023 net.cpp:127] Setting up fire2/concat
I1027 13:10:19.283120  9023 net.cpp:136] Top shape: 50 128 56 56 (20070400)
I1027 13:10:19.283126  9023 net.cpp:144] Memory required for data: 678931000
I1027 13:10:19.283133  9023 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I1027 13:10:19.283144  9023 net.cpp:84] Creating Layer fire3/squeeze1x1
I1027 13:10:19.283149  9023 net.cpp:413] fire3/squeeze1x1 <- fire2/concat
I1027 13:10:19.283157  9023 net.cpp:387] fire3/squeeze1x1 -> fire3/squeeze1x1
I1027 13:10:19.283512  9023 net.cpp:127] Setting up fire3/squeeze1x1
I1027 13:10:19.283527  9023 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1027 13:10:19.283532  9023 net.cpp:144] Memory required for data: 688966200
I1027 13:10:19.283541  9023 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1027 13:10:19.283550  9023 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1027 13:10:19.283556  9023 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1027 13:10:19.283563  9023 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1027 13:10:19.283569  9023 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I1027 13:10:19.283581  9023 net.cpp:84] Creating Layer fire3/relu_squeeze1x1
I1027 13:10:19.283586  9023 net.cpp:413] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I1027 13:10:19.283596  9023 net.cpp:374] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I1027 13:10:19.283803  9023 net.cpp:127] Setting up fire3/relu_squeeze1x1
I1027 13:10:19.283816  9023 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1027 13:10:19.283821  9023 net.cpp:144] Memory required for data: 699001400
I1027 13:10:19.283828  9023 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1027 13:10:19.283834  9023 net.cpp:84] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1027 13:10:19.283839  9023 net.cpp:413] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I1027 13:10:19.283849  9023 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1027 13:10:19.283857  9023 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1027 13:10:19.283906  9023 net.cpp:127] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1027 13:10:19.283916  9023 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1027 13:10:19.283922  9023 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1027 13:10:19.283927  9023 net.cpp:144] Memory required for data: 719071800
I1027 13:10:19.283932  9023 layer_factory.hpp:77] Creating layer fire3/expand1x1
I1027 13:10:19.283947  9023 net.cpp:84] Creating Layer fire3/expand1x1
I1027 13:10:19.283953  9023 net.cpp:413] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1027 13:10:19.283962  9023 net.cpp:387] fire3/expand1x1 -> fire3/expand1x1
I1027 13:10:19.284309  9023 net.cpp:127] Setting up fire3/expand1x1
I1027 13:10:19.284322  9023 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 13:10:19.284327  9023 net.cpp:144] Memory required for data: 759212600
I1027 13:10:19.284334  9023 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1027 13:10:19.284342  9023 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1027 13:10:19.284346  9023 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1027 13:10:19.284360  9023 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1027 13:10:19.284368  9023 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I1027 13:10:19.284389  9023 net.cpp:84] Creating Layer fire3/relu_expand1x1
I1027 13:10:19.284394  9023 net.cpp:413] fire3/relu_expand1x1 <- fire3/expand1x1
I1027 13:10:19.284402  9023 net.cpp:374] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I1027 13:10:19.284610  9023 net.cpp:127] Setting up fire3/relu_expand1x1
I1027 13:10:19.284623  9023 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 13:10:19.284628  9023 net.cpp:144] Memory required for data: 799353400
I1027 13:10:19.284634  9023 layer_factory.hpp:77] Creating layer fire3/expand3x3
I1027 13:10:19.284646  9023 net.cpp:84] Creating Layer fire3/expand3x3
I1027 13:10:19.284651  9023 net.cpp:413] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1027 13:10:19.284662  9023 net.cpp:387] fire3/expand3x3 -> fire3/expand3x3
I1027 13:10:19.285089  9023 net.cpp:127] Setting up fire3/expand3x3
I1027 13:10:19.285101  9023 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 13:10:19.285106  9023 net.cpp:144] Memory required for data: 839494200
I1027 13:10:19.285114  9023 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1027 13:10:19.285120  9023 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1027 13:10:19.285125  9023 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1027 13:10:19.285130  9023 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1027 13:10:19.285136  9023 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I1027 13:10:19.285145  9023 net.cpp:84] Creating Layer fire3/relu_expand3x3
I1027 13:10:19.285151  9023 net.cpp:413] fire3/relu_expand3x3 <- fire3/expand3x3
I1027 13:10:19.285158  9023 net.cpp:374] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I1027 13:10:19.286546  9023 net.cpp:127] Setting up fire3/relu_expand3x3
I1027 13:10:19.286566  9023 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1027 13:10:19.286572  9023 net.cpp:144] Memory required for data: 879635000
I1027 13:10:19.286577  9023 layer_factory.hpp:77] Creating layer fire3/concat
I1027 13:10:19.286586  9023 net.cpp:84] Creating Layer fire3/concat
I1027 13:10:19.286592  9023 net.cpp:413] fire3/concat <- fire3/expand1x1
I1027 13:10:19.286599  9023 net.cpp:413] fire3/concat <- fire3/expand3x3
I1027 13:10:19.286607  9023 net.cpp:387] fire3/concat -> fire3/concat
I1027 13:10:19.286648  9023 net.cpp:127] Setting up fire3/concat
I1027 13:10:19.286658  9023 net.cpp:136] Top shape: 50 128 56 56 (20070400)
I1027 13:10:19.286661  9023 net.cpp:144] Memory required for data: 959916600
I1027 13:10:19.286665  9023 layer_factory.hpp:77] Creating layer pool3
I1027 13:10:19.286677  9023 net.cpp:84] Creating Layer pool3
I1027 13:10:19.286682  9023 net.cpp:413] pool3 <- fire3/concat
I1027 13:10:19.286689  9023 net.cpp:387] pool3 -> pool3
I1027 13:10:19.286736  9023 net.cpp:127] Setting up pool3
I1027 13:10:19.286746  9023 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 13:10:19.286749  9023 net.cpp:144] Memory required for data: 979987000
I1027 13:10:19.286754  9023 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I1027 13:10:19.286767  9023 net.cpp:84] Creating Layer fire4/squeeze1x1
I1027 13:10:19.286772  9023 net.cpp:413] fire4/squeeze1x1 <- pool3
I1027 13:10:19.286780  9023 net.cpp:387] fire4/squeeze1x1 -> fire4/squeeze1x1
I1027 13:10:19.287175  9023 net.cpp:127] Setting up fire4/squeeze1x1
I1027 13:10:19.287187  9023 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1027 13:10:19.287192  9023 net.cpp:144] Memory required for data: 985004600
I1027 13:10:19.287199  9023 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1027 13:10:19.287206  9023 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1027 13:10:19.287212  9023 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1027 13:10:19.287225  9023 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1027 13:10:19.287230  9023 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I1027 13:10:19.287250  9023 net.cpp:84] Creating Layer fire4/relu_squeeze1x1
I1027 13:10:19.287256  9023 net.cpp:413] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I1027 13:10:19.287261  9023 net.cpp:374] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I1027 13:10:19.287482  9023 net.cpp:127] Setting up fire4/relu_squeeze1x1
I1027 13:10:19.287495  9023 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1027 13:10:19.287500  9023 net.cpp:144] Memory required for data: 990022200
I1027 13:10:19.287508  9023 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1027 13:10:19.287514  9023 net.cpp:84] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1027 13:10:19.287519  9023 net.cpp:413] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I1027 13:10:19.287526  9023 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1027 13:10:19.287536  9023 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1027 13:10:19.287587  9023 net.cpp:127] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1027 13:10:19.287597  9023 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1027 13:10:19.287605  9023 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1027 13:10:19.287611  9023 net.cpp:144] Memory required for data: 1000057400
I1027 13:10:19.287614  9023 layer_factory.hpp:77] Creating layer fire4/expand1x1
I1027 13:10:19.287627  9023 net.cpp:84] Creating Layer fire4/expand1x1
I1027 13:10:19.287633  9023 net.cpp:413] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1027 13:10:19.287642  9023 net.cpp:387] fire4/expand1x1 -> fire4/expand1x1
I1027 13:10:19.287999  9023 net.cpp:127] Setting up fire4/expand1x1
I1027 13:10:19.288012  9023 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 13:10:19.288017  9023 net.cpp:144] Memory required for data: 1020127800
I1027 13:10:19.288028  9023 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1027 13:10:19.288038  9023 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1027 13:10:19.288044  9023 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1027 13:10:19.288050  9023 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1027 13:10:19.288055  9023 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I1027 13:10:19.288064  9023 net.cpp:84] Creating Layer fire4/relu_expand1x1
I1027 13:10:19.288069  9023 net.cpp:413] fire4/relu_expand1x1 <- fire4/expand1x1
I1027 13:10:19.288076  9023 net.cpp:374] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I1027 13:10:19.288280  9023 net.cpp:127] Setting up fire4/relu_expand1x1
I1027 13:10:19.288290  9023 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 13:10:19.288301  9023 net.cpp:144] Memory required for data: 1040198200
I1027 13:10:19.288308  9023 layer_factory.hpp:77] Creating layer fire4/expand3x3
I1027 13:10:19.288323  9023 net.cpp:84] Creating Layer fire4/expand3x3
I1027 13:10:19.288331  9023 net.cpp:413] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1027 13:10:19.288338  9023 net.cpp:387] fire4/expand3x3 -> fire4/expand3x3
I1027 13:10:19.289000  9023 net.cpp:127] Setting up fire4/expand3x3
I1027 13:10:19.289011  9023 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 13:10:19.289016  9023 net.cpp:144] Memory required for data: 1060268600
I1027 13:10:19.289022  9023 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1027 13:10:19.289028  9023 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1027 13:10:19.289036  9023 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1027 13:10:19.289047  9023 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1027 13:10:19.289052  9023 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I1027 13:10:19.289069  9023 net.cpp:84] Creating Layer fire4/relu_expand3x3
I1027 13:10:19.289075  9023 net.cpp:413] fire4/relu_expand3x3 <- fire4/expand3x3
I1027 13:10:19.289082  9023 net.cpp:374] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I1027 13:10:19.289286  9023 net.cpp:127] Setting up fire4/relu_expand3x3
I1027 13:10:19.289304  9023 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 13:10:19.289314  9023 net.cpp:144] Memory required for data: 1080339000
I1027 13:10:19.289319  9023 layer_factory.hpp:77] Creating layer fire4/concat
I1027 13:10:19.289327  9023 net.cpp:84] Creating Layer fire4/concat
I1027 13:10:19.289332  9023 net.cpp:413] fire4/concat <- fire4/expand1x1
I1027 13:10:19.289338  9023 net.cpp:413] fire4/concat <- fire4/expand3x3
I1027 13:10:19.289345  9023 net.cpp:387] fire4/concat -> fire4/concat
I1027 13:10:19.289378  9023 net.cpp:127] Setting up fire4/concat
I1027 13:10:19.289386  9023 net.cpp:136] Top shape: 50 256 28 28 (10035200)
I1027 13:10:19.289391  9023 net.cpp:144] Memory required for data: 1120479800
I1027 13:10:19.289397  9023 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I1027 13:10:19.289407  9023 net.cpp:84] Creating Layer fire5/squeeze1x1
I1027 13:10:19.289412  9023 net.cpp:413] fire5/squeeze1x1 <- fire4/concat
I1027 13:10:19.289423  9023 net.cpp:387] fire5/squeeze1x1 -> fire5/squeeze1x1
I1027 13:10:19.289831  9023 net.cpp:127] Setting up fire5/squeeze1x1
I1027 13:10:19.289844  9023 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1027 13:10:19.289849  9023 net.cpp:144] Memory required for data: 1125497400
I1027 13:10:19.289855  9023 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1027 13:10:19.289862  9023 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1027 13:10:19.289868  9023 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1027 13:10:19.289873  9023 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1027 13:10:19.289880  9023 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I1027 13:10:19.289890  9023 net.cpp:84] Creating Layer fire5/relu_squeeze1x1
I1027 13:10:19.289897  9023 net.cpp:413] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I1027 13:10:19.289903  9023 net.cpp:374] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I1027 13:10:19.291290  9023 net.cpp:127] Setting up fire5/relu_squeeze1x1
I1027 13:10:19.291311  9023 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1027 13:10:19.291318  9023 net.cpp:144] Memory required for data: 1130515000
I1027 13:10:19.291323  9023 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1027 13:10:19.291337  9023 net.cpp:84] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1027 13:10:19.291342  9023 net.cpp:413] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I1027 13:10:19.291350  9023 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1027 13:10:19.291363  9023 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1027 13:10:19.291417  9023 net.cpp:127] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1027 13:10:19.291425  9023 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1027 13:10:19.291430  9023 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1027 13:10:19.291435  9023 net.cpp:144] Memory required for data: 1140550200
I1027 13:10:19.291440  9023 layer_factory.hpp:77] Creating layer fire5/expand1x1
I1027 13:10:19.291450  9023 net.cpp:84] Creating Layer fire5/expand1x1
I1027 13:10:19.291456  9023 net.cpp:413] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1027 13:10:19.291465  9023 net.cpp:387] fire5/expand1x1 -> fire5/expand1x1
I1027 13:10:19.291832  9023 net.cpp:127] Setting up fire5/expand1x1
I1027 13:10:19.291851  9023 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 13:10:19.291857  9023 net.cpp:144] Memory required for data: 1160620600
I1027 13:10:19.291863  9023 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1027 13:10:19.291882  9023 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1027 13:10:19.291887  9023 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1027 13:10:19.291894  9023 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1027 13:10:19.291900  9023 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I1027 13:10:19.291909  9023 net.cpp:84] Creating Layer fire5/relu_expand1x1
I1027 13:10:19.291915  9023 net.cpp:413] fire5/relu_expand1x1 <- fire5/expand1x1
I1027 13:10:19.291923  9023 net.cpp:374] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I1027 13:10:19.292125  9023 net.cpp:127] Setting up fire5/relu_expand1x1
I1027 13:10:19.292137  9023 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 13:10:19.292142  9023 net.cpp:144] Memory required for data: 1180691000
I1027 13:10:19.292148  9023 layer_factory.hpp:77] Creating layer fire5/expand3x3
I1027 13:10:19.292162  9023 net.cpp:84] Creating Layer fire5/expand3x3
I1027 13:10:19.292171  9023 net.cpp:413] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1027 13:10:19.292178  9023 net.cpp:387] fire5/expand3x3 -> fire5/expand3x3
I1027 13:10:19.292845  9023 net.cpp:127] Setting up fire5/expand3x3
I1027 13:10:19.292858  9023 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 13:10:19.292863  9023 net.cpp:144] Memory required for data: 1200761400
I1027 13:10:19.292870  9023 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1027 13:10:19.292877  9023 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1027 13:10:19.292883  9023 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1027 13:10:19.292888  9023 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1027 13:10:19.292893  9023 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I1027 13:10:19.292901  9023 net.cpp:84] Creating Layer fire5/relu_expand3x3
I1027 13:10:19.292909  9023 net.cpp:413] fire5/relu_expand3x3 <- fire5/expand3x3
I1027 13:10:19.292917  9023 net.cpp:374] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I1027 13:10:19.293124  9023 net.cpp:127] Setting up fire5/relu_expand3x3
I1027 13:10:19.293136  9023 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1027 13:10:19.293141  9023 net.cpp:144] Memory required for data: 1220831800
I1027 13:10:19.293148  9023 layer_factory.hpp:77] Creating layer fire5/concat
I1027 13:10:19.293155  9023 net.cpp:84] Creating Layer fire5/concat
I1027 13:10:19.293160  9023 net.cpp:413] fire5/concat <- fire5/expand1x1
I1027 13:10:19.293167  9023 net.cpp:413] fire5/concat <- fire5/expand3x3
I1027 13:10:19.293174  9023 net.cpp:387] fire5/concat -> fire5/concat
I1027 13:10:19.293206  9023 net.cpp:127] Setting up fire5/concat
I1027 13:10:19.293215  9023 net.cpp:136] Top shape: 50 256 28 28 (10035200)
I1027 13:10:19.293220  9023 net.cpp:144] Memory required for data: 1260972600
I1027 13:10:19.293226  9023 layer_factory.hpp:77] Creating layer pool5
I1027 13:10:19.293236  9023 net.cpp:84] Creating Layer pool5
I1027 13:10:19.293241  9023 net.cpp:413] pool5 <- fire5/concat
I1027 13:10:19.293247  9023 net.cpp:387] pool5 -> pool5
I1027 13:10:19.293303  9023 net.cpp:127] Setting up pool5
I1027 13:10:19.293313  9023 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 13:10:19.293319  9023 net.cpp:144] Memory required for data: 1271007800
I1027 13:10:19.293326  9023 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I1027 13:10:19.293339  9023 net.cpp:84] Creating Layer fire6/squeeze1x1
I1027 13:10:19.293344  9023 net.cpp:413] fire6/squeeze1x1 <- pool5
I1027 13:10:19.293354  9023 net.cpp:387] fire6/squeeze1x1 -> fire6/squeeze1x1
I1027 13:10:19.293813  9023 net.cpp:127] Setting up fire6/squeeze1x1
I1027 13:10:19.293831  9023 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1027 13:10:19.293836  9023 net.cpp:144] Memory required for data: 1272889400
I1027 13:10:19.293843  9023 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1027 13:10:19.293861  9023 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1027 13:10:19.293869  9023 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1027 13:10:19.293875  9023 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1027 13:10:19.293881  9023 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I1027 13:10:19.293889  9023 net.cpp:84] Creating Layer fire6/relu_squeeze1x1
I1027 13:10:19.293895  9023 net.cpp:413] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I1027 13:10:19.293903  9023 net.cpp:374] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I1027 13:10:19.294111  9023 net.cpp:127] Setting up fire6/relu_squeeze1x1
I1027 13:10:19.294123  9023 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1027 13:10:19.294128  9023 net.cpp:144] Memory required for data: 1274771000
I1027 13:10:19.294134  9023 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1027 13:10:19.294142  9023 net.cpp:84] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1027 13:10:19.294147  9023 net.cpp:413] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I1027 13:10:19.294157  9023 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1027 13:10:19.294167  9023 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1027 13:10:19.294234  9023 net.cpp:127] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1027 13:10:19.294243  9023 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1027 13:10:19.294250  9023 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1027 13:10:19.294255  9023 net.cpp:144] Memory required for data: 1278534200
I1027 13:10:19.294260  9023 layer_factory.hpp:77] Creating layer fire6/expand1x1
I1027 13:10:19.294272  9023 net.cpp:84] Creating Layer fire6/expand1x1
I1027 13:10:19.294278  9023 net.cpp:413] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1027 13:10:19.294286  9023 net.cpp:387] fire6/expand1x1 -> fire6/expand1x1
I1027 13:10:19.294699  9023 net.cpp:127] Setting up fire6/expand1x1
I1027 13:10:19.294713  9023 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1027 13:10:19.294718  9023 net.cpp:144] Memory required for data: 1286060600
I1027 13:10:19.294726  9023 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1027 13:10:19.294733  9023 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1027 13:10:19.294739  9023 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1027 13:10:19.294744  9023 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1027 13:10:19.294749  9023 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I1027 13:10:19.294764  9023 net.cpp:84] Creating Layer fire6/relu_expand1x1
I1027 13:10:19.294771  9023 net.cpp:413] fire6/relu_expand1x1 <- fire6/expand1x1
I1027 13:10:19.294777  9023 net.cpp:374] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I1027 13:10:19.296164  9023 net.cpp:127] Setting up fire6/relu_expand1x1
I1027 13:10:19.296185  9023 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1027 13:10:19.296192  9023 net.cpp:144] Memory required for data: 1293587000
I1027 13:10:19.296200  9023 layer_factory.hpp:77] Creating layer fire6/expand3x3
I1027 13:10:19.296211  9023 net.cpp:84] Creating Layer fire6/expand3x3
I1027 13:10:19.296217  9023 net.cpp:413] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1027 13:10:19.296229  9023 net.cpp:387] fire6/expand3x3 -> fire6/expand3x3
I1027 13:10:19.297300  9023 net.cpp:127] Setting up fire6/expand3x3
I1027 13:10:19.297314  9023 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1027 13:10:19.297325  9023 net.cpp:144] Memory required for data: 1301113400
I1027 13:10:19.297333  9023 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1027 13:10:19.297355  9023 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1027 13:10:19.297366  9023 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1027 13:10:19.297372  9023 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1027 13:10:19.297377  9023 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I1027 13:10:19.297386  9023 net.cpp:84] Creating Layer fire6/relu_expand3x3
I1027 13:10:19.297392  9023 net.cpp:413] fire6/relu_expand3x3 <- fire6/expand3x3
I1027 13:10:19.297399  9023 net.cpp:374] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I1027 13:10:19.297605  9023 net.cpp:127] Setting up fire6/relu_expand3x3
I1027 13:10:19.297617  9023 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1027 13:10:19.297623  9023 net.cpp:144] Memory required for data: 1308639800
I1027 13:10:19.297629  9023 layer_factory.hpp:77] Creating layer fire6/concat
I1027 13:10:19.297639  9023 net.cpp:84] Creating Layer fire6/concat
I1027 13:10:19.297644  9023 net.cpp:413] fire6/concat <- fire6/expand1x1
I1027 13:10:19.297650  9023 net.cpp:413] fire6/concat <- fire6/expand3x3
I1027 13:10:19.297658  9023 net.cpp:387] fire6/concat -> fire6/concat
I1027 13:10:19.297694  9023 net.cpp:127] Setting up fire6/concat
I1027 13:10:19.297703  9023 net.cpp:136] Top shape: 50 384 14 14 (3763200)
I1027 13:10:19.297708  9023 net.cpp:144] Memory required for data: 1323692600
I1027 13:10:19.297713  9023 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I1027 13:10:19.297724  9023 net.cpp:84] Creating Layer fire7/squeeze1x1
I1027 13:10:19.297729  9023 net.cpp:413] fire7/squeeze1x1 <- fire6/concat
I1027 13:10:19.297736  9023 net.cpp:387] fire7/squeeze1x1 -> fire7/squeeze1x1
I1027 13:10:19.298234  9023 net.cpp:127] Setting up fire7/squeeze1x1
I1027 13:10:19.298246  9023 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1027 13:10:19.298252  9023 net.cpp:144] Memory required for data: 1325574200
I1027 13:10:19.298269  9023 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1027 13:10:19.298280  9023 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1027 13:10:19.298286  9023 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1027 13:10:19.298295  9023 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1027 13:10:19.298310  9023 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I1027 13:10:19.298317  9023 net.cpp:84] Creating Layer fire7/relu_squeeze1x1
I1027 13:10:19.298322  9023 net.cpp:413] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I1027 13:10:19.298329  9023 net.cpp:374] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I1027 13:10:19.298542  9023 net.cpp:127] Setting up fire7/relu_squeeze1x1
I1027 13:10:19.298555  9023 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1027 13:10:19.298560  9023 net.cpp:144] Memory required for data: 1327455800
I1027 13:10:19.298566  9023 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1027 13:10:19.298575  9023 net.cpp:84] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1027 13:10:19.298580  9023 net.cpp:413] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I1027 13:10:19.298588  9023 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1027 13:10:19.298599  9023 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1027 13:10:19.298647  9023 net.cpp:127] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1027 13:10:19.298657  9023 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1027 13:10:19.298665  9023 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1027 13:10:19.298669  9023 net.cpp:144] Memory required for data: 1331219000
I1027 13:10:19.298679  9023 layer_factory.hpp:77] Creating layer fire7/expand1x1
I1027 13:10:19.298692  9023 net.cpp:84] Creating Layer fire7/expand1x1
I1027 13:10:19.298708  9023 net.cpp:413] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1027 13:10:19.298718  9023 net.cpp:387] fire7/expand1x1 -> fire7/expand1x1
I1027 13:10:19.299130  9023 net.cpp:127] Setting up fire7/expand1x1
I1027 13:10:19.299142  9023 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1027 13:10:19.299149  9023 net.cpp:144] Memory required for data: 1338745400
I1027 13:10:19.299156  9023 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1027 13:10:19.299162  9023 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1027 13:10:19.299168  9023 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1027 13:10:19.299173  9023 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1027 13:10:19.299178  9023 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I1027 13:10:19.299185  9023 net.cpp:84] Creating Layer fire7/relu_expand1x1
I1027 13:10:19.299190  9023 net.cpp:413] fire7/relu_expand1x1 <- fire7/expand1x1
I1027 13:10:19.299199  9023 net.cpp:374] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I1027 13:10:19.300590  9023 net.cpp:127] Setting up fire7/relu_expand1x1
I1027 13:10:19.300611  9023 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1027 13:10:19.300619  9023 net.cpp:144] Memory required for data: 1346271800
I1027 13:10:19.300626  9023 layer_factory.hpp:77] Creating layer fire7/expand3x3
I1027 13:10:19.300640  9023 net.cpp:84] Creating Layer fire7/expand3x3
I1027 13:10:19.300647  9023 net.cpp:413] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1027 13:10:19.300658  9023 net.cpp:387] fire7/expand3x3 -> fire7/expand3x3
I1027 13:10:19.301734  9023 net.cpp:127] Setting up fire7/expand3x3
I1027 13:10:19.301749  9023 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1027 13:10:19.301754  9023 net.cpp:144] Memory required for data: 1353798200
I1027 13:10:19.301762  9023 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1027 13:10:19.301771  9023 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1027 13:10:19.301782  9023 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1027 13:10:19.301789  9023 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1027 13:10:19.301793  9023 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I1027 13:10:19.301800  9023 net.cpp:84] Creating Layer fire7/relu_expand3x3
I1027 13:10:19.301806  9023 net.cpp:413] fire7/relu_expand3x3 <- fire7/expand3x3
I1027 13:10:19.301813  9023 net.cpp:374] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I1027 13:10:19.302027  9023 net.cpp:127] Setting up fire7/relu_expand3x3
I1027 13:10:19.302040  9023 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1027 13:10:19.302047  9023 net.cpp:144] Memory required for data: 1361324600
I1027 13:10:19.302052  9023 layer_factory.hpp:77] Creating layer fire7/concat
I1027 13:10:19.302060  9023 net.cpp:84] Creating Layer fire7/concat
I1027 13:10:19.302065  9023 net.cpp:413] fire7/concat <- fire7/expand1x1
I1027 13:10:19.302072  9023 net.cpp:413] fire7/concat <- fire7/expand3x3
I1027 13:10:19.302078  9023 net.cpp:387] fire7/concat -> fire7/concat
I1027 13:10:19.302112  9023 net.cpp:127] Setting up fire7/concat
I1027 13:10:19.302121  9023 net.cpp:136] Top shape: 50 384 14 14 (3763200)
I1027 13:10:19.302126  9023 net.cpp:144] Memory required for data: 1376377400
I1027 13:10:19.302131  9023 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I1027 13:10:19.302144  9023 net.cpp:84] Creating Layer fire8/squeeze1x1
I1027 13:10:19.302150  9023 net.cpp:413] fire8/squeeze1x1 <- fire7/concat
I1027 13:10:19.302158  9023 net.cpp:387] fire8/squeeze1x1 -> fire8/squeeze1x1
I1027 13:10:19.304096  9023 net.cpp:127] Setting up fire8/squeeze1x1
I1027 13:10:19.304122  9023 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1027 13:10:19.304128  9023 net.cpp:144] Memory required for data: 1378886200
I1027 13:10:19.304136  9023 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1027 13:10:19.304157  9023 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1027 13:10:19.304163  9023 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1027 13:10:19.304168  9023 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1027 13:10:19.304173  9023 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I1027 13:10:19.304184  9023 net.cpp:84] Creating Layer fire8/relu_squeeze1x1
I1027 13:10:19.304191  9023 net.cpp:413] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I1027 13:10:19.304198  9023 net.cpp:374] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I1027 13:10:19.304428  9023 net.cpp:127] Setting up fire8/relu_squeeze1x1
I1027 13:10:19.304442  9023 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1027 13:10:19.304448  9023 net.cpp:144] Memory required for data: 1381395000
I1027 13:10:19.304455  9023 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1027 13:10:19.304466  9023 net.cpp:84] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1027 13:10:19.304471  9023 net.cpp:413] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I1027 13:10:19.304478  9023 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1027 13:10:19.304487  9023 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1027 13:10:19.304540  9023 net.cpp:127] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1027 13:10:19.304558  9023 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1027 13:10:19.304564  9023 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1027 13:10:19.304569  9023 net.cpp:144] Memory required for data: 1386412600
I1027 13:10:19.304574  9023 layer_factory.hpp:77] Creating layer fire8/expand1x1
I1027 13:10:19.304587  9023 net.cpp:84] Creating Layer fire8/expand1x1
I1027 13:10:19.304594  9023 net.cpp:413] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1027 13:10:19.304602  9023 net.cpp:387] fire8/expand1x1 -> fire8/expand1x1
I1027 13:10:19.305078  9023 net.cpp:127] Setting up fire8/expand1x1
I1027 13:10:19.305088  9023 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 13:10:19.305094  9023 net.cpp:144] Memory required for data: 1396447800
I1027 13:10:19.305101  9023 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1027 13:10:19.305107  9023 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1027 13:10:19.305114  9023 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1027 13:10:19.305119  9023 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1027 13:10:19.305124  9023 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I1027 13:10:19.305132  9023 net.cpp:84] Creating Layer fire8/relu_expand1x1
I1027 13:10:19.305138  9023 net.cpp:413] fire8/relu_expand1x1 <- fire8/expand1x1
I1027 13:10:19.305147  9023 net.cpp:374] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I1027 13:10:19.305367  9023 net.cpp:127] Setting up fire8/relu_expand1x1
I1027 13:10:19.305382  9023 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 13:10:19.305387  9023 net.cpp:144] Memory required for data: 1406483000
I1027 13:10:19.305395  9023 layer_factory.hpp:77] Creating layer fire8/expand3x3
I1027 13:10:19.305408  9023 net.cpp:84] Creating Layer fire8/expand3x3
I1027 13:10:19.305414  9023 net.cpp:413] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1027 13:10:19.305424  9023 net.cpp:387] fire8/expand3x3 -> fire8/expand3x3
I1027 13:10:19.308270  9023 net.cpp:127] Setting up fire8/expand3x3
I1027 13:10:19.308291  9023 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 13:10:19.308307  9023 net.cpp:144] Memory required for data: 1416518200
I1027 13:10:19.308318  9023 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1027 13:10:19.308339  9023 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1027 13:10:19.308346  9023 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1027 13:10:19.308351  9023 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1027 13:10:19.308357  9023 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I1027 13:10:19.308368  9023 net.cpp:84] Creating Layer fire8/relu_expand3x3
I1027 13:10:19.308375  9023 net.cpp:413] fire8/relu_expand3x3 <- fire8/expand3x3
I1027 13:10:19.308384  9023 net.cpp:374] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I1027 13:10:19.309803  9023 net.cpp:127] Setting up fire8/relu_expand3x3
I1027 13:10:19.309823  9023 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 13:10:19.309828  9023 net.cpp:144] Memory required for data: 1426553400
I1027 13:10:19.309834  9023 layer_factory.hpp:77] Creating layer fire8/concat
I1027 13:10:19.309842  9023 net.cpp:84] Creating Layer fire8/concat
I1027 13:10:19.309849  9023 net.cpp:413] fire8/concat <- fire8/expand1x1
I1027 13:10:19.309854  9023 net.cpp:413] fire8/concat <- fire8/expand3x3
I1027 13:10:19.309862  9023 net.cpp:387] fire8/concat -> fire8/concat
I1027 13:10:19.309902  9023 net.cpp:127] Setting up fire8/concat
I1027 13:10:19.309912  9023 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1027 13:10:19.309916  9023 net.cpp:144] Memory required for data: 1446623800
I1027 13:10:19.309921  9023 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I1027 13:10:19.309933  9023 net.cpp:84] Creating Layer fire9/squeeze1x1
I1027 13:10:19.309938  9023 net.cpp:413] fire9/squeeze1x1 <- fire8/concat
I1027 13:10:19.309948  9023 net.cpp:387] fire9/squeeze1x1 -> fire9/squeeze1x1
I1027 13:10:19.310565  9023 net.cpp:127] Setting up fire9/squeeze1x1
I1027 13:10:19.310578  9023 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1027 13:10:19.310583  9023 net.cpp:144] Memory required for data: 1449132600
I1027 13:10:19.310590  9023 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1027 13:10:19.310597  9023 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1027 13:10:19.310603  9023 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1027 13:10:19.310608  9023 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1027 13:10:19.310614  9023 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I1027 13:10:19.310636  9023 net.cpp:84] Creating Layer fire9/relu_squeeze1x1
I1027 13:10:19.310643  9023 net.cpp:413] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I1027 13:10:19.310653  9023 net.cpp:374] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I1027 13:10:19.310864  9023 net.cpp:127] Setting up fire9/relu_squeeze1x1
I1027 13:10:19.310876  9023 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1027 13:10:19.310883  9023 net.cpp:144] Memory required for data: 1451641400
I1027 13:10:19.310889  9023 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1027 13:10:19.310896  9023 net.cpp:84] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1027 13:10:19.310901  9023 net.cpp:413] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I1027 13:10:19.310910  9023 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1027 13:10:19.310920  9023 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1027 13:10:19.310971  9023 net.cpp:127] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1027 13:10:19.310981  9023 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1027 13:10:19.310986  9023 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1027 13:10:19.310992  9023 net.cpp:144] Memory required for data: 1456659000
I1027 13:10:19.311004  9023 layer_factory.hpp:77] Creating layer fire9/expand1x1
I1027 13:10:19.311019  9023 net.cpp:84] Creating Layer fire9/expand1x1
I1027 13:10:19.311025  9023 net.cpp:413] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1027 13:10:19.311044  9023 net.cpp:387] fire9/expand1x1 -> fire9/expand1x1
I1027 13:10:19.311538  9023 net.cpp:127] Setting up fire9/expand1x1
I1027 13:10:19.311550  9023 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 13:10:19.311556  9023 net.cpp:144] Memory required for data: 1466694200
I1027 13:10:19.311563  9023 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1027 13:10:19.311569  9023 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1027 13:10:19.311575  9023 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1027 13:10:19.311580  9023 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1027 13:10:19.311585  9023 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I1027 13:10:19.311592  9023 net.cpp:84] Creating Layer fire9/relu_expand1x1
I1027 13:10:19.311599  9023 net.cpp:413] fire9/relu_expand1x1 <- fire9/expand1x1
I1027 13:10:19.311605  9023 net.cpp:374] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I1027 13:10:19.311827  9023 net.cpp:127] Setting up fire9/relu_expand1x1
I1027 13:10:19.311839  9023 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 13:10:19.311844  9023 net.cpp:144] Memory required for data: 1476729400
I1027 13:10:19.311851  9023 layer_factory.hpp:77] Creating layer fire9/expand3x3
I1027 13:10:19.311863  9023 net.cpp:84] Creating Layer fire9/expand3x3
I1027 13:10:19.311869  9023 net.cpp:413] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1027 13:10:19.311879  9023 net.cpp:387] fire9/expand3x3 -> fire9/expand3x3
I1027 13:10:19.314740  9023 net.cpp:127] Setting up fire9/expand3x3
I1027 13:10:19.314760  9023 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 13:10:19.314766  9023 net.cpp:144] Memory required for data: 1486764600
I1027 13:10:19.314774  9023 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1027 13:10:19.314780  9023 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1027 13:10:19.314788  9023 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1027 13:10:19.314795  9023 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1027 13:10:19.314800  9023 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I1027 13:10:19.314806  9023 net.cpp:84] Creating Layer fire9/relu_expand3x3
I1027 13:10:19.314812  9023 net.cpp:413] fire9/relu_expand3x3 <- fire9/expand3x3
I1027 13:10:19.314822  9023 net.cpp:374] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I1027 13:10:19.315050  9023 net.cpp:127] Setting up fire9/relu_expand3x3
I1027 13:10:19.315063  9023 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1027 13:10:19.315068  9023 net.cpp:144] Memory required for data: 1496799800
I1027 13:10:19.315074  9023 layer_factory.hpp:77] Creating layer fire9/concat
I1027 13:10:19.315084  9023 net.cpp:84] Creating Layer fire9/concat
I1027 13:10:19.315090  9023 net.cpp:413] fire9/concat <- fire9/expand1x1
I1027 13:10:19.315098  9023 net.cpp:413] fire9/concat <- fire9/expand3x3
I1027 13:10:19.315104  9023 net.cpp:387] fire9/concat -> fire9/concat
I1027 13:10:19.315140  9023 net.cpp:127] Setting up fire9/concat
I1027 13:10:19.315153  9023 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1027 13:10:19.315158  9023 net.cpp:144] Memory required for data: 1516870200
I1027 13:10:19.315163  9023 layer_factory.hpp:77] Creating layer drop9
I1027 13:10:19.315173  9023 net.cpp:84] Creating Layer drop9
I1027 13:10:19.315178  9023 net.cpp:413] drop9 <- fire9/concat
I1027 13:10:19.315186  9023 net.cpp:374] drop9 -> fire9/concat (in-place)
I1027 13:10:19.315215  9023 net.cpp:127] Setting up drop9
I1027 13:10:19.315225  9023 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1027 13:10:19.315238  9023 net.cpp:144] Memory required for data: 1536940600
I1027 13:10:19.315244  9023 layer_factory.hpp:77] Creating layer conv10
I1027 13:10:19.315256  9023 net.cpp:84] Creating Layer conv10
I1027 13:10:19.315279  9023 net.cpp:413] conv10 <- fire9/concat
I1027 13:10:19.315289  9023 net.cpp:387] conv10 -> conv10
I1027 13:10:19.324847  9023 net.cpp:127] Setting up conv10
I1027 13:10:19.324872  9023 net.cpp:136] Top shape: 50 1000 14 14 (9800000)
I1027 13:10:19.324882  9023 net.cpp:144] Memory required for data: 1576140600
I1027 13:10:19.324890  9023 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1027 13:10:19.324898  9023 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1027 13:10:19.324903  9023 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1027 13:10:19.324909  9023 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1027 13:10:19.324914  9023 layer_factory.hpp:77] Creating layer relu_conv10
I1027 13:10:19.324923  9023 net.cpp:84] Creating Layer relu_conv10
I1027 13:10:19.324929  9023 net.cpp:413] relu_conv10 <- conv10
I1027 13:10:19.324937  9023 net.cpp:374] relu_conv10 -> conv10 (in-place)
I1027 13:10:19.326365  9023 net.cpp:127] Setting up relu_conv10
I1027 13:10:19.326385  9023 net.cpp:136] Top shape: 50 1000 14 14 (9800000)
I1027 13:10:19.326391  9023 net.cpp:144] Memory required for data: 1615340600
I1027 13:10:19.326396  9023 layer_factory.hpp:77] Creating layer pool10
I1027 13:10:19.326408  9023 net.cpp:84] Creating Layer pool10
I1027 13:10:19.326413  9023 net.cpp:413] pool10 <- conv10
I1027 13:10:19.326428  9023 net.cpp:387] pool10 -> pool10
I1027 13:10:19.326658  9023 net.cpp:127] Setting up pool10
I1027 13:10:19.326673  9023 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1027 13:10:19.326678  9023 net.cpp:144] Memory required for data: 1615540600
I1027 13:10:19.326683  9023 layer_factory.hpp:77] Creating layer pool10_pool10_0_split
I1027 13:10:19.326691  9023 net.cpp:84] Creating Layer pool10_pool10_0_split
I1027 13:10:19.326696  9023 net.cpp:413] pool10_pool10_0_split <- pool10
I1027 13:10:19.326705  9023 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_0
I1027 13:10:19.326714  9023 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_1
I1027 13:10:19.326722  9023 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_2
I1027 13:10:19.326786  9023 net.cpp:127] Setting up pool10_pool10_0_split
I1027 13:10:19.326797  9023 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1027 13:10:19.326803  9023 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1027 13:10:19.326810  9023 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1027 13:10:19.326814  9023 net.cpp:144] Memory required for data: 1616140600
I1027 13:10:19.326818  9023 layer_factory.hpp:77] Creating layer loss
I1027 13:10:19.326828  9023 net.cpp:84] Creating Layer loss
I1027 13:10:19.326833  9023 net.cpp:413] loss <- pool10_pool10_0_split_0
I1027 13:10:19.326840  9023 net.cpp:413] loss <- label_data_1_split_0
I1027 13:10:19.326846  9023 net.cpp:387] loss -> loss
I1027 13:10:19.326855  9023 layer_factory.hpp:77] Creating layer loss
I1027 13:10:19.327214  9023 net.cpp:127] Setting up loss
I1027 13:10:19.327229  9023 net.cpp:136] Top shape: (1)
I1027 13:10:19.327235  9023 net.cpp:139]     with loss weight 1
I1027 13:10:19.327249  9023 net.cpp:144] Memory required for data: 1616140604
I1027 13:10:19.327252  9023 layer_factory.hpp:77] Creating layer accuracy_top1
I1027 13:10:19.327265  9023 net.cpp:84] Creating Layer accuracy_top1
I1027 13:10:19.327272  9023 net.cpp:413] accuracy_top1 <- pool10_pool10_0_split_1
I1027 13:10:19.327280  9023 net.cpp:413] accuracy_top1 <- label_data_1_split_1
I1027 13:10:19.327286  9023 net.cpp:387] accuracy_top1 -> accuracy_top1
I1027 13:10:19.327306  9023 net.cpp:127] Setting up accuracy_top1
I1027 13:10:19.327313  9023 net.cpp:136] Top shape: (1)
I1027 13:10:19.327318  9023 net.cpp:144] Memory required for data: 1616140608
I1027 13:10:19.327322  9023 layer_factory.hpp:77] Creating layer accuracy_top5
I1027 13:10:19.327340  9023 net.cpp:84] Creating Layer accuracy_top5
I1027 13:10:19.327347  9023 net.cpp:413] accuracy_top5 <- pool10_pool10_0_split_2
I1027 13:10:19.327354  9023 net.cpp:413] accuracy_top5 <- label_data_1_split_2
I1027 13:10:19.327373  9023 net.cpp:387] accuracy_top5 -> accuracy_top5
I1027 13:10:19.327390  9023 net.cpp:127] Setting up accuracy_top5
I1027 13:10:19.327397  9023 net.cpp:136] Top shape: (1)
I1027 13:10:19.327402  9023 net.cpp:144] Memory required for data: 1616140612
I1027 13:10:19.327407  9023 net.cpp:207] accuracy_top5 does not need backward computation.
I1027 13:10:19.327412  9023 net.cpp:207] accuracy_top1 does not need backward computation.
I1027 13:10:19.327417  9023 net.cpp:205] loss needs backward computation.
I1027 13:10:19.327424  9023 net.cpp:205] pool10_pool10_0_split needs backward computation.
I1027 13:10:19.327428  9023 net.cpp:205] pool10 needs backward computation.
I1027 13:10:19.327432  9023 net.cpp:205] relu_conv10 needs backward computation.
I1027 13:10:19.327437  9023 net.cpp:205] conv10 needs backward computation.
I1027 13:10:19.327441  9023 net.cpp:205] drop9 needs backward computation.
I1027 13:10:19.327446  9023 net.cpp:205] fire9/concat needs backward computation.
I1027 13:10:19.327452  9023 net.cpp:205] fire9/relu_expand3x3 needs backward computation.
I1027 13:10:19.327457  9023 net.cpp:205] fire9/expand3x3 needs backward computation.
I1027 13:10:19.327462  9023 net.cpp:205] fire9/relu_expand1x1 needs backward computation.
I1027 13:10:19.327468  9023 net.cpp:205] fire9/expand1x1 needs backward computation.
I1027 13:10:19.327474  9023 net.cpp:205] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I1027 13:10:19.327481  9023 net.cpp:205] fire9/relu_squeeze1x1 needs backward computation.
I1027 13:10:19.327486  9023 net.cpp:205] fire9/squeeze1x1 needs backward computation.
I1027 13:10:19.327492  9023 net.cpp:205] fire8/concat needs backward computation.
I1027 13:10:19.327498  9023 net.cpp:205] fire8/relu_expand3x3 needs backward computation.
I1027 13:10:19.327505  9023 net.cpp:205] fire8/expand3x3 needs backward computation.
I1027 13:10:19.327512  9023 net.cpp:205] fire8/relu_expand1x1 needs backward computation.
I1027 13:10:19.327517  9023 net.cpp:205] fire8/expand1x1 needs backward computation.
I1027 13:10:19.327523  9023 net.cpp:205] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I1027 13:10:19.327530  9023 net.cpp:205] fire8/relu_squeeze1x1 needs backward computation.
I1027 13:10:19.327536  9023 net.cpp:205] fire8/squeeze1x1 needs backward computation.
I1027 13:10:19.327543  9023 net.cpp:205] fire7/concat needs backward computation.
I1027 13:10:19.327549  9023 net.cpp:205] fire7/relu_expand3x3 needs backward computation.
I1027 13:10:19.327554  9023 net.cpp:205] fire7/expand3x3 needs backward computation.
I1027 13:10:19.327566  9023 net.cpp:205] fire7/relu_expand1x1 needs backward computation.
I1027 13:10:19.327571  9023 net.cpp:205] fire7/expand1x1 needs backward computation.
I1027 13:10:19.327577  9023 net.cpp:205] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I1027 13:10:19.327584  9023 net.cpp:205] fire7/relu_squeeze1x1 needs backward computation.
I1027 13:10:19.327590  9023 net.cpp:205] fire7/squeeze1x1 needs backward computation.
I1027 13:10:19.327596  9023 net.cpp:205] fire6/concat needs backward computation.
I1027 13:10:19.327607  9023 net.cpp:205] fire6/relu_expand3x3 needs backward computation.
I1027 13:10:19.327612  9023 net.cpp:205] fire6/expand3x3 needs backward computation.
I1027 13:10:19.327617  9023 net.cpp:205] fire6/relu_expand1x1 needs backward computation.
I1027 13:10:19.327621  9023 net.cpp:205] fire6/expand1x1 needs backward computation.
I1027 13:10:19.327626  9023 net.cpp:205] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I1027 13:10:19.327631  9023 net.cpp:205] fire6/relu_squeeze1x1 needs backward computation.
I1027 13:10:19.327636  9023 net.cpp:205] fire6/squeeze1x1 needs backward computation.
I1027 13:10:19.327641  9023 net.cpp:205] pool5 needs backward computation.
I1027 13:10:19.327651  9023 net.cpp:205] fire5/concat needs backward computation.
I1027 13:10:19.327656  9023 net.cpp:205] fire5/relu_expand3x3 needs backward computation.
I1027 13:10:19.327666  9023 net.cpp:205] fire5/expand3x3 needs backward computation.
I1027 13:10:19.327672  9023 net.cpp:205] fire5/relu_expand1x1 needs backward computation.
I1027 13:10:19.327675  9023 net.cpp:205] fire5/expand1x1 needs backward computation.
I1027 13:10:19.327680  9023 net.cpp:205] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I1027 13:10:19.327685  9023 net.cpp:205] fire5/relu_squeeze1x1 needs backward computation.
I1027 13:10:19.327689  9023 net.cpp:205] fire5/squeeze1x1 needs backward computation.
I1027 13:10:19.327694  9023 net.cpp:205] fire4/concat needs backward computation.
I1027 13:10:19.327699  9023 net.cpp:205] fire4/relu_expand3x3 needs backward computation.
I1027 13:10:19.327703  9023 net.cpp:205] fire4/expand3x3 needs backward computation.
I1027 13:10:19.327708  9023 net.cpp:205] fire4/relu_expand1x1 needs backward computation.
I1027 13:10:19.327713  9023 net.cpp:205] fire4/expand1x1 needs backward computation.
I1027 13:10:19.327716  9023 net.cpp:205] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I1027 13:10:19.327721  9023 net.cpp:205] fire4/relu_squeeze1x1 needs backward computation.
I1027 13:10:19.327725  9023 net.cpp:205] fire4/squeeze1x1 needs backward computation.
I1027 13:10:19.327730  9023 net.cpp:205] pool3 needs backward computation.
I1027 13:10:19.327734  9023 net.cpp:205] fire3/concat needs backward computation.
I1027 13:10:19.327739  9023 net.cpp:205] fire3/relu_expand3x3 needs backward computation.
I1027 13:10:19.327744  9023 net.cpp:205] fire3/expand3x3 needs backward computation.
I1027 13:10:19.327749  9023 net.cpp:205] fire3/relu_expand1x1 needs backward computation.
I1027 13:10:19.327752  9023 net.cpp:205] fire3/expand1x1 needs backward computation.
I1027 13:10:19.327759  9023 net.cpp:205] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I1027 13:10:19.327764  9023 net.cpp:205] fire3/relu_squeeze1x1 needs backward computation.
I1027 13:10:19.327769  9023 net.cpp:205] fire3/squeeze1x1 needs backward computation.
I1027 13:10:19.327772  9023 net.cpp:205] fire2/concat needs backward computation.
I1027 13:10:19.327777  9023 net.cpp:205] fire2/relu_expand3x3 needs backward computation.
I1027 13:10:19.327782  9023 net.cpp:205] fire2/expand3x3 needs backward computation.
I1027 13:10:19.327786  9023 net.cpp:205] fire2/relu_expand1x1 needs backward computation.
I1027 13:10:19.327791  9023 net.cpp:205] fire2/expand1x1 needs backward computation.
I1027 13:10:19.327795  9023 net.cpp:205] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I1027 13:10:19.327800  9023 net.cpp:205] fire2/relu_squeeze1x1 needs backward computation.
I1027 13:10:19.327805  9023 net.cpp:205] fire2/squeeze1x1 needs backward computation.
I1027 13:10:19.327810  9023 net.cpp:205] pool1 needs backward computation.
I1027 13:10:19.327814  9023 net.cpp:205] relu_conv1 needs backward computation.
I1027 13:10:19.327818  9023 net.cpp:205] conv1 needs backward computation.
I1027 13:10:19.327824  9023 net.cpp:207] label_data_1_split does not need backward computation.
I1027 13:10:19.327832  9023 net.cpp:207] data does not need backward computation.
I1027 13:10:19.327836  9023 net.cpp:249] This network produces output accuracy_top1
I1027 13:10:19.327842  9023 net.cpp:249] This network produces output accuracy_top5
I1027 13:10:19.327847  9023 net.cpp:249] This network produces output loss
I1027 13:10:19.327906  9023 net.cpp:262] Network initialization done.
I1027 13:10:19.328193  9023 solver.cpp:56] Solver scaffolding done.
I1027 13:10:19.332715  9023 caffe.cpp:242] Resuming from SqueezeNet/SqueezeNet_v1.1/sqznet_inq_20_iter_64500.solverstate
I1027 13:10:19.454387  9023 sgd_solver.cpp:372] SGDSolver: restoring history
I1027 13:10:19.469236  9023 caffe.cpp:248] Starting Optimization
I1027 13:10:23.247344  9078 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_0.prototxt
I1027 13:10:23.249168  9076 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_0.prototxt
I1027 13:10:23.253871  9077 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_0.prototxt
I1027 13:10:23.807291  9076 sgd_solver.cpp:372] SGDSolver: restoring history
I1027 13:10:23.835861  9077 sgd_solver.cpp:372] SGDSolver: restoring history
I1027 13:10:23.835861  9078 sgd_solver.cpp:372] SGDSolver: restoring history
I1027 13:10:24.077674  9023 solver.cpp:276] Solving SqueezeNet
I1027 13:10:24.077729  9023 solver.cpp:277] Learning Rate Policy: poly
I1027 13:10:24.078249  9023 solver.cpp:334] Iteration 64500, Testing net (#0)
I1027 13:10:55.751788  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54216
I1027 13:10:55.751935  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77984
I1027 13:10:55.751950  9023 solver.cpp:401]     Test net output #2: loss = 2.05084 (* 1 = 2.05084 loss)
I1027 13:11:12.183110  9023 solver.cpp:222] Iteration 64520 (1341.3 iter/s, 48.1025s/40 iters), loss = 1.54545
I1027 13:11:12.183189  9023 solver.cpp:241]     Train net output #0: loss = 1.54545 (* 1 = 1.54545 loss)
I1027 13:11:12.183207  9023 sgd_solver.cpp:105] Iteration 64520, lr = 0.00563982
I1027 13:11:42.990409  9023 solver.cpp:222] Iteration 64560 (1.29845 iter/s, 30.8061s/40 iters), loss = 1.42419
I1027 13:11:42.990603  9023 solver.cpp:241]     Train net output #0: loss = 1.42419 (* 1 = 1.42419 loss)
I1027 13:11:42.990622  9023 sgd_solver.cpp:105] Iteration 64560, lr = 0.00563726
I1027 13:12:13.667577  9023 solver.cpp:222] Iteration 64600 (1.30396 iter/s, 30.6758s/40 iters), loss = 1.77421
I1027 13:12:13.667791  9023 solver.cpp:241]     Train net output #0: loss = 1.77421 (* 1 = 1.77421 loss)
I1027 13:12:13.667814  9023 sgd_solver.cpp:105] Iteration 64600, lr = 0.00563469
I1027 13:12:44.263059  9023 solver.cpp:222] Iteration 64640 (1.30744 iter/s, 30.5941s/40 iters), loss = 1.73137
I1027 13:12:44.263254  9023 solver.cpp:241]     Train net output #0: loss = 1.73137 (* 1 = 1.73137 loss)
I1027 13:12:44.263273  9023 sgd_solver.cpp:105] Iteration 64640, lr = 0.00563212
I1027 13:13:14.936944  9023 solver.cpp:222] Iteration 64680 (1.3041 iter/s, 30.6725s/40 iters), loss = 2.13066
I1027 13:13:14.937121  9023 solver.cpp:241]     Train net output #0: loss = 2.13066 (* 1 = 2.13066 loss)
I1027 13:13:14.937137  9023 sgd_solver.cpp:105] Iteration 64680, lr = 0.00562956
I1027 13:13:45.664746  9023 solver.cpp:222] Iteration 64720 (1.30181 iter/s, 30.7265s/40 iters), loss = 1.75645
I1027 13:13:45.664950  9023 solver.cpp:241]     Train net output #0: loss = 1.75645 (* 1 = 1.75645 loss)
I1027 13:13:45.664968  9023 sgd_solver.cpp:105] Iteration 64720, lr = 0.00562699
I1027 13:14:16.383008  9023 solver.cpp:222] Iteration 64760 (1.30222 iter/s, 30.7169s/40 iters), loss = 1.86828
I1027 13:14:16.383193  9023 solver.cpp:241]     Train net output #0: loss = 1.86828 (* 1 = 1.86828 loss)
I1027 13:14:16.383208  9023 sgd_solver.cpp:105] Iteration 64760, lr = 0.00562443
I1027 13:14:47.100878  9023 solver.cpp:222] Iteration 64800 (1.30223 iter/s, 30.7165s/40 iters), loss = 1.86407
I1027 13:14:47.101078  9023 solver.cpp:241]     Train net output #0: loss = 1.86407 (* 1 = 1.86407 loss)
I1027 13:14:47.101095  9023 sgd_solver.cpp:105] Iteration 64800, lr = 0.00562186
I1027 13:15:17.873337  9023 solver.cpp:222] Iteration 64840 (1.29992 iter/s, 30.7711s/40 iters), loss = 1.64247
I1027 13:15:17.873553  9023 solver.cpp:241]     Train net output #0: loss = 1.64247 (* 1 = 1.64247 loss)
I1027 13:15:17.873569  9023 sgd_solver.cpp:105] Iteration 64840, lr = 0.0056193
I1027 13:15:48.538239  9023 solver.cpp:222] Iteration 64880 (1.30448 iter/s, 30.6635s/40 iters), loss = 1.89891
I1027 13:15:48.538442  9023 solver.cpp:241]     Train net output #0: loss = 1.89891 (* 1 = 1.89891 loss)
I1027 13:15:48.538458  9023 sgd_solver.cpp:105] Iteration 64880, lr = 0.00561673
I1027 13:16:19.156699  9023 solver.cpp:222] Iteration 64920 (1.30646 iter/s, 30.6171s/40 iters), loss = 1.78836
I1027 13:16:19.156924  9023 solver.cpp:241]     Train net output #0: loss = 1.78836 (* 1 = 1.78836 loss)
I1027 13:16:19.156947  9023 sgd_solver.cpp:105] Iteration 64920, lr = 0.00561417
I1027 13:16:49.861172  9023 solver.cpp:222] Iteration 64960 (1.3028 iter/s, 30.7031s/40 iters), loss = 1.87411
I1027 13:16:49.861388  9023 solver.cpp:241]     Train net output #0: loss = 1.87411 (* 1 = 1.87411 loss)
I1027 13:16:49.861405  9023 sgd_solver.cpp:105] Iteration 64960, lr = 0.0056116
I1027 13:17:19.838860  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_65000.caffemodel
I1027 13:17:19.871716  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_65000.solverstate
I1027 13:17:19.889729  9023 solver.cpp:334] Iteration 65000, Testing net (#0)
I1027 13:17:50.993949  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 13:17:51.204563  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53568
I1027 13:17:51.204618  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77512
I1027 13:17:51.204632  9023 solver.cpp:401]     Test net output #2: loss = 2.05976 (* 1 = 2.05976 loss)
I1027 13:17:51.963268  9023 solver.cpp:222] Iteration 65000 (0.644127 iter/s, 62.0996s/40 iters), loss = 1.67862
I1027 13:17:51.963333  9023 solver.cpp:241]     Train net output #0: loss = 1.67862 (* 1 = 1.67862 loss)
I1027 13:17:51.963349  9023 sgd_solver.cpp:105] Iteration 65000, lr = 0.00560904
I1027 13:18:22.949715  9023 solver.cpp:222] Iteration 65040 (1.29094 iter/s, 30.9852s/40 iters), loss = 1.82008
I1027 13:18:22.949889  9023 solver.cpp:241]     Train net output #0: loss = 1.82008 (* 1 = 1.82008 loss)
I1027 13:18:22.949905  9023 sgd_solver.cpp:105] Iteration 65040, lr = 0.00560647
I1027 13:18:53.931743  9023 solver.cpp:222] Iteration 65080 (1.29113 iter/s, 30.9807s/40 iters), loss = 1.49541
I1027 13:18:53.931934  9023 solver.cpp:241]     Train net output #0: loss = 1.49541 (* 1 = 1.49541 loss)
I1027 13:18:53.931951  9023 sgd_solver.cpp:105] Iteration 65080, lr = 0.00560391
I1027 13:19:24.880867  9023 solver.cpp:222] Iteration 65120 (1.2925 iter/s, 30.9478s/40 iters), loss = 1.85589
I1027 13:19:24.881063  9023 solver.cpp:241]     Train net output #0: loss = 1.85589 (* 1 = 1.85589 loss)
I1027 13:19:24.881080  9023 sgd_solver.cpp:105] Iteration 65120, lr = 0.00560135
I1027 13:19:55.897791  9023 solver.cpp:222] Iteration 65160 (1.28968 iter/s, 31.0156s/40 iters), loss = 1.40905
I1027 13:19:55.897986  9023 solver.cpp:241]     Train net output #0: loss = 1.40905 (* 1 = 1.40905 loss)
I1027 13:19:55.898002  9023 sgd_solver.cpp:105] Iteration 65160, lr = 0.00559878
I1027 13:20:26.541321  9023 solver.cpp:222] Iteration 65200 (1.30539 iter/s, 30.6422s/40 iters), loss = 1.27842
I1027 13:20:26.541520  9023 solver.cpp:241]     Train net output #0: loss = 1.27842 (* 1 = 1.27842 loss)
I1027 13:20:26.541537  9023 sgd_solver.cpp:105] Iteration 65200, lr = 0.00559622
I1027 13:20:57.479215  9023 solver.cpp:222] Iteration 65240 (1.29297 iter/s, 30.9365s/40 iters), loss = 1.75184
I1027 13:20:57.479411  9023 solver.cpp:241]     Train net output #0: loss = 1.75184 (* 1 = 1.75184 loss)
I1027 13:20:57.479429  9023 sgd_solver.cpp:105] Iteration 65240, lr = 0.00559366
I1027 13:21:28.362515  9023 solver.cpp:222] Iteration 65280 (1.29526 iter/s, 30.8819s/40 iters), loss = 1.93079
I1027 13:21:28.362725  9023 solver.cpp:241]     Train net output #0: loss = 1.93079 (* 1 = 1.93079 loss)
I1027 13:21:28.362742  9023 sgd_solver.cpp:105] Iteration 65280, lr = 0.00559109
I1027 13:21:59.081770  9023 solver.cpp:222] Iteration 65320 (1.30217 iter/s, 30.7179s/40 iters), loss = 1.81678
I1027 13:21:59.081979  9023 solver.cpp:241]     Train net output #0: loss = 1.81678 (* 1 = 1.81678 loss)
I1027 13:21:59.082401  9023 sgd_solver.cpp:105] Iteration 65320, lr = 0.00558853
I1027 13:22:29.734042  9023 solver.cpp:222] Iteration 65360 (1.30502 iter/s, 30.6509s/40 iters), loss = 1.78842
I1027 13:22:29.734267  9023 solver.cpp:241]     Train net output #0: loss = 1.78842 (* 1 = 1.78842 loss)
I1027 13:22:29.734284  9023 sgd_solver.cpp:105] Iteration 65360, lr = 0.00558597
I1027 13:23:00.418325  9023 solver.cpp:222] Iteration 65400 (1.30366 iter/s, 30.6829s/40 iters), loss = 1.50882
I1027 13:23:00.418520  9023 solver.cpp:241]     Train net output #0: loss = 1.50882 (* 1 = 1.50882 loss)
I1027 13:23:00.418536  9023 sgd_solver.cpp:105] Iteration 65400, lr = 0.00558341
I1027 13:23:31.486963  9023 solver.cpp:222] Iteration 65440 (1.28753 iter/s, 31.0673s/40 iters), loss = 1.71955
I1027 13:23:31.487164  9023 solver.cpp:241]     Train net output #0: loss = 1.71955 (* 1 = 1.71955 loss)
I1027 13:23:31.487180  9023 sgd_solver.cpp:105] Iteration 65440, lr = 0.00558084
I1027 13:24:02.407250  9023 solver.cpp:222] Iteration 65480 (1.29371 iter/s, 30.9189s/40 iters), loss = 1.75258
I1027 13:24:02.407446  9023 solver.cpp:241]     Train net output #0: loss = 1.75258 (* 1 = 1.75258 loss)
I1027 13:24:02.407462  9023 sgd_solver.cpp:105] Iteration 65480, lr = 0.00557828
I1027 13:24:17.013465  9023 solver.cpp:334] Iteration 65500, Testing net (#0)
I1027 13:24:48.698540  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54264
I1027 13:24:48.698715  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78176
I1027 13:24:48.698730  9023 solver.cpp:401]     Test net output #2: loss = 2.02893 (* 1 = 2.02893 loss)
I1027 13:25:04.885671  9023 solver.cpp:222] Iteration 65520 (0.640247 iter/s, 62.4759s/40 iters), loss = 1.54661
I1027 13:25:04.885741  9023 solver.cpp:241]     Train net output #0: loss = 1.54661 (* 1 = 1.54661 loss)
I1027 13:25:04.885756  9023 sgd_solver.cpp:105] Iteration 65520, lr = 0.00557572
I1027 13:25:35.759729  9023 solver.cpp:222] Iteration 65560 (1.29564 iter/s, 30.8728s/40 iters), loss = 1.92782
I1027 13:25:35.759933  9023 solver.cpp:241]     Train net output #0: loss = 1.92782 (* 1 = 1.92782 loss)
I1027 13:25:35.759950  9023 sgd_solver.cpp:105] Iteration 65560, lr = 0.00557316
I1027 13:26:06.563851  9023 solver.cpp:222] Iteration 65600 (1.29859 iter/s, 30.8027s/40 iters), loss = 1.86379
I1027 13:26:06.564035  9023 solver.cpp:241]     Train net output #0: loss = 1.86379 (* 1 = 1.86379 loss)
I1027 13:26:06.564051  9023 sgd_solver.cpp:105] Iteration 65600, lr = 0.0055706
I1027 13:26:37.212406  9023 solver.cpp:222] Iteration 65640 (1.30518 iter/s, 30.6472s/40 iters), loss = 1.6985
I1027 13:26:37.212587  9023 solver.cpp:241]     Train net output #0: loss = 1.6985 (* 1 = 1.6985 loss)
I1027 13:26:37.212604  9023 sgd_solver.cpp:105] Iteration 65640, lr = 0.00556804
I1027 13:27:07.967756  9023 solver.cpp:222] Iteration 65680 (1.30064 iter/s, 30.754s/40 iters), loss = 1.91823
I1027 13:27:07.967937  9023 solver.cpp:241]     Train net output #0: loss = 1.91823 (* 1 = 1.91823 loss)
I1027 13:27:07.967952  9023 sgd_solver.cpp:105] Iteration 65680, lr = 0.00556548
I1027 13:27:38.727772  9023 solver.cpp:222] Iteration 65720 (1.30045 iter/s, 30.7587s/40 iters), loss = 1.82756
I1027 13:27:38.727963  9023 solver.cpp:241]     Train net output #0: loss = 1.82756 (* 1 = 1.82756 loss)
I1027 13:27:38.727979  9023 sgd_solver.cpp:105] Iteration 65720, lr = 0.00556292
I1027 13:28:09.408367  9023 solver.cpp:222] Iteration 65760 (1.30381 iter/s, 30.6792s/40 iters), loss = 1.33654
I1027 13:28:09.408571  9023 solver.cpp:241]     Train net output #0: loss = 1.33654 (* 1 = 1.33654 loss)
I1027 13:28:09.408586  9023 sgd_solver.cpp:105] Iteration 65760, lr = 0.00556036
I1027 13:28:40.306686  9023 solver.cpp:222] Iteration 65800 (1.29463 iter/s, 30.8969s/40 iters), loss = 1.73345
I1027 13:28:40.306896  9023 solver.cpp:241]     Train net output #0: loss = 1.73345 (* 1 = 1.73345 loss)
I1027 13:28:40.306912  9023 sgd_solver.cpp:105] Iteration 65800, lr = 0.0055578
I1027 13:29:11.405781  9023 solver.cpp:222] Iteration 65840 (1.28627 iter/s, 31.0977s/40 iters), loss = 1.55942
I1027 13:29:11.406016  9023 solver.cpp:241]     Train net output #0: loss = 1.55942 (* 1 = 1.55942 loss)
I1027 13:29:11.406066  9023 sgd_solver.cpp:105] Iteration 65840, lr = 0.00555524
I1027 13:29:42.293911  9023 solver.cpp:222] Iteration 65880 (1.29505 iter/s, 30.8867s/40 iters), loss = 1.8957
I1027 13:29:42.294183  9023 solver.cpp:241]     Train net output #0: loss = 1.8957 (* 1 = 1.8957 loss)
I1027 13:29:42.294222  9023 sgd_solver.cpp:105] Iteration 65880, lr = 0.00555268
I1027 13:30:13.259292  9023 solver.cpp:222] Iteration 65920 (1.29182 iter/s, 30.964s/40 iters), loss = 2.0033
I1027 13:30:13.259490  9023 solver.cpp:241]     Train net output #0: loss = 2.0033 (* 1 = 2.0033 loss)
I1027 13:30:13.259505  9023 sgd_solver.cpp:105] Iteration 65920, lr = 0.00555012
I1027 13:30:44.360414  9023 solver.cpp:222] Iteration 65960 (1.28618 iter/s, 31.0998s/40 iters), loss = 1.90742
I1027 13:30:44.360621  9023 solver.cpp:241]     Train net output #0: loss = 1.90742 (* 1 = 1.90742 loss)
I1027 13:30:44.360638  9023 sgd_solver.cpp:105] Iteration 65960, lr = 0.00554756
I1027 13:31:14.593757  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_66000.caffemodel
I1027 13:31:14.626647  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_66000.solverstate
I1027 13:31:14.644454  9023 solver.cpp:334] Iteration 66000, Testing net (#0)
I1027 13:31:45.980466  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 13:31:46.191498  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5418
I1027 13:31:46.191560  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78244
I1027 13:31:46.191572  9023 solver.cpp:401]     Test net output #2: loss = 2.09112 (* 1 = 2.09112 loss)
I1027 13:31:46.962939  9023 solver.cpp:222] Iteration 66000 (0.638978 iter/s, 62.6s/40 iters), loss = 1.64545
I1027 13:31:46.963003  9023 solver.cpp:241]     Train net output #0: loss = 1.64545 (* 1 = 1.64545 loss)
I1027 13:31:46.963017  9023 sgd_solver.cpp:105] Iteration 66000, lr = 0.005545
I1027 13:32:17.581696  9023 solver.cpp:222] Iteration 66040 (1.30644 iter/s, 30.6175s/40 iters), loss = 1.42096
I1027 13:32:17.581892  9023 solver.cpp:241]     Train net output #0: loss = 1.42096 (* 1 = 1.42096 loss)
I1027 13:32:17.583600  9023 sgd_solver.cpp:105] Iteration 66040, lr = 0.00554244
I1027 13:32:48.130803  9023 solver.cpp:222] Iteration 66080 (1.30943 iter/s, 30.5477s/40 iters), loss = 1.59947
I1027 13:32:48.131024  9023 solver.cpp:241]     Train net output #0: loss = 1.59947 (* 1 = 1.59947 loss)
I1027 13:32:48.131042  9023 sgd_solver.cpp:105] Iteration 66080, lr = 0.00553988
I1027 13:33:18.109493  9023 solver.cpp:222] Iteration 66120 (1.33434 iter/s, 29.9773s/40 iters), loss = 1.49746
I1027 13:33:18.109565  9023 solver.cpp:241]     Train net output #0: loss = 1.49746 (* 1 = 1.49746 loss)
I1027 13:33:18.109578  9023 sgd_solver.cpp:105] Iteration 66120, lr = 0.00553732
I1027 13:33:48.645303  9023 solver.cpp:222] Iteration 66160 (1.30999 iter/s, 30.5346s/40 iters), loss = 1.79547
I1027 13:33:48.645524  9023 solver.cpp:241]     Train net output #0: loss = 1.79547 (* 1 = 1.79547 loss)
I1027 13:33:48.645541  9023 sgd_solver.cpp:105] Iteration 66160, lr = 0.00553476
I1027 13:34:19.034668  9023 solver.cpp:222] Iteration 66200 (1.31631 iter/s, 30.388s/40 iters), loss = 1.74834
I1027 13:34:19.034868  9023 solver.cpp:241]     Train net output #0: loss = 1.74834 (* 1 = 1.74834 loss)
I1027 13:34:19.040726  9023 sgd_solver.cpp:105] Iteration 66200, lr = 0.0055322
I1027 13:34:49.168716  9023 solver.cpp:222] Iteration 66240 (1.32746 iter/s, 30.1327s/40 iters), loss = 1.77715
I1027 13:34:49.168906  9023 solver.cpp:241]     Train net output #0: loss = 1.77715 (* 1 = 1.77715 loss)
I1027 13:34:49.168925  9023 sgd_solver.cpp:105] Iteration 66240, lr = 0.00552964
I1027 13:35:19.275547  9023 solver.cpp:222] Iteration 66280 (1.32866 iter/s, 30.1055s/40 iters), loss = 1.92243
I1027 13:35:19.275768  9023 solver.cpp:241]     Train net output #0: loss = 1.92243 (* 1 = 1.92243 loss)
I1027 13:35:19.275784  9023 sgd_solver.cpp:105] Iteration 66280, lr = 0.00552709
I1027 13:35:49.609043  9023 solver.cpp:222] Iteration 66320 (1.31873 iter/s, 30.3321s/40 iters), loss = 1.84273
I1027 13:35:49.609316  9023 solver.cpp:241]     Train net output #0: loss = 1.84273 (* 1 = 1.84273 loss)
I1027 13:35:49.609335  9023 sgd_solver.cpp:105] Iteration 66320, lr = 0.00552453
I1027 13:36:19.970562  9023 solver.cpp:222] Iteration 66360 (1.31752 iter/s, 30.3601s/40 iters), loss = 1.72023
I1027 13:36:19.970736  9023 solver.cpp:241]     Train net output #0: loss = 1.72023 (* 1 = 1.72023 loss)
I1027 13:36:19.970754  9023 sgd_solver.cpp:105] Iteration 66360, lr = 0.00552197
I1027 13:36:50.541829  9023 solver.cpp:222] Iteration 66400 (1.30848 iter/s, 30.5699s/40 iters), loss = 1.6347
I1027 13:36:50.542068  9023 solver.cpp:241]     Train net output #0: loss = 1.6347 (* 1 = 1.6347 loss)
I1027 13:36:50.542083  9023 sgd_solver.cpp:105] Iteration 66400, lr = 0.00551941
I1027 13:37:20.771164  9023 solver.cpp:222] Iteration 66440 (1.32328 iter/s, 30.228s/40 iters), loss = 1.43726
I1027 13:37:20.771381  9023 solver.cpp:241]     Train net output #0: loss = 1.43726 (* 1 = 1.43726 loss)
I1027 13:37:20.771397  9023 sgd_solver.cpp:105] Iteration 66440, lr = 0.00551686
I1027 13:37:51.258045  9023 solver.cpp:222] Iteration 66480 (1.3121 iter/s, 30.4855s/40 iters), loss = 2.09338
I1027 13:37:51.258244  9023 solver.cpp:241]     Train net output #0: loss = 2.09338 (* 1 = 2.09338 loss)
I1027 13:37:51.258260  9023 sgd_solver.cpp:105] Iteration 66480, lr = 0.0055143
I1027 13:38:05.736672  9023 solver.cpp:334] Iteration 66500, Testing net (#0)
I1027 13:38:37.461696  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54656
I1027 13:38:37.461920  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.77792
I1027 13:38:37.461936  9023 solver.cpp:401]     Test net output #2: loss = 2.02788 (* 1 = 2.02788 loss)
I1027 13:38:53.568951  9023 solver.cpp:222] Iteration 66520 (0.641968 iter/s, 62.3084s/40 iters), loss = 1.95553
I1027 13:38:53.569025  9023 solver.cpp:241]     Train net output #0: loss = 1.95553 (* 1 = 1.95553 loss)
I1027 13:38:53.569039  9023 sgd_solver.cpp:105] Iteration 66520, lr = 0.00551174
I1027 13:39:23.654459  9023 solver.cpp:222] Iteration 66560 (1.3296 iter/s, 30.0843s/40 iters), loss = 1.99563
I1027 13:39:23.654696  9023 solver.cpp:241]     Train net output #0: loss = 1.99563 (* 1 = 1.99563 loss)
I1027 13:39:23.654716  9023 sgd_solver.cpp:105] Iteration 66560, lr = 0.00550919
I1027 13:39:53.436750  9023 solver.cpp:222] Iteration 66600 (1.34314 iter/s, 29.7809s/40 iters), loss = 1.76343
I1027 13:39:53.436825  9023 solver.cpp:241]     Train net output #0: loss = 1.76343 (* 1 = 1.76343 loss)
I1027 13:39:53.436841  9023 sgd_solver.cpp:105] Iteration 66600, lr = 0.00550663
I1027 13:40:23.744637  9023 solver.cpp:222] Iteration 66640 (1.31984 iter/s, 30.3067s/40 iters), loss = 1.36973
I1027 13:40:23.744853  9023 solver.cpp:241]     Train net output #0: loss = 1.36973 (* 1 = 1.36973 loss)
I1027 13:40:23.744870  9023 sgd_solver.cpp:105] Iteration 66640, lr = 0.00550407
I1027 13:40:54.187049  9023 solver.cpp:222] Iteration 66680 (1.31402 iter/s, 30.441s/40 iters), loss = 1.75071
I1027 13:40:54.187239  9023 solver.cpp:241]     Train net output #0: loss = 1.75071 (* 1 = 1.75071 loss)
I1027 13:40:54.187256  9023 sgd_solver.cpp:105] Iteration 66680, lr = 0.00550152
I1027 13:41:24.715350  9023 solver.cpp:222] Iteration 66720 (1.31032 iter/s, 30.527s/40 iters), loss = 1.72443
I1027 13:41:24.715561  9023 solver.cpp:241]     Train net output #0: loss = 1.72443 (* 1 = 1.72443 loss)
I1027 13:41:24.715579  9023 sgd_solver.cpp:105] Iteration 66720, lr = 0.00549896
I1027 13:41:55.206356  9023 solver.cpp:222] Iteration 66760 (1.31192 iter/s, 30.4896s/40 iters), loss = 1.72337
I1027 13:41:55.206562  9023 solver.cpp:241]     Train net output #0: loss = 1.72337 (* 1 = 1.72337 loss)
I1027 13:41:55.206578  9023 sgd_solver.cpp:105] Iteration 66760, lr = 0.00549641
I1027 13:42:25.283521  9023 solver.cpp:222] Iteration 66800 (1.32997 iter/s, 30.0758s/40 iters), loss = 1.84793
I1027 13:42:25.283745  9023 solver.cpp:241]     Train net output #0: loss = 1.84793 (* 1 = 1.84793 loss)
I1027 13:42:25.283776  9023 sgd_solver.cpp:105] Iteration 66800, lr = 0.00549385
I1027 13:42:54.948071  9023 solver.cpp:222] Iteration 66840 (1.34847 iter/s, 29.6632s/40 iters), loss = 1.69033
I1027 13:42:54.948144  9023 solver.cpp:241]     Train net output #0: loss = 1.69033 (* 1 = 1.69033 loss)
I1027 13:42:54.948158  9023 sgd_solver.cpp:105] Iteration 66840, lr = 0.0054913
I1027 13:43:20.178941  9077 blocking_queue.cpp:49] Waiting for data
I1027 13:43:38.385177  9023 solver.cpp:222] Iteration 66880 (0.920908 iter/s, 43.4354s/40 iters), loss = 2.19787
I1027 13:43:38.385274  9023 solver.cpp:241]     Train net output #0: loss = 2.19787 (* 1 = 2.19787 loss)
I1027 13:43:38.385295  9023 sgd_solver.cpp:105] Iteration 66880, lr = 0.00548874
I1027 13:46:06.767320  9023 solver.cpp:222] Iteration 66920 (0.269584 iter/s, 148.377s/40 iters), loss = 1.67537
I1027 13:46:06.767547  9023 solver.cpp:241]     Train net output #0: loss = 1.67537 (* 1 = 1.67537 loss)
I1027 13:46:06.767575  9023 sgd_solver.cpp:105] Iteration 66920, lr = 0.00548619
I1027 13:46:40.537499  9023 solver.cpp:222] Iteration 66960 (1.18453 iter/s, 33.7687s/40 iters), loss = 1.81598
I1027 13:46:40.537722  9023 solver.cpp:241]     Train net output #0: loss = 1.81598 (* 1 = 1.81598 loss)
I1027 13:46:40.537757  9023 sgd_solver.cpp:105] Iteration 66960, lr = 0.00548363
I1027 13:47:12.871485  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1027 13:47:13.521600  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_67000.caffemodel
I1027 13:47:13.564365  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_67000.solverstate
I1027 13:47:13.587543  9023 solver.cpp:334] Iteration 67000, Testing net (#0)
I1027 13:47:44.659318  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 13:47:44.871445  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.543239
I1027 13:47:44.871510  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7818
I1027 13:47:44.871523  9023 solver.cpp:401]     Test net output #2: loss = 2.01773 (* 1 = 2.01773 loss)
I1027 13:47:45.643996  9023 solver.cpp:222] Iteration 67000 (0.614403 iter/s, 65.1039s/40 iters), loss = 1.54722
I1027 13:47:45.644063  9023 solver.cpp:241]     Train net output #0: loss = 1.54722 (* 1 = 1.54722 loss)
I1027 13:47:45.644078  9023 sgd_solver.cpp:105] Iteration 67000, lr = 0.00548108
I1027 13:48:16.314067  9023 solver.cpp:222] Iteration 67040 (1.30426 iter/s, 30.6688s/40 iters), loss = 1.65772
I1027 13:48:16.314252  9023 solver.cpp:241]     Train net output #0: loss = 1.65772 (* 1 = 1.65772 loss)
I1027 13:48:16.314270  9023 sgd_solver.cpp:105] Iteration 67040, lr = 0.00547852
I1027 13:48:46.583508  9023 solver.cpp:222] Iteration 67080 (1.32152 iter/s, 30.2681s/40 iters), loss = 1.93011
I1027 13:48:46.583737  9023 solver.cpp:241]     Train net output #0: loss = 1.93011 (* 1 = 1.93011 loss)
I1027 13:48:46.583753  9023 sgd_solver.cpp:105] Iteration 67080, lr = 0.00547597
I1027 13:49:17.646735  9023 solver.cpp:222] Iteration 67120 (1.28775 iter/s, 31.0618s/40 iters), loss = 1.57521
I1027 13:49:17.646916  9023 solver.cpp:241]     Train net output #0: loss = 1.57521 (* 1 = 1.57521 loss)
I1027 13:49:17.646932  9023 sgd_solver.cpp:105] Iteration 67120, lr = 0.00547342
I1027 13:49:48.745050  9023 solver.cpp:222] Iteration 67160 (1.2863 iter/s, 31.097s/40 iters), loss = 1.9226
I1027 13:49:48.745215  9023 solver.cpp:241]     Train net output #0: loss = 1.9226 (* 1 = 1.9226 loss)
I1027 13:49:48.745232  9023 sgd_solver.cpp:105] Iteration 67160, lr = 0.00547086
I1027 13:50:19.889976  9023 solver.cpp:222] Iteration 67200 (1.28437 iter/s, 31.1436s/40 iters), loss = 1.77189
I1027 13:50:19.890190  9023 solver.cpp:241]     Train net output #0: loss = 1.77189 (* 1 = 1.77189 loss)
I1027 13:50:19.890214  9023 sgd_solver.cpp:105] Iteration 67200, lr = 0.00546831
I1027 13:50:50.878873  9023 solver.cpp:222] Iteration 67240 (1.29084 iter/s, 30.9875s/40 iters), loss = 1.65216
I1027 13:50:50.879127  9023 solver.cpp:241]     Train net output #0: loss = 1.65216 (* 1 = 1.65216 loss)
I1027 13:50:50.879148  9023 sgd_solver.cpp:105] Iteration 67240, lr = 0.00546576
I1027 13:51:21.624810  9023 solver.cpp:222] Iteration 67280 (1.30104 iter/s, 30.7445s/40 iters), loss = 1.81051
I1027 13:51:21.625021  9023 solver.cpp:241]     Train net output #0: loss = 1.81051 (* 1 = 1.81051 loss)
I1027 13:51:21.625039  9023 sgd_solver.cpp:105] Iteration 67280, lr = 0.0054632
I1027 13:51:52.305104  9023 solver.cpp:222] Iteration 67320 (1.30383 iter/s, 30.6789s/40 iters), loss = 1.67824
I1027 13:51:52.305311  9023 solver.cpp:241]     Train net output #0: loss = 1.67824 (* 1 = 1.67824 loss)
I1027 13:51:52.305330  9023 sgd_solver.cpp:105] Iteration 67320, lr = 0.00546065
I1027 13:52:23.235957  9023 solver.cpp:222] Iteration 67360 (1.29327 iter/s, 30.9295s/40 iters), loss = 1.79762
I1027 13:52:23.236186  9023 solver.cpp:241]     Train net output #0: loss = 1.79762 (* 1 = 1.79762 loss)
I1027 13:52:23.236228  9023 sgd_solver.cpp:105] Iteration 67360, lr = 0.0054581
I1027 13:52:54.523490  9023 solver.cpp:222] Iteration 67400 (1.27852 iter/s, 31.2861s/40 iters), loss = 2.08881
I1027 13:52:54.523725  9023 solver.cpp:241]     Train net output #0: loss = 2.08881 (* 1 = 2.08881 loss)
I1027 13:52:54.523749  9023 sgd_solver.cpp:105] Iteration 67400, lr = 0.00545555
I1027 13:53:25.096918  9023 solver.cpp:222] Iteration 67440 (1.30839 iter/s, 30.572s/40 iters), loss = 1.40468
I1027 13:53:25.097103  9023 solver.cpp:241]     Train net output #0: loss = 1.40468 (* 1 = 1.40468 loss)
I1027 13:53:25.097127  9023 sgd_solver.cpp:105] Iteration 67440, lr = 0.00545299
I1027 13:53:55.603659  9023 solver.cpp:222] Iteration 67480 (1.31124 iter/s, 30.5054s/40 iters), loss = 1.93913
I1027 13:53:55.603830  9023 solver.cpp:241]     Train net output #0: loss = 1.93913 (* 1 = 1.93913 loss)
I1027 13:53:55.603849  9023 sgd_solver.cpp:105] Iteration 67480, lr = 0.00545044
I1027 13:54:10.104732  9023 solver.cpp:334] Iteration 67500, Testing net (#0)
I1027 13:54:41.332381  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54584
I1027 13:54:41.332548  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78524
I1027 13:54:41.332563  9023 solver.cpp:401]     Test net output #2: loss = 2.0244 (* 1 = 2.0244 loss)
I1027 13:54:57.385635  9023 solver.cpp:222] Iteration 67520 (0.647464 iter/s, 61.7795s/40 iters), loss = 1.6063
I1027 13:54:57.385710  9023 solver.cpp:241]     Train net output #0: loss = 1.6063 (* 1 = 1.6063 loss)
I1027 13:54:57.385726  9023 sgd_solver.cpp:105] Iteration 67520, lr = 0.00544789
I1027 13:55:27.937677  9023 solver.cpp:222] Iteration 67560 (1.30929 iter/s, 30.5508s/40 iters), loss = 1.46598
I1027 13:55:27.937835  9023 solver.cpp:241]     Train net output #0: loss = 1.46598 (* 1 = 1.46598 loss)
I1027 13:55:27.937852  9023 sgd_solver.cpp:105] Iteration 67560, lr = 0.00544534
I1027 13:55:58.490869  9023 solver.cpp:222] Iteration 67600 (1.30925 iter/s, 30.5519s/40 iters), loss = 1.75744
I1027 13:55:58.491027  9023 solver.cpp:241]     Train net output #0: loss = 1.75744 (* 1 = 1.75744 loss)
I1027 13:55:58.491046  9023 sgd_solver.cpp:105] Iteration 67600, lr = 0.00544279
I1027 13:56:28.986656  9023 solver.cpp:222] Iteration 67640 (1.31171 iter/s, 30.4945s/40 iters), loss = 1.30493
I1027 13:56:28.986822  9023 solver.cpp:241]     Train net output #0: loss = 1.30493 (* 1 = 1.30493 loss)
I1027 13:56:28.986841  9023 sgd_solver.cpp:105] Iteration 67640, lr = 0.00544023
I1027 13:56:59.978193  9023 solver.cpp:222] Iteration 67680 (1.29073 iter/s, 30.9902s/40 iters), loss = 1.69688
I1027 13:56:59.978466  9023 solver.cpp:241]     Train net output #0: loss = 1.69688 (* 1 = 1.69688 loss)
I1027 13:56:59.978492  9023 sgd_solver.cpp:105] Iteration 67680, lr = 0.00543768
I1027 13:57:33.639396  9023 solver.cpp:222] Iteration 67720 (1.18837 iter/s, 33.6597s/40 iters), loss = 2.22806
I1027 13:57:33.639616  9023 solver.cpp:241]     Train net output #0: loss = 2.22806 (* 1 = 2.22806 loss)
I1027 13:57:33.639652  9023 sgd_solver.cpp:105] Iteration 67720, lr = 0.00543513
I1027 13:58:04.275790  9023 solver.cpp:222] Iteration 67760 (1.3057 iter/s, 30.635s/40 iters), loss = 1.78212
I1027 13:58:04.276043  9023 solver.cpp:241]     Train net output #0: loss = 1.78212 (* 1 = 1.78212 loss)
I1027 13:58:04.276064  9023 sgd_solver.cpp:105] Iteration 67760, lr = 0.00543258
I1027 13:58:34.985349  9023 solver.cpp:222] Iteration 67800 (1.30259 iter/s, 30.7082s/40 iters), loss = 1.76565
I1027 13:58:34.985580  9023 solver.cpp:241]     Train net output #0: loss = 1.76565 (* 1 = 1.76565 loss)
I1027 13:58:34.985604  9023 sgd_solver.cpp:105] Iteration 67800, lr = 0.00543003
I1027 13:59:05.668473  9023 solver.cpp:222] Iteration 67840 (1.30371 iter/s, 30.6817s/40 iters), loss = 1.97922
I1027 13:59:05.668663  9023 solver.cpp:241]     Train net output #0: loss = 1.97922 (* 1 = 1.97922 loss)
I1027 13:59:05.668680  9023 sgd_solver.cpp:105] Iteration 67840, lr = 0.00542748
I1027 13:59:36.699962  9023 solver.cpp:222] Iteration 67880 (1.28907 iter/s, 31.0301s/40 iters), loss = 1.40409
I1027 13:59:36.700223  9023 solver.cpp:241]     Train net output #0: loss = 1.40409 (* 1 = 1.40409 loss)
I1027 13:59:36.700251  9023 sgd_solver.cpp:105] Iteration 67880, lr = 0.00542493
I1027 14:00:07.655640  9023 solver.cpp:222] Iteration 67920 (1.29223 iter/s, 30.9543s/40 iters), loss = 1.8955
I1027 14:00:07.655841  9023 solver.cpp:241]     Train net output #0: loss = 1.8955 (* 1 = 1.8955 loss)
I1027 14:00:07.655860  9023 sgd_solver.cpp:105] Iteration 67920, lr = 0.00542238
I1027 14:00:38.432312  9023 solver.cpp:222] Iteration 67960 (1.29974 iter/s, 30.7753s/40 iters), loss = 1.663
I1027 14:00:38.432513  9023 solver.cpp:241]     Train net output #0: loss = 1.663 (* 1 = 1.663 loss)
I1027 14:00:38.432531  9023 sgd_solver.cpp:105] Iteration 67960, lr = 0.00541983
I1027 14:01:08.180836  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_68000.caffemodel
I1027 14:01:08.213758  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_68000.solverstate
I1027 14:01:08.234683  9023 solver.cpp:334] Iteration 68000, Testing net (#0)
I1027 14:01:39.855094  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 14:01:40.063931  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54564
I1027 14:01:40.063994  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78608
I1027 14:01:40.064007  9023 solver.cpp:401]     Test net output #2: loss = 2.01884 (* 1 = 2.01884 loss)
I1027 14:01:40.827783  9023 solver.cpp:222] Iteration 68000 (0.641098 iter/s, 62.3929s/40 iters), loss = 1.41252
I1027 14:01:40.827859  9023 solver.cpp:241]     Train net output #0: loss = 1.41252 (* 1 = 1.41252 loss)
I1027 14:01:40.827877  9023 sgd_solver.cpp:105] Iteration 68000, lr = 0.00541728
I1027 14:02:11.539249  9023 solver.cpp:222] Iteration 68040 (1.3025 iter/s, 30.7102s/40 iters), loss = 1.72378
I1027 14:02:11.539441  9023 solver.cpp:241]     Train net output #0: loss = 1.72378 (* 1 = 1.72378 loss)
I1027 14:02:11.539458  9023 sgd_solver.cpp:105] Iteration 68040, lr = 0.00541473
I1027 14:02:42.162009  9023 solver.cpp:222] Iteration 68080 (1.30628 iter/s, 30.6214s/40 iters), loss = 1.86758
I1027 14:02:42.162168  9023 solver.cpp:241]     Train net output #0: loss = 1.86758 (* 1 = 1.86758 loss)
I1027 14:02:42.162190  9023 sgd_solver.cpp:105] Iteration 68080, lr = 0.00541218
I1027 14:03:12.752250  9023 solver.cpp:222] Iteration 68120 (1.30766 iter/s, 30.5889s/40 iters), loss = 1.65657
I1027 14:03:12.752403  9023 solver.cpp:241]     Train net output #0: loss = 1.65657 (* 1 = 1.65657 loss)
I1027 14:03:12.752419  9023 sgd_solver.cpp:105] Iteration 68120, lr = 0.00540964
I1027 14:03:44.820489  9023 solver.cpp:222] Iteration 68160 (1.24739 iter/s, 32.0669s/40 iters), loss = 1.86816
I1027 14:03:44.820724  9023 solver.cpp:241]     Train net output #0: loss = 1.86816 (* 1 = 1.86816 loss)
I1027 14:03:44.820744  9023 sgd_solver.cpp:105] Iteration 68160, lr = 0.00540709
I1027 14:04:15.317726  9023 solver.cpp:222] Iteration 68200 (1.31165 iter/s, 30.4959s/40 iters), loss = 2.04965
I1027 14:04:15.318025  9023 solver.cpp:241]     Train net output #0: loss = 2.04965 (* 1 = 2.04965 loss)
I1027 14:04:15.318045  9023 sgd_solver.cpp:105] Iteration 68200, lr = 0.00540454
I1027 14:04:45.743142  9023 solver.cpp:222] Iteration 68240 (1.31475 iter/s, 30.424s/40 iters), loss = 1.63804
I1027 14:04:45.743332  9023 solver.cpp:241]     Train net output #0: loss = 1.63804 (* 1 = 1.63804 loss)
I1027 14:04:45.743357  9023 sgd_solver.cpp:105] Iteration 68240, lr = 0.00540199
I1027 14:05:16.335587  9023 solver.cpp:222] Iteration 68280 (1.30757 iter/s, 30.5911s/40 iters), loss = 1.61351
I1027 14:05:16.335764  9023 solver.cpp:241]     Train net output #0: loss = 1.61351 (* 1 = 1.61351 loss)
I1027 14:05:16.335785  9023 sgd_solver.cpp:105] Iteration 68280, lr = 0.00539944
I1027 14:05:48.109799  9023 solver.cpp:222] Iteration 68320 (1.25894 iter/s, 31.7728s/40 iters), loss = 1.50626
I1027 14:05:48.110029  9023 solver.cpp:241]     Train net output #0: loss = 1.50626 (* 1 = 1.50626 loss)
I1027 14:05:48.110056  9023 sgd_solver.cpp:105] Iteration 68320, lr = 0.00539689
I1027 14:06:19.220760  9023 solver.cpp:222] Iteration 68360 (1.28578 iter/s, 31.1096s/40 iters), loss = 1.98396
I1027 14:06:19.220964  9023 solver.cpp:241]     Train net output #0: loss = 1.98396 (* 1 = 1.98396 loss)
I1027 14:06:19.220983  9023 sgd_solver.cpp:105] Iteration 68360, lr = 0.00539435
I1027 14:06:50.151513  9023 solver.cpp:222] Iteration 68400 (1.29327 iter/s, 30.9294s/40 iters), loss = 1.30561
I1027 14:06:50.151718  9023 solver.cpp:241]     Train net output #0: loss = 1.30561 (* 1 = 1.30561 loss)
I1027 14:06:50.151741  9023 sgd_solver.cpp:105] Iteration 68400, lr = 0.0053918
I1027 14:07:21.146577  9023 solver.cpp:222] Iteration 68440 (1.29059 iter/s, 30.9937s/40 iters), loss = 1.59543
I1027 14:07:21.146791  9023 solver.cpp:241]     Train net output #0: loss = 1.59543 (* 1 = 1.59543 loss)
I1027 14:07:21.146814  9023 sgd_solver.cpp:105] Iteration 68440, lr = 0.00538925
I1027 14:07:52.077106  9023 solver.cpp:222] Iteration 68480 (1.29328 iter/s, 30.9291s/40 iters), loss = 1.2528
I1027 14:07:52.077306  9023 solver.cpp:241]     Train net output #0: loss = 1.2528 (* 1 = 1.2528 loss)
I1027 14:07:52.077325  9023 sgd_solver.cpp:105] Iteration 68480, lr = 0.0053867
I1027 14:08:06.607753  9023 solver.cpp:334] Iteration 68500, Testing net (#0)
I1027 14:08:38.431696  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.541
I1027 14:08:38.431885  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.781
I1027 14:08:38.431900  9023 solver.cpp:401]     Test net output #2: loss = 2.03199 (* 1 = 2.03199 loss)
I1027 14:08:54.466895  9023 solver.cpp:222] Iteration 68520 (0.641157 iter/s, 62.3873s/40 iters), loss = 1.53276
I1027 14:08:54.466975  9023 solver.cpp:241]     Train net output #0: loss = 1.53276 (* 1 = 1.53276 loss)
I1027 14:08:54.466994  9023 sgd_solver.cpp:105] Iteration 68520, lr = 0.00538416
I1027 14:09:25.018875  9023 solver.cpp:222] Iteration 68560 (1.3093 iter/s, 30.5507s/40 iters), loss = 1.65088
I1027 14:09:25.019058  9023 solver.cpp:241]     Train net output #0: loss = 1.65088 (* 1 = 1.65088 loss)
I1027 14:09:25.019078  9023 sgd_solver.cpp:105] Iteration 68560, lr = 0.00538161
I1027 14:09:55.555188  9023 solver.cpp:222] Iteration 68600 (1.30997 iter/s, 30.535s/40 iters), loss = 1.72253
I1027 14:09:55.555384  9023 solver.cpp:241]     Train net output #0: loss = 1.72253 (* 1 = 1.72253 loss)
I1027 14:09:55.555405  9023 sgd_solver.cpp:105] Iteration 68600, lr = 0.00537907
I1027 14:10:26.113833  9023 solver.cpp:222] Iteration 68640 (1.30902 iter/s, 30.5573s/40 iters), loss = 1.55521
I1027 14:10:26.114008  9023 solver.cpp:241]     Train net output #0: loss = 1.55521 (* 1 = 1.55521 loss)
I1027 14:10:26.114027  9023 sgd_solver.cpp:105] Iteration 68640, lr = 0.00537652
I1027 14:10:56.679216  9023 solver.cpp:222] Iteration 68680 (1.30873 iter/s, 30.564s/40 iters), loss = 1.77036
I1027 14:10:56.679385  9023 solver.cpp:241]     Train net output #0: loss = 1.77036 (* 1 = 1.77036 loss)
I1027 14:10:56.679417  9023 sgd_solver.cpp:105] Iteration 68680, lr = 0.00537397
I1027 14:11:28.511220  9023 solver.cpp:222] Iteration 68720 (1.25665 iter/s, 31.8306s/40 iters), loss = 1.65204
I1027 14:11:28.511503  9023 solver.cpp:241]     Train net output #0: loss = 1.65204 (* 1 = 1.65204 loss)
I1027 14:11:28.511540  9023 sgd_solver.cpp:105] Iteration 68720, lr = 0.00537143
I1027 14:11:58.700996  9023 solver.cpp:222] Iteration 68760 (1.32501 iter/s, 30.1884s/40 iters), loss = 1.99659
I1027 14:11:58.701195  9023 solver.cpp:241]     Train net output #0: loss = 1.99659 (* 1 = 1.99659 loss)
I1027 14:11:58.701212  9023 sgd_solver.cpp:105] Iteration 68760, lr = 0.00536888
I1027 14:12:29.330931  9023 solver.cpp:222] Iteration 68800 (1.30597 iter/s, 30.6286s/40 iters), loss = 1.71983
I1027 14:12:29.331116  9023 solver.cpp:241]     Train net output #0: loss = 1.71983 (* 1 = 1.71983 loss)
I1027 14:12:29.331135  9023 sgd_solver.cpp:105] Iteration 68800, lr = 0.00536634
I1027 14:12:59.865409  9023 solver.cpp:222] Iteration 68840 (1.31005 iter/s, 30.5331s/40 iters), loss = 1.40729
I1027 14:12:59.865576  9023 solver.cpp:241]     Train net output #0: loss = 1.40729 (* 1 = 1.40729 loss)
I1027 14:12:59.865593  9023 sgd_solver.cpp:105] Iteration 68840, lr = 0.00536379
I1027 14:13:30.548638  9023 solver.cpp:222] Iteration 68880 (1.3037 iter/s, 30.6819s/40 iters), loss = 1.5615
I1027 14:13:30.548815  9023 solver.cpp:241]     Train net output #0: loss = 1.5615 (* 1 = 1.5615 loss)
I1027 14:13:30.548833  9023 sgd_solver.cpp:105] Iteration 68880, lr = 0.00536125
I1027 14:14:01.289991  9023 solver.cpp:222] Iteration 68920 (1.30124 iter/s, 30.74s/40 iters), loss = 1.28724
I1027 14:14:01.290169  9023 solver.cpp:241]     Train net output #0: loss = 1.28724 (* 1 = 1.28724 loss)
I1027 14:14:01.290189  9023 sgd_solver.cpp:105] Iteration 68920, lr = 0.0053587
I1027 14:14:32.052897  9023 solver.cpp:222] Iteration 68960 (1.30032 iter/s, 30.7616s/40 iters), loss = 1.94742
I1027 14:14:32.053084  9023 solver.cpp:241]     Train net output #0: loss = 1.94742 (* 1 = 1.94742 loss)
I1027 14:14:32.053103  9023 sgd_solver.cpp:105] Iteration 68960, lr = 0.00535616
I1027 14:15:02.040668  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_69000.caffemodel
I1027 14:15:02.077606  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_69000.solverstate
I1027 14:15:02.110009  9023 solver.cpp:334] Iteration 69000, Testing net (#0)
I1027 14:15:33.634646  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 14:15:33.843672  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54736
I1027 14:15:33.843730  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78576
I1027 14:15:33.843744  9023 solver.cpp:401]     Test net output #2: loss = 2.03289 (* 1 = 2.03289 loss)
I1027 14:15:34.656780  9023 solver.cpp:222] Iteration 69000 (0.638964 iter/s, 62.6013s/40 iters), loss = 1.54402
I1027 14:15:34.656885  9023 solver.cpp:241]     Train net output #0: loss = 1.54402 (* 1 = 1.54402 loss)
I1027 14:15:34.656914  9023 sgd_solver.cpp:105] Iteration 69000, lr = 0.00535361
I1027 14:16:07.967209  9023 solver.cpp:222] Iteration 69040 (1.20087 iter/s, 33.3091s/40 iters), loss = 1.72623
I1027 14:16:07.967473  9023 solver.cpp:241]     Train net output #0: loss = 1.72623 (* 1 = 1.72623 loss)
I1027 14:16:07.967501  9023 sgd_solver.cpp:105] Iteration 69040, lr = 0.00535107
I1027 14:16:39.319304  9023 solver.cpp:222] Iteration 69080 (1.27589 iter/s, 31.3506s/40 iters), loss = 1.902
I1027 14:16:39.319536  9023 solver.cpp:241]     Train net output #0: loss = 1.902 (* 1 = 1.902 loss)
I1027 14:16:39.319553  9023 sgd_solver.cpp:105] Iteration 69080, lr = 0.00534852
I1027 14:17:09.662045  9023 solver.cpp:222] Iteration 69120 (1.31833 iter/s, 30.3413s/40 iters), loss = 1.90665
I1027 14:17:09.662250  9023 solver.cpp:241]     Train net output #0: loss = 1.90665 (* 1 = 1.90665 loss)
I1027 14:17:09.662288  9023 sgd_solver.cpp:105] Iteration 69120, lr = 0.00534598
I1027 14:17:40.230628  9023 solver.cpp:222] Iteration 69160 (1.30859 iter/s, 30.5672s/40 iters), loss = 1.75415
I1027 14:17:40.230919  9023 solver.cpp:241]     Train net output #0: loss = 1.75415 (* 1 = 1.75415 loss)
I1027 14:17:40.230958  9023 sgd_solver.cpp:105] Iteration 69160, lr = 0.00534344
I1027 14:18:10.633232  9023 solver.cpp:222] Iteration 69200 (1.31574 iter/s, 30.4012s/40 iters), loss = 2.11011
I1027 14:18:10.633415  9023 solver.cpp:241]     Train net output #0: loss = 2.11011 (* 1 = 2.11011 loss)
I1027 14:18:10.633435  9023 sgd_solver.cpp:105] Iteration 69200, lr = 0.00534089
I1027 14:18:41.037874  9023 solver.cpp:222] Iteration 69240 (1.31565 iter/s, 30.4033s/40 iters), loss = 1.58354
I1027 14:18:41.038043  9023 solver.cpp:241]     Train net output #0: loss = 1.58354 (* 1 = 1.58354 loss)
I1027 14:18:41.038063  9023 sgd_solver.cpp:105] Iteration 69240, lr = 0.00533835
I1027 14:19:11.085377  9023 solver.cpp:222] Iteration 69280 (1.33128 iter/s, 30.0462s/40 iters), loss = 1.43116
I1027 14:19:11.085541  9023 solver.cpp:241]     Train net output #0: loss = 1.43116 (* 1 = 1.43116 loss)
I1027 14:19:11.085561  9023 sgd_solver.cpp:105] Iteration 69280, lr = 0.00533581
I1027 14:19:41.007725  9023 solver.cpp:222] Iteration 69320 (1.33685 iter/s, 29.9211s/40 iters), loss = 1.76436
I1027 14:19:41.007804  9023 solver.cpp:241]     Train net output #0: loss = 1.76436 (* 1 = 1.76436 loss)
I1027 14:19:41.007822  9023 sgd_solver.cpp:105] Iteration 69320, lr = 0.00533326
I1027 14:20:11.095316  9023 solver.cpp:222] Iteration 69360 (1.32951 iter/s, 30.0864s/40 iters), loss = 1.96942
I1027 14:20:11.095489  9023 solver.cpp:241]     Train net output #0: loss = 1.96942 (* 1 = 1.96942 loss)
I1027 14:20:11.095506  9023 sgd_solver.cpp:105] Iteration 69360, lr = 0.00533072
I1027 14:20:43.051795  9023 solver.cpp:222] Iteration 69400 (1.25176 iter/s, 31.9551s/40 iters), loss = 1.47733
I1027 14:20:43.052042  9023 solver.cpp:241]     Train net output #0: loss = 1.47733 (* 1 = 1.47733 loss)
I1027 14:20:43.052067  9023 sgd_solver.cpp:105] Iteration 69400, lr = 0.00532818
I1027 14:21:15.058166  9023 solver.cpp:222] Iteration 69440 (1.24981 iter/s, 32.0049s/40 iters), loss = 1.30118
I1027 14:21:15.058518  9023 solver.cpp:241]     Train net output #0: loss = 1.30118 (* 1 = 1.30118 loss)
I1027 14:21:15.058534  9023 sgd_solver.cpp:105] Iteration 69440, lr = 0.00532564
I1027 14:21:45.700595  9023 solver.cpp:222] Iteration 69480 (1.30544 iter/s, 30.6409s/40 iters), loss = 1.568
I1027 14:21:45.700767  9023 solver.cpp:241]     Train net output #0: loss = 1.568 (* 1 = 1.568 loss)
I1027 14:21:45.700783  9023 sgd_solver.cpp:105] Iteration 69480, lr = 0.0053231
I1027 14:22:00.286856  9023 solver.cpp:334] Iteration 69500, Testing net (#0)
I1027 14:22:32.887923  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5498
I1027 14:22:32.888077  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.783959
I1027 14:22:32.888098  9023 solver.cpp:401]     Test net output #2: loss = 2.01126 (* 1 = 2.01126 loss)
I1027 14:22:33.733052  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1027 14:22:48.365767  9023 solver.cpp:222] Iteration 69520 (0.638339 iter/s, 62.6626s/40 iters), loss = 1.89407
I1027 14:22:48.365823  9023 solver.cpp:241]     Train net output #0: loss = 1.89407 (* 1 = 1.89407 loss)
I1027 14:22:48.365838  9023 sgd_solver.cpp:105] Iteration 69520, lr = 0.00532055
I1027 14:23:18.107437  9023 solver.cpp:222] Iteration 69560 (1.34497 iter/s, 29.7405s/40 iters), loss = 1.75426
I1027 14:23:18.107616  9023 solver.cpp:241]     Train net output #0: loss = 1.75426 (* 1 = 1.75426 loss)
I1027 14:23:18.107633  9023 sgd_solver.cpp:105] Iteration 69560, lr = 0.00531801
I1027 14:23:48.844107  9023 solver.cpp:222] Iteration 69600 (1.30143 iter/s, 30.7353s/40 iters), loss = 1.80249
I1027 14:23:48.844251  9023 solver.cpp:241]     Train net output #0: loss = 1.80249 (* 1 = 1.80249 loss)
I1027 14:23:48.844267  9023 sgd_solver.cpp:105] Iteration 69600, lr = 0.00531547
I1027 14:24:19.596559  9023 solver.cpp:222] Iteration 69640 (1.30076 iter/s, 30.7512s/40 iters), loss = 1.58017
I1027 14:24:19.596740  9023 solver.cpp:241]     Train net output #0: loss = 1.58017 (* 1 = 1.58017 loss)
I1027 14:24:19.596756  9023 sgd_solver.cpp:105] Iteration 69640, lr = 0.00531293
I1027 14:24:50.371834  9023 solver.cpp:222] Iteration 69680 (1.2998 iter/s, 30.7739s/40 iters), loss = 1.80473
I1027 14:24:50.372031  9023 solver.cpp:241]     Train net output #0: loss = 1.80473 (* 1 = 1.80473 loss)
I1027 14:24:50.372047  9023 sgd_solver.cpp:105] Iteration 69680, lr = 0.00531039
I1027 14:25:21.650033  9023 solver.cpp:222] Iteration 69720 (1.2789 iter/s, 31.2768s/40 iters), loss = 1.98146
I1027 14:25:21.650244  9023 solver.cpp:241]     Train net output #0: loss = 1.98146 (* 1 = 1.98146 loss)
I1027 14:25:21.650269  9023 sgd_solver.cpp:105] Iteration 69720, lr = 0.00530785
I1027 14:25:53.034652  9023 solver.cpp:222] Iteration 69760 (1.27457 iter/s, 31.3832s/40 iters), loss = 1.8263
I1027 14:25:53.034804  9023 solver.cpp:241]     Train net output #0: loss = 1.8263 (* 1 = 1.8263 loss)
I1027 14:25:53.034823  9023 sgd_solver.cpp:105] Iteration 69760, lr = 0.00530531
I1027 14:26:24.083571  9023 solver.cpp:222] Iteration 69800 (1.28835 iter/s, 31.0476s/40 iters), loss = 1.74589
I1027 14:26:24.083736  9023 solver.cpp:241]     Train net output #0: loss = 1.74589 (* 1 = 1.74589 loss)
I1027 14:26:24.083753  9023 sgd_solver.cpp:105] Iteration 69800, lr = 0.00530277
I1027 14:26:55.446398  9023 solver.cpp:222] Iteration 69840 (1.27545 iter/s, 31.3615s/40 iters), loss = 1.7187
I1027 14:26:55.446622  9023 solver.cpp:241]     Train net output #0: loss = 1.7187 (* 1 = 1.7187 loss)
I1027 14:26:55.446645  9023 sgd_solver.cpp:105] Iteration 69840, lr = 0.00530023
I1027 14:27:26.439853  9023 solver.cpp:222] Iteration 69880 (1.29065 iter/s, 30.9921s/40 iters), loss = 1.38264
I1027 14:27:26.440047  9023 solver.cpp:241]     Train net output #0: loss = 1.38264 (* 1 = 1.38264 loss)
I1027 14:27:26.440065  9023 sgd_solver.cpp:105] Iteration 69880, lr = 0.00529769
I1027 14:27:56.375788  9023 solver.cpp:222] Iteration 69920 (1.33625 iter/s, 29.9346s/40 iters), loss = 1.88926
I1027 14:27:56.375852  9023 solver.cpp:241]     Train net output #0: loss = 1.88926 (* 1 = 1.88926 loss)
I1027 14:27:56.375871  9023 sgd_solver.cpp:105] Iteration 69920, lr = 0.00529515
I1027 14:28:26.332451  9023 solver.cpp:222] Iteration 69960 (1.33532 iter/s, 29.9555s/40 iters), loss = 1.76265
I1027 14:28:26.332614  9023 solver.cpp:241]     Train net output #0: loss = 1.76265 (* 1 = 1.76265 loss)
I1027 14:28:26.332633  9023 sgd_solver.cpp:105] Iteration 69960, lr = 0.00529261
I1027 14:28:55.311571  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_70000.caffemodel
I1027 14:28:55.344130  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_70000.solverstate
I1027 14:28:55.379413  9023 solver.cpp:334] Iteration 70000, Testing net (#0)
I1027 14:29:27.406502  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 14:29:27.610934  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.53976
I1027 14:29:27.610986  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.782279
I1027 14:29:27.611001  9023 solver.cpp:401]     Test net output #2: loss = 2.05491 (* 1 = 2.05491 loss)
I1027 14:29:28.365468  9023 solver.cpp:222] Iteration 70000 (0.644844 iter/s, 62.0305s/40 iters), loss = 1.70717
I1027 14:29:28.365532  9023 solver.cpp:241]     Train net output #0: loss = 1.70717 (* 1 = 1.70717 loss)
I1027 14:29:28.365550  9023 sgd_solver.cpp:105] Iteration 70000, lr = 0.00529007
I1027 14:29:58.036375  9023 solver.cpp:222] Iteration 70040 (1.34818 iter/s, 29.6697s/40 iters), loss = 1.51744
I1027 14:29:58.036541  9023 solver.cpp:241]     Train net output #0: loss = 1.51744 (* 1 = 1.51744 loss)
I1027 14:29:58.036561  9023 sgd_solver.cpp:105] Iteration 70040, lr = 0.00528753
I1027 14:30:27.733979  9023 solver.cpp:222] Iteration 70080 (1.34697 iter/s, 29.6963s/40 iters), loss = 1.38329
I1027 14:30:27.734050  9023 solver.cpp:241]     Train net output #0: loss = 1.38329 (* 1 = 1.38329 loss)
I1027 14:30:27.734067  9023 sgd_solver.cpp:105] Iteration 70080, lr = 0.00528499
I1027 14:30:57.013501  9023 solver.cpp:222] Iteration 70120 (1.3662 iter/s, 29.2783s/40 iters), loss = 1.6285
I1027 14:30:57.013732  9023 solver.cpp:241]     Train net output #0: loss = 1.6285 (* 1 = 1.6285 loss)
I1027 14:30:57.013752  9023 sgd_solver.cpp:105] Iteration 70120, lr = 0.00528245
I1027 14:31:27.500730  9023 solver.cpp:222] Iteration 70160 (1.31208 iter/s, 30.4859s/40 iters), loss = 1.80923
I1027 14:31:27.500929  9023 solver.cpp:241]     Train net output #0: loss = 1.80923 (* 1 = 1.80923 loss)
I1027 14:31:27.500946  9023 sgd_solver.cpp:105] Iteration 70160, lr = 0.00527991
I1027 14:31:56.831558  9023 solver.cpp:222] Iteration 70200 (1.36381 iter/s, 29.3295s/40 iters), loss = 1.67759
I1027 14:31:56.831610  9023 solver.cpp:241]     Train net output #0: loss = 1.67759 (* 1 = 1.67759 loss)
I1027 14:31:56.831626  9023 sgd_solver.cpp:105] Iteration 70200, lr = 0.00527737
I1027 14:32:28.022836  9023 solver.cpp:222] Iteration 70240 (1.28246 iter/s, 31.19s/40 iters), loss = 1.49758
I1027 14:32:28.023030  9023 solver.cpp:241]     Train net output #0: loss = 1.49758 (* 1 = 1.49758 loss)
I1027 14:32:28.023061  9023 sgd_solver.cpp:105] Iteration 70240, lr = 0.00527484
I1027 14:33:00.220342  9023 solver.cpp:222] Iteration 70280 (1.24239 iter/s, 32.1961s/40 iters), loss = 1.75934
I1027 14:33:00.220548  9023 solver.cpp:241]     Train net output #0: loss = 1.75934 (* 1 = 1.75934 loss)
I1027 14:33:00.220579  9023 sgd_solver.cpp:105] Iteration 70280, lr = 0.0052723
I1027 14:33:30.094100  9023 solver.cpp:222] Iteration 70320 (1.33903 iter/s, 29.8724s/40 iters), loss = 1.62863
I1027 14:33:30.094166  9023 solver.cpp:241]     Train net output #0: loss = 1.62863 (* 1 = 1.62863 loss)
I1027 14:33:30.094180  9023 sgd_solver.cpp:105] Iteration 70320, lr = 0.00526976
I1027 14:34:00.625973  9023 solver.cpp:222] Iteration 70360 (1.31016 iter/s, 30.5307s/40 iters), loss = 1.69994
I1027 14:34:00.626149  9023 solver.cpp:241]     Train net output #0: loss = 1.69994 (* 1 = 1.69994 loss)
I1027 14:34:00.626166  9023 sgd_solver.cpp:105] Iteration 70360, lr = 0.00526722
I1027 14:34:31.175395  9023 solver.cpp:222] Iteration 70400 (1.30941 iter/s, 30.5481s/40 iters), loss = 1.62513
I1027 14:34:31.175554  9023 solver.cpp:241]     Train net output #0: loss = 1.62513 (* 1 = 1.62513 loss)
I1027 14:34:31.175572  9023 sgd_solver.cpp:105] Iteration 70400, lr = 0.00526469
I1027 14:35:01.784759  9023 solver.cpp:222] Iteration 70440 (1.30685 iter/s, 30.6081s/40 iters), loss = 1.59478
I1027 14:35:01.784904  9023 solver.cpp:241]     Train net output #0: loss = 1.59478 (* 1 = 1.59478 loss)
I1027 14:35:01.784919  9023 sgd_solver.cpp:105] Iteration 70440, lr = 0.00526215
I1027 14:35:32.383580  9023 solver.cpp:222] Iteration 70480 (1.3073 iter/s, 30.5975s/40 iters), loss = 1.83903
I1027 14:35:32.383731  9023 solver.cpp:241]     Train net output #0: loss = 1.83903 (* 1 = 1.83903 loss)
I1027 14:35:32.383747  9023 sgd_solver.cpp:105] Iteration 70480, lr = 0.00525961
I1027 14:35:46.856799  9023 solver.cpp:334] Iteration 70500, Testing net (#0)
I1027 14:36:18.428167  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54804
I1027 14:36:18.428537  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.784079
I1027 14:36:18.428555  9023 solver.cpp:401]     Test net output #2: loss = 1.99949 (* 1 = 1.99949 loss)
I1027 14:36:34.532227  9023 solver.cpp:222] Iteration 70520 (0.643644 iter/s, 62.1462s/40 iters), loss = 1.65228
I1027 14:36:34.532295  9023 solver.cpp:241]     Train net output #0: loss = 1.65228 (* 1 = 1.65228 loss)
I1027 14:36:34.532316  9023 sgd_solver.cpp:105] Iteration 70520, lr = 0.00525708
I1027 14:37:05.146739  9023 solver.cpp:222] Iteration 70560 (1.30662 iter/s, 30.6133s/40 iters), loss = 1.56081
I1027 14:37:05.146946  9023 solver.cpp:241]     Train net output #0: loss = 1.56081 (* 1 = 1.56081 loss)
I1027 14:37:05.146987  9023 sgd_solver.cpp:105] Iteration 70560, lr = 0.00525454
I1027 14:37:35.780441  9023 solver.cpp:222] Iteration 70600 (1.30581 iter/s, 30.6323s/40 iters), loss = 1.52709
I1027 14:37:35.780614  9023 solver.cpp:241]     Train net output #0: loss = 1.52709 (* 1 = 1.52709 loss)
I1027 14:37:35.780632  9023 sgd_solver.cpp:105] Iteration 70600, lr = 0.005252
I1027 14:38:06.469367  9023 solver.cpp:222] Iteration 70640 (1.30346 iter/s, 30.6876s/40 iters), loss = 1.92958
I1027 14:38:06.469547  9023 solver.cpp:241]     Train net output #0: loss = 1.92958 (* 1 = 1.92958 loss)
I1027 14:38:06.469564  9023 sgd_solver.cpp:105] Iteration 70640, lr = 0.00524947
I1027 14:38:37.215080  9023 solver.cpp:222] Iteration 70680 (1.30105 iter/s, 30.7444s/40 iters), loss = 1.61977
I1027 14:38:37.215260  9023 solver.cpp:241]     Train net output #0: loss = 1.61977 (* 1 = 1.61977 loss)
I1027 14:38:37.215276  9023 sgd_solver.cpp:105] Iteration 70680, lr = 0.00524693
I1027 14:39:07.753861  9023 solver.cpp:222] Iteration 70720 (1.30987 iter/s, 30.5374s/40 iters), loss = 1.61763
I1027 14:39:07.754060  9023 solver.cpp:241]     Train net output #0: loss = 1.61763 (* 1 = 1.61763 loss)
I1027 14:39:07.754079  9023 sgd_solver.cpp:105] Iteration 70720, lr = 0.00524439
I1027 14:39:38.151459  9023 solver.cpp:222] Iteration 70760 (1.31595 iter/s, 30.3963s/40 iters), loss = 1.46049
I1027 14:39:38.151626  9023 solver.cpp:241]     Train net output #0: loss = 1.46049 (* 1 = 1.46049 loss)
I1027 14:39:38.151643  9023 sgd_solver.cpp:105] Iteration 70760, lr = 0.00524186
I1027 14:40:08.599835  9023 solver.cpp:222] Iteration 70800 (1.31376 iter/s, 30.4471s/40 iters), loss = 1.35555
I1027 14:40:08.600029  9023 solver.cpp:241]     Train net output #0: loss = 1.35555 (* 1 = 1.35555 loss)
I1027 14:40:08.600045  9023 sgd_solver.cpp:105] Iteration 70800, lr = 0.00523932
I1027 14:40:39.907109  9023 solver.cpp:222] Iteration 70840 (1.27772 iter/s, 31.3059s/40 iters), loss = 1.55881
I1027 14:40:39.907677  9023 solver.cpp:241]     Train net output #0: loss = 1.55881 (* 1 = 1.55881 loss)
I1027 14:40:39.907704  9023 sgd_solver.cpp:105] Iteration 70840, lr = 0.00523679
I1027 14:41:12.440254  9023 solver.cpp:222] Iteration 70880 (1.22958 iter/s, 32.5314s/40 iters), loss = 1.63795
I1027 14:41:12.440488  9023 solver.cpp:241]     Train net output #0: loss = 1.63795 (* 1 = 1.63795 loss)
I1027 14:41:12.440518  9023 sgd_solver.cpp:105] Iteration 70880, lr = 0.00523425
I1027 14:41:43.660413  9023 solver.cpp:222] Iteration 70920 (1.28128 iter/s, 31.2188s/40 iters), loss = 1.71045
I1027 14:41:43.660567  9023 solver.cpp:241]     Train net output #0: loss = 1.71045 (* 1 = 1.71045 loss)
I1027 14:41:43.660583  9023 sgd_solver.cpp:105] Iteration 70920, lr = 0.00523172
I1027 14:42:14.563033  9023 solver.cpp:222] Iteration 70960 (1.29444 iter/s, 30.9013s/40 iters), loss = 1.70391
I1027 14:42:14.563195  9023 solver.cpp:241]     Train net output #0: loss = 1.70391 (* 1 = 1.70391 loss)
I1027 14:42:14.563211  9023 sgd_solver.cpp:105] Iteration 70960, lr = 0.00522918
I1027 14:42:44.803272  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_71000.caffemodel
I1027 14:42:44.854784  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_71000.solverstate
I1027 14:42:44.903244  9023 solver.cpp:334] Iteration 71000, Testing net (#0)
I1027 14:43:17.773982  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 14:43:17.972683  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54632
I1027 14:43:17.972741  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78472
I1027 14:43:17.972754  9023 solver.cpp:401]     Test net output #2: loss = 2.01558 (* 1 = 2.01558 loss)
I1027 14:43:18.752225  9023 solver.cpp:222] Iteration 71000 (0.623183 iter/s, 64.1866s/40 iters), loss = 1.7566
I1027 14:43:18.752286  9023 solver.cpp:241]     Train net output #0: loss = 1.7566 (* 1 = 1.7566 loss)
I1027 14:43:18.752306  9023 sgd_solver.cpp:105] Iteration 71000, lr = 0.00522665
I1027 14:43:49.928277  9023 solver.cpp:222] Iteration 71040 (1.28309 iter/s, 31.1748s/40 iters), loss = 1.59632
I1027 14:43:49.928532  9023 solver.cpp:241]     Train net output #0: loss = 1.59632 (* 1 = 1.59632 loss)
I1027 14:43:49.928560  9023 sgd_solver.cpp:105] Iteration 71040, lr = 0.00522412
I1027 14:44:20.951997  9023 solver.cpp:222] Iteration 71080 (1.2894 iter/s, 31.0223s/40 iters), loss = 1.49391
I1027 14:44:20.952178  9023 solver.cpp:241]     Train net output #0: loss = 1.49391 (* 1 = 1.49391 loss)
I1027 14:44:20.952195  9023 sgd_solver.cpp:105] Iteration 71080, lr = 0.00522158
I1027 14:44:51.811112  9023 solver.cpp:222] Iteration 71120 (1.29627 iter/s, 30.8578s/40 iters), loss = 1.42588
I1027 14:44:51.811265  9023 solver.cpp:241]     Train net output #0: loss = 1.42588 (* 1 = 1.42588 loss)
I1027 14:44:51.811281  9023 sgd_solver.cpp:105] Iteration 71120, lr = 0.00521905
I1027 14:45:22.713784  9023 solver.cpp:222] Iteration 71160 (1.29444 iter/s, 30.9013s/40 iters), loss = 1.94799
I1027 14:45:22.713943  9023 solver.cpp:241]     Train net output #0: loss = 1.94799 (* 1 = 1.94799 loss)
I1027 14:45:22.713958  9023 sgd_solver.cpp:105] Iteration 71160, lr = 0.00521652
I1027 14:45:53.582412  9023 solver.cpp:222] Iteration 71200 (1.29587 iter/s, 30.8673s/40 iters), loss = 1.9271
I1027 14:45:53.582583  9023 solver.cpp:241]     Train net output #0: loss = 1.9271 (* 1 = 1.9271 loss)
I1027 14:45:53.582599  9023 sgd_solver.cpp:105] Iteration 71200, lr = 0.00521398
I1027 14:46:26.252980  9023 solver.cpp:222] Iteration 71240 (1.2244 iter/s, 32.6692s/40 iters), loss = 1.45746
I1027 14:46:26.253147  9023 solver.cpp:241]     Train net output #0: loss = 1.45746 (* 1 = 1.45746 loss)
I1027 14:46:26.253165  9023 sgd_solver.cpp:105] Iteration 71240, lr = 0.00521145
I1027 14:46:57.231767  9023 solver.cpp:222] Iteration 71280 (1.29126 iter/s, 30.9775s/40 iters), loss = 1.72595
I1027 14:46:57.231941  9023 solver.cpp:241]     Train net output #0: loss = 1.72595 (* 1 = 1.72595 loss)
I1027 14:46:57.231961  9023 sgd_solver.cpp:105] Iteration 71280, lr = 0.00520892
I1027 14:47:28.381897  9023 solver.cpp:222] Iteration 71320 (1.28416 iter/s, 31.1488s/40 iters), loss = 1.94536
I1027 14:47:28.382057  9023 solver.cpp:241]     Train net output #0: loss = 1.94536 (* 1 = 1.94536 loss)
I1027 14:47:28.382076  9023 sgd_solver.cpp:105] Iteration 71320, lr = 0.00520638
I1027 14:47:59.576441  9023 solver.cpp:222] Iteration 71360 (1.28233 iter/s, 31.1932s/40 iters), loss = 1.8141
I1027 14:47:59.576591  9023 solver.cpp:241]     Train net output #0: loss = 1.8141 (* 1 = 1.8141 loss)
I1027 14:47:59.576607  9023 sgd_solver.cpp:105] Iteration 71360, lr = 0.00520385
I1027 14:48:30.782963  9023 solver.cpp:222] Iteration 71400 (1.28184 iter/s, 31.2052s/40 iters), loss = 1.73376
I1027 14:48:30.783102  9023 solver.cpp:241]     Train net output #0: loss = 1.73376 (* 1 = 1.73376 loss)
I1027 14:48:30.783118  9023 sgd_solver.cpp:105] Iteration 71400, lr = 0.00520132
I1027 14:49:01.971755  9023 solver.cpp:222] Iteration 71440 (1.28257 iter/s, 31.1875s/40 iters), loss = 1.84366
I1027 14:49:01.971925  9023 solver.cpp:241]     Train net output #0: loss = 1.84366 (* 1 = 1.84366 loss)
I1027 14:49:01.971943  9023 sgd_solver.cpp:105] Iteration 71440, lr = 0.00519879
I1027 14:49:33.060607  9023 solver.cpp:222] Iteration 71480 (1.28669 iter/s, 31.0875s/40 iters), loss = 1.64187
I1027 14:49:33.060745  9023 solver.cpp:241]     Train net output #0: loss = 1.64187 (* 1 = 1.64187 loss)
I1027 14:49:33.060761  9023 sgd_solver.cpp:105] Iteration 71480, lr = 0.00519626
I1027 14:49:47.685281  9023 solver.cpp:334] Iteration 71500, Testing net (#0)
I1027 14:50:19.905540  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54908
I1027 14:50:19.905709  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78524
I1027 14:50:19.905725  9023 solver.cpp:401]     Test net output #2: loss = 1.98341 (* 1 = 1.98341 loss)
I1027 14:50:36.023036  9023 solver.cpp:222] Iteration 71520 (0.635325 iter/s, 62.9599s/40 iters), loss = 1.5441
I1027 14:50:36.023123  9023 solver.cpp:241]     Train net output #0: loss = 1.5441 (* 1 = 1.5441 loss)
I1027 14:50:36.023152  9023 sgd_solver.cpp:105] Iteration 71520, lr = 0.00519372
I1027 14:51:06.888509  9023 solver.cpp:222] Iteration 71560 (1.296 iter/s, 30.8642s/40 iters), loss = 1.82722
I1027 14:51:06.888725  9023 solver.cpp:241]     Train net output #0: loss = 1.82722 (* 1 = 1.82722 loss)
I1027 14:51:06.888746  9023 sgd_solver.cpp:105] Iteration 71560, lr = 0.00519119
I1027 14:51:37.799437  9023 solver.cpp:222] Iteration 71600 (1.2941 iter/s, 30.9095s/40 iters), loss = 1.68479
I1027 14:51:37.799597  9023 solver.cpp:241]     Train net output #0: loss = 1.68479 (* 1 = 1.68479 loss)
I1027 14:51:37.799615  9023 sgd_solver.cpp:105] Iteration 71600, lr = 0.00518866
I1027 14:52:08.773918  9023 solver.cpp:222] Iteration 71640 (1.29144 iter/s, 30.9732s/40 iters), loss = 1.83146
I1027 14:52:08.774049  9023 solver.cpp:241]     Train net output #0: loss = 1.83146 (* 1 = 1.83146 loss)
I1027 14:52:08.774066  9023 sgd_solver.cpp:105] Iteration 71640, lr = 0.00518613
I1027 14:52:39.522639  9023 solver.cpp:222] Iteration 71680 (1.30092 iter/s, 30.7474s/40 iters), loss = 1.94618
I1027 14:52:39.522768  9023 solver.cpp:241]     Train net output #0: loss = 1.94618 (* 1 = 1.94618 loss)
I1027 14:52:39.522784  9023 sgd_solver.cpp:105] Iteration 71680, lr = 0.0051836
I1027 14:53:10.319558  9023 solver.cpp:222] Iteration 71720 (1.29889 iter/s, 30.7956s/40 iters), loss = 1.25685
I1027 14:53:10.319681  9023 solver.cpp:241]     Train net output #0: loss = 1.25685 (* 1 = 1.25685 loss)
I1027 14:53:10.319697  9023 sgd_solver.cpp:105] Iteration 71720, lr = 0.00518107
I1027 14:53:41.316313  9023 solver.cpp:222] Iteration 71760 (1.29051 iter/s, 30.9955s/40 iters), loss = 1.75781
I1027 14:53:41.316448  9023 solver.cpp:241]     Train net output #0: loss = 1.75781 (* 1 = 1.75781 loss)
I1027 14:53:41.316464  9023 sgd_solver.cpp:105] Iteration 71760, lr = 0.00517854
I1027 14:54:12.247496  9023 solver.cpp:222] Iteration 71800 (1.29325 iter/s, 30.9299s/40 iters), loss = 1.71174
I1027 14:54:12.247655  9023 solver.cpp:241]     Train net output #0: loss = 1.71174 (* 1 = 1.71174 loss)
I1027 14:54:12.247671  9023 sgd_solver.cpp:105] Iteration 71800, lr = 0.00517601
I1027 14:54:42.857918  9023 solver.cpp:222] Iteration 71840 (1.3068 iter/s, 30.6091s/40 iters), loss = 1.55452
I1027 14:54:42.858073  9023 solver.cpp:241]     Train net output #0: loss = 1.55452 (* 1 = 1.55452 loss)
I1027 14:54:42.858089  9023 sgd_solver.cpp:105] Iteration 71840, lr = 0.00517348
I1027 14:55:13.544857  9023 solver.cpp:222] Iteration 71880 (1.30354 iter/s, 30.6856s/40 iters), loss = 1.76179
I1027 14:55:13.545022  9023 solver.cpp:241]     Train net output #0: loss = 1.76179 (* 1 = 1.76179 loss)
I1027 14:55:13.545037  9023 sgd_solver.cpp:105] Iteration 71880, lr = 0.00517095
I1027 14:55:44.223816  9023 solver.cpp:222] Iteration 71920 (1.30388 iter/s, 30.6776s/40 iters), loss = 1.67198
I1027 14:55:44.223989  9023 solver.cpp:241]     Train net output #0: loss = 1.67198 (* 1 = 1.67198 loss)
I1027 14:55:44.224004  9023 sgd_solver.cpp:105] Iteration 71920, lr = 0.00516842
I1027 14:56:14.907851  9023 solver.cpp:222] Iteration 71960 (1.30367 iter/s, 30.6827s/40 iters), loss = 2.12185
I1027 14:56:14.908005  9023 solver.cpp:241]     Train net output #0: loss = 2.12185 (* 1 = 2.12185 loss)
I1027 14:56:14.908021  9023 sgd_solver.cpp:105] Iteration 71960, lr = 0.00516589
I1027 14:56:44.859582  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_72000.caffemodel
I1027 14:56:44.890554  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_72000.solverstate
I1027 14:56:44.907042  9023 solver.cpp:334] Iteration 72000, Testing net (#0)
I1027 14:57:16.301673  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 14:57:16.512133  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54432
I1027 14:57:16.512192  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.783119
I1027 14:57:16.512207  9023 solver.cpp:401]     Test net output #2: loss = 2.04934 (* 1 = 2.04934 loss)
I1027 14:57:17.278472  9023 solver.cpp:222] Iteration 72000 (0.641353 iter/s, 62.3681s/40 iters), loss = 1.70806
I1027 14:57:17.278512  9023 solver.cpp:241]     Train net output #0: loss = 1.70806 (* 1 = 1.70806 loss)
I1027 14:57:17.278527  9023 sgd_solver.cpp:105] Iteration 72000, lr = 0.00516336
I1027 14:57:18.929533  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1027 14:57:47.995632  9023 solver.cpp:222] Iteration 72040 (1.30225 iter/s, 30.716s/40 iters), loss = 1.68796
I1027 14:57:47.995810  9023 solver.cpp:241]     Train net output #0: loss = 1.68796 (* 1 = 1.68796 loss)
I1027 14:57:47.995826  9023 sgd_solver.cpp:105] Iteration 72040, lr = 0.00516083
I1027 14:58:18.811684  9023 solver.cpp:222] Iteration 72080 (1.29808 iter/s, 30.8147s/40 iters), loss = 1.67913
I1027 14:58:18.811908  9023 solver.cpp:241]     Train net output #0: loss = 1.67913 (* 1 = 1.67913 loss)
I1027 14:58:18.811940  9023 sgd_solver.cpp:105] Iteration 72080, lr = 0.0051583
I1027 14:58:50.156432  9023 solver.cpp:222] Iteration 72120 (1.27619 iter/s, 31.3433s/40 iters), loss = 1.72651
I1027 14:58:50.156618  9023 solver.cpp:241]     Train net output #0: loss = 1.72651 (* 1 = 1.72651 loss)
I1027 14:58:50.156635  9023 sgd_solver.cpp:105] Iteration 72120, lr = 0.00515578
I1027 14:59:20.909843  9023 solver.cpp:222] Iteration 72160 (1.30073 iter/s, 30.7521s/40 iters), loss = 1.42587
I1027 14:59:20.910014  9023 solver.cpp:241]     Train net output #0: loss = 1.42587 (* 1 = 1.42587 loss)
I1027 14:59:20.910030  9023 sgd_solver.cpp:105] Iteration 72160, lr = 0.00515325
I1027 14:59:51.743057  9023 solver.cpp:222] Iteration 72200 (1.29736 iter/s, 30.8319s/40 iters), loss = 1.51603
I1027 14:59:51.743221  9023 solver.cpp:241]     Train net output #0: loss = 1.51603 (* 1 = 1.51603 loss)
I1027 14:59:51.743237  9023 sgd_solver.cpp:105] Iteration 72200, lr = 0.00515072
I1027 15:00:26.919658  9023 solver.cpp:222] Iteration 72240 (1.13717 iter/s, 35.1751s/40 iters), loss = 2.15624
I1027 15:00:26.919859  9023 solver.cpp:241]     Train net output #0: loss = 2.15624 (* 1 = 2.15624 loss)
I1027 15:00:26.919881  9023 sgd_solver.cpp:105] Iteration 72240, lr = 0.00514819
I1027 15:01:02.938555  9023 solver.cpp:222] Iteration 72280 (1.11058 iter/s, 36.0173s/40 iters), loss = 1.73647
I1027 15:01:02.938803  9023 solver.cpp:241]     Train net output #0: loss = 1.73647 (* 1 = 1.73647 loss)
I1027 15:01:02.938827  9023 sgd_solver.cpp:105] Iteration 72280, lr = 0.00514566
I1027 15:01:35.396966  9023 solver.cpp:222] Iteration 72320 (1.2324 iter/s, 32.457s/40 iters), loss = 1.74231
I1027 15:01:35.397119  9023 solver.cpp:241]     Train net output #0: loss = 1.74231 (* 1 = 1.74231 loss)
I1027 15:01:35.397135  9023 sgd_solver.cpp:105] Iteration 72320, lr = 0.00514314
I1027 15:02:06.133747  9023 solver.cpp:222] Iteration 72360 (1.30143 iter/s, 30.7355s/40 iters), loss = 1.71024
I1027 15:02:06.133924  9023 solver.cpp:241]     Train net output #0: loss = 1.71024 (* 1 = 1.71024 loss)
I1027 15:02:06.133940  9023 sgd_solver.cpp:105] Iteration 72360, lr = 0.00514061
I1027 15:02:36.893326  9023 solver.cpp:222] Iteration 72400 (1.30046 iter/s, 30.7582s/40 iters), loss = 1.50986
I1027 15:02:36.893473  9023 solver.cpp:241]     Train net output #0: loss = 1.50986 (* 1 = 1.50986 loss)
I1027 15:02:36.893489  9023 sgd_solver.cpp:105] Iteration 72400, lr = 0.00513808
I1027 15:03:07.533804  9023 solver.cpp:222] Iteration 72440 (1.30552 iter/s, 30.6392s/40 iters), loss = 1.67882
I1027 15:03:07.533960  9023 solver.cpp:241]     Train net output #0: loss = 1.67882 (* 1 = 1.67882 loss)
I1027 15:03:07.533977  9023 sgd_solver.cpp:105] Iteration 72440, lr = 0.00513556
I1027 15:03:38.366751  9023 solver.cpp:222] Iteration 72480 (1.29737 iter/s, 30.8316s/40 iters), loss = 1.58992
I1027 15:03:38.366897  9023 solver.cpp:241]     Train net output #0: loss = 1.58992 (* 1 = 1.58992 loss)
I1027 15:03:38.366914  9023 sgd_solver.cpp:105] Iteration 72480, lr = 0.00513303
I1027 15:03:53.057435  9023 solver.cpp:334] Iteration 72500, Testing net (#0)
I1027 15:04:24.511148  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54244
I1027 15:04:24.512002  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78048
I1027 15:04:24.512019  9023 solver.cpp:401]     Test net output #2: loss = 2.0544 (* 1 = 2.0544 loss)
I1027 15:04:40.518517  9023 solver.cpp:222] Iteration 72520 (0.643611 iter/s, 62.1493s/40 iters), loss = 1.68004
I1027 15:04:40.518591  9023 solver.cpp:241]     Train net output #0: loss = 1.68004 (* 1 = 1.68004 loss)
I1027 15:04:40.518606  9023 sgd_solver.cpp:105] Iteration 72520, lr = 0.0051305
I1027 15:05:11.028442  9023 solver.cpp:222] Iteration 72560 (1.3111 iter/s, 30.5087s/40 iters), loss = 1.47904
I1027 15:05:11.028601  9023 solver.cpp:241]     Train net output #0: loss = 1.47904 (* 1 = 1.47904 loss)
I1027 15:05:11.028620  9023 sgd_solver.cpp:105] Iteration 72560, lr = 0.00512798
I1027 15:05:41.731578  9023 solver.cpp:222] Iteration 72600 (1.30285 iter/s, 30.7018s/40 iters), loss = 1.37209
I1027 15:05:41.731727  9023 solver.cpp:241]     Train net output #0: loss = 1.37209 (* 1 = 1.37209 loss)
I1027 15:05:41.731743  9023 sgd_solver.cpp:105] Iteration 72600, lr = 0.00512545
I1027 15:06:12.469887  9023 solver.cpp:222] Iteration 72640 (1.30136 iter/s, 30.737s/40 iters), loss = 1.71893
I1027 15:06:12.470022  9023 solver.cpp:241]     Train net output #0: loss = 1.71893 (* 1 = 1.71893 loss)
I1027 15:06:12.470037  9023 sgd_solver.cpp:105] Iteration 72640, lr = 0.00512292
I1027 15:06:43.121083  9023 solver.cpp:222] Iteration 72680 (1.30506 iter/s, 30.6499s/40 iters), loss = 2.01199
I1027 15:06:43.121207  9023 solver.cpp:241]     Train net output #0: loss = 2.01199 (* 1 = 2.01199 loss)
I1027 15:06:43.121222  9023 sgd_solver.cpp:105] Iteration 72680, lr = 0.0051204
I1027 15:07:13.840378  9023 solver.cpp:222] Iteration 72720 (1.30217 iter/s, 30.718s/40 iters), loss = 1.90963
I1027 15:07:13.840526  9023 solver.cpp:241]     Train net output #0: loss = 1.90963 (* 1 = 1.90963 loss)
I1027 15:07:13.840541  9023 sgd_solver.cpp:105] Iteration 72720, lr = 0.00511787
I1027 15:08:12.922020  9023 solver.cpp:222] Iteration 72760 (0.677057 iter/s, 59.0793s/40 iters), loss = 1.52464
I1027 15:08:12.922227  9023 solver.cpp:241]     Train net output #0: loss = 1.52464 (* 1 = 1.52464 loss)
I1027 15:08:12.922250  9023 sgd_solver.cpp:105] Iteration 72760, lr = 0.00511535
I1027 15:08:43.847579  9023 solver.cpp:222] Iteration 72800 (1.29349 iter/s, 30.9242s/40 iters), loss = 1.47146
I1027 15:08:43.847730  9023 solver.cpp:241]     Train net output #0: loss = 1.47146 (* 1 = 1.47146 loss)
I1027 15:08:43.847746  9023 sgd_solver.cpp:105] Iteration 72800, lr = 0.00511282
I1027 15:09:14.739264  9023 solver.cpp:222] Iteration 72840 (1.2949 iter/s, 30.8904s/40 iters), loss = 1.88677
I1027 15:09:14.739403  9023 solver.cpp:241]     Train net output #0: loss = 1.88677 (* 1 = 1.88677 loss)
I1027 15:09:14.739419  9023 sgd_solver.cpp:105] Iteration 72840, lr = 0.0051103
I1027 15:09:45.435883  9023 solver.cpp:222] Iteration 72880 (1.30313 iter/s, 30.6953s/40 iters), loss = 1.62076
I1027 15:09:45.436029  9023 solver.cpp:241]     Train net output #0: loss = 1.62076 (* 1 = 1.62076 loss)
I1027 15:09:45.436044  9023 sgd_solver.cpp:105] Iteration 72880, lr = 0.00510777
I1027 15:10:16.410214  9023 solver.cpp:222] Iteration 72920 (1.29145 iter/s, 30.973s/40 iters), loss = 1.57794
I1027 15:10:16.410408  9023 solver.cpp:241]     Train net output #0: loss = 1.57794 (* 1 = 1.57794 loss)
I1027 15:10:16.410425  9023 sgd_solver.cpp:105] Iteration 72920, lr = 0.00510525
I1027 15:10:48.045404  9023 solver.cpp:222] Iteration 72960 (1.26447 iter/s, 31.6338s/40 iters), loss = 2.10216
I1027 15:10:48.045595  9023 solver.cpp:241]     Train net output #0: loss = 2.10216 (* 1 = 2.10216 loss)
I1027 15:10:48.045611  9023 sgd_solver.cpp:105] Iteration 72960, lr = 0.00510273
I1027 15:11:17.892428  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_73000.caffemodel
I1027 15:11:17.948607  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_73000.solverstate
I1027 15:11:17.970515  9023 solver.cpp:334] Iteration 73000, Testing net (#0)
I1027 15:11:49.036739  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 15:11:49.248124  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55168
I1027 15:11:49.248178  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.790039
I1027 15:11:49.248189  9023 solver.cpp:401]     Test net output #2: loss = 1.99811 (* 1 = 1.99811 loss)
I1027 15:11:50.018967  9023 solver.cpp:222] Iteration 73000 (0.645463 iter/s, 61.9711s/40 iters), loss = 1.55798
I1027 15:11:50.019028  9023 solver.cpp:241]     Train net output #0: loss = 1.55798 (* 1 = 1.55798 loss)
I1027 15:11:50.019043  9023 sgd_solver.cpp:105] Iteration 73000, lr = 0.0051002
I1027 15:12:20.619011  9023 solver.cpp:222] Iteration 73040 (1.30724 iter/s, 30.5988s/40 iters), loss = 1.43281
I1027 15:12:20.619233  9023 solver.cpp:241]     Train net output #0: loss = 1.43281 (* 1 = 1.43281 loss)
I1027 15:12:20.619249  9023 sgd_solver.cpp:105] Iteration 73040, lr = 0.00509768
I1027 15:12:51.427088  9023 solver.cpp:222] Iteration 73080 (1.29842 iter/s, 30.8067s/40 iters), loss = 1.84905
I1027 15:12:51.427289  9023 solver.cpp:241]     Train net output #0: loss = 1.84905 (* 1 = 1.84905 loss)
I1027 15:12:51.427309  9023 sgd_solver.cpp:105] Iteration 73080, lr = 0.00509515
I1027 15:13:23.668583  9023 solver.cpp:222] Iteration 73120 (1.24069 iter/s, 32.2401s/40 iters), loss = 1.93781
I1027 15:13:23.668751  9023 solver.cpp:241]     Train net output #0: loss = 1.93781 (* 1 = 1.93781 loss)
I1027 15:13:23.668768  9023 sgd_solver.cpp:105] Iteration 73120, lr = 0.00509263
I1027 15:13:54.116292  9023 solver.cpp:222] Iteration 73160 (1.31379 iter/s, 30.4464s/40 iters), loss = 1.79077
I1027 15:13:54.116557  9023 solver.cpp:241]     Train net output #0: loss = 1.79077 (* 1 = 1.79077 loss)
I1027 15:13:54.116581  9023 sgd_solver.cpp:105] Iteration 73160, lr = 0.00509011
I1027 15:14:36.361729  9023 solver.cpp:222] Iteration 73200 (0.94689 iter/s, 42.2436s/40 iters), loss = 1.71211
I1027 15:14:36.361994  9023 solver.cpp:241]     Train net output #0: loss = 1.71211 (* 1 = 1.71211 loss)
I1027 15:14:36.362017  9023 sgd_solver.cpp:105] Iteration 73200, lr = 0.00508759
I1027 15:15:07.143137  9023 solver.cpp:222] Iteration 73240 (1.29955 iter/s, 30.78s/40 iters), loss = 1.87432
I1027 15:15:07.143260  9023 solver.cpp:241]     Train net output #0: loss = 1.87432 (* 1 = 1.87432 loss)
I1027 15:15:07.143275  9023 sgd_solver.cpp:105] Iteration 73240, lr = 0.00508506
I1027 15:15:37.909205  9023 solver.cpp:222] Iteration 73280 (1.30019 iter/s, 30.7648s/40 iters), loss = 1.71852
I1027 15:15:37.909317  9023 solver.cpp:241]     Train net output #0: loss = 1.71852 (* 1 = 1.71852 loss)
I1027 15:15:37.909334  9023 sgd_solver.cpp:105] Iteration 73280, lr = 0.00508254
I1027 15:16:08.567528  9023 solver.cpp:222] Iteration 73320 (1.30476 iter/s, 30.6571s/40 iters), loss = 1.35003
I1027 15:16:08.567665  9023 solver.cpp:241]     Train net output #0: loss = 1.35003 (* 1 = 1.35003 loss)
I1027 15:16:08.567682  9023 sgd_solver.cpp:105] Iteration 73320, lr = 0.00508002
I1027 15:16:39.038745  9023 solver.cpp:222] Iteration 73360 (1.31277 iter/s, 30.4699s/40 iters), loss = 1.50319
I1027 15:16:39.038957  9023 solver.cpp:241]     Train net output #0: loss = 1.50319 (* 1 = 1.50319 loss)
I1027 15:16:39.038972  9023 sgd_solver.cpp:105] Iteration 73360, lr = 0.0050775
I1027 15:17:09.280309  9023 solver.cpp:222] Iteration 73400 (1.32274 iter/s, 30.2402s/40 iters), loss = 1.56973
I1027 15:17:09.280434  9023 solver.cpp:241]     Train net output #0: loss = 1.56973 (* 1 = 1.56973 loss)
I1027 15:17:09.280449  9023 sgd_solver.cpp:105] Iteration 73400, lr = 0.00507497
I1027 15:17:40.223060  9023 solver.cpp:222] Iteration 73440 (1.29276 iter/s, 30.9415s/40 iters), loss = 1.65954
I1027 15:17:40.223242  9023 solver.cpp:241]     Train net output #0: loss = 1.65954 (* 1 = 1.65954 loss)
I1027 15:17:40.223258  9023 sgd_solver.cpp:105] Iteration 73440, lr = 0.00507245
I1027 15:18:10.877053  9023 solver.cpp:222] Iteration 73480 (1.30494 iter/s, 30.6527s/40 iters), loss = 1.73609
I1027 15:18:10.877287  9023 solver.cpp:241]     Train net output #0: loss = 1.73609 (* 1 = 1.73609 loss)
I1027 15:18:10.877333  9023 sgd_solver.cpp:105] Iteration 73480, lr = 0.00506993
I1027 15:18:25.335834  9023 solver.cpp:334] Iteration 73500, Testing net (#0)
I1027 15:18:56.725682  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54816
I1027 15:18:56.725860  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78304
I1027 15:18:56.725877  9023 solver.cpp:401]     Test net output #2: loss = 2.0277 (* 1 = 2.0277 loss)
I1027 15:19:12.721421  9023 solver.cpp:222] Iteration 73520 (0.646811 iter/s, 61.8418s/40 iters), loss = 2.03264
I1027 15:19:12.721489  9023 solver.cpp:241]     Train net output #0: loss = 2.03264 (* 1 = 2.03264 loss)
I1027 15:19:12.721503  9023 sgd_solver.cpp:105] Iteration 73520, lr = 0.00506741
I1027 15:19:43.145511  9023 solver.cpp:222] Iteration 73560 (1.3148 iter/s, 30.4229s/40 iters), loss = 1.74188
I1027 15:19:43.145676  9023 solver.cpp:241]     Train net output #0: loss = 1.74188 (* 1 = 1.74188 loss)
I1027 15:19:43.145691  9023 sgd_solver.cpp:105] Iteration 73560, lr = 0.00506489
I1027 15:20:13.616295  9023 solver.cpp:222] Iteration 73600 (1.31279 iter/s, 30.4695s/40 iters), loss = 1.84735
I1027 15:20:13.616456  9023 solver.cpp:241]     Train net output #0: loss = 1.84735 (* 1 = 1.84735 loss)
I1027 15:20:13.616470  9023 sgd_solver.cpp:105] Iteration 73600, lr = 0.00506237
I1027 15:20:44.039001  9023 solver.cpp:222] Iteration 73640 (1.31486 iter/s, 30.4214s/40 iters), loss = 1.62422
I1027 15:20:44.039163  9023 solver.cpp:241]     Train net output #0: loss = 1.62422 (* 1 = 1.62422 loss)
I1027 15:20:44.039180  9023 sgd_solver.cpp:105] Iteration 73640, lr = 0.00505985
I1027 15:21:14.611690  9023 solver.cpp:222] Iteration 73680 (1.30841 iter/s, 30.5714s/40 iters), loss = 2.07569
I1027 15:21:14.611881  9023 solver.cpp:241]     Train net output #0: loss = 2.07569 (* 1 = 2.07569 loss)
I1027 15:21:14.611896  9023 sgd_solver.cpp:105] Iteration 73680, lr = 0.00505733
I1027 15:21:45.664958  9023 solver.cpp:222] Iteration 73720 (1.28817 iter/s, 31.0519s/40 iters), loss = 1.65823
I1027 15:21:45.665249  9023 solver.cpp:241]     Train net output #0: loss = 1.65823 (* 1 = 1.65823 loss)
I1027 15:21:45.665287  9023 sgd_solver.cpp:105] Iteration 73720, lr = 0.00505481
I1027 15:22:18.131279  9023 solver.cpp:222] Iteration 73760 (1.2321 iter/s, 32.4648s/40 iters), loss = 1.83227
I1027 15:22:18.131487  9023 solver.cpp:241]     Train net output #0: loss = 1.83227 (* 1 = 1.83227 loss)
I1027 15:22:18.131510  9023 sgd_solver.cpp:105] Iteration 73760, lr = 0.00505229
I1027 15:22:49.011570  9023 solver.cpp:222] Iteration 73800 (1.29538 iter/s, 30.8789s/40 iters), loss = 2.12254
I1027 15:22:49.011735  9023 solver.cpp:241]     Train net output #0: loss = 2.12254 (* 1 = 2.12254 loss)
I1027 15:22:49.011751  9023 sgd_solver.cpp:105] Iteration 73800, lr = 0.00504977
I1027 15:23:19.691354  9023 solver.cpp:222] Iteration 73840 (1.30385 iter/s, 30.6785s/40 iters), loss = 1.60975
I1027 15:23:19.691514  9023 solver.cpp:241]     Train net output #0: loss = 1.60975 (* 1 = 1.60975 loss)
I1027 15:23:19.691529  9023 sgd_solver.cpp:105] Iteration 73840, lr = 0.00504725
I1027 15:23:50.167685  9023 solver.cpp:222] Iteration 73880 (1.31255 iter/s, 30.475s/40 iters), loss = 1.93548
I1027 15:23:50.167835  9023 solver.cpp:241]     Train net output #0: loss = 1.93548 (* 1 = 1.93548 loss)
I1027 15:23:50.167850  9023 sgd_solver.cpp:105] Iteration 73880, lr = 0.00504473
I1027 15:24:20.835899  9023 solver.cpp:222] Iteration 73920 (1.30434 iter/s, 30.6669s/40 iters), loss = 1.75408
I1027 15:24:20.836077  9023 solver.cpp:241]     Train net output #0: loss = 1.75408 (* 1 = 1.75408 loss)
I1027 15:24:20.836093  9023 sgd_solver.cpp:105] Iteration 73920, lr = 0.00504221
I1027 15:24:51.276154  9023 solver.cpp:222] Iteration 73960 (1.31411 iter/s, 30.4389s/40 iters), loss = 1.79314
I1027 15:24:51.276324  9023 solver.cpp:241]     Train net output #0: loss = 1.79314 (* 1 = 1.79314 loss)
I1027 15:24:51.276353  9023 sgd_solver.cpp:105] Iteration 73960, lr = 0.00503969
I1027 15:25:20.957121  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_74000.caffemodel
I1027 15:25:20.994772  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_74000.solverstate
I1027 15:25:21.011624  9023 solver.cpp:334] Iteration 74000, Testing net (#0)
I1027 15:25:52.485301  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 15:25:52.696637  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54912
I1027 15:25:52.696699  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78536
I1027 15:25:52.696712  9023 solver.cpp:401]     Test net output #2: loss = 2.00202 (* 1 = 2.00202 loss)
I1027 15:25:53.465715  9023 solver.cpp:222] Iteration 74000 (0.643221 iter/s, 62.1871s/40 iters), loss = 2.00092
I1027 15:25:53.465777  9023 solver.cpp:241]     Train net output #0: loss = 2.00092 (* 1 = 2.00092 loss)
I1027 15:25:53.465792  9023 sgd_solver.cpp:105] Iteration 74000, lr = 0.00503717
I1027 15:26:24.023444  9023 solver.cpp:222] Iteration 74040 (1.30905 iter/s, 30.5565s/40 iters), loss = 2.0315
I1027 15:26:24.023633  9023 solver.cpp:241]     Train net output #0: loss = 2.0315 (* 1 = 2.0315 loss)
I1027 15:26:24.023653  9023 sgd_solver.cpp:105] Iteration 74040, lr = 0.00503465
I1027 15:26:54.463604  9023 solver.cpp:222] Iteration 74080 (1.31411 iter/s, 30.4388s/40 iters), loss = 1.85047
I1027 15:26:54.463768  9023 solver.cpp:241]     Train net output #0: loss = 1.85047 (* 1 = 1.85047 loss)
I1027 15:26:54.463783  9023 sgd_solver.cpp:105] Iteration 74080, lr = 0.00503214
I1027 15:27:25.103540  9023 solver.cpp:222] Iteration 74120 (1.30554 iter/s, 30.6386s/40 iters), loss = 1.75973
I1027 15:27:25.103693  9023 solver.cpp:241]     Train net output #0: loss = 1.75973 (* 1 = 1.75973 loss)
I1027 15:27:25.103708  9023 sgd_solver.cpp:105] Iteration 74120, lr = 0.00502962
I1027 15:27:55.923868  9023 solver.cpp:222] Iteration 74160 (1.2979 iter/s, 30.819s/40 iters), loss = 1.47989
I1027 15:27:55.924041  9023 solver.cpp:241]     Train net output #0: loss = 1.47989 (* 1 = 1.47989 loss)
I1027 15:27:55.924057  9023 sgd_solver.cpp:105] Iteration 74160, lr = 0.0050271
I1027 15:28:26.526499  9023 solver.cpp:222] Iteration 74200 (1.30713 iter/s, 30.6013s/40 iters), loss = 1.71776
I1027 15:28:26.526670  9023 solver.cpp:241]     Train net output #0: loss = 1.71776 (* 1 = 1.71776 loss)
I1027 15:28:26.526685  9023 sgd_solver.cpp:105] Iteration 74200, lr = 0.00502458
I1027 15:28:57.274698  9023 solver.cpp:222] Iteration 74240 (1.30095 iter/s, 30.7469s/40 iters), loss = 1.9206
I1027 15:28:57.274852  9023 solver.cpp:241]     Train net output #0: loss = 1.9206 (* 1 = 1.9206 loss)
I1027 15:28:57.274866  9023 sgd_solver.cpp:105] Iteration 74240, lr = 0.00502206
I1027 15:29:28.000953  9023 solver.cpp:222] Iteration 74280 (1.30187 iter/s, 30.7249s/40 iters), loss = 1.62628
I1027 15:29:28.001118  9023 solver.cpp:241]     Train net output #0: loss = 1.62628 (* 1 = 1.62628 loss)
I1027 15:29:28.001133  9023 sgd_solver.cpp:105] Iteration 74280, lr = 0.00501955
I1027 15:29:58.813799  9023 solver.cpp:222] Iteration 74320 (1.29822 iter/s, 30.8115s/40 iters), loss = 1.88444
I1027 15:29:58.813961  9023 solver.cpp:241]     Train net output #0: loss = 1.88444 (* 1 = 1.88444 loss)
I1027 15:29:58.813977  9023 sgd_solver.cpp:105] Iteration 74320, lr = 0.00501703
I1027 15:30:29.504175  9023 solver.cpp:222] Iteration 74360 (1.3034 iter/s, 30.6891s/40 iters), loss = 1.84395
I1027 15:30:29.504591  9023 solver.cpp:241]     Train net output #0: loss = 1.84395 (* 1 = 1.84395 loss)
I1027 15:30:29.504607  9023 sgd_solver.cpp:105] Iteration 74360, lr = 0.00501451
I1027 15:31:00.513564  9023 solver.cpp:222] Iteration 74400 (1.29 iter/s, 31.0078s/40 iters), loss = 1.59341
I1027 15:31:00.513769  9023 solver.cpp:241]     Train net output #0: loss = 1.59341 (* 1 = 1.59341 loss)
I1027 15:31:00.513806  9023 sgd_solver.cpp:105] Iteration 74400, lr = 0.005012
I1027 15:31:34.428396  9023 solver.cpp:222] Iteration 74440 (1.17948 iter/s, 33.9134s/40 iters), loss = 2.00528
I1027 15:31:34.428686  9023 solver.cpp:241]     Train net output #0: loss = 2.00528 (* 1 = 2.00528 loss)
I1027 15:31:34.428722  9023 sgd_solver.cpp:105] Iteration 74440, lr = 0.00500948
I1027 15:32:05.128085  9023 solver.cpp:222] Iteration 74480 (1.30301 iter/s, 30.6982s/40 iters), loss = 1.63116
I1027 15:32:05.128268  9023 solver.cpp:241]     Train net output #0: loss = 1.63116 (* 1 = 1.63116 loss)
I1027 15:32:05.128283  9023 sgd_solver.cpp:105] Iteration 74480, lr = 0.00500696
I1027 15:32:19.685391  9023 solver.cpp:334] Iteration 74500, Testing net (#0)
I1027 15:32:51.007148  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55284
I1027 15:32:51.007335  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78712
I1027 15:32:51.007350  9023 solver.cpp:401]     Test net output #2: loss = 1.97633 (* 1 = 1.97633 loss)
I1027 15:32:55.633690  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1027 15:33:07.280095  9023 solver.cpp:222] Iteration 74520 (0.643609 iter/s, 62.1495s/40 iters), loss = 1.75201
I1027 15:33:07.280164  9023 solver.cpp:241]     Train net output #0: loss = 1.75201 (* 1 = 1.75201 loss)
I1027 15:33:07.280180  9023 sgd_solver.cpp:105] Iteration 74520, lr = 0.00500445
I1027 15:33:38.067147  9023 solver.cpp:222] Iteration 74560 (1.2993 iter/s, 30.7858s/40 iters), loss = 1.69912
I1027 15:33:38.067459  9023 solver.cpp:241]     Train net output #0: loss = 1.69912 (* 1 = 1.69912 loss)
I1027 15:33:38.067476  9023 sgd_solver.cpp:105] Iteration 74560, lr = 0.00500193
I1027 15:34:09.006065  9023 solver.cpp:222] Iteration 74600 (1.29293 iter/s, 30.9374s/40 iters), loss = 1.70292
I1027 15:34:09.006222  9023 solver.cpp:241]     Train net output #0: loss = 1.70292 (* 1 = 1.70292 loss)
I1027 15:34:09.006237  9023 sgd_solver.cpp:105] Iteration 74600, lr = 0.00499942
I1027 15:34:40.230607  9023 solver.cpp:222] Iteration 74640 (1.2811 iter/s, 31.2232s/40 iters), loss = 1.93635
I1027 15:34:40.230814  9023 solver.cpp:241]     Train net output #0: loss = 1.93635 (* 1 = 1.93635 loss)
I1027 15:34:40.230839  9023 sgd_solver.cpp:105] Iteration 74640, lr = 0.0049969
I1027 15:35:14.845186  9023 solver.cpp:222] Iteration 74680 (1.15563 iter/s, 34.6131s/40 iters), loss = 1.76054
I1027 15:35:14.845412  9023 solver.cpp:241]     Train net output #0: loss = 1.76054 (* 1 = 1.76054 loss)
I1027 15:35:14.845435  9023 sgd_solver.cpp:105] Iteration 74680, lr = 0.00499439
I1027 15:35:48.168517  9023 solver.cpp:222] Iteration 74720 (1.20041 iter/s, 33.3218s/40 iters), loss = 1.69613
I1027 15:35:48.168776  9023 solver.cpp:241]     Train net output #0: loss = 1.69613 (* 1 = 1.69613 loss)
I1027 15:35:48.168799  9023 sgd_solver.cpp:105] Iteration 74720, lr = 0.00499187
I1027 15:36:21.827584  9023 solver.cpp:222] Iteration 74760 (1.18844 iter/s, 33.6575s/40 iters), loss = 1.74169
I1027 15:36:21.827849  9023 solver.cpp:241]     Train net output #0: loss = 1.74169 (* 1 = 1.74169 loss)
I1027 15:36:21.827879  9023 sgd_solver.cpp:105] Iteration 74760, lr = 0.00498936
I1027 15:36:53.297524  9023 solver.cpp:222] Iteration 74800 (1.27111 iter/s, 31.4685s/40 iters), loss = 1.6499
I1027 15:36:53.297737  9023 solver.cpp:241]     Train net output #0: loss = 1.6499 (* 1 = 1.6499 loss)
I1027 15:36:53.297754  9023 sgd_solver.cpp:105] Iteration 74800, lr = 0.00498684
I1027 15:37:24.121562  9023 solver.cpp:222] Iteration 74840 (1.29775 iter/s, 30.8227s/40 iters), loss = 1.70116
I1027 15:37:24.121803  9023 solver.cpp:241]     Train net output #0: loss = 1.70116 (* 1 = 1.70116 loss)
I1027 15:37:24.121824  9023 sgd_solver.cpp:105] Iteration 74840, lr = 0.00498433
I1027 15:37:56.315351  9023 solver.cpp:222] Iteration 74880 (1.24253 iter/s, 32.1923s/40 iters), loss = 1.47584
I1027 15:37:56.315532  9023 solver.cpp:241]     Train net output #0: loss = 1.47584 (* 1 = 1.47584 loss)
I1027 15:37:56.315551  9023 sgd_solver.cpp:105] Iteration 74880, lr = 0.00498181
I1027 15:38:27.385712  9023 solver.cpp:222] Iteration 74920 (1.28746 iter/s, 31.069s/40 iters), loss = 1.42858
I1027 15:38:27.385980  9023 solver.cpp:241]     Train net output #0: loss = 1.42858 (* 1 = 1.42858 loss)
I1027 15:38:27.385998  9023 sgd_solver.cpp:105] Iteration 74920, lr = 0.0049793
I1027 15:38:59.217176  9023 solver.cpp:222] Iteration 74960 (1.25668 iter/s, 31.83s/40 iters), loss = 1.38963
I1027 15:38:59.217388  9023 solver.cpp:241]     Train net output #0: loss = 1.38963 (* 1 = 1.38963 loss)
I1027 15:38:59.217414  9023 sgd_solver.cpp:105] Iteration 74960, lr = 0.00497679
I1027 15:39:29.191229  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_75000.caffemodel
I1027 15:39:29.224138  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_75000.solverstate
I1027 15:39:29.241247  9023 solver.cpp:334] Iteration 75000, Testing net (#0)
I1027 15:40:01.503085  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 15:40:01.714273  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54164
I1027 15:40:01.714342  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78404
I1027 15:40:01.714357  9023 solver.cpp:401]     Test net output #2: loss = 2.06827 (* 1 = 2.06827 loss)
I1027 15:40:02.474822  9023 solver.cpp:222] Iteration 75000 (0.63236 iter/s, 63.2551s/40 iters), loss = 1.77451
I1027 15:40:02.474884  9023 solver.cpp:241]     Train net output #0: loss = 1.77451 (* 1 = 1.77451 loss)
I1027 15:40:02.474900  9023 sgd_solver.cpp:105] Iteration 75000, lr = 0.00497427
I1027 15:40:33.803128  9023 solver.cpp:222] Iteration 75040 (1.27685 iter/s, 31.3271s/40 iters), loss = 1.80883
I1027 15:40:33.803311  9023 solver.cpp:241]     Train net output #0: loss = 1.80883 (* 1 = 1.80883 loss)
I1027 15:40:33.803329  9023 sgd_solver.cpp:105] Iteration 75040, lr = 0.00497176
I1027 15:41:04.821331  9023 solver.cpp:222] Iteration 75080 (1.28962 iter/s, 31.0169s/40 iters), loss = 1.68716
I1027 15:41:04.821540  9023 solver.cpp:241]     Train net output #0: loss = 1.68716 (* 1 = 1.68716 loss)
I1027 15:41:04.821557  9023 sgd_solver.cpp:105] Iteration 75080, lr = 0.00496925
I1027 15:41:35.181864  9023 solver.cpp:222] Iteration 75120 (1.31756 iter/s, 30.3592s/40 iters), loss = 1.58455
I1027 15:41:35.182024  9023 solver.cpp:241]     Train net output #0: loss = 1.58455 (* 1 = 1.58455 loss)
I1027 15:41:35.182040  9023 sgd_solver.cpp:105] Iteration 75120, lr = 0.00496673
I1027 15:42:05.962291  9023 solver.cpp:222] Iteration 75160 (1.29958 iter/s, 30.7791s/40 iters), loss = 1.82936
I1027 15:42:05.962462  9023 solver.cpp:241]     Train net output #0: loss = 1.82936 (* 1 = 1.82936 loss)
I1027 15:42:05.962478  9023 sgd_solver.cpp:105] Iteration 75160, lr = 0.00496422
I1027 15:42:36.693243  9023 solver.cpp:222] Iteration 75200 (1.30168 iter/s, 30.7296s/40 iters), loss = 1.44107
I1027 15:42:36.693444  9023 solver.cpp:241]     Train net output #0: loss = 1.44107 (* 1 = 1.44107 loss)
I1027 15:42:36.693881  9023 sgd_solver.cpp:105] Iteration 75200, lr = 0.00496171
I1027 15:43:07.302901  9023 solver.cpp:222] Iteration 75240 (1.30683 iter/s, 30.6083s/40 iters), loss = 1.45349
I1027 15:43:07.303052  9023 solver.cpp:241]     Train net output #0: loss = 1.45349 (* 1 = 1.45349 loss)
I1027 15:43:07.303067  9023 sgd_solver.cpp:105] Iteration 75240, lr = 0.0049592
I1027 15:43:37.863973  9023 solver.cpp:222] Iteration 75280 (1.30891 iter/s, 30.5598s/40 iters), loss = 1.81225
I1027 15:43:37.864127  9023 solver.cpp:241]     Train net output #0: loss = 1.81225 (* 1 = 1.81225 loss)
I1027 15:43:37.864143  9023 sgd_solver.cpp:105] Iteration 75280, lr = 0.00495668
I1027 15:44:08.099553  9023 solver.cpp:222] Iteration 75320 (1.323 iter/s, 30.2343s/40 iters), loss = 1.52463
I1027 15:44:08.099747  9023 solver.cpp:241]     Train net output #0: loss = 1.52463 (* 1 = 1.52463 loss)
I1027 15:44:08.099764  9023 sgd_solver.cpp:105] Iteration 75320, lr = 0.00495417
I1027 15:44:39.517323  9023 solver.cpp:222] Iteration 75360 (1.27322 iter/s, 31.4164s/40 iters), loss = 1.71629
I1027 15:44:39.517614  9023 solver.cpp:241]     Train net output #0: loss = 1.71629 (* 1 = 1.71629 loss)
I1027 15:44:39.517632  9023 sgd_solver.cpp:105] Iteration 75360, lr = 0.00495166
I1027 15:45:09.970721  9023 solver.cpp:222] Iteration 75400 (1.31354 iter/s, 30.452s/40 iters), loss = 1.87035
I1027 15:45:09.970854  9023 solver.cpp:241]     Train net output #0: loss = 1.87035 (* 1 = 1.87035 loss)
I1027 15:45:09.970868  9023 sgd_solver.cpp:105] Iteration 75400, lr = 0.00494915
I1027 15:45:40.464229  9023 solver.cpp:222] Iteration 75440 (1.31181 iter/s, 30.4922s/40 iters), loss = 1.84455
I1027 15:45:40.464385  9023 solver.cpp:241]     Train net output #0: loss = 1.84455 (* 1 = 1.84455 loss)
I1027 15:45:40.464401  9023 sgd_solver.cpp:105] Iteration 75440, lr = 0.00494664
I1027 15:46:12.091365  9023 solver.cpp:222] Iteration 75480 (1.26479 iter/s, 31.6258s/40 iters), loss = 1.58986
I1027 15:46:12.091557  9023 solver.cpp:241]     Train net output #0: loss = 1.58986 (* 1 = 1.58986 loss)
I1027 15:46:12.091575  9023 sgd_solver.cpp:105] Iteration 75480, lr = 0.00494413
I1027 15:46:26.709303  9023 solver.cpp:334] Iteration 75500, Testing net (#0)
I1027 15:46:58.102772  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55364
I1027 15:46:58.102942  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78796
I1027 15:46:58.102959  9023 solver.cpp:401]     Test net output #2: loss = 1.9944 (* 1 = 1.9944 loss)
I1027 15:47:14.179222  9023 solver.cpp:222] Iteration 75520 (0.644275 iter/s, 62.0853s/40 iters), loss = 1.62063
I1027 15:47:14.179292  9023 solver.cpp:241]     Train net output #0: loss = 1.62063 (* 1 = 1.62063 loss)
I1027 15:47:14.179313  9023 sgd_solver.cpp:105] Iteration 75520, lr = 0.00494162
I1027 15:47:44.651626  9023 solver.cpp:222] Iteration 75560 (1.31272 iter/s, 30.4712s/40 iters), loss = 1.60767
I1027 15:47:44.651785  9023 solver.cpp:241]     Train net output #0: loss = 1.60767 (* 1 = 1.60767 loss)
I1027 15:47:44.651801  9023 sgd_solver.cpp:105] Iteration 75560, lr = 0.00493911
I1027 15:48:15.409342  9023 solver.cpp:222] Iteration 75600 (1.30054 iter/s, 30.7564s/40 iters), loss = 1.87503
I1027 15:48:15.409498  9023 solver.cpp:241]     Train net output #0: loss = 1.87503 (* 1 = 1.87503 loss)
I1027 15:48:15.409514  9023 sgd_solver.cpp:105] Iteration 75600, lr = 0.0049366
I1027 15:48:46.151917  9023 solver.cpp:222] Iteration 75640 (1.30118 iter/s, 30.7413s/40 iters), loss = 1.63176
I1027 15:48:46.152055  9023 solver.cpp:241]     Train net output #0: loss = 1.63176 (* 1 = 1.63176 loss)
I1027 15:48:46.152070  9023 sgd_solver.cpp:105] Iteration 75640, lr = 0.00493409
I1027 15:49:16.933468  9023 solver.cpp:222] Iteration 75680 (1.29953 iter/s, 30.7802s/40 iters), loss = 1.78039
I1027 15:49:16.933629  9023 solver.cpp:241]     Train net output #0: loss = 1.78039 (* 1 = 1.78039 loss)
I1027 15:49:16.933645  9023 sgd_solver.cpp:105] Iteration 75680, lr = 0.00493158
I1027 15:49:48.489466  9023 solver.cpp:222] Iteration 75720 (1.26764 iter/s, 31.5546s/40 iters), loss = 1.49001
I1027 15:49:48.489660  9023 solver.cpp:241]     Train net output #0: loss = 1.49001 (* 1 = 1.49001 loss)
I1027 15:49:48.489677  9023 sgd_solver.cpp:105] Iteration 75720, lr = 0.00492907
I1027 15:50:19.438210  9023 solver.cpp:222] Iteration 75760 (1.29252 iter/s, 30.9474s/40 iters), loss = 1.77056
I1027 15:50:19.438391  9023 solver.cpp:241]     Train net output #0: loss = 1.77056 (* 1 = 1.77056 loss)
I1027 15:50:19.438407  9023 sgd_solver.cpp:105] Iteration 75760, lr = 0.00492656
I1027 15:50:50.526276  9023 solver.cpp:222] Iteration 75800 (1.28672 iter/s, 31.0867s/40 iters), loss = 1.76837
I1027 15:50:50.526468  9023 solver.cpp:241]     Train net output #0: loss = 1.76837 (* 1 = 1.76837 loss)
I1027 15:50:50.526484  9023 sgd_solver.cpp:105] Iteration 75800, lr = 0.00492405
I1027 15:51:22.354246  9023 solver.cpp:222] Iteration 75840 (1.25681 iter/s, 31.8266s/40 iters), loss = 1.88892
I1027 15:51:22.354511  9023 solver.cpp:241]     Train net output #0: loss = 1.88892 (* 1 = 1.88892 loss)
I1027 15:51:22.354563  9023 sgd_solver.cpp:105] Iteration 75840, lr = 0.00492154
I1027 15:51:54.051056  9023 solver.cpp:222] Iteration 75880 (1.26201 iter/s, 31.6953s/40 iters), loss = 1.8754
I1027 15:51:54.051288  9023 solver.cpp:241]     Train net output #0: loss = 1.8754 (* 1 = 1.8754 loss)
I1027 15:51:54.051311  9023 sgd_solver.cpp:105] Iteration 75880, lr = 0.00491903
I1027 15:52:24.608197  9023 solver.cpp:222] Iteration 75920 (1.30908 iter/s, 30.5558s/40 iters), loss = 1.99292
I1027 15:52:24.608388  9023 solver.cpp:241]     Train net output #0: loss = 1.99292 (* 1 = 1.99292 loss)
I1027 15:52:24.608403  9023 sgd_solver.cpp:105] Iteration 75920, lr = 0.00491652
I1027 15:52:55.371464  9023 solver.cpp:222] Iteration 75960 (1.30031 iter/s, 30.7619s/40 iters), loss = 1.65727
I1027 15:52:55.371615  9023 solver.cpp:241]     Train net output #0: loss = 1.65727 (* 1 = 1.65727 loss)
I1027 15:52:55.371630  9023 sgd_solver.cpp:105] Iteration 75960, lr = 0.00491401
I1027 15:53:25.603925  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_76000.caffemodel
I1027 15:53:25.634914  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_76000.solverstate
I1027 15:53:25.651330  9023 solver.cpp:334] Iteration 76000, Testing net (#0)
I1027 15:53:56.924103  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 15:53:57.135248  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54772
I1027 15:53:57.135313  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78672
I1027 15:53:57.135326  9023 solver.cpp:401]     Test net output #2: loss = 2.01981 (* 1 = 2.01981 loss)
I1027 15:53:57.905061  9023 solver.cpp:222] Iteration 76000 (0.639682 iter/s, 62.5311s/40 iters), loss = 1.49754
I1027 15:53:57.905102  9023 solver.cpp:241]     Train net output #0: loss = 1.49754 (* 1 = 1.49754 loss)
I1027 15:53:57.905115  9023 sgd_solver.cpp:105] Iteration 76000, lr = 0.00491151
I1027 15:54:28.758488  9023 solver.cpp:222] Iteration 76040 (1.2965 iter/s, 30.8522s/40 iters), loss = 1.34429
I1027 15:54:28.758630  9023 solver.cpp:241]     Train net output #0: loss = 1.34429 (* 1 = 1.34429 loss)
I1027 15:54:28.758646  9023 sgd_solver.cpp:105] Iteration 76040, lr = 0.004909
I1027 15:54:59.607344  9023 solver.cpp:222] Iteration 76080 (1.2967 iter/s, 30.8476s/40 iters), loss = 1.59533
I1027 15:54:59.607445  9023 solver.cpp:241]     Train net output #0: loss = 1.59533 (* 1 = 1.59533 loss)
I1027 15:54:59.607460  9023 sgd_solver.cpp:105] Iteration 76080, lr = 0.00490649
I1027 15:55:30.308239  9023 solver.cpp:222] Iteration 76120 (1.30295 iter/s, 30.6996s/40 iters), loss = 1.77724
I1027 15:55:30.308369  9023 solver.cpp:241]     Train net output #0: loss = 1.77724 (* 1 = 1.77724 loss)
I1027 15:55:30.308385  9023 sgd_solver.cpp:105] Iteration 76120, lr = 0.00490398
I1027 15:56:00.950247  9023 solver.cpp:222] Iteration 76160 (1.30545 iter/s, 30.6407s/40 iters), loss = 1.50619
I1027 15:56:00.950389  9023 solver.cpp:241]     Train net output #0: loss = 1.50619 (* 1 = 1.50619 loss)
I1027 15:56:00.950405  9023 sgd_solver.cpp:105] Iteration 76160, lr = 0.00490148
I1027 15:56:31.533156  9023 solver.cpp:222] Iteration 76200 (1.30798 iter/s, 30.5816s/40 iters), loss = 1.93939
I1027 15:56:31.533303  9023 solver.cpp:241]     Train net output #0: loss = 1.93939 (* 1 = 1.93939 loss)
I1027 15:56:31.533320  9023 sgd_solver.cpp:105] Iteration 76200, lr = 0.00489897
I1027 15:57:02.049335  9023 solver.cpp:222] Iteration 76240 (1.31084 iter/s, 30.5149s/40 iters), loss = 1.93956
I1027 15:57:02.049432  9023 solver.cpp:241]     Train net output #0: loss = 1.93956 (* 1 = 1.93956 loss)
I1027 15:57:02.049448  9023 sgd_solver.cpp:105] Iteration 76240, lr = 0.00489646
I1027 15:57:32.640022  9023 solver.cpp:222] Iteration 76280 (1.30764 iter/s, 30.5894s/40 iters), loss = 1.28878
I1027 15:57:32.640151  9023 solver.cpp:241]     Train net output #0: loss = 1.28878 (* 1 = 1.28878 loss)
I1027 15:57:32.640167  9023 sgd_solver.cpp:105] Iteration 76280, lr = 0.00489396
I1027 15:58:03.274732  9023 solver.cpp:222] Iteration 76320 (1.30576 iter/s, 30.6334s/40 iters), loss = 1.73909
I1027 15:58:03.274924  9023 solver.cpp:241]     Train net output #0: loss = 1.73909 (* 1 = 1.73909 loss)
I1027 15:58:03.274940  9023 sgd_solver.cpp:105] Iteration 76320, lr = 0.00489145
I1027 15:58:36.276695  9023 solver.cpp:222] Iteration 76360 (1.2121 iter/s, 33.0005s/40 iters), loss = 1.62417
I1027 15:58:36.276882  9023 solver.cpp:241]     Train net output #0: loss = 1.62417 (* 1 = 1.62417 loss)
I1027 15:58:36.276899  9023 sgd_solver.cpp:105] Iteration 76360, lr = 0.00488894
I1027 15:59:07.599000  9023 solver.cpp:222] Iteration 76400 (1.2771 iter/s, 31.3209s/40 iters), loss = 1.55604
I1027 15:59:07.599200  9023 solver.cpp:241]     Train net output #0: loss = 1.55604 (* 1 = 1.55604 loss)
I1027 15:59:07.599220  9023 sgd_solver.cpp:105] Iteration 76400, lr = 0.00488644
I1027 15:59:38.762456  9023 solver.cpp:222] Iteration 76440 (1.28361 iter/s, 31.1621s/40 iters), loss = 1.78407
I1027 15:59:38.762625  9023 solver.cpp:241]     Train net output #0: loss = 1.78407 (* 1 = 1.78407 loss)
I1027 15:59:38.762642  9023 sgd_solver.cpp:105] Iteration 76440, lr = 0.00488393
I1027 16:00:09.394477  9023 solver.cpp:222] Iteration 76480 (1.30588 iter/s, 30.6307s/40 iters), loss = 1.58869
I1027 16:00:09.394661  9023 solver.cpp:241]     Train net output #0: loss = 1.58869 (* 1 = 1.58869 loss)
I1027 16:00:09.394678  9023 sgd_solver.cpp:105] Iteration 76480, lr = 0.00488143
I1027 16:00:23.892041  9023 solver.cpp:334] Iteration 76500, Testing net (#0)
I1027 16:00:55.265421  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54676
I1027 16:00:55.265604  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78176
I1027 16:00:55.265619  9023 solver.cpp:401]     Test net output #2: loss = 2.02876 (* 1 = 2.02876 loss)
I1027 16:01:11.361413  9023 solver.cpp:222] Iteration 76520 (0.645532 iter/s, 61.9644s/40 iters), loss = 1.70321
I1027 16:01:11.361484  9023 solver.cpp:241]     Train net output #0: loss = 1.70321 (* 1 = 1.70321 loss)
I1027 16:01:11.361498  9023 sgd_solver.cpp:105] Iteration 76520, lr = 0.00487892
I1027 16:01:41.954270  9023 solver.cpp:222] Iteration 76560 (1.30755 iter/s, 30.5916s/40 iters), loss = 1.67087
I1027 16:01:41.954463  9023 solver.cpp:241]     Train net output #0: loss = 1.67087 (* 1 = 1.67087 loss)
I1027 16:01:41.954479  9023 sgd_solver.cpp:105] Iteration 76560, lr = 0.00487642
I1027 16:02:12.357411  9023 solver.cpp:222] Iteration 76600 (1.31571 iter/s, 30.4018s/40 iters), loss = 1.91081
I1027 16:02:12.357574  9023 solver.cpp:241]     Train net output #0: loss = 1.91081 (* 1 = 1.91081 loss)
I1027 16:02:12.357590  9023 sgd_solver.cpp:105] Iteration 76600, lr = 0.00487391
I1027 16:02:43.166643  9023 solver.cpp:222] Iteration 76640 (1.29837 iter/s, 30.8079s/40 iters), loss = 1.72151
I1027 16:02:43.166800  9023 solver.cpp:241]     Train net output #0: loss = 1.72151 (* 1 = 1.72151 loss)
I1027 16:02:43.166816  9023 sgd_solver.cpp:105] Iteration 76640, lr = 0.00487141
I1027 16:03:13.854995  9023 solver.cpp:222] Iteration 76680 (1.30348 iter/s, 30.687s/40 iters), loss = 1.59765
I1027 16:03:13.855125  9023 solver.cpp:241]     Train net output #0: loss = 1.59765 (* 1 = 1.59765 loss)
I1027 16:03:13.855141  9023 sgd_solver.cpp:105] Iteration 76680, lr = 0.0048689
I1027 16:03:44.377610  9023 solver.cpp:222] Iteration 76720 (1.31056 iter/s, 30.5213s/40 iters), loss = 1.83873
I1027 16:03:44.377758  9023 solver.cpp:241]     Train net output #0: loss = 1.83873 (* 1 = 1.83873 loss)
I1027 16:03:44.377773  9023 sgd_solver.cpp:105] Iteration 76720, lr = 0.0048664
I1027 16:04:14.973014  9023 solver.cpp:222] Iteration 76760 (1.30744 iter/s, 30.5941s/40 iters), loss = 1.60707
I1027 16:04:14.973155  9023 solver.cpp:241]     Train net output #0: loss = 1.60707 (* 1 = 1.60707 loss)
I1027 16:04:14.973170  9023 sgd_solver.cpp:105] Iteration 76760, lr = 0.00486389
I1027 16:04:45.529752  9023 solver.cpp:222] Iteration 76800 (1.3091 iter/s, 30.5554s/40 iters), loss = 1.57662
I1027 16:04:45.529902  9023 solver.cpp:241]     Train net output #0: loss = 1.57662 (* 1 = 1.57662 loss)
I1027 16:04:45.529939  9023 sgd_solver.cpp:105] Iteration 76800, lr = 0.00486139
I1027 16:05:16.105082  9023 solver.cpp:222] Iteration 76840 (1.3083 iter/s, 30.574s/40 iters), loss = 1.91387
I1027 16:05:16.105267  9023 solver.cpp:241]     Train net output #0: loss = 1.91387 (* 1 = 1.91387 loss)
I1027 16:05:16.105284  9023 sgd_solver.cpp:105] Iteration 76840, lr = 0.00485888
I1027 16:05:46.651183  9023 solver.cpp:222] Iteration 76880 (1.30955 iter/s, 30.5448s/40 iters), loss = 1.59241
I1027 16:05:46.651399  9023 solver.cpp:241]     Train net output #0: loss = 1.59241 (* 1 = 1.59241 loss)
I1027 16:05:46.651417  9023 sgd_solver.cpp:105] Iteration 76880, lr = 0.00485638
I1027 16:06:17.340168  9023 solver.cpp:222] Iteration 76920 (1.30346 iter/s, 30.6876s/40 iters), loss = 1.85748
I1027 16:06:17.340370  9023 solver.cpp:241]     Train net output #0: loss = 1.85748 (* 1 = 1.85748 loss)
I1027 16:06:17.340387  9023 sgd_solver.cpp:105] Iteration 76920, lr = 0.00485388
I1027 16:06:48.350951  9023 solver.cpp:222] Iteration 76960 (1.28993 iter/s, 31.0094s/40 iters), loss = 1.59181
I1027 16:06:48.351127  9023 solver.cpp:241]     Train net output #0: loss = 1.59181 (* 1 = 1.59181 loss)
I1027 16:06:48.351143  9023 sgd_solver.cpp:105] Iteration 76960, lr = 0.00485138
I1027 16:07:18.541559  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_77000.caffemodel
I1027 16:07:18.595194  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_77000.solverstate
I1027 16:07:18.613270  9023 solver.cpp:334] Iteration 77000, Testing net (#0)
I1027 16:07:50.063763  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 16:07:50.274333  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5468
I1027 16:07:50.274394  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79056
I1027 16:07:50.274408  9023 solver.cpp:401]     Test net output #2: loss = 1.97547 (* 1 = 1.97547 loss)
I1027 16:07:51.048982  9023 solver.cpp:222] Iteration 77000 (0.638004 iter/s, 62.6955s/40 iters), loss = 1.88962
I1027 16:07:51.049046  9023 solver.cpp:241]     Train net output #0: loss = 1.88962 (* 1 = 1.88962 loss)
I1027 16:07:51.049062  9023 sgd_solver.cpp:105] Iteration 77000, lr = 0.00484887
I1027 16:07:56.541312  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1027 16:08:22.234388  9023 solver.cpp:222] Iteration 77040 (1.2827 iter/s, 31.1842s/40 iters), loss = 1.5776
I1027 16:08:22.234577  9023 solver.cpp:241]     Train net output #0: loss = 1.5776 (* 1 = 1.5776 loss)
I1027 16:08:22.234593  9023 sgd_solver.cpp:105] Iteration 77040, lr = 0.00484637
I1027 16:08:53.495971  9023 solver.cpp:222] Iteration 77080 (1.27958 iter/s, 31.2602s/40 iters), loss = 1.97033
I1027 16:08:53.496152  9023 solver.cpp:241]     Train net output #0: loss = 1.97033 (* 1 = 1.97033 loss)
I1027 16:08:53.496168  9023 sgd_solver.cpp:105] Iteration 77080, lr = 0.00484387
I1027 16:09:25.265261  9023 solver.cpp:222] Iteration 77120 (1.25913 iter/s, 31.7679s/40 iters), loss = 1.61519
I1027 16:09:25.265527  9023 solver.cpp:241]     Train net output #0: loss = 1.61519 (* 1 = 1.61519 loss)
I1027 16:09:25.265549  9023 sgd_solver.cpp:105] Iteration 77120, lr = 0.00484137
I1027 16:09:58.120502  9023 solver.cpp:222] Iteration 77160 (1.21752 iter/s, 32.8537s/40 iters), loss = 1.38143
I1027 16:09:58.120689  9023 solver.cpp:241]     Train net output #0: loss = 1.38143 (* 1 = 1.38143 loss)
I1027 16:09:58.120705  9023 sgd_solver.cpp:105] Iteration 77160, lr = 0.00483886
I1027 16:10:39.249917  9023 solver.cpp:222] Iteration 77200 (0.972581 iter/s, 41.1277s/40 iters), loss = 1.7631
I1027 16:10:39.250165  9023 solver.cpp:241]     Train net output #0: loss = 1.7631 (* 1 = 1.7631 loss)
I1027 16:10:39.250190  9023 sgd_solver.cpp:105] Iteration 77200, lr = 0.00483636
I1027 16:11:11.553513  9023 solver.cpp:222] Iteration 77240 (1.23831 iter/s, 32.3021s/40 iters), loss = 1.78457
I1027 16:11:11.553730  9023 solver.cpp:241]     Train net output #0: loss = 1.78457 (* 1 = 1.78457 loss)
I1027 16:11:11.553768  9023 sgd_solver.cpp:105] Iteration 77240, lr = 0.00483386
I1027 16:11:43.936264  9023 solver.cpp:222] Iteration 77280 (1.23528 iter/s, 32.3813s/40 iters), loss = 1.57754
I1027 16:11:43.936480  9023 solver.cpp:241]     Train net output #0: loss = 1.57754 (* 1 = 1.57754 loss)
I1027 16:11:43.936496  9023 sgd_solver.cpp:105] Iteration 77280, lr = 0.00483136
I1027 16:12:15.084522  9023 solver.cpp:222] Iteration 77320 (1.28424 iter/s, 31.1469s/40 iters), loss = 1.69907
I1027 16:12:15.084702  9023 solver.cpp:241]     Train net output #0: loss = 1.69907 (* 1 = 1.69907 loss)
I1027 16:12:15.084719  9023 sgd_solver.cpp:105] Iteration 77320, lr = 0.00482886
I1027 16:12:46.200410  9023 solver.cpp:222] Iteration 77360 (1.28557 iter/s, 31.1145s/40 iters), loss = 1.81694
I1027 16:12:46.200590  9023 solver.cpp:241]     Train net output #0: loss = 1.81694 (* 1 = 1.81694 loss)
I1027 16:12:46.200606  9023 sgd_solver.cpp:105] Iteration 77360, lr = 0.00482636
I1027 16:13:17.221339  9023 solver.cpp:222] Iteration 77400 (1.28951 iter/s, 31.0196s/40 iters), loss = 1.432
I1027 16:13:17.221515  9023 solver.cpp:241]     Train net output #0: loss = 1.432 (* 1 = 1.432 loss)
I1027 16:13:17.221531  9023 sgd_solver.cpp:105] Iteration 77400, lr = 0.00482386
I1027 16:13:47.887918  9023 solver.cpp:222] Iteration 77440 (1.30441 iter/s, 30.6652s/40 iters), loss = 2.03747
I1027 16:13:47.888098  9023 solver.cpp:241]     Train net output #0: loss = 2.03747 (* 1 = 2.03747 loss)
I1027 16:13:47.888113  9023 sgd_solver.cpp:105] Iteration 77440, lr = 0.00482136
I1027 16:14:18.634142  9023 solver.cpp:222] Iteration 77480 (1.30103 iter/s, 30.7449s/40 iters), loss = 1.67739
I1027 16:14:18.634332  9023 solver.cpp:241]     Train net output #0: loss = 1.67739 (* 1 = 1.67739 loss)
I1027 16:14:18.634351  9023 sgd_solver.cpp:105] Iteration 77480, lr = 0.00481886
I1027 16:14:34.725924  9023 solver.cpp:334] Iteration 77500, Testing net (#0)
I1027 16:15:06.018232  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54588
I1027 16:15:06.018436  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78544
I1027 16:15:06.018452  9023 solver.cpp:401]     Test net output #2: loss = 1.99523 (* 1 = 1.99523 loss)
I1027 16:15:22.547276  9023 solver.cpp:222] Iteration 77520 (0.625875 iter/s, 63.9105s/40 iters), loss = 1.62732
I1027 16:15:22.547359  9023 solver.cpp:241]     Train net output #0: loss = 1.62732 (* 1 = 1.62732 loss)
I1027 16:15:22.547375  9023 sgd_solver.cpp:105] Iteration 77520, lr = 0.00481636
I1027 16:15:53.230518  9023 solver.cpp:222] Iteration 77560 (1.3037 iter/s, 30.682s/40 iters), loss = 1.53476
I1027 16:15:53.230705  9023 solver.cpp:241]     Train net output #0: loss = 1.53476 (* 1 = 1.53476 loss)
I1027 16:15:53.230720  9023 sgd_solver.cpp:105] Iteration 77560, lr = 0.00481386
I1027 16:16:24.529660  9023 solver.cpp:222] Iteration 77600 (1.27805 iter/s, 31.2977s/40 iters), loss = 1.76654
I1027 16:16:24.529929  9023 solver.cpp:241]     Train net output #0: loss = 1.76654 (* 1 = 1.76654 loss)
I1027 16:16:24.529954  9023 sgd_solver.cpp:105] Iteration 77600, lr = 0.00481136
I1027 16:16:56.220019  9023 solver.cpp:222] Iteration 77640 (1.26227 iter/s, 31.6889s/40 iters), loss = 1.5931
I1027 16:16:56.220216  9023 solver.cpp:241]     Train net output #0: loss = 1.5931 (* 1 = 1.5931 loss)
I1027 16:16:56.220232  9023 sgd_solver.cpp:105] Iteration 77640, lr = 0.00480886
I1027 16:17:27.540900  9023 solver.cpp:222] Iteration 77680 (1.27716 iter/s, 31.3195s/40 iters), loss = 1.65067
I1027 16:17:27.541105  9023 solver.cpp:241]     Train net output #0: loss = 1.65067 (* 1 = 1.65067 loss)
I1027 16:17:27.541122  9023 sgd_solver.cpp:105] Iteration 77680, lr = 0.00480636
I1027 16:17:58.154067  9023 solver.cpp:222] Iteration 77720 (1.30669 iter/s, 30.6118s/40 iters), loss = 1.58312
I1027 16:17:58.154235  9023 solver.cpp:241]     Train net output #0: loss = 1.58312 (* 1 = 1.58312 loss)
I1027 16:17:58.154253  9023 sgd_solver.cpp:105] Iteration 77720, lr = 0.00480386
I1027 16:18:28.751898  9023 solver.cpp:222] Iteration 77760 (1.30734 iter/s, 30.5965s/40 iters), loss = 1.9422
I1027 16:18:28.752109  9023 solver.cpp:241]     Train net output #0: loss = 1.9422 (* 1 = 1.9422 loss)
I1027 16:18:28.752125  9023 sgd_solver.cpp:105] Iteration 77760, lr = 0.00480136
I1027 16:18:59.433147  9023 solver.cpp:222] Iteration 77800 (1.30379 iter/s, 30.6799s/40 iters), loss = 1.60552
I1027 16:18:59.433331  9023 solver.cpp:241]     Train net output #0: loss = 1.60552 (* 1 = 1.60552 loss)
I1027 16:18:59.433347  9023 sgd_solver.cpp:105] Iteration 77800, lr = 0.00479886
I1027 16:19:30.061800  9023 solver.cpp:222] Iteration 77840 (1.30602 iter/s, 30.6273s/40 iters), loss = 1.775
I1027 16:19:30.061935  9023 solver.cpp:241]     Train net output #0: loss = 1.775 (* 1 = 1.775 loss)
I1027 16:19:30.061950  9023 sgd_solver.cpp:105] Iteration 77840, lr = 0.00479637
I1027 16:20:04.291941  9023 solver.cpp:222] Iteration 77880 (1.16861 iter/s, 34.2287s/40 iters), loss = 1.48729
I1027 16:20:04.292146  9023 solver.cpp:241]     Train net output #0: loss = 1.48729 (* 1 = 1.48729 loss)
I1027 16:20:04.292168  9023 sgd_solver.cpp:105] Iteration 77880, lr = 0.00479387
I1027 16:20:37.969880  9023 solver.cpp:222] Iteration 77920 (1.18777 iter/s, 33.6765s/40 iters), loss = 1.48042
I1027 16:20:37.970125  9023 solver.cpp:241]     Train net output #0: loss = 1.48042 (* 1 = 1.48042 loss)
I1027 16:20:37.970149  9023 sgd_solver.cpp:105] Iteration 77920, lr = 0.00479137
I1027 16:21:08.596880  9023 solver.cpp:222] Iteration 77960 (1.3061 iter/s, 30.6256s/40 iters), loss = 1.46369
I1027 16:21:08.597065  9023 solver.cpp:241]     Train net output #0: loss = 1.46369 (* 1 = 1.46369 loss)
I1027 16:21:08.597082  9023 sgd_solver.cpp:105] Iteration 77960, lr = 0.00478887
I1027 16:21:38.518638  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_78000.caffemodel
I1027 16:21:38.551604  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_78000.solverstate
I1027 16:21:38.568241  9023 solver.cpp:334] Iteration 78000, Testing net (#0)
I1027 16:22:09.609213  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 16:22:09.821688  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55004
I1027 16:22:09.821749  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.787999
I1027 16:22:09.821764  9023 solver.cpp:401]     Test net output #2: loss = 2.01137 (* 1 = 2.01137 loss)
I1027 16:22:10.595284  9023 solver.cpp:222] Iteration 78000 (0.645204 iter/s, 61.9959s/40 iters), loss = 1.48295
I1027 16:22:10.595355  9023 solver.cpp:241]     Train net output #0: loss = 1.48295 (* 1 = 1.48295 loss)
I1027 16:22:10.595371  9023 sgd_solver.cpp:105] Iteration 78000, lr = 0.00478637
I1027 16:22:41.265502  9023 solver.cpp:222] Iteration 78040 (1.30425 iter/s, 30.669s/40 iters), loss = 1.71789
I1027 16:22:41.265683  9023 solver.cpp:241]     Train net output #0: loss = 1.71789 (* 1 = 1.71789 loss)
I1027 16:22:41.265699  9023 sgd_solver.cpp:105] Iteration 78040, lr = 0.00478388
I1027 16:23:11.830528  9023 solver.cpp:222] Iteration 78080 (1.30874 iter/s, 30.5637s/40 iters), loss = 1.59827
I1027 16:23:11.830703  9023 solver.cpp:241]     Train net output #0: loss = 1.59827 (* 1 = 1.59827 loss)
I1027 16:23:11.830718  9023 sgd_solver.cpp:105] Iteration 78080, lr = 0.00478138
I1027 16:23:42.464828  9023 solver.cpp:222] Iteration 78120 (1.30578 iter/s, 30.633s/40 iters), loss = 1.66564
I1027 16:23:42.465000  9023 solver.cpp:241]     Train net output #0: loss = 1.66564 (* 1 = 1.66564 loss)
I1027 16:23:42.465016  9023 sgd_solver.cpp:105] Iteration 78120, lr = 0.00477888
I1027 16:24:13.179250  9023 solver.cpp:222] Iteration 78160 (1.30238 iter/s, 30.7131s/40 iters), loss = 1.97325
I1027 16:24:13.179443  9023 solver.cpp:241]     Train net output #0: loss = 1.97325 (* 1 = 1.97325 loss)
I1027 16:24:13.179460  9023 sgd_solver.cpp:105] Iteration 78160, lr = 0.00477639
I1027 16:24:43.793948  9023 solver.cpp:222] Iteration 78200 (1.30662 iter/s, 30.6133s/40 iters), loss = 1.61933
I1027 16:24:43.794225  9023 solver.cpp:241]     Train net output #0: loss = 1.61933 (* 1 = 1.61933 loss)
I1027 16:24:43.794260  9023 sgd_solver.cpp:105] Iteration 78200, lr = 0.00477389
I1027 16:25:14.413583  9023 solver.cpp:222] Iteration 78240 (1.30641 iter/s, 30.6182s/40 iters), loss = 1.51708
I1027 16:25:14.413765  9023 solver.cpp:241]     Train net output #0: loss = 1.51708 (* 1 = 1.51708 loss)
I1027 16:25:14.413782  9023 sgd_solver.cpp:105] Iteration 78240, lr = 0.00477139
I1027 16:25:45.205103  9023 solver.cpp:222] Iteration 78280 (1.29912 iter/s, 30.7902s/40 iters), loss = 1.78173
I1027 16:25:45.205299  9023 solver.cpp:241]     Train net output #0: loss = 1.78173 (* 1 = 1.78173 loss)
I1027 16:25:45.205319  9023 sgd_solver.cpp:105] Iteration 78280, lr = 0.0047689
I1027 16:26:16.140516  9023 solver.cpp:222] Iteration 78320 (1.29307 iter/s, 30.934s/40 iters), loss = 1.62101
I1027 16:26:16.140717  9023 solver.cpp:241]     Train net output #0: loss = 1.62101 (* 1 = 1.62101 loss)
I1027 16:26:16.140733  9023 sgd_solver.cpp:105] Iteration 78320, lr = 0.0047664
I1027 16:26:46.823338  9023 solver.cpp:222] Iteration 78360 (1.30372 iter/s, 30.6815s/40 iters), loss = 1.94511
I1027 16:26:46.823537  9023 solver.cpp:241]     Train net output #0: loss = 1.94511 (* 1 = 1.94511 loss)
I1027 16:26:46.823555  9023 sgd_solver.cpp:105] Iteration 78360, lr = 0.00476391
I1027 16:27:17.494200  9023 solver.cpp:222] Iteration 78400 (1.30423 iter/s, 30.6695s/40 iters), loss = 1.35213
I1027 16:27:17.494371  9023 solver.cpp:241]     Train net output #0: loss = 1.35213 (* 1 = 1.35213 loss)
I1027 16:27:17.494387  9023 sgd_solver.cpp:105] Iteration 78400, lr = 0.00476141
I1027 16:27:47.994766  9023 solver.cpp:222] Iteration 78440 (1.31151 iter/s, 30.4992s/40 iters), loss = 2.0602
I1027 16:27:47.994917  9023 solver.cpp:241]     Train net output #0: loss = 2.0602 (* 1 = 2.0602 loss)
I1027 16:27:47.994935  9023 sgd_solver.cpp:105] Iteration 78440, lr = 0.00475892
I1027 16:28:18.487346  9023 solver.cpp:222] Iteration 78480 (1.31185 iter/s, 30.4913s/40 iters), loss = 1.44292
I1027 16:28:18.487566  9023 solver.cpp:241]     Train net output #0: loss = 1.44292 (* 1 = 1.44292 loss)
I1027 16:28:18.487581  9023 sgd_solver.cpp:105] Iteration 78480, lr = 0.00475642
I1027 16:28:33.534073  9023 solver.cpp:334] Iteration 78500, Testing net (#0)
I1027 16:29:05.010658  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54976
I1027 16:29:05.010838  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78576
I1027 16:29:05.010852  9023 solver.cpp:401]     Test net output #2: loss = 1.9904 (* 1 = 1.9904 loss)
I1027 16:29:21.197844  9023 solver.cpp:222] Iteration 78520 (0.637878 iter/s, 62.7079s/40 iters), loss = 1.6017
I1027 16:29:21.197916  9023 solver.cpp:241]     Train net output #0: loss = 1.6017 (* 1 = 1.6017 loss)
I1027 16:29:21.197932  9023 sgd_solver.cpp:105] Iteration 78520, lr = 0.00475393
I1027 16:29:51.939990  9023 solver.cpp:222] Iteration 78560 (1.3012 iter/s, 30.7409s/40 iters), loss = 1.3637
I1027 16:29:51.940158  9023 solver.cpp:241]     Train net output #0: loss = 1.3637 (* 1 = 1.3637 loss)
I1027 16:29:51.940174  9023 sgd_solver.cpp:105] Iteration 78560, lr = 0.00475143
I1027 16:30:22.702193  9023 solver.cpp:222] Iteration 78600 (1.30035 iter/s, 30.7609s/40 iters), loss = 1.54319
I1027 16:30:22.702356  9023 solver.cpp:241]     Train net output #0: loss = 1.54319 (* 1 = 1.54319 loss)
I1027 16:30:22.702373  9023 sgd_solver.cpp:105] Iteration 78600, lr = 0.00474894
I1027 16:30:53.143018  9023 solver.cpp:222] Iteration 78640 (1.31408 iter/s, 30.4395s/40 iters), loss = 1.56729
I1027 16:30:53.143196  9023 solver.cpp:241]     Train net output #0: loss = 1.56729 (* 1 = 1.56729 loss)
I1027 16:30:53.143211  9023 sgd_solver.cpp:105] Iteration 78640, lr = 0.00474645
I1027 16:31:24.851588  9023 solver.cpp:222] Iteration 78680 (1.26154 iter/s, 31.7072s/40 iters), loss = 2.0826
I1027 16:31:24.851795  9023 solver.cpp:241]     Train net output #0: loss = 2.0826 (* 1 = 2.0826 loss)
I1027 16:31:24.851811  9023 sgd_solver.cpp:105] Iteration 78680, lr = 0.00474395
I1027 16:31:55.582404  9023 solver.cpp:222] Iteration 78720 (1.30168 iter/s, 30.7295s/40 iters), loss = 1.65861
I1027 16:31:55.582675  9023 solver.cpp:241]     Train net output #0: loss = 1.65861 (* 1 = 1.65861 loss)
I1027 16:31:55.582692  9023 sgd_solver.cpp:105] Iteration 78720, lr = 0.00474146
I1027 16:32:27.472702  9023 solver.cpp:222] Iteration 78760 (1.25436 iter/s, 31.8888s/40 iters), loss = 1.7563
I1027 16:32:27.472951  9023 solver.cpp:241]     Train net output #0: loss = 1.7563 (* 1 = 1.7563 loss)
I1027 16:32:27.472973  9023 sgd_solver.cpp:105] Iteration 78760, lr = 0.00473897
I1027 16:32:58.431629  9023 solver.cpp:222] Iteration 78800 (1.29209 iter/s, 30.9575s/40 iters), loss = 1.45061
I1027 16:32:58.431802  9023 solver.cpp:241]     Train net output #0: loss = 1.45061 (* 1 = 1.45061 loss)
I1027 16:32:58.431816  9023 sgd_solver.cpp:105] Iteration 78800, lr = 0.00473647
I1027 16:33:29.063760  9023 solver.cpp:222] Iteration 78840 (1.30588 iter/s, 30.6308s/40 iters), loss = 1.45911
I1027 16:33:29.063925  9023 solver.cpp:241]     Train net output #0: loss = 1.45911 (* 1 = 1.45911 loss)
I1027 16:33:29.063941  9023 sgd_solver.cpp:105] Iteration 78840, lr = 0.00473398
I1027 16:33:59.739738  9023 solver.cpp:222] Iteration 78880 (1.30401 iter/s, 30.6746s/40 iters), loss = 1.81499
I1027 16:33:59.739907  9023 solver.cpp:241]     Train net output #0: loss = 1.81499 (* 1 = 1.81499 loss)
I1027 16:33:59.739924  9023 sgd_solver.cpp:105] Iteration 78880, lr = 0.00473149
I1027 16:34:30.363849  9023 solver.cpp:222] Iteration 78920 (1.30622 iter/s, 30.6228s/40 iters), loss = 1.76421
I1027 16:34:30.364019  9023 solver.cpp:241]     Train net output #0: loss = 1.76421 (* 1 = 1.76421 loss)
I1027 16:34:30.364035  9023 sgd_solver.cpp:105] Iteration 78920, lr = 0.004729
I1027 16:35:00.981484  9023 solver.cpp:222] Iteration 78960 (1.30649 iter/s, 30.6163s/40 iters), loss = 1.64238
I1027 16:35:00.981638  9023 solver.cpp:241]     Train net output #0: loss = 1.64238 (* 1 = 1.64238 loss)
I1027 16:35:00.981655  9023 sgd_solver.cpp:105] Iteration 78960, lr = 0.0047265
I1027 16:35:30.793283  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_79000.caffemodel
I1027 16:35:30.825184  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_79000.solverstate
I1027 16:35:30.842231  9023 solver.cpp:334] Iteration 79000, Testing net (#0)
I1027 16:36:01.952869  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 16:36:02.161285  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54836
I1027 16:36:02.161356  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.788519
I1027 16:36:02.161370  9023 solver.cpp:401]     Test net output #2: loss = 2.02046 (* 1 = 2.02046 loss)
I1027 16:36:02.931478  9023 solver.cpp:222] Iteration 79000 (0.645708 iter/s, 61.9475s/40 iters), loss = 1.59229
I1027 16:36:02.931540  9023 solver.cpp:241]     Train net output #0: loss = 1.59229 (* 1 = 1.59229 loss)
I1027 16:36:02.931555  9023 sgd_solver.cpp:105] Iteration 79000, lr = 0.00472401
I1027 16:36:33.498483  9023 solver.cpp:222] Iteration 79040 (1.30865 iter/s, 30.5658s/40 iters), loss = 1.77339
I1027 16:36:33.498656  9023 solver.cpp:241]     Train net output #0: loss = 1.77339 (* 1 = 1.77339 loss)
I1027 16:36:33.498672  9023 sgd_solver.cpp:105] Iteration 79040, lr = 0.00472152
I1027 16:37:04.444049  9023 solver.cpp:222] Iteration 79080 (1.29265 iter/s, 30.9442s/40 iters), loss = 1.70222
I1027 16:37:04.444317  9023 solver.cpp:241]     Train net output #0: loss = 1.70222 (* 1 = 1.70222 loss)
I1027 16:37:04.444352  9023 sgd_solver.cpp:105] Iteration 79080, lr = 0.00471903
I1027 16:37:59.515794  9023 solver.cpp:222] Iteration 79120 (0.726356 iter/s, 55.0694s/40 iters), loss = 1.36324
I1027 16:37:59.516000  9023 solver.cpp:241]     Train net output #0: loss = 1.36324 (* 1 = 1.36324 loss)
I1027 16:37:59.516017  9023 sgd_solver.cpp:105] Iteration 79120, lr = 0.00471654
I1027 16:38:30.248414  9023 solver.cpp:222] Iteration 79160 (1.30161 iter/s, 30.7313s/40 iters), loss = 1.42795
I1027 16:38:30.248647  9023 solver.cpp:241]     Train net output #0: loss = 1.42795 (* 1 = 1.42795 loss)
I1027 16:38:30.248664  9023 sgd_solver.cpp:105] Iteration 79160, lr = 0.00471405
I1027 16:39:01.279266  9023 solver.cpp:222] Iteration 79200 (1.2891 iter/s, 31.0295s/40 iters), loss = 1.32637
I1027 16:39:01.279459  9023 solver.cpp:241]     Train net output #0: loss = 1.32637 (* 1 = 1.32637 loss)
I1027 16:39:01.279484  9023 sgd_solver.cpp:105] Iteration 79200, lr = 0.00471156
I1027 16:39:32.738868  9023 solver.cpp:222] Iteration 79240 (1.27153 iter/s, 31.4582s/40 iters), loss = 1.59246
I1027 16:39:32.739028  9023 solver.cpp:241]     Train net output #0: loss = 1.59246 (* 1 = 1.59246 loss)
I1027 16:39:32.739044  9023 sgd_solver.cpp:105] Iteration 79240, lr = 0.00470906
I1027 16:40:03.740105  9023 solver.cpp:222] Iteration 79280 (1.29033 iter/s, 30.9999s/40 iters), loss = 1.59085
I1027 16:40:03.740291  9023 solver.cpp:241]     Train net output #0: loss = 1.59085 (* 1 = 1.59085 loss)
I1027 16:40:03.740314  9023 sgd_solver.cpp:105] Iteration 79280, lr = 0.00470657
I1027 16:40:34.594094  9023 solver.cpp:222] Iteration 79320 (1.29649 iter/s, 30.8526s/40 iters), loss = 1.72389
I1027 16:40:34.594322  9023 solver.cpp:241]     Train net output #0: loss = 1.72389 (* 1 = 1.72389 loss)
I1027 16:40:34.594339  9023 sgd_solver.cpp:105] Iteration 79320, lr = 0.00470408
I1027 16:41:05.428516  9023 solver.cpp:222] Iteration 79360 (1.29731 iter/s, 30.833s/40 iters), loss = 1.56642
I1027 16:41:05.428726  9023 solver.cpp:241]     Train net output #0: loss = 1.56642 (* 1 = 1.56642 loss)
I1027 16:41:05.428741  9023 sgd_solver.cpp:105] Iteration 79360, lr = 0.00470159
I1027 16:41:36.268724  9023 solver.cpp:222] Iteration 79400 (1.29707 iter/s, 30.8388s/40 iters), loss = 1.54549
I1027 16:41:36.268919  9023 solver.cpp:241]     Train net output #0: loss = 1.54549 (* 1 = 1.54549 loss)
I1027 16:41:36.268935  9023 sgd_solver.cpp:105] Iteration 79400, lr = 0.0046991
I1027 16:42:06.595120  9023 solver.cpp:222] Iteration 79440 (1.31904 iter/s, 30.3251s/40 iters), loss = 1.53603
I1027 16:42:06.595337  9023 solver.cpp:241]     Train net output #0: loss = 1.53603 (* 1 = 1.53603 loss)
I1027 16:42:06.595355  9023 sgd_solver.cpp:105] Iteration 79440, lr = 0.00469662
I1027 16:42:37.538247  9023 solver.cpp:222] Iteration 79480 (1.29275 iter/s, 30.9417s/40 iters), loss = 1.80531
I1027 16:42:37.538452  9023 solver.cpp:241]     Train net output #0: loss = 1.80531 (* 1 = 1.80531 loss)
I1027 16:42:37.538470  9023 sgd_solver.cpp:105] Iteration 79480, lr = 0.00469413
I1027 16:42:52.136598  9023 solver.cpp:334] Iteration 79500, Testing net (#0)
I1027 16:43:23.837349  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54112
I1027 16:43:23.837507  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.782
I1027 16:43:23.837523  9023 solver.cpp:401]     Test net output #2: loss = 2.01445 (* 1 = 2.01445 loss)
I1027 16:43:32.376052  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1027 16:43:40.424863  9023 solver.cpp:222] Iteration 79520 (0.636092 iter/s, 62.884s/40 iters), loss = 1.48473
I1027 16:43:40.424957  9023 solver.cpp:241]     Train net output #0: loss = 1.48473 (* 1 = 1.48473 loss)
I1027 16:43:40.424973  9023 sgd_solver.cpp:105] Iteration 79520, lr = 0.00469164
I1027 16:44:10.888437  9023 solver.cpp:222] Iteration 79560 (1.3131 iter/s, 30.4623s/40 iters), loss = 1.78793
I1027 16:44:10.888655  9023 solver.cpp:241]     Train net output #0: loss = 1.78793 (* 1 = 1.78793 loss)
I1027 16:44:10.888671  9023 sgd_solver.cpp:105] Iteration 79560, lr = 0.00468915
I1027 16:44:41.290560  9023 solver.cpp:222] Iteration 79600 (1.31576 iter/s, 30.4008s/40 iters), loss = 1.59818
I1027 16:44:41.290740  9023 solver.cpp:241]     Train net output #0: loss = 1.59818 (* 1 = 1.59818 loss)
I1027 16:44:41.290757  9023 sgd_solver.cpp:105] Iteration 79600, lr = 0.00468666
I1027 16:45:11.678547  9023 solver.cpp:222] Iteration 79640 (1.31637 iter/s, 30.3867s/40 iters), loss = 1.93308
I1027 16:45:11.678818  9023 solver.cpp:241]     Train net output #0: loss = 1.93308 (* 1 = 1.93308 loss)
I1027 16:45:11.678835  9023 sgd_solver.cpp:105] Iteration 79640, lr = 0.00468417
I1027 16:45:41.990305  9023 solver.cpp:222] Iteration 79680 (1.31968 iter/s, 30.3103s/40 iters), loss = 1.47503
I1027 16:45:41.990489  9023 solver.cpp:241]     Train net output #0: loss = 1.47503 (* 1 = 1.47503 loss)
I1027 16:45:41.990505  9023 sgd_solver.cpp:105] Iteration 79680, lr = 0.00468168
I1027 16:46:12.362664  9023 solver.cpp:222] Iteration 79720 (1.31704 iter/s, 30.371s/40 iters), loss = 1.70209
I1027 16:46:12.362838  9023 solver.cpp:241]     Train net output #0: loss = 1.70209 (* 1 = 1.70209 loss)
I1027 16:46:12.362854  9023 sgd_solver.cpp:105] Iteration 79720, lr = 0.00467919
I1027 16:46:42.817876  9023 solver.cpp:222] Iteration 79760 (1.31346 iter/s, 30.4539s/40 iters), loss = 1.5609
I1027 16:46:42.818033  9023 solver.cpp:241]     Train net output #0: loss = 1.5609 (* 1 = 1.5609 loss)
I1027 16:46:42.818050  9023 sgd_solver.cpp:105] Iteration 79760, lr = 0.00467671
I1027 16:47:13.404528  9023 solver.cpp:222] Iteration 79800 (1.30782 iter/s, 30.5853s/40 iters), loss = 1.55008
I1027 16:47:13.404696  9023 solver.cpp:241]     Train net output #0: loss = 1.55008 (* 1 = 1.55008 loss)
I1027 16:47:13.404713  9023 sgd_solver.cpp:105] Iteration 79800, lr = 0.00467422
I1027 16:47:43.880581  9023 solver.cpp:222] Iteration 79840 (1.31256 iter/s, 30.4747s/40 iters), loss = 1.68354
I1027 16:47:43.880767  9023 solver.cpp:241]     Train net output #0: loss = 1.68354 (* 1 = 1.68354 loss)
I1027 16:47:43.880784  9023 sgd_solver.cpp:105] Iteration 79840, lr = 0.00467173
I1027 16:48:14.371609  9023 solver.cpp:222] Iteration 79880 (1.31192 iter/s, 30.4897s/40 iters), loss = 1.77776
I1027 16:48:14.371779  9023 solver.cpp:241]     Train net output #0: loss = 1.77776 (* 1 = 1.77776 loss)
I1027 16:48:14.371795  9023 sgd_solver.cpp:105] Iteration 79880, lr = 0.00466925
I1027 16:48:44.871250  9023 solver.cpp:222] Iteration 79920 (1.31155 iter/s, 30.4983s/40 iters), loss = 2.03193
I1027 16:48:44.871402  9023 solver.cpp:241]     Train net output #0: loss = 2.03193 (* 1 = 2.03193 loss)
I1027 16:48:44.871417  9023 sgd_solver.cpp:105] Iteration 79920, lr = 0.00466676
I1027 16:49:15.554394  9023 solver.cpp:222] Iteration 79960 (1.3037 iter/s, 30.6818s/40 iters), loss = 1.88555
I1027 16:49:15.554555  9023 solver.cpp:241]     Train net output #0: loss = 1.88555 (* 1 = 1.88555 loss)
I1027 16:49:15.554571  9023 sgd_solver.cpp:105] Iteration 79960, lr = 0.00466427
I1027 16:49:45.195688  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_80000.caffemodel
I1027 16:49:45.227783  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_80000.solverstate
I1027 16:49:45.246637  9023 solver.cpp:334] Iteration 80000, Testing net (#0)
I1027 16:50:17.059994  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 16:50:17.270115  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54924
I1027 16:50:17.270184  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.786399
I1027 16:50:17.270196  9023 solver.cpp:401]     Test net output #2: loss = 1.99707 (* 1 = 1.99707 loss)
I1027 16:50:18.043654  9023 solver.cpp:222] Iteration 80000 (0.640136 iter/s, 62.4868s/40 iters), loss = 1.68447
I1027 16:50:18.043720  9023 solver.cpp:241]     Train net output #0: loss = 1.68447 (* 1 = 1.68447 loss)
I1027 16:50:18.043735  9023 sgd_solver.cpp:105] Iteration 80000, lr = 0.00466179
I1027 16:50:50.187594  9023 solver.cpp:222] Iteration 80040 (1.24445 iter/s, 32.1426s/40 iters), loss = 1.7153
I1027 16:50:50.187896  9023 solver.cpp:241]     Train net output #0: loss = 1.7153 (* 1 = 1.7153 loss)
I1027 16:50:50.187919  9023 sgd_solver.cpp:105] Iteration 80040, lr = 0.0046593
I1027 16:53:20.440625  9023 solver.cpp:222] Iteration 80080 (0.266228 iter/s, 150.247s/40 iters), loss = 1.6066
I1027 16:53:20.440832  9023 solver.cpp:241]     Train net output #0: loss = 1.6066 (* 1 = 1.6066 loss)
I1027 16:53:20.440863  9023 sgd_solver.cpp:105] Iteration 80080, lr = 0.00465681
I1027 16:53:51.290010  9023 solver.cpp:222] Iteration 80120 (1.29668 iter/s, 30.848s/40 iters), loss = 1.46872
I1027 16:53:51.290289  9023 solver.cpp:241]     Train net output #0: loss = 1.46872 (* 1 = 1.46872 loss)
I1027 16:53:51.290324  9023 sgd_solver.cpp:105] Iteration 80120, lr = 0.00465433
I1027 16:54:21.954839  9023 solver.cpp:222] Iteration 80160 (1.30449 iter/s, 30.6634s/40 iters), loss = 1.73116
I1027 16:54:21.955029  9023 solver.cpp:241]     Train net output #0: loss = 1.73116 (* 1 = 1.73116 loss)
I1027 16:54:21.955046  9023 sgd_solver.cpp:105] Iteration 80160, lr = 0.00465184
I1027 16:54:52.825616  9023 solver.cpp:222] Iteration 80200 (1.29578 iter/s, 30.8694s/40 iters), loss = 1.73115
I1027 16:54:52.825806  9023 solver.cpp:241]     Train net output #0: loss = 1.73115 (* 1 = 1.73115 loss)
I1027 16:54:52.825822  9023 sgd_solver.cpp:105] Iteration 80200, lr = 0.00464936
I1027 16:55:23.539288  9023 solver.cpp:222] Iteration 80240 (1.30241 iter/s, 30.7123s/40 iters), loss = 1.71495
I1027 16:55:23.539505  9023 solver.cpp:241]     Train net output #0: loss = 1.71495 (* 1 = 1.71495 loss)
I1027 16:55:23.539521  9023 sgd_solver.cpp:105] Iteration 80240, lr = 0.00464687
I1027 16:55:53.971228  9023 solver.cpp:222] Iteration 80280 (1.31447 iter/s, 30.4306s/40 iters), loss = 1.42259
I1027 16:55:53.971407  9023 solver.cpp:241]     Train net output #0: loss = 1.42259 (* 1 = 1.42259 loss)
I1027 16:55:53.971424  9023 sgd_solver.cpp:105] Iteration 80280, lr = 0.00464439
I1027 16:56:25.016434  9023 solver.cpp:222] Iteration 80320 (1.2885 iter/s, 31.0438s/40 iters), loss = 1.5794
I1027 16:56:25.016630  9023 solver.cpp:241]     Train net output #0: loss = 1.5794 (* 1 = 1.5794 loss)
I1027 16:56:25.016654  9023 sgd_solver.cpp:105] Iteration 80320, lr = 0.0046419
I1027 16:56:56.905167  9023 solver.cpp:222] Iteration 80360 (1.25442 iter/s, 31.8873s/40 iters), loss = 1.75614
I1027 16:56:56.905376  9023 solver.cpp:241]     Train net output #0: loss = 1.75614 (* 1 = 1.75614 loss)
I1027 16:56:56.905393  9023 sgd_solver.cpp:105] Iteration 80360, lr = 0.00463942
I1027 16:57:27.638032  9023 solver.cpp:222] Iteration 80400 (1.3016 iter/s, 30.7315s/40 iters), loss = 1.56064
I1027 16:57:27.638206  9023 solver.cpp:241]     Train net output #0: loss = 1.56064 (* 1 = 1.56064 loss)
I1027 16:57:27.638221  9023 sgd_solver.cpp:105] Iteration 80400, lr = 0.00463693
I1027 16:57:58.445753  9023 solver.cpp:222] Iteration 80440 (1.29843 iter/s, 30.8064s/40 iters), loss = 1.61272
I1027 16:57:58.445878  9023 solver.cpp:241]     Train net output #0: loss = 1.61272 (* 1 = 1.61272 loss)
I1027 16:57:58.445894  9023 sgd_solver.cpp:105] Iteration 80440, lr = 0.00463445
I1027 16:58:29.143419  9023 solver.cpp:222] Iteration 80480 (1.30309 iter/s, 30.6964s/40 iters), loss = 1.71197
I1027 16:58:29.143615  9023 solver.cpp:241]     Train net output #0: loss = 1.71197 (* 1 = 1.71197 loss)
I1027 16:58:29.143630  9023 sgd_solver.cpp:105] Iteration 80480, lr = 0.00463197
I1027 16:58:43.691169  9023 solver.cpp:334] Iteration 80500, Testing net (#0)
I1027 16:59:14.958375  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55272
I1027 16:59:14.958528  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78824
I1027 16:59:14.958544  9023 solver.cpp:401]     Test net output #2: loss = 2.05086 (* 1 = 2.05086 loss)
I1027 16:59:30.988481  9023 solver.cpp:222] Iteration 80520 (0.646804 iter/s, 61.8425s/40 iters), loss = 1.838
I1027 16:59:30.988548  9023 solver.cpp:241]     Train net output #0: loss = 1.838 (* 1 = 1.838 loss)
I1027 16:59:30.988564  9023 sgd_solver.cpp:105] Iteration 80520, lr = 0.00462948
I1027 17:00:01.608661  9023 solver.cpp:222] Iteration 80560 (1.30638 iter/s, 30.6189s/40 iters), loss = 1.78609
I1027 17:00:01.608837  9023 solver.cpp:241]     Train net output #0: loss = 1.78609 (* 1 = 1.78609 loss)
I1027 17:00:01.608855  9023 sgd_solver.cpp:105] Iteration 80560, lr = 0.004627
I1027 17:00:32.134760  9023 solver.cpp:222] Iteration 80600 (1.31041 iter/s, 30.5248s/40 iters), loss = 1.52759
I1027 17:00:32.135058  9023 solver.cpp:241]     Train net output #0: loss = 1.52759 (* 1 = 1.52759 loss)
I1027 17:00:32.135078  9023 sgd_solver.cpp:105] Iteration 80600, lr = 0.00462452
I1027 17:01:04.245481  9023 solver.cpp:222] Iteration 80640 (1.24575 iter/s, 32.1092s/40 iters), loss = 1.42808
I1027 17:01:04.245712  9023 solver.cpp:241]     Train net output #0: loss = 1.42808 (* 1 = 1.42808 loss)
I1027 17:01:04.245733  9023 sgd_solver.cpp:105] Iteration 80640, lr = 0.00462203
I1027 17:01:35.620859  9023 solver.cpp:222] Iteration 80680 (1.27494 iter/s, 31.374s/40 iters), loss = 1.69069
I1027 17:01:35.621048  9023 solver.cpp:241]     Train net output #0: loss = 1.69069 (* 1 = 1.69069 loss)
I1027 17:01:35.621064  9023 sgd_solver.cpp:105] Iteration 80680, lr = 0.00461955
I1027 17:02:06.657048  9023 solver.cpp:222] Iteration 80720 (1.28887 iter/s, 31.0348s/40 iters), loss = 1.80622
I1027 17:02:06.657253  9023 solver.cpp:241]     Train net output #0: loss = 1.80622 (* 1 = 1.80622 loss)
I1027 17:02:06.657269  9023 sgd_solver.cpp:105] Iteration 80720, lr = 0.00461707
I1027 17:02:37.909541  9023 solver.cpp:222] Iteration 80760 (1.27996 iter/s, 31.2511s/40 iters), loss = 1.54418
I1027 17:02:37.909768  9023 solver.cpp:241]     Train net output #0: loss = 1.54418 (* 1 = 1.54418 loss)
I1027 17:02:37.909791  9023 sgd_solver.cpp:105] Iteration 80760, lr = 0.00461459
I1027 17:03:09.475980  9023 solver.cpp:222] Iteration 80800 (1.26723 iter/s, 31.565s/40 iters), loss = 1.79401
I1027 17:03:09.476145  9023 solver.cpp:241]     Train net output #0: loss = 1.79401 (* 1 = 1.79401 loss)
I1027 17:03:09.476161  9023 sgd_solver.cpp:105] Iteration 80800, lr = 0.0046121
I1027 17:03:40.547145  9023 solver.cpp:222] Iteration 80840 (1.28742 iter/s, 31.0698s/40 iters), loss = 1.64461
I1027 17:03:40.547343  9023 solver.cpp:241]     Train net output #0: loss = 1.64461 (* 1 = 1.64461 loss)
I1027 17:03:40.547360  9023 sgd_solver.cpp:105] Iteration 80840, lr = 0.00460962
I1027 17:04:11.831825  9023 solver.cpp:222] Iteration 80880 (1.27864 iter/s, 31.2833s/40 iters), loss = 1.95635
I1027 17:04:11.832013  9023 solver.cpp:241]     Train net output #0: loss = 1.95635 (* 1 = 1.95635 loss)
I1027 17:04:11.832029  9023 sgd_solver.cpp:105] Iteration 80880, lr = 0.00460714
I1027 17:04:42.848923  9023 solver.cpp:222] Iteration 80920 (1.28967 iter/s, 31.0157s/40 iters), loss = 1.69874
I1027 17:04:42.849131  9023 solver.cpp:241]     Train net output #0: loss = 1.69874 (* 1 = 1.69874 loss)
I1027 17:04:42.849148  9023 sgd_solver.cpp:105] Iteration 80920, lr = 0.00460466
I1027 17:05:13.890135  9023 solver.cpp:222] Iteration 80960 (1.28867 iter/s, 31.0398s/40 iters), loss = 1.94051
I1027 17:05:13.890331  9023 solver.cpp:241]     Train net output #0: loss = 1.94051 (* 1 = 1.94051 loss)
I1027 17:05:13.890348  9023 sgd_solver.cpp:105] Iteration 80960, lr = 0.00460218
I1027 17:05:44.181681  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_81000.caffemodel
I1027 17:05:44.213132  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_81000.solverstate
I1027 17:05:44.229816  9023 solver.cpp:334] Iteration 81000, Testing net (#0)
I1027 17:06:15.238667  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 17:06:15.448734  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54648
I1027 17:06:15.448796  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.786399
I1027 17:06:15.448808  9023 solver.cpp:401]     Test net output #2: loss = 2.04299 (* 1 = 2.04299 loss)
I1027 17:06:16.219723  9023 solver.cpp:222] Iteration 81000 (0.641776 iter/s, 62.3271s/40 iters), loss = 1.63571
I1027 17:06:16.219787  9023 solver.cpp:241]     Train net output #0: loss = 1.63571 (* 1 = 1.63571 loss)
I1027 17:06:16.219802  9023 sgd_solver.cpp:105] Iteration 81000, lr = 0.0045997
I1027 17:06:47.189113  9023 solver.cpp:222] Iteration 81040 (1.29165 iter/s, 30.9681s/40 iters), loss = 2.05284
I1027 17:06:47.189380  9023 solver.cpp:241]     Train net output #0: loss = 2.05284 (* 1 = 2.05284 loss)
I1027 17:06:47.189398  9023 sgd_solver.cpp:105] Iteration 81040, lr = 0.00459722
I1027 17:07:18.235987  9023 solver.cpp:222] Iteration 81080 (1.28843 iter/s, 31.0454s/40 iters), loss = 2.00385
I1027 17:07:18.236215  9023 solver.cpp:241]     Train net output #0: loss = 2.00385 (* 1 = 2.00385 loss)
I1027 17:07:18.236232  9023 sgd_solver.cpp:105] Iteration 81080, lr = 0.00459474
I1027 17:07:48.985733  9023 solver.cpp:222] Iteration 81120 (1.30088 iter/s, 30.7484s/40 iters), loss = 1.60316
I1027 17:07:48.985919  9023 solver.cpp:241]     Train net output #0: loss = 1.60316 (* 1 = 1.60316 loss)
I1027 17:07:48.985936  9023 sgd_solver.cpp:105] Iteration 81120, lr = 0.00459226
I1027 17:08:19.660392  9023 solver.cpp:222] Iteration 81160 (1.30406 iter/s, 30.6733s/40 iters), loss = 1.89833
I1027 17:08:19.660573  9023 solver.cpp:241]     Train net output #0: loss = 1.89833 (* 1 = 1.89833 loss)
I1027 17:08:19.660589  9023 sgd_solver.cpp:105] Iteration 81160, lr = 0.00458978
I1027 17:08:50.571243  9023 solver.cpp:222] Iteration 81200 (1.2941 iter/s, 30.9095s/40 iters), loss = 1.37377
I1027 17:08:50.571422  9023 solver.cpp:241]     Train net output #0: loss = 1.37377 (* 1 = 1.37377 loss)
I1027 17:08:50.571439  9023 sgd_solver.cpp:105] Iteration 81200, lr = 0.0045873
I1027 17:09:21.332334  9023 solver.cpp:222] Iteration 81240 (1.3004 iter/s, 30.7598s/40 iters), loss = 1.5052
I1027 17:09:21.332504  9023 solver.cpp:241]     Train net output #0: loss = 1.5052 (* 1 = 1.5052 loss)
I1027 17:09:21.332520  9023 sgd_solver.cpp:105] Iteration 81240, lr = 0.00458482
I1027 17:09:51.866755  9023 solver.cpp:222] Iteration 81280 (1.31005 iter/s, 30.5331s/40 iters), loss = 1.62778
I1027 17:09:51.866936  9023 solver.cpp:241]     Train net output #0: loss = 1.62778 (* 1 = 1.62778 loss)
I1027 17:09:51.866955  9023 sgd_solver.cpp:105] Iteration 81280, lr = 0.00458234
I1027 17:10:22.550235  9023 solver.cpp:222] Iteration 81320 (1.30369 iter/s, 30.6821s/40 iters), loss = 1.46613
I1027 17:10:22.550420  9023 solver.cpp:241]     Train net output #0: loss = 1.46613 (* 1 = 1.46613 loss)
I1027 17:10:22.550436  9023 sgd_solver.cpp:105] Iteration 81320, lr = 0.00457986
I1027 17:10:54.119637  9023 solver.cpp:222] Iteration 81360 (1.2671 iter/s, 31.568s/40 iters), loss = 1.58927
I1027 17:10:54.119869  9023 solver.cpp:241]     Train net output #0: loss = 1.58927 (* 1 = 1.58927 loss)
I1027 17:10:54.119891  9023 sgd_solver.cpp:105] Iteration 81360, lr = 0.00457738
I1027 17:11:26.045372  9023 solver.cpp:222] Iteration 81400 (1.25296 iter/s, 31.9243s/40 iters), loss = 2.20975
I1027 17:11:26.045621  9023 solver.cpp:241]     Train net output #0: loss = 2.20975 (* 1 = 2.20975 loss)
I1027 17:11:26.045645  9023 sgd_solver.cpp:105] Iteration 81400, lr = 0.0045749
I1027 17:11:57.776942  9023 solver.cpp:222] Iteration 81440 (1.26063 iter/s, 31.7301s/40 iters), loss = 1.44098
I1027 17:11:57.777191  9023 solver.cpp:241]     Train net output #0: loss = 1.44098 (* 1 = 1.44098 loss)
I1027 17:11:57.777212  9023 sgd_solver.cpp:105] Iteration 81440, lr = 0.00457242
I1027 17:12:28.641206  9023 solver.cpp:222] Iteration 81480 (1.29606 iter/s, 30.8629s/40 iters), loss = 1.59166
I1027 17:12:28.641386  9023 solver.cpp:241]     Train net output #0: loss = 1.59166 (* 1 = 1.59166 loss)
I1027 17:12:28.641402  9023 sgd_solver.cpp:105] Iteration 81480, lr = 0.00456994
I1027 17:12:43.232821  9023 solver.cpp:334] Iteration 81500, Testing net (#0)
I1027 17:13:14.911061  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55216
I1027 17:13:14.911222  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7868
I1027 17:13:14.911237  9023 solver.cpp:401]     Test net output #2: loss = 1.98196 (* 1 = 1.98196 loss)
I1027 17:13:31.074440  9023 solver.cpp:222] Iteration 81520 (0.64071 iter/s, 62.4307s/40 iters), loss = 1.90013
I1027 17:13:31.074506  9023 solver.cpp:241]     Train net output #0: loss = 1.90013 (* 1 = 1.90013 loss)
I1027 17:13:31.074522  9023 sgd_solver.cpp:105] Iteration 81520, lr = 0.00456747
I1027 17:14:01.876761  9023 solver.cpp:222] Iteration 81560 (1.29866 iter/s, 30.8011s/40 iters), loss = 1.84943
I1027 17:14:01.877007  9023 solver.cpp:241]     Train net output #0: loss = 1.84943 (* 1 = 1.84943 loss)
I1027 17:14:01.877038  9023 sgd_solver.cpp:105] Iteration 81560, lr = 0.00456499
I1027 17:14:32.629258  9023 solver.cpp:222] Iteration 81600 (1.30077 iter/s, 30.7511s/40 iters), loss = 1.52992
I1027 17:14:32.629436  9023 solver.cpp:241]     Train net output #0: loss = 1.52992 (* 1 = 1.52992 loss)
I1027 17:14:32.629452  9023 sgd_solver.cpp:105] Iteration 81600, lr = 0.00456251
I1027 17:15:03.567821  9023 solver.cpp:222] Iteration 81640 (1.29294 iter/s, 30.9372s/40 iters), loss = 1.80389
I1027 17:15:03.567987  9023 solver.cpp:241]     Train net output #0: loss = 1.80389 (* 1 = 1.80389 loss)
I1027 17:15:03.568003  9023 sgd_solver.cpp:105] Iteration 81640, lr = 0.00456003
I1027 17:15:34.202795  9023 solver.cpp:222] Iteration 81680 (1.30575 iter/s, 30.6336s/40 iters), loss = 1.64809
I1027 17:15:34.202975  9023 solver.cpp:241]     Train net output #0: loss = 1.64809 (* 1 = 1.64809 loss)
I1027 17:15:34.202991  9023 sgd_solver.cpp:105] Iteration 81680, lr = 0.00455756
I1027 17:16:04.877727  9023 solver.cpp:222] Iteration 81720 (1.30405 iter/s, 30.6736s/40 iters), loss = 1.66314
I1027 17:16:04.877907  9023 solver.cpp:241]     Train net output #0: loss = 1.66314 (* 1 = 1.66314 loss)
I1027 17:16:04.877923  9023 sgd_solver.cpp:105] Iteration 81720, lr = 0.00455508
I1027 17:16:35.566525  9023 solver.cpp:222] Iteration 81760 (1.30346 iter/s, 30.6875s/40 iters), loss = 1.59745
I1027 17:16:35.566697  9023 solver.cpp:241]     Train net output #0: loss = 1.59745 (* 1 = 1.59745 loss)
I1027 17:16:35.566714  9023 sgd_solver.cpp:105] Iteration 81760, lr = 0.0045526
I1027 17:17:06.419070  9023 solver.cpp:222] Iteration 81800 (1.29655 iter/s, 30.8512s/40 iters), loss = 1.69364
I1027 17:17:06.419256  9023 solver.cpp:241]     Train net output #0: loss = 1.69364 (* 1 = 1.69364 loss)
I1027 17:17:06.419272  9023 sgd_solver.cpp:105] Iteration 81800, lr = 0.00455013
I1027 17:17:37.061990  9023 solver.cpp:222] Iteration 81840 (1.30542 iter/s, 30.6416s/40 iters), loss = 1.65862
I1027 17:17:37.062157  9023 solver.cpp:241]     Train net output #0: loss = 1.65862 (* 1 = 1.65862 loss)
I1027 17:17:37.062173  9023 sgd_solver.cpp:105] Iteration 81840, lr = 0.00454765
I1027 17:18:07.726213  9023 solver.cpp:222] Iteration 81880 (1.30451 iter/s, 30.6629s/40 iters), loss = 1.52828
I1027 17:18:07.726460  9023 solver.cpp:241]     Train net output #0: loss = 1.52828 (* 1 = 1.52828 loss)
I1027 17:18:07.726485  9023 sgd_solver.cpp:105] Iteration 81880, lr = 0.00454518
I1027 17:18:38.633524  9023 solver.cpp:222] Iteration 81920 (1.29425 iter/s, 30.9059s/40 iters), loss = 1.75744
I1027 17:18:38.633741  9023 solver.cpp:241]     Train net output #0: loss = 1.75744 (* 1 = 1.75744 loss)
I1027 17:18:38.633759  9023 sgd_solver.cpp:105] Iteration 81920, lr = 0.0045427
I1027 17:19:09.172994  9023 solver.cpp:222] Iteration 81960 (1.30984 iter/s, 30.5381s/40 iters), loss = 1.54941
I1027 17:19:09.173174  9023 solver.cpp:241]     Train net output #0: loss = 1.54941 (* 1 = 1.54941 loss)
I1027 17:19:09.173192  9023 sgd_solver.cpp:105] Iteration 81960, lr = 0.00454022
I1027 17:19:39.099104  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_82000.caffemodel
I1027 17:19:39.130502  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_82000.solverstate
I1027 17:19:39.147974  9023 solver.cpp:334] Iteration 82000, Testing net (#0)
I1027 17:20:10.566963  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 17:20:10.780880  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54824
I1027 17:20:10.780946  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78896
I1027 17:20:10.780961  9023 solver.cpp:401]     Test net output #2: loss = 1.9924 (* 1 = 1.9924 loss)
I1027 17:20:11.545168  9023 solver.cpp:222] Iteration 82000 (0.641337 iter/s, 62.3697s/40 iters), loss = 1.4376
I1027 17:20:11.545231  9023 solver.cpp:241]     Train net output #0: loss = 1.4376 (* 1 = 1.4376 loss)
I1027 17:20:11.545248  9023 sgd_solver.cpp:105] Iteration 82000, lr = 0.00453775
I1027 17:20:19.990708  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1027 17:20:42.102627  9023 solver.cpp:222] Iteration 82040 (1.30906 iter/s, 30.5562s/40 iters), loss = 1.5771
I1027 17:20:42.102900  9023 solver.cpp:241]     Train net output #0: loss = 1.5771 (* 1 = 1.5771 loss)
I1027 17:20:42.102928  9023 sgd_solver.cpp:105] Iteration 82040, lr = 0.00453527
I1027 17:22:34.068787  9023 solver.cpp:222] Iteration 82080 (0.357265 iter/s, 111.962s/40 iters), loss = 1.68936
I1027 17:22:34.069010  9023 solver.cpp:241]     Train net output #0: loss = 1.68936 (* 1 = 1.68936 loss)
I1027 17:22:34.069032  9023 sgd_solver.cpp:105] Iteration 82080, lr = 0.0045328
I1027 17:23:05.425740  9023 solver.cpp:222] Iteration 82120 (1.27569 iter/s, 31.3555s/40 iters), loss = 1.5684
I1027 17:23:05.425940  9023 solver.cpp:241]     Train net output #0: loss = 1.5684 (* 1 = 1.5684 loss)
I1027 17:23:05.425962  9023 sgd_solver.cpp:105] Iteration 82120, lr = 0.00453032
I1027 17:23:36.441021  9023 solver.cpp:222] Iteration 82160 (1.28974 iter/s, 31.0139s/40 iters), loss = 1.48505
I1027 17:23:36.441197  9023 solver.cpp:241]     Train net output #0: loss = 1.48505 (* 1 = 1.48505 loss)
I1027 17:23:36.441215  9023 sgd_solver.cpp:105] Iteration 82160, lr = 0.00452785
I1027 17:24:07.385251  9023 solver.cpp:222] Iteration 82200 (1.2927 iter/s, 30.9429s/40 iters), loss = 1.77997
I1027 17:24:07.385427  9023 solver.cpp:241]     Train net output #0: loss = 1.77997 (* 1 = 1.77997 loss)
I1027 17:24:07.385443  9023 sgd_solver.cpp:105] Iteration 82200, lr = 0.00452538
I1027 17:24:38.445776  9023 solver.cpp:222] Iteration 82240 (1.28786 iter/s, 31.0592s/40 iters), loss = 1.36457
I1027 17:24:38.445964  9023 solver.cpp:241]     Train net output #0: loss = 1.36457 (* 1 = 1.36457 loss)
I1027 17:24:38.445981  9023 sgd_solver.cpp:105] Iteration 82240, lr = 0.0045229
I1027 17:25:16.054620  9023 solver.cpp:222] Iteration 82280 (1.06363 iter/s, 37.6072s/40 iters), loss = 1.93667
I1027 17:25:16.054832  9023 solver.cpp:241]     Train net output #0: loss = 1.93667 (* 1 = 1.93667 loss)
I1027 17:25:16.054849  9023 sgd_solver.cpp:105] Iteration 82280, lr = 0.00452043
I1027 17:25:47.058439  9023 solver.cpp:222] Iteration 82320 (1.29022 iter/s, 31.0024s/40 iters), loss = 1.74108
I1027 17:25:47.058641  9023 solver.cpp:241]     Train net output #0: loss = 1.74108 (* 1 = 1.74108 loss)
I1027 17:25:47.058660  9023 sgd_solver.cpp:105] Iteration 82320, lr = 0.00451796
I1027 17:26:17.993418  9023 solver.cpp:222] Iteration 82360 (1.29309 iter/s, 30.9336s/40 iters), loss = 1.76122
I1027 17:26:17.993618  9023 solver.cpp:241]     Train net output #0: loss = 1.76122 (* 1 = 1.76122 loss)
I1027 17:26:17.993634  9023 sgd_solver.cpp:105] Iteration 82360, lr = 0.00451548
I1027 17:26:48.723105  9023 solver.cpp:222] Iteration 82400 (1.30173 iter/s, 30.7283s/40 iters), loss = 1.68539
I1027 17:26:48.723292  9023 solver.cpp:241]     Train net output #0: loss = 1.68539 (* 1 = 1.68539 loss)
I1027 17:26:48.723315  9023 sgd_solver.cpp:105] Iteration 82400, lr = 0.00451301
I1027 17:27:19.709800  9023 solver.cpp:222] Iteration 82440 (1.29093 iter/s, 30.9853s/40 iters), loss = 1.44324
I1027 17:27:19.709997  9023 solver.cpp:241]     Train net output #0: loss = 1.44324 (* 1 = 1.44324 loss)
I1027 17:27:19.710026  9023 sgd_solver.cpp:105] Iteration 82440, lr = 0.00451054
I1027 17:27:50.855978  9023 solver.cpp:222] Iteration 82480 (1.28432 iter/s, 31.1448s/40 iters), loss = 1.68913
I1027 17:27:50.856163  9023 solver.cpp:241]     Train net output #0: loss = 1.68913 (* 1 = 1.68913 loss)
I1027 17:27:50.856179  9023 sgd_solver.cpp:105] Iteration 82480, lr = 0.00450806
I1027 17:28:05.860852  9023 solver.cpp:334] Iteration 82500, Testing net (#0)
I1027 17:28:37.122094  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5482
I1027 17:28:37.122489  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.783399
I1027 17:28:37.122510  9023 solver.cpp:401]     Test net output #2: loss = 2.00383 (* 1 = 2.00383 loss)
I1027 17:28:53.606351  9023 solver.cpp:222] Iteration 82520 (0.637472 iter/s, 62.7478s/40 iters), loss = 1.64482
I1027 17:28:53.606421  9023 solver.cpp:241]     Train net output #0: loss = 1.64482 (* 1 = 1.64482 loss)
I1027 17:28:53.606436  9023 sgd_solver.cpp:105] Iteration 82520, lr = 0.00450559
I1027 17:29:25.050559  9023 solver.cpp:222] Iteration 82560 (1.27215 iter/s, 31.4429s/40 iters), loss = 1.67591
I1027 17:29:25.050729  9023 solver.cpp:241]     Train net output #0: loss = 1.67591 (* 1 = 1.67591 loss)
I1027 17:29:25.050745  9023 sgd_solver.cpp:105] Iteration 82560, lr = 0.00450312
I1027 17:29:56.720283  9023 solver.cpp:222] Iteration 82600 (1.26309 iter/s, 31.6684s/40 iters), loss = 1.61074
I1027 17:29:56.720508  9023 solver.cpp:241]     Train net output #0: loss = 1.61074 (* 1 = 1.61074 loss)
I1027 17:29:56.720526  9023 sgd_solver.cpp:105] Iteration 82600, lr = 0.00450065
I1027 17:30:27.407636  9023 solver.cpp:222] Iteration 82640 (1.30353 iter/s, 30.686s/40 iters), loss = 2.00523
I1027 17:30:27.407845  9023 solver.cpp:241]     Train net output #0: loss = 2.00523 (* 1 = 2.00523 loss)
I1027 17:30:27.408310  9023 sgd_solver.cpp:105] Iteration 82640, lr = 0.00449818
I1027 17:30:58.241925  9023 solver.cpp:222] Iteration 82680 (1.29731 iter/s, 30.8329s/40 iters), loss = 1.62957
I1027 17:30:58.242094  9023 solver.cpp:241]     Train net output #0: loss = 1.62957 (* 1 = 1.62957 loss)
I1027 17:30:58.242111  9023 sgd_solver.cpp:105] Iteration 82680, lr = 0.0044957
I1027 17:31:29.720621  9023 solver.cpp:222] Iteration 82720 (1.27076 iter/s, 31.4773s/40 iters), loss = 1.89494
I1027 17:31:29.720819  9023 solver.cpp:241]     Train net output #0: loss = 1.89494 (* 1 = 1.89494 loss)
I1027 17:31:29.720835  9023 sgd_solver.cpp:105] Iteration 82720, lr = 0.00449323
I1027 17:32:01.092715  9023 solver.cpp:222] Iteration 82760 (1.27507 iter/s, 31.3707s/40 iters), loss = 1.67925
I1027 17:32:01.092928  9023 solver.cpp:241]     Train net output #0: loss = 1.67925 (* 1 = 1.67925 loss)
I1027 17:32:01.092943  9023 sgd_solver.cpp:105] Iteration 82760, lr = 0.00449076
I1027 17:32:31.766738  9023 solver.cpp:222] Iteration 82800 (1.30409 iter/s, 30.6727s/40 iters), loss = 1.98675
I1027 17:32:31.766913  9023 solver.cpp:241]     Train net output #0: loss = 1.98675 (* 1 = 1.98675 loss)
I1027 17:32:31.766930  9023 sgd_solver.cpp:105] Iteration 82800, lr = 0.00448829
I1027 17:33:02.311031  9023 solver.cpp:222] Iteration 82840 (1.30963 iter/s, 30.543s/40 iters), loss = 1.49502
I1027 17:33:02.311183  9023 solver.cpp:241]     Train net output #0: loss = 1.49502 (* 1 = 1.49502 loss)
I1027 17:33:02.311199  9023 sgd_solver.cpp:105] Iteration 82840, lr = 0.00448582
I1027 17:33:33.278584  9023 solver.cpp:222] Iteration 82880 (1.29173 iter/s, 30.9662s/40 iters), loss = 1.53334
I1027 17:33:33.278748  9023 solver.cpp:241]     Train net output #0: loss = 1.53334 (* 1 = 1.53334 loss)
I1027 17:33:33.278762  9023 sgd_solver.cpp:105] Iteration 82880, lr = 0.00448335
I1027 17:34:09.191187  9023 solver.cpp:222] Iteration 82920 (1.11386 iter/s, 35.9111s/40 iters), loss = 1.66388
I1027 17:34:09.191411  9023 solver.cpp:241]     Train net output #0: loss = 1.66388 (* 1 = 1.66388 loss)
I1027 17:34:09.191426  9023 sgd_solver.cpp:105] Iteration 82920, lr = 0.00448088
I1027 17:34:41.003309  9023 solver.cpp:222] Iteration 82960 (1.25744 iter/s, 31.8107s/40 iters), loss = 1.62927
I1027 17:34:41.003563  9023 solver.cpp:241]     Train net output #0: loss = 1.62927 (* 1 = 1.62927 loss)
I1027 17:34:41.003588  9023 sgd_solver.cpp:105] Iteration 82960, lr = 0.00447841
I1027 17:35:12.485759  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_83000.caffemodel
I1027 17:35:12.516626  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_83000.solverstate
I1027 17:35:12.532951  9023 solver.cpp:334] Iteration 83000, Testing net (#0)
I1027 17:35:43.616432  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 17:35:43.824965  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55104
I1027 17:35:43.825028  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78784
I1027 17:35:43.825042  9023 solver.cpp:401]     Test net output #2: loss = 2.00202 (* 1 = 2.00202 loss)
I1027 17:35:44.591855  9023 solver.cpp:222] Iteration 83000 (0.62907 iter/s, 63.5859s/40 iters), loss = 1.98289
I1027 17:35:44.591919  9023 solver.cpp:241]     Train net output #0: loss = 1.98289 (* 1 = 1.98289 loss)
I1027 17:35:44.591933  9023 sgd_solver.cpp:105] Iteration 83000, lr = 0.00447594
I1027 17:36:16.184360  9023 solver.cpp:222] Iteration 83040 (1.26617 iter/s, 31.5912s/40 iters), loss = 1.65498
I1027 17:36:16.184566  9023 solver.cpp:241]     Train net output #0: loss = 1.65498 (* 1 = 1.65498 loss)
I1027 17:36:16.184583  9023 sgd_solver.cpp:105] Iteration 83040, lr = 0.00447347
I1027 17:36:47.833674  9023 solver.cpp:222] Iteration 83080 (1.26391 iter/s, 31.6479s/40 iters), loss = 1.39667
I1027 17:36:47.833889  9023 solver.cpp:241]     Train net output #0: loss = 1.39667 (* 1 = 1.39667 loss)
I1027 17:36:47.833914  9023 sgd_solver.cpp:105] Iteration 83080, lr = 0.004471
I1027 17:37:18.461196  9023 solver.cpp:222] Iteration 83120 (1.30607 iter/s, 30.6262s/40 iters), loss = 1.18694
I1027 17:37:18.461382  9023 solver.cpp:241]     Train net output #0: loss = 1.18694 (* 1 = 1.18694 loss)
I1027 17:37:18.461398  9023 sgd_solver.cpp:105] Iteration 83120, lr = 0.00446853
I1027 17:37:49.104339  9023 solver.cpp:222] Iteration 83160 (1.30541 iter/s, 30.6418s/40 iters), loss = 1.47848
I1027 17:37:49.104506  9023 solver.cpp:241]     Train net output #0: loss = 1.47848 (* 1 = 1.47848 loss)
I1027 17:37:49.104521  9023 sgd_solver.cpp:105] Iteration 83160, lr = 0.00446606
I1027 17:38:20.176563  9023 solver.cpp:222] Iteration 83200 (1.28738 iter/s, 31.0709s/40 iters), loss = 1.73867
I1027 17:38:20.176753  9023 solver.cpp:241]     Train net output #0: loss = 1.73867 (* 1 = 1.73867 loss)
I1027 17:38:20.176769  9023 sgd_solver.cpp:105] Iteration 83200, lr = 0.0044636
I1027 17:38:50.667381  9023 solver.cpp:222] Iteration 83240 (1.31193 iter/s, 30.4895s/40 iters), loss = 1.58464
I1027 17:38:50.667546  9023 solver.cpp:241]     Train net output #0: loss = 1.58464 (* 1 = 1.58464 loss)
I1027 17:38:50.667562  9023 sgd_solver.cpp:105] Iteration 83240, lr = 0.00446113
I1027 17:39:21.135962  9023 solver.cpp:222] Iteration 83280 (1.31288 iter/s, 30.4673s/40 iters), loss = 1.73386
I1027 17:39:21.136121  9023 solver.cpp:241]     Train net output #0: loss = 1.73386 (* 1 = 1.73386 loss)
I1027 17:39:21.136137  9023 sgd_solver.cpp:105] Iteration 83280, lr = 0.00445866
I1027 17:39:51.567427  9023 solver.cpp:222] Iteration 83320 (1.31449 iter/s, 30.4302s/40 iters), loss = 1.49317
I1027 17:39:51.567581  9023 solver.cpp:241]     Train net output #0: loss = 1.49317 (* 1 = 1.49317 loss)
I1027 17:39:51.567597  9023 sgd_solver.cpp:105] Iteration 83320, lr = 0.00445619
I1027 17:40:22.858685  9023 solver.cpp:222] Iteration 83360 (1.27837 iter/s, 31.2899s/40 iters), loss = 1.77678
I1027 17:40:22.858912  9023 solver.cpp:241]     Train net output #0: loss = 1.77678 (* 1 = 1.77678 loss)
I1027 17:40:22.858928  9023 sgd_solver.cpp:105] Iteration 83360, lr = 0.00445373
I1027 17:40:53.677426  9023 solver.cpp:222] Iteration 83400 (1.29797 iter/s, 30.8173s/40 iters), loss = 1.78261
I1027 17:40:53.677606  9023 solver.cpp:241]     Train net output #0: loss = 1.78261 (* 1 = 1.78261 loss)
I1027 17:40:53.677623  9023 sgd_solver.cpp:105] Iteration 83400, lr = 0.00445126
I1027 17:41:24.336645  9023 solver.cpp:222] Iteration 83440 (1.30472 iter/s, 30.6579s/40 iters), loss = 1.52349
I1027 17:41:24.336848  9023 solver.cpp:241]     Train net output #0: loss = 1.52349 (* 1 = 1.52349 loss)
I1027 17:41:24.336864  9023 sgd_solver.cpp:105] Iteration 83440, lr = 0.00444879
I1027 17:41:54.922967  9023 solver.cpp:222] Iteration 83480 (1.30783 iter/s, 30.585s/40 iters), loss = 1.69833
I1027 17:41:54.923244  9023 solver.cpp:241]     Train net output #0: loss = 1.69833 (* 1 = 1.69833 loss)
I1027 17:41:54.923261  9023 sgd_solver.cpp:105] Iteration 83480, lr = 0.00444632
I1027 17:42:09.448209  9023 solver.cpp:334] Iteration 83500, Testing net (#0)
I1027 17:42:41.021183  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54824
I1027 17:42:41.021359  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.786
I1027 17:42:41.021375  9023 solver.cpp:401]     Test net output #2: loss = 2.00666 (* 1 = 2.00666 loss)
I1027 17:42:57.002068  9023 solver.cpp:222] Iteration 83520 (0.644366 iter/s, 62.0765s/40 iters), loss = 1.41974
I1027 17:42:57.002135  9023 solver.cpp:241]     Train net output #0: loss = 1.41974 (* 1 = 1.41974 loss)
I1027 17:42:57.002151  9023 sgd_solver.cpp:105] Iteration 83520, lr = 0.00444386
I1027 17:43:27.492818  9023 solver.cpp:222] Iteration 83560 (1.31193 iter/s, 30.4895s/40 iters), loss = 1.48799
I1027 17:43:27.493006  9023 solver.cpp:241]     Train net output #0: loss = 1.48799 (* 1 = 1.48799 loss)
I1027 17:43:27.493023  9023 sgd_solver.cpp:105] Iteration 83560, lr = 0.00444139
I1027 17:43:57.916716  9023 solver.cpp:222] Iteration 83600 (1.31481 iter/s, 30.4225s/40 iters), loss = 1.95347
I1027 17:43:57.916887  9023 solver.cpp:241]     Train net output #0: loss = 1.95347 (* 1 = 1.95347 loss)
I1027 17:43:57.916904  9023 sgd_solver.cpp:105] Iteration 83600, lr = 0.00443893
I1027 17:44:29.213229  9023 solver.cpp:222] Iteration 83640 (1.27815 iter/s, 31.2951s/40 iters), loss = 2.01613
I1027 17:44:29.213459  9023 solver.cpp:241]     Train net output #0: loss = 2.01613 (* 1 = 2.01613 loss)
I1027 17:44:29.213487  9023 sgd_solver.cpp:105] Iteration 83640, lr = 0.00443646
I1027 17:45:00.588230  9023 solver.cpp:222] Iteration 83680 (1.27496 iter/s, 31.3736s/40 iters), loss = 1.66742
I1027 17:45:00.588403  9023 solver.cpp:241]     Train net output #0: loss = 1.66742 (* 1 = 1.66742 loss)
I1027 17:45:00.588420  9023 sgd_solver.cpp:105] Iteration 83680, lr = 0.00443399
I1027 17:45:32.396903  9023 solver.cpp:222] Iteration 83720 (1.25757 iter/s, 31.8073s/40 iters), loss = 1.78503
I1027 17:45:32.397097  9023 solver.cpp:241]     Train net output #0: loss = 1.78503 (* 1 = 1.78503 loss)
I1027 17:45:32.397114  9023 sgd_solver.cpp:105] Iteration 83720, lr = 0.00443153
I1027 17:46:03.096055  9023 solver.cpp:222] Iteration 83760 (1.30303 iter/s, 30.6978s/40 iters), loss = 1.60848
I1027 17:46:03.096235  9023 solver.cpp:241]     Train net output #0: loss = 1.60848 (* 1 = 1.60848 loss)
I1027 17:46:03.096251  9023 sgd_solver.cpp:105] Iteration 83760, lr = 0.00442906
I1027 17:46:33.619273  9023 solver.cpp:222] Iteration 83800 (1.31053 iter/s, 30.5219s/40 iters), loss = 1.57267
I1027 17:46:33.619436  9023 solver.cpp:241]     Train net output #0: loss = 1.57267 (* 1 = 1.57267 loss)
I1027 17:46:33.619451  9023 sgd_solver.cpp:105] Iteration 83800, lr = 0.0044266
I1027 17:47:04.155980  9023 solver.cpp:222] Iteration 83840 (1.30996 iter/s, 30.5354s/40 iters), loss = 1.61583
I1027 17:47:04.156152  9023 solver.cpp:241]     Train net output #0: loss = 1.61583 (* 1 = 1.61583 loss)
I1027 17:47:04.156167  9023 sgd_solver.cpp:105] Iteration 83840, lr = 0.00442413
I1027 17:47:34.878954  9023 solver.cpp:222] Iteration 83880 (1.30201 iter/s, 30.7216s/40 iters), loss = 1.73131
I1027 17:47:34.879120  9023 solver.cpp:241]     Train net output #0: loss = 1.73131 (* 1 = 1.73131 loss)
I1027 17:47:34.879137  9023 sgd_solver.cpp:105] Iteration 83880, lr = 0.00442167
I1027 17:48:05.866678  9023 solver.cpp:222] Iteration 83920 (1.29089 iter/s, 30.9864s/40 iters), loss = 1.77618
I1027 17:48:05.866849  9023 solver.cpp:241]     Train net output #0: loss = 1.77618 (* 1 = 1.77618 loss)
I1027 17:48:05.866865  9023 sgd_solver.cpp:105] Iteration 83920, lr = 0.0044192
I1027 17:48:36.727741  9023 solver.cpp:222] Iteration 83960 (1.29619 iter/s, 30.8597s/40 iters), loss = 1.70917
I1027 17:48:36.727901  9023 solver.cpp:241]     Train net output #0: loss = 1.70917 (* 1 = 1.70917 loss)
I1027 17:48:36.727917  9023 sgd_solver.cpp:105] Iteration 83960, lr = 0.00441674
I1027 17:49:06.653668  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_84000.caffemodel
I1027 17:49:06.684645  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_84000.solverstate
I1027 17:49:06.701009  9023 solver.cpp:334] Iteration 84000, Testing net (#0)
I1027 17:49:38.231734  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 17:49:38.443729  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54324
I1027 17:49:38.443792  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78244
I1027 17:49:38.443806  9023 solver.cpp:401]     Test net output #2: loss = 2.03543 (* 1 = 2.03543 loss)
I1027 17:49:39.213919  9023 solver.cpp:222] Iteration 84000 (0.640167 iter/s, 62.4837s/40 iters), loss = 1.48193
I1027 17:49:39.213985  9023 solver.cpp:241]     Train net output #0: loss = 1.48193 (* 1 = 1.48193 loss)
I1027 17:49:39.214001  9023 sgd_solver.cpp:105] Iteration 84000, lr = 0.00441428
I1027 17:50:09.767891  9023 solver.cpp:222] Iteration 84040 (1.30921 iter/s, 30.5527s/40 iters), loss = 1.44102
I1027 17:50:09.768087  9023 solver.cpp:241]     Train net output #0: loss = 1.44102 (* 1 = 1.44102 loss)
I1027 17:50:09.768105  9023 sgd_solver.cpp:105] Iteration 84040, lr = 0.00441181
I1027 17:50:39.893285  9023 solver.cpp:222] Iteration 84080 (1.32784 iter/s, 30.1241s/40 iters), loss = 1.49942
I1027 17:50:39.893489  9023 solver.cpp:241]     Train net output #0: loss = 1.49942 (* 1 = 1.49942 loss)
I1027 17:50:39.893506  9023 sgd_solver.cpp:105] Iteration 84080, lr = 0.00440935
I1027 17:51:10.314039  9023 solver.cpp:222] Iteration 84120 (1.31495 iter/s, 30.4194s/40 iters), loss = 1.73794
I1027 17:51:10.314240  9023 solver.cpp:241]     Train net output #0: loss = 1.73794 (* 1 = 1.73794 loss)
I1027 17:51:10.314257  9023 sgd_solver.cpp:105] Iteration 84120, lr = 0.00440689
I1027 17:51:39.991116  9023 solver.cpp:222] Iteration 84160 (1.3479 iter/s, 29.6758s/40 iters), loss = 2.00668
I1027 17:51:39.991183  9023 solver.cpp:241]     Train net output #0: loss = 2.00668 (* 1 = 2.00668 loss)
I1027 17:51:39.991199  9023 sgd_solver.cpp:105] Iteration 84160, lr = 0.00440442
I1027 17:52:09.860231  9023 solver.cpp:222] Iteration 84200 (1.33923 iter/s, 29.8679s/40 iters), loss = 1.81363
I1027 17:52:09.860399  9023 solver.cpp:241]     Train net output #0: loss = 1.81363 (* 1 = 1.81363 loss)
I1027 17:52:09.860415  9023 sgd_solver.cpp:105] Iteration 84200, lr = 0.00440196
I1027 17:52:39.469719  9023 solver.cpp:222] Iteration 84240 (1.35098 iter/s, 29.6082s/40 iters), loss = 1.5557
I1027 17:52:39.469786  9023 solver.cpp:241]     Train net output #0: loss = 1.5557 (* 1 = 1.5557 loss)
I1027 17:52:39.469801  9023 sgd_solver.cpp:105] Iteration 84240, lr = 0.0043995
I1027 17:53:09.136631  9023 solver.cpp:222] Iteration 84280 (1.34836 iter/s, 29.6657s/40 iters), loss = 1.75578
I1027 17:53:09.136785  9023 solver.cpp:241]     Train net output #0: loss = 1.75578 (* 1 = 1.75578 loss)
I1027 17:53:09.136801  9023 sgd_solver.cpp:105] Iteration 84280, lr = 0.00439703
I1027 17:53:38.757074  9023 solver.cpp:222] Iteration 84320 (1.35048 iter/s, 29.6192s/40 iters), loss = 1.96652
I1027 17:53:38.757145  9023 solver.cpp:241]     Train net output #0: loss = 1.96652 (* 1 = 1.96652 loss)
I1027 17:53:38.757159  9023 sgd_solver.cpp:105] Iteration 84320, lr = 0.00439457
I1027 17:54:09.050751  9023 solver.cpp:222] Iteration 84360 (1.32046 iter/s, 30.2925s/40 iters), loss = 1.59865
I1027 17:54:09.050930  9023 solver.cpp:241]     Train net output #0: loss = 1.59865 (* 1 = 1.59865 loss)
I1027 17:54:09.050945  9023 sgd_solver.cpp:105] Iteration 84360, lr = 0.00439211
I1027 17:54:40.358846  9023 solver.cpp:222] Iteration 84400 (1.27768 iter/s, 31.3067s/40 iters), loss = 1.48708
I1027 17:54:40.359102  9023 solver.cpp:241]     Train net output #0: loss = 1.48708 (* 1 = 1.48708 loss)
I1027 17:54:40.359123  9023 sgd_solver.cpp:105] Iteration 84400, lr = 0.00438965
I1027 17:55:12.019338  9023 solver.cpp:222] Iteration 84440 (1.26346 iter/s, 31.659s/40 iters), loss = 1.75894
I1027 17:55:12.019708  9023 solver.cpp:241]     Train net output #0: loss = 1.75894 (* 1 = 1.75894 loss)
I1027 17:55:12.019735  9023 sgd_solver.cpp:105] Iteration 84440, lr = 0.00438719
I1027 17:55:45.115480  9023 solver.cpp:222] Iteration 84480 (1.20866 iter/s, 33.0945s/40 iters), loss = 1.5629
I1027 17:55:45.115695  9023 solver.cpp:241]     Train net output #0: loss = 1.5629 (* 1 = 1.5629 loss)
I1027 17:55:45.115717  9023 sgd_solver.cpp:105] Iteration 84480, lr = 0.00438473
I1027 17:56:00.852196  9023 solver.cpp:334] Iteration 84500, Testing net (#0)
I1027 17:56:33.974884  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54792
I1027 17:56:33.975070  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78424
I1027 17:56:33.975085  9023 solver.cpp:401]     Test net output #2: loss = 2.00042 (* 1 = 2.00042 loss)
I1027 17:56:45.496767  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1027 17:56:49.970563  9023 solver.cpp:222] Iteration 84520 (0.616785 iter/s, 64.8524s/40 iters), loss = 1.81287
I1027 17:56:49.970636  9023 solver.cpp:241]     Train net output #0: loss = 1.81287 (* 1 = 1.81287 loss)
I1027 17:56:49.970651  9023 sgd_solver.cpp:105] Iteration 84520, lr = 0.00438227
I1027 17:57:20.546391  9023 solver.cpp:222] Iteration 84560 (1.30828 iter/s, 30.5746s/40 iters), loss = 1.63363
I1027 17:57:20.546583  9023 solver.cpp:241]     Train net output #0: loss = 1.63363 (* 1 = 1.63363 loss)
I1027 17:57:20.546600  9023 sgd_solver.cpp:105] Iteration 84560, lr = 0.00437981
I1027 17:57:50.914672  9023 solver.cpp:222] Iteration 84600 (1.31722 iter/s, 30.3669s/40 iters), loss = 1.39006
I1027 17:57:50.914846  9023 solver.cpp:241]     Train net output #0: loss = 1.39006 (* 1 = 1.39006 loss)
I1027 17:57:50.914862  9023 sgd_solver.cpp:105] Iteration 84600, lr = 0.00437734
I1027 17:58:21.502127  9023 solver.cpp:222] Iteration 84640 (1.30778 iter/s, 30.5861s/40 iters), loss = 1.50723
I1027 17:58:21.502295  9023 solver.cpp:241]     Train net output #0: loss = 1.50723 (* 1 = 1.50723 loss)
I1027 17:58:21.502316  9023 sgd_solver.cpp:105] Iteration 84640, lr = 0.00437488
I1027 17:58:51.939692  9023 solver.cpp:222] Iteration 84680 (1.31422 iter/s, 30.4362s/40 iters), loss = 1.70542
I1027 17:58:51.939859  9023 solver.cpp:241]     Train net output #0: loss = 1.70542 (* 1 = 1.70542 loss)
I1027 17:58:51.939875  9023 sgd_solver.cpp:105] Iteration 84680, lr = 0.00437242
I1027 17:59:23.425951  9023 solver.cpp:222] Iteration 84720 (1.27045 iter/s, 31.4849s/40 iters), loss = 1.57123
I1027 17:59:23.426164  9023 solver.cpp:241]     Train net output #0: loss = 1.57123 (* 1 = 1.57123 loss)
I1027 17:59:23.426182  9023 sgd_solver.cpp:105] Iteration 84720, lr = 0.00436996
I1027 17:59:54.796958  9023 solver.cpp:222] Iteration 84760 (1.27512 iter/s, 31.3696s/40 iters), loss = 1.63356
I1027 17:59:54.797143  9023 solver.cpp:241]     Train net output #0: loss = 1.63356 (* 1 = 1.63356 loss)
I1027 17:59:54.797159  9023 sgd_solver.cpp:105] Iteration 84760, lr = 0.00436751
I1027 18:00:27.347654  9023 solver.cpp:222] Iteration 84800 (1.22891 iter/s, 32.5493s/40 iters), loss = 1.52859
I1027 18:00:27.347894  9023 solver.cpp:241]     Train net output #0: loss = 1.52859 (* 1 = 1.52859 loss)
I1027 18:00:27.347925  9023 sgd_solver.cpp:105] Iteration 84800, lr = 0.00436505
I1027 18:00:59.066413  9023 solver.cpp:222] Iteration 84840 (1.26114 iter/s, 31.7173s/40 iters), loss = 1.92566
I1027 18:00:59.066598  9023 solver.cpp:241]     Train net output #0: loss = 1.92566 (* 1 = 1.92566 loss)
I1027 18:00:59.066614  9023 sgd_solver.cpp:105] Iteration 84840, lr = 0.00436259
I1027 18:01:29.800225  9023 solver.cpp:222] Iteration 84880 (1.30156 iter/s, 30.7325s/40 iters), loss = 1.535
I1027 18:01:29.800417  9023 solver.cpp:241]     Train net output #0: loss = 1.535 (* 1 = 1.535 loss)
I1027 18:01:29.800433  9023 sgd_solver.cpp:105] Iteration 84880, lr = 0.00436013
I1027 18:02:00.510839  9023 solver.cpp:222] Iteration 84920 (1.30254 iter/s, 30.7093s/40 iters), loss = 1.4186
I1027 18:02:00.511068  9023 solver.cpp:241]     Train net output #0: loss = 1.4186 (* 1 = 1.4186 loss)
I1027 18:02:00.511086  9023 sgd_solver.cpp:105] Iteration 84920, lr = 0.00435767
I1027 18:02:31.196671  9023 solver.cpp:222] Iteration 84960 (1.30359 iter/s, 30.6844s/40 iters), loss = 1.79114
I1027 18:02:31.196856  9023 solver.cpp:241]     Train net output #0: loss = 1.79114 (* 1 = 1.79114 loss)
I1027 18:02:31.196873  9023 sgd_solver.cpp:105] Iteration 84960, lr = 0.00435521
I1027 18:03:01.166229  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_85000.caffemodel
I1027 18:03:01.223750  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_85000.solverstate
I1027 18:03:01.245713  9023 solver.cpp:334] Iteration 85000, Testing net (#0)
I1027 18:03:33.643965  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 18:03:33.855952  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55024
I1027 18:03:33.856019  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78876
I1027 18:03:33.856034  9023 solver.cpp:401]     Test net output #2: loss = 1.99964 (* 1 = 1.99964 loss)
I1027 18:03:34.625077  9023 solver.cpp:222] Iteration 85000 (0.630658 iter/s, 63.4258s/40 iters), loss = 1.33081
I1027 18:03:34.625135  9023 solver.cpp:241]     Train net output #0: loss = 1.33081 (* 1 = 1.33081 loss)
I1027 18:03:34.625150  9023 sgd_solver.cpp:105] Iteration 85000, lr = 0.00435275
I1027 18:04:05.464555  9023 solver.cpp:222] Iteration 85040 (1.29709 iter/s, 30.8383s/40 iters), loss = 1.76795
I1027 18:04:05.464746  9023 solver.cpp:241]     Train net output #0: loss = 1.76795 (* 1 = 1.76795 loss)
I1027 18:04:05.464763  9023 sgd_solver.cpp:105] Iteration 85040, lr = 0.00435029
I1027 18:04:36.920564  9023 solver.cpp:222] Iteration 85080 (1.27167 iter/s, 31.4546s/40 iters), loss = 1.37251
I1027 18:04:36.920759  9023 solver.cpp:241]     Train net output #0: loss = 1.37251 (* 1 = 1.37251 loss)
I1027 18:04:36.920776  9023 sgd_solver.cpp:105] Iteration 85080, lr = 0.00434784
I1027 18:05:07.876746  9023 solver.cpp:222] Iteration 85120 (1.29221 iter/s, 30.9548s/40 iters), loss = 1.84061
I1027 18:05:07.876912  9023 solver.cpp:241]     Train net output #0: loss = 1.84061 (* 1 = 1.84061 loss)
I1027 18:05:07.876929  9023 sgd_solver.cpp:105] Iteration 85120, lr = 0.00434538
I1027 18:05:38.992800  9023 solver.cpp:222] Iteration 85160 (1.28557 iter/s, 31.1147s/40 iters), loss = 1.53574
I1027 18:05:38.992982  9023 solver.cpp:241]     Train net output #0: loss = 1.53574 (* 1 = 1.53574 loss)
I1027 18:05:38.992998  9023 sgd_solver.cpp:105] Iteration 85160, lr = 0.00434292
I1027 18:06:09.931392  9023 solver.cpp:222] Iteration 85200 (1.29294 iter/s, 30.9372s/40 iters), loss = 1.85285
I1027 18:06:09.931655  9023 solver.cpp:241]     Train net output #0: loss = 1.85285 (* 1 = 1.85285 loss)
I1027 18:06:09.931681  9023 sgd_solver.cpp:105] Iteration 85200, lr = 0.00434047
I1027 18:06:41.213882  9023 solver.cpp:222] Iteration 85240 (1.27873 iter/s, 31.2811s/40 iters), loss = 1.93338
I1027 18:06:41.214079  9023 solver.cpp:241]     Train net output #0: loss = 1.93338 (* 1 = 1.93338 loss)
I1027 18:06:41.214097  9023 sgd_solver.cpp:105] Iteration 85240, lr = 0.00433801
I1027 18:07:12.370272  9023 solver.cpp:222] Iteration 85280 (1.2839 iter/s, 31.155s/40 iters), loss = 1.48457
I1027 18:07:12.370524  9023 solver.cpp:241]     Train net output #0: loss = 1.48457 (* 1 = 1.48457 loss)
I1027 18:07:12.370599  9023 sgd_solver.cpp:105] Iteration 85280, lr = 0.00433555
I1027 18:07:44.310564  9023 solver.cpp:222] Iteration 85320 (1.25239 iter/s, 31.9389s/40 iters), loss = 1.55249
I1027 18:07:44.310768  9023 solver.cpp:241]     Train net output #0: loss = 1.55249 (* 1 = 1.55249 loss)
I1027 18:07:44.310786  9023 sgd_solver.cpp:105] Iteration 85320, lr = 0.0043331
I1027 18:08:15.921711  9023 solver.cpp:222] Iteration 85360 (1.26543 iter/s, 31.6098s/40 iters), loss = 1.80271
I1027 18:08:15.921933  9023 solver.cpp:241]     Train net output #0: loss = 1.80271 (* 1 = 1.80271 loss)
I1027 18:08:15.921978  9023 sgd_solver.cpp:105] Iteration 85360, lr = 0.00433064
I1027 18:08:47.481590  9023 solver.cpp:222] Iteration 85400 (1.26749 iter/s, 31.5585s/40 iters), loss = 1.71759
I1027 18:08:47.481827  9023 solver.cpp:241]     Train net output #0: loss = 1.71759 (* 1 = 1.71759 loss)
I1027 18:08:47.481848  9023 sgd_solver.cpp:105] Iteration 85400, lr = 0.00432818
I1027 18:09:18.473697  9023 solver.cpp:222] Iteration 85440 (1.29071 iter/s, 30.9906s/40 iters), loss = 1.73624
I1027 18:09:18.473866  9023 solver.cpp:241]     Train net output #0: loss = 1.73624 (* 1 = 1.73624 loss)
I1027 18:09:18.473882  9023 sgd_solver.cpp:105] Iteration 85440, lr = 0.00432573
I1027 18:09:49.683537  9023 solver.cpp:222] Iteration 85480 (1.2817 iter/s, 31.2085s/40 iters), loss = 1.47962
I1027 18:09:49.683704  9023 solver.cpp:241]     Train net output #0: loss = 1.47962 (* 1 = 1.47962 loss)
I1027 18:09:49.683719  9023 sgd_solver.cpp:105] Iteration 85480, lr = 0.00432327
I1027 18:10:04.251948  9023 solver.cpp:334] Iteration 85500, Testing net (#0)
I1027 18:10:35.657011  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55188
I1027 18:10:35.657167  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78584
I1027 18:10:35.657183  9023 solver.cpp:401]     Test net output #2: loss = 1.9693 (* 1 = 1.9693 loss)
I1027 18:10:51.793817  9023 solver.cpp:222] Iteration 85520 (0.644042 iter/s, 62.1078s/40 iters), loss = 1.7228
I1027 18:10:51.793884  9023 solver.cpp:241]     Train net output #0: loss = 1.7228 (* 1 = 1.7228 loss)
I1027 18:10:51.793898  9023 sgd_solver.cpp:105] Iteration 85520, lr = 0.00432082
I1027 18:11:22.432873  9023 solver.cpp:222] Iteration 85560 (1.30558 iter/s, 30.6378s/40 iters), loss = 1.66517
I1027 18:11:22.433069  9023 solver.cpp:241]     Train net output #0: loss = 1.66517 (* 1 = 1.66517 loss)
I1027 18:11:22.433085  9023 sgd_solver.cpp:105] Iteration 85560, lr = 0.00431836
I1027 18:11:53.105546  9023 solver.cpp:222] Iteration 85600 (1.30415 iter/s, 30.6713s/40 iters), loss = 1.59351
I1027 18:11:53.105723  9023 solver.cpp:241]     Train net output #0: loss = 1.59351 (* 1 = 1.59351 loss)
I1027 18:11:53.105738  9023 sgd_solver.cpp:105] Iteration 85600, lr = 0.00431591
I1027 18:12:23.722636  9023 solver.cpp:222] Iteration 85640 (1.30652 iter/s, 30.6158s/40 iters), loss = 1.62377
I1027 18:12:23.722779  9023 solver.cpp:241]     Train net output #0: loss = 1.62377 (* 1 = 1.62377 loss)
I1027 18:12:23.722795  9023 sgd_solver.cpp:105] Iteration 85640, lr = 0.00431345
I1027 18:12:54.324734  9023 solver.cpp:222] Iteration 85680 (1.30716 iter/s, 30.6008s/40 iters), loss = 1.52058
I1027 18:12:54.324828  9023 solver.cpp:241]     Train net output #0: loss = 1.52058 (* 1 = 1.52058 loss)
I1027 18:12:54.324843  9023 sgd_solver.cpp:105] Iteration 85680, lr = 0.004311
I1027 18:13:24.994786  9023 solver.cpp:222] Iteration 85720 (1.30426 iter/s, 30.6688s/40 iters), loss = 1.38522
I1027 18:13:24.994886  9023 solver.cpp:241]     Train net output #0: loss = 1.38522 (* 1 = 1.38522 loss)
I1027 18:13:24.994901  9023 sgd_solver.cpp:105] Iteration 85720, lr = 0.00430855
I1027 18:13:55.771908  9023 solver.cpp:222] Iteration 85760 (1.29972 iter/s, 30.7759s/40 iters), loss = 1.49231
I1027 18:13:55.772064  9023 solver.cpp:241]     Train net output #0: loss = 1.49231 (* 1 = 1.49231 loss)
I1027 18:13:55.772080  9023 sgd_solver.cpp:105] Iteration 85760, lr = 0.00430609
I1027 18:14:26.520802  9023 solver.cpp:222] Iteration 85800 (1.30092 iter/s, 30.7476s/40 iters), loss = 1.65208
I1027 18:14:26.520963  9023 solver.cpp:241]     Train net output #0: loss = 1.65208 (* 1 = 1.65208 loss)
I1027 18:14:26.520979  9023 sgd_solver.cpp:105] Iteration 85800, lr = 0.00430364
I1027 18:14:57.131892  9023 solver.cpp:222] Iteration 85840 (1.30677 iter/s, 30.6098s/40 iters), loss = 1.44929
I1027 18:14:57.132050  9023 solver.cpp:241]     Train net output #0: loss = 1.44929 (* 1 = 1.44929 loss)
I1027 18:14:57.132064  9023 sgd_solver.cpp:105] Iteration 85840, lr = 0.00430119
I1027 18:15:28.410601  9023 solver.cpp:222] Iteration 85880 (1.27888 iter/s, 31.2774s/40 iters), loss = 1.69555
I1027 18:15:28.410895  9023 solver.cpp:241]     Train net output #0: loss = 1.69555 (* 1 = 1.69555 loss)
I1027 18:15:28.410920  9023 sgd_solver.cpp:105] Iteration 85880, lr = 0.00429873
I1027 18:16:00.144217  9023 solver.cpp:222] Iteration 85920 (1.26055 iter/s, 31.7321s/40 iters), loss = 1.73048
I1027 18:16:00.144413  9023 solver.cpp:241]     Train net output #0: loss = 1.73048 (* 1 = 1.73048 loss)
I1027 18:16:00.144429  9023 sgd_solver.cpp:105] Iteration 85920, lr = 0.00429628
I1027 18:16:30.889173  9023 solver.cpp:222] Iteration 85960 (1.30108 iter/s, 30.7436s/40 iters), loss = 1.73987
I1027 18:16:30.889331  9023 solver.cpp:241]     Train net output #0: loss = 1.73987 (* 1 = 1.73987 loss)
I1027 18:16:30.889348  9023 sgd_solver.cpp:105] Iteration 85960, lr = 0.00429383
I1027 18:17:00.941028  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_86000.caffemodel
I1027 18:17:00.972504  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_86000.solverstate
I1027 18:17:00.989789  9023 solver.cpp:334] Iteration 86000, Testing net (#0)
I1027 18:17:32.131518  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 18:17:32.342455  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55156
I1027 18:17:32.342515  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7874
I1027 18:17:32.342530  9023 solver.cpp:401]     Test net output #2: loss = 1.97481 (* 1 = 1.97481 loss)
I1027 18:17:33.109763  9023 solver.cpp:222] Iteration 86000 (0.6429 iter/s, 62.2181s/40 iters), loss = 1.4634
I1027 18:17:33.109825  9023 solver.cpp:241]     Train net output #0: loss = 1.4634 (* 1 = 1.4634 loss)
I1027 18:17:33.109840  9023 sgd_solver.cpp:105] Iteration 86000, lr = 0.00429137
I1027 18:18:03.765817  9023 solver.cpp:222] Iteration 86040 (1.30485 iter/s, 30.6548s/40 iters), loss = 1.42875
I1027 18:18:03.765995  9023 solver.cpp:241]     Train net output #0: loss = 1.42875 (* 1 = 1.42875 loss)
I1027 18:18:03.766012  9023 sgd_solver.cpp:105] Iteration 86040, lr = 0.00428892
I1027 18:18:34.765744  9023 solver.cpp:222] Iteration 86080 (1.29038 iter/s, 30.9986s/40 iters), loss = 1.66648
I1027 18:18:34.765913  9023 solver.cpp:241]     Train net output #0: loss = 1.66648 (* 1 = 1.66648 loss)
I1027 18:18:34.765929  9023 sgd_solver.cpp:105] Iteration 86080, lr = 0.00428647
I1027 18:19:05.478761  9023 solver.cpp:222] Iteration 86120 (1.30244 iter/s, 30.7117s/40 iters), loss = 1.65083
I1027 18:19:05.478947  9023 solver.cpp:241]     Train net output #0: loss = 1.65083 (* 1 = 1.65083 loss)
I1027 18:19:05.478965  9023 sgd_solver.cpp:105] Iteration 86120, lr = 0.00428402
I1027 18:19:36.231057  9023 solver.cpp:222] Iteration 86160 (1.30077 iter/s, 30.7509s/40 iters), loss = 1.79629
I1027 18:19:36.231232  9023 solver.cpp:241]     Train net output #0: loss = 1.79629 (* 1 = 1.79629 loss)
I1027 18:19:36.231251  9023 sgd_solver.cpp:105] Iteration 86160, lr = 0.00428157
I1027 18:20:07.018426  9023 solver.cpp:222] Iteration 86200 (1.29929 iter/s, 30.786s/40 iters), loss = 1.73121
I1027 18:20:07.018606  9023 solver.cpp:241]     Train net output #0: loss = 1.73121 (* 1 = 1.73121 loss)
I1027 18:20:07.018623  9023 sgd_solver.cpp:105] Iteration 86200, lr = 0.00427912
I1027 18:20:37.527726  9023 solver.cpp:222] Iteration 86240 (1.31113 iter/s, 30.508s/40 iters), loss = 1.53074
I1027 18:20:37.527899  9023 solver.cpp:241]     Train net output #0: loss = 1.53074 (* 1 = 1.53074 loss)
I1027 18:20:37.527916  9023 sgd_solver.cpp:105] Iteration 86240, lr = 0.00427667
I1027 18:21:11.156428  9023 solver.cpp:222] Iteration 86280 (1.18951 iter/s, 33.6273s/40 iters), loss = 2.03213
I1027 18:21:11.156685  9023 solver.cpp:241]     Train net output #0: loss = 2.03213 (* 1 = 2.03213 loss)
I1027 18:21:11.156708  9023 sgd_solver.cpp:105] Iteration 86280, lr = 0.00427421
I1027 18:21:43.251317  9023 solver.cpp:222] Iteration 86320 (1.24636 iter/s, 32.0934s/40 iters), loss = 1.60038
I1027 18:21:43.251652  9023 solver.cpp:241]     Train net output #0: loss = 1.60038 (* 1 = 1.60038 loss)
I1027 18:21:43.251682  9023 sgd_solver.cpp:105] Iteration 86320, lr = 0.00427176
I1027 18:22:13.842489  9023 solver.cpp:222] Iteration 86360 (1.30763 iter/s, 30.5897s/40 iters), loss = 1.70279
I1027 18:22:13.842679  9023 solver.cpp:241]     Train net output #0: loss = 1.70279 (* 1 = 1.70279 loss)
I1027 18:22:13.842695  9023 sgd_solver.cpp:105] Iteration 86360, lr = 0.00426931
I1027 18:22:44.464577  9023 solver.cpp:222] Iteration 86400 (1.3063 iter/s, 30.6207s/40 iters), loss = 1.31177
I1027 18:22:44.464754  9023 solver.cpp:241]     Train net output #0: loss = 1.31177 (* 1 = 1.31177 loss)
I1027 18:22:44.464771  9023 sgd_solver.cpp:105] Iteration 86400, lr = 0.00426686
I1027 18:23:15.225456  9023 solver.cpp:222] Iteration 86440 (1.30041 iter/s, 30.7595s/40 iters), loss = 1.67568
I1027 18:23:15.225653  9023 solver.cpp:241]     Train net output #0: loss = 1.67568 (* 1 = 1.67568 loss)
I1027 18:23:15.225672  9023 sgd_solver.cpp:105] Iteration 86440, lr = 0.00426441
I1027 18:23:46.051693  9023 solver.cpp:222] Iteration 86480 (1.29765 iter/s, 30.8249s/40 iters), loss = 1.66665
I1027 18:23:46.051920  9023 solver.cpp:241]     Train net output #0: loss = 1.66665 (* 1 = 1.66665 loss)
I1027 18:23:46.051942  9023 sgd_solver.cpp:105] Iteration 86480, lr = 0.00426196
I1027 18:24:02.291752  9023 solver.cpp:334] Iteration 86500, Testing net (#0)
I1027 18:24:34.012369  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5538
I1027 18:24:34.012573  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.789519
I1027 18:24:34.012588  9023 solver.cpp:401]     Test net output #2: loss = 1.96802 (* 1 = 1.96802 loss)
I1027 18:24:50.937428  9023 solver.cpp:222] Iteration 86520 (0.616494 iter/s, 64.8831s/40 iters), loss = 1.59529
I1027 18:24:50.937500  9023 solver.cpp:241]     Train net output #0: loss = 1.59529 (* 1 = 1.59529 loss)
I1027 18:24:50.937515  9023 sgd_solver.cpp:105] Iteration 86520, lr = 0.00425952
I1027 18:25:22.459344  9023 solver.cpp:222] Iteration 86560 (1.26901 iter/s, 31.5206s/40 iters), loss = 1.56147
I1027 18:25:22.459564  9023 solver.cpp:241]     Train net output #0: loss = 1.56147 (* 1 = 1.56147 loss)
I1027 18:25:22.459590  9023 sgd_solver.cpp:105] Iteration 86560, lr = 0.00425707
I1027 18:25:53.255143  9023 solver.cpp:222] Iteration 86600 (1.29894 iter/s, 30.7944s/40 iters), loss = 1.55104
I1027 18:25:53.255324  9023 solver.cpp:241]     Train net output #0: loss = 1.55104 (* 1 = 1.55104 loss)
I1027 18:25:53.255342  9023 sgd_solver.cpp:105] Iteration 86600, lr = 0.00425462
I1027 18:26:24.480922  9023 solver.cpp:222] Iteration 86640 (1.28105 iter/s, 31.2244s/40 iters), loss = 1.64961
I1027 18:26:24.481145  9023 solver.cpp:241]     Train net output #0: loss = 1.64961 (* 1 = 1.64961 loss)
I1027 18:26:24.481169  9023 sgd_solver.cpp:105] Iteration 86640, lr = 0.00425217
I1027 18:26:56.670621  9023 solver.cpp:222] Iteration 86680 (1.24269 iter/s, 32.1883s/40 iters), loss = 1.50647
I1027 18:26:56.670838  9023 solver.cpp:241]     Train net output #0: loss = 1.50647 (* 1 = 1.50647 loss)
I1027 18:26:56.670864  9023 sgd_solver.cpp:105] Iteration 86680, lr = 0.00424972
I1027 18:27:29.177445  9023 solver.cpp:222] Iteration 86720 (1.23057 iter/s, 32.5054s/40 iters), loss = 1.36819
I1027 18:27:29.177642  9023 solver.cpp:241]     Train net output #0: loss = 1.36819 (* 1 = 1.36819 loss)
I1027 18:27:29.177659  9023 sgd_solver.cpp:105] Iteration 86720, lr = 0.00424727
I1027 18:27:59.625041  9023 solver.cpp:222] Iteration 86760 (1.31379 iter/s, 30.4462s/40 iters), loss = 1.6296
I1027 18:27:59.625211  9023 solver.cpp:241]     Train net output #0: loss = 1.6296 (* 1 = 1.6296 loss)
I1027 18:27:59.625227  9023 sgd_solver.cpp:105] Iteration 86760, lr = 0.00424482
I1027 18:28:29.967116  9023 solver.cpp:222] Iteration 86800 (1.31836 iter/s, 30.3407s/40 iters), loss = 1.51435
I1027 18:28:29.967262  9023 solver.cpp:241]     Train net output #0: loss = 1.51435 (* 1 = 1.51435 loss)
I1027 18:28:29.967278  9023 sgd_solver.cpp:105] Iteration 86800, lr = 0.00424238
I1027 18:29:00.328794  9023 solver.cpp:222] Iteration 86840 (1.31751 iter/s, 30.3604s/40 iters), loss = 1.65381
I1027 18:29:00.329018  9023 solver.cpp:241]     Train net output #0: loss = 1.65381 (* 1 = 1.65381 loss)
I1027 18:29:00.329035  9023 sgd_solver.cpp:105] Iteration 86840, lr = 0.00423993
I1027 18:29:30.771776  9023 solver.cpp:222] Iteration 86880 (1.31399 iter/s, 30.4416s/40 iters), loss = 1.69488
I1027 18:29:30.771926  9023 solver.cpp:241]     Train net output #0: loss = 1.69488 (* 1 = 1.69488 loss)
I1027 18:29:30.771941  9023 sgd_solver.cpp:105] Iteration 86880, lr = 0.00423748
I1027 18:30:01.209004  9023 solver.cpp:222] Iteration 86920 (1.31424 iter/s, 30.4359s/40 iters), loss = 1.53359
I1027 18:30:01.209147  9023 solver.cpp:241]     Train net output #0: loss = 1.53359 (* 1 = 1.53359 loss)
I1027 18:30:01.209163  9023 sgd_solver.cpp:105] Iteration 86920, lr = 0.00423504
I1027 18:30:31.632048  9023 solver.cpp:222] Iteration 86960 (1.31485 iter/s, 30.4218s/40 iters), loss = 1.66768
I1027 18:30:31.632215  9023 solver.cpp:241]     Train net output #0: loss = 1.66768 (* 1 = 1.66768 loss)
I1027 18:30:31.632230  9023 sgd_solver.cpp:105] Iteration 86960, lr = 0.00423259
I1027 18:31:08.655107  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_87000.caffemodel
I1027 18:31:09.330963  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_87000.solverstate
I1027 18:31:09.455951  9023 solver.cpp:334] Iteration 87000, Testing net (#0)
I1027 18:31:43.802661  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 18:31:44.003458  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55068
I1027 18:31:44.003559  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79032
I1027 18:31:44.003587  9023 solver.cpp:401]     Test net output #2: loss = 1.98456 (* 1 = 1.98456 loss)
I1027 18:31:44.816318  9023 solver.cpp:222] Iteration 87000 (0.546587 iter/s, 73.1814s/40 iters), loss = 1.98533
I1027 18:31:44.816409  9023 solver.cpp:241]     Train net output #0: loss = 1.98533 (* 1 = 1.98533 loss)
I1027 18:31:44.816431  9023 sgd_solver.cpp:105] Iteration 87000, lr = 0.00423014
I1027 18:31:58.103387  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1027 18:32:16.789487  9023 solver.cpp:222] Iteration 87040 (1.2511 iter/s, 31.9719s/40 iters), loss = 1.66483
I1027 18:32:16.789687  9023 solver.cpp:241]     Train net output #0: loss = 1.66483 (* 1 = 1.66483 loss)
I1027 18:32:16.789705  9023 sgd_solver.cpp:105] Iteration 87040, lr = 0.0042277
I1027 18:32:47.417235  9023 solver.cpp:222] Iteration 87080 (1.30606 iter/s, 30.6264s/40 iters), loss = 1.49486
I1027 18:32:47.417429  9023 solver.cpp:241]     Train net output #0: loss = 1.49486 (* 1 = 1.49486 loss)
I1027 18:32:47.417446  9023 sgd_solver.cpp:105] Iteration 87080, lr = 0.00422525
I1027 18:33:18.925701  9023 solver.cpp:222] Iteration 87120 (1.26956 iter/s, 31.5071s/40 iters), loss = 1.90203
I1027 18:33:18.925873  9023 solver.cpp:241]     Train net output #0: loss = 1.90203 (* 1 = 1.90203 loss)
I1027 18:33:18.925890  9023 sgd_solver.cpp:105] Iteration 87120, lr = 0.0042228
I1027 18:33:50.352210  9023 solver.cpp:222] Iteration 87160 (1.27287 iter/s, 31.4251s/40 iters), loss = 1.5463
I1027 18:33:50.352412  9023 solver.cpp:241]     Train net output #0: loss = 1.5463 (* 1 = 1.5463 loss)
I1027 18:33:50.352434  9023 sgd_solver.cpp:105] Iteration 87160, lr = 0.00422036
I1027 18:34:21.546005  9023 solver.cpp:222] Iteration 87200 (1.28236 iter/s, 31.1924s/40 iters), loss = 1.57471
I1027 18:34:21.546177  9023 solver.cpp:241]     Train net output #0: loss = 1.57471 (* 1 = 1.57471 loss)
I1027 18:34:21.546192  9023 sgd_solver.cpp:105] Iteration 87200, lr = 0.00421791
I1027 18:34:52.684093  9023 solver.cpp:222] Iteration 87240 (1.28466 iter/s, 31.1367s/40 iters), loss = 1.64586
I1027 18:34:52.684289  9023 solver.cpp:241]     Train net output #0: loss = 1.64586 (* 1 = 1.64586 loss)
I1027 18:34:52.684324  9023 sgd_solver.cpp:105] Iteration 87240, lr = 0.00421547
I1027 18:35:24.445994  9023 solver.cpp:222] Iteration 87280 (1.25943 iter/s, 31.7605s/40 iters), loss = 1.74921
I1027 18:35:24.446234  9023 solver.cpp:241]     Train net output #0: loss = 1.74921 (* 1 = 1.74921 loss)
I1027 18:35:24.446251  9023 sgd_solver.cpp:105] Iteration 87280, lr = 0.00421302
I1027 18:35:55.597905  9023 solver.cpp:222] Iteration 87320 (1.28409 iter/s, 31.1505s/40 iters), loss = 1.40125
I1027 18:35:55.598094  9023 solver.cpp:241]     Train net output #0: loss = 1.40125 (* 1 = 1.40125 loss)
I1027 18:35:55.598110  9023 sgd_solver.cpp:105] Iteration 87320, lr = 0.00421058
I1027 18:36:26.448040  9023 solver.cpp:222] Iteration 87360 (1.29665 iter/s, 30.8488s/40 iters), loss = 1.72566
I1027 18:36:26.448248  9023 solver.cpp:241]     Train net output #0: loss = 1.72566 (* 1 = 1.72566 loss)
I1027 18:36:26.448264  9023 sgd_solver.cpp:105] Iteration 87360, lr = 0.00420813
I1027 18:36:57.158130  9023 solver.cpp:222] Iteration 87400 (1.30256 iter/s, 30.7087s/40 iters), loss = 1.72189
I1027 18:36:57.158319  9023 solver.cpp:241]     Train net output #0: loss = 1.72189 (* 1 = 1.72189 loss)
I1027 18:36:57.158335  9023 sgd_solver.cpp:105] Iteration 87400, lr = 0.00420569
I1027 18:37:28.548717  9023 solver.cpp:222] Iteration 87440 (1.27432 iter/s, 31.3892s/40 iters), loss = 1.81347
I1027 18:37:28.548892  9023 solver.cpp:241]     Train net output #0: loss = 1.81347 (* 1 = 1.81347 loss)
I1027 18:37:28.548909  9023 sgd_solver.cpp:105] Iteration 87440, lr = 0.00420325
I1027 18:37:59.611717  9023 solver.cpp:222] Iteration 87480 (1.28776 iter/s, 31.0616s/40 iters), loss = 1.62017
I1027 18:37:59.611884  9023 solver.cpp:241]     Train net output #0: loss = 1.62017 (* 1 = 1.62017 loss)
I1027 18:37:59.611902  9023 sgd_solver.cpp:105] Iteration 87480, lr = 0.0042008
I1027 18:38:14.721694  9023 solver.cpp:334] Iteration 87500, Testing net (#0)
I1027 18:38:46.018997  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5524
I1027 18:38:46.019196  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78772
I1027 18:38:46.019212  9023 solver.cpp:401]     Test net output #2: loss = 1.99139 (* 1 = 1.99139 loss)
I1027 18:39:02.288576  9023 solver.cpp:222] Iteration 87520 (0.63822 iter/s, 62.6743s/40 iters), loss = 1.7942
I1027 18:39:02.288653  9023 solver.cpp:241]     Train net output #0: loss = 1.7942 (* 1 = 1.7942 loss)
I1027 18:39:02.288671  9023 sgd_solver.cpp:105] Iteration 87520, lr = 0.00419836
I1027 18:39:33.222654  9023 solver.cpp:222] Iteration 87560 (1.29312 iter/s, 30.9328s/40 iters), loss = 1.82644
I1027 18:39:33.222860  9023 solver.cpp:241]     Train net output #0: loss = 1.82644 (* 1 = 1.82644 loss)
I1027 18:39:33.222877  9023 sgd_solver.cpp:105] Iteration 87560, lr = 0.00419592
I1027 18:40:04.278969  9023 solver.cpp:222] Iteration 87600 (1.28804 iter/s, 31.0549s/40 iters), loss = 1.47446
I1027 18:40:04.279151  9023 solver.cpp:241]     Train net output #0: loss = 1.47446 (* 1 = 1.47446 loss)
I1027 18:40:04.279166  9023 sgd_solver.cpp:105] Iteration 87600, lr = 0.00419347
I1027 18:40:35.040760  9023 solver.cpp:222] Iteration 87640 (1.30037 iter/s, 30.7604s/40 iters), loss = 1.77294
I1027 18:40:35.040971  9023 solver.cpp:241]     Train net output #0: loss = 1.77294 (* 1 = 1.77294 loss)
I1027 18:40:35.040988  9023 sgd_solver.cpp:105] Iteration 87640, lr = 0.00419103
I1027 18:41:05.756734  9023 solver.cpp:222] Iteration 87680 (1.30231 iter/s, 30.7146s/40 iters), loss = 1.55657
I1027 18:41:05.756927  9023 solver.cpp:241]     Train net output #0: loss = 1.55657 (* 1 = 1.55657 loss)
I1027 18:41:05.756942  9023 sgd_solver.cpp:105] Iteration 87680, lr = 0.00418859
I1027 18:41:36.594449  9023 solver.cpp:222] Iteration 87720 (1.29717 iter/s, 30.8364s/40 iters), loss = 1.7575
I1027 18:41:36.594638  9023 solver.cpp:241]     Train net output #0: loss = 1.7575 (* 1 = 1.7575 loss)
I1027 18:41:36.594656  9023 sgd_solver.cpp:105] Iteration 87720, lr = 0.00418615
I1027 18:42:07.345712  9023 solver.cpp:222] Iteration 87760 (1.30082 iter/s, 30.7499s/40 iters), loss = 1.39453
I1027 18:42:07.345963  9023 solver.cpp:241]     Train net output #0: loss = 1.39453 (* 1 = 1.39453 loss)
I1027 18:42:07.345980  9023 sgd_solver.cpp:105] Iteration 87760, lr = 0.0041837
I1027 18:42:38.088212  9023 solver.cpp:222] Iteration 87800 (1.30119 iter/s, 30.7411s/40 iters), loss = 1.69495
I1027 18:42:38.088373  9023 solver.cpp:241]     Train net output #0: loss = 1.69495 (* 1 = 1.69495 loss)
I1027 18:42:38.088390  9023 sgd_solver.cpp:105] Iteration 87800, lr = 0.00418126
I1027 18:43:08.717170  9023 solver.cpp:222] Iteration 87840 (1.30601 iter/s, 30.6276s/40 iters), loss = 1.35788
I1027 18:43:08.717331  9023 solver.cpp:241]     Train net output #0: loss = 1.35788 (* 1 = 1.35788 loss)
I1027 18:43:08.717350  9023 sgd_solver.cpp:105] Iteration 87840, lr = 0.00417882
I1027 18:43:39.420356  9023 solver.cpp:222] Iteration 87880 (1.30285 iter/s, 30.7019s/40 iters), loss = 1.57873
I1027 18:43:39.420542  9023 solver.cpp:241]     Train net output #0: loss = 1.57873 (* 1 = 1.57873 loss)
I1027 18:43:39.420558  9023 sgd_solver.cpp:105] Iteration 87880, lr = 0.00417638
I1027 18:44:10.423537  9023 solver.cpp:222] Iteration 87920 (1.29025 iter/s, 31.0018s/40 iters), loss = 1.61491
I1027 18:44:10.423722  9023 solver.cpp:241]     Train net output #0: loss = 1.61491 (* 1 = 1.61491 loss)
I1027 18:44:10.423738  9023 sgd_solver.cpp:105] Iteration 87920, lr = 0.00417394
I1027 18:44:41.245154  9023 solver.cpp:222] Iteration 87960 (1.29785 iter/s, 30.8203s/40 iters), loss = 1.76725
I1027 18:44:41.245335  9023 solver.cpp:241]     Train net output #0: loss = 1.76725 (* 1 = 1.76725 loss)
I1027 18:44:41.245352  9023 sgd_solver.cpp:105] Iteration 87960, lr = 0.0041715
I1027 18:45:12.103564  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_88000.caffemodel
I1027 18:45:12.134892  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_88000.solverstate
I1027 18:45:12.151479  9023 solver.cpp:334] Iteration 88000, Testing net (#0)
I1027 18:45:43.172521  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 18:45:43.382707  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55044
I1027 18:45:43.382767  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78708
I1027 18:45:43.382781  9023 solver.cpp:401]     Test net output #2: loss = 2.02895 (* 1 = 2.02895 loss)
I1027 18:45:44.154954  9023 solver.cpp:222] Iteration 88000 (0.635857 iter/s, 62.9073s/40 iters), loss = 1.64386
I1027 18:45:44.155019  9023 solver.cpp:241]     Train net output #0: loss = 1.64386 (* 1 = 1.64386 loss)
I1027 18:45:44.155035  9023 sgd_solver.cpp:105] Iteration 88000, lr = 0.00416906
I1027 18:46:15.583602  9023 solver.cpp:222] Iteration 88040 (1.27277 iter/s, 31.4274s/40 iters), loss = 1.50028
I1027 18:46:15.583783  9023 solver.cpp:241]     Train net output #0: loss = 1.50028 (* 1 = 1.50028 loss)
I1027 18:46:15.583802  9023 sgd_solver.cpp:105] Iteration 88040, lr = 0.00416662
I1027 18:46:47.148324  9023 solver.cpp:222] Iteration 88080 (1.26729 iter/s, 31.5633s/40 iters), loss = 1.53699
I1027 18:46:47.148543  9023 solver.cpp:241]     Train net output #0: loss = 1.53699 (* 1 = 1.53699 loss)
I1027 18:46:47.148569  9023 sgd_solver.cpp:105] Iteration 88080, lr = 0.00416418
I1027 18:47:19.945415  9023 solver.cpp:222] Iteration 88120 (1.21967 iter/s, 32.7956s/40 iters), loss = 1.52329
I1027 18:47:19.945593  9023 solver.cpp:241]     Train net output #0: loss = 1.52329 (* 1 = 1.52329 loss)
I1027 18:47:19.945610  9023 sgd_solver.cpp:105] Iteration 88120, lr = 0.00416174
I1027 18:47:50.733769  9023 solver.cpp:222] Iteration 88160 (1.29925 iter/s, 30.787s/40 iters), loss = 1.55304
I1027 18:47:50.733948  9023 solver.cpp:241]     Train net output #0: loss = 1.55304 (* 1 = 1.55304 loss)
I1027 18:47:50.733964  9023 sgd_solver.cpp:105] Iteration 88160, lr = 0.0041593
I1027 18:48:21.485960  9023 solver.cpp:222] Iteration 88200 (1.30078 iter/s, 30.7508s/40 iters), loss = 1.45222
I1027 18:48:21.486168  9023 solver.cpp:241]     Train net output #0: loss = 1.45222 (* 1 = 1.45222 loss)
I1027 18:48:21.486205  9023 sgd_solver.cpp:105] Iteration 88200, lr = 0.00415686
I1027 18:48:51.963977  9023 solver.cpp:222] Iteration 88240 (1.31248 iter/s, 30.4767s/40 iters), loss = 1.75745
I1027 18:48:51.964323  9023 solver.cpp:241]     Train net output #0: loss = 1.75745 (* 1 = 1.75745 loss)
I1027 18:48:51.964361  9023 sgd_solver.cpp:105] Iteration 88240, lr = 0.00415442
I1027 18:49:22.523072  9023 solver.cpp:222] Iteration 88280 (1.309 iter/s, 30.5576s/40 iters), loss = 1.72388
I1027 18:49:22.523233  9023 solver.cpp:241]     Train net output #0: loss = 1.72388 (* 1 = 1.72388 loss)
I1027 18:49:22.523250  9023 sgd_solver.cpp:105] Iteration 88280, lr = 0.00415198
I1027 18:49:53.243999  9023 solver.cpp:222] Iteration 88320 (1.3021 iter/s, 30.7196s/40 iters), loss = 1.51107
I1027 18:49:53.244164  9023 solver.cpp:241]     Train net output #0: loss = 1.51107 (* 1 = 1.51107 loss)
I1027 18:49:53.244190  9023 sgd_solver.cpp:105] Iteration 88320, lr = 0.00414954
I1027 18:50:24.555112  9023 solver.cpp:222] Iteration 88360 (1.27756 iter/s, 31.3098s/40 iters), loss = 1.85016
I1027 18:50:24.555294  9023 solver.cpp:241]     Train net output #0: loss = 1.85016 (* 1 = 1.85016 loss)
I1027 18:50:24.555317  9023 sgd_solver.cpp:105] Iteration 88360, lr = 0.0041471
I1027 18:50:55.255857  9023 solver.cpp:222] Iteration 88400 (1.30296 iter/s, 30.6994s/40 iters), loss = 1.58319
I1027 18:50:55.256026  9023 solver.cpp:241]     Train net output #0: loss = 1.58319 (* 1 = 1.58319 loss)
I1027 18:50:55.256043  9023 sgd_solver.cpp:105] Iteration 88400, lr = 0.00414467
I1027 18:51:25.538542  9023 solver.cpp:222] Iteration 88440 (1.32094 iter/s, 30.2814s/40 iters), loss = 1.80764
I1027 18:51:25.538763  9023 solver.cpp:241]     Train net output #0: loss = 1.80764 (* 1 = 1.80764 loss)
I1027 18:51:25.538789  9023 sgd_solver.cpp:105] Iteration 88440, lr = 0.00414223
I1027 18:51:55.753017  9023 solver.cpp:222] Iteration 88480 (1.32393 iter/s, 30.2131s/40 iters), loss = 1.9356
I1027 18:51:55.753198  9023 solver.cpp:241]     Train net output #0: loss = 1.9356 (* 1 = 1.9356 loss)
I1027 18:51:55.753214  9023 sgd_solver.cpp:105] Iteration 88480, lr = 0.00413979
I1027 18:52:09.803017  9023 solver.cpp:334] Iteration 88500, Testing net (#0)
I1027 18:52:41.193811  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55296
I1027 18:52:41.193996  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7848
I1027 18:52:41.194012  9023 solver.cpp:401]     Test net output #2: loss = 1.98377 (* 1 = 1.98377 loss)
I1027 18:52:56.967864  9023 solver.cpp:222] Iteration 88520 (0.653463 iter/s, 61.2123s/40 iters), loss = 1.66367
I1027 18:52:56.967936  9023 solver.cpp:241]     Train net output #0: loss = 1.66367 (* 1 = 1.66367 loss)
I1027 18:52:56.967952  9023 sgd_solver.cpp:105] Iteration 88520, lr = 0.00413735
I1027 18:53:26.553208  9023 solver.cpp:222] Iteration 88560 (1.35207 iter/s, 29.5842s/40 iters), loss = 1.47312
I1027 18:53:26.553412  9023 solver.cpp:241]     Train net output #0: loss = 1.47312 (* 1 = 1.47312 loss)
I1027 18:53:26.553428  9023 sgd_solver.cpp:105] Iteration 88560, lr = 0.00413491
I1027 18:53:57.274442  9023 solver.cpp:222] Iteration 88600 (1.30209 iter/s, 30.7199s/40 iters), loss = 1.45585
I1027 18:53:57.274597  9023 solver.cpp:241]     Train net output #0: loss = 1.45585 (* 1 = 1.45585 loss)
I1027 18:53:57.274613  9023 sgd_solver.cpp:105] Iteration 88600, lr = 0.00413248
I1027 18:54:28.153149  9023 solver.cpp:222] Iteration 88640 (1.29545 iter/s, 30.8774s/40 iters), loss = 1.95025
I1027 18:54:28.153340  9023 solver.cpp:241]     Train net output #0: loss = 1.95025 (* 1 = 1.95025 loss)
I1027 18:54:28.153357  9023 sgd_solver.cpp:105] Iteration 88640, lr = 0.00413004
I1027 18:54:59.694618  9023 solver.cpp:222] Iteration 88680 (1.26823 iter/s, 31.5401s/40 iters), loss = 1.5393
I1027 18:54:59.694808  9023 solver.cpp:241]     Train net output #0: loss = 1.5393 (* 1 = 1.5393 loss)
I1027 18:54:59.694823  9023 sgd_solver.cpp:105] Iteration 88680, lr = 0.0041276
I1027 18:55:33.223884  9023 solver.cpp:222] Iteration 88720 (1.19304 iter/s, 33.5278s/40 iters), loss = 1.54063
I1027 18:55:33.224174  9023 solver.cpp:241]     Train net output #0: loss = 1.54063 (* 1 = 1.54063 loss)
I1027 18:55:33.224198  9023 sgd_solver.cpp:105] Iteration 88720, lr = 0.00412517
I1027 18:56:04.811013  9023 solver.cpp:222] Iteration 88760 (1.2664 iter/s, 31.5857s/40 iters), loss = 1.62502
I1027 18:56:04.811200  9023 solver.cpp:241]     Train net output #0: loss = 1.62502 (* 1 = 1.62502 loss)
I1027 18:56:04.811216  9023 sgd_solver.cpp:105] Iteration 88760, lr = 0.00412273
I1027 18:56:35.838836  9023 solver.cpp:222] Iteration 88800 (1.28922 iter/s, 31.0265s/40 iters), loss = 1.50725
I1027 18:56:35.839030  9023 solver.cpp:241]     Train net output #0: loss = 1.50725 (* 1 = 1.50725 loss)
I1027 18:56:35.839051  9023 sgd_solver.cpp:105] Iteration 88800, lr = 0.0041203
I1027 18:57:13.202334  9023 solver.cpp:222] Iteration 88840 (1.07061 iter/s, 37.3619s/40 iters), loss = 1.55119
I1027 18:57:13.202556  9023 solver.cpp:241]     Train net output #0: loss = 1.55119 (* 1 = 1.55119 loss)
I1027 18:57:13.202579  9023 sgd_solver.cpp:105] Iteration 88840, lr = 0.00411786
I1027 18:57:46.713248  9023 solver.cpp:222] Iteration 88880 (1.19369 iter/s, 33.5094s/40 iters), loss = 2.00307
I1027 18:57:46.713434  9023 solver.cpp:241]     Train net output #0: loss = 2.00307 (* 1 = 2.00307 loss)
I1027 18:57:46.713450  9023 sgd_solver.cpp:105] Iteration 88880, lr = 0.00411543
I1027 18:58:17.503273  9023 solver.cpp:222] Iteration 88920 (1.29918 iter/s, 30.7887s/40 iters), loss = 1.45162
I1027 18:58:17.503455  9023 solver.cpp:241]     Train net output #0: loss = 1.45162 (* 1 = 1.45162 loss)
I1027 18:58:17.503470  9023 sgd_solver.cpp:105] Iteration 88920, lr = 0.00411299
I1027 18:58:48.107666  9023 solver.cpp:222] Iteration 88960 (1.30706 iter/s, 30.6031s/40 iters), loss = 1.3688
I1027 18:58:48.107846  9023 solver.cpp:241]     Train net output #0: loss = 1.3688 (* 1 = 1.3688 loss)
I1027 18:58:48.107862  9023 sgd_solver.cpp:105] Iteration 88960, lr = 0.00411056
I1027 18:59:18.436993  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_89000.caffemodel
I1027 18:59:18.521849  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_89000.solverstate
I1027 18:59:18.544472  9023 solver.cpp:334] Iteration 89000, Testing net (#0)
I1027 18:59:49.861136  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 18:59:50.069548  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55456
I1027 18:59:50.069610  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.791679
I1027 18:59:50.069624  9023 solver.cpp:401]     Test net output #2: loss = 1.9758 (* 1 = 1.9758 loss)
I1027 18:59:50.848431  9023 solver.cpp:222] Iteration 89000 (0.63757 iter/s, 62.7382s/40 iters), loss = 2.04795
I1027 18:59:50.848492  9023 solver.cpp:241]     Train net output #0: loss = 2.04795 (* 1 = 2.04795 loss)
I1027 18:59:50.848507  9023 sgd_solver.cpp:105] Iteration 89000, lr = 0.00410812
I1027 19:00:21.508263  9023 solver.cpp:222] Iteration 89040 (1.30469 iter/s, 30.6586s/40 iters), loss = 1.81761
I1027 19:00:21.508460  9023 solver.cpp:241]     Train net output #0: loss = 1.81761 (* 1 = 1.81761 loss)
I1027 19:00:21.508476  9023 sgd_solver.cpp:105] Iteration 89040, lr = 0.00410569
I1027 19:00:52.495755  9023 solver.cpp:222] Iteration 89080 (1.2909 iter/s, 30.9861s/40 iters), loss = 1.56679
I1027 19:00:52.495965  9023 solver.cpp:241]     Train net output #0: loss = 1.56679 (* 1 = 1.56679 loss)
I1027 19:00:52.495986  9023 sgd_solver.cpp:105] Iteration 89080, lr = 0.00410325
I1027 19:01:37.332343  9023 solver.cpp:222] Iteration 89120 (0.892166 iter/s, 44.8347s/40 iters), loss = 1.78502
I1027 19:01:37.332551  9023 solver.cpp:241]     Train net output #0: loss = 1.78502 (* 1 = 1.78502 loss)
I1027 19:01:37.332566  9023 sgd_solver.cpp:105] Iteration 89120, lr = 0.00410082
I1027 19:02:08.254070  9023 solver.cpp:222] Iteration 89160 (1.29365 iter/s, 30.9204s/40 iters), loss = 1.47604
I1027 19:02:08.254418  9023 solver.cpp:241]     Train net output #0: loss = 1.47604 (* 1 = 1.47604 loss)
I1027 19:02:08.254454  9023 sgd_solver.cpp:105] Iteration 89160, lr = 0.00409839
I1027 19:02:39.049525  9023 solver.cpp:222] Iteration 89200 (1.29896 iter/s, 30.7939s/40 iters), loss = 1.67691
I1027 19:02:39.049731  9023 solver.cpp:241]     Train net output #0: loss = 1.67691 (* 1 = 1.67691 loss)
I1027 19:02:39.049747  9023 sgd_solver.cpp:105] Iteration 89200, lr = 0.00409595
I1027 19:03:09.867712  9023 solver.cpp:222] Iteration 89240 (1.29799 iter/s, 30.8168s/40 iters), loss = 1.86682
I1027 19:03:09.867894  9023 solver.cpp:241]     Train net output #0: loss = 1.86682 (* 1 = 1.86682 loss)
I1027 19:03:09.867910  9023 sgd_solver.cpp:105] Iteration 89240, lr = 0.00409352
I1027 19:03:40.652966  9023 solver.cpp:222] Iteration 89280 (1.29938 iter/s, 30.7839s/40 iters), loss = 1.46721
I1027 19:03:40.653147  9023 solver.cpp:241]     Train net output #0: loss = 1.46721 (* 1 = 1.46721 loss)
I1027 19:03:40.653164  9023 sgd_solver.cpp:105] Iteration 89280, lr = 0.00409109
I1027 19:04:11.611280  9023 solver.cpp:222] Iteration 89320 (1.29212 iter/s, 30.9569s/40 iters), loss = 1.89264
I1027 19:04:11.611491  9023 solver.cpp:241]     Train net output #0: loss = 1.89264 (* 1 = 1.89264 loss)
I1027 19:04:11.611508  9023 sgd_solver.cpp:105] Iteration 89320, lr = 0.00408865
I1027 19:04:42.381664  9023 solver.cpp:222] Iteration 89360 (1.30001 iter/s, 30.769s/40 iters), loss = 1.64053
I1027 19:04:42.381845  9023 solver.cpp:241]     Train net output #0: loss = 1.64053 (* 1 = 1.64053 loss)
I1027 19:04:42.381861  9023 sgd_solver.cpp:105] Iteration 89360, lr = 0.00408622
I1027 19:05:13.144495  9023 solver.cpp:222] Iteration 89400 (1.30033 iter/s, 30.7615s/40 iters), loss = 1.77309
I1027 19:05:13.144682  9023 solver.cpp:241]     Train net output #0: loss = 1.77309 (* 1 = 1.77309 loss)
I1027 19:05:13.144700  9023 sgd_solver.cpp:105] Iteration 89400, lr = 0.00408379
I1027 19:05:44.976313  9023 solver.cpp:222] Iteration 89440 (1.25666 iter/s, 31.8304s/40 iters), loss = 1.88127
I1027 19:05:44.976513  9023 solver.cpp:241]     Train net output #0: loss = 1.88127 (* 1 = 1.88127 loss)
I1027 19:05:44.976531  9023 sgd_solver.cpp:105] Iteration 89440, lr = 0.00408136
I1027 19:06:16.398442  9023 solver.cpp:222] Iteration 89480 (1.27305 iter/s, 31.4207s/40 iters), loss = 1.53631
I1027 19:06:16.398708  9023 solver.cpp:241]     Train net output #0: loss = 1.53631 (* 1 = 1.53631 loss)
I1027 19:06:16.399360  9023 sgd_solver.cpp:105] Iteration 89480, lr = 0.00407893
I1027 19:06:31.137883  9023 solver.cpp:334] Iteration 89500, Testing net (#0)
I1027 19:07:02.430213  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54968
I1027 19:07:02.430403  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78744
I1027 19:07:02.430419  9023 solver.cpp:401]     Test net output #2: loss = 1.99999 (* 1 = 1.99999 loss)
I1027 19:07:17.697206  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1027 19:07:18.683653  9023 solver.cpp:222] Iteration 89520 (0.642234 iter/s, 62.2826s/40 iters), loss = 2.06547
I1027 19:07:18.683720  9023 solver.cpp:241]     Train net output #0: loss = 2.06547 (* 1 = 2.06547 loss)
I1027 19:07:18.683735  9023 sgd_solver.cpp:105] Iteration 89520, lr = 0.00407649
I1027 19:07:49.452976  9023 solver.cpp:222] Iteration 89560 (1.30005 iter/s, 30.7681s/40 iters), loss = 1.76519
I1027 19:07:49.453160  9023 solver.cpp:241]     Train net output #0: loss = 1.76519 (* 1 = 1.76519 loss)
I1027 19:07:49.453174  9023 sgd_solver.cpp:105] Iteration 89560, lr = 0.00407406
I1027 19:08:20.049317  9023 solver.cpp:222] Iteration 89600 (1.3074 iter/s, 30.595s/40 iters), loss = 1.56294
I1027 19:08:20.049492  9023 solver.cpp:241]     Train net output #0: loss = 1.56294 (* 1 = 1.56294 loss)
I1027 19:08:20.049510  9023 sgd_solver.cpp:105] Iteration 89600, lr = 0.00407163
I1027 19:08:50.803360  9023 solver.cpp:222] Iteration 89640 (1.3007 iter/s, 30.7527s/40 iters), loss = 1.43059
I1027 19:08:50.803534  9023 solver.cpp:241]     Train net output #0: loss = 1.43059 (* 1 = 1.43059 loss)
I1027 19:08:50.803561  9023 sgd_solver.cpp:105] Iteration 89640, lr = 0.0040692
I1027 19:09:21.472189  9023 solver.cpp:222] Iteration 89680 (1.30431 iter/s, 30.6675s/40 iters), loss = 1.17802
I1027 19:09:21.472497  9023 solver.cpp:241]     Train net output #0: loss = 1.17802 (* 1 = 1.17802 loss)
I1027 19:09:21.472538  9023 sgd_solver.cpp:105] Iteration 89680, lr = 0.00406677
I1027 19:09:52.445668  9023 solver.cpp:222] Iteration 89720 (1.29149 iter/s, 30.972s/40 iters), loss = 1.45697
I1027 19:09:52.445863  9023 solver.cpp:241]     Train net output #0: loss = 1.45697 (* 1 = 1.45697 loss)
I1027 19:09:52.445879  9023 sgd_solver.cpp:105] Iteration 89720, lr = 0.00406434
I1027 19:10:23.819128  9023 solver.cpp:222] Iteration 89760 (1.27502 iter/s, 31.3721s/40 iters), loss = 1.42544
I1027 19:10:23.819334  9023 solver.cpp:241]     Train net output #0: loss = 1.42544 (* 1 = 1.42544 loss)
I1027 19:10:23.819351  9023 sgd_solver.cpp:105] Iteration 89760, lr = 0.00406191
I1027 19:10:54.565026  9023 solver.cpp:222] Iteration 89800 (1.30104 iter/s, 30.7445s/40 iters), loss = 1.97315
I1027 19:10:54.565255  9023 solver.cpp:241]     Train net output #0: loss = 1.97315 (* 1 = 1.97315 loss)
I1027 19:10:54.565271  9023 sgd_solver.cpp:105] Iteration 89800, lr = 0.00405948
I1027 19:11:25.180812  9023 solver.cpp:222] Iteration 89840 (1.30657 iter/s, 30.6144s/40 iters), loss = 1.52497
I1027 19:11:25.181013  9023 solver.cpp:241]     Train net output #0: loss = 1.52497 (* 1 = 1.52497 loss)
I1027 19:11:25.181030  9023 sgd_solver.cpp:105] Iteration 89840, lr = 0.00405705
I1027 19:11:55.861637  9023 solver.cpp:222] Iteration 89880 (1.3038 iter/s, 30.6795s/40 iters), loss = 1.86025
I1027 19:11:55.861842  9023 solver.cpp:241]     Train net output #0: loss = 1.86025 (* 1 = 1.86025 loss)
I1027 19:11:55.861858  9023 sgd_solver.cpp:105] Iteration 89880, lr = 0.00405462
I1027 19:12:26.972316  9023 solver.cpp:222] Iteration 89920 (1.28579 iter/s, 31.1093s/40 iters), loss = 1.57867
I1027 19:12:26.972550  9023 solver.cpp:241]     Train net output #0: loss = 1.57867 (* 1 = 1.57867 loss)
I1027 19:12:26.972573  9023 sgd_solver.cpp:105] Iteration 89920, lr = 0.00405219
I1027 19:12:57.658466  9023 solver.cpp:222] Iteration 89960 (1.30358 iter/s, 30.6848s/40 iters), loss = 1.75417
I1027 19:12:57.658648  9023 solver.cpp:241]     Train net output #0: loss = 1.75417 (* 1 = 1.75417 loss)
I1027 19:12:57.658663  9023 sgd_solver.cpp:105] Iteration 89960, lr = 0.00404976
I1027 19:13:27.569659  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_90000.caffemodel
I1027 19:13:27.606211  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_90000.solverstate
I1027 19:13:27.629549  9023 solver.cpp:334] Iteration 90000, Testing net (#0)
I1027 19:13:59.014053  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 19:13:59.228471  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55756
I1027 19:13:59.228529  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79124
I1027 19:13:59.228543  9023 solver.cpp:401]     Test net output #2: loss = 1.98099 (* 1 = 1.98099 loss)
I1027 19:13:59.999918  9023 solver.cpp:222] Iteration 90000 (0.641654 iter/s, 62.3389s/40 iters), loss = 1.7707
I1027 19:13:59.999986  9023 solver.cpp:241]     Train net output #0: loss = 1.7707 (* 1 = 1.7707 loss)
I1027 19:14:00.000002  9023 sgd_solver.cpp:105] Iteration 90000, lr = 0.00404734
I1027 19:14:30.788589  9023 solver.cpp:222] Iteration 90040 (1.29923 iter/s, 30.7874s/40 iters), loss = 1.62176
I1027 19:14:30.788780  9023 solver.cpp:241]     Train net output #0: loss = 1.62176 (* 1 = 1.62176 loss)
I1027 19:14:30.788796  9023 sgd_solver.cpp:105] Iteration 90040, lr = 0.00404491
I1027 19:15:01.728374  9023 solver.cpp:222] Iteration 90080 (1.29289 iter/s, 30.9384s/40 iters), loss = 1.56858
I1027 19:15:01.728597  9023 solver.cpp:241]     Train net output #0: loss = 1.56858 (* 1 = 1.56858 loss)
I1027 19:15:01.728641  9023 sgd_solver.cpp:105] Iteration 90080, lr = 0.00404248
I1027 19:15:33.076946  9023 solver.cpp:222] Iteration 90120 (1.27603 iter/s, 31.3472s/40 iters), loss = 1.8044
I1027 19:15:33.077198  9023 solver.cpp:241]     Train net output #0: loss = 1.8044 (* 1 = 1.8044 loss)
I1027 19:15:33.077215  9023 sgd_solver.cpp:105] Iteration 90120, lr = 0.00404005
I1027 19:16:04.297288  9023 solver.cpp:222] Iteration 90160 (1.28127 iter/s, 31.2189s/40 iters), loss = 1.8052
I1027 19:16:04.297534  9023 solver.cpp:241]     Train net output #0: loss = 1.8052 (* 1 = 1.8052 loss)
I1027 19:16:04.297559  9023 sgd_solver.cpp:105] Iteration 90160, lr = 0.00403762
I1027 19:16:35.414391  9023 solver.cpp:222] Iteration 90200 (1.28553 iter/s, 31.1157s/40 iters), loss = 1.59197
I1027 19:16:35.414590  9023 solver.cpp:241]     Train net output #0: loss = 1.59197 (* 1 = 1.59197 loss)
I1027 19:16:35.414608  9023 sgd_solver.cpp:105] Iteration 90200, lr = 0.0040352
I1027 19:17:06.371670  9023 solver.cpp:222] Iteration 90240 (1.29216 iter/s, 30.9559s/40 iters), loss = 1.40989
I1027 19:17:06.371881  9023 solver.cpp:241]     Train net output #0: loss = 1.40989 (* 1 = 1.40989 loss)
I1027 19:17:06.371964  9023 sgd_solver.cpp:105] Iteration 90240, lr = 0.00403277
I1027 19:17:37.171079  9023 solver.cpp:222] Iteration 90280 (1.29878 iter/s, 30.798s/40 iters), loss = 1.73199
I1027 19:17:37.171277  9023 solver.cpp:241]     Train net output #0: loss = 1.73199 (* 1 = 1.73199 loss)
I1027 19:17:37.171294  9023 sgd_solver.cpp:105] Iteration 90280, lr = 0.00403034
I1027 19:18:08.023422  9023 solver.cpp:222] Iteration 90320 (1.29656 iter/s, 30.851s/40 iters), loss = 1.4413
I1027 19:18:08.023660  9023 solver.cpp:241]     Train net output #0: loss = 1.4413 (* 1 = 1.4413 loss)
I1027 19:18:08.023684  9023 sgd_solver.cpp:105] Iteration 90320, lr = 0.00402792
I1027 19:18:40.951722  9023 solver.cpp:222] Iteration 90360 (1.21482 iter/s, 32.9268s/40 iters), loss = 1.77406
I1027 19:18:40.951920  9023 solver.cpp:241]     Train net output #0: loss = 1.77406 (* 1 = 1.77406 loss)
I1027 19:18:40.951941  9023 sgd_solver.cpp:105] Iteration 90360, lr = 0.00402549
I1027 19:19:43.323628  9023 solver.cpp:222] Iteration 90400 (0.64134 iter/s, 62.3694s/40 iters), loss = 1.74128
I1027 19:19:43.323894  9023 solver.cpp:241]     Train net output #0: loss = 1.74128 (* 1 = 1.74128 loss)
I1027 19:19:43.323927  9023 sgd_solver.cpp:105] Iteration 90400, lr = 0.00402306
I1027 19:20:14.201822  9023 solver.cpp:222] Iteration 90440 (1.29547 iter/s, 30.8768s/40 iters), loss = 1.37879
I1027 19:20:14.202003  9023 solver.cpp:241]     Train net output #0: loss = 1.37879 (* 1 = 1.37879 loss)
I1027 19:20:14.202018  9023 sgd_solver.cpp:105] Iteration 90440, lr = 0.00402064
I1027 19:20:44.845178  9023 solver.cpp:222] Iteration 90480 (1.3054 iter/s, 30.642s/40 iters), loss = 1.50631
I1027 19:20:44.845387  9023 solver.cpp:241]     Train net output #0: loss = 1.50631 (* 1 = 1.50631 loss)
I1027 19:20:44.845403  9023 sgd_solver.cpp:105] Iteration 90480, lr = 0.00401821
I1027 19:20:59.395409  9023 solver.cpp:334] Iteration 90500, Testing net (#0)
I1027 19:21:30.729095  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55932
I1027 19:21:30.729288  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79224
I1027 19:21:30.729308  9023 solver.cpp:401]     Test net output #2: loss = 1.98315 (* 1 = 1.98315 loss)
I1027 19:21:46.807397  9023 solver.cpp:222] Iteration 90520 (0.645581 iter/s, 61.9597s/40 iters), loss = 1.49885
I1027 19:21:46.807464  9023 solver.cpp:241]     Train net output #0: loss = 1.49885 (* 1 = 1.49885 loss)
I1027 19:21:46.807479  9023 sgd_solver.cpp:105] Iteration 90520, lr = 0.00401579
I1027 19:22:17.330651  9023 solver.cpp:222] Iteration 90560 (1.31053 iter/s, 30.522s/40 iters), loss = 1.46504
I1027 19:22:17.330839  9023 solver.cpp:241]     Train net output #0: loss = 1.46504 (* 1 = 1.46504 loss)
I1027 19:22:17.330858  9023 sgd_solver.cpp:105] Iteration 90560, lr = 0.00401336
I1027 19:22:47.944677  9023 solver.cpp:222] Iteration 90600 (1.30665 iter/s, 30.6127s/40 iters), loss = 1.60463
I1027 19:22:47.944921  9023 solver.cpp:241]     Train net output #0: loss = 1.60463 (* 1 = 1.60463 loss)
I1027 19:22:47.944939  9023 sgd_solver.cpp:105] Iteration 90600, lr = 0.00401094
I1027 19:23:18.698022  9023 solver.cpp:222] Iteration 90640 (1.30073 iter/s, 30.7519s/40 iters), loss = 1.66237
I1027 19:23:18.698233  9023 solver.cpp:241]     Train net output #0: loss = 1.66237 (* 1 = 1.66237 loss)
I1027 19:23:18.698257  9023 sgd_solver.cpp:105] Iteration 90640, lr = 0.00400851
I1027 19:23:49.729924  9023 solver.cpp:222] Iteration 90680 (1.28905 iter/s, 31.0305s/40 iters), loss = 1.49205
I1027 19:23:49.730136  9023 solver.cpp:241]     Train net output #0: loss = 1.49205 (* 1 = 1.49205 loss)
I1027 19:23:49.730154  9023 sgd_solver.cpp:105] Iteration 90680, lr = 0.00400609
I1027 19:24:20.467793  9023 solver.cpp:222] Iteration 90720 (1.30139 iter/s, 30.7365s/40 iters), loss = 1.71851
I1027 19:24:20.468050  9023 solver.cpp:241]     Train net output #0: loss = 1.71851 (* 1 = 1.71851 loss)
I1027 19:24:20.468075  9023 sgd_solver.cpp:105] Iteration 90720, lr = 0.00400366
I1027 19:24:51.708349  9023 solver.cpp:222] Iteration 90760 (1.28045 iter/s, 31.2391s/40 iters), loss = 1.959
I1027 19:24:51.708565  9023 solver.cpp:241]     Train net output #0: loss = 1.959 (* 1 = 1.959 loss)
I1027 19:24:51.708590  9023 sgd_solver.cpp:105] Iteration 90760, lr = 0.00400124
I1027 19:25:23.349733  9023 solver.cpp:222] Iteration 90800 (1.26422 iter/s, 31.64s/40 iters), loss = 1.53142
I1027 19:25:23.349925  9023 solver.cpp:241]     Train net output #0: loss = 1.53142 (* 1 = 1.53142 loss)
I1027 19:25:23.349942  9023 sgd_solver.cpp:105] Iteration 90800, lr = 0.00399882
I1027 19:25:54.425436  9023 solver.cpp:222] Iteration 90840 (1.28724 iter/s, 31.0743s/40 iters), loss = 1.60805
I1027 19:25:54.425678  9023 solver.cpp:241]     Train net output #0: loss = 1.60805 (* 1 = 1.60805 loss)
I1027 19:25:54.425709  9023 sgd_solver.cpp:105] Iteration 90840, lr = 0.00399639
I1027 19:26:25.504525  9023 solver.cpp:222] Iteration 90880 (1.2871 iter/s, 31.0777s/40 iters), loss = 1.38997
I1027 19:26:25.504698  9023 solver.cpp:241]     Train net output #0: loss = 1.38997 (* 1 = 1.38997 loss)
I1027 19:26:25.504714  9023 sgd_solver.cpp:105] Iteration 90880, lr = 0.00399397
I1027 19:26:56.775032  9023 solver.cpp:222] Iteration 90920 (1.27922 iter/s, 31.2692s/40 iters), loss = 1.93112
I1027 19:26:56.775218  9023 solver.cpp:241]     Train net output #0: loss = 1.93112 (* 1 = 1.93112 loss)
I1027 19:26:56.775234  9023 sgd_solver.cpp:105] Iteration 90920, lr = 0.00399155
I1027 19:27:27.597887  9023 solver.cpp:222] Iteration 90960 (1.2978 iter/s, 30.8215s/40 iters), loss = 1.69062
I1027 19:27:27.598054  9023 solver.cpp:241]     Train net output #0: loss = 1.69062 (* 1 = 1.69062 loss)
I1027 19:27:27.598070  9023 sgd_solver.cpp:105] Iteration 90960, lr = 0.00398912
I1027 19:28:09.695711  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_91000.caffemodel
I1027 19:28:09.727419  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_91000.solverstate
I1027 19:28:09.744287  9023 solver.cpp:334] Iteration 91000, Testing net (#0)
I1027 19:28:41.014817  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 19:28:41.225428  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.54996
I1027 19:28:41.225493  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.789919
I1027 19:28:41.225507  9023 solver.cpp:401]     Test net output #2: loss = 2.01543 (* 1 = 2.01543 loss)
I1027 19:28:41.994415  9023 solver.cpp:222] Iteration 91000 (0.537681 iter/s, 74.3936s/40 iters), loss = 1.75259
I1027 19:28:41.994474  9023 solver.cpp:241]     Train net output #0: loss = 1.75259 (* 1 = 1.75259 loss)
I1027 19:28:41.994489  9023 sgd_solver.cpp:105] Iteration 91000, lr = 0.0039867
I1027 19:29:13.625351  9023 solver.cpp:222] Iteration 91040 (1.26463 iter/s, 31.6297s/40 iters), loss = 1.84702
I1027 19:29:13.625516  9023 solver.cpp:241]     Train net output #0: loss = 1.84702 (* 1 = 1.84702 loss)
I1027 19:29:13.625545  9023 sgd_solver.cpp:105] Iteration 91040, lr = 0.00398428
I1027 19:29:45.529467  9023 solver.cpp:222] Iteration 91080 (1.25381 iter/s, 31.9028s/40 iters), loss = 1.34314
I1027 19:29:45.529696  9023 solver.cpp:241]     Train net output #0: loss = 1.34314 (* 1 = 1.34314 loss)
I1027 19:29:45.529719  9023 sgd_solver.cpp:105] Iteration 91080, lr = 0.00398186
I1027 19:30:16.242849  9023 solver.cpp:222] Iteration 91120 (1.30242 iter/s, 30.712s/40 iters), loss = 2.0845
I1027 19:30:16.243026  9023 solver.cpp:241]     Train net output #0: loss = 2.0845 (* 1 = 2.0845 loss)
I1027 19:30:16.243041  9023 sgd_solver.cpp:105] Iteration 91120, lr = 0.00397944
I1027 19:30:46.824658  9023 solver.cpp:222] Iteration 91160 (1.30802 iter/s, 30.5805s/40 iters), loss = 1.79542
I1027 19:30:46.824808  9023 solver.cpp:241]     Train net output #0: loss = 1.79542 (* 1 = 1.79542 loss)
I1027 19:30:46.824825  9023 sgd_solver.cpp:105] Iteration 91160, lr = 0.00397702
I1027 19:31:17.331315  9023 solver.cpp:222] Iteration 91200 (1.31125 iter/s, 30.5054s/40 iters), loss = 1.35665
I1027 19:31:17.331487  9023 solver.cpp:241]     Train net output #0: loss = 1.35665 (* 1 = 1.35665 loss)
I1027 19:31:17.331503  9023 sgd_solver.cpp:105] Iteration 91200, lr = 0.00397459
I1027 19:31:48.103512  9023 solver.cpp:222] Iteration 91240 (1.29993 iter/s, 30.7709s/40 iters), loss = 2.01398
I1027 19:31:48.103700  9023 solver.cpp:241]     Train net output #0: loss = 2.01398 (* 1 = 2.01398 loss)
I1027 19:31:48.103718  9023 sgd_solver.cpp:105] Iteration 91240, lr = 0.00397217
I1027 19:32:18.569583  9023 solver.cpp:222] Iteration 91280 (1.31299 iter/s, 30.4647s/40 iters), loss = 1.59916
I1027 19:32:18.569747  9023 solver.cpp:241]     Train net output #0: loss = 1.59916 (* 1 = 1.59916 loss)
I1027 19:32:18.569764  9023 sgd_solver.cpp:105] Iteration 91280, lr = 0.00396975
I1027 19:32:49.034225  9023 solver.cpp:222] Iteration 91320 (1.31305 iter/s, 30.4633s/40 iters), loss = 1.36415
I1027 19:32:49.034411  9023 solver.cpp:241]     Train net output #0: loss = 1.36415 (* 1 = 1.36415 loss)
I1027 19:32:49.034428  9023 sgd_solver.cpp:105] Iteration 91320, lr = 0.00396733
I1027 19:33:20.066540  9023 solver.cpp:222] Iteration 91360 (1.28904 iter/s, 31.031s/40 iters), loss = 1.51163
I1027 19:33:20.066735  9023 solver.cpp:241]     Train net output #0: loss = 1.51163 (* 1 = 1.51163 loss)
I1027 19:33:20.066751  9023 sgd_solver.cpp:105] Iteration 91360, lr = 0.00396491
I1027 19:33:51.531303  9023 solver.cpp:222] Iteration 91400 (1.27132 iter/s, 31.4634s/40 iters), loss = 1.57979
I1027 19:33:51.531548  9023 solver.cpp:241]     Train net output #0: loss = 1.57979 (* 1 = 1.57979 loss)
I1027 19:33:51.531576  9023 sgd_solver.cpp:105] Iteration 91400, lr = 0.00396249
I1027 19:34:25.360975  9023 solver.cpp:222] Iteration 91440 (1.18245 iter/s, 33.8281s/40 iters), loss = 1.6288
I1027 19:34:25.361196  9023 solver.cpp:241]     Train net output #0: loss = 1.6288 (* 1 = 1.6288 loss)
I1027 19:34:25.361215  9023 sgd_solver.cpp:105] Iteration 91440, lr = 0.00396007
I1027 19:34:56.526496  9023 solver.cpp:222] Iteration 91480 (1.28353 iter/s, 31.1641s/40 iters), loss = 1.83363
I1027 19:34:56.526700  9023 solver.cpp:241]     Train net output #0: loss = 1.83363 (* 1 = 1.83363 loss)
I1027 19:34:56.526716  9023 sgd_solver.cpp:105] Iteration 91480, lr = 0.00395765
I1027 19:35:11.000843  9023 solver.cpp:334] Iteration 91500, Testing net (#0)
I1027 19:35:42.600771  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5574
I1027 19:35:42.600955  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79
I1027 19:35:42.600971  9023 solver.cpp:401]     Test net output #2: loss = 1.96775 (* 1 = 1.96775 loss)
I1027 19:35:58.587857  9023 solver.cpp:222] Iteration 91520 (0.64455 iter/s, 62.0588s/40 iters), loss = 1.63255
I1027 19:35:58.587921  9023 solver.cpp:241]     Train net output #0: loss = 1.63255 (* 1 = 1.63255 loss)
I1027 19:35:58.587937  9023 sgd_solver.cpp:105] Iteration 91520, lr = 0.00395523
I1027 19:36:29.263474  9023 solver.cpp:222] Iteration 91560 (1.30402 iter/s, 30.6744s/40 iters), loss = 1.72749
I1027 19:36:29.263751  9023 solver.cpp:241]     Train net output #0: loss = 1.72749 (* 1 = 1.72749 loss)
I1027 19:36:29.263769  9023 sgd_solver.cpp:105] Iteration 91560, lr = 0.00395281
I1027 19:36:59.877676  9023 solver.cpp:222] Iteration 91600 (1.30664 iter/s, 30.6128s/40 iters), loss = 1.49227
I1027 19:36:59.877866  9023 solver.cpp:241]     Train net output #0: loss = 1.49227 (* 1 = 1.49227 loss)
I1027 19:36:59.878268  9023 sgd_solver.cpp:105] Iteration 91600, lr = 0.0039504
I1027 19:37:30.511687  9023 solver.cpp:222] Iteration 91640 (1.3058 iter/s, 30.6327s/40 iters), loss = 1.99943
I1027 19:37:30.511858  9023 solver.cpp:241]     Train net output #0: loss = 1.99943 (* 1 = 1.99943 loss)
I1027 19:37:30.511878  9023 sgd_solver.cpp:105] Iteration 91640, lr = 0.00394798
I1027 19:38:01.288292  9023 solver.cpp:222] Iteration 91680 (1.29975 iter/s, 30.7753s/40 iters), loss = 1.85349
I1027 19:38:01.288450  9023 solver.cpp:241]     Train net output #0: loss = 1.85349 (* 1 = 1.85349 loss)
I1027 19:38:01.288470  9023 sgd_solver.cpp:105] Iteration 91680, lr = 0.00394556
I1027 19:38:32.064054  9023 solver.cpp:222] Iteration 91720 (1.29978 iter/s, 30.7744s/40 iters), loss = 1.74579
I1027 19:38:32.064232  9023 solver.cpp:241]     Train net output #0: loss = 1.74579 (* 1 = 1.74579 loss)
I1027 19:38:32.064249  9023 sgd_solver.cpp:105] Iteration 91720, lr = 0.00394314
I1027 19:39:02.728411  9023 solver.cpp:222] Iteration 91760 (1.3045 iter/s, 30.663s/40 iters), loss = 1.54965
I1027 19:39:02.728570  9023 solver.cpp:241]     Train net output #0: loss = 1.54965 (* 1 = 1.54965 loss)
I1027 19:39:02.728587  9023 sgd_solver.cpp:105] Iteration 91760, lr = 0.00394072
I1027 19:39:33.363252  9023 solver.cpp:222] Iteration 91800 (1.30576 iter/s, 30.6335s/40 iters), loss = 1.505
I1027 19:39:33.363414  9023 solver.cpp:241]     Train net output #0: loss = 1.505 (* 1 = 1.505 loss)
I1027 19:39:33.363431  9023 sgd_solver.cpp:105] Iteration 91800, lr = 0.00393831
I1027 19:40:04.032143  9023 solver.cpp:222] Iteration 91840 (1.30431 iter/s, 30.6676s/40 iters), loss = 1.68812
I1027 19:40:04.032323  9023 solver.cpp:241]     Train net output #0: loss = 1.68812 (* 1 = 1.68812 loss)
I1027 19:40:04.032342  9023 sgd_solver.cpp:105] Iteration 91840, lr = 0.00393589
I1027 19:40:34.699090  9023 solver.cpp:222] Iteration 91880 (1.30439 iter/s, 30.6656s/40 iters), loss = 1.68391
I1027 19:40:34.699260  9023 solver.cpp:241]     Train net output #0: loss = 1.68391 (* 1 = 1.68391 loss)
I1027 19:40:34.699276  9023 sgd_solver.cpp:105] Iteration 91880, lr = 0.00393347
I1027 19:41:05.967435  9023 solver.cpp:222] Iteration 91920 (1.2793 iter/s, 31.267s/40 iters), loss = 1.9133
I1027 19:41:05.967628  9023 solver.cpp:241]     Train net output #0: loss = 1.9133 (* 1 = 1.9133 loss)
I1027 19:41:05.967644  9023 sgd_solver.cpp:105] Iteration 91920, lr = 0.00393105
I1027 19:41:36.768474  9023 solver.cpp:222] Iteration 91960 (1.29871 iter/s, 30.7997s/40 iters), loss = 1.68804
I1027 19:41:36.768668  9023 solver.cpp:241]     Train net output #0: loss = 1.68804 (* 1 = 1.68804 loss)
I1027 19:41:36.768685  9023 sgd_solver.cpp:105] Iteration 91960, lr = 0.00392864
I1027 19:42:06.815438  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_92000.caffemodel
I1027 19:42:06.847301  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_92000.solverstate
I1027 19:42:06.865336  9023 solver.cpp:334] Iteration 92000, Testing net (#0)
I1027 19:42:37.946841  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 19:42:38.157804  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55488
I1027 19:42:38.157866  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7942
I1027 19:42:38.157878  9023 solver.cpp:401]     Test net output #2: loss = 1.98372 (* 1 = 1.98372 loss)
I1027 19:42:38.926303  9023 solver.cpp:222] Iteration 92000 (0.643549 iter/s, 62.1553s/40 iters), loss = 1.67188
I1027 19:42:38.926383  9023 solver.cpp:241]     Train net output #0: loss = 1.67188 (* 1 = 1.67188 loss)
I1027 19:42:38.926398  9023 sgd_solver.cpp:105] Iteration 92000, lr = 0.00392622
I1027 19:42:55.063540  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1027 19:43:09.644657  9023 solver.cpp:222] Iteration 92040 (1.30221 iter/s, 30.7171s/40 iters), loss = 1.46547
I1027 19:43:09.644891  9023 solver.cpp:241]     Train net output #0: loss = 1.46547 (* 1 = 1.46547 loss)
I1027 19:43:09.644907  9023 sgd_solver.cpp:105] Iteration 92040, lr = 0.00392381
I1027 19:43:40.692114  9023 solver.cpp:222] Iteration 92080 (1.28841 iter/s, 31.0461s/40 iters), loss = 1.85353
I1027 19:43:40.692306  9023 solver.cpp:241]     Train net output #0: loss = 1.85353 (* 1 = 1.85353 loss)
I1027 19:43:40.692323  9023 sgd_solver.cpp:105] Iteration 92080, lr = 0.00392139
I1027 19:44:11.600363  9023 solver.cpp:222] Iteration 92120 (1.29421 iter/s, 30.9069s/40 iters), loss = 1.81364
I1027 19:44:11.600551  9023 solver.cpp:241]     Train net output #0: loss = 1.81364 (* 1 = 1.81364 loss)
I1027 19:44:11.600567  9023 sgd_solver.cpp:105] Iteration 92120, lr = 0.00391897
I1027 19:44:43.012501  9023 solver.cpp:222] Iteration 92160 (1.27345 iter/s, 31.4108s/40 iters), loss = 1.41517
I1027 19:44:43.012678  9023 solver.cpp:241]     Train net output #0: loss = 1.41517 (* 1 = 1.41517 loss)
I1027 19:44:43.012694  9023 sgd_solver.cpp:105] Iteration 92160, lr = 0.00391656
I1027 19:45:13.717119  9023 solver.cpp:222] Iteration 92200 (1.30279 iter/s, 30.7033s/40 iters), loss = 1.59344
I1027 19:45:13.717312  9023 solver.cpp:241]     Train net output #0: loss = 1.59344 (* 1 = 1.59344 loss)
I1027 19:45:13.717332  9023 sgd_solver.cpp:105] Iteration 92200, lr = 0.00391414
I1027 19:45:44.651988  9023 solver.cpp:222] Iteration 92240 (1.2931 iter/s, 30.9335s/40 iters), loss = 1.7228
I1027 19:45:44.652173  9023 solver.cpp:241]     Train net output #0: loss = 1.7228 (* 1 = 1.7228 loss)
I1027 19:45:44.652190  9023 sgd_solver.cpp:105] Iteration 92240, lr = 0.00391173
I1027 19:46:15.780524  9023 solver.cpp:222] Iteration 92280 (1.28505 iter/s, 31.1272s/40 iters), loss = 1.34796
I1027 19:46:15.780748  9023 solver.cpp:241]     Train net output #0: loss = 1.34796 (* 1 = 1.34796 loss)
I1027 19:46:15.780771  9023 sgd_solver.cpp:105] Iteration 92280, lr = 0.00390931
I1027 19:46:46.757773  9023 solver.cpp:222] Iteration 92320 (1.29133 iter/s, 30.9759s/40 iters), loss = 1.46099
I1027 19:46:46.757956  9023 solver.cpp:241]     Train net output #0: loss = 1.46099 (* 1 = 1.46099 loss)
I1027 19:46:46.757972  9023 sgd_solver.cpp:105] Iteration 92320, lr = 0.0039069
I1027 19:47:17.611003  9023 solver.cpp:222] Iteration 92360 (1.29652 iter/s, 30.8519s/40 iters), loss = 1.45559
I1027 19:47:17.611193  9023 solver.cpp:241]     Train net output #0: loss = 1.45559 (* 1 = 1.45559 loss)
I1027 19:47:17.611210  9023 sgd_solver.cpp:105] Iteration 92360, lr = 0.00390449
I1027 19:47:48.397763  9023 solver.cpp:222] Iteration 92400 (1.29932 iter/s, 30.7854s/40 iters), loss = 1.77438
I1027 19:47:48.397958  9023 solver.cpp:241]     Train net output #0: loss = 1.77438 (* 1 = 1.77438 loss)
I1027 19:47:48.397975  9023 sgd_solver.cpp:105] Iteration 92400, lr = 0.00390207
I1027 19:48:19.474943  9023 solver.cpp:222] Iteration 92440 (1.28717 iter/s, 31.0758s/40 iters), loss = 1.65892
I1027 19:48:19.475131  9023 solver.cpp:241]     Train net output #0: loss = 1.65892 (* 1 = 1.65892 loss)
I1027 19:48:19.475148  9023 sgd_solver.cpp:105] Iteration 92440, lr = 0.00389966
I1027 19:48:50.892218  9023 solver.cpp:222] Iteration 92480 (1.27324 iter/s, 31.4159s/40 iters), loss = 1.63412
I1027 19:48:50.892405  9023 solver.cpp:241]     Train net output #0: loss = 1.63412 (* 1 = 1.63412 loss)
I1027 19:48:50.892428  9023 sgd_solver.cpp:105] Iteration 92480, lr = 0.00389725
I1027 19:49:12.433348  9023 solver.cpp:334] Iteration 92500, Testing net (#0)
I1027 19:49:44.326342  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55236
I1027 19:49:44.326506  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7888
I1027 19:49:44.326534  9023 solver.cpp:401]     Test net output #2: loss = 1.98568 (* 1 = 1.98568 loss)
I1027 19:50:13.706871  9023 solver.cpp:222] Iteration 92520 (0.483025 iter/s, 82.8114s/40 iters), loss = 1.73741
I1027 19:50:13.706959  9023 solver.cpp:241]     Train net output #0: loss = 1.73741 (* 1 = 1.73741 loss)
I1027 19:50:13.712893  9023 sgd_solver.cpp:105] Iteration 92520, lr = 0.00389483
I1027 19:50:47.651401  9023 solver.cpp:222] Iteration 92560 (1.17844 iter/s, 33.9432s/40 iters), loss = 1.60821
I1027 19:50:47.651741  9023 solver.cpp:241]     Train net output #0: loss = 1.60821 (* 1 = 1.60821 loss)
I1027 19:50:47.651768  9023 sgd_solver.cpp:105] Iteration 92560, lr = 0.00389242
I1027 19:51:18.522949  9023 solver.cpp:222] Iteration 92600 (1.29576 iter/s, 30.87s/40 iters), loss = 1.41805
I1027 19:51:18.523183  9023 solver.cpp:241]     Train net output #0: loss = 1.41805 (* 1 = 1.41805 loss)
I1027 19:51:18.523201  9023 sgd_solver.cpp:105] Iteration 92600, lr = 0.00389001
I1027 19:51:58.715494  9023 solver.cpp:222] Iteration 92640 (0.995253 iter/s, 40.1908s/40 iters), loss = 1.67693
I1027 19:51:58.715723  9023 solver.cpp:241]     Train net output #0: loss = 1.67693 (* 1 = 1.67693 loss)
I1027 19:51:58.715746  9023 sgd_solver.cpp:105] Iteration 92640, lr = 0.00388759
I1027 19:52:31.342303  9023 solver.cpp:222] Iteration 92680 (1.22604 iter/s, 32.6254s/40 iters), loss = 1.34734
I1027 19:52:31.342488  9023 solver.cpp:241]     Train net output #0: loss = 1.34734 (* 1 = 1.34734 loss)
I1027 19:52:31.342504  9023 sgd_solver.cpp:105] Iteration 92680, lr = 0.00388518
I1027 19:53:02.225355  9023 solver.cpp:222] Iteration 92720 (1.29527 iter/s, 30.8817s/40 iters), loss = 1.4236
I1027 19:53:02.225535  9023 solver.cpp:241]     Train net output #0: loss = 1.4236 (* 1 = 1.4236 loss)
I1027 19:53:02.225551  9023 sgd_solver.cpp:105] Iteration 92720, lr = 0.00388277
I1027 19:53:33.542872  9023 solver.cpp:222] Iteration 92760 (1.2773 iter/s, 31.3162s/40 iters), loss = 1.28626
I1027 19:53:33.543040  9023 solver.cpp:241]     Train net output #0: loss = 1.28626 (* 1 = 1.28626 loss)
I1027 19:53:33.543056  9023 sgd_solver.cpp:105] Iteration 92760, lr = 0.00388036
I1027 19:54:04.608623  9023 solver.cpp:222] Iteration 92800 (1.28765 iter/s, 31.0644s/40 iters), loss = 1.52025
I1027 19:54:04.608799  9023 solver.cpp:241]     Train net output #0: loss = 1.52025 (* 1 = 1.52025 loss)
I1027 19:54:04.608817  9023 sgd_solver.cpp:105] Iteration 92800, lr = 0.00387795
I1027 19:54:35.479187  9023 solver.cpp:222] Iteration 92840 (1.29579 iter/s, 30.8692s/40 iters), loss = 1.76146
I1027 19:54:35.479395  9023 solver.cpp:241]     Train net output #0: loss = 1.76146 (* 1 = 1.76146 loss)
I1027 19:54:35.479411  9023 sgd_solver.cpp:105] Iteration 92840, lr = 0.00387554
I1027 19:55:06.142031  9023 solver.cpp:222] Iteration 92880 (1.30457 iter/s, 30.6615s/40 iters), loss = 1.53269
I1027 19:55:06.142271  9023 solver.cpp:241]     Train net output #0: loss = 1.53269 (* 1 = 1.53269 loss)
I1027 19:55:06.143607  9023 sgd_solver.cpp:105] Iteration 92880, lr = 0.00387313
I1027 19:55:36.913218  9023 solver.cpp:222] Iteration 92920 (1.29998 iter/s, 30.7698s/40 iters), loss = 1.42658
I1027 19:55:36.913431  9023 solver.cpp:241]     Train net output #0: loss = 1.42658 (* 1 = 1.42658 loss)
I1027 19:55:36.913449  9023 sgd_solver.cpp:105] Iteration 92920, lr = 0.00387072
I1027 19:56:07.731098  9023 solver.cpp:222] Iteration 92960 (1.29801 iter/s, 30.8165s/40 iters), loss = 1.83337
I1027 19:56:07.731257  9023 solver.cpp:241]     Train net output #0: loss = 1.83337 (* 1 = 1.83337 loss)
I1027 19:56:07.731273  9023 sgd_solver.cpp:105] Iteration 92960, lr = 0.00386831
I1027 19:56:37.821555  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_93000.caffemodel
I1027 19:56:37.858726  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_93000.solverstate
I1027 19:56:37.880847  9023 solver.cpp:334] Iteration 93000, Testing net (#0)
I1027 19:57:09.578650  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 19:57:09.787781  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55668
I1027 19:57:09.787842  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79124
I1027 19:57:09.787855  9023 solver.cpp:401]     Test net output #2: loss = 1.96137 (* 1 = 1.96137 loss)
I1027 19:57:10.565171  9023 solver.cpp:222] Iteration 93000 (0.636623 iter/s, 62.8316s/40 iters), loss = 1.57956
I1027 19:57:10.565234  9023 solver.cpp:241]     Train net output #0: loss = 1.57956 (* 1 = 1.57956 loss)
I1027 19:57:10.565250  9023 sgd_solver.cpp:105] Iteration 93000, lr = 0.0038659
I1027 19:57:41.499641  9023 solver.cpp:222] Iteration 93040 (1.29311 iter/s, 30.9332s/40 iters), loss = 1.67843
I1027 19:57:41.499846  9023 solver.cpp:241]     Train net output #0: loss = 1.67843 (* 1 = 1.67843 loss)
I1027 19:57:41.499863  9023 sgd_solver.cpp:105] Iteration 93040, lr = 0.00386349
I1027 19:58:13.929862  9023 solver.cpp:222] Iteration 93080 (1.23347 iter/s, 32.4288s/40 iters), loss = 1.36299
I1027 19:58:13.930034  9023 solver.cpp:241]     Train net output #0: loss = 1.36299 (* 1 = 1.36299 loss)
I1027 19:58:13.930050  9023 sgd_solver.cpp:105] Iteration 93080, lr = 0.00386108
I1027 19:58:51.819047  9023 solver.cpp:222] Iteration 93120 (1.05576 iter/s, 37.8876s/40 iters), loss = 1.66409
I1027 19:58:51.819293  9023 solver.cpp:241]     Train net output #0: loss = 1.66409 (* 1 = 1.66409 loss)
I1027 19:58:51.819324  9023 sgd_solver.cpp:105] Iteration 93120, lr = 0.00385867
I1027 19:59:22.566646  9023 solver.cpp:222] Iteration 93160 (1.30097 iter/s, 30.7462s/40 iters), loss = 1.74441
I1027 19:59:22.566820  9023 solver.cpp:241]     Train net output #0: loss = 1.74441 (* 1 = 1.74441 loss)
I1027 19:59:22.566838  9023 sgd_solver.cpp:105] Iteration 93160, lr = 0.00385626
I1027 20:00:00.372916  9023 solver.cpp:222] Iteration 93200 (1.05807 iter/s, 37.8047s/40 iters), loss = 1.85384
I1027 20:00:00.373127  9023 solver.cpp:241]     Train net output #0: loss = 1.85384 (* 1 = 1.85384 loss)
I1027 20:00:00.373162  9023 sgd_solver.cpp:105] Iteration 93200, lr = 0.00385385
I1027 20:00:31.558629  9023 solver.cpp:222] Iteration 93240 (1.2827 iter/s, 31.1843s/40 iters), loss = 1.84746
I1027 20:00:31.558851  9023 solver.cpp:241]     Train net output #0: loss = 1.84746 (* 1 = 1.84746 loss)
I1027 20:00:31.558867  9023 sgd_solver.cpp:105] Iteration 93240, lr = 0.00385144
I1027 20:01:02.309341  9023 solver.cpp:222] Iteration 93280 (1.30084 iter/s, 30.7493s/40 iters), loss = 1.61855
I1027 20:01:02.309530  9023 solver.cpp:241]     Train net output #0: loss = 1.61855 (* 1 = 1.61855 loss)
I1027 20:01:02.309547  9023 sgd_solver.cpp:105] Iteration 93280, lr = 0.00384903
I1027 20:01:33.055665  9023 solver.cpp:222] Iteration 93320 (1.30103 iter/s, 30.745s/40 iters), loss = 1.51243
I1027 20:01:33.055843  9023 solver.cpp:241]     Train net output #0: loss = 1.51243 (* 1 = 1.51243 loss)
I1027 20:01:33.055860  9023 sgd_solver.cpp:105] Iteration 93320, lr = 0.00384662
I1027 20:02:03.566268  9023 solver.cpp:222] Iteration 93360 (1.31108 iter/s, 30.5093s/40 iters), loss = 1.42475
I1027 20:02:03.566457  9023 solver.cpp:241]     Train net output #0: loss = 1.42475 (* 1 = 1.42475 loss)
I1027 20:02:03.566473  9023 sgd_solver.cpp:105] Iteration 93360, lr = 0.00384422
I1027 20:02:34.021782  9023 solver.cpp:222] Iteration 93400 (1.31345 iter/s, 30.4542s/40 iters), loss = 1.5428
I1027 20:02:34.021960  9023 solver.cpp:241]     Train net output #0: loss = 1.5428 (* 1 = 1.5428 loss)
I1027 20:02:34.021976  9023 sgd_solver.cpp:105] Iteration 93400, lr = 0.00384181
I1027 20:03:04.620153  9023 solver.cpp:222] Iteration 93440 (1.30732 iter/s, 30.597s/40 iters), loss = 1.58782
I1027 20:03:04.620316  9023 solver.cpp:241]     Train net output #0: loss = 1.58782 (* 1 = 1.58782 loss)
I1027 20:03:04.620333  9023 sgd_solver.cpp:105] Iteration 93440, lr = 0.0038394
I1027 20:03:35.284066  9023 solver.cpp:222] Iteration 93480 (1.30452 iter/s, 30.6626s/40 iters), loss = 1.53198
I1027 20:03:35.284224  9023 solver.cpp:241]     Train net output #0: loss = 1.53198 (* 1 = 1.53198 loss)
I1027 20:03:35.284260  9023 sgd_solver.cpp:105] Iteration 93480, lr = 0.00383699
I1027 20:03:49.924125  9023 solver.cpp:334] Iteration 93500, Testing net (#0)
I1027 20:04:21.177716  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55756
I1027 20:04:21.177966  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7878
I1027 20:04:21.177984  9023 solver.cpp:401]     Test net output #2: loss = 1.97995 (* 1 = 1.97995 loss)
I1027 20:04:37.307623  9023 solver.cpp:222] Iteration 93520 (0.644942 iter/s, 62.0211s/40 iters), loss = 1.61291
I1027 20:04:37.307689  9023 solver.cpp:241]     Train net output #0: loss = 1.61291 (* 1 = 1.61291 loss)
I1027 20:04:37.307705  9023 sgd_solver.cpp:105] Iteration 93520, lr = 0.00383459
I1027 20:05:08.289358  9023 solver.cpp:222] Iteration 93560 (1.29113 iter/s, 30.9805s/40 iters), loss = 1.41147
I1027 20:05:08.289587  9023 solver.cpp:241]     Train net output #0: loss = 1.41147 (* 1 = 1.41147 loss)
I1027 20:05:08.289608  9023 sgd_solver.cpp:105] Iteration 93560, lr = 0.00383218
I1027 20:05:38.967458  9023 solver.cpp:222] Iteration 93600 (1.30392 iter/s, 30.6767s/40 iters), loss = 1.43025
I1027 20:05:38.967648  9023 solver.cpp:241]     Train net output #0: loss = 1.43025 (* 1 = 1.43025 loss)
I1027 20:05:38.967664  9023 sgd_solver.cpp:105] Iteration 93600, lr = 0.00382978
I1027 20:06:09.515612  9023 solver.cpp:222] Iteration 93640 (1.30947 iter/s, 30.5468s/40 iters), loss = 1.60091
I1027 20:06:09.515763  9023 solver.cpp:241]     Train net output #0: loss = 1.60091 (* 1 = 1.60091 loss)
I1027 20:06:09.515780  9023 sgd_solver.cpp:105] Iteration 93640, lr = 0.00382737
I1027 20:06:40.211064  9023 solver.cpp:222] Iteration 93680 (1.30318 iter/s, 30.6941s/40 iters), loss = 1.56255
I1027 20:06:40.211251  9023 solver.cpp:241]     Train net output #0: loss = 1.56255 (* 1 = 1.56255 loss)
I1027 20:06:40.211267  9023 sgd_solver.cpp:105] Iteration 93680, lr = 0.00382496
I1027 20:07:10.902324  9023 solver.cpp:222] Iteration 93720 (1.30336 iter/s, 30.6899s/40 iters), loss = 1.67122
I1027 20:07:10.902521  9023 solver.cpp:241]     Train net output #0: loss = 1.67122 (* 1 = 1.67122 loss)
I1027 20:07:10.902539  9023 sgd_solver.cpp:105] Iteration 93720, lr = 0.00382256
I1027 20:07:42.928408  9023 solver.cpp:222] Iteration 93760 (1.24904 iter/s, 32.0247s/40 iters), loss = 1.57036
I1027 20:07:42.928640  9023 solver.cpp:241]     Train net output #0: loss = 1.57036 (* 1 = 1.57036 loss)
I1027 20:07:42.928668  9023 sgd_solver.cpp:105] Iteration 93760, lr = 0.00382015
I1027 20:08:14.836503  9023 solver.cpp:222] Iteration 93800 (1.25366 iter/s, 31.9066s/40 iters), loss = 1.28339
I1027 20:08:14.836675  9023 solver.cpp:241]     Train net output #0: loss = 1.28339 (* 1 = 1.28339 loss)
I1027 20:08:14.836693  9023 sgd_solver.cpp:105] Iteration 93800, lr = 0.00381775
I1027 20:08:45.539369  9023 solver.cpp:222] Iteration 93840 (1.30287 iter/s, 30.7015s/40 iters), loss = 1.7935
I1027 20:08:45.539535  9023 solver.cpp:241]     Train net output #0: loss = 1.7935 (* 1 = 1.7935 loss)
I1027 20:08:45.539551  9023 sgd_solver.cpp:105] Iteration 93840, lr = 0.00381534
I1027 20:09:16.205634  9023 solver.cpp:222] Iteration 93880 (1.30442 iter/s, 30.6649s/40 iters), loss = 1.48506
I1027 20:09:16.205799  9023 solver.cpp:241]     Train net output #0: loss = 1.48506 (* 1 = 1.48506 loss)
I1027 20:09:16.205816  9023 sgd_solver.cpp:105] Iteration 93880, lr = 0.00381294
I1027 20:09:47.297150  9023 solver.cpp:222] Iteration 93920 (1.28658 iter/s, 31.0902s/40 iters), loss = 1.92806
I1027 20:09:47.297315  9023 solver.cpp:241]     Train net output #0: loss = 1.92806 (* 1 = 1.92806 loss)
I1027 20:09:47.297332  9023 sgd_solver.cpp:105] Iteration 93920, lr = 0.00381053
I1027 20:10:18.175101  9023 solver.cpp:222] Iteration 93960 (1.29548 iter/s, 30.8766s/40 iters), loss = 1.50183
I1027 20:10:18.175278  9023 solver.cpp:241]     Train net output #0: loss = 1.50183 (* 1 = 1.50183 loss)
I1027 20:10:18.175294  9023 sgd_solver.cpp:105] Iteration 93960, lr = 0.00380813
I1027 20:10:48.079068  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_94000.caffemodel
I1027 20:10:48.111037  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_94000.solverstate
I1027 20:10:48.127900  9023 solver.cpp:334] Iteration 94000, Testing net (#0)
I1027 20:11:19.307751  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 20:11:19.519615  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55844
I1027 20:11:19.519675  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79476
I1027 20:11:19.519687  9023 solver.cpp:401]     Test net output #2: loss = 1.97622 (* 1 = 1.97622 loss)
I1027 20:11:20.287986  9023 solver.cpp:222] Iteration 94000 (0.644015 iter/s, 62.1104s/40 iters), loss = 1.53326
I1027 20:11:20.288058  9023 solver.cpp:241]     Train net output #0: loss = 1.53326 (* 1 = 1.53326 loss)
I1027 20:11:20.288074  9023 sgd_solver.cpp:105] Iteration 94000, lr = 0.00380573
I1027 20:11:50.905925  9023 solver.cpp:222] Iteration 94040 (1.30648 iter/s, 30.6167s/40 iters), loss = 1.81371
I1027 20:11:50.906118  9023 solver.cpp:241]     Train net output #0: loss = 1.81371 (* 1 = 1.81371 loss)
I1027 20:11:50.906134  9023 sgd_solver.cpp:105] Iteration 94040, lr = 0.00380332
I1027 20:12:21.729269  9023 solver.cpp:222] Iteration 94080 (1.29777 iter/s, 30.822s/40 iters), loss = 1.74851
I1027 20:12:21.729476  9023 solver.cpp:241]     Train net output #0: loss = 1.74851 (* 1 = 1.74851 loss)
I1027 20:12:21.729493  9023 sgd_solver.cpp:105] Iteration 94080, lr = 0.00380092
I1027 20:12:56.281854  9023 solver.cpp:222] Iteration 94120 (1.15771 iter/s, 34.5511s/40 iters), loss = 1.82215
I1027 20:12:56.282057  9023 solver.cpp:241]     Train net output #0: loss = 1.82215 (* 1 = 1.82215 loss)
I1027 20:12:56.282073  9023 sgd_solver.cpp:105] Iteration 94120, lr = 0.00379852
I1027 20:13:26.914556  9023 solver.cpp:222] Iteration 94160 (1.30585 iter/s, 30.6313s/40 iters), loss = 1.6969
I1027 20:13:26.914705  9023 solver.cpp:241]     Train net output #0: loss = 1.6969 (* 1 = 1.6969 loss)
I1027 20:13:26.914721  9023 sgd_solver.cpp:105] Iteration 94160, lr = 0.00379611
I1027 20:13:57.433885  9023 solver.cpp:222] Iteration 94200 (1.3107 iter/s, 30.518s/40 iters), loss = 1.55988
I1027 20:13:57.434052  9023 solver.cpp:241]     Train net output #0: loss = 1.55988 (* 1 = 1.55988 loss)
I1027 20:13:57.434068  9023 sgd_solver.cpp:105] Iteration 94200, lr = 0.00379371
I1027 20:14:27.951153  9023 solver.cpp:222] Iteration 94240 (1.31079 iter/s, 30.516s/40 iters), loss = 1.4462
I1027 20:14:27.951324  9023 solver.cpp:241]     Train net output #0: loss = 1.4462 (* 1 = 1.4462 loss)
I1027 20:14:27.951341  9023 sgd_solver.cpp:105] Iteration 94240, lr = 0.00379131
I1027 20:14:58.723848  9023 solver.cpp:222] Iteration 94280 (1.29991 iter/s, 30.7714s/40 iters), loss = 1.6844
I1027 20:14:58.724050  9023 solver.cpp:241]     Train net output #0: loss = 1.6844 (* 1 = 1.6844 loss)
I1027 20:14:58.724066  9023 sgd_solver.cpp:105] Iteration 94280, lr = 0.00378891
I1027 20:15:29.517859  9023 solver.cpp:222] Iteration 94320 (1.29901 iter/s, 30.7926s/40 iters), loss = 1.6042
I1027 20:15:29.518048  9023 solver.cpp:241]     Train net output #0: loss = 1.6042 (* 1 = 1.6042 loss)
I1027 20:15:29.518065  9023 sgd_solver.cpp:105] Iteration 94320, lr = 0.00378651
I1027 20:16:00.351604  9023 solver.cpp:222] Iteration 94360 (1.29734 iter/s, 30.8324s/40 iters), loss = 1.84536
I1027 20:16:00.351783  9023 solver.cpp:241]     Train net output #0: loss = 1.84536 (* 1 = 1.84536 loss)
I1027 20:16:00.351799  9023 sgd_solver.cpp:105] Iteration 94360, lr = 0.0037841
I1027 20:16:31.329838  9023 solver.cpp:222] Iteration 94400 (1.29129 iter/s, 30.9769s/40 iters), loss = 1.28727
I1027 20:16:31.330096  9023 solver.cpp:241]     Train net output #0: loss = 1.28727 (* 1 = 1.28727 loss)
I1027 20:16:31.330119  9023 sgd_solver.cpp:105] Iteration 94400, lr = 0.0037817
I1027 20:17:02.851491  9023 solver.cpp:222] Iteration 94440 (1.26903 iter/s, 31.5202s/40 iters), loss = 1.43561
I1027 20:17:02.851754  9023 solver.cpp:241]     Train net output #0: loss = 1.43561 (* 1 = 1.43561 loss)
I1027 20:17:02.851773  9023 sgd_solver.cpp:105] Iteration 94440, lr = 0.0037793
I1027 20:17:33.885152  9023 solver.cpp:222] Iteration 94480 (1.28898 iter/s, 31.0322s/40 iters), loss = 1.54115
I1027 20:17:33.885392  9023 solver.cpp:241]     Train net output #0: loss = 1.54115 (* 1 = 1.54115 loss)
I1027 20:17:33.885416  9023 sgd_solver.cpp:105] Iteration 94480, lr = 0.0037769
I1027 20:18:48.497619  9023 solver.cpp:334] Iteration 94500, Testing net (#0)
I1027 20:19:20.222373  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55108
I1027 20:19:20.222527  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.788079
I1027 20:19:20.222542  9023 solver.cpp:401]     Test net output #2: loss = 1.99073 (* 1 = 1.99073 loss)
I1027 20:19:36.600363  9023 solver.cpp:222] Iteration 94520 (0.325971 iter/s, 122.71s/40 iters), loss = 1.71059
I1027 20:19:36.600455  9023 solver.cpp:241]     Train net output #0: loss = 1.71059 (* 1 = 1.71059 loss)
I1027 20:19:36.600481  9023 sgd_solver.cpp:105] Iteration 94520, lr = 0.0037745
I1027 20:19:41.090728  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1027 20:20:08.391520  9023 solver.cpp:222] Iteration 94560 (1.25826 iter/s, 31.7899s/40 iters), loss = 1.65311
I1027 20:20:08.391775  9023 solver.cpp:241]     Train net output #0: loss = 1.65311 (* 1 = 1.65311 loss)
I1027 20:20:08.391803  9023 sgd_solver.cpp:105] Iteration 94560, lr = 0.0037721
I1027 20:20:38.988435  9023 solver.cpp:222] Iteration 94600 (1.30738 iter/s, 30.5955s/40 iters), loss = 1.95286
I1027 20:20:38.988597  9023 solver.cpp:241]     Train net output #0: loss = 1.95286 (* 1 = 1.95286 loss)
I1027 20:20:38.988613  9023 sgd_solver.cpp:105] Iteration 94600, lr = 0.0037697
I1027 20:21:09.564882  9023 solver.cpp:222] Iteration 94640 (1.30825 iter/s, 30.5751s/40 iters), loss = 1.86418
I1027 20:21:09.565095  9023 solver.cpp:241]     Train net output #0: loss = 1.86418 (* 1 = 1.86418 loss)
I1027 20:21:09.565112  9023 sgd_solver.cpp:105] Iteration 94640, lr = 0.0037673
I1027 20:21:40.075966  9023 solver.cpp:222] Iteration 94680 (1.31106 iter/s, 30.5097s/40 iters), loss = 1.51089
I1027 20:21:40.076113  9023 solver.cpp:241]     Train net output #0: loss = 1.51089 (* 1 = 1.51089 loss)
I1027 20:21:40.076134  9023 sgd_solver.cpp:105] Iteration 94680, lr = 0.0037649
I1027 20:22:11.404795  9023 solver.cpp:222] Iteration 94720 (1.27683 iter/s, 31.3275s/40 iters), loss = 1.59272
I1027 20:22:11.405019  9023 solver.cpp:241]     Train net output #0: loss = 1.59272 (* 1 = 1.59272 loss)
I1027 20:22:11.405040  9023 sgd_solver.cpp:105] Iteration 94720, lr = 0.0037625
I1027 20:22:54.422660  9023 solver.cpp:222] Iteration 94760 (0.929886 iter/s, 43.016s/40 iters), loss = 1.76832
I1027 20:22:54.422821  9023 solver.cpp:241]     Train net output #0: loss = 1.76832 (* 1 = 1.76832 loss)
I1027 20:22:54.422837  9023 sgd_solver.cpp:105] Iteration 94760, lr = 0.0037601
I1027 20:23:25.329619  9023 solver.cpp:222] Iteration 94800 (1.29426 iter/s, 30.9056s/40 iters), loss = 1.52897
I1027 20:23:25.329804  9023 solver.cpp:241]     Train net output #0: loss = 1.52897 (* 1 = 1.52897 loss)
I1027 20:23:25.329824  9023 sgd_solver.cpp:105] Iteration 94800, lr = 0.0037577
I1027 20:23:55.949026  9023 solver.cpp:222] Iteration 94840 (1.30642 iter/s, 30.6181s/40 iters), loss = 1.20817
I1027 20:23:55.949214  9023 solver.cpp:241]     Train net output #0: loss = 1.20817 (* 1 = 1.20817 loss)
I1027 20:23:55.949231  9023 sgd_solver.cpp:105] Iteration 94840, lr = 0.00375531
I1027 20:24:26.812221  9023 solver.cpp:222] Iteration 94880 (1.2961 iter/s, 30.8618s/40 iters), loss = 1.89096
I1027 20:24:26.812386  9023 solver.cpp:241]     Train net output #0: loss = 1.89096 (* 1 = 1.89096 loss)
I1027 20:24:26.812402  9023 sgd_solver.cpp:105] Iteration 94880, lr = 0.00375291
I1027 20:24:57.769057  9023 solver.cpp:222] Iteration 94920 (1.29218 iter/s, 30.9555s/40 iters), loss = 2.04621
I1027 20:24:57.769271  9023 solver.cpp:241]     Train net output #0: loss = 2.04621 (* 1 = 2.04621 loss)
I1027 20:24:57.769310  9023 sgd_solver.cpp:105] Iteration 94920, lr = 0.00375051
I1027 20:25:28.668691  9023 solver.cpp:222] Iteration 94960 (1.29457 iter/s, 30.8983s/40 iters), loss = 1.8001
I1027 20:25:28.668936  9023 solver.cpp:241]     Train net output #0: loss = 1.8001 (* 1 = 1.8001 loss)
I1027 20:25:28.668956  9023 sgd_solver.cpp:105] Iteration 94960, lr = 0.00374811
I1027 20:25:58.794102  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_95000.caffemodel
I1027 20:25:58.826472  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_95000.solverstate
I1027 20:25:58.843207  9023 solver.cpp:334] Iteration 95000, Testing net (#0)
I1027 20:26:30.130439  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 20:26:30.338907  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55608
I1027 20:26:30.338966  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79296
I1027 20:26:30.338979  9023 solver.cpp:401]     Test net output #2: loss = 1.98137 (* 1 = 1.98137 loss)
I1027 20:26:31.105181  9023 solver.cpp:222] Iteration 95000 (0.640678 iter/s, 62.4339s/40 iters), loss = 1.43378
I1027 20:26:31.105249  9023 solver.cpp:241]     Train net output #0: loss = 1.43378 (* 1 = 1.43378 loss)
I1027 20:26:31.105265  9023 sgd_solver.cpp:105] Iteration 95000, lr = 0.00374572
I1027 20:27:02.205818  9023 solver.cpp:222] Iteration 95040 (1.2862 iter/s, 31.0994s/40 iters), loss = 1.4286
I1027 20:27:02.206007  9023 solver.cpp:241]     Train net output #0: loss = 1.4286 (* 1 = 1.4286 loss)
I1027 20:27:02.206022  9023 sgd_solver.cpp:105] Iteration 95040, lr = 0.00374332
I1027 20:27:33.168625  9023 solver.cpp:222] Iteration 95080 (1.29193 iter/s, 30.9615s/40 iters), loss = 1.69235
I1027 20:27:33.168824  9023 solver.cpp:241]     Train net output #0: loss = 1.69235 (* 1 = 1.69235 loss)
I1027 20:27:33.168841  9023 sgd_solver.cpp:105] Iteration 95080, lr = 0.00374092
I1027 20:28:04.120069  9023 solver.cpp:222] Iteration 95120 (1.2924 iter/s, 30.9501s/40 iters), loss = 1.40775
I1027 20:28:04.120256  9023 solver.cpp:241]     Train net output #0: loss = 1.40775 (* 1 = 1.40775 loss)
I1027 20:28:04.120272  9023 sgd_solver.cpp:105] Iteration 95120, lr = 0.00373852
I1027 20:28:34.922134  9023 solver.cpp:222] Iteration 95160 (1.29867 iter/s, 30.8007s/40 iters), loss = 1.91269
I1027 20:28:34.922340  9023 solver.cpp:241]     Train net output #0: loss = 1.91269 (* 1 = 1.91269 loss)
I1027 20:28:34.922358  9023 sgd_solver.cpp:105] Iteration 95160, lr = 0.00373613
I1027 20:29:05.555723  9023 solver.cpp:222] Iteration 95200 (1.30581 iter/s, 30.6322s/40 iters), loss = 1.62776
I1027 20:29:05.555887  9023 solver.cpp:241]     Train net output #0: loss = 1.62776 (* 1 = 1.62776 loss)
I1027 20:29:05.555904  9023 sgd_solver.cpp:105] Iteration 95200, lr = 0.00373373
I1027 20:29:36.741403  9023 solver.cpp:222] Iteration 95240 (1.2827 iter/s, 31.1843s/40 iters), loss = 1.41678
I1027 20:29:36.741611  9023 solver.cpp:241]     Train net output #0: loss = 1.41678 (* 1 = 1.41678 loss)
I1027 20:29:36.741628  9023 sgd_solver.cpp:105] Iteration 95240, lr = 0.00373134
I1027 20:30:07.583395  9023 solver.cpp:222] Iteration 95280 (1.29699 iter/s, 30.8406s/40 iters), loss = 1.68322
I1027 20:30:07.583633  9023 solver.cpp:241]     Train net output #0: loss = 1.68322 (* 1 = 1.68322 loss)
I1027 20:30:07.584169  9023 sgd_solver.cpp:105] Iteration 95280, lr = 0.00372894
I1027 20:30:38.633002  9023 solver.cpp:222] Iteration 95320 (1.28832 iter/s, 31.0482s/40 iters), loss = 1.79641
I1027 20:30:38.633183  9023 solver.cpp:241]     Train net output #0: loss = 1.79641 (* 1 = 1.79641 loss)
I1027 20:30:38.633199  9023 sgd_solver.cpp:105] Iteration 95320, lr = 0.00372655
I1027 20:31:09.856415  9023 solver.cpp:222] Iteration 95360 (1.28115 iter/s, 31.2221s/40 iters), loss = 1.36966
I1027 20:31:09.856607  9023 solver.cpp:241]     Train net output #0: loss = 1.36966 (* 1 = 1.36966 loss)
I1027 20:31:09.856624  9023 sgd_solver.cpp:105] Iteration 95360, lr = 0.00372415
I1027 20:31:40.848529  9023 solver.cpp:222] Iteration 95400 (1.29071 iter/s, 30.9908s/40 iters), loss = 1.5334
I1027 20:31:40.848794  9023 solver.cpp:241]     Train net output #0: loss = 1.5334 (* 1 = 1.5334 loss)
I1027 20:31:40.848814  9023 sgd_solver.cpp:105] Iteration 95400, lr = 0.00372176
I1027 20:32:11.651958  9023 solver.cpp:222] Iteration 95440 (1.29862 iter/s, 30.802s/40 iters), loss = 1.7054
I1027 20:32:11.652150  9023 solver.cpp:241]     Train net output #0: loss = 1.7054 (* 1 = 1.7054 loss)
I1027 20:32:11.652166  9023 sgd_solver.cpp:105] Iteration 95440, lr = 0.00371936
I1027 20:32:42.250588  9023 solver.cpp:222] Iteration 95480 (1.30731 iter/s, 30.5973s/40 iters), loss = 1.70232
I1027 20:32:42.250783  9023 solver.cpp:241]     Train net output #0: loss = 1.70232 (* 1 = 1.70232 loss)
I1027 20:32:42.250800  9023 sgd_solver.cpp:105] Iteration 95480, lr = 0.00371697
I1027 20:32:56.921432  9023 solver.cpp:334] Iteration 95500, Testing net (#0)
I1027 20:33:28.481317  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5612
I1027 20:33:28.481467  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.793039
I1027 20:33:28.481482  9023 solver.cpp:401]     Test net output #2: loss = 1.95442 (* 1 = 1.95442 loss)
I1027 20:33:44.567056  9023 solver.cpp:222] Iteration 95520 (0.641911 iter/s, 62.3139s/40 iters), loss = 1.2662
I1027 20:33:44.567124  9023 solver.cpp:241]     Train net output #0: loss = 1.2662 (* 1 = 1.2662 loss)
I1027 20:33:44.567139  9023 sgd_solver.cpp:105] Iteration 95520, lr = 0.00371457
I1027 20:34:14.841984  9023 solver.cpp:222] Iteration 95560 (1.32128 iter/s, 30.2737s/40 iters), loss = 1.65109
I1027 20:34:14.842154  9023 solver.cpp:241]     Train net output #0: loss = 1.65109 (* 1 = 1.65109 loss)
I1027 20:34:14.842170  9023 sgd_solver.cpp:105] Iteration 95560, lr = 0.00371218
I1027 20:34:45.187371  9023 solver.cpp:222] Iteration 95600 (1.31821 iter/s, 30.3441s/40 iters), loss = 1.60756
I1027 20:34:45.187532  9023 solver.cpp:241]     Train net output #0: loss = 1.60756 (* 1 = 1.60756 loss)
I1027 20:34:45.187549  9023 sgd_solver.cpp:105] Iteration 95600, lr = 0.00370979
I1027 20:35:15.582027  9023 solver.cpp:222] Iteration 95640 (1.31608 iter/s, 30.3934s/40 iters), loss = 1.4927
I1027 20:35:15.582176  9023 solver.cpp:241]     Train net output #0: loss = 1.4927 (* 1 = 1.4927 loss)
I1027 20:35:15.582192  9023 sgd_solver.cpp:105] Iteration 95640, lr = 0.00370739
I1027 20:35:46.062762  9023 solver.cpp:222] Iteration 95680 (1.31236 iter/s, 30.4794s/40 iters), loss = 1.59762
I1027 20:35:46.062928  9023 solver.cpp:241]     Train net output #0: loss = 1.59762 (* 1 = 1.59762 loss)
I1027 20:35:46.062944  9023 sgd_solver.cpp:105] Iteration 95680, lr = 0.003705
I1027 20:36:16.613346  9023 solver.cpp:222] Iteration 95720 (1.30936 iter/s, 30.5493s/40 iters), loss = 1.54516
I1027 20:36:16.613504  9023 solver.cpp:241]     Train net output #0: loss = 1.54516 (* 1 = 1.54516 loss)
I1027 20:36:16.613520  9023 sgd_solver.cpp:105] Iteration 95720, lr = 0.00370261
I1027 20:36:47.204587  9023 solver.cpp:222] Iteration 95760 (1.30762 iter/s, 30.5899s/40 iters), loss = 1.98097
I1027 20:36:47.204743  9023 solver.cpp:241]     Train net output #0: loss = 1.98097 (* 1 = 1.98097 loss)
I1027 20:36:47.204759  9023 sgd_solver.cpp:105] Iteration 95760, lr = 0.00370021
I1027 20:37:17.856276  9023 solver.cpp:222] Iteration 95800 (1.30504 iter/s, 30.6504s/40 iters), loss = 1.50143
I1027 20:37:17.856433  9023 solver.cpp:241]     Train net output #0: loss = 1.50143 (* 1 = 1.50143 loss)
I1027 20:37:17.856449  9023 sgd_solver.cpp:105] Iteration 95800, lr = 0.00369782
I1027 20:37:48.595428  9023 solver.cpp:222] Iteration 95840 (1.30133 iter/s, 30.7378s/40 iters), loss = 1.26912
I1027 20:37:48.595615  9023 solver.cpp:241]     Train net output #0: loss = 1.26912 (* 1 = 1.26912 loss)
I1027 20:37:48.595633  9023 sgd_solver.cpp:105] Iteration 95840, lr = 0.00369543
I1027 20:38:19.516868  9023 solver.cpp:222] Iteration 95880 (1.29366 iter/s, 30.9201s/40 iters), loss = 1.59216
I1027 20:38:19.517105  9023 solver.cpp:241]     Train net output #0: loss = 1.59216 (* 1 = 1.59216 loss)
I1027 20:38:19.517122  9023 sgd_solver.cpp:105] Iteration 95880, lr = 0.00369304
I1027 20:38:50.275897  9023 solver.cpp:222] Iteration 95920 (1.30049 iter/s, 30.7576s/40 iters), loss = 1.48054
I1027 20:38:50.276057  9023 solver.cpp:241]     Train net output #0: loss = 1.48054 (* 1 = 1.48054 loss)
I1027 20:38:50.276072  9023 sgd_solver.cpp:105] Iteration 95920, lr = 0.00369065
I1027 20:39:20.957523  9023 solver.cpp:222] Iteration 95960 (1.30377 iter/s, 30.6803s/40 iters), loss = 1.80084
I1027 20:39:20.957682  9023 solver.cpp:241]     Train net output #0: loss = 1.80084 (* 1 = 1.80084 loss)
I1027 20:39:20.957698  9023 sgd_solver.cpp:105] Iteration 95960, lr = 0.00368826
I1027 20:39:50.837874  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_96000.caffemodel
I1027 20:39:50.869125  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_96000.solverstate
I1027 20:39:50.885798  9023 solver.cpp:334] Iteration 96000, Testing net (#0)
I1027 20:40:22.175633  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 20:40:22.388594  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55192
I1027 20:40:22.388659  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.792159
I1027 20:40:22.388672  9023 solver.cpp:401]     Test net output #2: loss = 1.96461 (* 1 = 1.96461 loss)
I1027 20:40:23.161592  9023 solver.cpp:222] Iteration 96000 (0.64307 iter/s, 62.2016s/40 iters), loss = 1.49674
I1027 20:40:23.161651  9023 solver.cpp:241]     Train net output #0: loss = 1.49674 (* 1 = 1.49674 loss)
I1027 20:40:23.161665  9023 sgd_solver.cpp:105] Iteration 96000, lr = 0.00368586
I1027 20:40:54.716828  9023 solver.cpp:222] Iteration 96040 (1.26767 iter/s, 31.554s/40 iters), loss = 2.0155
I1027 20:40:54.717037  9023 solver.cpp:241]     Train net output #0: loss = 2.0155 (* 1 = 2.0155 loss)
I1027 20:40:54.717054  9023 sgd_solver.cpp:105] Iteration 96040, lr = 0.00368347
I1027 20:41:26.095659  9023 solver.cpp:222] Iteration 96080 (1.2748 iter/s, 31.3774s/40 iters), loss = 1.4954
I1027 20:41:26.095897  9023 solver.cpp:241]     Train net output #0: loss = 1.4954 (* 1 = 1.4954 loss)
I1027 20:41:26.095926  9023 sgd_solver.cpp:105] Iteration 96080, lr = 0.00368108
I1027 20:41:57.275800  9023 solver.cpp:222] Iteration 96120 (1.28293 iter/s, 31.1787s/40 iters), loss = 1.67082
I1027 20:41:57.275977  9023 solver.cpp:241]     Train net output #0: loss = 1.67082 (* 1 = 1.67082 loss)
I1027 20:41:57.275993  9023 sgd_solver.cpp:105] Iteration 96120, lr = 0.00367869
I1027 20:42:27.964293  9023 solver.cpp:222] Iteration 96160 (1.30348 iter/s, 30.6872s/40 iters), loss = 1.58623
I1027 20:42:27.964458  9023 solver.cpp:241]     Train net output #0: loss = 1.58623 (* 1 = 1.58623 loss)
I1027 20:42:27.964474  9023 sgd_solver.cpp:105] Iteration 96160, lr = 0.0036763
I1027 20:42:58.631955  9023 solver.cpp:222] Iteration 96200 (1.30436 iter/s, 30.6663s/40 iters), loss = 1.9793
I1027 20:42:58.632114  9023 solver.cpp:241]     Train net output #0: loss = 1.9793 (* 1 = 1.9793 loss)
I1027 20:42:58.632130  9023 sgd_solver.cpp:105] Iteration 96200, lr = 0.00367391
I1027 20:43:29.154475  9023 solver.cpp:222] Iteration 96240 (1.31056 iter/s, 30.5212s/40 iters), loss = 1.51981
I1027 20:43:29.154615  9023 solver.cpp:241]     Train net output #0: loss = 1.51981 (* 1 = 1.51981 loss)
I1027 20:43:29.154630  9023 sgd_solver.cpp:105] Iteration 96240, lr = 0.00367152
I1027 20:44:10.511174  9023 solver.cpp:222] Iteration 96280 (0.967235 iter/s, 41.355s/40 iters), loss = 1.89182
I1027 20:44:10.511467  9023 solver.cpp:241]     Train net output #0: loss = 1.89182 (* 1 = 1.89182 loss)
I1027 20:44:10.511507  9023 sgd_solver.cpp:105] Iteration 96280, lr = 0.00366913
I1027 20:44:41.836216  9023 solver.cpp:222] Iteration 96320 (1.27699 iter/s, 31.3236s/40 iters), loss = 1.50022
I1027 20:44:41.836402  9023 solver.cpp:241]     Train net output #0: loss = 1.50022 (* 1 = 1.50022 loss)
I1027 20:44:41.836870  9023 sgd_solver.cpp:105] Iteration 96320, lr = 0.00366675
I1027 20:45:12.479295  9023 solver.cpp:222] Iteration 96360 (1.30541 iter/s, 30.6417s/40 iters), loss = 1.50443
I1027 20:45:12.479538  9023 solver.cpp:241]     Train net output #0: loss = 1.50443 (* 1 = 1.50443 loss)
I1027 20:45:12.479576  9023 sgd_solver.cpp:105] Iteration 96360, lr = 0.00366436
I1027 20:45:42.993048  9023 solver.cpp:222] Iteration 96400 (1.31094 iter/s, 30.5124s/40 iters), loss = 1.69999
I1027 20:45:42.993240  9023 solver.cpp:241]     Train net output #0: loss = 1.69999 (* 1 = 1.69999 loss)
I1027 20:45:42.993257  9023 sgd_solver.cpp:105] Iteration 96400, lr = 0.00366197
I1027 20:46:13.817600  9023 solver.cpp:222] Iteration 96440 (1.29772 iter/s, 30.8232s/40 iters), loss = 1.69088
I1027 20:46:13.817775  9023 solver.cpp:241]     Train net output #0: loss = 1.69088 (* 1 = 1.69088 loss)
I1027 20:46:13.817791  9023 sgd_solver.cpp:105] Iteration 96440, lr = 0.00365958
I1027 20:46:44.744204  9023 solver.cpp:222] Iteration 96480 (1.29344 iter/s, 30.9253s/40 iters), loss = 1.67191
I1027 20:46:44.744390  9023 solver.cpp:241]     Train net output #0: loss = 1.67191 (* 1 = 1.67191 loss)
I1027 20:46:44.744406  9023 sgd_solver.cpp:105] Iteration 96480, lr = 0.00365719
I1027 20:46:59.737994  9023 solver.cpp:334] Iteration 96500, Testing net (#0)
I1027 20:47:31.476119  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55308
I1027 20:47:31.476336  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78708
I1027 20:47:31.476352  9023 solver.cpp:401]     Test net output #2: loss = 1.98718 (* 1 = 1.98718 loss)
I1027 20:47:48.369048  9023 solver.cpp:222] Iteration 96520 (0.628711 iter/s, 63.6223s/40 iters), loss = 1.74843
I1027 20:47:48.369114  9023 solver.cpp:241]     Train net output #0: loss = 1.74843 (* 1 = 1.74843 loss)
I1027 20:47:48.369130  9023 sgd_solver.cpp:105] Iteration 96520, lr = 0.00365481
I1027 20:48:20.194677  9023 solver.cpp:222] Iteration 96560 (1.2569 iter/s, 31.8244s/40 iters), loss = 1.42892
I1027 20:48:20.194922  9023 solver.cpp:241]     Train net output #0: loss = 1.42892 (* 1 = 1.42892 loss)
I1027 20:48:20.194955  9023 sgd_solver.cpp:105] Iteration 96560, lr = 0.00365242
I1027 20:48:53.079937  9023 solver.cpp:222] Iteration 96600 (1.21641 iter/s, 32.8838s/40 iters), loss = 1.7579
I1027 20:48:53.080178  9023 solver.cpp:241]     Train net output #0: loss = 1.7579 (* 1 = 1.7579 loss)
I1027 20:48:53.080205  9023 sgd_solver.cpp:105] Iteration 96600, lr = 0.00365003
I1027 20:49:26.183354  9023 solver.cpp:222] Iteration 96640 (1.20839 iter/s, 33.1019s/40 iters), loss = 1.3174
I1027 20:49:26.183531  9023 solver.cpp:241]     Train net output #0: loss = 1.3174 (* 1 = 1.3174 loss)
I1027 20:49:26.183547  9023 sgd_solver.cpp:105] Iteration 96640, lr = 0.00364764
I1027 20:49:59.446164  9023 solver.cpp:222] Iteration 96680 (1.2026 iter/s, 33.2614s/40 iters), loss = 1.39928
I1027 20:49:59.446419  9023 solver.cpp:241]     Train net output #0: loss = 1.39928 (* 1 = 1.39928 loss)
I1027 20:49:59.446436  9023 sgd_solver.cpp:105] Iteration 96680, lr = 0.00364526
I1027 20:50:38.995129  9023 solver.cpp:222] Iteration 96720 (1.01145 iter/s, 39.5472s/40 iters), loss = 1.40051
I1027 20:50:38.995390  9023 solver.cpp:241]     Train net output #0: loss = 1.40051 (* 1 = 1.40051 loss)
I1027 20:50:38.995420  9023 sgd_solver.cpp:105] Iteration 96720, lr = 0.00364287
I1027 20:51:09.860787  9023 solver.cpp:222] Iteration 96760 (1.296 iter/s, 30.8642s/40 iters), loss = 1.46432
I1027 20:51:09.860960  9023 solver.cpp:241]     Train net output #0: loss = 1.46432 (* 1 = 1.46432 loss)
I1027 20:51:09.860975  9023 sgd_solver.cpp:105] Iteration 96760, lr = 0.00364048
I1027 20:51:40.469322  9023 solver.cpp:222] Iteration 96800 (1.30688 iter/s, 30.6072s/40 iters), loss = 1.48438
I1027 20:51:40.469391  9023 solver.cpp:241]     Train net output #0: loss = 1.48438 (* 1 = 1.48438 loss)
I1027 20:51:40.469406  9023 sgd_solver.cpp:105] Iteration 96800, lr = 0.0036381
I1027 20:52:11.143169  9023 solver.cpp:222] Iteration 96840 (1.30409 iter/s, 30.6726s/40 iters), loss = 1.39922
I1027 20:52:11.143538  9023 solver.cpp:241]     Train net output #0: loss = 1.39922 (* 1 = 1.39922 loss)
I1027 20:52:11.143554  9023 sgd_solver.cpp:105] Iteration 96840, lr = 0.00363571
I1027 20:52:41.739356  9023 solver.cpp:222] Iteration 96880 (1.30742 iter/s, 30.5947s/40 iters), loss = 1.47997
I1027 20:52:41.739495  9023 solver.cpp:241]     Train net output #0: loss = 1.47997 (* 1 = 1.47997 loss)
I1027 20:52:41.739511  9023 sgd_solver.cpp:105] Iteration 96880, lr = 0.00363333
I1027 20:53:12.336963  9023 solver.cpp:222] Iteration 96920 (1.30735 iter/s, 30.5963s/40 iters), loss = 1.57846
I1027 20:53:12.337115  9023 solver.cpp:241]     Train net output #0: loss = 1.57846 (* 1 = 1.57846 loss)
I1027 20:53:12.337129  9023 sgd_solver.cpp:105] Iteration 96920, lr = 0.00363094
I1027 20:53:42.909730  9023 solver.cpp:222] Iteration 96960 (1.30841 iter/s, 30.5715s/40 iters), loss = 1.6234
I1027 20:53:42.909838  9023 solver.cpp:241]     Train net output #0: loss = 1.6234 (* 1 = 1.6234 loss)
I1027 20:53:42.909853  9023 sgd_solver.cpp:105] Iteration 96960, lr = 0.00362856
I1027 20:54:12.702666  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_97000.caffemodel
I1027 20:54:12.746098  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_97000.solverstate
I1027 20:54:12.762800  9023 solver.cpp:334] Iteration 97000, Testing net (#0)
I1027 20:54:43.948101  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 20:54:44.157387  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55232
I1027 20:54:44.157447  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.790719
I1027 20:54:44.157461  9023 solver.cpp:401]     Test net output #2: loss = 1.9852 (* 1 = 1.9852 loss)
I1027 20:54:44.921456  9023 solver.cpp:222] Iteration 97000 (0.645064 iter/s, 62.0093s/40 iters), loss = 1.62049
I1027 20:54:44.921496  9023 solver.cpp:241]     Train net output #0: loss = 1.62049 (* 1 = 1.62049 loss)
I1027 20:54:44.921510  9023 sgd_solver.cpp:105] Iteration 97000, lr = 0.00362617
I1027 20:55:04.573346  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1027 20:55:15.931879  9023 solver.cpp:222] Iteration 97040 (1.28994 iter/s, 31.0092s/40 iters), loss = 1.64807
I1027 20:55:15.932083  9023 solver.cpp:241]     Train net output #0: loss = 1.64807 (* 1 = 1.64807 loss)
I1027 20:55:15.932099  9023 sgd_solver.cpp:105] Iteration 97040, lr = 0.00362379
I1027 20:55:46.537870  9023 solver.cpp:222] Iteration 97080 (1.30699 iter/s, 30.6046s/40 iters), loss = 1.74007
I1027 20:55:46.538076  9023 solver.cpp:241]     Train net output #0: loss = 1.74007 (* 1 = 1.74007 loss)
I1027 20:55:46.538094  9023 sgd_solver.cpp:105] Iteration 97080, lr = 0.00362141
I1027 20:56:17.560009  9023 solver.cpp:222] Iteration 97120 (1.28946 iter/s, 31.0208s/40 iters), loss = 1.82406
I1027 20:56:17.560207  9023 solver.cpp:241]     Train net output #0: loss = 1.82406 (* 1 = 1.82406 loss)
I1027 20:56:17.560225  9023 sgd_solver.cpp:105] Iteration 97120, lr = 0.00361902
I1027 20:56:48.800287  9023 solver.cpp:222] Iteration 97160 (1.28045 iter/s, 31.2389s/40 iters), loss = 1.43253
I1027 20:56:48.800463  9023 solver.cpp:241]     Train net output #0: loss = 1.43253 (* 1 = 1.43253 loss)
I1027 20:56:48.800479  9023 sgd_solver.cpp:105] Iteration 97160, lr = 0.00361664
I1027 20:57:19.389819  9023 solver.cpp:222] Iteration 97200 (1.30769 iter/s, 30.5882s/40 iters), loss = 1.38795
I1027 20:57:19.389989  9023 solver.cpp:241]     Train net output #0: loss = 1.38795 (* 1 = 1.38795 loss)
I1027 20:57:19.390005  9023 sgd_solver.cpp:105] Iteration 97200, lr = 0.00361426
I1027 20:57:48.966764  9023 solver.cpp:222] Iteration 97240 (1.35246 iter/s, 29.5757s/40 iters), loss = 1.71663
I1027 20:57:48.966830  9023 solver.cpp:241]     Train net output #0: loss = 1.71663 (* 1 = 1.71663 loss)
I1027 20:57:48.966845  9023 sgd_solver.cpp:105] Iteration 97240, lr = 0.00361187
I1027 20:58:20.419724  9023 solver.cpp:222] Iteration 97280 (1.27179 iter/s, 31.4517s/40 iters), loss = 1.66619
I1027 20:58:20.419986  9023 solver.cpp:241]     Train net output #0: loss = 1.66619 (* 1 = 1.66619 loss)
I1027 20:58:20.420003  9023 sgd_solver.cpp:105] Iteration 97280, lr = 0.00360949
I1027 20:58:51.228688  9023 solver.cpp:222] Iteration 97320 (1.29838 iter/s, 30.8075s/40 iters), loss = 1.45125
I1027 20:58:51.228876  9023 solver.cpp:241]     Train net output #0: loss = 1.45125 (* 1 = 1.45125 loss)
I1027 20:58:51.228893  9023 sgd_solver.cpp:105] Iteration 97320, lr = 0.00360711
I1027 20:59:21.998217  9023 solver.cpp:222] Iteration 97360 (1.30004 iter/s, 30.7682s/40 iters), loss = 1.63458
I1027 20:59:21.998405  9023 solver.cpp:241]     Train net output #0: loss = 1.63458 (* 1 = 1.63458 loss)
I1027 20:59:21.998422  9023 sgd_solver.cpp:105] Iteration 97360, lr = 0.00360473
I1027 20:59:53.168697  9023 solver.cpp:222] Iteration 97400 (1.28332 iter/s, 31.1691s/40 iters), loss = 1.62908
I1027 20:59:53.168879  9023 solver.cpp:241]     Train net output #0: loss = 1.62908 (* 1 = 1.62908 loss)
I1027 20:59:53.168895  9023 sgd_solver.cpp:105] Iteration 97400, lr = 0.00360234
I1027 21:00:23.958940  9023 solver.cpp:222] Iteration 97440 (1.29917 iter/s, 30.7889s/40 iters), loss = 1.67752
I1027 21:00:23.959096  9023 solver.cpp:241]     Train net output #0: loss = 1.67752 (* 1 = 1.67752 loss)
I1027 21:00:23.959112  9023 sgd_solver.cpp:105] Iteration 97440, lr = 0.00359996
I1027 21:00:55.164400  9023 solver.cpp:222] Iteration 97480 (1.28188 iter/s, 31.2041s/40 iters), loss = 1.46199
I1027 21:00:55.164598  9023 solver.cpp:241]     Train net output #0: loss = 1.46199 (* 1 = 1.46199 loss)
I1027 21:00:55.164614  9023 sgd_solver.cpp:105] Iteration 97480, lr = 0.00359758
I1027 21:01:09.950529  9023 solver.cpp:334] Iteration 97500, Testing net (#0)
I1027 21:01:41.240198  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55868
I1027 21:01:41.240561  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.792719
I1027 21:01:41.240576  9023 solver.cpp:401]     Test net output #2: loss = 1.9971 (* 1 = 1.9971 loss)
I1027 21:01:57.368095  9023 solver.cpp:222] Iteration 97520 (0.643075 iter/s, 62.2012s/40 iters), loss = 1.65442
I1027 21:01:57.368145  9023 solver.cpp:241]     Train net output #0: loss = 1.65442 (* 1 = 1.65442 loss)
I1027 21:01:57.368160  9023 sgd_solver.cpp:105] Iteration 97520, lr = 0.0035952
I1027 21:02:28.171167  9023 solver.cpp:222] Iteration 97560 (1.29862 iter/s, 30.8019s/40 iters), loss = 1.63039
I1027 21:02:28.171336  9023 solver.cpp:241]     Train net output #0: loss = 1.63039 (* 1 = 1.63039 loss)
I1027 21:02:28.171353  9023 sgd_solver.cpp:105] Iteration 97560, lr = 0.00359282
I1027 21:02:59.109939  9023 solver.cpp:222] Iteration 97600 (1.29293 iter/s, 30.9374s/40 iters), loss = 1.70884
I1027 21:02:59.110106  9023 solver.cpp:241]     Train net output #0: loss = 1.70884 (* 1 = 1.70884 loss)
I1027 21:02:59.110121  9023 sgd_solver.cpp:105] Iteration 97600, lr = 0.00359044
I1027 21:03:30.098111  9023 solver.cpp:222] Iteration 97640 (1.29087 iter/s, 30.9868s/40 iters), loss = 1.66562
I1027 21:03:30.098223  9023 solver.cpp:241]     Train net output #0: loss = 1.66562 (* 1 = 1.66562 loss)
I1027 21:03:30.098239  9023 sgd_solver.cpp:105] Iteration 97640, lr = 0.00358806
I1027 21:04:01.119863  9023 solver.cpp:222] Iteration 97680 (1.28947 iter/s, 31.0205s/40 iters), loss = 1.74118
I1027 21:04:01.119973  9023 solver.cpp:241]     Train net output #0: loss = 1.74118 (* 1 = 1.74118 loss)
I1027 21:04:01.119989  9023 sgd_solver.cpp:105] Iteration 97680, lr = 0.00358568
I1027 21:04:31.735903  9023 solver.cpp:222] Iteration 97720 (1.30656 iter/s, 30.6148s/40 iters), loss = 1.43597
I1027 21:04:31.736032  9023 solver.cpp:241]     Train net output #0: loss = 1.43597 (* 1 = 1.43597 loss)
I1027 21:04:31.736047  9023 sgd_solver.cpp:105] Iteration 97720, lr = 0.0035833
I1027 21:05:02.425495  9023 solver.cpp:222] Iteration 97760 (1.30343 iter/s, 30.6883s/40 iters), loss = 1.46055
I1027 21:05:02.425642  9023 solver.cpp:241]     Train net output #0: loss = 1.46055 (* 1 = 1.46055 loss)
I1027 21:05:02.425669  9023 sgd_solver.cpp:105] Iteration 97760, lr = 0.00358092
I1027 21:05:33.152904  9023 solver.cpp:222] Iteration 97800 (1.30182 iter/s, 30.7261s/40 iters), loss = 1.77215
I1027 21:05:33.153158  9023 solver.cpp:241]     Train net output #0: loss = 1.77215 (* 1 = 1.77215 loss)
I1027 21:05:33.153195  9023 sgd_solver.cpp:105] Iteration 97800, lr = 0.00357854
I1027 21:06:03.555742  9023 solver.cpp:222] Iteration 97840 (1.31573 iter/s, 30.4015s/40 iters), loss = 1.40292
I1027 21:06:03.555891  9023 solver.cpp:241]     Train net output #0: loss = 1.40292 (* 1 = 1.40292 loss)
I1027 21:06:03.555907  9023 sgd_solver.cpp:105] Iteration 97840, lr = 0.00357616
I1027 21:06:33.891306  9023 solver.cpp:222] Iteration 97880 (1.31864 iter/s, 30.3343s/40 iters), loss = 1.69225
I1027 21:06:33.891450  9023 solver.cpp:241]     Train net output #0: loss = 1.69225 (* 1 = 1.69225 loss)
I1027 21:06:33.891468  9023 sgd_solver.cpp:105] Iteration 97880, lr = 0.00357378
I1027 21:07:05.179803  9023 solver.cpp:222] Iteration 97920 (1.27848 iter/s, 31.2872s/40 iters), loss = 1.99082
I1027 21:07:05.180004  9023 solver.cpp:241]     Train net output #0: loss = 1.99082 (* 1 = 1.99082 loss)
I1027 21:07:05.180022  9023 sgd_solver.cpp:105] Iteration 97920, lr = 0.0035714
I1027 21:07:36.599577  9023 solver.cpp:222] Iteration 97960 (1.27314 iter/s, 31.4184s/40 iters), loss = 1.33549
I1027 21:07:36.599798  9023 solver.cpp:241]     Train net output #0: loss = 1.33549 (* 1 = 1.33549 loss)
I1027 21:07:36.599828  9023 sgd_solver.cpp:105] Iteration 97960, lr = 0.00356903
I1027 21:08:08.325527  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_98000.caffemodel
I1027 21:08:08.356945  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_98000.solverstate
I1027 21:08:08.373723  9023 solver.cpp:334] Iteration 98000, Testing net (#0)
I1027 21:08:39.635848  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 21:08:39.847760  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5604
I1027 21:08:39.847821  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79336
I1027 21:08:39.847836  9023 solver.cpp:401]     Test net output #2: loss = 1.97072 (* 1 = 1.97072 loss)
I1027 21:08:40.618234  9023 solver.cpp:222] Iteration 98000 (0.624843 iter/s, 64.016s/40 iters), loss = 1.75902
I1027 21:08:40.618304  9023 solver.cpp:241]     Train net output #0: loss = 1.75902 (* 1 = 1.75902 loss)
I1027 21:08:40.618321  9023 sgd_solver.cpp:105] Iteration 98000, lr = 0.00356665
I1027 21:09:11.676798  9023 solver.cpp:222] Iteration 98040 (1.28794 iter/s, 31.0573s/40 iters), loss = 1.44419
I1027 21:09:11.676961  9023 solver.cpp:241]     Train net output #0: loss = 1.44419 (* 1 = 1.44419 loss)
I1027 21:09:11.676977  9023 sgd_solver.cpp:105] Iteration 98040, lr = 0.00356427
I1027 21:09:42.926978  9023 solver.cpp:222] Iteration 98080 (1.28005 iter/s, 31.2488s/40 iters), loss = 1.32401
I1027 21:09:42.927131  9023 solver.cpp:241]     Train net output #0: loss = 1.32401 (* 1 = 1.32401 loss)
I1027 21:09:42.927147  9023 sgd_solver.cpp:105] Iteration 98080, lr = 0.00356189
I1027 21:10:14.361433  9023 solver.cpp:222] Iteration 98120 (1.27254 iter/s, 31.4331s/40 iters), loss = 1.21658
I1027 21:10:14.361685  9023 solver.cpp:241]     Train net output #0: loss = 1.21658 (* 1 = 1.21658 loss)
I1027 21:10:14.361707  9023 sgd_solver.cpp:105] Iteration 98120, lr = 0.00355952
I1027 21:10:45.317688  9023 solver.cpp:222] Iteration 98160 (1.29221 iter/s, 30.9548s/40 iters), loss = 1.60804
I1027 21:10:45.317867  9023 solver.cpp:241]     Train net output #0: loss = 1.60804 (* 1 = 1.60804 loss)
I1027 21:10:45.317883  9023 sgd_solver.cpp:105] Iteration 98160, lr = 0.00355714
I1027 21:11:17.673789  9023 solver.cpp:222] Iteration 98200 (1.2363 iter/s, 32.3547s/40 iters), loss = 1.54411
I1027 21:11:17.674046  9023 solver.cpp:241]     Train net output #0: loss = 1.54411 (* 1 = 1.54411 loss)
I1027 21:11:17.679769  9023 sgd_solver.cpp:105] Iteration 98200, lr = 0.00355476
I1027 21:11:49.164477  9023 solver.cpp:222] Iteration 98240 (1.27027 iter/s, 31.4893s/40 iters), loss = 1.67541
I1027 21:11:49.164774  9023 solver.cpp:241]     Train net output #0: loss = 1.67541 (* 1 = 1.67541 loss)
I1027 21:11:49.164811  9023 sgd_solver.cpp:105] Iteration 98240, lr = 0.00355239
I1027 21:12:19.839510  9023 solver.cpp:222] Iteration 98280 (1.30405 iter/s, 30.6736s/40 iters), loss = 1.52434
I1027 21:12:19.839685  9023 solver.cpp:241]     Train net output #0: loss = 1.52434 (* 1 = 1.52434 loss)
I1027 21:12:19.839702  9023 sgd_solver.cpp:105] Iteration 98280, lr = 0.00355001
I1027 21:12:50.479189  9023 solver.cpp:222] Iteration 98320 (1.30555 iter/s, 30.6384s/40 iters), loss = 1.63515
I1027 21:12:50.479369  9023 solver.cpp:241]     Train net output #0: loss = 1.63515 (* 1 = 1.63515 loss)
I1027 21:12:50.479387  9023 sgd_solver.cpp:105] Iteration 98320, lr = 0.00354763
I1027 21:13:21.093315  9023 solver.cpp:222] Iteration 98360 (1.30664 iter/s, 30.6128s/40 iters), loss = 1.57972
I1027 21:13:21.093487  9023 solver.cpp:241]     Train net output #0: loss = 1.57972 (* 1 = 1.57972 loss)
I1027 21:13:21.093502  9023 sgd_solver.cpp:105] Iteration 98360, lr = 0.00354526
I1027 21:13:51.981420  9023 solver.cpp:222] Iteration 98400 (1.29505 iter/s, 30.8868s/40 iters), loss = 1.75303
I1027 21:13:51.981580  9023 solver.cpp:241]     Train net output #0: loss = 1.75303 (* 1 = 1.75303 loss)
I1027 21:13:51.981600  9023 sgd_solver.cpp:105] Iteration 98400, lr = 0.00354288
I1027 21:14:23.684311  9023 solver.cpp:222] Iteration 98440 (1.26177 iter/s, 31.7015s/40 iters), loss = 1.55413
I1027 21:14:23.684504  9023 solver.cpp:241]     Train net output #0: loss = 1.55413 (* 1 = 1.55413 loss)
I1027 21:14:23.684954  9023 sgd_solver.cpp:105] Iteration 98440, lr = 0.00354051
I1027 21:14:55.672534  9023 solver.cpp:222] Iteration 98480 (1.25052 iter/s, 31.9868s/40 iters), loss = 1.82286
I1027 21:14:55.672703  9023 solver.cpp:241]     Train net output #0: loss = 1.82286 (* 1 = 1.82286 loss)
I1027 21:14:55.672729  9023 sgd_solver.cpp:105] Iteration 98480, lr = 0.00353813
I1027 21:15:44.062379  9023 solver.cpp:334] Iteration 98500, Testing net (#0)
I1027 21:16:15.615671  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55496
I1027 21:16:15.615841  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.791
I1027 21:16:15.615856  9023 solver.cpp:401]     Test net output #2: loss = 1.96347 (* 1 = 1.96347 loss)
I1027 21:16:31.675813  9023 solver.cpp:222] Iteration 98520 (0.416669 iter/s, 95.9995s/40 iters), loss = 1.42861
I1027 21:16:31.675884  9023 solver.cpp:241]     Train net output #0: loss = 1.42861 (* 1 = 1.42861 loss)
I1027 21:16:31.675899  9023 sgd_solver.cpp:105] Iteration 98520, lr = 0.00353576
I1027 21:17:02.094451  9023 solver.cpp:222] Iteration 98560 (1.31504 iter/s, 30.4174s/40 iters), loss = 1.75029
I1027 21:17:02.094622  9023 solver.cpp:241]     Train net output #0: loss = 1.75029 (* 1 = 1.75029 loss)
I1027 21:17:02.094637  9023 sgd_solver.cpp:105] Iteration 98560, lr = 0.00353339
I1027 21:17:32.813906  9023 solver.cpp:222] Iteration 98600 (1.30216 iter/s, 30.7181s/40 iters), loss = 2.03179
I1027 21:17:32.814071  9023 solver.cpp:241]     Train net output #0: loss = 2.03179 (* 1 = 2.03179 loss)
I1027 21:17:32.814086  9023 sgd_solver.cpp:105] Iteration 98600, lr = 0.00353101
I1027 21:18:03.824764  9023 solver.cpp:222] Iteration 98640 (1.28993 iter/s, 31.0095s/40 iters), loss = 1.42272
I1027 21:18:03.824983  9023 solver.cpp:241]     Train net output #0: loss = 1.42272 (* 1 = 1.42272 loss)
I1027 21:18:03.825002  9023 sgd_solver.cpp:105] Iteration 98640, lr = 0.00352864
I1027 21:18:35.246601  9023 solver.cpp:222] Iteration 98680 (1.27306 iter/s, 31.4204s/40 iters), loss = 1.61324
I1027 21:18:35.246851  9023 solver.cpp:241]     Train net output #0: loss = 1.61324 (* 1 = 1.61324 loss)
I1027 21:18:35.246881  9023 sgd_solver.cpp:105] Iteration 98680, lr = 0.00352626
I1027 21:19:05.525420  9023 solver.cpp:222] Iteration 98720 (1.32112 iter/s, 30.2774s/40 iters), loss = 1.54043
I1027 21:19:05.525753  9023 solver.cpp:241]     Train net output #0: loss = 1.54043 (* 1 = 1.54043 loss)
I1027 21:19:05.525773  9023 sgd_solver.cpp:105] Iteration 98720, lr = 0.00352389
I1027 21:20:36.545212  9023 solver.cpp:222] Iteration 98760 (0.439483 iter/s, 91.0161s/40 iters), loss = 1.70041
I1027 21:20:36.545478  9023 solver.cpp:241]     Train net output #0: loss = 1.70041 (* 1 = 1.70041 loss)
I1027 21:20:36.545498  9023 sgd_solver.cpp:105] Iteration 98760, lr = 0.00352152
I1027 21:21:07.848995  9023 solver.cpp:222] Iteration 98800 (1.27786 iter/s, 31.3023s/40 iters), loss = 1.65744
I1027 21:21:07.849201  9023 solver.cpp:241]     Train net output #0: loss = 1.65744 (* 1 = 1.65744 loss)
I1027 21:21:07.849227  9023 sgd_solver.cpp:105] Iteration 98800, lr = 0.00351915
I1027 21:21:38.731758  9023 solver.cpp:222] Iteration 98840 (1.29528 iter/s, 30.8814s/40 iters), loss = 1.77148
I1027 21:21:38.731931  9023 solver.cpp:241]     Train net output #0: loss = 1.77148 (* 1 = 1.77148 loss)
I1027 21:21:38.731947  9023 sgd_solver.cpp:105] Iteration 98840, lr = 0.00351677
I1027 21:22:09.540604  9023 solver.cpp:222] Iteration 98880 (1.29839 iter/s, 30.8075s/40 iters), loss = 1.34903
I1027 21:22:09.540797  9023 solver.cpp:241]     Train net output #0: loss = 1.34903 (* 1 = 1.34903 loss)
I1027 21:22:09.540814  9023 sgd_solver.cpp:105] Iteration 98880, lr = 0.0035144
I1027 21:22:40.276523  9023 solver.cpp:222] Iteration 98920 (1.30147 iter/s, 30.7346s/40 iters), loss = 1.67892
I1027 21:22:40.276696  9023 solver.cpp:241]     Train net output #0: loss = 1.67892 (* 1 = 1.67892 loss)
I1027 21:22:40.276713  9023 sgd_solver.cpp:105] Iteration 98920, lr = 0.00351203
I1027 21:23:11.007277  9023 solver.cpp:222] Iteration 98960 (1.30168 iter/s, 30.7294s/40 iters), loss = 1.92712
I1027 21:23:11.007464  9023 solver.cpp:241]     Train net output #0: loss = 1.92712 (* 1 = 1.92712 loss)
I1027 21:23:11.007481  9023 sgd_solver.cpp:105] Iteration 98960, lr = 0.00350966
I1027 21:23:41.651048  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_99000.caffemodel
I1027 21:23:41.682567  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_99000.solverstate
I1027 21:23:41.700793  9023 solver.cpp:334] Iteration 99000, Testing net (#0)
I1027 21:24:12.980900  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 21:24:13.189553  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5542
I1027 21:24:13.189617  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78932
I1027 21:24:13.189631  9023 solver.cpp:401]     Test net output #2: loss = 1.96451 (* 1 = 1.96451 loss)
I1027 21:24:13.945801  9023 solver.cpp:222] Iteration 99000 (0.635566 iter/s, 62.936s/40 iters), loss = 1.84349
I1027 21:24:13.945865  9023 solver.cpp:241]     Train net output #0: loss = 1.84349 (* 1 = 1.84349 loss)
I1027 21:24:13.945880  9023 sgd_solver.cpp:105] Iteration 99000, lr = 0.00350729
I1027 21:24:43.834254  9023 solver.cpp:222] Iteration 99040 (1.33836 iter/s, 29.8873s/40 iters), loss = 1.67749
I1027 21:24:43.834446  9023 solver.cpp:241]     Train net output #0: loss = 1.67749 (* 1 = 1.67749 loss)
I1027 21:24:43.834465  9023 sgd_solver.cpp:105] Iteration 99040, lr = 0.00350492
I1027 21:25:14.787506  9023 solver.cpp:222] Iteration 99080 (1.29233 iter/s, 30.9519s/40 iters), loss = 1.67853
I1027 21:25:14.787786  9023 solver.cpp:241]     Train net output #0: loss = 1.67853 (* 1 = 1.67853 loss)
I1027 21:25:14.787811  9023 sgd_solver.cpp:105] Iteration 99080, lr = 0.00350255
I1027 21:25:46.331781  9023 solver.cpp:222] Iteration 99120 (1.26812 iter/s, 31.5428s/40 iters), loss = 1.67763
I1027 21:25:46.332039  9023 solver.cpp:241]     Train net output #0: loss = 1.67763 (* 1 = 1.67763 loss)
I1027 21:25:46.332064  9023 sgd_solver.cpp:105] Iteration 99120, lr = 0.00350017
I1027 21:26:18.028815  9023 solver.cpp:222] Iteration 99160 (1.26201 iter/s, 31.6956s/40 iters), loss = 1.56064
I1027 21:26:18.029033  9023 solver.cpp:241]     Train net output #0: loss = 1.56064 (* 1 = 1.56064 loss)
I1027 21:26:18.029065  9023 sgd_solver.cpp:105] Iteration 99160, lr = 0.0034978
I1027 21:26:47.854554  9023 solver.cpp:222] Iteration 99200 (1.34118 iter/s, 29.8244s/40 iters), loss = 1.57393
I1027 21:26:47.854625  9023 solver.cpp:241]     Train net output #0: loss = 1.57393 (* 1 = 1.57393 loss)
I1027 21:26:47.854641  9023 sgd_solver.cpp:105] Iteration 99200, lr = 0.00349543
I1027 21:27:18.736021  9023 solver.cpp:222] Iteration 99240 (1.29533 iter/s, 30.8802s/40 iters), loss = 2.12296
I1027 21:27:18.736284  9023 solver.cpp:241]     Train net output #0: loss = 2.12296 (* 1 = 2.12296 loss)
I1027 21:27:18.736305  9023 sgd_solver.cpp:105] Iteration 99240, lr = 0.00349306
I1027 21:27:49.409651  9023 solver.cpp:222] Iteration 99280 (1.30411 iter/s, 30.6722s/40 iters), loss = 1.89849
I1027 21:27:49.409828  9023 solver.cpp:241]     Train net output #0: loss = 1.89849 (* 1 = 1.89849 loss)
I1027 21:27:49.409844  9023 sgd_solver.cpp:105] Iteration 99280, lr = 0.0034907
I1027 21:28:19.909782  9023 solver.cpp:222] Iteration 99320 (1.31153 iter/s, 30.4988s/40 iters), loss = 1.55581
I1027 21:28:19.909951  9023 solver.cpp:241]     Train net output #0: loss = 1.55581 (* 1 = 1.55581 loss)
I1027 21:28:19.909967  9023 sgd_solver.cpp:105] Iteration 99320, lr = 0.00348833
I1027 21:28:50.586654  9023 solver.cpp:222] Iteration 99360 (1.30397 iter/s, 30.6755s/40 iters), loss = 2.00976
I1027 21:28:50.586815  9023 solver.cpp:241]     Train net output #0: loss = 2.00976 (* 1 = 2.00976 loss)
I1027 21:28:50.586832  9023 sgd_solver.cpp:105] Iteration 99360, lr = 0.00348596
I1027 21:29:21.488358  9023 solver.cpp:222] Iteration 99400 (1.29448 iter/s, 30.9004s/40 iters), loss = 1.60041
I1027 21:29:21.488557  9023 solver.cpp:241]     Train net output #0: loss = 1.60041 (* 1 = 1.60041 loss)
I1027 21:29:21.488574  9023 sgd_solver.cpp:105] Iteration 99400, lr = 0.00348359
I1027 21:29:52.730988  9023 solver.cpp:222] Iteration 99440 (1.28036 iter/s, 31.2412s/40 iters), loss = 1.43025
I1027 21:29:52.731160  9023 solver.cpp:241]     Train net output #0: loss = 1.43025 (* 1 = 1.43025 loss)
I1027 21:29:52.731176  9023 sgd_solver.cpp:105] Iteration 99440, lr = 0.00348122
I1027 21:30:23.808113  9023 solver.cpp:222] Iteration 99480 (1.28718 iter/s, 31.0758s/40 iters), loss = 1.57907
I1027 21:30:23.808331  9023 solver.cpp:241]     Train net output #0: loss = 1.57907 (* 1 = 1.57907 loss)
I1027 21:30:23.808357  9023 sgd_solver.cpp:105] Iteration 99480, lr = 0.00347885
I1027 21:30:42.040760  9023 solver.cpp:334] Iteration 99500, Testing net (#0)
I1027 21:31:13.541077  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55288
I1027 21:31:13.541244  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78832
I1027 21:31:13.541260  9023 solver.cpp:401]     Test net output #2: loss = 1.96728 (* 1 = 1.96728 loss)
I1027 21:31:29.698047  9023 solver.cpp:222] Iteration 99520 (0.607098 iter/s, 65.8873s/40 iters), loss = 1.7314
I1027 21:31:29.698139  9023 solver.cpp:241]     Train net output #0: loss = 1.7314 (* 1 = 1.7314 loss)
I1027 21:31:29.698158  9023 sgd_solver.cpp:105] Iteration 99520, lr = 0.00347648
I1027 21:31:35.644160  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1027 21:32:00.387400  9023 solver.cpp:222] Iteration 99560 (1.30344 iter/s, 30.6881s/40 iters), loss = 1.58624
I1027 21:32:00.387606  9023 solver.cpp:241]     Train net output #0: loss = 1.58624 (* 1 = 1.58624 loss)
I1027 21:32:00.387622  9023 sgd_solver.cpp:105] Iteration 99560, lr = 0.00347412
I1027 21:32:30.905258  9023 solver.cpp:222] Iteration 99600 (1.31077 iter/s, 30.5165s/40 iters), loss = 1.36422
I1027 21:32:30.905475  9023 solver.cpp:241]     Train net output #0: loss = 1.36422 (* 1 = 1.36422 loss)
I1027 21:32:30.905493  9023 sgd_solver.cpp:105] Iteration 99600, lr = 0.00347175
I1027 21:33:01.687388  9023 solver.cpp:222] Iteration 99640 (1.29951 iter/s, 30.7808s/40 iters), loss = 1.33367
I1027 21:33:01.687562  9023 solver.cpp:241]     Train net output #0: loss = 1.33367 (* 1 = 1.33367 loss)
I1027 21:33:01.687579  9023 sgd_solver.cpp:105] Iteration 99640, lr = 0.00346938
I1027 21:33:32.302616  9023 solver.cpp:222] Iteration 99680 (1.3066 iter/s, 30.6139s/40 iters), loss = 1.34639
I1027 21:33:32.302836  9023 solver.cpp:241]     Train net output #0: loss = 1.34639 (* 1 = 1.34639 loss)
I1027 21:33:32.302855  9023 sgd_solver.cpp:105] Iteration 99680, lr = 0.00346702
I1027 21:34:04.092383  9023 solver.cpp:222] Iteration 99720 (1.25832 iter/s, 31.7883s/40 iters), loss = 1.72967
I1027 21:34:04.092597  9023 solver.cpp:241]     Train net output #0: loss = 1.72967 (* 1 = 1.72967 loss)
I1027 21:34:04.092613  9023 sgd_solver.cpp:105] Iteration 99720, lr = 0.00346465
I1027 21:34:35.134536  9023 solver.cpp:222] Iteration 99760 (1.28863 iter/s, 31.0408s/40 iters), loss = 1.51591
I1027 21:34:35.134728  9023 solver.cpp:241]     Train net output #0: loss = 1.51591 (* 1 = 1.51591 loss)
I1027 21:34:35.134747  9023 sgd_solver.cpp:105] Iteration 99760, lr = 0.00346228
I1027 21:35:06.159451  9023 solver.cpp:222] Iteration 99800 (1.28934 iter/s, 31.0236s/40 iters), loss = 1.49837
I1027 21:35:06.159631  9023 solver.cpp:241]     Train net output #0: loss = 1.49837 (* 1 = 1.49837 loss)
I1027 21:35:06.159647  9023 sgd_solver.cpp:105] Iteration 99800, lr = 0.00345992
I1027 21:35:37.035365  9023 solver.cpp:222] Iteration 99840 (1.29556 iter/s, 30.8746s/40 iters), loss = 1.45258
I1027 21:35:37.035537  9023 solver.cpp:241]     Train net output #0: loss = 1.45258 (* 1 = 1.45258 loss)
I1027 21:35:37.035555  9023 sgd_solver.cpp:105] Iteration 99840, lr = 0.00345755
I1027 21:36:07.812151  9023 solver.cpp:222] Iteration 99880 (1.29974 iter/s, 30.7755s/40 iters), loss = 1.73368
I1027 21:36:07.812288  9023 solver.cpp:241]     Train net output #0: loss = 1.73368 (* 1 = 1.73368 loss)
I1027 21:36:07.812310  9023 sgd_solver.cpp:105] Iteration 99880, lr = 0.00345519
I1027 21:36:40.668115  9023 solver.cpp:222] Iteration 99920 (1.21749 iter/s, 32.8546s/40 iters), loss = 1.77005
I1027 21:36:40.668344  9023 solver.cpp:241]     Train net output #0: loss = 1.77005 (* 1 = 1.77005 loss)
I1027 21:36:40.668370  9023 sgd_solver.cpp:105] Iteration 99920, lr = 0.00345282
I1027 21:37:11.584538  9023 solver.cpp:222] Iteration 99960 (1.29387 iter/s, 30.915s/40 iters), loss = 1.58399
I1027 21:37:11.584707  9023 solver.cpp:241]     Train net output #0: loss = 1.58399 (* 1 = 1.58399 loss)
I1027 21:37:11.584723  9023 sgd_solver.cpp:105] Iteration 99960, lr = 0.00345046
I1027 21:37:41.523607  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_100000.caffemodel
I1027 21:37:41.561190  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_100000.solverstate
I1027 21:37:41.577960  9023 solver.cpp:334] Iteration 100000, Testing net (#0)
I1027 21:38:12.924000  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 21:38:13.136391  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55464
I1027 21:38:13.136442  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.78748
I1027 21:38:13.136456  9023 solver.cpp:401]     Test net output #2: loss = 1.98077 (* 1 = 1.98077 loss)
I1027 21:38:13.907696  9023 solver.cpp:222] Iteration 100000 (0.641842 iter/s, 62.3207s/40 iters), loss = 1.63242
I1027 21:38:13.907733  9023 solver.cpp:241]     Train net output #0: loss = 1.63242 (* 1 = 1.63242 loss)
I1027 21:38:13.907748  9023 sgd_solver.cpp:105] Iteration 100000, lr = 0.00344809
I1027 21:38:44.655653  9023 solver.cpp:222] Iteration 100040 (1.30095 iter/s, 30.7468s/40 iters), loss = 1.51209
I1027 21:38:44.655805  9023 solver.cpp:241]     Train net output #0: loss = 1.51209 (* 1 = 1.51209 loss)
I1027 21:38:44.655822  9023 sgd_solver.cpp:105] Iteration 100040, lr = 0.00344573
I1027 21:39:15.298125  9023 solver.cpp:222] Iteration 100080 (1.30543 iter/s, 30.6412s/40 iters), loss = 1.72999
I1027 21:39:15.298269  9023 solver.cpp:241]     Train net output #0: loss = 1.72999 (* 1 = 1.72999 loss)
I1027 21:39:15.298286  9023 sgd_solver.cpp:105] Iteration 100080, lr = 0.00344336
I1027 21:39:45.949245  9023 solver.cpp:222] Iteration 100120 (1.30506 iter/s, 30.6498s/40 iters), loss = 1.37117
I1027 21:39:45.949410  9023 solver.cpp:241]     Train net output #0: loss = 1.37117 (* 1 = 1.37117 loss)
I1027 21:39:45.949427  9023 sgd_solver.cpp:105] Iteration 100120, lr = 0.003441
I1027 21:40:16.595885  9023 solver.cpp:222] Iteration 100160 (1.30526 iter/s, 30.6453s/40 iters), loss = 1.59686
I1027 21:40:16.596012  9023 solver.cpp:241]     Train net output #0: loss = 1.59686 (* 1 = 1.59686 loss)
I1027 21:40:16.596030  9023 sgd_solver.cpp:105] Iteration 100160, lr = 0.00343864
I1027 21:40:47.145964  9023 solver.cpp:222] Iteration 100200 (1.30938 iter/s, 30.5488s/40 iters), loss = 1.46198
I1027 21:40:47.146090  9023 solver.cpp:241]     Train net output #0: loss = 1.46198 (* 1 = 1.46198 loss)
I1027 21:40:47.146106  9023 sgd_solver.cpp:105] Iteration 100200, lr = 0.00343627
I1027 21:41:17.777514  9023 solver.cpp:222] Iteration 100240 (1.3059 iter/s, 30.6303s/40 iters), loss = 1.83624
I1027 21:41:17.777698  9023 solver.cpp:241]     Train net output #0: loss = 1.83624 (* 1 = 1.83624 loss)
I1027 21:41:17.777714  9023 sgd_solver.cpp:105] Iteration 100240, lr = 0.00343391
I1027 21:41:48.469920  9023 solver.cpp:222] Iteration 100280 (1.30331 iter/s, 30.6911s/40 iters), loss = 1.62179
I1027 21:41:48.470077  9023 solver.cpp:241]     Train net output #0: loss = 1.62179 (* 1 = 1.62179 loss)
I1027 21:41:48.470094  9023 sgd_solver.cpp:105] Iteration 100280, lr = 0.00343155
I1027 21:42:19.301970  9023 solver.cpp:222] Iteration 100320 (1.29741 iter/s, 30.8307s/40 iters), loss = 1.84429
I1027 21:42:19.302103  9023 solver.cpp:241]     Train net output #0: loss = 1.84429 (* 1 = 1.84429 loss)
I1027 21:42:19.302119  9023 sgd_solver.cpp:105] Iteration 100320, lr = 0.00342919
I1027 21:42:50.132374  9023 solver.cpp:222] Iteration 100360 (1.29747 iter/s, 30.8291s/40 iters), loss = 1.48031
I1027 21:42:50.132503  9023 solver.cpp:241]     Train net output #0: loss = 1.48031 (* 1 = 1.48031 loss)
I1027 21:42:50.132519  9023 sgd_solver.cpp:105] Iteration 100360, lr = 0.00342682
I1027 21:43:20.908452  9023 solver.cpp:222] Iteration 100400 (1.29976 iter/s, 30.7748s/40 iters), loss = 1.73002
I1027 21:43:20.908588  9023 solver.cpp:241]     Train net output #0: loss = 1.73002 (* 1 = 1.73002 loss)
I1027 21:43:20.908604  9023 sgd_solver.cpp:105] Iteration 100400, lr = 0.00342446
I1027 21:43:51.561496  9023 solver.cpp:222] Iteration 100440 (1.30498 iter/s, 30.6518s/40 iters), loss = 1.58767
I1027 21:43:51.561620  9023 solver.cpp:241]     Train net output #0: loss = 1.58767 (* 1 = 1.58767 loss)
I1027 21:43:51.561636  9023 sgd_solver.cpp:105] Iteration 100440, lr = 0.0034221
I1027 21:44:22.158120  9023 solver.cpp:222] Iteration 100480 (1.30739 iter/s, 30.5954s/40 iters), loss = 1.37633
I1027 21:44:22.158252  9023 solver.cpp:241]     Train net output #0: loss = 1.37633 (* 1 = 1.37633 loss)
I1027 21:44:22.158272  9023 sgd_solver.cpp:105] Iteration 100480, lr = 0.00341974
I1027 21:44:37.430747  9023 solver.cpp:334] Iteration 100500, Testing net (#0)
I1027 21:45:08.845624  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5614
I1027 21:45:08.845768  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79468
I1027 21:45:08.845783  9023 solver.cpp:401]     Test net output #2: loss = 1.92891 (* 1 = 1.92891 loss)
I1027 21:45:24.954164  9023 solver.cpp:222] Iteration 100520 (0.637008 iter/s, 62.7936s/40 iters), loss = 1.57684
I1027 21:45:24.954218  9023 solver.cpp:241]     Train net output #0: loss = 1.57684 (* 1 = 1.57684 loss)
I1027 21:45:24.954234  9023 sgd_solver.cpp:105] Iteration 100520, lr = 0.00341738
I1027 21:45:55.586697  9023 solver.cpp:222] Iteration 100560 (1.30585 iter/s, 30.6313s/40 iters), loss = 1.42803
I1027 21:45:55.586874  9023 solver.cpp:241]     Train net output #0: loss = 1.42803 (* 1 = 1.42803 loss)
I1027 21:45:55.586889  9023 sgd_solver.cpp:105] Iteration 100560, lr = 0.00341502
I1027 21:46:26.214912  9023 solver.cpp:222] Iteration 100600 (1.30604 iter/s, 30.6269s/40 iters), loss = 1.40441
I1027 21:46:26.215055  9023 solver.cpp:241]     Train net output #0: loss = 1.40441 (* 1 = 1.40441 loss)
I1027 21:46:26.215080  9023 sgd_solver.cpp:105] Iteration 100600, lr = 0.00341266
I1027 21:46:57.409572  9023 solver.cpp:222] Iteration 100640 (1.28233 iter/s, 31.1933s/40 iters), loss = 1.37123
I1027 21:46:57.409822  9023 solver.cpp:241]     Train net output #0: loss = 1.37123 (* 1 = 1.37123 loss)
I1027 21:46:57.409845  9023 sgd_solver.cpp:105] Iteration 100640, lr = 0.0034103
I1027 21:47:30.294237  9023 solver.cpp:222] Iteration 100680 (1.21643 iter/s, 32.8832s/40 iters), loss = 1.27091
I1027 21:47:30.294395  9023 solver.cpp:241]     Train net output #0: loss = 1.27091 (* 1 = 1.27091 loss)
I1027 21:47:30.294410  9023 sgd_solver.cpp:105] Iteration 100680, lr = 0.00340794
I1027 21:48:01.160374  9023 solver.cpp:222] Iteration 100720 (1.29597 iter/s, 30.8648s/40 iters), loss = 1.60246
I1027 21:48:01.160542  9023 solver.cpp:241]     Train net output #0: loss = 1.60246 (* 1 = 1.60246 loss)
I1027 21:48:01.160559  9023 sgd_solver.cpp:105] Iteration 100720, lr = 0.00340558
I1027 21:48:32.467501  9023 solver.cpp:222] Iteration 100760 (1.27772 iter/s, 31.3058s/40 iters), loss = 1.58009
I1027 21:48:32.467725  9023 solver.cpp:241]     Train net output #0: loss = 1.58009 (* 1 = 1.58009 loss)
I1027 21:48:32.467747  9023 sgd_solver.cpp:105] Iteration 100760, lr = 0.00340322
I1027 21:49:06.332996  9023 solver.cpp:222] Iteration 100800 (1.1812 iter/s, 33.864s/40 iters), loss = 1.63445
I1027 21:49:06.333178  9023 solver.cpp:241]     Train net output #0: loss = 1.63445 (* 1 = 1.63445 loss)
I1027 21:49:06.333197  9023 sgd_solver.cpp:105] Iteration 100800, lr = 0.00340086
I1027 21:49:38.111579  9023 solver.cpp:222] Iteration 100840 (1.25876 iter/s, 31.7772s/40 iters), loss = 1.62918
I1027 21:49:38.111722  9023 solver.cpp:241]     Train net output #0: loss = 1.62918 (* 1 = 1.62918 loss)
I1027 21:49:38.111739  9023 sgd_solver.cpp:105] Iteration 100840, lr = 0.0033985
I1027 21:50:16.779623  9023 solver.cpp:222] Iteration 100880 (1.03449 iter/s, 38.6664s/40 iters), loss = 1.31371
I1027 21:50:16.779860  9023 solver.cpp:241]     Train net output #0: loss = 1.31371 (* 1 = 1.31371 loss)
I1027 21:50:16.779884  9023 sgd_solver.cpp:105] Iteration 100880, lr = 0.00339614
I1027 21:50:51.139838  9023 solver.cpp:222] Iteration 100920 (1.16419 iter/s, 34.3587s/40 iters), loss = 1.56369
I1027 21:50:51.140079  9023 solver.cpp:241]     Train net output #0: loss = 1.56369 (* 1 = 1.56369 loss)
I1027 21:50:51.140101  9023 sgd_solver.cpp:105] Iteration 100920, lr = 0.00339378
I1027 21:51:22.195389  9023 solver.cpp:222] Iteration 100960 (1.28807 iter/s, 31.0541s/40 iters), loss = 1.84634
I1027 21:51:22.195555  9023 solver.cpp:241]     Train net output #0: loss = 1.84634 (* 1 = 1.84634 loss)
I1027 21:51:22.195574  9023 sgd_solver.cpp:105] Iteration 100960, lr = 0.00339142
I1027 21:51:52.308337  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_101000.caffemodel
I1027 21:51:52.343736  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_101000.solverstate
I1027 21:51:52.360352  9023 solver.cpp:334] Iteration 101000, Testing net (#0)
I1027 21:52:23.650044  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 21:52:23.862167  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55564
I1027 21:52:23.862213  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79412
I1027 21:52:23.862226  9023 solver.cpp:401]     Test net output #2: loss = 2.00318 (* 1 = 2.00318 loss)
I1027 21:52:24.636962  9023 solver.cpp:222] Iteration 101000 (0.640625 iter/s, 62.4391s/40 iters), loss = 1.60645
I1027 21:52:24.637007  9023 solver.cpp:241]     Train net output #0: loss = 1.60645 (* 1 = 1.60645 loss)
I1027 21:52:24.637022  9023 sgd_solver.cpp:105] Iteration 101000, lr = 0.00338907
I1027 21:52:55.652082  9023 solver.cpp:222] Iteration 101040 (1.28974 iter/s, 31.0139s/40 iters), loss = 1.45625
I1027 21:52:55.652230  9023 solver.cpp:241]     Train net output #0: loss = 1.45625 (* 1 = 1.45625 loss)
I1027 21:52:55.652262  9023 sgd_solver.cpp:105] Iteration 101040, lr = 0.00338671
I1027 21:53:27.120276  9023 solver.cpp:222] Iteration 101080 (1.27118 iter/s, 31.4669s/40 iters), loss = 1.46511
I1027 21:53:27.120524  9023 solver.cpp:241]     Train net output #0: loss = 1.46511 (* 1 = 1.46511 loss)
I1027 21:53:27.120561  9023 sgd_solver.cpp:105] Iteration 101080, lr = 0.00338435
I1027 21:53:59.013651  9023 solver.cpp:222] Iteration 101120 (1.25424 iter/s, 31.8919s/40 iters), loss = 1.53591
I1027 21:53:59.013831  9023 solver.cpp:241]     Train net output #0: loss = 1.53591 (* 1 = 1.53591 loss)
I1027 21:53:59.013849  9023 sgd_solver.cpp:105] Iteration 101120, lr = 0.003382
I1027 21:54:29.749083  9023 solver.cpp:222] Iteration 101160 (1.30149 iter/s, 30.7341s/40 iters), loss = 1.6142
I1027 21:54:29.749261  9023 solver.cpp:241]     Train net output #0: loss = 1.6142 (* 1 = 1.6142 loss)
I1027 21:54:29.749277  9023 sgd_solver.cpp:105] Iteration 101160, lr = 0.00337964
I1027 21:55:00.456917  9023 solver.cpp:222] Iteration 101200 (1.30266 iter/s, 30.7065s/40 iters), loss = 1.61438
I1027 21:55:00.457074  9023 solver.cpp:241]     Train net output #0: loss = 1.61438 (* 1 = 1.61438 loss)
I1027 21:55:00.457090  9023 sgd_solver.cpp:105] Iteration 101200, lr = 0.00337728
I1027 21:55:31.081681  9023 solver.cpp:222] Iteration 101240 (1.30619 iter/s, 30.6234s/40 iters), loss = 1.75295
I1027 21:55:31.081835  9023 solver.cpp:241]     Train net output #0: loss = 1.75295 (* 1 = 1.75295 loss)
I1027 21:55:31.081851  9023 sgd_solver.cpp:105] Iteration 101240, lr = 0.00337493
I1027 21:56:01.817149  9023 solver.cpp:222] Iteration 101280 (1.30148 iter/s, 30.7342s/40 iters), loss = 1.46961
I1027 21:56:01.817304  9023 solver.cpp:241]     Train net output #0: loss = 1.46961 (* 1 = 1.46961 loss)
I1027 21:56:01.817327  9023 sgd_solver.cpp:105] Iteration 101280, lr = 0.00337257
I1027 21:56:33.019904  9023 solver.cpp:222] Iteration 101320 (1.28199 iter/s, 31.2014s/40 iters), loss = 1.76186
I1027 21:56:33.020092  9023 solver.cpp:241]     Train net output #0: loss = 1.76186 (* 1 = 1.76186 loss)
I1027 21:56:33.020108  9023 sgd_solver.cpp:105] Iteration 101320, lr = 0.00337021
I1027 21:57:03.865727  9023 solver.cpp:222] Iteration 101360 (1.29683 iter/s, 30.8445s/40 iters), loss = 1.56928
I1027 21:57:03.865907  9023 solver.cpp:241]     Train net output #0: loss = 1.56928 (* 1 = 1.56928 loss)
I1027 21:57:03.865924  9023 sgd_solver.cpp:105] Iteration 101360, lr = 0.00336786
I1027 21:57:35.116205  9023 solver.cpp:222] Iteration 101400 (1.28004 iter/s, 31.2491s/40 iters), loss = 1.4682
I1027 21:57:35.116468  9023 solver.cpp:241]     Train net output #0: loss = 1.4682 (* 1 = 1.4682 loss)
I1027 21:57:35.116498  9023 sgd_solver.cpp:105] Iteration 101400, lr = 0.0033655
I1027 21:58:06.394572  9023 solver.cpp:222] Iteration 101440 (1.2789 iter/s, 31.2769s/40 iters), loss = 1.56615
I1027 21:58:06.394816  9023 solver.cpp:241]     Train net output #0: loss = 1.56615 (* 1 = 1.56615 loss)
I1027 21:58:06.394840  9023 sgd_solver.cpp:105] Iteration 101440, lr = 0.00336315
I1027 21:58:37.667073  9023 solver.cpp:222] Iteration 101480 (1.27914 iter/s, 31.2711s/40 iters), loss = 1.3407
I1027 21:58:37.667245  9023 solver.cpp:241]     Train net output #0: loss = 1.3407 (* 1 = 1.3407 loss)
I1027 21:58:37.667263  9023 sgd_solver.cpp:105] Iteration 101480, lr = 0.0033608
I1027 21:58:52.204591  9023 solver.cpp:334] Iteration 101500, Testing net (#0)
I1027 21:59:23.700280  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56224
I1027 21:59:23.700438  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7924
I1027 21:59:23.700453  9023 solver.cpp:401]     Test net output #2: loss = 1.94203 (* 1 = 1.94203 loss)
I1027 21:59:40.069670  9023 solver.cpp:222] Iteration 101520 (0.641025 iter/s, 62.4001s/40 iters), loss = 1.51972
I1027 21:59:40.069741  9023 solver.cpp:241]     Train net output #0: loss = 1.51972 (* 1 = 1.51972 loss)
I1027 21:59:40.069757  9023 sgd_solver.cpp:105] Iteration 101520, lr = 0.00335844
I1027 22:00:10.838387  9023 solver.cpp:222] Iteration 101560 (1.30007 iter/s, 30.7675s/40 iters), loss = 1.69821
I1027 22:00:10.838599  9023 solver.cpp:241]     Train net output #0: loss = 1.69821 (* 1 = 1.69821 loss)
I1027 22:00:10.838618  9023 sgd_solver.cpp:105] Iteration 101560, lr = 0.00335609
I1027 22:00:41.442296  9023 solver.cpp:222] Iteration 101600 (1.30708 iter/s, 30.6025s/40 iters), loss = 1.83158
I1027 22:00:41.442442  9023 solver.cpp:241]     Train net output #0: loss = 1.83158 (* 1 = 1.83158 loss)
I1027 22:00:41.442459  9023 sgd_solver.cpp:105] Iteration 101600, lr = 0.00335373
I1027 22:01:12.222537  9023 solver.cpp:222] Iteration 101640 (1.29959 iter/s, 30.7789s/40 iters), loss = 1.43587
I1027 22:01:12.222746  9023 solver.cpp:241]     Train net output #0: loss = 1.43587 (* 1 = 1.43587 loss)
I1027 22:01:12.222769  9023 sgd_solver.cpp:105] Iteration 101640, lr = 0.00335138
I1027 22:01:43.222143  9023 solver.cpp:222] Iteration 101680 (1.2904 iter/s, 30.9982s/40 iters), loss = 1.65899
I1027 22:01:43.222342  9023 solver.cpp:241]     Train net output #0: loss = 1.65899 (* 1 = 1.65899 loss)
I1027 22:01:43.222363  9023 sgd_solver.cpp:105] Iteration 101680, lr = 0.00334903
I1027 22:02:14.893731  9023 solver.cpp:222] Iteration 101720 (1.26302 iter/s, 31.6702s/40 iters), loss = 1.7002
I1027 22:02:14.893923  9023 solver.cpp:241]     Train net output #0: loss = 1.7002 (* 1 = 1.7002 loss)
I1027 22:02:14.893939  9023 sgd_solver.cpp:105] Iteration 101720, lr = 0.00334667
I1027 22:02:45.546272  9023 solver.cpp:222] Iteration 101760 (1.30501 iter/s, 30.6512s/40 iters), loss = 1.53253
I1027 22:02:45.546447  9023 solver.cpp:241]     Train net output #0: loss = 1.53253 (* 1 = 1.53253 loss)
I1027 22:02:45.546464  9023 sgd_solver.cpp:105] Iteration 101760, lr = 0.00334432
I1027 22:03:16.406918  9023 solver.cpp:222] Iteration 101800 (1.29621 iter/s, 30.8593s/40 iters), loss = 1.77712
I1027 22:03:16.407085  9023 solver.cpp:241]     Train net output #0: loss = 1.77712 (* 1 = 1.77712 loss)
I1027 22:03:16.407102  9023 sgd_solver.cpp:105] Iteration 101800, lr = 0.00334197
I1027 22:03:47.224905  9023 solver.cpp:222] Iteration 101840 (1.298 iter/s, 30.8166s/40 iters), loss = 1.65115
I1027 22:03:47.225096  9023 solver.cpp:241]     Train net output #0: loss = 1.65115 (* 1 = 1.65115 loss)
I1027 22:03:47.225114  9023 sgd_solver.cpp:105] Iteration 101840, lr = 0.00333962
I1027 22:04:17.906663  9023 solver.cpp:222] Iteration 101880 (1.30376 iter/s, 30.6804s/40 iters), loss = 1.32689
I1027 22:04:17.906853  9023 solver.cpp:241]     Train net output #0: loss = 1.32689 (* 1 = 1.32689 loss)
I1027 22:04:17.906873  9023 sgd_solver.cpp:105] Iteration 101880, lr = 0.00333727
I1027 22:04:48.387198  9023 solver.cpp:222] Iteration 101920 (1.31237 iter/s, 30.4792s/40 iters), loss = 1.43334
I1027 22:04:48.387392  9023 solver.cpp:241]     Train net output #0: loss = 1.43334 (* 1 = 1.43334 loss)
I1027 22:04:48.387413  9023 sgd_solver.cpp:105] Iteration 101920, lr = 0.00333491
I1027 22:05:18.580245  9023 solver.cpp:222] Iteration 101960 (1.32487 iter/s, 30.1917s/40 iters), loss = 1.60239
I1027 22:05:18.580447  9023 solver.cpp:241]     Train net output #0: loss = 1.60239 (* 1 = 1.60239 loss)
I1027 22:05:18.580471  9023 sgd_solver.cpp:105] Iteration 101960, lr = 0.00333256
I1027 22:05:48.206912  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_102000.caffemodel
I1027 22:05:48.238703  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_102000.solverstate
I1027 22:05:48.258942  9023 solver.cpp:334] Iteration 102000, Testing net (#0)
I1027 22:06:19.728823  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 22:06:19.943620  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55672
I1027 22:06:19.943670  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79424
I1027 22:06:19.943683  9023 solver.cpp:401]     Test net output #2: loss = 1.97402 (* 1 = 1.97402 loss)
I1027 22:06:20.715900  9023 solver.cpp:222] Iteration 102000 (0.643779 iter/s, 62.1331s/40 iters), loss = 1.7833
I1027 22:06:20.715997  9023 solver.cpp:241]     Train net output #0: loss = 1.7833 (* 1 = 1.7833 loss)
I1027 22:06:20.716019  9023 sgd_solver.cpp:105] Iteration 102000, lr = 0.00333021
I1027 22:06:43.666275  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1027 22:06:51.385116  9023 solver.cpp:222] Iteration 102040 (1.30429 iter/s, 30.668s/40 iters), loss = 1.37536
I1027 22:06:51.385489  9023 solver.cpp:241]     Train net output #0: loss = 1.37536 (* 1 = 1.37536 loss)
I1027 22:06:51.385512  9023 sgd_solver.cpp:105] Iteration 102040, lr = 0.00332786
I1027 22:07:23.026337  9023 solver.cpp:222] Iteration 102080 (1.26424 iter/s, 31.6396s/40 iters), loss = 1.46464
I1027 22:07:23.026602  9023 solver.cpp:241]     Train net output #0: loss = 1.46464 (* 1 = 1.46464 loss)
I1027 22:07:23.026639  9023 sgd_solver.cpp:105] Iteration 102080, lr = 0.00332551
I1027 22:07:55.176527  9023 solver.cpp:222] Iteration 102120 (1.24422 iter/s, 32.1487s/40 iters), loss = 1.87585
I1027 22:07:55.176681  9023 solver.cpp:241]     Train net output #0: loss = 1.87585 (* 1 = 1.87585 loss)
I1027 22:07:55.176697  9023 sgd_solver.cpp:105] Iteration 102120, lr = 0.00332316
I1027 22:08:25.977552  9023 solver.cpp:222] Iteration 102160 (1.29871 iter/s, 30.7997s/40 iters), loss = 1.25142
I1027 22:08:25.977748  9023 solver.cpp:241]     Train net output #0: loss = 1.25142 (* 1 = 1.25142 loss)
I1027 22:08:25.977764  9023 sgd_solver.cpp:105] Iteration 102160, lr = 0.00332081
I1027 22:08:56.951808  9023 solver.cpp:222] Iteration 102200 (1.29145 iter/s, 30.9729s/40 iters), loss = 1.36818
I1027 22:08:56.951949  9023 solver.cpp:241]     Train net output #0: loss = 1.36818 (* 1 = 1.36818 loss)
I1027 22:08:56.951967  9023 sgd_solver.cpp:105] Iteration 102200, lr = 0.00331846
I1027 22:09:27.860698  9023 solver.cpp:222] Iteration 102240 (1.29418 iter/s, 30.9076s/40 iters), loss = 1.54157
I1027 22:09:27.860864  9023 solver.cpp:241]     Train net output #0: loss = 1.54157 (* 1 = 1.54157 loss)
I1027 22:09:27.860880  9023 sgd_solver.cpp:105] Iteration 102240, lr = 0.00331611
I1027 22:09:58.573612  9023 solver.cpp:222] Iteration 102280 (1.30244 iter/s, 30.7116s/40 iters), loss = 1.66515
I1027 22:09:58.573783  9023 solver.cpp:241]     Train net output #0: loss = 1.66515 (* 1 = 1.66515 loss)
I1027 22:09:58.573801  9023 sgd_solver.cpp:105] Iteration 102280, lr = 0.00331376
I1027 22:10:31.108079  9023 solver.cpp:222] Iteration 102320 (1.22952 iter/s, 32.5331s/40 iters), loss = 1.83624
I1027 22:10:31.108326  9023 solver.cpp:241]     Train net output #0: loss = 1.83624 (* 1 = 1.83624 loss)
I1027 22:10:31.108356  9023 sgd_solver.cpp:105] Iteration 102320, lr = 0.00331142
I1027 22:11:02.401811  9023 solver.cpp:222] Iteration 102360 (1.27827 iter/s, 31.2923s/40 iters), loss = 1.83144
I1027 22:11:02.401986  9023 solver.cpp:241]     Train net output #0: loss = 1.83144 (* 1 = 1.83144 loss)
I1027 22:11:02.402003  9023 sgd_solver.cpp:105] Iteration 102360, lr = 0.00330907
I1027 22:11:33.072490  9023 solver.cpp:222] Iteration 102400 (1.30423 iter/s, 30.6693s/40 iters), loss = 1.4876
I1027 22:11:33.072702  9023 solver.cpp:241]     Train net output #0: loss = 1.4876 (* 1 = 1.4876 loss)
I1027 22:11:33.072723  9023 sgd_solver.cpp:105] Iteration 102400, lr = 0.00330672
I1027 22:12:03.848259  9023 solver.cpp:222] Iteration 102440 (1.29978 iter/s, 30.7744s/40 iters), loss = 1.72644
I1027 22:12:03.848461  9023 solver.cpp:241]     Train net output #0: loss = 1.72644 (* 1 = 1.72644 loss)
I1027 22:12:03.848481  9023 sgd_solver.cpp:105] Iteration 102440, lr = 0.00330437
I1027 22:12:33.762359  9023 solver.cpp:222] Iteration 102480 (1.33722 iter/s, 29.9128s/40 iters), loss = 1.75047
I1027 22:12:33.762444  9023 solver.cpp:241]     Train net output #0: loss = 1.75047 (* 1 = 1.75047 loss)
I1027 22:12:33.762465  9023 sgd_solver.cpp:105] Iteration 102480, lr = 0.00330202
I1027 22:12:48.410953  9023 solver.cpp:334] Iteration 102500, Testing net (#0)
I1027 22:13:19.993768  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55548
I1027 22:13:19.993937  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79288
I1027 22:13:19.993953  9023 solver.cpp:401]     Test net output #2: loss = 1.94202 (* 1 = 1.94202 loss)
I1027 22:13:36.123932  9023 solver.cpp:222] Iteration 102520 (0.641445 iter/s, 62.3592s/40 iters), loss = 1.87714
I1027 22:13:36.124011  9023 solver.cpp:241]     Train net output #0: loss = 1.87714 (* 1 = 1.87714 loss)
I1027 22:13:36.124032  9023 sgd_solver.cpp:105] Iteration 102520, lr = 0.00329968
I1027 22:14:06.851183  9023 solver.cpp:222] Iteration 102560 (1.30183 iter/s, 30.726s/40 iters), loss = 1.97838
I1027 22:14:06.851411  9023 solver.cpp:241]     Train net output #0: loss = 1.97838 (* 1 = 1.97838 loss)
I1027 22:14:06.851433  9023 sgd_solver.cpp:105] Iteration 102560, lr = 0.00329733
I1027 22:14:36.569207  9023 solver.cpp:222] Iteration 102600 (1.34605 iter/s, 29.7167s/40 iters), loss = 1.99331
I1027 22:14:36.569278  9023 solver.cpp:241]     Train net output #0: loss = 1.99331 (* 1 = 1.99331 loss)
I1027 22:14:36.569294  9023 sgd_solver.cpp:105] Iteration 102600, lr = 0.00329498
I1027 22:15:18.373432  9023 solver.cpp:222] Iteration 102640 (0.956879 iter/s, 41.8026s/40 iters), loss = 1.44639
I1027 22:15:18.373633  9023 solver.cpp:241]     Train net output #0: loss = 1.44639 (* 1 = 1.44639 loss)
I1027 22:15:18.373651  9023 sgd_solver.cpp:105] Iteration 102640, lr = 0.00329264
I1027 22:15:49.471124  9023 solver.cpp:222] Iteration 102680 (1.28633 iter/s, 31.0963s/40 iters), loss = 1.46206
I1027 22:15:49.471318  9023 solver.cpp:241]     Train net output #0: loss = 1.46206 (* 1 = 1.46206 loss)
I1027 22:15:49.471336  9023 sgd_solver.cpp:105] Iteration 102680, lr = 0.00329029
I1027 22:16:21.761065  9023 solver.cpp:222] Iteration 102720 (1.23883 iter/s, 32.2885s/40 iters), loss = 1.45986
I1027 22:16:21.761342  9023 solver.cpp:241]     Train net output #0: loss = 1.45986 (* 1 = 1.45986 loss)
I1027 22:16:21.761368  9023 sgd_solver.cpp:105] Iteration 102720, lr = 0.00328794
I1027 22:16:57.101752  9023 solver.cpp:222] Iteration 102760 (1.13189 iter/s, 35.3391s/40 iters), loss = 1.74039
I1027 22:16:57.101979  9023 solver.cpp:241]     Train net output #0: loss = 1.74039 (* 1 = 1.74039 loss)
I1027 22:16:57.101999  9023 sgd_solver.cpp:105] Iteration 102760, lr = 0.0032856
I1027 22:17:28.771268  9023 solver.cpp:222] Iteration 102800 (1.2631 iter/s, 31.6681s/40 iters), loss = 1.73552
I1027 22:17:28.771481  9023 solver.cpp:241]     Train net output #0: loss = 1.73552 (* 1 = 1.73552 loss)
I1027 22:17:28.771505  9023 sgd_solver.cpp:105] Iteration 102800, lr = 0.00328325
I1027 22:18:12.164908  9023 solver.cpp:222] Iteration 102840 (0.921833 iter/s, 43.3918s/40 iters), loss = 1.61449
I1027 22:18:12.165100  9023 solver.cpp:241]     Train net output #0: loss = 1.61449 (* 1 = 1.61449 loss)
I1027 22:18:12.165117  9023 sgd_solver.cpp:105] Iteration 102840, lr = 0.00328091
I1027 22:18:43.142923  9023 solver.cpp:222] Iteration 102880 (1.2913 iter/s, 30.9767s/40 iters), loss = 1.70728
I1027 22:18:43.143115  9023 solver.cpp:241]     Train net output #0: loss = 1.70728 (* 1 = 1.70728 loss)
I1027 22:18:43.143131  9023 sgd_solver.cpp:105] Iteration 102880, lr = 0.00327856
I1027 22:19:13.927979  9023 solver.cpp:222] Iteration 102920 (1.29939 iter/s, 30.7837s/40 iters), loss = 1.42343
I1027 22:19:13.928159  9023 solver.cpp:241]     Train net output #0: loss = 1.42343 (* 1 = 1.42343 loss)
I1027 22:19:13.928176  9023 sgd_solver.cpp:105] Iteration 102920, lr = 0.00327622
I1027 22:19:44.662351  9023 solver.cpp:222] Iteration 102960 (1.30153 iter/s, 30.733s/40 iters), loss = 1.8898
I1027 22:19:44.662550  9023 solver.cpp:241]     Train net output #0: loss = 1.8898 (* 1 = 1.8898 loss)
I1027 22:19:44.662567  9023 sgd_solver.cpp:105] Iteration 102960, lr = 0.00327387
I1027 22:20:14.902437  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_103000.caffemodel
I1027 22:20:14.940641  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_103000.solverstate
I1027 22:20:14.957020  9023 solver.cpp:334] Iteration 103000, Testing net (#0)
I1027 22:20:46.337149  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 22:20:46.548571  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56276
I1027 22:20:46.548635  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.795639
I1027 22:20:46.548650  9023 solver.cpp:401]     Test net output #2: loss = 1.94408 (* 1 = 1.94408 loss)
I1027 22:20:47.314422  9023 solver.cpp:222] Iteration 103000 (0.638472 iter/s, 62.6495s/40 iters), loss = 1.78346
I1027 22:20:47.314486  9023 solver.cpp:241]     Train net output #0: loss = 1.78346 (* 1 = 1.78346 loss)
I1027 22:20:47.314501  9023 sgd_solver.cpp:105] Iteration 103000, lr = 0.00327153
I1027 22:21:21.847967  9023 solver.cpp:222] Iteration 103040 (1.15834 iter/s, 34.5322s/40 iters), loss = 1.6575
I1027 22:21:21.848170  9023 solver.cpp:241]     Train net output #0: loss = 1.6575 (* 1 = 1.6575 loss)
I1027 22:21:21.848188  9023 sgd_solver.cpp:105] Iteration 103040, lr = 0.00326919
I1027 22:21:52.822245  9023 solver.cpp:222] Iteration 103080 (1.29145 iter/s, 30.9729s/40 iters), loss = 1.7736
I1027 22:21:52.822448  9023 solver.cpp:241]     Train net output #0: loss = 1.7736 (* 1 = 1.7736 loss)
I1027 22:21:52.822465  9023 sgd_solver.cpp:105] Iteration 103080, lr = 0.00326684
I1027 22:22:23.899842  9023 solver.cpp:222] Iteration 103120 (1.28716 iter/s, 31.0762s/40 iters), loss = 1.63233
I1027 22:22:23.900015  9023 solver.cpp:241]     Train net output #0: loss = 1.63233 (* 1 = 1.63233 loss)
I1027 22:22:23.900032  9023 sgd_solver.cpp:105] Iteration 103120, lr = 0.0032645
I1027 22:22:54.688704  9023 solver.cpp:222] Iteration 103160 (1.29923 iter/s, 30.7875s/40 iters), loss = 1.66242
I1027 22:22:54.688889  9023 solver.cpp:241]     Train net output #0: loss = 1.66242 (* 1 = 1.66242 loss)
I1027 22:22:54.688905  9023 sgd_solver.cpp:105] Iteration 103160, lr = 0.00326216
I1027 22:23:25.893157  9023 solver.cpp:222] Iteration 103200 (1.28192 iter/s, 31.2031s/40 iters), loss = 1.85064
I1027 22:23:25.893375  9023 solver.cpp:241]     Train net output #0: loss = 1.85064 (* 1 = 1.85064 loss)
I1027 22:23:25.893393  9023 sgd_solver.cpp:105] Iteration 103200, lr = 0.00325982
I1027 22:23:57.719249  9023 solver.cpp:222] Iteration 103240 (1.25689 iter/s, 31.8247s/40 iters), loss = 1.26709
I1027 22:23:57.719523  9023 solver.cpp:241]     Train net output #0: loss = 1.26709 (* 1 = 1.26709 loss)
I1027 22:23:57.719553  9023 sgd_solver.cpp:105] Iteration 103240, lr = 0.00325747
I1027 22:24:29.489248  9023 solver.cpp:222] Iteration 103280 (1.25911 iter/s, 31.7685s/40 iters), loss = 1.62494
I1027 22:24:29.489436  9023 solver.cpp:241]     Train net output #0: loss = 1.62494 (* 1 = 1.62494 loss)
I1027 22:24:29.489454  9023 sgd_solver.cpp:105] Iteration 103280, lr = 0.00325513
I1027 22:25:00.317965  9023 solver.cpp:222] Iteration 103320 (1.29755 iter/s, 30.8274s/40 iters), loss = 1.64451
I1027 22:25:00.318145  9023 solver.cpp:241]     Train net output #0: loss = 1.64451 (* 1 = 1.64451 loss)
I1027 22:25:00.318159  9023 sgd_solver.cpp:105] Iteration 103320, lr = 0.00325279
I1027 22:25:31.270823  9023 solver.cpp:222] Iteration 103360 (1.29234 iter/s, 30.9515s/40 iters), loss = 2.022
I1027 22:25:31.271008  9023 solver.cpp:241]     Train net output #0: loss = 2.022 (* 1 = 2.022 loss)
I1027 22:25:31.271023  9023 sgd_solver.cpp:105] Iteration 103360, lr = 0.00325045
I1027 22:26:01.964573  9023 solver.cpp:222] Iteration 103400 (1.30325 iter/s, 30.6924s/40 iters), loss = 1.77136
I1027 22:26:01.964787  9023 solver.cpp:241]     Train net output #0: loss = 1.77136 (* 1 = 1.77136 loss)
I1027 22:26:01.964802  9023 sgd_solver.cpp:105] Iteration 103400, lr = 0.00324811
I1027 22:26:32.718211  9023 solver.cpp:222] Iteration 103440 (1.30072 iter/s, 30.7523s/40 iters), loss = 1.35803
I1027 22:26:32.718385  9023 solver.cpp:241]     Train net output #0: loss = 1.35803 (* 1 = 1.35803 loss)
I1027 22:26:32.718402  9023 sgd_solver.cpp:105] Iteration 103440, lr = 0.00324577
I1027 22:27:03.281203  9023 solver.cpp:222] Iteration 103480 (1.30883 iter/s, 30.5617s/40 iters), loss = 1.62848
I1027 22:27:03.281409  9023 solver.cpp:241]     Train net output #0: loss = 1.62848 (* 1 = 1.62848 loss)
I1027 22:27:03.281424  9023 sgd_solver.cpp:105] Iteration 103480, lr = 0.00324343
I1027 22:27:17.768913  9023 solver.cpp:334] Iteration 103500, Testing net (#0)
I1027 22:27:49.147740  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55808
I1027 22:27:49.147940  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7912
I1027 22:27:49.147958  9023 solver.cpp:401]     Test net output #2: loss = 2.01753 (* 1 = 2.01753 loss)
I1027 22:28:05.300881  9023 solver.cpp:222] Iteration 103520 (0.644983 iter/s, 62.0171s/40 iters), loss = 1.20144
I1027 22:28:05.300947  9023 solver.cpp:241]     Train net output #0: loss = 1.20144 (* 1 = 1.20144 loss)
I1027 22:28:05.300964  9023 sgd_solver.cpp:105] Iteration 103520, lr = 0.00324109
I1027 22:28:35.782178  9023 solver.cpp:222] Iteration 103560 (1.31233 iter/s, 30.4801s/40 iters), loss = 1.65429
I1027 22:28:35.782372  9023 solver.cpp:241]     Train net output #0: loss = 1.65429 (* 1 = 1.65429 loss)
I1027 22:28:35.782390  9023 sgd_solver.cpp:105] Iteration 103560, lr = 0.00323875
I1027 22:29:06.382876  9023 solver.cpp:222] Iteration 103600 (1.30722 iter/s, 30.5993s/40 iters), loss = 1.69416
I1027 22:29:06.383028  9023 solver.cpp:241]     Train net output #0: loss = 1.69416 (* 1 = 1.69416 loss)
I1027 22:29:06.383044  9023 sgd_solver.cpp:105] Iteration 103600, lr = 0.00323641
I1027 22:29:36.981542  9023 solver.cpp:222] Iteration 103640 (1.3073 iter/s, 30.5974s/40 iters), loss = 1.51818
I1027 22:29:36.981734  9023 solver.cpp:241]     Train net output #0: loss = 1.51818 (* 1 = 1.51818 loss)
I1027 22:29:36.981748  9023 sgd_solver.cpp:105] Iteration 103640, lr = 0.00323407
I1027 22:30:08.158406  9023 solver.cpp:222] Iteration 103680 (1.28306 iter/s, 31.1755s/40 iters), loss = 1.66693
I1027 22:30:08.158589  9023 solver.cpp:241]     Train net output #0: loss = 1.66693 (* 1 = 1.66693 loss)
I1027 22:30:08.158607  9023 sgd_solver.cpp:105] Iteration 103680, lr = 0.00323173
I1027 22:30:38.845966  9023 solver.cpp:222] Iteration 103720 (1.30352 iter/s, 30.6862s/40 iters), loss = 1.70803
I1027 22:30:38.846119  9023 solver.cpp:241]     Train net output #0: loss = 1.70803 (* 1 = 1.70803 loss)
I1027 22:30:38.846135  9023 sgd_solver.cpp:105] Iteration 103720, lr = 0.00322939
I1027 22:31:14.685645  9023 solver.cpp:222] Iteration 103760 (1.11613 iter/s, 35.8382s/40 iters), loss = 1.49171
I1027 22:31:14.685904  9023 solver.cpp:241]     Train net output #0: loss = 1.49171 (* 1 = 1.49171 loss)
I1027 22:31:14.685931  9023 sgd_solver.cpp:105] Iteration 103760, lr = 0.00322705
I1027 22:31:45.830513  9023 solver.cpp:222] Iteration 103800 (1.28438 iter/s, 31.1434s/40 iters), loss = 1.71127
I1027 22:31:45.830705  9023 solver.cpp:241]     Train net output #0: loss = 1.71127 (* 1 = 1.71127 loss)
I1027 22:31:45.830721  9023 sgd_solver.cpp:105] Iteration 103800, lr = 0.00322471
I1027 22:32:16.422937  9023 solver.cpp:222] Iteration 103840 (1.30757 iter/s, 30.5911s/40 iters), loss = 1.58273
I1027 22:32:16.423091  9023 solver.cpp:241]     Train net output #0: loss = 1.58273 (* 1 = 1.58273 loss)
I1027 22:32:16.423107  9023 sgd_solver.cpp:105] Iteration 103840, lr = 0.00322237
I1027 22:32:47.118144  9023 solver.cpp:222] Iteration 103880 (1.30319 iter/s, 30.6939s/40 iters), loss = 1.93879
I1027 22:32:47.118330  9023 solver.cpp:241]     Train net output #0: loss = 1.93879 (* 1 = 1.93879 loss)
I1027 22:32:47.118348  9023 sgd_solver.cpp:105] Iteration 103880, lr = 0.00322004
I1027 22:33:17.687206  9023 solver.cpp:222] Iteration 103920 (1.30857 iter/s, 30.5677s/40 iters), loss = 1.30106
I1027 22:33:17.687369  9023 solver.cpp:241]     Train net output #0: loss = 1.30106 (* 1 = 1.30106 loss)
I1027 22:33:17.687384  9023 sgd_solver.cpp:105] Iteration 103920, lr = 0.0032177
I1027 22:33:48.647791  9023 solver.cpp:222] Iteration 103960 (1.29202 iter/s, 30.9593s/40 iters), loss = 1.53377
I1027 22:33:48.647959  9023 solver.cpp:241]     Train net output #0: loss = 1.53377 (* 1 = 1.53377 loss)
I1027 22:33:48.647990  9023 sgd_solver.cpp:105] Iteration 103960, lr = 0.00321536
I1027 22:34:19.201696  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_104000.caffemodel
I1027 22:34:19.244482  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_104000.solverstate
I1027 22:34:19.267760  9023 solver.cpp:334] Iteration 104000, Testing net (#0)
I1027 22:34:50.648000  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 22:34:50.858826  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55528
I1027 22:34:50.858886  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7884
I1027 22:34:50.858899  9023 solver.cpp:401]     Test net output #2: loss = 2.03111 (* 1 = 2.03111 loss)
I1027 22:34:51.629782  9023 solver.cpp:222] Iteration 104000 (0.635128 iter/s, 62.9795s/40 iters), loss = 1.66285
I1027 22:34:51.629845  9023 solver.cpp:241]     Train net output #0: loss = 1.66285 (* 1 = 1.66285 loss)
I1027 22:34:51.629860  9023 sgd_solver.cpp:105] Iteration 104000, lr = 0.00321302
I1027 22:35:22.360301  9023 solver.cpp:222] Iteration 104040 (1.30169 iter/s, 30.7293s/40 iters), loss = 1.53623
I1027 22:35:22.360455  9023 solver.cpp:241]     Train net output #0: loss = 1.53623 (* 1 = 1.53623 loss)
I1027 22:35:22.360472  9023 sgd_solver.cpp:105] Iteration 104040, lr = 0.00321069
I1027 22:35:53.181706  9023 solver.cpp:222] Iteration 104080 (1.29785 iter/s, 30.8201s/40 iters), loss = 1.74447
I1027 22:35:53.181905  9023 solver.cpp:241]     Train net output #0: loss = 1.74447 (* 1 = 1.74447 loss)
I1027 22:35:53.181921  9023 sgd_solver.cpp:105] Iteration 104080, lr = 0.00320835
I1027 22:36:23.791965  9023 solver.cpp:222] Iteration 104120 (1.30681 iter/s, 30.6089s/40 iters), loss = 1.60981
I1027 22:36:23.792183  9023 solver.cpp:241]     Train net output #0: loss = 1.60981 (* 1 = 1.60981 loss)
I1027 22:36:23.792209  9023 sgd_solver.cpp:105] Iteration 104120, lr = 0.00320602
I1027 22:36:55.417834  9023 solver.cpp:222] Iteration 104160 (1.26484 iter/s, 31.6245s/40 iters), loss = 1.52502
I1027 22:36:55.418015  9023 solver.cpp:241]     Train net output #0: loss = 1.52502 (* 1 = 1.52502 loss)
I1027 22:36:55.418031  9023 sgd_solver.cpp:105] Iteration 104160, lr = 0.00320368
I1027 22:37:26.034549  9023 solver.cpp:222] Iteration 104200 (1.30653 iter/s, 30.6154s/40 iters), loss = 1.62479
I1027 22:37:26.034721  9023 solver.cpp:241]     Train net output #0: loss = 1.62479 (* 1 = 1.62479 loss)
I1027 22:37:26.034739  9023 sgd_solver.cpp:105] Iteration 104200, lr = 0.00320134
I1027 22:37:56.152343  9023 solver.cpp:222] Iteration 104240 (1.32818 iter/s, 30.1165s/40 iters), loss = 1.74473
I1027 22:37:56.152513  9023 solver.cpp:241]     Train net output #0: loss = 1.74473 (* 1 = 1.74473 loss)
I1027 22:37:56.152529  9023 sgd_solver.cpp:105] Iteration 104240, lr = 0.00319901
I1027 22:38:26.879211  9023 solver.cpp:222] Iteration 104280 (1.30185 iter/s, 30.7255s/40 iters), loss = 1.38057
I1027 22:38:26.879374  9023 solver.cpp:241]     Train net output #0: loss = 1.38057 (* 1 = 1.38057 loss)
I1027 22:38:26.879390  9023 sgd_solver.cpp:105] Iteration 104280, lr = 0.00319667
I1027 22:38:57.744760  9023 solver.cpp:222] Iteration 104320 (1.296 iter/s, 30.8642s/40 iters), loss = 1.73584
I1027 22:38:57.744943  9023 solver.cpp:241]     Train net output #0: loss = 1.73584 (* 1 = 1.73584 loss)
I1027 22:38:57.744961  9023 sgd_solver.cpp:105] Iteration 104320, lr = 0.00319434
I1027 22:39:28.396194  9023 solver.cpp:222] Iteration 104360 (1.30505 iter/s, 30.6501s/40 iters), loss = 1.59475
I1027 22:39:28.396471  9023 solver.cpp:241]     Train net output #0: loss = 1.59475 (* 1 = 1.59475 loss)
I1027 22:39:28.396488  9023 sgd_solver.cpp:105] Iteration 104360, lr = 0.003192
I1027 22:39:59.185160  9023 solver.cpp:222] Iteration 104400 (1.29923 iter/s, 30.7875s/40 iters), loss = 1.41898
I1027 22:39:59.185362  9023 solver.cpp:241]     Train net output #0: loss = 1.41898 (* 1 = 1.41898 loss)
I1027 22:39:59.185395  9023 sgd_solver.cpp:105] Iteration 104400, lr = 0.00318967
I1027 22:40:29.876889  9023 solver.cpp:222] Iteration 104440 (1.30334 iter/s, 30.6904s/40 iters), loss = 1.48697
I1027 22:40:29.877123  9023 solver.cpp:241]     Train net output #0: loss = 1.48697 (* 1 = 1.48697 loss)
I1027 22:40:29.877141  9023 sgd_solver.cpp:105] Iteration 104440, lr = 0.00318734
I1027 22:41:01.708513  9023 solver.cpp:222] Iteration 104480 (1.25667 iter/s, 31.8302s/40 iters), loss = 1.68406
I1027 22:41:01.708742  9023 solver.cpp:241]     Train net output #0: loss = 1.68406 (* 1 = 1.68406 loss)
I1027 22:41:01.708767  9023 sgd_solver.cpp:105] Iteration 104480, lr = 0.003185
I1027 22:41:16.612941  9023 solver.cpp:334] Iteration 104500, Testing net (#0)
I1027 22:41:48.404443  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55904
I1027 22:41:48.404641  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79104
I1027 22:41:48.404656  9023 solver.cpp:401]     Test net output #2: loss = 1.95073 (* 1 = 1.95073 loss)
I1027 22:42:04.943236  9023 solver.cpp:222] Iteration 104520 (0.63259 iter/s, 63.2321s/40 iters), loss = 1.39903
I1027 22:42:04.943310  9023 solver.cpp:241]     Train net output #0: loss = 1.39903 (* 1 = 1.39903 loss)
I1027 22:42:04.943327  9023 sgd_solver.cpp:105] Iteration 104520, lr = 0.00318267
I1027 22:42:14.624548  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1027 22:42:35.866196  9023 solver.cpp:222] Iteration 104560 (1.29359 iter/s, 30.9217s/40 iters), loss = 1.51294
I1027 22:42:35.866402  9023 solver.cpp:241]     Train net output #0: loss = 1.51294 (* 1 = 1.51294 loss)
I1027 22:42:35.866420  9023 sgd_solver.cpp:105] Iteration 104560, lr = 0.00318034
I1027 22:43:06.903177  9023 solver.cpp:222] Iteration 104600 (1.28884 iter/s, 31.0356s/40 iters), loss = 1.75158
I1027 22:43:06.903364  9023 solver.cpp:241]     Train net output #0: loss = 1.75158 (* 1 = 1.75158 loss)
I1027 22:43:06.903381  9023 sgd_solver.cpp:105] Iteration 104600, lr = 0.00317801
I1027 22:43:38.126325  9023 solver.cpp:222] Iteration 104640 (1.28116 iter/s, 31.2218s/40 iters), loss = 1.3628
I1027 22:43:38.126508  9023 solver.cpp:241]     Train net output #0: loss = 1.3628 (* 1 = 1.3628 loss)
I1027 22:43:38.126525  9023 sgd_solver.cpp:105] Iteration 104640, lr = 0.00317567
I1027 22:44:09.389307  9023 solver.cpp:222] Iteration 104680 (1.27952 iter/s, 31.2616s/40 iters), loss = 1.47096
I1027 22:44:09.389490  9023 solver.cpp:241]     Train net output #0: loss = 1.47096 (* 1 = 1.47096 loss)
I1027 22:44:09.389508  9023 sgd_solver.cpp:105] Iteration 104680, lr = 0.00317334
I1027 22:44:40.490227  9023 solver.cpp:222] Iteration 104720 (1.28619 iter/s, 31.0996s/40 iters), loss = 1.90168
I1027 22:44:40.490438  9023 solver.cpp:241]     Train net output #0: loss = 1.90168 (* 1 = 1.90168 loss)
I1027 22:44:40.490455  9023 sgd_solver.cpp:105] Iteration 104720, lr = 0.00317101
I1027 22:45:11.994571  9023 solver.cpp:222] Iteration 104760 (1.26972 iter/s, 31.5029s/40 iters), loss = 1.43631
I1027 22:45:11.994771  9023 solver.cpp:241]     Train net output #0: loss = 1.43631 (* 1 = 1.43631 loss)
I1027 22:45:11.994788  9023 sgd_solver.cpp:105] Iteration 104760, lr = 0.00316868
I1027 22:45:43.146714  9023 solver.cpp:222] Iteration 104800 (1.28408 iter/s, 31.1508s/40 iters), loss = 1.63326
I1027 22:45:43.146908  9023 solver.cpp:241]     Train net output #0: loss = 1.63326 (* 1 = 1.63326 loss)
I1027 22:45:43.146924  9023 sgd_solver.cpp:105] Iteration 104800, lr = 0.00316635
I1027 22:46:15.213965  9023 solver.cpp:222] Iteration 104840 (1.24743 iter/s, 32.0658s/40 iters), loss = 1.6399
I1027 22:46:15.214159  9023 solver.cpp:241]     Train net output #0: loss = 1.6399 (* 1 = 1.6399 loss)
I1027 22:46:15.214186  9023 sgd_solver.cpp:105] Iteration 104840, lr = 0.00316402
I1027 22:46:46.042157  9023 solver.cpp:222] Iteration 104880 (1.29757 iter/s, 30.8268s/40 iters), loss = 1.72687
I1027 22:46:46.042520  9023 solver.cpp:241]     Train net output #0: loss = 1.72687 (* 1 = 1.72687 loss)
I1027 22:46:46.042537  9023 sgd_solver.cpp:105] Iteration 104880, lr = 0.00316168
I1027 22:47:17.026684  9023 solver.cpp:222] Iteration 104920 (1.29103 iter/s, 30.983s/40 iters), loss = 1.59165
I1027 22:47:17.026998  9023 solver.cpp:241]     Train net output #0: loss = 1.59165 (* 1 = 1.59165 loss)
I1027 22:47:17.027029  9023 sgd_solver.cpp:105] Iteration 104920, lr = 0.00315935
I1027 22:47:49.808977  9023 solver.cpp:222] Iteration 104960 (1.22023 iter/s, 32.7807s/40 iters), loss = 1.65467
I1027 22:47:49.809185  9023 solver.cpp:241]     Train net output #0: loss = 1.65467 (* 1 = 1.65467 loss)
I1027 22:47:49.809201  9023 sgd_solver.cpp:105] Iteration 104960, lr = 0.00315702
I1027 22:48:19.974351  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_105000.caffemodel
I1027 22:48:20.021627  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_105000.solverstate
I1027 22:48:20.041600  9023 solver.cpp:334] Iteration 105000, Testing net (#0)
I1027 22:48:51.179457  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 22:48:51.391723  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5618
I1027 22:48:51.391784  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79572
I1027 22:48:51.391798  9023 solver.cpp:401]     Test net output #2: loss = 1.93433 (* 1 = 1.93433 loss)
I1027 22:48:52.164000  9023 solver.cpp:222] Iteration 105000 (0.641514 iter/s, 62.3525s/40 iters), loss = 1.56314
I1027 22:48:52.164064  9023 solver.cpp:241]     Train net output #0: loss = 1.56314 (* 1 = 1.56314 loss)
I1027 22:48:52.164082  9023 sgd_solver.cpp:105] Iteration 105000, lr = 0.00315469
I1027 22:49:24.328223  9023 solver.cpp:222] Iteration 105040 (1.24367 iter/s, 32.1629s/40 iters), loss = 1.33024
I1027 22:49:24.328425  9023 solver.cpp:241]     Train net output #0: loss = 1.33024 (* 1 = 1.33024 loss)
I1027 22:49:24.328445  9023 sgd_solver.cpp:105] Iteration 105040, lr = 0.00315236
I1027 22:49:56.129864  9023 solver.cpp:222] Iteration 105080 (1.25785 iter/s, 31.8002s/40 iters), loss = 1.5342
I1027 22:49:56.130112  9023 solver.cpp:241]     Train net output #0: loss = 1.5342 (* 1 = 1.5342 loss)
I1027 22:49:56.130141  9023 sgd_solver.cpp:105] Iteration 105080, lr = 0.00315004
I1027 22:50:28.829439  9023 solver.cpp:222] Iteration 105120 (1.22331 iter/s, 32.6981s/40 iters), loss = 1.74302
I1027 22:50:28.829648  9023 solver.cpp:241]     Train net output #0: loss = 1.74302 (* 1 = 1.74302 loss)
I1027 22:50:28.829664  9023 sgd_solver.cpp:105] Iteration 105120, lr = 0.00314771
I1027 22:50:59.154795  9023 solver.cpp:222] Iteration 105160 (1.31909 iter/s, 30.324s/40 iters), loss = 1.78963
I1027 22:50:59.154971  9023 solver.cpp:241]     Train net output #0: loss = 1.78963 (* 1 = 1.78963 loss)
I1027 22:50:59.154988  9023 sgd_solver.cpp:105] Iteration 105160, lr = 0.00314538
I1027 22:51:29.628207  9023 solver.cpp:222] Iteration 105200 (1.31268 iter/s, 30.4721s/40 iters), loss = 1.70791
I1027 22:51:29.628415  9023 solver.cpp:241]     Train net output #0: loss = 1.70791 (* 1 = 1.70791 loss)
I1027 22:51:29.628432  9023 sgd_solver.cpp:105] Iteration 105200, lr = 0.00314305
I1027 22:52:00.727028  9023 solver.cpp:222] Iteration 105240 (1.28628 iter/s, 31.0974s/40 iters), loss = 1.66193
I1027 22:52:00.727238  9023 solver.cpp:241]     Train net output #0: loss = 1.66193 (* 1 = 1.66193 loss)
I1027 22:52:00.727254  9023 sgd_solver.cpp:105] Iteration 105240, lr = 0.00314072
I1027 22:52:31.112792  9023 solver.cpp:222] Iteration 105280 (1.31646 iter/s, 30.3844s/40 iters), loss = 1.69754
I1027 22:52:31.112962  9023 solver.cpp:241]     Train net output #0: loss = 1.69754 (* 1 = 1.69754 loss)
I1027 22:52:31.112977  9023 sgd_solver.cpp:105] Iteration 105280, lr = 0.00313839
I1027 22:53:01.902555  9023 solver.cpp:222] Iteration 105320 (1.29919 iter/s, 30.7884s/40 iters), loss = 1.52424
I1027 22:53:01.902753  9023 solver.cpp:241]     Train net output #0: loss = 1.52424 (* 1 = 1.52424 loss)
I1027 22:53:01.902770  9023 sgd_solver.cpp:105] Iteration 105320, lr = 0.00313607
I1027 22:53:33.073017  9023 solver.cpp:222] Iteration 105360 (1.28332 iter/s, 31.1691s/40 iters), loss = 2.17372
I1027 22:53:33.073313  9023 solver.cpp:241]     Train net output #0: loss = 2.17372 (* 1 = 2.17372 loss)
I1027 22:53:33.073344  9023 sgd_solver.cpp:105] Iteration 105360, lr = 0.00313374
I1027 22:54:04.973834  9023 solver.cpp:222] Iteration 105400 (1.25394 iter/s, 31.8993s/40 iters), loss = 1.77704
I1027 22:54:04.974064  9023 solver.cpp:241]     Train net output #0: loss = 1.77704 (* 1 = 1.77704 loss)
I1027 22:54:04.974092  9023 sgd_solver.cpp:105] Iteration 105400, lr = 0.00313141
I1027 22:54:36.357681  9023 solver.cpp:222] Iteration 105440 (1.2746 iter/s, 31.3824s/40 iters), loss = 1.65707
I1027 22:54:36.357875  9023 solver.cpp:241]     Train net output #0: loss = 1.65707 (* 1 = 1.65707 loss)
I1027 22:54:36.357893  9023 sgd_solver.cpp:105] Iteration 105440, lr = 0.00312909
I1027 22:55:07.586484  9023 solver.cpp:222] Iteration 105480 (1.28093 iter/s, 31.2274s/40 iters), loss = 1.77967
I1027 22:55:07.586661  9023 solver.cpp:241]     Train net output #0: loss = 1.77967 (* 1 = 1.77967 loss)
I1027 22:55:07.586678  9023 sgd_solver.cpp:105] Iteration 105480, lr = 0.00312676
I1027 22:55:22.259599  9023 solver.cpp:334] Iteration 105500, Testing net (#0)
I1027 22:55:53.518867  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56476
I1027 22:55:53.519058  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7938
I1027 22:55:53.519074  9023 solver.cpp:401]     Test net output #2: loss = 1.9454 (* 1 = 1.9454 loss)
I1027 22:56:09.737046  9023 solver.cpp:222] Iteration 105520 (0.643624 iter/s, 62.1481s/40 iters), loss = 1.76297
I1027 22:56:09.737115  9023 solver.cpp:241]     Train net output #0: loss = 1.76297 (* 1 = 1.76297 loss)
I1027 22:56:09.737130  9023 sgd_solver.cpp:105] Iteration 105520, lr = 0.00312443
I1027 22:56:40.548909  9023 solver.cpp:222] Iteration 105560 (1.29825 iter/s, 30.8106s/40 iters), loss = 1.36331
I1027 22:56:40.549115  9023 solver.cpp:241]     Train net output #0: loss = 1.36331 (* 1 = 1.36331 loss)
I1027 22:56:40.549132  9023 sgd_solver.cpp:105] Iteration 105560, lr = 0.00312211
I1027 22:57:11.387714  9023 solver.cpp:222] Iteration 105600 (1.29712 iter/s, 30.8374s/40 iters), loss = 1.56316
I1027 22:57:11.387887  9023 solver.cpp:241]     Train net output #0: loss = 1.56316 (* 1 = 1.56316 loss)
I1027 22:57:11.387903  9023 sgd_solver.cpp:105] Iteration 105600, lr = 0.00311978
I1027 22:57:42.212390  9023 solver.cpp:222] Iteration 105640 (1.29772 iter/s, 30.8233s/40 iters), loss = 1.38796
I1027 22:57:42.212559  9023 solver.cpp:241]     Train net output #0: loss = 1.38796 (* 1 = 1.38796 loss)
I1027 22:57:42.212575  9023 sgd_solver.cpp:105] Iteration 105640, lr = 0.00311746
I1027 22:58:12.937654  9023 solver.cpp:222] Iteration 105680 (1.30192 iter/s, 30.7239s/40 iters), loss = 1.74227
I1027 22:58:12.937813  9023 solver.cpp:241]     Train net output #0: loss = 1.74227 (* 1 = 1.74227 loss)
I1027 22:58:12.937829  9023 sgd_solver.cpp:105] Iteration 105680, lr = 0.00311513
I1027 22:58:43.814988  9023 solver.cpp:222] Iteration 105720 (1.2955 iter/s, 30.876s/40 iters), loss = 1.65456
I1027 22:58:43.815150  9023 solver.cpp:241]     Train net output #0: loss = 1.65456 (* 1 = 1.65456 loss)
I1027 22:58:43.815166  9023 sgd_solver.cpp:105] Iteration 105720, lr = 0.00311281
I1027 22:59:14.817136  9023 solver.cpp:222] Iteration 105760 (1.29029 iter/s, 31.0008s/40 iters), loss = 1.46057
I1027 22:59:14.817309  9023 solver.cpp:241]     Train net output #0: loss = 1.46057 (* 1 = 1.46057 loss)
I1027 22:59:14.817327  9023 sgd_solver.cpp:105] Iteration 105760, lr = 0.00311048
I1027 22:59:45.838572  9023 solver.cpp:222] Iteration 105800 (1.28949 iter/s, 31.0201s/40 iters), loss = 1.43626
I1027 22:59:45.838726  9023 solver.cpp:241]     Train net output #0: loss = 1.43626 (* 1 = 1.43626 loss)
I1027 22:59:45.838742  9023 sgd_solver.cpp:105] Iteration 105800, lr = 0.00310816
I1027 23:00:16.861697  9023 solver.cpp:222] Iteration 105840 (1.28942 iter/s, 31.0218s/40 iters), loss = 1.75323
I1027 23:00:16.861876  9023 solver.cpp:241]     Train net output #0: loss = 1.75323 (* 1 = 1.75323 loss)
I1027 23:00:16.861912  9023 sgd_solver.cpp:105] Iteration 105840, lr = 0.00310584
I1027 23:00:47.774315  9023 solver.cpp:222] Iteration 105880 (1.29403 iter/s, 30.9113s/40 iters), loss = 1.45244
I1027 23:00:47.774549  9023 solver.cpp:241]     Train net output #0: loss = 1.45244 (* 1 = 1.45244 loss)
I1027 23:00:47.774567  9023 sgd_solver.cpp:105] Iteration 105880, lr = 0.00310351
I1027 23:01:18.511570  9023 solver.cpp:222] Iteration 105920 (1.30141 iter/s, 30.7359s/40 iters), loss = 1.35783
I1027 23:01:18.511762  9023 solver.cpp:241]     Train net output #0: loss = 1.35783 (* 1 = 1.35783 loss)
I1027 23:01:18.511780  9023 sgd_solver.cpp:105] Iteration 105920, lr = 0.00310119
I1027 23:01:49.319533  9023 solver.cpp:222] Iteration 105960 (1.29842 iter/s, 30.8066s/40 iters), loss = 1.5903
I1027 23:01:49.319713  9023 solver.cpp:241]     Train net output #0: loss = 1.5903 (* 1 = 1.5903 loss)
I1027 23:01:49.319730  9023 sgd_solver.cpp:105] Iteration 105960, lr = 0.00309887
I1027 23:02:19.275513  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_106000.caffemodel
I1027 23:02:19.307837  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_106000.solverstate
I1027 23:02:19.325999  9023 solver.cpp:334] Iteration 106000, Testing net (#0)
I1027 23:02:50.694579  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 23:02:50.905716  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55752
I1027 23:02:50.905776  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.794719
I1027 23:02:50.905788  9023 solver.cpp:401]     Test net output #2: loss = 1.94623 (* 1 = 1.94623 loss)
I1027 23:02:51.647321  9023 solver.cpp:222] Iteration 106000 (0.641794 iter/s, 62.3253s/40 iters), loss = 1.50584
I1027 23:02:51.647383  9023 solver.cpp:241]     Train net output #0: loss = 1.50584 (* 1 = 1.50584 loss)
I1027 23:02:51.647398  9023 sgd_solver.cpp:105] Iteration 106000, lr = 0.00309654
I1027 23:03:22.787957  9023 solver.cpp:222] Iteration 106040 (1.28455 iter/s, 31.1394s/40 iters), loss = 1.4745
I1027 23:03:22.788141  9023 solver.cpp:241]     Train net output #0: loss = 1.4745 (* 1 = 1.4745 loss)
I1027 23:03:22.788157  9023 sgd_solver.cpp:105] Iteration 106040, lr = 0.00309422
I1027 23:03:53.599161  9023 solver.cpp:222] Iteration 106080 (1.29829 iter/s, 30.8099s/40 iters), loss = 1.62595
I1027 23:03:53.599318  9023 solver.cpp:241]     Train net output #0: loss = 1.62595 (* 1 = 1.62595 loss)
I1027 23:03:53.599337  9023 sgd_solver.cpp:105] Iteration 106080, lr = 0.0030919
I1027 23:04:24.254731  9023 solver.cpp:222] Iteration 106120 (1.30488 iter/s, 30.6543s/40 iters), loss = 1.41835
I1027 23:04:24.254870  9023 solver.cpp:241]     Train net output #0: loss = 1.41835 (* 1 = 1.41835 loss)
I1027 23:04:24.254887  9023 sgd_solver.cpp:105] Iteration 106120, lr = 0.00308958
I1027 23:04:54.994560  9023 solver.cpp:222] Iteration 106160 (1.3013 iter/s, 30.7385s/40 iters), loss = 1.6619
I1027 23:04:54.994696  9023 solver.cpp:241]     Train net output #0: loss = 1.6619 (* 1 = 1.6619 loss)
I1027 23:04:54.994714  9023 sgd_solver.cpp:105] Iteration 106160, lr = 0.00308726
I1027 23:05:25.783668  9023 solver.cpp:222] Iteration 106200 (1.29922 iter/s, 30.7878s/40 iters), loss = 1.558
I1027 23:05:25.783774  9023 solver.cpp:241]     Train net output #0: loss = 1.558 (* 1 = 1.558 loss)
I1027 23:05:25.783790  9023 sgd_solver.cpp:105] Iteration 106200, lr = 0.00308494
I1027 23:05:56.682693  9023 solver.cpp:222] Iteration 106240 (1.29459 iter/s, 30.8978s/40 iters), loss = 1.44885
I1027 23:05:56.682847  9023 solver.cpp:241]     Train net output #0: loss = 1.44885 (* 1 = 1.44885 loss)
I1027 23:05:56.682862  9023 sgd_solver.cpp:105] Iteration 106240, lr = 0.00308261
I1027 23:06:29.321552  9023 solver.cpp:222] Iteration 106280 (1.22558 iter/s, 32.6375s/40 iters), loss = 1.50911
I1027 23:06:29.321743  9023 solver.cpp:241]     Train net output #0: loss = 1.50911 (* 1 = 1.50911 loss)
I1027 23:06:29.321772  9023 sgd_solver.cpp:105] Iteration 106280, lr = 0.00308029
I1027 23:06:59.978032  9023 solver.cpp:222] Iteration 106320 (1.30484 iter/s, 30.6551s/40 iters), loss = 1.72121
I1027 23:06:59.978286  9023 solver.cpp:241]     Train net output #0: loss = 1.72121 (* 1 = 1.72121 loss)
I1027 23:06:59.978344  9023 sgd_solver.cpp:105] Iteration 106320, lr = 0.00307797
I1027 23:07:30.523617  9023 solver.cpp:222] Iteration 106360 (1.30958 iter/s, 30.5442s/40 iters), loss = 1.41394
I1027 23:07:30.523808  9023 solver.cpp:241]     Train net output #0: loss = 1.41394 (* 1 = 1.41394 loss)
I1027 23:07:30.523823  9023 sgd_solver.cpp:105] Iteration 106360, lr = 0.00307565
I1027 23:08:01.628533  9023 solver.cpp:222] Iteration 106400 (1.28603 iter/s, 31.1035s/40 iters), loss = 1.61189
I1027 23:08:01.628778  9023 solver.cpp:241]     Train net output #0: loss = 1.61189 (* 1 = 1.61189 loss)
I1027 23:08:01.628803  9023 sgd_solver.cpp:105] Iteration 106400, lr = 0.00307333
I1027 23:08:33.145176  9023 solver.cpp:222] Iteration 106440 (1.26923 iter/s, 31.5152s/40 iters), loss = 1.57747
I1027 23:08:33.145381  9023 solver.cpp:241]     Train net output #0: loss = 1.57747 (* 1 = 1.57747 loss)
I1027 23:08:33.145398  9023 sgd_solver.cpp:105] Iteration 106440, lr = 0.00307102
I1027 23:09:04.842770  9023 solver.cpp:222] Iteration 106480 (1.26198 iter/s, 31.6962s/40 iters), loss = 1.91457
I1027 23:09:04.842962  9023 solver.cpp:241]     Train net output #0: loss = 1.91457 (* 1 = 1.91457 loss)
I1027 23:09:04.842978  9023 sgd_solver.cpp:105] Iteration 106480, lr = 0.0030687
I1027 23:09:19.578059  9023 solver.cpp:334] Iteration 106500, Testing net (#0)
I1027 23:09:51.361558  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56112
I1027 23:09:51.361752  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79376
I1027 23:09:51.361768  9023 solver.cpp:401]     Test net output #2: loss = 1.92835 (* 1 = 1.92835 loss)
I1027 23:10:07.765537  9023 solver.cpp:222] Iteration 106520 (0.635726 iter/s, 62.9202s/40 iters), loss = 1.3727
I1027 23:10:07.765612  9023 solver.cpp:241]     Train net output #0: loss = 1.3727 (* 1 = 1.3727 loss)
I1027 23:10:07.765628  9023 sgd_solver.cpp:105] Iteration 106520, lr = 0.00306638
I1027 23:10:39.190204  9023 solver.cpp:222] Iteration 106560 (1.27294 iter/s, 31.4234s/40 iters), loss = 1.48839
I1027 23:10:39.190418  9023 solver.cpp:241]     Train net output #0: loss = 1.48839 (* 1 = 1.48839 loss)
I1027 23:10:39.190435  9023 sgd_solver.cpp:105] Iteration 106560, lr = 0.00306406
I1027 23:11:10.128867  9023 solver.cpp:222] Iteration 106600 (1.29294 iter/s, 30.9373s/40 iters), loss = 1.83675
I1027 23:11:10.129048  9023 solver.cpp:241]     Train net output #0: loss = 1.83675 (* 1 = 1.83675 loss)
I1027 23:11:10.129065  9023 sgd_solver.cpp:105] Iteration 106600, lr = 0.00306174
I1027 23:11:40.775655  9023 solver.cpp:222] Iteration 106640 (1.30525 iter/s, 30.6455s/40 iters), loss = 1.6155
I1027 23:11:40.775840  9023 solver.cpp:241]     Train net output #0: loss = 1.6155 (* 1 = 1.6155 loss)
I1027 23:11:40.775857  9023 sgd_solver.cpp:105] Iteration 106640, lr = 0.00305942
I1027 23:12:11.538775  9023 solver.cpp:222] Iteration 106680 (1.30031 iter/s, 30.7618s/40 iters), loss = 1.64987
I1027 23:12:11.538873  9023 solver.cpp:241]     Train net output #0: loss = 1.64987 (* 1 = 1.64987 loss)
I1027 23:12:11.538889  9023 sgd_solver.cpp:105] Iteration 106680, lr = 0.00305711
I1027 23:12:43.063841  9023 solver.cpp:222] Iteration 106720 (1.26888 iter/s, 31.5238s/40 iters), loss = 1.55496
I1027 23:12:43.064100  9023 solver.cpp:241]     Train net output #0: loss = 1.55496 (* 1 = 1.55496 loss)
I1027 23:12:43.064126  9023 sgd_solver.cpp:105] Iteration 106720, lr = 0.00305479
I1027 23:13:24.169201  9023 solver.cpp:222] Iteration 106760 (0.973152 iter/s, 41.1035s/40 iters), loss = 1.66747
I1027 23:13:24.169481  9023 solver.cpp:241]     Train net output #0: loss = 1.66747 (* 1 = 1.66747 loss)
I1027 23:13:24.169505  9023 sgd_solver.cpp:105] Iteration 106760, lr = 0.00305247
I1027 23:14:02.253506  9023 solver.cpp:222] Iteration 106800 (1.05035 iter/s, 38.0826s/40 iters), loss = 1.40064
I1027 23:14:02.253779  9023 solver.cpp:241]     Train net output #0: loss = 1.40064 (* 1 = 1.40064 loss)
I1027 23:14:02.253801  9023 sgd_solver.cpp:105] Iteration 106800, lr = 0.00305015
I1027 23:14:45.994637  9023 solver.cpp:222] Iteration 106840 (0.914511 iter/s, 43.7392s/40 iters), loss = 1.38239
I1027 23:14:45.994875  9023 solver.cpp:241]     Train net output #0: loss = 1.38239 (* 1 = 1.38239 loss)
I1027 23:14:45.994904  9023 sgd_solver.cpp:105] Iteration 106840, lr = 0.00304784
I1027 23:15:17.411509  9023 solver.cpp:222] Iteration 106880 (1.27326 iter/s, 31.4155s/40 iters), loss = 1.47979
I1027 23:15:17.411726  9023 solver.cpp:241]     Train net output #0: loss = 1.47979 (* 1 = 1.47979 loss)
I1027 23:15:17.411743  9023 sgd_solver.cpp:105] Iteration 106880, lr = 0.00304552
I1027 23:15:49.993317  9023 solver.cpp:222] Iteration 106920 (1.22773 iter/s, 32.5804s/40 iters), loss = 1.73851
I1027 23:15:49.993515  9023 solver.cpp:241]     Train net output #0: loss = 1.73851 (* 1 = 1.73851 loss)
I1027 23:15:49.993530  9023 sgd_solver.cpp:105] Iteration 106920, lr = 0.00304321
I1027 23:16:21.284754  9023 solver.cpp:222] Iteration 106960 (1.27836 iter/s, 31.2901s/40 iters), loss = 1.5831
I1027 23:16:21.284940  9023 solver.cpp:241]     Train net output #0: loss = 1.5831 (* 1 = 1.5831 loss)
I1027 23:16:21.284957  9023 sgd_solver.cpp:105] Iteration 106960, lr = 0.00304089
I1027 23:16:51.819156  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_107000.caffemodel
I1027 23:16:51.862484  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_107000.solverstate
I1027 23:16:51.885982  9023 solver.cpp:334] Iteration 107000, Testing net (#0)
I1027 23:17:23.082389  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 23:17:23.290908  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56052
I1027 23:17:23.290967  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79488
I1027 23:17:23.290980  9023 solver.cpp:401]     Test net output #2: loss = 1.95803 (* 1 = 1.95803 loss)
I1027 23:17:24.053344  9023 solver.cpp:222] Iteration 107000 (0.637287 iter/s, 62.7661s/40 iters), loss = 1.72793
I1027 23:17:24.053407  9023 solver.cpp:241]     Train net output #0: loss = 1.72793 (* 1 = 1.72793 loss)
I1027 23:17:24.053423  9023 sgd_solver.cpp:105] Iteration 107000, lr = 0.00303857
I1027 23:17:51.617770  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1027 23:17:55.864446  9023 solver.cpp:222] Iteration 107040 (1.25747 iter/s, 31.8098s/40 iters), loss = 1.65333
I1027 23:17:55.864672  9023 solver.cpp:241]     Train net output #0: loss = 1.65333 (* 1 = 1.65333 loss)
I1027 23:17:55.864691  9023 sgd_solver.cpp:105] Iteration 107040, lr = 0.00303626
I1027 23:18:27.139825  9023 solver.cpp:222] Iteration 107080 (1.27902 iter/s, 31.274s/40 iters), loss = 1.76278
I1027 23:18:27.140024  9023 solver.cpp:241]     Train net output #0: loss = 1.76278 (* 1 = 1.76278 loss)
I1027 23:18:27.140043  9023 sgd_solver.cpp:105] Iteration 107080, lr = 0.00303395
I1027 23:18:58.467437  9023 solver.cpp:222] Iteration 107120 (1.27689 iter/s, 31.3262s/40 iters), loss = 1.61554
I1027 23:18:58.467651  9023 solver.cpp:241]     Train net output #0: loss = 1.61554 (* 1 = 1.61554 loss)
I1027 23:18:58.468094  9023 sgd_solver.cpp:105] Iteration 107120, lr = 0.00303163
I1027 23:19:29.467510  9023 solver.cpp:222] Iteration 107160 (1.29038 iter/s, 30.9987s/40 iters), loss = 1.77928
I1027 23:19:29.467700  9023 solver.cpp:241]     Train net output #0: loss = 1.77928 (* 1 = 1.77928 loss)
I1027 23:19:29.467716  9023 sgd_solver.cpp:105] Iteration 107160, lr = 0.00302932
I1027 23:20:00.203388  9023 solver.cpp:222] Iteration 107200 (1.30147 iter/s, 30.7345s/40 iters), loss = 1.89442
I1027 23:20:00.203564  9023 solver.cpp:241]     Train net output #0: loss = 1.89442 (* 1 = 1.89442 loss)
I1027 23:20:00.203582  9023 sgd_solver.cpp:105] Iteration 107200, lr = 0.003027
I1027 23:20:30.887624  9023 solver.cpp:222] Iteration 107240 (1.30366 iter/s, 30.6829s/40 iters), loss = 1.66766
I1027 23:20:30.887873  9023 solver.cpp:241]     Train net output #0: loss = 1.66766 (* 1 = 1.66766 loss)
I1027 23:20:30.887907  9023 sgd_solver.cpp:105] Iteration 107240, lr = 0.00302469
I1027 23:21:01.720628  9023 solver.cpp:222] Iteration 107280 (1.29737 iter/s, 30.8316s/40 iters), loss = 1.52036
I1027 23:21:01.720796  9023 solver.cpp:241]     Train net output #0: loss = 1.52036 (* 1 = 1.52036 loss)
I1027 23:21:01.720813  9023 sgd_solver.cpp:105] Iteration 107280, lr = 0.00302238
I1027 23:21:32.449085  9023 solver.cpp:222] Iteration 107320 (1.30178 iter/s, 30.7271s/40 iters), loss = 1.62667
I1027 23:21:32.449292  9023 solver.cpp:241]     Train net output #0: loss = 1.62667 (* 1 = 1.62667 loss)
I1027 23:21:32.449316  9023 sgd_solver.cpp:105] Iteration 107320, lr = 0.00302006
I1027 23:22:03.214416  9023 solver.cpp:222] Iteration 107360 (1.30022 iter/s, 30.764s/40 iters), loss = 1.73695
I1027 23:22:03.214594  9023 solver.cpp:241]     Train net output #0: loss = 1.73695 (* 1 = 1.73695 loss)
I1027 23:22:03.214612  9023 sgd_solver.cpp:105] Iteration 107360, lr = 0.00301775
I1027 23:22:34.172114  9023 solver.cpp:222] Iteration 107400 (1.29214 iter/s, 30.9564s/40 iters), loss = 1.78159
I1027 23:22:34.172327  9023 solver.cpp:241]     Train net output #0: loss = 1.78159 (* 1 = 1.78159 loss)
I1027 23:22:34.172345  9023 sgd_solver.cpp:105] Iteration 107400, lr = 0.00301544
I1027 23:23:06.115656  9023 solver.cpp:222] Iteration 107440 (1.25227 iter/s, 31.9421s/40 iters), loss = 1.43183
I1027 23:23:06.115922  9023 solver.cpp:241]     Train net output #0: loss = 1.43183 (* 1 = 1.43183 loss)
I1027 23:23:06.115954  9023 sgd_solver.cpp:105] Iteration 107440, lr = 0.00301313
I1027 23:23:37.529070  9023 solver.cpp:222] Iteration 107480 (1.2734 iter/s, 31.412s/40 iters), loss = 1.37214
I1027 23:23:37.529291  9023 solver.cpp:241]     Train net output #0: loss = 1.37214 (* 1 = 1.37214 loss)
I1027 23:23:37.529317  9023 sgd_solver.cpp:105] Iteration 107480, lr = 0.00301081
I1027 23:23:52.238950  9023 solver.cpp:334] Iteration 107500, Testing net (#0)
I1027 23:24:23.472591  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56464
I1027 23:24:23.472798  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.795879
I1027 23:24:23.472815  9023 solver.cpp:401]     Test net output #2: loss = 1.95732 (* 1 = 1.95732 loss)
I1027 23:24:39.581924  9023 solver.cpp:222] Iteration 107520 (0.644638 iter/s, 62.0503s/40 iters), loss = 1.57083
I1027 23:24:39.581998  9023 solver.cpp:241]     Train net output #0: loss = 1.57083 (* 1 = 1.57083 loss)
I1027 23:24:39.582015  9023 sgd_solver.cpp:105] Iteration 107520, lr = 0.0030085
I1027 23:25:10.180047  9023 solver.cpp:222] Iteration 107560 (1.30732 iter/s, 30.5969s/40 iters), loss = 1.66758
I1027 23:25:10.180246  9023 solver.cpp:241]     Train net output #0: loss = 1.66758 (* 1 = 1.66758 loss)
I1027 23:25:10.180264  9023 sgd_solver.cpp:105] Iteration 107560, lr = 0.00300619
I1027 23:25:40.801303  9023 solver.cpp:222] Iteration 107600 (1.30634 iter/s, 30.6199s/40 iters), loss = 1.50021
I1027 23:25:40.801405  9023 solver.cpp:241]     Train net output #0: loss = 1.50021 (* 1 = 1.50021 loss)
I1027 23:25:40.801421  9023 sgd_solver.cpp:105] Iteration 107600, lr = 0.00300388
I1027 23:26:11.514130  9023 solver.cpp:222] Iteration 107640 (1.30244 iter/s, 30.7116s/40 iters), loss = 1.62898
I1027 23:26:11.514313  9023 solver.cpp:241]     Train net output #0: loss = 1.62898 (* 1 = 1.62898 loss)
I1027 23:26:11.514333  9023 sgd_solver.cpp:105] Iteration 107640, lr = 0.00300157
I1027 23:26:42.351058  9023 solver.cpp:222] Iteration 107680 (1.2972 iter/s, 30.8356s/40 iters), loss = 1.87701
I1027 23:26:42.351218  9023 solver.cpp:241]     Train net output #0: loss = 1.87701 (* 1 = 1.87701 loss)
I1027 23:26:42.351235  9023 sgd_solver.cpp:105] Iteration 107680, lr = 0.00299926
I1027 23:27:13.383117  9023 solver.cpp:222] Iteration 107720 (1.28904 iter/s, 31.0307s/40 iters), loss = 1.61307
I1027 23:27:13.383364  9023 solver.cpp:241]     Train net output #0: loss = 1.61307 (* 1 = 1.61307 loss)
I1027 23:27:13.383381  9023 sgd_solver.cpp:105] Iteration 107720, lr = 0.00299695
I1027 23:27:44.498632  9023 solver.cpp:222] Iteration 107760 (1.28559 iter/s, 31.1141s/40 iters), loss = 1.72249
I1027 23:27:44.498801  9023 solver.cpp:241]     Train net output #0: loss = 1.72249 (* 1 = 1.72249 loss)
I1027 23:27:44.498817  9023 sgd_solver.cpp:105] Iteration 107760, lr = 0.00299464
I1027 23:28:15.375444  9023 solver.cpp:222] Iteration 107800 (1.29553 iter/s, 30.8755s/40 iters), loss = 1.31338
I1027 23:28:15.375610  9023 solver.cpp:241]     Train net output #0: loss = 1.31338 (* 1 = 1.31338 loss)
I1027 23:28:15.375627  9023 sgd_solver.cpp:105] Iteration 107800, lr = 0.00299233
I1027 23:28:46.106426  9023 solver.cpp:222] Iteration 107840 (1.30167 iter/s, 30.7297s/40 iters), loss = 1.77444
I1027 23:28:46.106583  9023 solver.cpp:241]     Train net output #0: loss = 1.77444 (* 1 = 1.77444 loss)
I1027 23:28:46.106598  9023 sgd_solver.cpp:105] Iteration 107840, lr = 0.00299002
I1027 23:29:17.126258  9023 solver.cpp:222] Iteration 107880 (1.28955 iter/s, 31.0185s/40 iters), loss = 1.66945
I1027 23:29:17.126463  9023 solver.cpp:241]     Train net output #0: loss = 1.66945 (* 1 = 1.66945 loss)
I1027 23:29:17.126479  9023 sgd_solver.cpp:105] Iteration 107880, lr = 0.00298771
I1027 23:29:47.847235  9023 solver.cpp:222] Iteration 107920 (1.3021 iter/s, 30.7196s/40 iters), loss = 1.75869
I1027 23:29:47.847403  9023 solver.cpp:241]     Train net output #0: loss = 1.75869 (* 1 = 1.75869 loss)
I1027 23:29:47.847419  9023 sgd_solver.cpp:105] Iteration 107920, lr = 0.00298541
I1027 23:30:18.568697  9023 solver.cpp:222] Iteration 107960 (1.30208 iter/s, 30.7201s/40 iters), loss = 1.50037
I1027 23:30:18.568895  9023 solver.cpp:241]     Train net output #0: loss = 1.50037 (* 1 = 1.50037 loss)
I1027 23:30:18.568925  9023 sgd_solver.cpp:105] Iteration 107960, lr = 0.0029831
I1027 23:30:48.371126  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_108000.caffemodel
I1027 23:30:48.403331  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_108000.solverstate
I1027 23:30:48.421236  9023 solver.cpp:334] Iteration 108000, Testing net (#0)
I1027 23:31:19.669512  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 23:31:19.883913  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55888
I1027 23:31:19.883980  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79556
I1027 23:31:19.883992  9023 solver.cpp:401]     Test net output #2: loss = 1.95432 (* 1 = 1.95432 loss)
I1027 23:31:20.653694  9023 solver.cpp:222] Iteration 108000 (0.644304 iter/s, 62.0825s/40 iters), loss = 1.69478
I1027 23:31:20.653765  9023 solver.cpp:241]     Train net output #0: loss = 1.69478 (* 1 = 1.69478 loss)
I1027 23:31:20.653782  9023 sgd_solver.cpp:105] Iteration 108000, lr = 0.00298079
I1027 23:31:51.210997  9023 solver.cpp:222] Iteration 108040 (1.30907 iter/s, 30.5561s/40 iters), loss = 1.28272
I1027 23:31:51.211187  9023 solver.cpp:241]     Train net output #0: loss = 1.28272 (* 1 = 1.28272 loss)
I1027 23:31:51.211205  9023 sgd_solver.cpp:105] Iteration 108040, lr = 0.00297848
I1027 23:32:21.804733  9023 solver.cpp:222] Iteration 108080 (1.30751 iter/s, 30.5924s/40 iters), loss = 1.59391
I1027 23:32:21.804874  9023 solver.cpp:241]     Train net output #0: loss = 1.59391 (* 1 = 1.59391 loss)
I1027 23:32:21.804893  9023 sgd_solver.cpp:105] Iteration 108080, lr = 0.00297617
I1027 23:32:52.901599  9023 solver.cpp:222] Iteration 108120 (1.28636 iter/s, 31.0956s/40 iters), loss = 1.83573
I1027 23:32:52.901794  9023 solver.cpp:241]     Train net output #0: loss = 1.83573 (* 1 = 1.83573 loss)
I1027 23:32:52.901810  9023 sgd_solver.cpp:105] Iteration 108120, lr = 0.00297387
I1027 23:33:23.778002  9023 solver.cpp:222] Iteration 108160 (1.29554 iter/s, 30.875s/40 iters), loss = 1.72726
I1027 23:33:23.778172  9023 solver.cpp:241]     Train net output #0: loss = 1.72726 (* 1 = 1.72726 loss)
I1027 23:33:23.778204  9023 sgd_solver.cpp:105] Iteration 108160, lr = 0.00297156
I1027 23:33:54.477388  9023 solver.cpp:222] Iteration 108200 (1.30301 iter/s, 30.6981s/40 iters), loss = 1.35292
I1027 23:33:54.477620  9023 solver.cpp:241]     Train net output #0: loss = 1.35292 (* 1 = 1.35292 loss)
I1027 23:33:54.477638  9023 sgd_solver.cpp:105] Iteration 108200, lr = 0.00296925
I1027 23:34:25.316694  9023 solver.cpp:222] Iteration 108240 (1.29711 iter/s, 30.8379s/40 iters), loss = 1.59263
I1027 23:34:25.316867  9023 solver.cpp:241]     Train net output #0: loss = 1.59263 (* 1 = 1.59263 loss)
I1027 23:34:25.316884  9023 sgd_solver.cpp:105] Iteration 108240, lr = 0.00296695
I1027 23:34:55.916231  9023 solver.cpp:222] Iteration 108280 (1.30727 iter/s, 30.5982s/40 iters), loss = 1.47699
I1027 23:34:55.916405  9023 solver.cpp:241]     Train net output #0: loss = 1.47699 (* 1 = 1.47699 loss)
I1027 23:34:55.916424  9023 sgd_solver.cpp:105] Iteration 108280, lr = 0.00296464
I1027 23:35:26.586146  9023 solver.cpp:222] Iteration 108320 (1.30427 iter/s, 30.6686s/40 iters), loss = 1.53643
I1027 23:35:26.586333  9023 solver.cpp:241]     Train net output #0: loss = 1.53643 (* 1 = 1.53643 loss)
I1027 23:35:26.586352  9023 sgd_solver.cpp:105] Iteration 108320, lr = 0.00296234
I1027 23:35:57.213235  9023 solver.cpp:222] Iteration 108360 (1.30609 iter/s, 30.6258s/40 iters), loss = 1.75021
I1027 23:35:57.213413  9023 solver.cpp:241]     Train net output #0: loss = 1.75021 (* 1 = 1.75021 loss)
I1027 23:35:57.213428  9023 sgd_solver.cpp:105] Iteration 108360, lr = 0.00296003
I1027 23:36:27.955965  9023 solver.cpp:222] Iteration 108400 (1.30118 iter/s, 30.7414s/40 iters), loss = 1.38879
I1027 23:36:27.956146  9023 solver.cpp:241]     Train net output #0: loss = 1.38879 (* 1 = 1.38879 loss)
I1027 23:36:27.956161  9023 sgd_solver.cpp:105] Iteration 108400, lr = 0.00295773
I1027 23:36:58.589206  9023 solver.cpp:222] Iteration 108440 (1.30583 iter/s, 30.6319s/40 iters), loss = 1.85951
I1027 23:36:58.589385  9023 solver.cpp:241]     Train net output #0: loss = 1.85951 (* 1 = 1.85951 loss)
I1027 23:36:58.589404  9023 sgd_solver.cpp:105] Iteration 108440, lr = 0.00295542
I1027 23:37:29.108206  9023 solver.cpp:222] Iteration 108480 (1.31072 iter/s, 30.5177s/40 iters), loss = 1.36224
I1027 23:37:29.108353  9023 solver.cpp:241]     Train net output #0: loss = 1.36224 (* 1 = 1.36224 loss)
I1027 23:37:29.108368  9023 sgd_solver.cpp:105] Iteration 108480, lr = 0.00295312
I1027 23:37:43.677989  9023 solver.cpp:334] Iteration 108500, Testing net (#0)
I1027 23:38:15.317562  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56284
I1027 23:38:15.317782  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.793559
I1027 23:38:15.317798  9023 solver.cpp:401]     Test net output #2: loss = 1.9178 (* 1 = 1.9178 loss)
I1027 23:38:31.501881  9023 solver.cpp:222] Iteration 108520 (0.641116 iter/s, 62.3912s/40 iters), loss = 1.643
I1027 23:38:31.501956  9023 solver.cpp:241]     Train net output #0: loss = 1.643 (* 1 = 1.643 loss)
I1027 23:38:31.501971  9023 sgd_solver.cpp:105] Iteration 108520, lr = 0.00295081
I1027 23:39:02.572438  9023 solver.cpp:222] Iteration 108560 (1.28744 iter/s, 31.0693s/40 iters), loss = 1.43363
I1027 23:39:02.572687  9023 solver.cpp:241]     Train net output #0: loss = 1.43363 (* 1 = 1.43363 loss)
I1027 23:39:02.572712  9023 sgd_solver.cpp:105] Iteration 108560, lr = 0.00294851
I1027 23:39:42.965049  9023 solver.cpp:222] Iteration 108600 (0.990324 iter/s, 40.3908s/40 iters), loss = 1.82138
I1027 23:39:42.965307  9023 solver.cpp:241]     Train net output #0: loss = 1.82138 (* 1 = 1.82138 loss)
I1027 23:39:42.971093  9023 sgd_solver.cpp:105] Iteration 108600, lr = 0.00294621
I1027 23:40:15.919343  9023 solver.cpp:222] Iteration 108640 (1.21386 iter/s, 32.9528s/40 iters), loss = 1.63331
I1027 23:40:15.919564  9023 solver.cpp:241]     Train net output #0: loss = 1.63331 (* 1 = 1.63331 loss)
I1027 23:40:15.919584  9023 sgd_solver.cpp:105] Iteration 108640, lr = 0.0029439
I1027 23:40:38.047778  9078 blocking_queue.cpp:49] Waiting for data
I1027 23:40:49.649642  9023 solver.cpp:222] Iteration 108680 (1.18593 iter/s, 33.7288s/40 iters), loss = 1.94029
I1027 23:40:49.649863  9023 solver.cpp:241]     Train net output #0: loss = 1.94029 (* 1 = 1.94029 loss)
I1027 23:40:49.649880  9023 sgd_solver.cpp:105] Iteration 108680, lr = 0.0029416
I1027 23:41:28.807584  9023 solver.cpp:222] Iteration 108720 (1.02155 iter/s, 39.1562s/40 iters), loss = 1.43309
I1027 23:41:28.807785  9023 solver.cpp:241]     Train net output #0: loss = 1.43309 (* 1 = 1.43309 loss)
I1027 23:41:28.807806  9023 sgd_solver.cpp:105] Iteration 108720, lr = 0.0029393
I1027 23:42:03.715339  9023 solver.cpp:222] Iteration 108760 (1.14593 iter/s, 34.9062s/40 iters), loss = 1.47938
I1027 23:42:03.715531  9023 solver.cpp:241]     Train net output #0: loss = 1.47938 (* 1 = 1.47938 loss)
I1027 23:42:03.715548  9023 sgd_solver.cpp:105] Iteration 108760, lr = 0.002937
I1027 23:42:34.426134  9023 solver.cpp:222] Iteration 108800 (1.30253 iter/s, 30.7094s/40 iters), loss = 1.48857
I1027 23:42:34.426311  9023 solver.cpp:241]     Train net output #0: loss = 1.48857 (* 1 = 1.48857 loss)
I1027 23:42:34.426331  9023 sgd_solver.cpp:105] Iteration 108800, lr = 0.0029347
I1027 23:43:06.475317  9023 solver.cpp:222] Iteration 108840 (1.24814 iter/s, 32.0478s/40 iters), loss = 1.27938
I1027 23:43:06.475549  9023 solver.cpp:241]     Train net output #0: loss = 1.27938 (* 1 = 1.27938 loss)
I1027 23:43:06.475572  9023 sgd_solver.cpp:105] Iteration 108840, lr = 0.00293239
I1027 23:43:38.387023  9023 solver.cpp:222] Iteration 108880 (1.25351 iter/s, 31.9103s/40 iters), loss = 1.75324
I1027 23:43:38.387236  9023 solver.cpp:241]     Train net output #0: loss = 1.75324 (* 1 = 1.75324 loss)
I1027 23:43:38.387253  9023 sgd_solver.cpp:105] Iteration 108880, lr = 0.00293009
I1027 23:44:10.041573  9023 solver.cpp:222] Iteration 108920 (1.2637 iter/s, 31.6531s/40 iters), loss = 1.49155
I1027 23:44:10.041822  9023 solver.cpp:241]     Train net output #0: loss = 1.49155 (* 1 = 1.49155 loss)
I1027 23:44:10.041851  9023 sgd_solver.cpp:105] Iteration 108920, lr = 0.00292779
I1027 23:44:41.273237  9023 solver.cpp:222] Iteration 108960 (1.28081 iter/s, 31.2302s/40 iters), loss = 1.45909
I1027 23:44:41.273428  9023 solver.cpp:241]     Train net output #0: loss = 1.45909 (* 1 = 1.45909 loss)
I1027 23:44:41.273444  9023 sgd_solver.cpp:105] Iteration 108960, lr = 0.00292549
I1027 23:45:11.305663  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_109000.caffemodel
I1027 23:45:11.348649  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_109000.solverstate
I1027 23:45:11.366232  9023 solver.cpp:334] Iteration 109000, Testing net (#0)
I1027 23:45:42.778512  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 23:45:42.989239  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5584
I1027 23:45:42.989305  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.796319
I1027 23:45:42.989320  9023 solver.cpp:401]     Test net output #2: loss = 1.95315 (* 1 = 1.95315 loss)
I1027 23:45:43.758782  9023 solver.cpp:222] Iteration 109000 (0.640174 iter/s, 62.483s/40 iters), loss = 1.70158
I1027 23:45:43.758848  9023 solver.cpp:241]     Train net output #0: loss = 1.70158 (* 1 = 1.70158 loss)
I1027 23:45:43.758863  9023 sgd_solver.cpp:105] Iteration 109000, lr = 0.00292319
I1027 23:46:14.576527  9023 solver.cpp:222] Iteration 109040 (1.29801 iter/s, 30.8165s/40 iters), loss = 1.52461
I1027 23:46:14.576723  9023 solver.cpp:241]     Train net output #0: loss = 1.52461 (* 1 = 1.52461 loss)
I1027 23:46:14.576740  9023 sgd_solver.cpp:105] Iteration 109040, lr = 0.00292089
I1027 23:46:45.358207  9023 solver.cpp:222] Iteration 109080 (1.29953 iter/s, 30.7803s/40 iters), loss = 1.68669
I1027 23:46:45.358381  9023 solver.cpp:241]     Train net output #0: loss = 1.68669 (* 1 = 1.68669 loss)
I1027 23:46:45.358398  9023 sgd_solver.cpp:105] Iteration 109080, lr = 0.00291859
I1027 23:47:17.490613  9023 solver.cpp:222] Iteration 109120 (1.2449 iter/s, 32.131s/40 iters), loss = 1.67976
I1027 23:47:17.490941  9023 solver.cpp:241]     Train net output #0: loss = 1.67976 (* 1 = 1.67976 loss)
I1027 23:47:17.490963  9023 sgd_solver.cpp:105] Iteration 109120, lr = 0.00291629
I1027 23:47:50.472642  9023 solver.cpp:222] Iteration 109160 (1.21284 iter/s, 32.9805s/40 iters), loss = 1.35863
I1027 23:47:50.472841  9023 solver.cpp:241]     Train net output #0: loss = 1.35863 (* 1 = 1.35863 loss)
I1027 23:47:50.472862  9023 sgd_solver.cpp:105] Iteration 109160, lr = 0.00291399
I1027 23:48:22.044222  9023 solver.cpp:222] Iteration 109200 (1.26702 iter/s, 31.5702s/40 iters), loss = 1.81033
I1027 23:48:22.044417  9023 solver.cpp:241]     Train net output #0: loss = 1.81033 (* 1 = 1.81033 loss)
I1027 23:48:22.044435  9023 sgd_solver.cpp:105] Iteration 109200, lr = 0.00291169
I1027 23:48:53.747455  9023 solver.cpp:222] Iteration 109240 (1.26176 iter/s, 31.7018s/40 iters), loss = 1.74142
I1027 23:48:53.747678  9023 solver.cpp:241]     Train net output #0: loss = 1.74142 (* 1 = 1.74142 loss)
I1027 23:48:53.747694  9023 sgd_solver.cpp:105] Iteration 109240, lr = 0.00290939
I1027 23:49:24.531672  9023 solver.cpp:222] Iteration 109280 (1.29943 iter/s, 30.7828s/40 iters), loss = 1.53485
I1027 23:49:24.531883  9023 solver.cpp:241]     Train net output #0: loss = 1.53485 (* 1 = 1.53485 loss)
I1027 23:49:24.531899  9023 sgd_solver.cpp:105] Iteration 109280, lr = 0.0029071
I1027 23:49:55.397007  9023 solver.cpp:222] Iteration 109320 (1.29601 iter/s, 30.864s/40 iters), loss = 1.62643
I1027 23:49:55.397194  9023 solver.cpp:241]     Train net output #0: loss = 1.62643 (* 1 = 1.62643 loss)
I1027 23:49:55.397210  9023 sgd_solver.cpp:105] Iteration 109320, lr = 0.0029048
I1027 23:50:26.136404  9023 solver.cpp:222] Iteration 109360 (1.30132 iter/s, 30.7381s/40 iters), loss = 1.72229
I1027 23:50:26.136605  9023 solver.cpp:241]     Train net output #0: loss = 1.72229 (* 1 = 1.72229 loss)
I1027 23:50:26.136620  9023 sgd_solver.cpp:105] Iteration 109360, lr = 0.0029025
I1027 23:50:56.949208  9023 solver.cpp:222] Iteration 109400 (1.29822 iter/s, 30.8114s/40 iters), loss = 1.51063
I1027 23:50:56.949376  9023 solver.cpp:241]     Train net output #0: loss = 1.51063 (* 1 = 1.51063 loss)
I1027 23:50:56.949393  9023 sgd_solver.cpp:105] Iteration 109400, lr = 0.0029002
I1027 23:51:27.737505  9023 solver.cpp:222] Iteration 109440 (1.29925 iter/s, 30.787s/40 iters), loss = 1.42207
I1027 23:51:27.737692  9023 solver.cpp:241]     Train net output #0: loss = 1.42207 (* 1 = 1.42207 loss)
I1027 23:51:27.737710  9023 sgd_solver.cpp:105] Iteration 109440, lr = 0.00289791
I1027 23:51:58.417538  9023 solver.cpp:222] Iteration 109480 (1.30384 iter/s, 30.6787s/40 iters), loss = 1.57029
I1027 23:51:58.417718  9023 solver.cpp:241]     Train net output #0: loss = 1.57029 (* 1 = 1.57029 loss)
I1027 23:51:58.417734  9023 sgd_solver.cpp:105] Iteration 109480, lr = 0.00289561
I1027 23:52:13.178932  9023 solver.cpp:334] Iteration 109500, Testing net (#0)
I1027 23:52:44.425158  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56088
I1027 23:52:44.425611  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79208
I1027 23:52:44.425631  9023 solver.cpp:401]     Test net output #2: loss = 1.94898 (* 1 = 1.94898 loss)
I1027 23:53:00.604753  9023 solver.cpp:222] Iteration 109520 (0.643245 iter/s, 62.1847s/40 iters), loss = 1.42001
I1027 23:53:00.604821  9023 solver.cpp:241]     Train net output #0: loss = 1.42001 (* 1 = 1.42001 loss)
I1027 23:53:00.604837  9023 sgd_solver.cpp:105] Iteration 109520, lr = 0.00289331
I1027 23:53:13.611472  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1027 23:53:31.181962  9023 solver.cpp:222] Iteration 109560 (1.30822 iter/s, 30.576s/40 iters), loss = 1.67137
I1027 23:53:31.182185  9023 solver.cpp:241]     Train net output #0: loss = 1.67137 (* 1 = 1.67137 loss)
I1027 23:53:31.182202  9023 sgd_solver.cpp:105] Iteration 109560, lr = 0.00289102
I1027 23:54:01.814213  9023 solver.cpp:222] Iteration 109600 (1.30587 iter/s, 30.6308s/40 iters), loss = 1.59198
I1027 23:54:01.814467  9023 solver.cpp:241]     Train net output #0: loss = 1.59198 (* 1 = 1.59198 loss)
I1027 23:54:01.814503  9023 sgd_solver.cpp:105] Iteration 109600, lr = 0.00288872
I1027 23:54:32.469069  9023 solver.cpp:222] Iteration 109640 (1.30491 iter/s, 30.6535s/40 iters), loss = 1.15716
I1027 23:54:32.469264  9023 solver.cpp:241]     Train net output #0: loss = 1.15716 (* 1 = 1.15716 loss)
I1027 23:54:32.469280  9023 sgd_solver.cpp:105] Iteration 109640, lr = 0.00288643
I1027 23:55:03.140383  9023 solver.cpp:222] Iteration 109680 (1.30421 iter/s, 30.67s/40 iters), loss = 1.51655
I1027 23:55:03.140516  9023 solver.cpp:241]     Train net output #0: loss = 1.51655 (* 1 = 1.51655 loss)
I1027 23:55:03.140532  9023 sgd_solver.cpp:105] Iteration 109680, lr = 0.00288413
I1027 23:55:33.744715  9023 solver.cpp:222] Iteration 109720 (1.30706 iter/s, 30.603s/40 iters), loss = 1.382
I1027 23:55:33.744856  9023 solver.cpp:241]     Train net output #0: loss = 1.382 (* 1 = 1.382 loss)
I1027 23:55:33.744873  9023 sgd_solver.cpp:105] Iteration 109720, lr = 0.00288183
I1027 23:56:04.744015  9023 solver.cpp:222] Iteration 109760 (1.29041 iter/s, 30.998s/40 iters), loss = 1.53435
I1027 23:56:04.744220  9023 solver.cpp:241]     Train net output #0: loss = 1.53435 (* 1 = 1.53435 loss)
I1027 23:56:04.744236  9023 sgd_solver.cpp:105] Iteration 109760, lr = 0.00287954
I1027 23:56:35.414012  9023 solver.cpp:222] Iteration 109800 (1.30426 iter/s, 30.6686s/40 iters), loss = 1.59857
I1027 23:56:35.414178  9023 solver.cpp:241]     Train net output #0: loss = 1.59857 (* 1 = 1.59857 loss)
I1027 23:56:35.414194  9023 sgd_solver.cpp:105] Iteration 109800, lr = 0.00287725
I1027 23:57:06.332172  9023 solver.cpp:222] Iteration 109840 (1.29379 iter/s, 30.9168s/40 iters), loss = 1.35253
I1027 23:57:06.332368  9023 solver.cpp:241]     Train net output #0: loss = 1.35253 (* 1 = 1.35253 loss)
I1027 23:57:06.332384  9023 sgd_solver.cpp:105] Iteration 109840, lr = 0.00287495
I1027 23:57:36.756528  9023 solver.cpp:222] Iteration 109880 (1.31479 iter/s, 30.423s/40 iters), loss = 1.78698
I1027 23:57:36.756683  9023 solver.cpp:241]     Train net output #0: loss = 1.78698 (* 1 = 1.78698 loss)
I1027 23:57:36.756700  9023 sgd_solver.cpp:105] Iteration 109880, lr = 0.00287266
I1027 23:58:07.685834  9023 solver.cpp:222] Iteration 109920 (1.29333 iter/s, 30.928s/40 iters), loss = 1.65682
I1027 23:58:07.686055  9023 solver.cpp:241]     Train net output #0: loss = 1.65682 (* 1 = 1.65682 loss)
I1027 23:58:07.686071  9023 sgd_solver.cpp:105] Iteration 109920, lr = 0.00287037
I1027 23:58:38.615136  9023 solver.cpp:222] Iteration 109960 (1.29333 iter/s, 30.9279s/40 iters), loss = 1.68108
I1027 23:58:38.615345  9023 solver.cpp:241]     Train net output #0: loss = 1.68108 (* 1 = 1.68108 loss)
I1027 23:58:38.615361  9023 sgd_solver.cpp:105] Iteration 109960, lr = 0.00286807
I1027 23:59:08.356626  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_110000.caffemodel
I1027 23:59:08.389880  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_110000.solverstate
I1027 23:59:08.407949  9023 solver.cpp:334] Iteration 110000, Testing net (#0)
I1027 23:59:39.507045  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1027 23:59:39.719197  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.564
I1027 23:59:39.719259  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.796799
I1027 23:59:39.719274  9023 solver.cpp:401]     Test net output #2: loss = 1.93852 (* 1 = 1.93852 loss)
I1027 23:59:40.487880  9023 solver.cpp:222] Iteration 110000 (0.646515 iter/s, 61.8702s/40 iters), loss = 1.43072
I1027 23:59:40.487944  9023 solver.cpp:241]     Train net output #0: loss = 1.43072 (* 1 = 1.43072 loss)
I1027 23:59:40.487959  9023 sgd_solver.cpp:105] Iteration 110000, lr = 0.00286578
I1028 00:00:11.121049  9023 solver.cpp:222] Iteration 110040 (1.30583 iter/s, 30.6319s/40 iters), loss = 1.44331
I1028 00:00:11.121382  9023 solver.cpp:241]     Train net output #0: loss = 1.44331 (* 1 = 1.44331 loss)
I1028 00:00:11.121417  9023 sgd_solver.cpp:105] Iteration 110040, lr = 0.00286349
I1028 00:00:41.866789  9023 solver.cpp:222] Iteration 110080 (1.30106 iter/s, 30.7443s/40 iters), loss = 1.28448
I1028 00:00:41.866981  9023 solver.cpp:241]     Train net output #0: loss = 1.28448 (* 1 = 1.28448 loss)
I1028 00:00:41.866997  9023 sgd_solver.cpp:105] Iteration 110080, lr = 0.00286119
I1028 00:01:12.923863  9023 solver.cpp:222] Iteration 110120 (1.28801 iter/s, 31.0557s/40 iters), loss = 1.42052
I1028 00:01:12.924054  9023 solver.cpp:241]     Train net output #0: loss = 1.42052 (* 1 = 1.42052 loss)
I1028 00:01:12.924072  9023 sgd_solver.cpp:105] Iteration 110120, lr = 0.0028589
I1028 00:01:44.089587  9023 solver.cpp:222] Iteration 110160 (1.28352 iter/s, 31.1644s/40 iters), loss = 1.27837
I1028 00:01:44.089752  9023 solver.cpp:241]     Train net output #0: loss = 1.27837 (* 1 = 1.27837 loss)
I1028 00:01:44.089769  9023 sgd_solver.cpp:105] Iteration 110160, lr = 0.00285661
I1028 00:02:15.222903  9023 solver.cpp:222] Iteration 110200 (1.28485 iter/s, 31.132s/40 iters), loss = 1.46928
I1028 00:02:15.223106  9023 solver.cpp:241]     Train net output #0: loss = 1.46928 (* 1 = 1.46928 loss)
I1028 00:02:15.223122  9023 sgd_solver.cpp:105] Iteration 110200, lr = 0.00285432
I1028 00:02:46.331976  9023 solver.cpp:222] Iteration 110240 (1.28586 iter/s, 31.1077s/40 iters), loss = 1.62303
I1028 00:02:46.332183  9023 solver.cpp:241]     Train net output #0: loss = 1.62303 (* 1 = 1.62303 loss)
I1028 00:02:46.332200  9023 sgd_solver.cpp:105] Iteration 110240, lr = 0.00285203
I1028 00:03:17.270650  9023 solver.cpp:222] Iteration 110280 (1.29294 iter/s, 30.9373s/40 iters), loss = 1.53651
I1028 00:03:17.270814  9023 solver.cpp:241]     Train net output #0: loss = 1.53651 (* 1 = 1.53651 loss)
I1028 00:03:17.270829  9023 sgd_solver.cpp:105] Iteration 110280, lr = 0.00284974
I1028 00:03:48.450544  9023 solver.cpp:222] Iteration 110320 (1.28293 iter/s, 31.1786s/40 iters), loss = 1.41442
I1028 00:03:48.450758  9023 solver.cpp:241]     Train net output #0: loss = 1.41442 (* 1 = 1.41442 loss)
I1028 00:03:48.450781  9023 sgd_solver.cpp:105] Iteration 110320, lr = 0.00284745
I1028 00:04:19.640619  9023 solver.cpp:222] Iteration 110360 (1.28252 iter/s, 31.1887s/40 iters), loss = 1.87208
I1028 00:04:19.640820  9023 solver.cpp:241]     Train net output #0: loss = 1.87208 (* 1 = 1.87208 loss)
I1028 00:04:19.640836  9023 sgd_solver.cpp:105] Iteration 110360, lr = 0.00284516
I1028 00:04:51.385063  9023 solver.cpp:222] Iteration 110400 (1.26012 iter/s, 31.743s/40 iters), loss = 1.65056
I1028 00:04:51.385267  9023 solver.cpp:241]     Train net output #0: loss = 1.65056 (* 1 = 1.65056 loss)
I1028 00:04:51.385282  9023 sgd_solver.cpp:105] Iteration 110400, lr = 0.00284287
I1028 00:05:23.958528  9023 solver.cpp:222] Iteration 110440 (1.22805 iter/s, 32.572s/40 iters), loss = 1.48571
I1028 00:05:23.958750  9023 solver.cpp:241]     Train net output #0: loss = 1.48571 (* 1 = 1.48571 loss)
I1028 00:05:23.958766  9023 sgd_solver.cpp:105] Iteration 110440, lr = 0.00284058
I1028 00:05:54.950062  9023 solver.cpp:222] Iteration 110480 (1.29073 iter/s, 30.9901s/40 iters), loss = 1.75148
I1028 00:05:54.950289  9023 solver.cpp:241]     Train net output #0: loss = 1.75148 (* 1 = 1.75148 loss)
I1028 00:05:54.950309  9023 sgd_solver.cpp:105] Iteration 110480, lr = 0.00283829
I1028 00:06:09.358083  9023 solver.cpp:334] Iteration 110500, Testing net (#0)
I1028 00:06:40.942582  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56656
I1028 00:06:40.942775  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79408
I1028 00:06:40.942790  9023 solver.cpp:401]     Test net output #2: loss = 1.92686 (* 1 = 1.92686 loss)
I1028 00:06:57.711658  9023 solver.cpp:222] Iteration 110520 (0.637359 iter/s, 62.759s/40 iters), loss = 1.48549
I1028 00:06:57.711735  9023 solver.cpp:241]     Train net output #0: loss = 1.48549 (* 1 = 1.48549 loss)
I1028 00:06:57.711767  9023 sgd_solver.cpp:105] Iteration 110520, lr = 0.002836
I1028 00:07:28.689674  9023 solver.cpp:222] Iteration 110560 (1.29129 iter/s, 30.9768s/40 iters), loss = 1.24444
I1028 00:07:28.689929  9023 solver.cpp:241]     Train net output #0: loss = 1.24444 (* 1 = 1.24444 loss)
I1028 00:07:28.689946  9023 sgd_solver.cpp:105] Iteration 110560, lr = 0.00283371
I1028 00:07:59.552486  9023 solver.cpp:222] Iteration 110600 (1.29612 iter/s, 30.8614s/40 iters), loss = 1.22381
I1028 00:07:59.552675  9023 solver.cpp:241]     Train net output #0: loss = 1.22381 (* 1 = 1.22381 loss)
I1028 00:07:59.552691  9023 sgd_solver.cpp:105] Iteration 110600, lr = 0.00283142
I1028 00:08:30.414288  9023 solver.cpp:222] Iteration 110640 (1.29616 iter/s, 30.8604s/40 iters), loss = 1.82431
I1028 00:08:30.414494  9023 solver.cpp:241]     Train net output #0: loss = 1.82431 (* 1 = 1.82431 loss)
I1028 00:08:30.414510  9023 sgd_solver.cpp:105] Iteration 110640, lr = 0.00282914
I1028 00:09:01.500885  9023 solver.cpp:222] Iteration 110680 (1.28679 iter/s, 31.0852s/40 iters), loss = 1.8854
I1028 00:09:01.501085  9023 solver.cpp:241]     Train net output #0: loss = 1.8854 (* 1 = 1.8854 loss)
I1028 00:09:01.501101  9023 sgd_solver.cpp:105] Iteration 110680, lr = 0.00282685
I1028 00:09:32.278658  9023 solver.cpp:222] Iteration 110720 (1.2997 iter/s, 30.7764s/40 iters), loss = 1.62957
I1028 00:09:32.278836  9023 solver.cpp:241]     Train net output #0: loss = 1.62957 (* 1 = 1.62957 loss)
I1028 00:09:32.278851  9023 sgd_solver.cpp:105] Iteration 110720, lr = 0.00282456
I1028 00:10:03.155860  9023 solver.cpp:222] Iteration 110760 (1.29551 iter/s, 30.8759s/40 iters), loss = 1.79227
I1028 00:10:03.156038  9023 solver.cpp:241]     Train net output #0: loss = 1.79227 (* 1 = 1.79227 loss)
I1028 00:10:03.156054  9023 sgd_solver.cpp:105] Iteration 110760, lr = 0.00282227
I1028 00:10:33.724723  9023 solver.cpp:222] Iteration 110800 (1.30858 iter/s, 30.5675s/40 iters), loss = 1.83018
I1028 00:10:33.724866  9023 solver.cpp:241]     Train net output #0: loss = 1.83018 (* 1 = 1.83018 loss)
I1028 00:10:33.724882  9023 sgd_solver.cpp:105] Iteration 110800, lr = 0.00281999
I1028 00:11:04.260294  9023 solver.cpp:222] Iteration 110840 (1.31 iter/s, 30.5343s/40 iters), loss = 1.45166
I1028 00:11:04.260499  9023 solver.cpp:241]     Train net output #0: loss = 1.45166 (* 1 = 1.45166 loss)
I1028 00:11:04.260514  9023 sgd_solver.cpp:105] Iteration 110840, lr = 0.0028177
I1028 00:11:35.197895  9023 solver.cpp:222] Iteration 110880 (1.29298 iter/s, 30.9362s/40 iters), loss = 1.49358
I1028 00:11:35.198091  9023 solver.cpp:241]     Train net output #0: loss = 1.49358 (* 1 = 1.49358 loss)
I1028 00:11:35.198114  9023 sgd_solver.cpp:105] Iteration 110880, lr = 0.00281542
I1028 00:12:07.770423  9023 solver.cpp:222] Iteration 110920 (1.22808 iter/s, 32.5711s/40 iters), loss = 1.58285
I1028 00:12:07.770648  9023 solver.cpp:241]     Train net output #0: loss = 1.58285 (* 1 = 1.58285 loss)
I1028 00:12:07.770665  9023 sgd_solver.cpp:105] Iteration 110920, lr = 0.00281313
I1028 00:12:38.453182  9023 solver.cpp:222] Iteration 110960 (1.30372 iter/s, 30.6814s/40 iters), loss = 1.77367
I1028 00:12:38.453341  9023 solver.cpp:241]     Train net output #0: loss = 1.77367 (* 1 = 1.77367 loss)
I1028 00:12:38.453356  9023 sgd_solver.cpp:105] Iteration 110960, lr = 0.00281084
I1028 00:13:08.400533  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_111000.caffemodel
I1028 00:13:08.432237  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_111000.solverstate
I1028 00:13:08.449916  9023 solver.cpp:334] Iteration 111000, Testing net (#0)
I1028 00:13:39.951658  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 00:13:40.165395  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56512
I1028 00:13:40.165447  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79808
I1028 00:13:40.165462  9023 solver.cpp:401]     Test net output #2: loss = 1.94547 (* 1 = 1.94547 loss)
I1028 00:13:40.940971  9023 solver.cpp:222] Iteration 111000 (0.640151 iter/s, 62.4853s/40 iters), loss = 1.41409
I1028 00:13:40.941015  9023 solver.cpp:241]     Train net output #0: loss = 1.41409 (* 1 = 1.41409 loss)
I1028 00:13:40.941032  9023 sgd_solver.cpp:105] Iteration 111000, lr = 0.00280856
I1028 00:15:49.924968  9023 solver.cpp:222] Iteration 111040 (0.310128 iter/s, 128.979s/40 iters), loss = 1.46717
I1028 00:15:49.925256  9023 solver.cpp:241]     Train net output #0: loss = 1.46717 (* 1 = 1.46717 loss)
I1028 00:15:49.925279  9023 sgd_solver.cpp:105] Iteration 111040, lr = 0.00280627
I1028 00:16:34.819339  9023 solver.cpp:222] Iteration 111080 (0.891019 iter/s, 44.8924s/40 iters), loss = 1.71585
I1028 00:16:34.819512  9023 solver.cpp:241]     Train net output #0: loss = 1.71585 (* 1 = 1.71585 loss)
I1028 00:16:34.819532  9023 sgd_solver.cpp:105] Iteration 111080, lr = 0.00280399
I1028 00:17:16.787180  9023 solver.cpp:222] Iteration 111120 (0.95315 iter/s, 41.9661s/40 iters), loss = 1.63308
I1028 00:17:16.787374  9023 solver.cpp:241]     Train net output #0: loss = 1.63308 (* 1 = 1.63308 loss)
I1028 00:17:16.787390  9023 sgd_solver.cpp:105] Iteration 111120, lr = 0.00280171
I1028 00:17:47.888609  9023 solver.cpp:222] Iteration 111160 (1.28617 iter/s, 31.1001s/40 iters), loss = 1.74781
I1028 00:17:47.888799  9023 solver.cpp:241]     Train net output #0: loss = 1.74781 (* 1 = 1.74781 loss)
I1028 00:17:47.888815  9023 sgd_solver.cpp:105] Iteration 111160, lr = 0.00279942
I1028 00:18:18.585538  9023 solver.cpp:222] Iteration 111200 (1.30312 iter/s, 30.6956s/40 iters), loss = 1.74849
I1028 00:18:18.585712  9023 solver.cpp:241]     Train net output #0: loss = 1.74849 (* 1 = 1.74849 loss)
I1028 00:18:18.585728  9023 sgd_solver.cpp:105] Iteration 111200, lr = 0.00279714
I1028 00:18:49.458416  9023 solver.cpp:222] Iteration 111240 (1.29569 iter/s, 30.8715s/40 iters), loss = 1.52673
I1028 00:18:49.458604  9023 solver.cpp:241]     Train net output #0: loss = 1.52673 (* 1 = 1.52673 loss)
I1028 00:18:49.458621  9023 sgd_solver.cpp:105] Iteration 111240, lr = 0.00279486
I1028 00:19:20.065383  9023 solver.cpp:222] Iteration 111280 (1.30695 iter/s, 30.6056s/40 iters), loss = 1.81348
I1028 00:19:20.065546  9023 solver.cpp:241]     Train net output #0: loss = 1.81348 (* 1 = 1.81348 loss)
I1028 00:19:20.065562  9023 sgd_solver.cpp:105] Iteration 111280, lr = 0.00279257
I1028 00:19:50.737705  9023 solver.cpp:222] Iteration 111320 (1.30416 iter/s, 30.671s/40 iters), loss = 1.57231
I1028 00:19:50.737856  9023 solver.cpp:241]     Train net output #0: loss = 1.57231 (* 1 = 1.57231 loss)
I1028 00:19:50.737872  9023 sgd_solver.cpp:105] Iteration 111320, lr = 0.00279029
I1028 00:20:21.400527  9023 solver.cpp:222] Iteration 111360 (1.30457 iter/s, 30.6615s/40 iters), loss = 1.74193
I1028 00:20:21.400692  9023 solver.cpp:241]     Train net output #0: loss = 1.74193 (* 1 = 1.74193 loss)
I1028 00:20:21.400707  9023 sgd_solver.cpp:105] Iteration 111360, lr = 0.00278801
I1028 00:20:52.061260  9023 solver.cpp:222] Iteration 111400 (1.30466 iter/s, 30.6594s/40 iters), loss = 1.29404
I1028 00:20:52.061435  9023 solver.cpp:241]     Train net output #0: loss = 1.29404 (* 1 = 1.29404 loss)
I1028 00:20:52.061451  9023 sgd_solver.cpp:105] Iteration 111400, lr = 0.00278573
I1028 00:21:22.896981  9023 solver.cpp:222] Iteration 111440 (1.29725 iter/s, 30.8344s/40 iters), loss = 1.53286
I1028 00:21:22.897166  9023 solver.cpp:241]     Train net output #0: loss = 1.53286 (* 1 = 1.53286 loss)
I1028 00:21:22.897181  9023 sgd_solver.cpp:105] Iteration 111440, lr = 0.00278344
I1028 00:21:53.510893  9023 solver.cpp:222] Iteration 111480 (1.30665 iter/s, 30.6126s/40 iters), loss = 1.55639
I1028 00:21:53.511049  9023 solver.cpp:241]     Train net output #0: loss = 1.55639 (* 1 = 1.55639 loss)
I1028 00:21:53.511065  9023 sgd_solver.cpp:105] Iteration 111480, lr = 0.00278116
I1028 00:22:07.968724  9023 solver.cpp:334] Iteration 111500, Testing net (#0)
I1028 00:22:39.237107  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56564
I1028 00:22:39.237473  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79436
I1028 00:22:39.237490  9023 solver.cpp:401]     Test net output #2: loss = 1.9557 (* 1 = 1.9557 loss)
I1028 00:22:55.418690  9023 solver.cpp:222] Iteration 111520 (0.646148 iter/s, 61.9053s/40 iters), loss = 1.80939
I1028 00:22:55.418759  9023 solver.cpp:241]     Train net output #0: loss = 1.80939 (* 1 = 1.80939 loss)
I1028 00:22:55.418774  9023 sgd_solver.cpp:105] Iteration 111520, lr = 0.00277888
I1028 00:23:26.645933  9023 solver.cpp:222] Iteration 111560 (1.28098 iter/s, 31.226s/40 iters), loss = 1.34083
I1028 00:23:26.646138  9023 solver.cpp:241]     Train net output #0: loss = 1.34083 (* 1 = 1.34083 loss)
I1028 00:23:26.646154  9023 sgd_solver.cpp:105] Iteration 111560, lr = 0.0027766
I1028 00:23:57.209810  9023 solver.cpp:222] Iteration 111600 (1.30879 iter/s, 30.5625s/40 iters), loss = 1.57264
I1028 00:23:57.209977  9023 solver.cpp:241]     Train net output #0: loss = 1.57264 (* 1 = 1.57264 loss)
I1028 00:23:57.209993  9023 sgd_solver.cpp:105] Iteration 111600, lr = 0.00277432
I1028 00:24:27.714596  9023 solver.cpp:222] Iteration 111640 (1.31133 iter/s, 30.5035s/40 iters), loss = 1.32221
I1028 00:24:27.714774  9023 solver.cpp:241]     Train net output #0: loss = 1.32221 (* 1 = 1.32221 loss)
I1028 00:24:27.714790  9023 sgd_solver.cpp:105] Iteration 111640, lr = 0.00277204
I1028 00:24:58.461809  9023 solver.cpp:222] Iteration 111680 (1.30099 iter/s, 30.7459s/40 iters), loss = 1.68777
I1028 00:24:58.462008  9023 solver.cpp:241]     Train net output #0: loss = 1.68777 (* 1 = 1.68777 loss)
I1028 00:24:58.462024  9023 sgd_solver.cpp:105] Iteration 111680, lr = 0.00276976
I1028 00:25:28.939021  9023 solver.cpp:222] Iteration 111720 (1.31251 iter/s, 30.4759s/40 iters), loss = 1.53726
I1028 00:25:28.939180  9023 solver.cpp:241]     Train net output #0: loss = 1.53726 (* 1 = 1.53726 loss)
I1028 00:25:28.939198  9023 sgd_solver.cpp:105] Iteration 111720, lr = 0.00276748
I1028 00:25:59.472335  9023 solver.cpp:222] Iteration 111760 (1.3101 iter/s, 30.532s/40 iters), loss = 1.85204
I1028 00:25:59.472494  9023 solver.cpp:241]     Train net output #0: loss = 1.85204 (* 1 = 1.85204 loss)
I1028 00:25:59.472512  9023 sgd_solver.cpp:105] Iteration 111760, lr = 0.0027652
I1028 00:26:29.700378  9023 solver.cpp:222] Iteration 111800 (1.32333 iter/s, 30.2267s/40 iters), loss = 1.68332
I1028 00:26:29.700536  9023 solver.cpp:241]     Train net output #0: loss = 1.68332 (* 1 = 1.68332 loss)
I1028 00:26:29.700552  9023 sgd_solver.cpp:105] Iteration 111800, lr = 0.00276292
I1028 00:26:59.974053  9023 solver.cpp:222] Iteration 111840 (1.32134 iter/s, 30.2724s/40 iters), loss = 1.53527
I1028 00:26:59.974207  9023 solver.cpp:241]     Train net output #0: loss = 1.53527 (* 1 = 1.53527 loss)
I1028 00:26:59.974223  9023 sgd_solver.cpp:105] Iteration 111840, lr = 0.00276065
I1028 00:27:30.513201  9023 solver.cpp:222] Iteration 111880 (1.30985 iter/s, 30.5378s/40 iters), loss = 1.54075
I1028 00:27:30.513393  9023 solver.cpp:241]     Train net output #0: loss = 1.54075 (* 1 = 1.54075 loss)
I1028 00:27:30.513409  9023 sgd_solver.cpp:105] Iteration 111880, lr = 0.00275837
I1028 00:28:01.098506  9023 solver.cpp:222] Iteration 111920 (1.30788 iter/s, 30.584s/40 iters), loss = 1.63113
I1028 00:28:01.098672  9023 solver.cpp:241]     Train net output #0: loss = 1.63113 (* 1 = 1.63113 loss)
I1028 00:28:01.098690  9023 sgd_solver.cpp:105] Iteration 111920, lr = 0.00275609
I1028 00:28:31.736917  9023 solver.cpp:222] Iteration 111960 (1.30561 iter/s, 30.6371s/40 iters), loss = 1.95097
I1028 00:28:31.737081  9023 solver.cpp:241]     Train net output #0: loss = 1.95097 (* 1 = 1.95097 loss)
I1028 00:28:31.737099  9023 sgd_solver.cpp:105] Iteration 111960, lr = 0.00275381
I1028 00:29:01.820751  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_112000.caffemodel
I1028 00:29:01.864358  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_112000.solverstate
I1028 00:29:01.890492  9023 solver.cpp:334] Iteration 112000, Testing net (#0)
I1028 00:29:32.920485  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 00:29:33.131589  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56452
I1028 00:29:33.131650  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79968
I1028 00:29:33.131664  9023 solver.cpp:401]     Test net output #2: loss = 1.9465 (* 1 = 1.9465 loss)
I1028 00:29:33.910533  9023 solver.cpp:222] Iteration 112000 (0.643386 iter/s, 62.1711s/40 iters), loss = 1.45821
I1028 00:29:33.910578  9023 solver.cpp:241]     Train net output #0: loss = 1.45821 (* 1 = 1.45821 loss)
I1028 00:29:33.910594  9023 sgd_solver.cpp:105] Iteration 112000, lr = 0.00275153
I1028 00:30:05.710412  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1028 00:30:06.389870  9023 solver.cpp:222] Iteration 112040 (1.2316 iter/s, 32.4781s/40 iters), loss = 1.52851
I1028 00:30:06.389922  9023 solver.cpp:241]     Train net output #0: loss = 1.52851 (* 1 = 1.52851 loss)
I1028 00:30:06.389938  9023 sgd_solver.cpp:105] Iteration 112040, lr = 0.00274926
I1028 00:30:42.271054  9023 solver.cpp:222] Iteration 112080 (1.11483 iter/s, 35.8798s/40 iters), loss = 1.5425
I1028 00:30:42.271245  9023 solver.cpp:241]     Train net output #0: loss = 1.5425 (* 1 = 1.5425 loss)
I1028 00:30:42.271260  9023 sgd_solver.cpp:105] Iteration 112080, lr = 0.00274698
I1028 00:31:13.144681  9023 solver.cpp:222] Iteration 112120 (1.29566 iter/s, 30.8722s/40 iters), loss = 1.41396
I1028 00:31:13.144862  9023 solver.cpp:241]     Train net output #0: loss = 1.41396 (* 1 = 1.41396 loss)
I1028 00:31:13.144879  9023 sgd_solver.cpp:105] Iteration 112120, lr = 0.0027447
I1028 00:31:44.725531  9023 solver.cpp:222] Iteration 112160 (1.26665 iter/s, 31.5795s/40 iters), loss = 1.55551
I1028 00:31:44.725754  9023 solver.cpp:241]     Train net output #0: loss = 1.55551 (* 1 = 1.55551 loss)
I1028 00:31:44.725769  9023 sgd_solver.cpp:105] Iteration 112160, lr = 0.00274243
I1028 00:32:21.530187  9023 solver.cpp:222] Iteration 112200 (1.08687 iter/s, 36.8031s/40 iters), loss = 1.39665
I1028 00:32:21.530443  9023 solver.cpp:241]     Train net output #0: loss = 1.39665 (* 1 = 1.39665 loss)
I1028 00:32:21.530469  9023 sgd_solver.cpp:105] Iteration 112200, lr = 0.00274015
I1028 00:32:53.027920  9023 solver.cpp:222] Iteration 112240 (1.26999 iter/s, 31.4963s/40 iters), loss = 1.88555
I1028 00:32:53.028115  9023 solver.cpp:241]     Train net output #0: loss = 1.88555 (* 1 = 1.88555 loss)
I1028 00:32:53.028131  9023 sgd_solver.cpp:105] Iteration 112240, lr = 0.00273788
I1028 00:33:23.750516  9023 solver.cpp:222] Iteration 112280 (1.30203 iter/s, 30.7213s/40 iters), loss = 1.80952
I1028 00:33:23.750701  9023 solver.cpp:241]     Train net output #0: loss = 1.80952 (* 1 = 1.80952 loss)
I1028 00:33:23.750718  9023 sgd_solver.cpp:105] Iteration 112280, lr = 0.0027356
I1028 00:33:54.663854  9023 solver.cpp:222] Iteration 112320 (1.294 iter/s, 30.912s/40 iters), loss = 1.87732
I1028 00:33:54.664063  9023 solver.cpp:241]     Train net output #0: loss = 1.87732 (* 1 = 1.87732 loss)
I1028 00:33:54.664085  9023 sgd_solver.cpp:105] Iteration 112320, lr = 0.00273333
I1028 00:34:25.500392  9023 solver.cpp:222] Iteration 112360 (1.29722 iter/s, 30.8351s/40 iters), loss = 1.45533
I1028 00:34:25.500581  9023 solver.cpp:241]     Train net output #0: loss = 1.45533 (* 1 = 1.45533 loss)
I1028 00:34:25.500597  9023 sgd_solver.cpp:105] Iteration 112360, lr = 0.00273105
I1028 00:34:56.145182  9023 solver.cpp:222] Iteration 112400 (1.30534 iter/s, 30.6435s/40 iters), loss = 1.62361
I1028 00:34:56.145392  9023 solver.cpp:241]     Train net output #0: loss = 1.62361 (* 1 = 1.62361 loss)
I1028 00:34:56.145409  9023 sgd_solver.cpp:105] Iteration 112400, lr = 0.00272878
I1028 00:35:25.637897  9023 solver.cpp:222] Iteration 112440 (1.35633 iter/s, 29.4914s/40 iters), loss = 1.23515
I1028 00:35:25.637965  9023 solver.cpp:241]     Train net output #0: loss = 1.23515 (* 1 = 1.23515 loss)
I1028 00:35:25.637995  9023 sgd_solver.cpp:105] Iteration 112440, lr = 0.0027265
I1028 00:35:56.516666  9023 solver.cpp:222] Iteration 112480 (1.29544 iter/s, 30.8775s/40 iters), loss = 1.47427
I1028 00:35:56.516976  9023 solver.cpp:241]     Train net output #0: loss = 1.47427 (* 1 = 1.47427 loss)
I1028 00:35:56.517010  9023 sgd_solver.cpp:105] Iteration 112480, lr = 0.00272423
I1028 00:36:11.171936  9023 solver.cpp:334] Iteration 112500, Testing net (#0)
I1028 00:36:42.838551  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56228
I1028 00:36:42.838723  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.794
I1028 00:36:42.838739  9023 solver.cpp:401]     Test net output #2: loss = 1.91396 (* 1 = 1.91396 loss)
I1028 00:36:59.045469  9023 solver.cpp:222] Iteration 112520 (0.639732 iter/s, 62.5262s/40 iters), loss = 1.70337
I1028 00:36:59.045538  9023 solver.cpp:241]     Train net output #0: loss = 1.70337 (* 1 = 1.70337 loss)
I1028 00:36:59.045554  9023 sgd_solver.cpp:105] Iteration 112520, lr = 0.00272196
I1028 00:37:29.985040  9023 solver.cpp:222] Iteration 112560 (1.29289 iter/s, 30.9383s/40 iters), loss = 1.52087
I1028 00:37:29.985219  9023 solver.cpp:241]     Train net output #0: loss = 1.52087 (* 1 = 1.52087 loss)
I1028 00:37:29.985234  9023 sgd_solver.cpp:105] Iteration 112560, lr = 0.00271968
I1028 00:38:01.356982  9023 solver.cpp:222] Iteration 112600 (1.27508 iter/s, 31.3706s/40 iters), loss = 1.49746
I1028 00:38:01.357167  9023 solver.cpp:241]     Train net output #0: loss = 1.49746 (* 1 = 1.49746 loss)
I1028 00:38:01.357183  9023 sgd_solver.cpp:105] Iteration 112600, lr = 0.00271741
I1028 00:38:32.357491  9023 solver.cpp:222] Iteration 112640 (1.29036 iter/s, 30.9992s/40 iters), loss = 1.75684
I1028 00:38:32.357664  9023 solver.cpp:241]     Train net output #0: loss = 1.75684 (* 1 = 1.75684 loss)
I1028 00:38:32.357681  9023 sgd_solver.cpp:105] Iteration 112640, lr = 0.00271514
I1028 00:39:03.116413  9023 solver.cpp:222] Iteration 112680 (1.30049 iter/s, 30.7576s/40 iters), loss = 1.5903
I1028 00:39:03.116578  9023 solver.cpp:241]     Train net output #0: loss = 1.5903 (* 1 = 1.5903 loss)
I1028 00:39:03.116593  9023 sgd_solver.cpp:105] Iteration 112680, lr = 0.00271287
I1028 00:39:34.005957  9023 solver.cpp:222] Iteration 112720 (1.29499 iter/s, 30.8882s/40 iters), loss = 1.33421
I1028 00:39:34.006181  9023 solver.cpp:241]     Train net output #0: loss = 1.33421 (* 1 = 1.33421 loss)
I1028 00:39:34.006203  9023 sgd_solver.cpp:105] Iteration 112720, lr = 0.0027106
I1028 00:40:05.241114  9023 solver.cpp:222] Iteration 112760 (1.28067 iter/s, 31.2338s/40 iters), loss = 1.64901
I1028 00:40:05.241314  9023 solver.cpp:241]     Train net output #0: loss = 1.64901 (* 1 = 1.64901 loss)
I1028 00:40:05.241331  9023 sgd_solver.cpp:105] Iteration 112760, lr = 0.00270832
I1028 00:40:35.966323  9023 solver.cpp:222] Iteration 112800 (1.30192 iter/s, 30.7238s/40 iters), loss = 1.58712
I1028 00:40:35.966488  9023 solver.cpp:241]     Train net output #0: loss = 1.58712 (* 1 = 1.58712 loss)
I1028 00:40:35.966505  9023 sgd_solver.cpp:105] Iteration 112800, lr = 0.00270605
I1028 00:41:09.033215  9023 solver.cpp:222] Iteration 112840 (1.20972 iter/s, 33.0655s/40 iters), loss = 1.54198
I1028 00:41:09.033442  9023 solver.cpp:241]     Train net output #0: loss = 1.54198 (* 1 = 1.54198 loss)
I1028 00:41:09.033457  9023 sgd_solver.cpp:105] Iteration 112840, lr = 0.00270378
I1028 00:41:39.154448  9023 solver.cpp:222] Iteration 112880 (1.32803 iter/s, 30.1199s/40 iters), loss = 1.72014
I1028 00:41:39.154651  9023 solver.cpp:241]     Train net output #0: loss = 1.72014 (* 1 = 1.72014 loss)
I1028 00:41:39.154670  9023 sgd_solver.cpp:105] Iteration 112880, lr = 0.00270151
I1028 00:42:10.060523  9023 solver.cpp:222] Iteration 112920 (1.2943 iter/s, 30.9047s/40 iters), loss = 1.50937
I1028 00:42:10.060694  9023 solver.cpp:241]     Train net output #0: loss = 1.50937 (* 1 = 1.50937 loss)
I1028 00:42:10.060711  9023 sgd_solver.cpp:105] Iteration 112920, lr = 0.00269924
I1028 00:42:40.869377  9023 solver.cpp:222] Iteration 112960 (1.29838 iter/s, 30.8075s/40 iters), loss = 1.34281
I1028 00:42:40.869628  9023 solver.cpp:241]     Train net output #0: loss = 1.34281 (* 1 = 1.34281 loss)
I1028 00:42:40.869645  9023 sgd_solver.cpp:105] Iteration 112960, lr = 0.00269697
I1028 00:43:10.825698  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_113000.caffemodel
I1028 00:43:10.903164  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_113000.solverstate
I1028 00:43:10.925990  9023 solver.cpp:334] Iteration 113000, Testing net (#0)
I1028 00:43:42.366287  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 00:43:42.574856  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.55972
I1028 00:43:42.574920  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79544
I1028 00:43:42.574934  9023 solver.cpp:401]     Test net output #2: loss = 1.94686 (* 1 = 1.94686 loss)
I1028 00:43:43.344396  9023 solver.cpp:222] Iteration 113000 (0.640282 iter/s, 62.4724s/40 iters), loss = 1.52148
I1028 00:43:43.344457  9023 solver.cpp:241]     Train net output #0: loss = 1.52148 (* 1 = 1.52148 loss)
I1028 00:43:43.344472  9023 sgd_solver.cpp:105] Iteration 113000, lr = 0.0026947
I1028 00:44:13.970098  9023 solver.cpp:222] Iteration 113040 (1.30614 iter/s, 30.6245s/40 iters), loss = 1.24773
I1028 00:44:13.970283  9023 solver.cpp:241]     Train net output #0: loss = 1.24773 (* 1 = 1.24773 loss)
I1028 00:44:13.970302  9023 sgd_solver.cpp:105] Iteration 113040, lr = 0.00269243
I1028 00:44:44.576072  9023 solver.cpp:222] Iteration 113080 (1.30699 iter/s, 30.6046s/40 iters), loss = 1.7641
I1028 00:44:44.576254  9023 solver.cpp:241]     Train net output #0: loss = 1.7641 (* 1 = 1.7641 loss)
I1028 00:44:44.576270  9023 sgd_solver.cpp:105] Iteration 113080, lr = 0.00269017
I1028 00:45:15.609899  9023 solver.cpp:222] Iteration 113120 (1.28897 iter/s, 31.0325s/40 iters), loss = 1.72233
I1028 00:45:15.610110  9023 solver.cpp:241]     Train net output #0: loss = 1.72233 (* 1 = 1.72233 loss)
I1028 00:45:15.610126  9023 sgd_solver.cpp:105] Iteration 113120, lr = 0.0026879
I1028 00:45:46.734740  9023 solver.cpp:222] Iteration 113160 (1.28521 iter/s, 31.1234s/40 iters), loss = 1.48397
I1028 00:45:46.734939  9023 solver.cpp:241]     Train net output #0: loss = 1.48397 (* 1 = 1.48397 loss)
I1028 00:45:46.734956  9023 sgd_solver.cpp:105] Iteration 113160, lr = 0.00268563
I1028 00:46:17.469897  9023 solver.cpp:222] Iteration 113200 (1.3015 iter/s, 30.7338s/40 iters), loss = 1.51848
I1028 00:46:17.470072  9023 solver.cpp:241]     Train net output #0: loss = 1.51848 (* 1 = 1.51848 loss)
I1028 00:46:17.470089  9023 sgd_solver.cpp:105] Iteration 113200, lr = 0.00268336
I1028 00:46:49.594362  9023 solver.cpp:222] Iteration 113240 (1.24521 iter/s, 32.1231s/40 iters), loss = 1.78172
I1028 00:46:49.594560  9023 solver.cpp:241]     Train net output #0: loss = 1.78172 (* 1 = 1.78172 loss)
I1028 00:46:49.594576  9023 sgd_solver.cpp:105] Iteration 113240, lr = 0.00268109
I1028 00:47:20.274097  9023 solver.cpp:222] Iteration 113280 (1.30385 iter/s, 30.6784s/40 iters), loss = 1.8031
I1028 00:47:20.274281  9023 solver.cpp:241]     Train net output #0: loss = 1.8031 (* 1 = 1.8031 loss)
I1028 00:47:20.274711  9023 sgd_solver.cpp:105] Iteration 113280, lr = 0.00267883
I1028 00:47:51.089798  9023 solver.cpp:222] Iteration 113320 (1.2981 iter/s, 30.8144s/40 iters), loss = 1.77288
I1028 00:47:51.089977  9023 solver.cpp:241]     Train net output #0: loss = 1.77288 (* 1 = 1.77288 loss)
I1028 00:47:51.089993  9023 sgd_solver.cpp:105] Iteration 113320, lr = 0.00267656
I1028 00:48:22.076508  9023 solver.cpp:222] Iteration 113360 (1.29093 iter/s, 30.9854s/40 iters), loss = 1.59638
I1028 00:48:22.076689  9023 solver.cpp:241]     Train net output #0: loss = 1.59638 (* 1 = 1.59638 loss)
I1028 00:48:22.076704  9023 sgd_solver.cpp:105] Iteration 113360, lr = 0.00267429
I1028 00:48:53.145364  9023 solver.cpp:222] Iteration 113400 (1.28752 iter/s, 31.0675s/40 iters), loss = 1.51034
I1028 00:48:53.145623  9023 solver.cpp:241]     Train net output #0: loss = 1.51034 (* 1 = 1.51034 loss)
I1028 00:48:53.145640  9023 sgd_solver.cpp:105] Iteration 113400, lr = 0.00267203
I1028 00:49:25.129694  9023 solver.cpp:222] Iteration 113440 (1.25067 iter/s, 31.9829s/40 iters), loss = 1.8316
I1028 00:49:25.129940  9023 solver.cpp:241]     Train net output #0: loss = 1.8316 (* 1 = 1.8316 loss)
I1028 00:49:25.129962  9023 sgd_solver.cpp:105] Iteration 113440, lr = 0.00266976
I1028 00:51:12.031596  9023 solver.cpp:222] Iteration 113480 (0.37419 iter/s, 106.898s/40 iters), loss = 1.09808
I1028 00:51:12.031858  9023 solver.cpp:241]     Train net output #0: loss = 1.09808 (* 1 = 1.09808 loss)
I1028 00:51:12.031883  9023 sgd_solver.cpp:105] Iteration 113480, lr = 0.0026675
I1028 00:51:27.077482  9023 solver.cpp:334] Iteration 113500, Testing net (#0)
I1028 00:51:58.414094  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56144
I1028 00:51:58.414290  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.7918
I1028 00:51:58.414312  9023 solver.cpp:401]     Test net output #2: loss = 1.96311 (* 1 = 1.96311 loss)
I1028 00:52:14.799731  9023 solver.cpp:222] Iteration 113520 (0.637292 iter/s, 62.7655s/40 iters), loss = 1.60053
I1028 00:52:14.799816  9023 solver.cpp:241]     Train net output #0: loss = 1.60053 (* 1 = 1.60053 loss)
I1028 00:52:14.799836  9023 sgd_solver.cpp:105] Iteration 113520, lr = 0.00266523
I1028 00:52:45.868521  9023 solver.cpp:222] Iteration 113560 (1.28752 iter/s, 31.0675s/40 iters), loss = 1.73569
I1028 00:52:45.868734  9023 solver.cpp:241]     Train net output #0: loss = 1.73569 (* 1 = 1.73569 loss)
I1028 00:52:45.868752  9023 sgd_solver.cpp:105] Iteration 113560, lr = 0.00266297
I1028 00:53:16.875401  9023 solver.cpp:222] Iteration 113600 (1.29009 iter/s, 31.0055s/40 iters), loss = 1.43689
I1028 00:53:16.875564  9023 solver.cpp:241]     Train net output #0: loss = 1.43689 (* 1 = 1.43689 loss)
I1028 00:53:16.875581  9023 sgd_solver.cpp:105] Iteration 113600, lr = 0.0026607
I1028 00:53:47.756587  9023 solver.cpp:222] Iteration 113640 (1.29534 iter/s, 30.8799s/40 iters), loss = 1.24403
I1028 00:53:47.756772  9023 solver.cpp:241]     Train net output #0: loss = 1.24403 (* 1 = 1.24403 loss)
I1028 00:53:47.756788  9023 sgd_solver.cpp:105] Iteration 113640, lr = 0.00265844
I1028 00:54:18.901656  9023 solver.cpp:222] Iteration 113680 (1.28437 iter/s, 31.1437s/40 iters), loss = 1.30774
I1028 00:54:18.901830  9023 solver.cpp:241]     Train net output #0: loss = 1.30774 (* 1 = 1.30774 loss)
I1028 00:54:18.901847  9023 sgd_solver.cpp:105] Iteration 113680, lr = 0.00265617
I1028 00:54:49.882705  9023 solver.cpp:222] Iteration 113720 (1.29117 iter/s, 30.9797s/40 iters), loss = 1.83813
I1028 00:54:49.882889  9023 solver.cpp:241]     Train net output #0: loss = 1.83813 (* 1 = 1.83813 loss)
I1028 00:54:49.882905  9023 sgd_solver.cpp:105] Iteration 113720, lr = 0.00265391
I1028 00:55:21.434065  9023 solver.cpp:222] Iteration 113760 (1.26783 iter/s, 31.55s/40 iters), loss = 1.59569
I1028 00:55:21.434275  9023 solver.cpp:241]     Train net output #0: loss = 1.59569 (* 1 = 1.59569 loss)
I1028 00:55:21.434303  9023 sgd_solver.cpp:105] Iteration 113760, lr = 0.00265165
I1028 00:55:52.488813  9023 solver.cpp:222] Iteration 113800 (1.28811 iter/s, 31.0534s/40 iters), loss = 1.39325
I1028 00:55:52.489012  9023 solver.cpp:241]     Train net output #0: loss = 1.39325 (* 1 = 1.39325 loss)
I1028 00:55:52.489028  9023 sgd_solver.cpp:105] Iteration 113800, lr = 0.00264938
I1028 00:56:24.491670  9023 solver.cpp:222] Iteration 113840 (1.24994 iter/s, 32.0014s/40 iters), loss = 1.51184
I1028 00:56:24.491875  9023 solver.cpp:241]     Train net output #0: loss = 1.51184 (* 1 = 1.51184 loss)
I1028 00:56:24.491892  9023 sgd_solver.cpp:105] Iteration 113840, lr = 0.00264712
I1028 00:56:55.880697  9023 solver.cpp:222] Iteration 113880 (1.27439 iter/s, 31.3876s/40 iters), loss = 1.51963
I1028 00:56:55.880874  9023 solver.cpp:241]     Train net output #0: loss = 1.51963 (* 1 = 1.51963 loss)
I1028 00:56:55.880890  9023 sgd_solver.cpp:105] Iteration 113880, lr = 0.00264486
I1028 00:57:26.846740  9023 solver.cpp:222] Iteration 113920 (1.29179 iter/s, 30.9647s/40 iters), loss = 1.31206
I1028 00:57:26.846961  9023 solver.cpp:241]     Train net output #0: loss = 1.31206 (* 1 = 1.31206 loss)
I1028 00:57:26.846978  9023 sgd_solver.cpp:105] Iteration 113920, lr = 0.0026426
I1028 00:57:57.811481  9023 solver.cpp:222] Iteration 113960 (1.29185 iter/s, 30.9634s/40 iters), loss = 1.67995
I1028 00:57:57.811659  9023 solver.cpp:241]     Train net output #0: loss = 1.67995 (* 1 = 1.67995 loss)
I1028 00:57:57.811676  9023 sgd_solver.cpp:105] Iteration 113960, lr = 0.00264033
I1028 00:58:28.334616  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_114000.caffemodel
I1028 00:58:28.368069  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_114000.solverstate
I1028 00:58:28.385695  9023 solver.cpp:334] Iteration 114000, Testing net (#0)
I1028 00:58:59.536641  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 00:58:59.747684  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.564801
I1028 00:58:59.747753  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.800559
I1028 00:58:59.747767  9023 solver.cpp:401]     Test net output #2: loss = 1.93631 (* 1 = 1.93631 loss)
I1028 00:59:00.519629  9023 solver.cpp:222] Iteration 114000 (0.637901 iter/s, 62.7056s/40 iters), loss = 1.32808
I1028 00:59:00.519696  9023 solver.cpp:241]     Train net output #0: loss = 1.32808 (* 1 = 1.32808 loss)
I1028 00:59:00.519711  9023 sgd_solver.cpp:105] Iteration 114000, lr = 0.00263807
I1028 00:59:31.586210  9023 solver.cpp:222] Iteration 114040 (1.28761 iter/s, 31.0653s/40 iters), loss = 1.42081
I1028 00:59:31.586408  9023 solver.cpp:241]     Train net output #0: loss = 1.42081 (* 1 = 1.42081 loss)
I1028 00:59:31.586426  9023 sgd_solver.cpp:105] Iteration 114040, lr = 0.00263581
I1028 01:00:02.108568  9023 solver.cpp:222] Iteration 114080 (1.31057 iter/s, 30.521s/40 iters), loss = 1.36988
I1028 01:00:02.108752  9023 solver.cpp:241]     Train net output #0: loss = 1.36988 (* 1 = 1.36988 loss)
I1028 01:00:02.108769  9023 sgd_solver.cpp:105] Iteration 114080, lr = 0.00263355
I1028 01:00:34.382014  9023 solver.cpp:222] Iteration 114120 (1.23946 iter/s, 32.272s/40 iters), loss = 1.60166
I1028 01:00:34.382190  9023 solver.cpp:241]     Train net output #0: loss = 1.60166 (* 1 = 1.60166 loss)
I1028 01:00:34.382207  9023 sgd_solver.cpp:105] Iteration 114120, lr = 0.00263129
I1028 01:01:05.298792  9023 solver.cpp:222] Iteration 114160 (1.29385 iter/s, 30.9154s/40 iters), loss = 1.89584
I1028 01:01:05.298985  9023 solver.cpp:241]     Train net output #0: loss = 1.89584 (* 1 = 1.89584 loss)
I1028 01:01:05.299001  9023 sgd_solver.cpp:105] Iteration 114160, lr = 0.00262903
I1028 01:01:36.650720  9023 solver.cpp:222] Iteration 114200 (1.27589 iter/s, 31.3505s/40 iters), loss = 1.31465
I1028 01:01:36.650918  9023 solver.cpp:241]     Train net output #0: loss = 1.31465 (* 1 = 1.31465 loss)
I1028 01:01:36.650934  9023 sgd_solver.cpp:105] Iteration 114200, lr = 0.00262677
I1028 01:02:07.628185  9023 solver.cpp:222] Iteration 114240 (1.29132 iter/s, 30.9761s/40 iters), loss = 1.65694
I1028 01:02:07.628376  9023 solver.cpp:241]     Train net output #0: loss = 1.65694 (* 1 = 1.65694 loss)
I1028 01:02:07.628391  9023 sgd_solver.cpp:105] Iteration 114240, lr = 0.00262451
I1028 01:02:38.466322  9023 solver.cpp:222] Iteration 114280 (1.29715 iter/s, 30.8368s/40 iters), loss = 1.34882
I1028 01:02:38.466521  9023 solver.cpp:241]     Train net output #0: loss = 1.34882 (* 1 = 1.34882 loss)
I1028 01:02:38.466536  9023 sgd_solver.cpp:105] Iteration 114280, lr = 0.00262225
I1028 01:03:09.527004  9023 solver.cpp:222] Iteration 114320 (1.28786 iter/s, 31.0593s/40 iters), loss = 1.71851
I1028 01:03:09.527179  9023 solver.cpp:241]     Train net output #0: loss = 1.71851 (* 1 = 1.71851 loss)
I1028 01:03:09.527194  9023 sgd_solver.cpp:105] Iteration 114320, lr = 0.00261999
I1028 01:03:40.184600  9023 solver.cpp:222] Iteration 114360 (1.30479 iter/s, 30.6563s/40 iters), loss = 1.44111
I1028 01:03:40.184799  9023 solver.cpp:241]     Train net output #0: loss = 1.44111 (* 1 = 1.44111 loss)
I1028 01:03:40.184815  9023 sgd_solver.cpp:105] Iteration 114360, lr = 0.00261774
I1028 01:04:10.945669  9023 solver.cpp:222] Iteration 114400 (1.3004 iter/s, 30.7597s/40 iters), loss = 1.78637
I1028 01:04:10.945859  9023 solver.cpp:241]     Train net output #0: loss = 1.78637 (* 1 = 1.78637 loss)
I1028 01:04:10.945875  9023 sgd_solver.cpp:105] Iteration 114400, lr = 0.00261548
I1028 01:04:41.867854  9023 solver.cpp:222] Iteration 114440 (1.29363 iter/s, 30.9208s/40 iters), loss = 1.49638
I1028 01:04:41.868049  9023 solver.cpp:241]     Train net output #0: loss = 1.49638 (* 1 = 1.49638 loss)
I1028 01:04:41.868067  9023 sgd_solver.cpp:105] Iteration 114440, lr = 0.00261322
I1028 01:05:12.813917  9023 solver.cpp:222] Iteration 114480 (1.29263 iter/s, 30.9447s/40 iters), loss = 1.61227
I1028 01:05:12.814098  9023 solver.cpp:241]     Train net output #0: loss = 1.61227 (* 1 = 1.61227 loss)
I1028 01:05:12.814116  9023 sgd_solver.cpp:105] Iteration 114480, lr = 0.00261096
I1028 01:05:27.650498  9023 solver.cpp:334] Iteration 114500, Testing net (#0)
I1028 01:05:59.232126  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56652
I1028 01:05:59.232336  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79476
I1028 01:05:59.232352  9023 solver.cpp:401]     Test net output #2: loss = 1.93595 (* 1 = 1.93595 loss)
I1028 01:06:15.620322  9023 solver.cpp:222] Iteration 114520 (0.636903 iter/s, 62.8039s/40 iters), loss = 1.31087
I1028 01:06:15.620389  9023 solver.cpp:241]     Train net output #0: loss = 1.31087 (* 1 = 1.31087 loss)
I1028 01:06:15.620405  9023 sgd_solver.cpp:105] Iteration 114520, lr = 0.00260871
I1028 01:06:32.369354  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1028 01:06:46.647152  9023 solver.cpp:222] Iteration 114560 (1.28926 iter/s, 31.0256s/40 iters), loss = 1.29527
I1028 01:06:46.647222  9023 solver.cpp:241]     Train net output #0: loss = 1.29527 (* 1 = 1.29527 loss)
I1028 01:06:46.647238  9023 sgd_solver.cpp:105] Iteration 114560, lr = 0.00260645
I1028 01:07:17.756574  9023 solver.cpp:222] Iteration 114600 (1.28584 iter/s, 31.1082s/40 iters), loss = 1.58468
I1028 01:07:17.756755  9023 solver.cpp:241]     Train net output #0: loss = 1.58468 (* 1 = 1.58468 loss)
I1028 01:07:17.756772  9023 sgd_solver.cpp:105] Iteration 114600, lr = 0.00260419
I1028 01:07:48.835057  9023 solver.cpp:222] Iteration 114640 (1.28712 iter/s, 31.0771s/40 iters), loss = 1.53623
I1028 01:07:48.835238  9023 solver.cpp:241]     Train net output #0: loss = 1.53623 (* 1 = 1.53623 loss)
I1028 01:07:48.835254  9023 sgd_solver.cpp:105] Iteration 114640, lr = 0.00260194
I1028 01:08:19.507665  9023 solver.cpp:222] Iteration 114680 (1.30415 iter/s, 30.6713s/40 iters), loss = 1.48339
I1028 01:08:19.507845  9023 solver.cpp:241]     Train net output #0: loss = 1.48339 (* 1 = 1.48339 loss)
I1028 01:08:19.507861  9023 sgd_solver.cpp:105] Iteration 114680, lr = 0.00259968
I1028 01:08:50.137012  9023 solver.cpp:222] Iteration 114720 (1.30599 iter/s, 30.628s/40 iters), loss = 1.3644
I1028 01:08:50.137147  9023 solver.cpp:241]     Train net output #0: loss = 1.3644 (* 1 = 1.3644 loss)
I1028 01:08:50.137163  9023 sgd_solver.cpp:105] Iteration 114720, lr = 0.00259742
I1028 01:09:21.025828  9023 solver.cpp:222] Iteration 114760 (1.29502 iter/s, 30.8875s/40 iters), loss = 1.32148
I1028 01:09:21.026008  9023 solver.cpp:241]     Train net output #0: loss = 1.32148 (* 1 = 1.32148 loss)
I1028 01:09:21.026027  9023 sgd_solver.cpp:105] Iteration 114760, lr = 0.00259517
I1028 01:09:51.578325  9023 solver.cpp:222] Iteration 114800 (1.30928 iter/s, 30.5511s/40 iters), loss = 1.51371
I1028 01:09:51.578487  9023 solver.cpp:241]     Train net output #0: loss = 1.51371 (* 1 = 1.51371 loss)
I1028 01:09:51.578503  9023 sgd_solver.cpp:105] Iteration 114800, lr = 0.00259291
I1028 01:10:22.438009  9023 solver.cpp:222] Iteration 114840 (1.29625 iter/s, 30.8584s/40 iters), loss = 1.44889
I1028 01:10:22.438282  9023 solver.cpp:241]     Train net output #0: loss = 1.44889 (* 1 = 1.44889 loss)
I1028 01:10:22.438304  9023 sgd_solver.cpp:105] Iteration 114840, lr = 0.00259066
I1028 01:10:53.199142  9023 solver.cpp:222] Iteration 114880 (1.3004 iter/s, 30.7597s/40 iters), loss = 1.52915
I1028 01:10:53.199295  9023 solver.cpp:241]     Train net output #0: loss = 1.52915 (* 1 = 1.52915 loss)
I1028 01:10:53.199316  9023 sgd_solver.cpp:105] Iteration 114880, lr = 0.00258841
I1028 01:11:23.903615  9023 solver.cpp:222] Iteration 114920 (1.3028 iter/s, 30.7032s/40 iters), loss = 1.66106
I1028 01:11:23.903818  9023 solver.cpp:241]     Train net output #0: loss = 1.66106 (* 1 = 1.66106 loss)
I1028 01:11:23.903834  9023 sgd_solver.cpp:105] Iteration 114920, lr = 0.00258615
I1028 01:11:55.268103  9023 solver.cpp:222] Iteration 114960 (1.27538 iter/s, 31.3631s/40 iters), loss = 1.43984
I1028 01:11:55.268321  9023 solver.cpp:241]     Train net output #0: loss = 1.43984 (* 1 = 1.43984 loss)
I1028 01:11:55.268339  9023 sgd_solver.cpp:105] Iteration 114960, lr = 0.0025839
I1028 01:12:26.848076  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_115000.caffemodel
I1028 01:12:26.881286  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_115000.solverstate
I1028 01:12:26.899335  9023 solver.cpp:334] Iteration 115000, Testing net (#0)
I1028 01:12:58.309278  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 01:12:58.519587  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56428
I1028 01:12:58.519652  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79772
I1028 01:12:58.519665  9023 solver.cpp:401]     Test net output #2: loss = 1.9319 (* 1 = 1.9319 loss)
I1028 01:12:59.295253  9023 solver.cpp:222] Iteration 115000 (0.62476 iter/s, 64.0245s/40 iters), loss = 1.55818
I1028 01:12:59.295318  9023 solver.cpp:241]     Train net output #0: loss = 1.55818 (* 1 = 1.55818 loss)
I1028 01:12:59.295334  9023 sgd_solver.cpp:105] Iteration 115000, lr = 0.00258164
I1028 01:13:30.519865  9023 solver.cpp:222] Iteration 115040 (1.28109 iter/s, 31.2234s/40 iters), loss = 1.39649
I1028 01:13:30.520090  9023 solver.cpp:241]     Train net output #0: loss = 1.39649 (* 1 = 1.39649 loss)
I1028 01:13:30.520112  9023 sgd_solver.cpp:105] Iteration 115040, lr = 0.00257939
I1028 01:14:01.838955  9023 solver.cpp:222] Iteration 115080 (1.27723 iter/s, 31.3177s/40 iters), loss = 1.61982
I1028 01:14:01.839148  9023 solver.cpp:241]     Train net output #0: loss = 1.61982 (* 1 = 1.61982 loss)
I1028 01:14:01.839164  9023 sgd_solver.cpp:105] Iteration 115080, lr = 0.00257714
I1028 01:14:32.748323  9023 solver.cpp:222] Iteration 115120 (1.29416 iter/s, 30.908s/40 iters), loss = 1.18581
I1028 01:14:32.748508  9023 solver.cpp:241]     Train net output #0: loss = 1.18581 (* 1 = 1.18581 loss)
I1028 01:14:32.748527  9023 sgd_solver.cpp:105] Iteration 115120, lr = 0.00257489
I1028 01:15:03.990969  9023 solver.cpp:222] Iteration 115160 (1.28036 iter/s, 31.2413s/40 iters), loss = 1.61773
I1028 01:15:03.991168  9023 solver.cpp:241]     Train net output #0: loss = 1.61773 (* 1 = 1.61773 loss)
I1028 01:15:03.991188  9023 sgd_solver.cpp:105] Iteration 115160, lr = 0.00257264
I1028 01:15:34.690048  9023 solver.cpp:222] Iteration 115200 (1.30303 iter/s, 30.6977s/40 iters), loss = 1.95692
I1028 01:15:34.690250  9023 solver.cpp:241]     Train net output #0: loss = 1.95692 (* 1 = 1.95692 loss)
I1028 01:15:34.690266  9023 sgd_solver.cpp:105] Iteration 115200, lr = 0.00257038
I1028 01:16:05.692360  9023 solver.cpp:222] Iteration 115240 (1.29028 iter/s, 31.0009s/40 iters), loss = 1.74417
I1028 01:16:05.692570  9023 solver.cpp:241]     Train net output #0: loss = 1.74417 (* 1 = 1.74417 loss)
I1028 01:16:05.692590  9023 sgd_solver.cpp:105] Iteration 115240, lr = 0.00256813
I1028 01:16:36.407146  9023 solver.cpp:222] Iteration 115280 (1.30236 iter/s, 30.7134s/40 iters), loss = 1.55871
I1028 01:16:36.407404  9023 solver.cpp:241]     Train net output #0: loss = 1.55871 (* 1 = 1.55871 loss)
I1028 01:16:36.407421  9023 sgd_solver.cpp:105] Iteration 115280, lr = 0.00256588
I1028 01:17:07.245990  9023 solver.cpp:222] Iteration 115320 (1.29713 iter/s, 30.8374s/40 iters), loss = 1.61977
I1028 01:17:07.246177  9023 solver.cpp:241]     Train net output #0: loss = 1.61977 (* 1 = 1.61977 loss)
I1028 01:17:07.246194  9023 sgd_solver.cpp:105] Iteration 115320, lr = 0.00256363
I1028 01:17:38.160498  9023 solver.cpp:222] Iteration 115360 (1.29395 iter/s, 30.9132s/40 iters), loss = 1.23303
I1028 01:17:38.160675  9023 solver.cpp:241]     Train net output #0: loss = 1.23303 (* 1 = 1.23303 loss)
I1028 01:17:38.160691  9023 sgd_solver.cpp:105] Iteration 115360, lr = 0.00256138
I1028 01:18:09.196074  9023 solver.cpp:222] Iteration 115400 (1.2889 iter/s, 31.0342s/40 iters), loss = 1.58438
I1028 01:18:09.196241  9023 solver.cpp:241]     Train net output #0: loss = 1.58438 (* 1 = 1.58438 loss)
I1028 01:18:09.196259  9023 sgd_solver.cpp:105] Iteration 115400, lr = 0.00255913
I1028 01:18:40.137244  9023 solver.cpp:222] Iteration 115440 (1.29283 iter/s, 30.9398s/40 iters), loss = 1.15996
I1028 01:18:40.137475  9023 solver.cpp:241]     Train net output #0: loss = 1.15996 (* 1 = 1.15996 loss)
I1028 01:18:40.137496  9023 sgd_solver.cpp:105] Iteration 115440, lr = 0.00255688
I1028 01:19:12.363703  9023 solver.cpp:222] Iteration 115480 (1.24127 iter/s, 32.225s/40 iters), loss = 1.65872
I1028 01:19:12.363881  9023 solver.cpp:241]     Train net output #0: loss = 1.65872 (* 1 = 1.65872 loss)
I1028 01:19:12.363898  9023 sgd_solver.cpp:105] Iteration 115480, lr = 0.00255463
I1028 01:19:26.922607  9023 solver.cpp:334] Iteration 115500, Testing net (#0)
I1028 01:19:58.430104  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56844
I1028 01:19:58.430274  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79624
I1028 01:19:58.430289  9023 solver.cpp:401]     Test net output #2: loss = 1.90153 (* 1 = 1.90153 loss)
I1028 01:20:14.504331  9023 solver.cpp:222] Iteration 115520 (0.643727 iter/s, 62.1381s/40 iters), loss = 1.6573
I1028 01:20:14.504400  9023 solver.cpp:241]     Train net output #0: loss = 1.6573 (* 1 = 1.6573 loss)
I1028 01:20:14.504413  9023 sgd_solver.cpp:105] Iteration 115520, lr = 0.00255238
I1028 01:20:46.243803  9023 solver.cpp:222] Iteration 115560 (1.26031 iter/s, 31.7382s/40 iters), loss = 1.23665
I1028 01:20:46.244004  9023 solver.cpp:241]     Train net output #0: loss = 1.23665 (* 1 = 1.23665 loss)
I1028 01:20:46.244021  9023 sgd_solver.cpp:105] Iteration 115560, lr = 0.00255013
I1028 01:21:17.027608  9023 solver.cpp:222] Iteration 115600 (1.29944 iter/s, 30.7824s/40 iters), loss = 1.54958
I1028 01:21:17.027798  9023 solver.cpp:241]     Train net output #0: loss = 1.54958 (* 1 = 1.54958 loss)
I1028 01:21:17.027814  9023 sgd_solver.cpp:105] Iteration 115600, lr = 0.00254789
I1028 01:21:47.436769  9023 solver.cpp:222] Iteration 115640 (1.31545 iter/s, 30.4078s/40 iters), loss = 1.55471
I1028 01:21:47.436925  9023 solver.cpp:241]     Train net output #0: loss = 1.55471 (* 1 = 1.55471 loss)
I1028 01:21:47.436941  9023 sgd_solver.cpp:105] Iteration 115640, lr = 0.00254564
I1028 01:22:18.583597  9023 solver.cpp:222] Iteration 115680 (1.28429 iter/s, 31.1455s/40 iters), loss = 1.99499
I1028 01:22:18.583782  9023 solver.cpp:241]     Train net output #0: loss = 1.99499 (* 1 = 1.99499 loss)
I1028 01:22:18.583799  9023 sgd_solver.cpp:105] Iteration 115680, lr = 0.00254339
I1028 01:22:49.555443  9023 solver.cpp:222] Iteration 115720 (1.29155 iter/s, 30.9705s/40 iters), loss = 1.31868
I1028 01:22:49.555613  9023 solver.cpp:241]     Train net output #0: loss = 1.31868 (* 1 = 1.31868 loss)
I1028 01:22:49.555629  9023 sgd_solver.cpp:105] Iteration 115720, lr = 0.00254114
I1028 01:23:21.350539  9023 solver.cpp:222] Iteration 115760 (1.25811 iter/s, 31.7937s/40 iters), loss = 1.46897
I1028 01:23:21.350777  9023 solver.cpp:241]     Train net output #0: loss = 1.46897 (* 1 = 1.46897 loss)
I1028 01:23:21.350824  9023 sgd_solver.cpp:105] Iteration 115760, lr = 0.0025389
I1028 01:23:53.344825  9023 solver.cpp:222] Iteration 115800 (1.25028 iter/s, 31.9928s/40 iters), loss = 1.79997
I1028 01:23:53.345134  9023 solver.cpp:241]     Train net output #0: loss = 1.79997 (* 1 = 1.79997 loss)
I1028 01:23:53.345162  9023 sgd_solver.cpp:105] Iteration 115800, lr = 0.00253665
I1028 01:25:29.650180  9023 solver.cpp:222] Iteration 115840 (0.415362 iter/s, 96.3014s/40 iters), loss = 1.56341
I1028 01:25:29.650445  9023 solver.cpp:241]     Train net output #0: loss = 1.56341 (* 1 = 1.56341 loss)
I1028 01:25:29.650475  9023 sgd_solver.cpp:105] Iteration 115840, lr = 0.0025344
I1028 01:26:02.469882  9023 solver.cpp:222] Iteration 115880 (1.21884 iter/s, 32.8182s/40 iters), loss = 1.92169
I1028 01:26:02.470060  9023 solver.cpp:241]     Train net output #0: loss = 1.92169 (* 1 = 1.92169 loss)
I1028 01:26:02.470077  9023 sgd_solver.cpp:105] Iteration 115880, lr = 0.00253216
I1028 01:26:34.154183  9023 solver.cpp:222] Iteration 115920 (1.26251 iter/s, 31.6829s/40 iters), loss = 1.73153
I1028 01:26:34.154381  9023 solver.cpp:241]     Train net output #0: loss = 1.73153 (* 1 = 1.73153 loss)
I1028 01:26:34.154404  9023 sgd_solver.cpp:105] Iteration 115920, lr = 0.00252991
I1028 01:27:05.373443  9023 solver.cpp:222] Iteration 115960 (1.28132 iter/s, 31.2179s/40 iters), loss = 1.49521
I1028 01:27:05.373631  9023 solver.cpp:241]     Train net output #0: loss = 1.49521 (* 1 = 1.49521 loss)
I1028 01:27:05.373648  9023 sgd_solver.cpp:105] Iteration 115960, lr = 0.00252767
I1028 01:27:35.439358  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_116000.caffemodel
I1028 01:27:35.473039  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_116000.solverstate
I1028 01:27:35.490609  9023 solver.cpp:334] Iteration 116000, Testing net (#0)
I1028 01:28:06.559901  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 01:28:06.771612  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.568
I1028 01:28:06.771674  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80168
I1028 01:28:06.771688  9023 solver.cpp:401]     Test net output #2: loss = 1.90529 (* 1 = 1.90529 loss)
I1028 01:28:07.549505  9023 solver.cpp:222] Iteration 116000 (0.64336 iter/s, 62.1736s/40 iters), loss = 1.61844
I1028 01:28:07.549571  9023 solver.cpp:241]     Train net output #0: loss = 1.61844 (* 1 = 1.61844 loss)
I1028 01:28:07.549585  9023 sgd_solver.cpp:105] Iteration 116000, lr = 0.00252542
I1028 01:28:38.395778  9023 solver.cpp:222] Iteration 116040 (1.2968 iter/s, 30.845s/40 iters), loss = 1.78744
I1028 01:28:38.395956  9023 solver.cpp:241]     Train net output #0: loss = 1.78744 (* 1 = 1.78744 loss)
I1028 01:28:38.395972  9023 sgd_solver.cpp:105] Iteration 116040, lr = 0.00252318
I1028 01:29:09.171445  9023 solver.cpp:222] Iteration 116080 (1.29979 iter/s, 30.7743s/40 iters), loss = 1.6094
I1028 01:29:09.171619  9023 solver.cpp:241]     Train net output #0: loss = 1.6094 (* 1 = 1.6094 loss)
I1028 01:29:09.171635  9023 sgd_solver.cpp:105] Iteration 116080, lr = 0.00252093
I1028 01:29:40.837425  9023 solver.cpp:222] Iteration 116120 (1.26324 iter/s, 31.6646s/40 iters), loss = 1.63093
I1028 01:29:40.837638  9023 solver.cpp:241]     Train net output #0: loss = 1.63093 (* 1 = 1.63093 loss)
I1028 01:29:40.837656  9023 sgd_solver.cpp:105] Iteration 116120, lr = 0.00251869
I1028 01:30:11.455706  9023 solver.cpp:222] Iteration 116160 (1.30647 iter/s, 30.6169s/40 iters), loss = 1.37927
I1028 01:30:11.455907  9023 solver.cpp:241]     Train net output #0: loss = 1.37927 (* 1 = 1.37927 loss)
I1028 01:30:11.455924  9023 sgd_solver.cpp:105] Iteration 116160, lr = 0.00251644
I1028 01:30:42.130051  9023 solver.cpp:222] Iteration 116200 (1.30408 iter/s, 30.673s/40 iters), loss = 1.68406
I1028 01:30:42.130244  9023 solver.cpp:241]     Train net output #0: loss = 1.68406 (* 1 = 1.68406 loss)
I1028 01:30:42.130260  9023 sgd_solver.cpp:105] Iteration 116200, lr = 0.0025142
I1028 01:31:13.010161  9023 solver.cpp:222] Iteration 116240 (1.29539 iter/s, 30.8788s/40 iters), loss = 1.42772
I1028 01:31:13.010500  9023 solver.cpp:241]     Train net output #0: loss = 1.42772 (* 1 = 1.42772 loss)
I1028 01:31:13.010522  9023 sgd_solver.cpp:105] Iteration 116240, lr = 0.00251196
I1028 01:31:44.454846  9023 solver.cpp:222] Iteration 116280 (1.27214 iter/s, 31.4432s/40 iters), loss = 1.2355
I1028 01:31:44.455034  9023 solver.cpp:241]     Train net output #0: loss = 1.2355 (* 1 = 1.2355 loss)
I1028 01:31:44.455050  9023 sgd_solver.cpp:105] Iteration 116280, lr = 0.00250972
I1028 01:32:15.573647  9023 solver.cpp:222] Iteration 116320 (1.28545 iter/s, 31.1174s/40 iters), loss = 1.63426
I1028 01:32:15.573819  9023 solver.cpp:241]     Train net output #0: loss = 1.63426 (* 1 = 1.63426 loss)
I1028 01:32:15.573837  9023 sgd_solver.cpp:105] Iteration 116320, lr = 0.00250747
I1028 01:32:46.322223  9023 solver.cpp:222] Iteration 116360 (1.30093 iter/s, 30.7472s/40 iters), loss = 1.5834
I1028 01:32:46.322341  9023 solver.cpp:241]     Train net output #0: loss = 1.5834 (* 1 = 1.5834 loss)
I1028 01:32:46.322358  9023 sgd_solver.cpp:105] Iteration 116360, lr = 0.00250523
I1028 01:33:17.605458  9023 solver.cpp:222] Iteration 116400 (1.27869 iter/s, 31.2819s/40 iters), loss = 1.48944
I1028 01:33:17.605639  9023 solver.cpp:241]     Train net output #0: loss = 1.48944 (* 1 = 1.48944 loss)
I1028 01:33:17.605665  9023 sgd_solver.cpp:105] Iteration 116400, lr = 0.00250299
I1028 01:33:48.631413  9023 solver.cpp:222] Iteration 116440 (1.2893 iter/s, 31.0246s/40 iters), loss = 1.47338
I1028 01:33:48.631584  9023 solver.cpp:241]     Train net output #0: loss = 1.47338 (* 1 = 1.47338 loss)
I1028 01:33:48.631603  9023 sgd_solver.cpp:105] Iteration 116440, lr = 0.00250075
I1028 01:34:19.715817  9023 solver.cpp:222] Iteration 116480 (1.28687 iter/s, 31.0831s/40 iters), loss = 1.69569
I1028 01:34:19.716006  9023 solver.cpp:241]     Train net output #0: loss = 1.69569 (* 1 = 1.69569 loss)
I1028 01:34:19.716022  9023 sgd_solver.cpp:105] Iteration 116480, lr = 0.00249851
I1028 01:34:34.350870  9023 solver.cpp:334] Iteration 116500, Testing net (#0)
I1028 01:35:05.628468  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56416
I1028 01:35:05.628657  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79724
I1028 01:35:05.628674  9023 solver.cpp:401]     Test net output #2: loss = 1.92698 (* 1 = 1.92698 loss)
I1028 01:35:21.822620  9023 solver.cpp:222] Iteration 116520 (0.644078 iter/s, 62.1043s/40 iters), loss = 1.41392
I1028 01:35:21.822690  9023 solver.cpp:241]     Train net output #0: loss = 1.41392 (* 1 = 1.41392 loss)
I1028 01:35:21.822705  9023 sgd_solver.cpp:105] Iteration 116520, lr = 0.00249627
I1028 01:35:53.271059  9023 solver.cpp:222] Iteration 116560 (1.27197 iter/s, 31.4472s/40 iters), loss = 1.4833
I1028 01:35:53.271246  9023 solver.cpp:241]     Train net output #0: loss = 1.4833 (* 1 = 1.4833 loss)
I1028 01:35:53.271262  9023 sgd_solver.cpp:105] Iteration 116560, lr = 0.00249403
I1028 01:36:24.353360  9023 solver.cpp:222] Iteration 116600 (1.28696 iter/s, 31.0809s/40 iters), loss = 1.86627
I1028 01:36:24.353544  9023 solver.cpp:241]     Train net output #0: loss = 1.86627 (* 1 = 1.86627 loss)
I1028 01:36:24.353561  9023 sgd_solver.cpp:105] Iteration 116600, lr = 0.00249179
I1028 01:36:54.989856  9023 solver.cpp:222] Iteration 116640 (1.30569 iter/s, 30.6351s/40 iters), loss = 1.70534
I1028 01:36:54.990023  9023 solver.cpp:241]     Train net output #0: loss = 1.70534 (* 1 = 1.70534 loss)
I1028 01:36:54.990041  9023 sgd_solver.cpp:105] Iteration 116640, lr = 0.00248955
I1028 01:37:26.051666  9023 solver.cpp:222] Iteration 116680 (1.28781 iter/s, 31.0605s/40 iters), loss = 1.39806
I1028 01:37:26.051874  9023 solver.cpp:241]     Train net output #0: loss = 1.39806 (* 1 = 1.39806 loss)
I1028 01:37:26.051890  9023 sgd_solver.cpp:105] Iteration 116680, lr = 0.00248731
I1028 01:37:56.777542  9023 solver.cpp:222] Iteration 116720 (1.30189 iter/s, 30.7245s/40 iters), loss = 1.64556
I1028 01:37:56.777896  9023 solver.cpp:241]     Train net output #0: loss = 1.64556 (* 1 = 1.64556 loss)
I1028 01:37:56.778416  9023 sgd_solver.cpp:105] Iteration 116720, lr = 0.00248507
I1028 01:38:28.000712  9023 solver.cpp:222] Iteration 116760 (1.28116 iter/s, 31.2217s/40 iters), loss = 1.52234
I1028 01:38:28.000915  9023 solver.cpp:241]     Train net output #0: loss = 1.52234 (* 1 = 1.52234 loss)
I1028 01:38:28.000936  9023 sgd_solver.cpp:105] Iteration 116760, lr = 0.00248283
I1028 01:38:58.360877  9023 solver.cpp:222] Iteration 116800 (1.31757 iter/s, 30.3588s/40 iters), loss = 1.90279
I1028 01:38:58.361053  9023 solver.cpp:241]     Train net output #0: loss = 1.90279 (* 1 = 1.90279 loss)
I1028 01:38:58.361068  9023 sgd_solver.cpp:105] Iteration 116800, lr = 0.00248059
I1028 01:39:28.990571  9023 solver.cpp:222] Iteration 116840 (1.30598 iter/s, 30.6284s/40 iters), loss = 1.69879
I1028 01:39:28.990717  9023 solver.cpp:241]     Train net output #0: loss = 1.69879 (* 1 = 1.69879 loss)
I1028 01:39:28.990734  9023 sgd_solver.cpp:105] Iteration 116840, lr = 0.00247835
I1028 01:39:59.608072  9023 solver.cpp:222] Iteration 116880 (1.3065 iter/s, 30.6162s/40 iters), loss = 1.7229
I1028 01:39:59.608208  9023 solver.cpp:241]     Train net output #0: loss = 1.7229 (* 1 = 1.7229 loss)
I1028 01:39:59.608224  9023 sgd_solver.cpp:105] Iteration 116880, lr = 0.00247612
I1028 01:40:30.946357  9023 solver.cpp:222] Iteration 116920 (1.27645 iter/s, 31.337s/40 iters), loss = 1.7452
I1028 01:40:30.946540  9023 solver.cpp:241]     Train net output #0: loss = 1.7452 (* 1 = 1.7452 loss)
I1028 01:40:30.946557  9023 sgd_solver.cpp:105] Iteration 116920, lr = 0.00247388
I1028 01:41:07.513830  9023 solver.cpp:222] Iteration 116960 (1.09392 iter/s, 36.5659s/40 iters), loss = 1.50494
I1028 01:41:07.514026  9023 solver.cpp:241]     Train net output #0: loss = 1.50494 (* 1 = 1.50494 loss)
I1028 01:41:07.514042  9023 sgd_solver.cpp:105] Iteration 116960, lr = 0.00247164
I1028 01:41:37.879621  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_117000.caffemodel
I1028 01:41:37.930855  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_117000.solverstate
I1028 01:41:37.948076  9023 solver.cpp:334] Iteration 117000, Testing net (#0)
I1028 01:42:09.365046  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 01:42:09.573765  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5666
I1028 01:42:09.573827  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.800959
I1028 01:42:09.573842  9023 solver.cpp:401]     Test net output #2: loss = 1.92322 (* 1 = 1.92322 loss)
I1028 01:42:10.347630  9023 solver.cpp:222] Iteration 117000 (0.636626 iter/s, 62.8313s/40 iters), loss = 1.56213
I1028 01:42:10.347694  9023 solver.cpp:241]     Train net output #0: loss = 1.56213 (* 1 = 1.56213 loss)
I1028 01:42:10.347709  9023 sgd_solver.cpp:105] Iteration 117000, lr = 0.00246941
I1028 01:42:41.273353  9023 solver.cpp:222] Iteration 117040 (1.29347 iter/s, 30.9245s/40 iters), loss = 1.45786
I1028 01:42:41.273535  9023 solver.cpp:241]     Train net output #0: loss = 1.45786 (* 1 = 1.45786 loss)
I1028 01:42:41.273551  9023 sgd_solver.cpp:105] Iteration 117040, lr = 0.00246717
I1028 01:42:43.676271  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1028 01:43:12.078054  9023 solver.cpp:222] Iteration 117080 (1.29856 iter/s, 30.8034s/40 iters), loss = 1.92161
I1028 01:43:12.078250  9023 solver.cpp:241]     Train net output #0: loss = 1.92161 (* 1 = 1.92161 loss)
I1028 01:43:12.078266  9023 sgd_solver.cpp:105] Iteration 117080, lr = 0.00246493
I1028 01:43:43.216552  9023 solver.cpp:222] Iteration 117120 (1.28464 iter/s, 31.1371s/40 iters), loss = 2.06742
I1028 01:43:43.216737  9023 solver.cpp:241]     Train net output #0: loss = 2.06742 (* 1 = 2.06742 loss)
I1028 01:43:43.216754  9023 sgd_solver.cpp:105] Iteration 117120, lr = 0.0024627
I1028 01:44:14.154954  9023 solver.cpp:222] Iteration 117160 (1.29295 iter/s, 30.9371s/40 iters), loss = 1.69119
I1028 01:44:14.155279  9023 solver.cpp:241]     Train net output #0: loss = 1.69119 (* 1 = 1.69119 loss)
I1028 01:44:14.155331  9023 sgd_solver.cpp:105] Iteration 117160, lr = 0.00246046
I1028 01:44:45.770403  9023 solver.cpp:222] Iteration 117200 (1.26526 iter/s, 31.614s/40 iters), loss = 1.7409
I1028 01:44:45.770591  9023 solver.cpp:241]     Train net output #0: loss = 1.7409 (* 1 = 1.7409 loss)
I1028 01:44:45.770608  9023 sgd_solver.cpp:105] Iteration 117200, lr = 0.00245823
I1028 01:45:16.900346  9023 solver.cpp:222] Iteration 117240 (1.28499 iter/s, 31.1286s/40 iters), loss = 1.52099
I1028 01:45:16.900547  9023 solver.cpp:241]     Train net output #0: loss = 1.52099 (* 1 = 1.52099 loss)
I1028 01:45:16.900563  9023 sgd_solver.cpp:105] Iteration 117240, lr = 0.00245599
I1028 01:45:47.964800  9023 solver.cpp:222] Iteration 117280 (1.2877 iter/s, 31.0631s/40 iters), loss = 1.44005
I1028 01:45:47.964980  9023 solver.cpp:241]     Train net output #0: loss = 1.44005 (* 1 = 1.44005 loss)
I1028 01:45:47.964998  9023 sgd_solver.cpp:105] Iteration 117280, lr = 0.00245376
I1028 01:46:19.063598  9023 solver.cpp:222] Iteration 117320 (1.28628 iter/s, 31.0974s/40 iters), loss = 1.71833
I1028 01:46:19.063755  9023 solver.cpp:241]     Train net output #0: loss = 1.71833 (* 1 = 1.71833 loss)
I1028 01:46:19.063771  9023 sgd_solver.cpp:105] Iteration 117320, lr = 0.00245152
I1028 01:46:50.317728  9023 solver.cpp:222] Iteration 117360 (1.27989 iter/s, 31.2528s/40 iters), loss = 1.15924
I1028 01:46:50.317915  9023 solver.cpp:241]     Train net output #0: loss = 1.15924 (* 1 = 1.15924 loss)
I1028 01:46:50.317931  9023 sgd_solver.cpp:105] Iteration 117360, lr = 0.00244929
I1028 01:47:21.389766  9023 solver.cpp:222] Iteration 117400 (1.28739 iter/s, 31.0707s/40 iters), loss = 1.45878
I1028 01:47:21.389955  9023 solver.cpp:241]     Train net output #0: loss = 1.45878 (* 1 = 1.45878 loss)
I1028 01:47:21.389971  9023 sgd_solver.cpp:105] Iteration 117400, lr = 0.00244706
I1028 01:47:52.475534  9023 solver.cpp:222] Iteration 117440 (1.28682 iter/s, 31.0844s/40 iters), loss = 1.66067
I1028 01:47:52.475716  9023 solver.cpp:241]     Train net output #0: loss = 1.66067 (* 1 = 1.66067 loss)
I1028 01:47:52.475733  9023 sgd_solver.cpp:105] Iteration 117440, lr = 0.00244482
I1028 01:48:23.432664  9023 solver.cpp:222] Iteration 117480 (1.29217 iter/s, 30.9558s/40 iters), loss = 1.62398
I1028 01:48:23.432853  9023 solver.cpp:241]     Train net output #0: loss = 1.62398 (* 1 = 1.62398 loss)
I1028 01:48:23.432869  9023 sgd_solver.cpp:105] Iteration 117480, lr = 0.00244259
I1028 01:48:38.161905  9023 solver.cpp:334] Iteration 117500, Testing net (#0)
I1028 01:49:09.858161  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56576
I1028 01:49:09.858361  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79692
I1028 01:49:09.858376  9023 solver.cpp:401]     Test net output #2: loss = 1.93024 (* 1 = 1.93024 loss)
I1028 01:49:26.251888  9023 solver.cpp:222] Iteration 117520 (0.636774 iter/s, 62.8167s/40 iters), loss = 1.67651
I1028 01:49:26.251958  9023 solver.cpp:241]     Train net output #0: loss = 1.67651 (* 1 = 1.67651 loss)
I1028 01:49:26.251973  9023 sgd_solver.cpp:105] Iteration 117520, lr = 0.00244036
I1028 01:49:57.306356  9023 solver.cpp:222] Iteration 117560 (1.28811 iter/s, 31.0532s/40 iters), loss = 1.46728
I1028 01:49:57.306581  9023 solver.cpp:241]     Train net output #0: loss = 1.46728 (* 1 = 1.46728 loss)
I1028 01:49:57.306602  9023 sgd_solver.cpp:105] Iteration 117560, lr = 0.00243813
I1028 01:50:28.595089  9023 solver.cpp:222] Iteration 117600 (1.27847 iter/s, 31.2873s/40 iters), loss = 1.11393
I1028 01:50:28.595268  9023 solver.cpp:241]     Train net output #0: loss = 1.11393 (* 1 = 1.11393 loss)
I1028 01:50:28.595284  9023 sgd_solver.cpp:105] Iteration 117600, lr = 0.0024359
I1028 01:51:00.041358  9023 solver.cpp:222] Iteration 117640 (1.27207 iter/s, 31.4449s/40 iters), loss = 1.82412
I1028 01:51:00.041525  9023 solver.cpp:241]     Train net output #0: loss = 1.82412 (* 1 = 1.82412 loss)
I1028 01:51:00.041553  9023 sgd_solver.cpp:105] Iteration 117640, lr = 0.00243367
I1028 01:51:30.259261  9023 solver.cpp:222] Iteration 117680 (1.32378 iter/s, 30.2166s/40 iters), loss = 1.65249
I1028 01:51:30.259519  9023 solver.cpp:241]     Train net output #0: loss = 1.65249 (* 1 = 1.65249 loss)
I1028 01:51:30.259536  9023 sgd_solver.cpp:105] Iteration 117680, lr = 0.00243143
I1028 01:52:00.182612  9023 solver.cpp:222] Iteration 117720 (1.33681 iter/s, 29.922s/40 iters), loss = 1.42062
I1028 01:52:00.182680  9023 solver.cpp:241]     Train net output #0: loss = 1.42062 (* 1 = 1.42062 loss)
I1028 01:52:00.182695  9023 sgd_solver.cpp:105] Iteration 117720, lr = 0.0024292
I1028 01:52:30.231820  9023 solver.cpp:222] Iteration 117760 (1.3312 iter/s, 30.048s/40 iters), loss = 1.33389
I1028 01:52:30.232019  9023 solver.cpp:241]     Train net output #0: loss = 1.33389 (* 1 = 1.33389 loss)
I1028 01:52:30.232034  9023 sgd_solver.cpp:105] Iteration 117760, lr = 0.00242697
I1028 01:53:00.665882  9023 solver.cpp:222] Iteration 117800 (1.31438 iter/s, 30.4327s/40 iters), loss = 2.05864
I1028 01:53:00.666036  9023 solver.cpp:241]     Train net output #0: loss = 2.05864 (* 1 = 2.05864 loss)
I1028 01:53:00.666054  9023 sgd_solver.cpp:105] Iteration 117800, lr = 0.00242474
I1028 01:53:33.050370  9023 solver.cpp:222] Iteration 117840 (1.23521 iter/s, 32.3831s/40 iters), loss = 1.49584
I1028 01:53:33.050619  9023 solver.cpp:241]     Train net output #0: loss = 1.49584 (* 1 = 1.49584 loss)
I1028 01:53:33.050642  9023 sgd_solver.cpp:105] Iteration 117840, lr = 0.00242251
I1028 01:54:17.063009  9023 solver.cpp:222] Iteration 117880 (0.908869 iter/s, 44.0107s/40 iters), loss = 1.85603
I1028 01:54:17.063262  9023 solver.cpp:241]     Train net output #0: loss = 1.85603 (* 1 = 1.85603 loss)
I1028 01:54:17.063287  9023 sgd_solver.cpp:105] Iteration 117880, lr = 0.00242029
I1028 01:54:48.634743  9023 solver.cpp:222] Iteration 117920 (1.26701 iter/s, 31.5703s/40 iters), loss = 1.46264
I1028 01:54:48.634928  9023 solver.cpp:241]     Train net output #0: loss = 1.46264 (* 1 = 1.46264 loss)
I1028 01:54:48.634943  9023 sgd_solver.cpp:105] Iteration 117920, lr = 0.00241806
I1028 01:55:19.397656  9023 solver.cpp:222] Iteration 117960 (1.30032 iter/s, 30.7616s/40 iters), loss = 1.40054
I1028 01:55:19.397826  9023 solver.cpp:241]     Train net output #0: loss = 1.40054 (* 1 = 1.40054 loss)
I1028 01:55:19.397842  9023 sgd_solver.cpp:105] Iteration 117960, lr = 0.00241583
I1028 01:55:49.722721  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_118000.caffemodel
I1028 01:55:49.755543  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_118000.solverstate
I1028 01:55:49.773488  9023 solver.cpp:334] Iteration 118000, Testing net (#0)
I1028 01:56:20.888253  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 01:56:21.099067  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5644
I1028 01:56:21.099135  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.800439
I1028 01:56:21.099149  9023 solver.cpp:401]     Test net output #2: loss = 1.92793 (* 1 = 1.92793 loss)
I1028 01:56:21.875557  9023 solver.cpp:222] Iteration 118000 (0.640252 iter/s, 62.4754s/40 iters), loss = 1.47317
I1028 01:56:21.875622  9023 solver.cpp:241]     Train net output #0: loss = 1.47317 (* 1 = 1.47317 loss)
I1028 01:56:21.875636  9023 sgd_solver.cpp:105] Iteration 118000, lr = 0.0024136
I1028 01:56:52.953017  9023 solver.cpp:222] Iteration 118040 (1.28716 iter/s, 31.0762s/40 iters), loss = 1.40321
I1028 01:56:52.953188  9023 solver.cpp:241]     Train net output #0: loss = 1.40321 (* 1 = 1.40321 loss)
I1028 01:56:52.953204  9023 sgd_solver.cpp:105] Iteration 118040, lr = 0.00241137
I1028 01:57:23.783208  9023 solver.cpp:222] Iteration 118080 (1.29749 iter/s, 30.8289s/40 iters), loss = 1.68296
I1028 01:57:23.783398  9023 solver.cpp:241]     Train net output #0: loss = 1.68296 (* 1 = 1.68296 loss)
I1028 01:57:23.783429  9023 sgd_solver.cpp:105] Iteration 118080, lr = 0.00240914
I1028 01:57:56.782594  9023 solver.cpp:222] Iteration 118120 (1.2122 iter/s, 32.9979s/40 iters), loss = 1.28205
I1028 01:57:56.782897  9023 solver.cpp:241]     Train net output #0: loss = 1.28205 (* 1 = 1.28205 loss)
I1028 01:57:56.782922  9023 sgd_solver.cpp:105] Iteration 118120, lr = 0.00240692
I1028 01:58:28.742204  9023 solver.cpp:222] Iteration 118160 (1.25164 iter/s, 31.9581s/40 iters), loss = 1.64082
I1028 01:58:28.742411  9023 solver.cpp:241]     Train net output #0: loss = 1.64082 (* 1 = 1.64082 loss)
I1028 01:58:28.742429  9023 sgd_solver.cpp:105] Iteration 118160, lr = 0.00240469
I1028 01:59:04.610538  9023 solver.cpp:222] Iteration 118200 (1.11524 iter/s, 35.8668s/40 iters), loss = 1.49749
I1028 01:59:04.610786  9023 solver.cpp:241]     Train net output #0: loss = 1.49749 (* 1 = 1.49749 loss)
I1028 01:59:04.610808  9023 sgd_solver.cpp:105] Iteration 118200, lr = 0.00240246
I1028 01:59:35.967375  9023 solver.cpp:222] Iteration 118240 (1.2757 iter/s, 31.3554s/40 iters), loss = 1.41664
I1028 01:59:35.967551  9023 solver.cpp:241]     Train net output #0: loss = 1.41664 (* 1 = 1.41664 loss)
I1028 01:59:35.967567  9023 sgd_solver.cpp:105] Iteration 118240, lr = 0.00240024
I1028 02:00:07.037549  9023 solver.cpp:222] Iteration 118280 (1.28746 iter/s, 31.0688s/40 iters), loss = 1.57104
I1028 02:00:07.037742  9023 solver.cpp:241]     Train net output #0: loss = 1.57104 (* 1 = 1.57104 loss)
I1028 02:00:07.037758  9023 sgd_solver.cpp:105] Iteration 118280, lr = 0.00239801
I1028 02:00:37.846899  9023 solver.cpp:222] Iteration 118320 (1.29836 iter/s, 30.808s/40 iters), loss = 1.39587
I1028 02:00:37.847081  9023 solver.cpp:241]     Train net output #0: loss = 1.39587 (* 1 = 1.39587 loss)
I1028 02:00:37.847097  9023 sgd_solver.cpp:105] Iteration 118320, lr = 0.00239579
I1028 02:01:08.683269  9023 solver.cpp:222] Iteration 118360 (1.29723 iter/s, 30.835s/40 iters), loss = 1.48548
I1028 02:01:08.683471  9023 solver.cpp:241]     Train net output #0: loss = 1.48548 (* 1 = 1.48548 loss)
I1028 02:01:08.683488  9023 sgd_solver.cpp:105] Iteration 118360, lr = 0.00239356
I1028 02:01:39.580781  9023 solver.cpp:222] Iteration 118400 (1.29466 iter/s, 30.8961s/40 iters), loss = 1.33123
I1028 02:01:39.580976  9023 solver.cpp:241]     Train net output #0: loss = 1.33123 (* 1 = 1.33123 loss)
I1028 02:01:39.580992  9023 sgd_solver.cpp:105] Iteration 118400, lr = 0.00239134
I1028 02:02:10.733592  9023 solver.cpp:222] Iteration 118440 (1.28405 iter/s, 31.1514s/40 iters), loss = 1.50817
I1028 02:02:10.733798  9023 solver.cpp:241]     Train net output #0: loss = 1.50817 (* 1 = 1.50817 loss)
I1028 02:02:10.733815  9023 sgd_solver.cpp:105] Iteration 118440, lr = 0.00238911
I1028 02:02:50.676055  9023 solver.cpp:222] Iteration 118480 (1.00148 iter/s, 39.9408s/40 iters), loss = 1.30018
I1028 02:02:50.676285  9023 solver.cpp:241]     Train net output #0: loss = 1.30018 (* 1 = 1.30018 loss)
I1028 02:02:50.676314  9023 sgd_solver.cpp:105] Iteration 118480, lr = 0.00238689
I1028 02:03:05.852237  9023 solver.cpp:334] Iteration 118500, Testing net (#0)
I1028 02:03:37.088999  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5698
I1028 02:03:37.089179  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.797479
I1028 02:03:37.089193  9023 solver.cpp:401]     Test net output #2: loss = 1.90927 (* 1 = 1.90927 loss)
I1028 02:03:53.337124  9023 solver.cpp:222] Iteration 118520 (0.638381 iter/s, 62.6585s/40 iters), loss = 1.67304
I1028 02:03:53.337193  9023 solver.cpp:241]     Train net output #0: loss = 1.67304 (* 1 = 1.67304 loss)
I1028 02:03:53.337208  9023 sgd_solver.cpp:105] Iteration 118520, lr = 0.00238467
I1028 02:04:24.522809  9023 solver.cpp:222] Iteration 118560 (1.28269 iter/s, 31.1844s/40 iters), loss = 1.72693
I1028 02:04:24.523007  9023 solver.cpp:241]     Train net output #0: loss = 1.72693 (* 1 = 1.72693 loss)
I1028 02:04:24.523023  9023 sgd_solver.cpp:105] Iteration 118560, lr = 0.00238244
I1028 02:04:55.708734  9023 solver.cpp:222] Iteration 118600 (1.28269 iter/s, 31.1845s/40 iters), loss = 1.54102
I1028 02:04:55.708988  9023 solver.cpp:241]     Train net output #0: loss = 1.54102 (* 1 = 1.54102 loss)
I1028 02:04:55.709005  9023 sgd_solver.cpp:105] Iteration 118600, lr = 0.00238022
I1028 02:05:26.414685  9023 solver.cpp:222] Iteration 118640 (1.30274 iter/s, 30.7045s/40 iters), loss = 1.58894
I1028 02:05:26.414870  9023 solver.cpp:241]     Train net output #0: loss = 1.58894 (* 1 = 1.58894 loss)
I1028 02:05:26.414887  9023 sgd_solver.cpp:105] Iteration 118640, lr = 0.002378
I1028 02:05:57.244040  9023 solver.cpp:222] Iteration 118680 (1.29752 iter/s, 30.828s/40 iters), loss = 1.33084
I1028 02:05:57.244222  9023 solver.cpp:241]     Train net output #0: loss = 1.33084 (* 1 = 1.33084 loss)
I1028 02:05:57.244238  9023 sgd_solver.cpp:105] Iteration 118680, lr = 0.00237577
I1028 02:06:27.892696  9023 solver.cpp:222] Iteration 118720 (1.30517 iter/s, 30.6473s/40 iters), loss = 1.55772
I1028 02:06:27.892863  9023 solver.cpp:241]     Train net output #0: loss = 1.55772 (* 1 = 1.55772 loss)
I1028 02:06:27.892879  9023 sgd_solver.cpp:105] Iteration 118720, lr = 0.00237355
I1028 02:06:58.525249  9023 solver.cpp:222] Iteration 118760 (1.30586 iter/s, 30.6312s/40 iters), loss = 1.31215
I1028 02:06:58.525414  9023 solver.cpp:241]     Train net output #0: loss = 1.31215 (* 1 = 1.31215 loss)
I1028 02:06:58.525430  9023 sgd_solver.cpp:105] Iteration 118760, lr = 0.00237133
I1028 02:07:29.252694  9023 solver.cpp:222] Iteration 118800 (1.30182 iter/s, 30.7261s/40 iters), loss = 1.70838
I1028 02:07:29.252866  9023 solver.cpp:241]     Train net output #0: loss = 1.70838 (* 1 = 1.70838 loss)
I1028 02:07:29.252882  9023 sgd_solver.cpp:105] Iteration 118800, lr = 0.00236911
I1028 02:08:00.373921  9023 solver.cpp:222] Iteration 118840 (1.28535 iter/s, 31.1199s/40 iters), loss = 1.90572
I1028 02:08:00.374094  9023 solver.cpp:241]     Train net output #0: loss = 1.90572 (* 1 = 1.90572 loss)
I1028 02:08:00.374110  9023 sgd_solver.cpp:105] Iteration 118840, lr = 0.00236689
I1028 02:08:31.315179  9023 solver.cpp:222] Iteration 118880 (1.29283 iter/s, 30.9399s/40 iters), loss = 1.41312
I1028 02:08:31.315367  9023 solver.cpp:241]     Train net output #0: loss = 1.41312 (* 1 = 1.41312 loss)
I1028 02:08:31.315383  9023 sgd_solver.cpp:105] Iteration 118880, lr = 0.00236467
I1028 02:09:02.246649  9023 solver.cpp:222] Iteration 118920 (1.29324 iter/s, 30.9301s/40 iters), loss = 1.90745
I1028 02:09:02.246837  9023 solver.cpp:241]     Train net output #0: loss = 1.90745 (* 1 = 1.90745 loss)
I1028 02:09:02.246855  9023 sgd_solver.cpp:105] Iteration 118920, lr = 0.00236245
I1028 02:09:33.239819  9023 solver.cpp:222] Iteration 118960 (1.29066 iter/s, 30.9918s/40 iters), loss = 1.53369
I1028 02:09:33.239977  9023 solver.cpp:241]     Train net output #0: loss = 1.53369 (* 1 = 1.53369 loss)
I1028 02:09:33.239994  9023 sgd_solver.cpp:105] Iteration 118960, lr = 0.00236023
I1028 02:10:03.475849  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_119000.caffemodel
I1028 02:10:03.512326  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_119000.solverstate
I1028 02:10:03.534232  9023 solver.cpp:334] Iteration 119000, Testing net (#0)
I1028 02:10:34.997828  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 02:10:35.210472  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56384
I1028 02:10:35.210535  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.797719
I1028 02:10:35.210548  9023 solver.cpp:401]     Test net output #2: loss = 1.92371 (* 1 = 1.92371 loss)
I1028 02:10:35.981956  9023 solver.cpp:222] Iteration 119000 (0.637556 iter/s, 62.7396s/40 iters), loss = 1.90178
I1028 02:10:35.982023  9023 solver.cpp:241]     Train net output #0: loss = 1.90178 (* 1 = 1.90178 loss)
I1028 02:10:35.982038  9023 sgd_solver.cpp:105] Iteration 119000, lr = 0.00235801
I1028 02:11:06.771543  9023 solver.cpp:222] Iteration 119040 (1.29919 iter/s, 30.7884s/40 iters), loss = 1.78722
I1028 02:11:06.771819  9023 solver.cpp:241]     Train net output #0: loss = 1.78722 (* 1 = 1.78722 loss)
I1028 02:11:06.771837  9023 sgd_solver.cpp:105] Iteration 119040, lr = 0.00235579
I1028 02:11:37.714514  9023 solver.cpp:222] Iteration 119080 (1.29276 iter/s, 30.9415s/40 iters), loss = 1.40846
I1028 02:11:37.714721  9023 solver.cpp:241]     Train net output #0: loss = 1.40846 (* 1 = 1.40846 loss)
I1028 02:11:37.714737  9023 sgd_solver.cpp:105] Iteration 119080, lr = 0.00235357
I1028 02:12:08.539286  9023 solver.cpp:222] Iteration 119120 (1.29772 iter/s, 30.8234s/40 iters), loss = 1.74304
I1028 02:12:08.539471  9023 solver.cpp:241]     Train net output #0: loss = 1.74304 (* 1 = 1.74304 loss)
I1028 02:12:08.539486  9023 sgd_solver.cpp:105] Iteration 119120, lr = 0.00235135
I1028 02:12:39.144101  9023 solver.cpp:222] Iteration 119160 (1.30704 iter/s, 30.6035s/40 iters), loss = 1.589
I1028 02:12:39.144276  9023 solver.cpp:241]     Train net output #0: loss = 1.589 (* 1 = 1.589 loss)
I1028 02:12:39.144291  9023 sgd_solver.cpp:105] Iteration 119160, lr = 0.00234913
I1028 02:13:09.891554  9023 solver.cpp:222] Iteration 119200 (1.30098 iter/s, 30.7461s/40 iters), loss = 1.52983
I1028 02:13:09.891757  9023 solver.cpp:241]     Train net output #0: loss = 1.52983 (* 1 = 1.52983 loss)
I1028 02:13:09.891773  9023 sgd_solver.cpp:105] Iteration 119200, lr = 0.00234692
I1028 02:13:40.728857  9023 solver.cpp:222] Iteration 119240 (1.29719 iter/s, 30.8359s/40 iters), loss = 1.69933
I1028 02:13:40.729053  9023 solver.cpp:241]     Train net output #0: loss = 1.69933 (* 1 = 1.69933 loss)
I1028 02:13:40.729074  9023 sgd_solver.cpp:105] Iteration 119240, lr = 0.0023447
I1028 02:14:11.454078  9023 solver.cpp:222] Iteration 119280 (1.30192 iter/s, 30.7239s/40 iters), loss = 1.15377
I1028 02:14:11.454257  9023 solver.cpp:241]     Train net output #0: loss = 1.15377 (* 1 = 1.15377 loss)
I1028 02:14:11.454273  9023 sgd_solver.cpp:105] Iteration 119280, lr = 0.00234248
I1028 02:14:42.167156  9023 solver.cpp:222] Iteration 119320 (1.30243 iter/s, 30.7117s/40 iters), loss = 1.33209
I1028 02:14:42.167340  9023 solver.cpp:241]     Train net output #0: loss = 1.33209 (* 1 = 1.33209 loss)
I1028 02:14:42.167357  9023 sgd_solver.cpp:105] Iteration 119320, lr = 0.00234027
I1028 02:15:13.054915  9023 solver.cpp:222] Iteration 119360 (1.29507 iter/s, 30.8864s/40 iters), loss = 1.66103
I1028 02:15:13.055086  9023 solver.cpp:241]     Train net output #0: loss = 1.66103 (* 1 = 1.66103 loss)
I1028 02:15:13.055102  9023 sgd_solver.cpp:105] Iteration 119360, lr = 0.00233805
I1028 02:15:43.709455  9023 solver.cpp:222] Iteration 119400 (1.30492 iter/s, 30.6532s/40 iters), loss = 1.72606
I1028 02:15:43.709626  9023 solver.cpp:241]     Train net output #0: loss = 1.72606 (* 1 = 1.72606 loss)
I1028 02:15:43.709642  9023 sgd_solver.cpp:105] Iteration 119400, lr = 0.00233583
I1028 02:16:14.570057  9023 solver.cpp:222] Iteration 119440 (1.29621 iter/s, 30.8593s/40 iters), loss = 1.53497
I1028 02:16:14.570232  9023 solver.cpp:241]     Train net output #0: loss = 1.53497 (* 1 = 1.53497 loss)
I1028 02:16:14.570248  9023 sgd_solver.cpp:105] Iteration 119440, lr = 0.00233362
I1028 02:16:45.307843  9023 solver.cpp:222] Iteration 119480 (1.30139 iter/s, 30.7364s/40 iters), loss = 1.80145
I1028 02:16:45.308014  9023 solver.cpp:241]     Train net output #0: loss = 1.80145 (* 1 = 1.80145 loss)
I1028 02:16:45.308029  9023 sgd_solver.cpp:105] Iteration 119480, lr = 0.0023314
I1028 02:16:59.882148  9023 solver.cpp:334] Iteration 119500, Testing net (#0)
I1028 02:17:31.587828  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5678
I1028 02:17:31.588016  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.799719
I1028 02:17:31.588030  9023 solver.cpp:401]     Test net output #2: loss = 1.90447 (* 1 = 1.90447 loss)
I1028 02:17:47.946460  9023 solver.cpp:222] Iteration 119520 (0.638609 iter/s, 62.6361s/40 iters), loss = 1.64052
I1028 02:17:47.946540  9023 solver.cpp:241]     Train net output #0: loss = 1.64052 (* 1 = 1.64052 loss)
I1028 02:17:47.947116  9023 sgd_solver.cpp:105] Iteration 119520, lr = 0.00232919
I1028 02:18:08.047240  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1028 02:18:18.778074  9023 solver.cpp:222] Iteration 119560 (1.29742 iter/s, 30.8304s/40 iters), loss = 1.25263
I1028 02:18:18.778144  9023 solver.cpp:241]     Train net output #0: loss = 1.25263 (* 1 = 1.25263 loss)
I1028 02:18:18.778161  9023 sgd_solver.cpp:105] Iteration 119560, lr = 0.00232697
I1028 02:18:49.616006  9023 solver.cpp:222] Iteration 119600 (1.29716 iter/s, 30.8367s/40 iters), loss = 1.38883
I1028 02:18:49.616194  9023 solver.cpp:241]     Train net output #0: loss = 1.38883 (* 1 = 1.38883 loss)
I1028 02:18:49.616211  9023 sgd_solver.cpp:105] Iteration 119600, lr = 0.00232476
I1028 02:19:20.595484  9023 solver.cpp:222] Iteration 119640 (1.29123 iter/s, 30.9781s/40 iters), loss = 1.79633
I1028 02:19:20.595662  9023 solver.cpp:241]     Train net output #0: loss = 1.79633 (* 1 = 1.79633 loss)
I1028 02:19:20.596101  9023 sgd_solver.cpp:105] Iteration 119640, lr = 0.00232255
I1028 02:19:51.384445  9023 solver.cpp:222] Iteration 119680 (1.29922 iter/s, 30.7876s/40 iters), loss = 1.26161
I1028 02:19:51.384604  9023 solver.cpp:241]     Train net output #0: loss = 1.26161 (* 1 = 1.26161 loss)
I1028 02:19:51.384620  9023 sgd_solver.cpp:105] Iteration 119680, lr = 0.00232033
I1028 02:20:22.197288  9023 solver.cpp:222] Iteration 119720 (1.29822 iter/s, 30.8115s/40 iters), loss = 1.60734
I1028 02:20:22.197473  9023 solver.cpp:241]     Train net output #0: loss = 1.60734 (* 1 = 1.60734 loss)
I1028 02:20:22.197489  9023 sgd_solver.cpp:105] Iteration 119720, lr = 0.00231812
I1028 02:20:53.128134  9023 solver.cpp:222] Iteration 119760 (1.29326 iter/s, 30.9295s/40 iters), loss = 1.85285
I1028 02:20:53.128330  9023 solver.cpp:241]     Train net output #0: loss = 1.85285 (* 1 = 1.85285 loss)
I1028 02:20:53.128346  9023 sgd_solver.cpp:105] Iteration 119760, lr = 0.00231591
I1028 02:21:23.797762  9023 solver.cpp:222] Iteration 119800 (1.30428 iter/s, 30.6683s/40 iters), loss = 1.10323
I1028 02:21:23.797968  9023 solver.cpp:241]     Train net output #0: loss = 1.10323 (* 1 = 1.10323 loss)
I1028 02:21:23.797984  9023 sgd_solver.cpp:105] Iteration 119800, lr = 0.00231369
I1028 02:21:54.513283  9023 solver.cpp:222] Iteration 119840 (1.30233 iter/s, 30.7142s/40 iters), loss = 1.66528
I1028 02:21:54.513464  9023 solver.cpp:241]     Train net output #0: loss = 1.66528 (* 1 = 1.66528 loss)
I1028 02:21:54.513479  9023 sgd_solver.cpp:105] Iteration 119840, lr = 0.00231148
I1028 02:22:25.196970  9023 solver.cpp:222] Iteration 119880 (1.30368 iter/s, 30.6823s/40 iters), loss = 1.63935
I1028 02:22:25.197141  9023 solver.cpp:241]     Train net output #0: loss = 1.63935 (* 1 = 1.63935 loss)
I1028 02:22:25.197156  9023 sgd_solver.cpp:105] Iteration 119880, lr = 0.00230927
I1028 02:22:56.040594  9023 solver.cpp:222] Iteration 119920 (1.29692 iter/s, 30.8423s/40 iters), loss = 1.44933
I1028 02:22:56.040782  9023 solver.cpp:241]     Train net output #0: loss = 1.44933 (* 1 = 1.44933 loss)
I1028 02:22:56.040798  9023 sgd_solver.cpp:105] Iteration 119920, lr = 0.00230706
I1028 02:23:27.133543  9023 solver.cpp:222] Iteration 119960 (1.28652 iter/s, 31.0916s/40 iters), loss = 1.84193
I1028 02:23:27.133718  9023 solver.cpp:241]     Train net output #0: loss = 1.84193 (* 1 = 1.84193 loss)
I1028 02:23:27.133733  9023 sgd_solver.cpp:105] Iteration 119960, lr = 0.00230485
I1028 02:23:58.731684  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_120000.caffemodel
I1028 02:23:58.773242  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_120000.solverstate
I1028 02:23:58.804368  9023 solver.cpp:334] Iteration 120000, Testing net (#0)
I1028 02:24:30.553494  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 02:24:30.765225  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56748
I1028 02:24:30.765286  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80048
I1028 02:24:30.765317  9023 solver.cpp:401]     Test net output #2: loss = 1.92315 (* 1 = 1.92315 loss)
I1028 02:24:31.543239  9023 solver.cpp:222] Iteration 120000 (0.62105 iter/s, 64.4071s/40 iters), loss = 1.16284
I1028 02:24:31.543313  9023 solver.cpp:241]     Train net output #0: loss = 1.16284 (* 1 = 1.16284 loss)
I1028 02:24:31.543329  9023 sgd_solver.cpp:105] Iteration 120000, lr = 0.00230264
I1028 02:25:02.456038  9023 solver.cpp:222] Iteration 120040 (1.29401 iter/s, 30.9116s/40 iters), loss = 1.61804
I1028 02:25:02.456306  9023 solver.cpp:241]     Train net output #0: loss = 1.61804 (* 1 = 1.61804 loss)
I1028 02:25:02.456324  9023 sgd_solver.cpp:105] Iteration 120040, lr = 0.00230043
I1028 02:25:33.698001  9023 solver.cpp:222] Iteration 120080 (1.28039 iter/s, 31.2405s/40 iters), loss = 1.49934
I1028 02:25:33.698199  9023 solver.cpp:241]     Train net output #0: loss = 1.49934 (* 1 = 1.49934 loss)
I1028 02:25:33.698215  9023 sgd_solver.cpp:105] Iteration 120080, lr = 0.00229822
I1028 02:26:05.517036  9023 solver.cpp:222] Iteration 120120 (1.25716 iter/s, 31.8176s/40 iters), loss = 1.44906
I1028 02:26:05.517262  9023 solver.cpp:241]     Train net output #0: loss = 1.44906 (* 1 = 1.44906 loss)
I1028 02:26:05.517287  9023 sgd_solver.cpp:105] Iteration 120120, lr = 0.00229601
I1028 02:26:41.148623  9023 solver.cpp:222] Iteration 120160 (1.12265 iter/s, 35.63s/40 iters), loss = 1.58421
I1028 02:26:41.148823  9023 solver.cpp:241]     Train net output #0: loss = 1.58421 (* 1 = 1.58421 loss)
I1028 02:26:41.148838  9023 sgd_solver.cpp:105] Iteration 120160, lr = 0.0022938
I1028 02:27:35.694016  9023 solver.cpp:222] Iteration 120200 (0.733365 iter/s, 54.5431s/40 iters), loss = 1.33954
I1028 02:27:35.694259  9023 solver.cpp:241]     Train net output #0: loss = 1.33954 (* 1 = 1.33954 loss)
I1028 02:27:35.694288  9023 sgd_solver.cpp:105] Iteration 120200, lr = 0.00229159
I1028 02:28:07.052073  9023 solver.cpp:222] Iteration 120240 (1.27565 iter/s, 31.3566s/40 iters), loss = 1.33998
I1028 02:28:07.052237  9023 solver.cpp:241]     Train net output #0: loss = 1.33998 (* 1 = 1.33998 loss)
I1028 02:28:07.052697  9023 sgd_solver.cpp:105] Iteration 120240, lr = 0.00228938
I1028 02:28:40.039137  9023 solver.cpp:222] Iteration 120280 (1.21265 iter/s, 32.9857s/40 iters), loss = 1.69453
I1028 02:28:40.039494  9023 solver.cpp:241]     Train net output #0: loss = 1.69453 (* 1 = 1.69453 loss)
I1028 02:28:40.039525  9023 sgd_solver.cpp:105] Iteration 120280, lr = 0.00228717
I1028 02:29:13.668085  9023 solver.cpp:222] Iteration 120320 (1.18951 iter/s, 33.6273s/40 iters), loss = 1.65668
I1028 02:29:13.668308  9023 solver.cpp:241]     Train net output #0: loss = 1.65668 (* 1 = 1.65668 loss)
I1028 02:29:13.668325  9023 sgd_solver.cpp:105] Iteration 120320, lr = 0.00228496
I1028 02:29:46.436967  9023 solver.cpp:222] Iteration 120360 (1.22073 iter/s, 32.7674s/40 iters), loss = 1.52217
I1028 02:29:46.437211  9023 solver.cpp:241]     Train net output #0: loss = 1.52217 (* 1 = 1.52217 loss)
I1028 02:29:46.437235  9023 sgd_solver.cpp:105] Iteration 120360, lr = 0.00228276
I1028 02:30:23.209712  9023 solver.cpp:222] Iteration 120400 (1.08781 iter/s, 36.7711s/40 iters), loss = 1.45067
I1028 02:30:23.209978  9023 solver.cpp:241]     Train net output #0: loss = 1.45067 (* 1 = 1.45067 loss)
I1028 02:30:23.210005  9023 sgd_solver.cpp:105] Iteration 120400, lr = 0.00228055
I1028 02:30:54.475582  9023 solver.cpp:222] Iteration 120440 (1.27941 iter/s, 31.2644s/40 iters), loss = 1.51714
I1028 02:30:54.475831  9023 solver.cpp:241]     Train net output #0: loss = 1.51714 (* 1 = 1.51714 loss)
I1028 02:30:54.475847  9023 sgd_solver.cpp:105] Iteration 120440, lr = 0.00227834
I1028 02:31:25.711946  9023 solver.cpp:222] Iteration 120480 (1.28062 iter/s, 31.2349s/40 iters), loss = 1.63787
I1028 02:31:25.712139  9023 solver.cpp:241]     Train net output #0: loss = 1.63787 (* 1 = 1.63787 loss)
I1028 02:31:25.712155  9023 sgd_solver.cpp:105] Iteration 120480, lr = 0.00227613
I1028 02:31:40.376447  9023 solver.cpp:334] Iteration 120500, Testing net (#0)
I1028 02:32:11.615221  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5694
I1028 02:32:11.615494  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.797999
I1028 02:32:11.615510  9023 solver.cpp:401]     Test net output #2: loss = 1.92752 (* 1 = 1.92752 loss)
I1028 02:32:28.087963  9023 solver.cpp:222] Iteration 120520 (0.641298 iter/s, 62.3735s/40 iters), loss = 1.3219
I1028 02:32:28.088032  9023 solver.cpp:241]     Train net output #0: loss = 1.3219 (* 1 = 1.3219 loss)
I1028 02:32:28.088047  9023 sgd_solver.cpp:105] Iteration 120520, lr = 0.00227393
I1028 02:32:59.703578  9023 solver.cpp:222] Iteration 120560 (1.26525 iter/s, 31.6143s/40 iters), loss = 1.57108
I1028 02:32:59.703773  9023 solver.cpp:241]     Train net output #0: loss = 1.57108 (* 1 = 1.57108 loss)
I1028 02:32:59.703788  9023 sgd_solver.cpp:105] Iteration 120560, lr = 0.00227172
I1028 02:33:32.205113  9023 solver.cpp:222] Iteration 120600 (1.23076 iter/s, 32.5001s/40 iters), loss = 1.44737
I1028 02:33:32.205389  9023 solver.cpp:241]     Train net output #0: loss = 1.44737 (* 1 = 1.44737 loss)
I1028 02:33:32.205415  9023 sgd_solver.cpp:105] Iteration 120600, lr = 0.00226952
I1028 02:34:03.549473  9023 solver.cpp:222] Iteration 120640 (1.27621 iter/s, 31.3429s/40 iters), loss = 1.5579
I1028 02:34:03.549679  9023 solver.cpp:241]     Train net output #0: loss = 1.5579 (* 1 = 1.5579 loss)
I1028 02:34:03.549695  9023 sgd_solver.cpp:105] Iteration 120640, lr = 0.00226731
I1028 02:34:34.502691  9023 solver.cpp:222] Iteration 120680 (1.29233 iter/s, 30.9518s/40 iters), loss = 1.51182
I1028 02:34:34.502892  9023 solver.cpp:241]     Train net output #0: loss = 1.51182 (* 1 = 1.51182 loss)
I1028 02:34:34.502907  9023 sgd_solver.cpp:105] Iteration 120680, lr = 0.00226511
I1028 02:35:05.375625  9023 solver.cpp:222] Iteration 120720 (1.29569 iter/s, 30.8716s/40 iters), loss = 1.50971
I1028 02:35:05.375818  9023 solver.cpp:241]     Train net output #0: loss = 1.50971 (* 1 = 1.50971 loss)
I1028 02:35:05.375835  9023 sgd_solver.cpp:105] Iteration 120720, lr = 0.0022629
I1028 02:35:36.262251  9023 solver.cpp:222] Iteration 120760 (1.29512 iter/s, 30.8853s/40 iters), loss = 1.4463
I1028 02:35:36.262461  9023 solver.cpp:241]     Train net output #0: loss = 1.4463 (* 1 = 1.4463 loss)
I1028 02:35:36.262478  9023 sgd_solver.cpp:105] Iteration 120760, lr = 0.0022607
I1028 02:36:06.971627  9023 solver.cpp:222] Iteration 120800 (1.30259 iter/s, 30.708s/40 iters), loss = 1.64512
I1028 02:36:06.971846  9023 solver.cpp:241]     Train net output #0: loss = 1.64512 (* 1 = 1.64512 loss)
I1028 02:36:06.971865  9023 sgd_solver.cpp:105] Iteration 120800, lr = 0.0022585
I1028 02:36:37.523385  9023 solver.cpp:222] Iteration 120840 (1.30931 iter/s, 30.5504s/40 iters), loss = 1.38846
I1028 02:36:37.523538  9023 solver.cpp:241]     Train net output #0: loss = 1.38846 (* 1 = 1.38846 loss)
I1028 02:36:37.523557  9023 sgd_solver.cpp:105] Iteration 120840, lr = 0.00225629
I1028 02:37:08.203163  9023 solver.cpp:222] Iteration 120880 (1.30385 iter/s, 30.6785s/40 iters), loss = 1.63523
I1028 02:37:08.203344  9023 solver.cpp:241]     Train net output #0: loss = 1.63523 (* 1 = 1.63523 loss)
I1028 02:37:08.203363  9023 sgd_solver.cpp:105] Iteration 120880, lr = 0.00225409
I1028 02:37:39.812503  9023 solver.cpp:222] Iteration 120920 (1.2655 iter/s, 31.608s/40 iters), loss = 1.85501
I1028 02:37:39.812711  9023 solver.cpp:241]     Train net output #0: loss = 1.85501 (* 1 = 1.85501 loss)
I1028 02:37:39.812726  9023 sgd_solver.cpp:105] Iteration 120920, lr = 0.00225189
I1028 02:38:10.503450  9023 solver.cpp:222] Iteration 120960 (1.30337 iter/s, 30.6896s/40 iters), loss = 1.45335
I1028 02:38:10.503620  9023 solver.cpp:241]     Train net output #0: loss = 1.45335 (* 1 = 1.45335 loss)
I1028 02:38:10.503636  9023 sgd_solver.cpp:105] Iteration 120960, lr = 0.00224969
I1028 02:38:40.239768  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_121000.caffemodel
I1028 02:38:40.272263  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_121000.solverstate
I1028 02:38:40.289266  9023 solver.cpp:334] Iteration 121000, Testing net (#0)
I1028 02:39:11.453897  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 02:39:11.665618  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56448
I1028 02:39:11.665683  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79968
I1028 02:39:11.665696  9023 solver.cpp:401]     Test net output #2: loss = 1.91828 (* 1 = 1.91828 loss)
I1028 02:39:12.429422  9023 solver.cpp:222] Iteration 121000 (0.645958 iter/s, 61.9235s/40 iters), loss = 1.5731
I1028 02:39:12.429486  9023 solver.cpp:241]     Train net output #0: loss = 1.5731 (* 1 = 1.5731 loss)
I1028 02:39:12.429502  9023 sgd_solver.cpp:105] Iteration 121000, lr = 0.00224748
I1028 02:39:43.631649  9023 solver.cpp:222] Iteration 121040 (1.28201 iter/s, 31.201s/40 iters), loss = 1.38303
I1028 02:39:43.631837  9023 solver.cpp:241]     Train net output #0: loss = 1.38303 (* 1 = 1.38303 loss)
I1028 02:39:43.631855  9023 sgd_solver.cpp:105] Iteration 121040, lr = 0.00224528
I1028 02:40:14.205349  9023 solver.cpp:222] Iteration 121080 (1.30837 iter/s, 30.5724s/40 iters), loss = 1.45311
I1028 02:40:14.205529  9023 solver.cpp:241]     Train net output #0: loss = 1.45311 (* 1 = 1.45311 loss)
I1028 02:40:14.205545  9023 sgd_solver.cpp:105] Iteration 121080, lr = 0.00224308
I1028 02:40:44.845495  9023 solver.cpp:222] Iteration 121120 (1.30553 iter/s, 30.6388s/40 iters), loss = 1.40767
I1028 02:40:44.845690  9023 solver.cpp:241]     Train net output #0: loss = 1.40767 (* 1 = 1.40767 loss)
I1028 02:40:44.845707  9023 sgd_solver.cpp:105] Iteration 121120, lr = 0.00224088
I1028 02:41:16.106701  9023 solver.cpp:222] Iteration 121160 (1.2796 iter/s, 31.2598s/40 iters), loss = 1.54912
I1028 02:41:16.106905  9023 solver.cpp:241]     Train net output #0: loss = 1.54912 (* 1 = 1.54912 loss)
I1028 02:41:16.106923  9023 sgd_solver.cpp:105] Iteration 121160, lr = 0.00223868
I1028 02:41:46.868386  9023 solver.cpp:222] Iteration 121200 (1.30038 iter/s, 30.7603s/40 iters), loss = 1.40345
I1028 02:41:46.868584  9023 solver.cpp:241]     Train net output #0: loss = 1.40345 (* 1 = 1.40345 loss)
I1028 02:41:46.868600  9023 sgd_solver.cpp:105] Iteration 121200, lr = 0.00223648
I1028 02:42:17.507690  9023 solver.cpp:222] Iteration 121240 (1.30557 iter/s, 30.638s/40 iters), loss = 1.6438
I1028 02:42:17.507838  9023 solver.cpp:241]     Train net output #0: loss = 1.6438 (* 1 = 1.6438 loss)
I1028 02:42:17.507854  9023 sgd_solver.cpp:105] Iteration 121240, lr = 0.00223428
I1028 02:42:48.129683  9023 solver.cpp:222] Iteration 121280 (1.30631 iter/s, 30.6207s/40 iters), loss = 1.55258
I1028 02:42:48.129850  9023 solver.cpp:241]     Train net output #0: loss = 1.55258 (* 1 = 1.55258 loss)
I1028 02:42:48.129865  9023 sgd_solver.cpp:105] Iteration 121280, lr = 0.00223208
I1028 02:43:19.283790  9023 solver.cpp:222] Iteration 121320 (1.284 iter/s, 31.1528s/40 iters), loss = 1.67596
I1028 02:43:19.283968  9023 solver.cpp:241]     Train net output #0: loss = 1.67596 (* 1 = 1.67596 loss)
I1028 02:43:19.283984  9023 sgd_solver.cpp:105] Iteration 121320, lr = 0.00222988
I1028 02:43:50.093928  9023 solver.cpp:222] Iteration 121360 (1.29833 iter/s, 30.8088s/40 iters), loss = 1.49235
I1028 02:43:50.094100  9023 solver.cpp:241]     Train net output #0: loss = 1.49235 (* 1 = 1.49235 loss)
I1028 02:43:50.094125  9023 sgd_solver.cpp:105] Iteration 121360, lr = 0.00222768
I1028 02:44:21.913108  9023 solver.cpp:222] Iteration 121400 (1.25716 iter/s, 31.8178s/40 iters), loss = 1.36797
I1028 02:44:21.913311  9023 solver.cpp:241]     Train net output #0: loss = 1.36797 (* 1 = 1.36797 loss)
I1028 02:44:21.913328  9023 sgd_solver.cpp:105] Iteration 121400, lr = 0.00222549
I1028 02:44:53.383496  9023 solver.cpp:222] Iteration 121440 (1.27109 iter/s, 31.469s/40 iters), loss = 1.43734
I1028 02:44:53.383693  9023 solver.cpp:241]     Train net output #0: loss = 1.43734 (* 1 = 1.43734 loss)
I1028 02:44:53.383709  9023 sgd_solver.cpp:105] Iteration 121440, lr = 0.00222329
I1028 02:45:24.186974  9023 solver.cpp:222] Iteration 121480 (1.29861 iter/s, 30.8021s/40 iters), loss = 1.41153
I1028 02:45:24.187193  9023 solver.cpp:241]     Train net output #0: loss = 1.41153 (* 1 = 1.41153 loss)
I1028 02:45:24.187209  9023 sgd_solver.cpp:105] Iteration 121480, lr = 0.00222109
I1028 02:45:38.700857  9023 solver.cpp:334] Iteration 121500, Testing net (#0)
I1028 02:46:10.180016  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57064
I1028 02:46:10.180212  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8004
I1028 02:46:10.180227  9023 solver.cpp:401]     Test net output #2: loss = 1.89585 (* 1 = 1.89585 loss)
I1028 02:46:26.255681  9023 solver.cpp:222] Iteration 121520 (0.644473 iter/s, 62.0662s/40 iters), loss = 1.54413
I1028 02:46:26.255755  9023 solver.cpp:241]     Train net output #0: loss = 1.54413 (* 1 = 1.54413 loss)
I1028 02:46:26.255770  9023 sgd_solver.cpp:105] Iteration 121520, lr = 0.00221889
I1028 02:46:57.694250  9023 solver.cpp:222] Iteration 121560 (1.27237 iter/s, 31.4373s/40 iters), loss = 1.59305
I1028 02:46:57.694448  9023 solver.cpp:241]     Train net output #0: loss = 1.59305 (* 1 = 1.59305 loss)
I1028 02:46:57.694464  9023 sgd_solver.cpp:105] Iteration 121560, lr = 0.0022167
I1028 02:47:28.561974  9023 solver.cpp:222] Iteration 121600 (1.29591 iter/s, 30.8664s/40 iters), loss = 1.32055
I1028 02:47:28.562147  9023 solver.cpp:241]     Train net output #0: loss = 1.32055 (* 1 = 1.32055 loss)
I1028 02:47:28.562163  9023 sgd_solver.cpp:105] Iteration 121600, lr = 0.0022145
I1028 02:48:00.176151  9023 solver.cpp:222] Iteration 121640 (1.26531 iter/s, 31.6128s/40 iters), loss = 1.44046
I1028 02:48:00.176343  9023 solver.cpp:241]     Train net output #0: loss = 1.44046 (* 1 = 1.44046 loss)
I1028 02:48:00.176359  9023 sgd_solver.cpp:105] Iteration 121640, lr = 0.0022123
I1028 02:48:31.291749  9023 solver.cpp:222] Iteration 121680 (1.28559 iter/s, 31.1142s/40 iters), loss = 1.46475
I1028 02:48:31.291914  9023 solver.cpp:241]     Train net output #0: loss = 1.46475 (* 1 = 1.46475 loss)
I1028 02:48:31.291932  9023 sgd_solver.cpp:105] Iteration 121680, lr = 0.00221011
I1028 02:49:02.560158  9023 solver.cpp:222] Iteration 121720 (1.2793 iter/s, 31.2671s/40 iters), loss = 1.57492
I1028 02:49:02.561065  9023 solver.cpp:241]     Train net output #0: loss = 1.57492 (* 1 = 1.57492 loss)
I1028 02:49:02.561084  9023 sgd_solver.cpp:105] Iteration 121720, lr = 0.00220791
I1028 02:49:34.099113  9023 solver.cpp:222] Iteration 121760 (1.26836 iter/s, 31.5369s/40 iters), loss = 1.56491
I1028 02:49:34.099328  9023 solver.cpp:241]     Train net output #0: loss = 1.56491 (* 1 = 1.56491 loss)
I1028 02:49:34.102017  9023 sgd_solver.cpp:105] Iteration 121760, lr = 0.00220572
I1028 02:50:04.828398  9023 solver.cpp:222] Iteration 121800 (1.30175 iter/s, 30.7279s/40 iters), loss = 1.79595
I1028 02:50:04.828579  9023 solver.cpp:241]     Train net output #0: loss = 1.79595 (* 1 = 1.79595 loss)
I1028 02:50:04.828595  9023 sgd_solver.cpp:105] Iteration 121800, lr = 0.00220352
I1028 02:50:35.553942  9023 solver.cpp:222] Iteration 121840 (1.30191 iter/s, 30.7242s/40 iters), loss = 1.69823
I1028 02:50:35.554113  9023 solver.cpp:241]     Train net output #0: loss = 1.69823 (* 1 = 1.69823 loss)
I1028 02:50:35.554131  9023 sgd_solver.cpp:105] Iteration 121840, lr = 0.00220133
I1028 02:51:06.377130  9023 solver.cpp:222] Iteration 121880 (1.29778 iter/s, 30.8219s/40 iters), loss = 1.75401
I1028 02:51:06.377315  9023 solver.cpp:241]     Train net output #0: loss = 1.75401 (* 1 = 1.75401 loss)
I1028 02:51:06.377331  9023 sgd_solver.cpp:105] Iteration 121880, lr = 0.00219914
I1028 02:51:37.087487  9023 solver.cpp:222] Iteration 121920 (1.30255 iter/s, 30.709s/40 iters), loss = 1.55876
I1028 02:51:37.087663  9023 solver.cpp:241]     Train net output #0: loss = 1.55876 (* 1 = 1.55876 loss)
I1028 02:51:37.087679  9023 sgd_solver.cpp:105] Iteration 121920, lr = 0.00219694
I1028 02:52:12.280946  9023 solver.cpp:222] Iteration 121960 (1.13662 iter/s, 35.1919s/40 iters), loss = 1.88684
I1028 02:52:12.281404  9023 solver.cpp:241]     Train net output #0: loss = 1.88684 (* 1 = 1.88684 loss)
I1028 02:52:12.281477  9023 sgd_solver.cpp:105] Iteration 121960, lr = 0.00219475
I1028 02:52:44.032541  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_122000.caffemodel
I1028 02:52:44.065346  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_122000.solverstate
I1028 02:52:44.083411  9023 solver.cpp:334] Iteration 122000, Testing net (#0)
I1028 02:53:15.462677  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 02:53:15.671521  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56332
I1028 02:53:15.671586  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8022
I1028 02:53:15.671599  9023 solver.cpp:401]     Test net output #2: loss = 1.9443 (* 1 = 1.9443 loss)
I1028 02:53:16.441334  9023 solver.cpp:222] Iteration 122000 (0.623465 iter/s, 64.1576s/40 iters), loss = 1.64683
I1028 02:53:16.441397  9023 solver.cpp:241]     Train net output #0: loss = 1.64683 (* 1 = 1.64683 loss)
I1028 02:53:16.441412  9023 sgd_solver.cpp:105] Iteration 122000, lr = 0.00219256
I1028 02:53:47.207815  9023 solver.cpp:222] Iteration 122040 (1.30017 iter/s, 30.7653s/40 iters), loss = 1.50725
I1028 02:53:47.207984  9023 solver.cpp:241]     Train net output #0: loss = 1.50725 (* 1 = 1.50725 loss)
I1028 02:53:47.208000  9023 sgd_solver.cpp:105] Iteration 122040, lr = 0.00219036
I1028 02:53:53.433084  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1028 02:54:18.120221  9023 solver.cpp:222] Iteration 122080 (1.29404 iter/s, 30.9111s/40 iters), loss = 1.69665
I1028 02:54:18.120405  9023 solver.cpp:241]     Train net output #0: loss = 1.69665 (* 1 = 1.69665 loss)
I1028 02:54:18.120421  9023 sgd_solver.cpp:105] Iteration 122080, lr = 0.00218817
I1028 02:54:50.053320  9023 solver.cpp:222] Iteration 122120 (1.25267 iter/s, 31.9317s/40 iters), loss = 1.53569
I1028 02:54:50.053592  9023 solver.cpp:241]     Train net output #0: loss = 1.53569 (* 1 = 1.53569 loss)
I1028 02:54:50.053620  9023 sgd_solver.cpp:105] Iteration 122120, lr = 0.00218598
I1028 02:55:21.312713  9023 solver.cpp:222] Iteration 122160 (1.27968 iter/s, 31.2579s/40 iters), loss = 1.68267
I1028 02:55:21.312898  9023 solver.cpp:241]     Train net output #0: loss = 1.68267 (* 1 = 1.68267 loss)
I1028 02:55:21.312919  9023 sgd_solver.cpp:105] Iteration 122160, lr = 0.00218379
I1028 02:55:53.197655  9023 solver.cpp:222] Iteration 122200 (1.25457 iter/s, 31.8835s/40 iters), loss = 1.59469
I1028 02:55:53.197871  9023 solver.cpp:241]     Train net output #0: loss = 1.59469 (* 1 = 1.59469 loss)
I1028 02:55:53.197893  9023 sgd_solver.cpp:105] Iteration 122200, lr = 0.0021816
I1028 02:56:24.402151  9023 solver.cpp:222] Iteration 122240 (1.28192 iter/s, 31.2031s/40 iters), loss = 1.13665
I1028 02:56:24.402499  9023 solver.cpp:241]     Train net output #0: loss = 1.13665 (* 1 = 1.13665 loss)
I1028 02:56:24.402515  9023 sgd_solver.cpp:105] Iteration 122240, lr = 0.00217941
I1028 02:56:55.875134  9023 solver.cpp:222] Iteration 122280 (1.27099 iter/s, 31.4714s/40 iters), loss = 1.67229
I1028 02:56:55.875334  9023 solver.cpp:241]     Train net output #0: loss = 1.67229 (* 1 = 1.67229 loss)
I1028 02:56:55.875353  9023 sgd_solver.cpp:105] Iteration 122280, lr = 0.00217722
I1028 02:57:31.259412  9023 solver.cpp:222] Iteration 122320 (1.13049 iter/s, 35.3827s/40 iters), loss = 1.52405
I1028 02:57:31.259620  9023 solver.cpp:241]     Train net output #0: loss = 1.52405 (* 1 = 1.52405 loss)
I1028 02:57:31.259637  9023 sgd_solver.cpp:105] Iteration 122320, lr = 0.00217503
I1028 02:58:05.066061  9023 solver.cpp:222] Iteration 122360 (1.18325 iter/s, 33.8052s/40 iters), loss = 1.48653
I1028 02:58:05.066277  9023 solver.cpp:241]     Train net output #0: loss = 1.48653 (* 1 = 1.48653 loss)
I1028 02:58:05.066294  9023 sgd_solver.cpp:105] Iteration 122360, lr = 0.00217284
I1028 02:58:37.273449  9023 solver.cpp:222] Iteration 122400 (1.24201 iter/s, 32.206s/40 iters), loss = 1.37339
I1028 02:58:37.273669  9023 solver.cpp:241]     Train net output #0: loss = 1.37339 (* 1 = 1.37339 loss)
I1028 02:58:37.273685  9023 sgd_solver.cpp:105] Iteration 122400, lr = 0.00217065
I1028 02:59:08.123657  9023 solver.cpp:222] Iteration 122440 (1.29665 iter/s, 30.8488s/40 iters), loss = 1.45436
I1028 02:59:08.123833  9023 solver.cpp:241]     Train net output #0: loss = 1.45436 (* 1 = 1.45436 loss)
I1028 02:59:08.123850  9023 sgd_solver.cpp:105] Iteration 122440, lr = 0.00216846
I1028 02:59:40.772676  9023 solver.cpp:222] Iteration 122480 (1.2252 iter/s, 32.6476s/40 iters), loss = 1.66406
I1028 02:59:40.772904  9023 solver.cpp:241]     Train net output #0: loss = 1.66406 (* 1 = 1.66406 loss)
I1028 02:59:40.772927  9023 sgd_solver.cpp:105] Iteration 122480, lr = 0.00216627
I1028 02:59:55.676988  9023 solver.cpp:334] Iteration 122500, Testing net (#0)
I1028 03:00:26.952780  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57276
I1028 03:00:26.952992  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.799719
I1028 03:00:26.953008  9023 solver.cpp:401]     Test net output #2: loss = 1.89474 (* 1 = 1.89474 loss)
I1028 03:00:43.289398  9023 solver.cpp:222] Iteration 122520 (0.639855 iter/s, 62.5142s/40 iters), loss = 1.38284
I1028 03:00:43.289466  9023 solver.cpp:241]     Train net output #0: loss = 1.38284 (* 1 = 1.38284 loss)
I1028 03:00:43.289481  9023 sgd_solver.cpp:105] Iteration 122520, lr = 0.00216408
I1028 03:01:14.134981  9023 solver.cpp:222] Iteration 122560 (1.29683 iter/s, 30.8444s/40 iters), loss = 1.64508
I1028 03:01:14.135196  9023 solver.cpp:241]     Train net output #0: loss = 1.64508 (* 1 = 1.64508 loss)
I1028 03:01:14.135212  9023 sgd_solver.cpp:105] Iteration 122560, lr = 0.0021619
I1028 03:01:45.037880  9023 solver.cpp:222] Iteration 122600 (1.29443 iter/s, 30.9015s/40 iters), loss = 1.75821
I1028 03:01:45.038084  9023 solver.cpp:241]     Train net output #0: loss = 1.75821 (* 1 = 1.75821 loss)
I1028 03:01:45.038100  9023 sgd_solver.cpp:105] Iteration 122600, lr = 0.00215971
I1028 03:02:15.836752  9023 solver.cpp:222] Iteration 122640 (1.29881 iter/s, 30.7975s/40 iters), loss = 1.50233
I1028 03:02:15.836958  9023 solver.cpp:241]     Train net output #0: loss = 1.50233 (* 1 = 1.50233 loss)
I1028 03:02:15.836974  9023 sgd_solver.cpp:105] Iteration 122640, lr = 0.00215752
I1028 03:02:46.777232  9023 solver.cpp:222] Iteration 122680 (1.29286 iter/s, 30.9391s/40 iters), loss = 1.62178
I1028 03:02:46.777447  9023 solver.cpp:241]     Train net output #0: loss = 1.62178 (* 1 = 1.62178 loss)
I1028 03:02:46.777463  9023 sgd_solver.cpp:105] Iteration 122680, lr = 0.00215534
I1028 03:03:17.611802  9023 solver.cpp:222] Iteration 122720 (1.2973 iter/s, 30.8332s/40 iters), loss = 1.44339
I1028 03:03:17.612004  9023 solver.cpp:241]     Train net output #0: loss = 1.44339 (* 1 = 1.44339 loss)
I1028 03:03:17.612020  9023 sgd_solver.cpp:105] Iteration 122720, lr = 0.00215315
I1028 03:03:48.517560  9023 solver.cpp:222] Iteration 122760 (1.29431 iter/s, 30.9044s/40 iters), loss = 1.46124
I1028 03:03:48.517757  9023 solver.cpp:241]     Train net output #0: loss = 1.46124 (* 1 = 1.46124 loss)
I1028 03:03:48.517773  9023 sgd_solver.cpp:105] Iteration 122760, lr = 0.00215096
I1028 03:04:19.192386  9023 solver.cpp:222] Iteration 122800 (1.30406 iter/s, 30.6735s/40 iters), loss = 1.76092
I1028 03:04:19.192584  9023 solver.cpp:241]     Train net output #0: loss = 1.76092 (* 1 = 1.76092 loss)
I1028 03:04:19.192600  9023 sgd_solver.cpp:105] Iteration 122800, lr = 0.00214878
I1028 03:04:50.110735  9023 solver.cpp:222] Iteration 122840 (1.29379 iter/s, 30.917s/40 iters), loss = 1.64346
I1028 03:04:50.110956  9023 solver.cpp:241]     Train net output #0: loss = 1.64346 (* 1 = 1.64346 loss)
I1028 03:04:50.110973  9023 sgd_solver.cpp:105] Iteration 122840, lr = 0.00214659
I1028 03:05:21.002534  9023 solver.cpp:222] Iteration 122880 (1.2949 iter/s, 30.8904s/40 iters), loss = 1.72603
I1028 03:05:21.002743  9023 solver.cpp:241]     Train net output #0: loss = 1.72603 (* 1 = 1.72603 loss)
I1028 03:05:21.002774  9023 sgd_solver.cpp:105] Iteration 122880, lr = 0.00214441
I1028 03:05:51.829810  9023 solver.cpp:222] Iteration 122920 (1.29761 iter/s, 30.8259s/40 iters), loss = 1.15307
I1028 03:05:51.830072  9023 solver.cpp:241]     Train net output #0: loss = 1.15307 (* 1 = 1.15307 loss)
I1028 03:05:51.830094  9023 sgd_solver.cpp:105] Iteration 122920, lr = 0.00214222
I1028 03:06:22.906153  9023 solver.cpp:222] Iteration 122960 (1.28721 iter/s, 31.0749s/40 iters), loss = 1.50179
I1028 03:06:22.906339  9023 solver.cpp:241]     Train net output #0: loss = 1.50179 (* 1 = 1.50179 loss)
I1028 03:06:22.906358  9023 sgd_solver.cpp:105] Iteration 122960, lr = 0.00214004
I1028 03:06:52.807543  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_123000.caffemodel
I1028 03:06:52.838937  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_123000.solverstate
I1028 03:06:52.857075  9023 solver.cpp:334] Iteration 123000, Testing net (#0)
I1028 03:07:23.945471  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 03:07:24.156574  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.567
I1028 03:07:24.156635  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80144
I1028 03:07:24.156649  9023 solver.cpp:401]     Test net output #2: loss = 1.92932 (* 1 = 1.92932 loss)
I1028 03:07:24.923625  9023 solver.cpp:222] Iteration 123000 (0.645006 iter/s, 62.015s/40 iters), loss = 1.55918
I1028 03:07:24.923691  9023 solver.cpp:241]     Train net output #0: loss = 1.55918 (* 1 = 1.55918 loss)
I1028 03:07:24.923705  9023 sgd_solver.cpp:105] Iteration 123000, lr = 0.00213786
I1028 03:07:55.751336  9023 solver.cpp:222] Iteration 123040 (1.29759 iter/s, 30.8265s/40 iters), loss = 1.28427
I1028 03:07:55.751507  9023 solver.cpp:241]     Train net output #0: loss = 1.28427 (* 1 = 1.28427 loss)
I1028 03:07:55.751524  9023 sgd_solver.cpp:105] Iteration 123040, lr = 0.00213567
I1028 03:08:26.555186  9023 solver.cpp:222] Iteration 123080 (1.2986 iter/s, 30.8025s/40 iters), loss = 1.27589
I1028 03:08:26.555415  9023 solver.cpp:241]     Train net output #0: loss = 1.27589 (* 1 = 1.27589 loss)
I1028 03:08:26.555433  9023 sgd_solver.cpp:105] Iteration 123080, lr = 0.00213349
I1028 03:08:57.318117  9023 solver.cpp:222] Iteration 123120 (1.30033 iter/s, 30.7615s/40 iters), loss = 1.21049
I1028 03:08:57.318317  9023 solver.cpp:241]     Train net output #0: loss = 1.21049 (* 1 = 1.21049 loss)
I1028 03:08:57.318336  9023 sgd_solver.cpp:105] Iteration 123120, lr = 0.00213131
I1028 03:09:28.228014  9023 solver.cpp:222] Iteration 123160 (1.29414 iter/s, 30.9085s/40 iters), loss = 1.89229
I1028 03:09:28.228180  9023 solver.cpp:241]     Train net output #0: loss = 1.89229 (* 1 = 1.89229 loss)
I1028 03:09:28.228197  9023 sgd_solver.cpp:105] Iteration 123160, lr = 0.00212913
I1028 03:09:59.327869  9023 solver.cpp:222] Iteration 123200 (1.28624 iter/s, 31.0985s/40 iters), loss = 1.82819
I1028 03:09:59.328099  9023 solver.cpp:241]     Train net output #0: loss = 1.82819 (* 1 = 1.82819 loss)
I1028 03:09:59.328115  9023 sgd_solver.cpp:105] Iteration 123200, lr = 0.00212695
I1028 03:10:30.524690  9023 solver.cpp:222] Iteration 123240 (1.28224 iter/s, 31.1954s/40 iters), loss = 1.5664
I1028 03:10:30.524879  9023 solver.cpp:241]     Train net output #0: loss = 1.5664 (* 1 = 1.5664 loss)
I1028 03:10:30.524894  9023 sgd_solver.cpp:105] Iteration 123240, lr = 0.00212476
I1028 03:11:01.544957  9023 solver.cpp:222] Iteration 123280 (1.28954 iter/s, 31.0189s/40 iters), loss = 1.52838
I1028 03:11:01.545125  9023 solver.cpp:241]     Train net output #0: loss = 1.52838 (* 1 = 1.52838 loss)
I1028 03:11:01.545141  9023 sgd_solver.cpp:105] Iteration 123280, lr = 0.00212258
I1028 03:11:32.364462  9023 solver.cpp:222] Iteration 123320 (1.29794 iter/s, 30.8182s/40 iters), loss = 1.35811
I1028 03:11:32.364682  9023 solver.cpp:241]     Train net output #0: loss = 1.35811 (* 1 = 1.35811 loss)
I1028 03:11:32.364711  9023 sgd_solver.cpp:105] Iteration 123320, lr = 0.0021204
I1028 03:12:02.965680  9023 solver.cpp:222] Iteration 123360 (1.3072 iter/s, 30.5998s/40 iters), loss = 1.53254
I1028 03:12:02.965908  9023 solver.cpp:241]     Train net output #0: loss = 1.53254 (* 1 = 1.53254 loss)
I1028 03:12:02.965934  9023 sgd_solver.cpp:105] Iteration 123360, lr = 0.00211822
I1028 03:12:33.988538  9023 solver.cpp:222] Iteration 123400 (1.28943 iter/s, 31.0215s/40 iters), loss = 1.58015
I1028 03:12:33.988741  9023 solver.cpp:241]     Train net output #0: loss = 1.58015 (* 1 = 1.58015 loss)
I1028 03:12:33.988759  9023 sgd_solver.cpp:105] Iteration 123400, lr = 0.00211604
I1028 03:13:05.137969  9023 solver.cpp:222] Iteration 123440 (1.28419 iter/s, 31.1481s/40 iters), loss = 1.54896
I1028 03:13:05.138165  9023 solver.cpp:241]     Train net output #0: loss = 1.54896 (* 1 = 1.54896 loss)
I1028 03:13:05.138181  9023 sgd_solver.cpp:105] Iteration 123440, lr = 0.00211386
I1028 03:13:36.039054  9023 solver.cpp:222] Iteration 123480 (1.29451 iter/s, 30.8997s/40 iters), loss = 1.43165
I1028 03:13:36.039232  9023 solver.cpp:241]     Train net output #0: loss = 1.43165 (* 1 = 1.43165 loss)
I1028 03:13:36.039248  9023 sgd_solver.cpp:105] Iteration 123480, lr = 0.00211168
I1028 03:13:50.828624  9023 solver.cpp:334] Iteration 123500, Testing net (#0)
I1028 03:14:22.470559  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56804
I1028 03:14:22.470736  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80028
I1028 03:14:22.470752  9023 solver.cpp:401]     Test net output #2: loss = 1.89913 (* 1 = 1.89913 loss)
I1028 03:14:38.735790  9023 solver.cpp:222] Iteration 123520 (0.638017 iter/s, 62.6942s/40 iters), loss = 1.53018
I1028 03:14:38.735862  9023 solver.cpp:241]     Train net output #0: loss = 1.53018 (* 1 = 1.53018 loss)
I1028 03:14:38.735877  9023 sgd_solver.cpp:105] Iteration 123520, lr = 0.00210951
I1028 03:15:10.544036  9023 solver.cpp:222] Iteration 123560 (1.25759 iter/s, 31.807s/40 iters), loss = 1.4877
I1028 03:15:10.544209  9023 solver.cpp:241]     Train net output #0: loss = 1.4877 (* 1 = 1.4877 loss)
I1028 03:15:10.544227  9023 sgd_solver.cpp:105] Iteration 123560, lr = 0.00210733
I1028 03:15:41.584314  9023 solver.cpp:222] Iteration 123600 (1.2887 iter/s, 31.0389s/40 iters), loss = 1.69294
I1028 03:15:41.584506  9023 solver.cpp:241]     Train net output #0: loss = 1.69294 (* 1 = 1.69294 loss)
I1028 03:15:41.584522  9023 sgd_solver.cpp:105] Iteration 123600, lr = 0.00210515
I1028 03:16:12.456081  9023 solver.cpp:222] Iteration 123640 (1.29574 iter/s, 30.8704s/40 iters), loss = 1.29239
I1028 03:16:12.456265  9023 solver.cpp:241]     Train net output #0: loss = 1.29239 (* 1 = 1.29239 loss)
I1028 03:16:12.456281  9023 sgd_solver.cpp:105] Iteration 123640, lr = 0.00210297
I1028 03:16:43.501946  9023 solver.cpp:222] Iteration 123680 (1.28847 iter/s, 31.0445s/40 iters), loss = 1.46886
I1028 03:16:43.502122  9023 solver.cpp:241]     Train net output #0: loss = 1.46886 (* 1 = 1.46886 loss)
I1028 03:16:43.502140  9023 sgd_solver.cpp:105] Iteration 123680, lr = 0.00210079
I1028 03:17:14.196914  9023 solver.cpp:222] Iteration 123720 (1.3032 iter/s, 30.6936s/40 iters), loss = 1.3964
I1028 03:17:14.197072  9023 solver.cpp:241]     Train net output #0: loss = 1.3964 (* 1 = 1.3964 loss)
I1028 03:17:14.197088  9023 sgd_solver.cpp:105] Iteration 123720, lr = 0.00209862
I1028 03:17:44.811372  9023 solver.cpp:222] Iteration 123760 (1.30663 iter/s, 30.6131s/40 iters), loss = 1.54794
I1028 03:17:44.811556  9023 solver.cpp:241]     Train net output #0: loss = 1.54794 (* 1 = 1.54794 loss)
I1028 03:17:44.811573  9023 sgd_solver.cpp:105] Iteration 123760, lr = 0.00209644
I1028 03:18:16.232836  9023 solver.cpp:222] Iteration 123800 (1.27307 iter/s, 31.4201s/40 iters), loss = 1.35587
I1028 03:18:16.233023  9023 solver.cpp:241]     Train net output #0: loss = 1.35587 (* 1 = 1.35587 loss)
I1028 03:18:16.233039  9023 sgd_solver.cpp:105] Iteration 123800, lr = 0.00209426
I1028 03:18:48.340803  9023 solver.cpp:222] Iteration 123840 (1.24585 iter/s, 32.1066s/40 iters), loss = 1.33239
I1028 03:18:48.341115  9023 solver.cpp:241]     Train net output #0: loss = 1.33239 (* 1 = 1.33239 loss)
I1028 03:18:48.341141  9023 sgd_solver.cpp:105] Iteration 123840, lr = 0.00209209
I1028 03:19:22.020938  9023 solver.cpp:222] Iteration 123880 (1.1877 iter/s, 33.6786s/40 iters), loss = 1.21651
I1028 03:19:22.021140  9023 solver.cpp:241]     Train net output #0: loss = 1.21651 (* 1 = 1.21651 loss)
I1028 03:19:22.021157  9023 sgd_solver.cpp:105] Iteration 123880, lr = 0.00208991
I1028 03:19:54.789631  9023 solver.cpp:222] Iteration 123920 (1.22073 iter/s, 32.7673s/40 iters), loss = 1.42787
I1028 03:19:54.789803  9023 solver.cpp:241]     Train net output #0: loss = 1.42787 (* 1 = 1.42787 loss)
I1028 03:19:54.789819  9023 sgd_solver.cpp:105] Iteration 123920, lr = 0.00208774
I1028 03:20:25.969455  9023 solver.cpp:222] Iteration 123960 (1.28294 iter/s, 31.1785s/40 iters), loss = 1.53578
I1028 03:20:25.969645  9023 solver.cpp:241]     Train net output #0: loss = 1.53578 (* 1 = 1.53578 loss)
I1028 03:20:25.969666  9023 sgd_solver.cpp:105] Iteration 123960, lr = 0.00208556
I1028 03:20:56.952109  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_124000.caffemodel
I1028 03:20:56.982606  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_124000.solverstate
I1028 03:20:56.999905  9023 solver.cpp:334] Iteration 124000, Testing net (#0)
I1028 03:21:28.295743  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 03:21:28.505460  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56896
I1028 03:21:28.505524  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80252
I1028 03:21:28.505538  9023 solver.cpp:401]     Test net output #2: loss = 1.90891 (* 1 = 1.90891 loss)
I1028 03:21:29.285825  9023 solver.cpp:222] Iteration 124000 (0.631774 iter/s, 63.3138s/40 iters), loss = 1.69371
I1028 03:21:29.285881  9023 solver.cpp:241]     Train net output #0: loss = 1.69371 (* 1 = 1.69371 loss)
I1028 03:21:29.285897  9023 sgd_solver.cpp:105] Iteration 124000, lr = 0.00208339
I1028 03:22:00.431205  9023 solver.cpp:222] Iteration 124040 (1.28435 iter/s, 31.1441s/40 iters), loss = 1.29021
I1028 03:22:00.431393  9023 solver.cpp:241]     Train net output #0: loss = 1.29021 (* 1 = 1.29021 loss)
I1028 03:22:00.431408  9023 sgd_solver.cpp:105] Iteration 124040, lr = 0.00208122
I1028 03:22:31.211416  9023 solver.cpp:222] Iteration 124080 (1.29959 iter/s, 30.7789s/40 iters), loss = 1.5421
I1028 03:22:31.211604  9023 solver.cpp:241]     Train net output #0: loss = 1.5421 (* 1 = 1.5421 loss)
I1028 03:22:31.211619  9023 sgd_solver.cpp:105] Iteration 124080, lr = 0.00207904
I1028 03:23:02.419502  9023 solver.cpp:222] Iteration 124120 (1.28178 iter/s, 31.2067s/40 iters), loss = 1.34155
I1028 03:23:02.419669  9023 solver.cpp:241]     Train net output #0: loss = 1.34155 (* 1 = 1.34155 loss)
I1028 03:23:02.419688  9023 sgd_solver.cpp:105] Iteration 124120, lr = 0.00207687
I1028 03:23:33.699559  9023 solver.cpp:222] Iteration 124160 (1.27883 iter/s, 31.2787s/40 iters), loss = 1.56575
I1028 03:23:33.699721  9023 solver.cpp:241]     Train net output #0: loss = 1.56575 (* 1 = 1.56575 loss)
I1028 03:23:33.699736  9023 sgd_solver.cpp:105] Iteration 124160, lr = 0.0020747
I1028 03:24:04.945116  9023 solver.cpp:222] Iteration 124200 (1.28024 iter/s, 31.2442s/40 iters), loss = 1.34478
I1028 03:24:04.945315  9023 solver.cpp:241]     Train net output #0: loss = 1.34478 (* 1 = 1.34478 loss)
I1028 03:24:04.945333  9023 sgd_solver.cpp:105] Iteration 124200, lr = 0.00207252
I1028 03:24:35.835774  9023 solver.cpp:222] Iteration 124240 (1.29495 iter/s, 30.8893s/40 iters), loss = 1.08678
I1028 03:24:35.835968  9023 solver.cpp:241]     Train net output #0: loss = 1.08678 (* 1 = 1.08678 loss)
I1028 03:24:35.835984  9023 sgd_solver.cpp:105] Iteration 124240, lr = 0.00207035
I1028 03:25:06.607635  9023 solver.cpp:222] Iteration 124280 (1.29995 iter/s, 30.7705s/40 iters), loss = 1.24495
I1028 03:25:06.607905  9023 solver.cpp:241]     Train net output #0: loss = 1.24495 (* 1 = 1.24495 loss)
I1028 03:25:06.607923  9023 sgd_solver.cpp:105] Iteration 124280, lr = 0.00206818
I1028 03:25:37.274718  9023 solver.cpp:222] Iteration 124320 (1.30439 iter/s, 30.6657s/40 iters), loss = 1.50478
I1028 03:25:37.274888  9023 solver.cpp:241]     Train net output #0: loss = 1.50478 (* 1 = 1.50478 loss)
I1028 03:25:37.274904  9023 sgd_solver.cpp:105] Iteration 124320, lr = 0.00206601
I1028 03:26:08.085242  9023 solver.cpp:222] Iteration 124360 (1.29831 iter/s, 30.8092s/40 iters), loss = 1.76379
I1028 03:26:08.085428  9023 solver.cpp:241]     Train net output #0: loss = 1.76379 (* 1 = 1.76379 loss)
I1028 03:26:08.085444  9023 sgd_solver.cpp:105] Iteration 124360, lr = 0.00206384
I1028 03:27:38.167387  9023 solver.cpp:222] Iteration 124400 (0.444057 iter/s, 90.0786s/40 iters), loss = 1.41783
I1028 03:27:38.167621  9023 solver.cpp:241]     Train net output #0: loss = 1.41783 (* 1 = 1.41783 loss)
I1028 03:27:38.167645  9023 sgd_solver.cpp:105] Iteration 124400, lr = 0.00206167
I1028 03:28:24.187453  9023 solver.cpp:222] Iteration 124440 (0.869223 iter/s, 46.0181s/40 iters), loss = 1.55337
I1028 03:28:24.187669  9023 solver.cpp:241]     Train net output #0: loss = 1.55337 (* 1 = 1.55337 loss)
I1028 03:28:24.187685  9023 sgd_solver.cpp:105] Iteration 124440, lr = 0.0020595
I1028 03:28:55.303927  9023 solver.cpp:222] Iteration 124480 (1.28555 iter/s, 31.1151s/40 iters), loss = 1.82124
I1028 03:28:55.304091  9023 solver.cpp:241]     Train net output #0: loss = 1.82124 (* 1 = 1.82124 loss)
I1028 03:28:55.304107  9023 sgd_solver.cpp:105] Iteration 124480, lr = 0.00205733
I1028 03:29:09.983244  9023 solver.cpp:334] Iteration 124500, Testing net (#0)
I1028 03:29:41.287777  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56872
I1028 03:29:41.287955  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79688
I1028 03:29:41.287971  9023 solver.cpp:401]     Test net output #2: loss = 1.93985 (* 1 = 1.93985 loss)
I1028 03:29:57.445860  9023 solver.cpp:222] Iteration 124520 (0.643714 iter/s, 62.1394s/40 iters), loss = 1.70689
I1028 03:29:57.445964  9023 solver.cpp:241]     Train net output #0: loss = 1.70689 (* 1 = 1.70689 loss)
I1028 03:29:57.445986  9023 sgd_solver.cpp:105] Iteration 124520, lr = 0.00205516
I1028 03:30:21.618144  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1028 03:30:28.911841  9023 solver.cpp:222] Iteration 124560 (1.27127 iter/s, 31.4647s/40 iters), loss = 1.31719
I1028 03:30:28.911916  9023 solver.cpp:241]     Train net output #0: loss = 1.31719 (* 1 = 1.31719 loss)
I1028 03:30:28.911932  9023 sgd_solver.cpp:105] Iteration 124560, lr = 0.00205299
I1028 03:30:59.664173  9023 solver.cpp:222] Iteration 124600 (1.30077 iter/s, 30.7511s/40 iters), loss = 1.7051
I1028 03:30:59.664362  9023 solver.cpp:241]     Train net output #0: loss = 1.7051 (* 1 = 1.7051 loss)
I1028 03:30:59.664378  9023 sgd_solver.cpp:105] Iteration 124600, lr = 0.00205082
I1028 03:31:30.686595  9023 solver.cpp:222] Iteration 124640 (1.28945 iter/s, 31.0211s/40 iters), loss = 1.65499
I1028 03:31:30.686791  9023 solver.cpp:241]     Train net output #0: loss = 1.65499 (* 1 = 1.65499 loss)
I1028 03:31:30.686807  9023 sgd_solver.cpp:105] Iteration 124640, lr = 0.00204866
I1028 03:32:01.457665  9023 solver.cpp:222] Iteration 124680 (1.29998 iter/s, 30.7697s/40 iters), loss = 1.4896
I1028 03:32:01.457834  9023 solver.cpp:241]     Train net output #0: loss = 1.4896 (* 1 = 1.4896 loss)
I1028 03:32:01.457850  9023 sgd_solver.cpp:105] Iteration 124680, lr = 0.00204649
I1028 03:32:32.118983  9023 solver.cpp:222] Iteration 124720 (1.30463 iter/s, 30.66s/40 iters), loss = 1.39433
I1028 03:32:32.119117  9023 solver.cpp:241]     Train net output #0: loss = 1.39433 (* 1 = 1.39433 loss)
I1028 03:32:32.119132  9023 sgd_solver.cpp:105] Iteration 124720, lr = 0.00204432
I1028 03:33:02.903738  9023 solver.cpp:222] Iteration 124760 (1.2994 iter/s, 30.7834s/40 iters), loss = 1.28044
I1028 03:33:02.903911  9023 solver.cpp:241]     Train net output #0: loss = 1.28044 (* 1 = 1.28044 loss)
I1028 03:33:02.903940  9023 sgd_solver.cpp:105] Iteration 124760, lr = 0.00204215
I1028 03:33:33.695881  9023 solver.cpp:222] Iteration 124800 (1.29909 iter/s, 30.7908s/40 iters), loss = 1.58051
I1028 03:33:33.696136  9023 solver.cpp:241]     Train net output #0: loss = 1.58051 (* 1 = 1.58051 loss)
I1028 03:33:33.696153  9023 sgd_solver.cpp:105] Iteration 124800, lr = 0.00203999
I1028 03:34:04.467504  9023 solver.cpp:222] Iteration 124840 (1.29996 iter/s, 30.7702s/40 iters), loss = 1.655
I1028 03:34:04.467700  9023 solver.cpp:241]     Train net output #0: loss = 1.655 (* 1 = 1.655 loss)
I1028 03:34:04.467717  9023 sgd_solver.cpp:105] Iteration 124840, lr = 0.00203782
I1028 03:34:35.223459  9023 solver.cpp:222] Iteration 124880 (1.30062 iter/s, 30.7546s/40 iters), loss = 1.85008
I1028 03:34:35.223630  9023 solver.cpp:241]     Train net output #0: loss = 1.85008 (* 1 = 1.85008 loss)
I1028 03:34:35.223649  9023 sgd_solver.cpp:105] Iteration 124880, lr = 0.00203566
I1028 03:35:06.084563  9023 solver.cpp:222] Iteration 124920 (1.29619 iter/s, 30.8598s/40 iters), loss = 1.41059
I1028 03:35:06.084733  9023 solver.cpp:241]     Train net output #0: loss = 1.41059 (* 1 = 1.41059 loss)
I1028 03:35:06.084749  9023 sgd_solver.cpp:105] Iteration 124920, lr = 0.00203349
I1028 03:35:37.284163  9023 solver.cpp:222] Iteration 124960 (1.28212 iter/s, 31.1982s/40 iters), loss = 1.47362
I1028 03:35:37.284354  9023 solver.cpp:241]     Train net output #0: loss = 1.47362 (* 1 = 1.47362 loss)
I1028 03:35:37.284370  9023 sgd_solver.cpp:105] Iteration 124960, lr = 0.00203132
I1028 03:36:07.520072  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_125000.caffemodel
I1028 03:36:07.551059  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_125000.solverstate
I1028 03:36:07.567556  9023 solver.cpp:334] Iteration 125000, Testing net (#0)
I1028 03:36:38.811398  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 03:36:39.022253  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57068
I1028 03:36:39.022323  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.802
I1028 03:36:39.022339  9023 solver.cpp:401]     Test net output #2: loss = 1.90095 (* 1 = 1.90095 loss)
I1028 03:36:39.792184  9023 solver.cpp:222] Iteration 125000 (0.639944 iter/s, 62.5055s/40 iters), loss = 1.52453
I1028 03:36:39.792248  9023 solver.cpp:241]     Train net output #0: loss = 1.52453 (* 1 = 1.52453 loss)
I1028 03:36:39.792266  9023 sgd_solver.cpp:105] Iteration 125000, lr = 0.00202916
I1028 03:37:10.539758  9023 solver.cpp:222] Iteration 125040 (1.30097 iter/s, 30.7463s/40 iters), loss = 1.64251
I1028 03:37:10.539958  9023 solver.cpp:241]     Train net output #0: loss = 1.64251 (* 1 = 1.64251 loss)
I1028 03:37:10.539974  9023 sgd_solver.cpp:105] Iteration 125040, lr = 0.002027
I1028 03:37:41.301507  9023 solver.cpp:222] Iteration 125080 (1.30037 iter/s, 30.7604s/40 iters), loss = 1.38386
I1028 03:37:41.301712  9023 solver.cpp:241]     Train net output #0: loss = 1.38386 (* 1 = 1.38386 loss)
I1028 03:37:41.301728  9023 sgd_solver.cpp:105] Iteration 125080, lr = 0.00202483
I1028 03:38:12.814671  9023 solver.cpp:222] Iteration 125120 (1.26937 iter/s, 31.5118s/40 iters), loss = 1.67137
I1028 03:38:12.814863  9023 solver.cpp:241]     Train net output #0: loss = 1.67137 (* 1 = 1.67137 loss)
I1028 03:38:12.814879  9023 sgd_solver.cpp:105] Iteration 125120, lr = 0.00202267
I1028 03:38:43.927186  9023 solver.cpp:222] Iteration 125160 (1.28571 iter/s, 31.1111s/40 iters), loss = 1.55717
I1028 03:38:43.927379  9023 solver.cpp:241]     Train net output #0: loss = 1.55717 (* 1 = 1.55717 loss)
I1028 03:38:43.927407  9023 sgd_solver.cpp:105] Iteration 125160, lr = 0.00202051
I1028 03:39:14.906918  9023 solver.cpp:222] Iteration 125200 (1.29122 iter/s, 30.9784s/40 iters), loss = 1.37116
I1028 03:39:14.907095  9023 solver.cpp:241]     Train net output #0: loss = 1.37116 (* 1 = 1.37116 loss)
I1028 03:39:14.907124  9023 sgd_solver.cpp:105] Iteration 125200, lr = 0.00201834
I1028 03:39:45.724447  9023 solver.cpp:222] Iteration 125240 (1.29802 iter/s, 30.8162s/40 iters), loss = 1.77069
I1028 03:39:45.724684  9023 solver.cpp:241]     Train net output #0: loss = 1.77069 (* 1 = 1.77069 loss)
I1028 03:39:45.724702  9023 sgd_solver.cpp:105] Iteration 125240, lr = 0.00201618
I1028 03:40:16.420799  9023 solver.cpp:222] Iteration 125280 (1.30315 iter/s, 30.695s/40 iters), loss = 1.57396
I1028 03:40:16.420987  9023 solver.cpp:241]     Train net output #0: loss = 1.57396 (* 1 = 1.57396 loss)
I1028 03:40:16.421002  9023 sgd_solver.cpp:105] Iteration 125280, lr = 0.00201402
I1028 03:40:47.262511  9023 solver.cpp:222] Iteration 125320 (1.297 iter/s, 30.8404s/40 iters), loss = 1.52771
I1028 03:40:47.262697  9023 solver.cpp:241]     Train net output #0: loss = 1.52771 (* 1 = 1.52771 loss)
I1028 03:40:47.262713  9023 sgd_solver.cpp:105] Iteration 125320, lr = 0.00201186
I1028 03:41:18.197083  9023 solver.cpp:222] Iteration 125360 (1.29311 iter/s, 30.9332s/40 iters), loss = 1.33321
I1028 03:41:18.197276  9023 solver.cpp:241]     Train net output #0: loss = 1.33321 (* 1 = 1.33321 loss)
I1028 03:41:18.197291  9023 sgd_solver.cpp:105] Iteration 125360, lr = 0.0020097
I1028 03:41:49.077338  9023 solver.cpp:222] Iteration 125400 (1.29538 iter/s, 30.8789s/40 iters), loss = 1.38594
I1028 03:41:49.077530  9023 solver.cpp:241]     Train net output #0: loss = 1.38594 (* 1 = 1.38594 loss)
I1028 03:41:49.077546  9023 sgd_solver.cpp:105] Iteration 125400, lr = 0.00200753
I1028 03:42:20.217471  9023 solver.cpp:222] Iteration 125440 (1.28457 iter/s, 31.1388s/40 iters), loss = 1.47971
I1028 03:42:20.217711  9023 solver.cpp:241]     Train net output #0: loss = 1.47971 (* 1 = 1.47971 loss)
I1028 03:42:20.217736  9023 sgd_solver.cpp:105] Iteration 125440, lr = 0.00200537
I1028 03:42:52.400665  9023 solver.cpp:222] Iteration 125480 (1.24294 iter/s, 32.1817s/40 iters), loss = 1.40302
I1028 03:42:52.400833  9023 solver.cpp:241]     Train net output #0: loss = 1.40302 (* 1 = 1.40302 loss)
I1028 03:42:52.400849  9023 sgd_solver.cpp:105] Iteration 125480, lr = 0.00200321
I1028 03:43:07.022112  9023 solver.cpp:334] Iteration 125500, Testing net (#0)
I1028 03:43:38.398885  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57028
I1028 03:43:38.399070  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.799399
I1028 03:43:38.399085  9023 solver.cpp:401]     Test net output #2: loss = 1.89039 (* 1 = 1.89039 loss)
I1028 03:43:55.325237  9023 solver.cpp:222] Iteration 125520 (0.635707 iter/s, 62.922s/40 iters), loss = 1.65239
I1028 03:43:55.325371  9023 solver.cpp:241]     Train net output #0: loss = 1.65239 (* 1 = 1.65239 loss)
I1028 03:43:55.325392  9023 sgd_solver.cpp:105] Iteration 125520, lr = 0.00200105
I1028 03:44:26.577180  9023 solver.cpp:222] Iteration 125560 (1.27997 iter/s, 31.2506s/40 iters), loss = 1.37892
I1028 03:44:26.577509  9023 solver.cpp:241]     Train net output #0: loss = 1.37892 (* 1 = 1.37892 loss)
I1028 03:44:26.577525  9023 sgd_solver.cpp:105] Iteration 125560, lr = 0.0019989
I1028 03:44:57.950160  9023 solver.cpp:222] Iteration 125600 (1.27504 iter/s, 31.3715s/40 iters), loss = 1.27441
I1028 03:44:57.950330  9023 solver.cpp:241]     Train net output #0: loss = 1.27441 (* 1 = 1.27441 loss)
I1028 03:44:57.950346  9023 sgd_solver.cpp:105] Iteration 125600, lr = 0.00199674
I1028 03:45:42.182663  9023 solver.cpp:222] Iteration 125640 (0.90435 iter/s, 44.2307s/40 iters), loss = 1.37254
I1028 03:45:42.182857  9023 solver.cpp:241]     Train net output #0: loss = 1.37254 (* 1 = 1.37254 loss)
I1028 03:45:42.182873  9023 sgd_solver.cpp:105] Iteration 125640, lr = 0.00199458
I1028 03:46:12.888417  9023 solver.cpp:222] Iteration 125680 (1.30274 iter/s, 30.7044s/40 iters), loss = 1.43878
I1028 03:46:12.888609  9023 solver.cpp:241]     Train net output #0: loss = 1.43878 (* 1 = 1.43878 loss)
I1028 03:46:12.888625  9023 sgd_solver.cpp:105] Iteration 125680, lr = 0.00199242
I1028 03:46:43.751895  9023 solver.cpp:222] Iteration 125720 (1.29609 iter/s, 30.8621s/40 iters), loss = 1.77648
I1028 03:46:43.752143  9023 solver.cpp:241]     Train net output #0: loss = 1.77648 (* 1 = 1.77648 loss)
I1028 03:46:43.752161  9023 sgd_solver.cpp:105] Iteration 125720, lr = 0.00199026
I1028 03:47:16.737493  9023 solver.cpp:222] Iteration 125760 (1.21271 iter/s, 32.9841s/40 iters), loss = 1.10447
I1028 03:47:16.737661  9023 solver.cpp:241]     Train net output #0: loss = 1.10447 (* 1 = 1.10447 loss)
I1028 03:47:16.737677  9023 sgd_solver.cpp:105] Iteration 125760, lr = 0.00198811
I1028 03:47:47.498257  9023 solver.cpp:222] Iteration 125800 (1.30041 iter/s, 30.7594s/40 iters), loss = 1.6159
I1028 03:47:47.498445  9023 solver.cpp:241]     Train net output #0: loss = 1.6159 (* 1 = 1.6159 loss)
I1028 03:47:47.498461  9023 sgd_solver.cpp:105] Iteration 125800, lr = 0.00198595
I1028 03:48:18.177376  9023 solver.cpp:222] Iteration 125840 (1.30388 iter/s, 30.6778s/40 iters), loss = 1.6477
I1028 03:48:18.177537  9023 solver.cpp:241]     Train net output #0: loss = 1.6477 (* 1 = 1.6477 loss)
I1028 03:48:18.177553  9023 sgd_solver.cpp:105] Iteration 125840, lr = 0.00198379
I1028 03:48:49.076336  9023 solver.cpp:222] Iteration 125880 (1.2946 iter/s, 30.8976s/40 iters), loss = 1.6811
I1028 03:48:49.076514  9023 solver.cpp:241]     Train net output #0: loss = 1.6811 (* 1 = 1.6811 loss)
I1028 03:48:49.076530  9023 sgd_solver.cpp:105] Iteration 125880, lr = 0.00198164
I1028 03:49:19.902894  9023 solver.cpp:222] Iteration 125920 (1.29764 iter/s, 30.8252s/40 iters), loss = 1.36713
I1028 03:49:19.903074  9023 solver.cpp:241]     Train net output #0: loss = 1.36713 (* 1 = 1.36713 loss)
I1028 03:49:19.903090  9023 sgd_solver.cpp:105] Iteration 125920, lr = 0.00197948
I1028 03:49:50.654373  9023 solver.cpp:222] Iteration 125960 (1.30081 iter/s, 30.7501s/40 iters), loss = 1.59352
I1028 03:49:50.654567  9023 solver.cpp:241]     Train net output #0: loss = 1.59352 (* 1 = 1.59352 loss)
I1028 03:49:50.654582  9023 sgd_solver.cpp:105] Iteration 125960, lr = 0.00197732
I1028 03:50:20.704442  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_126000.caffemodel
I1028 03:50:20.735957  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_126000.solverstate
I1028 03:50:20.753235  9023 solver.cpp:334] Iteration 126000, Testing net (#0)
I1028 03:50:52.027127  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 03:50:52.239238  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56888
I1028 03:50:52.239305  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.803159
I1028 03:50:52.239320  9023 solver.cpp:401]     Test net output #2: loss = 1.92632 (* 1 = 1.92632 loss)
I1028 03:50:53.013753  9023 solver.cpp:222] Iteration 126000 (0.641469 iter/s, 62.3569s/40 iters), loss = 1.29578
I1028 03:50:53.013818  9023 solver.cpp:241]     Train net output #0: loss = 1.29578 (* 1 = 1.29578 loss)
I1028 03:50:53.013833  9023 sgd_solver.cpp:105] Iteration 126000, lr = 0.00197517
I1028 03:51:23.898370  9023 solver.cpp:222] Iteration 126040 (1.29519 iter/s, 30.8834s/40 iters), loss = 1.3417
I1028 03:51:23.898564  9023 solver.cpp:241]     Train net output #0: loss = 1.3417 (* 1 = 1.3417 loss)
I1028 03:51:23.898581  9023 sgd_solver.cpp:105] Iteration 126040, lr = 0.00197302
I1028 03:51:55.471647  9023 solver.cpp:222] Iteration 126080 (1.26695 iter/s, 31.5719s/40 iters), loss = 1.51704
I1028 03:51:55.471845  9023 solver.cpp:241]     Train net output #0: loss = 1.51704 (* 1 = 1.51704 loss)
I1028 03:51:55.471869  9023 sgd_solver.cpp:105] Iteration 126080, lr = 0.00197086
I1028 03:52:35.607106  9023 solver.cpp:222] Iteration 126120 (0.996667 iter/s, 40.1338s/40 iters), loss = 1.45384
I1028 03:52:35.607316  9023 solver.cpp:241]     Train net output #0: loss = 1.45384 (* 1 = 1.45384 loss)
I1028 03:52:35.607333  9023 sgd_solver.cpp:105] Iteration 126120, lr = 0.00196871
I1028 03:53:06.427207  9023 solver.cpp:222] Iteration 126160 (1.29791 iter/s, 30.8187s/40 iters), loss = 1.76484
I1028 03:53:06.427520  9023 solver.cpp:241]     Train net output #0: loss = 1.76484 (* 1 = 1.76484 loss)
I1028 03:53:06.427549  9023 sgd_solver.cpp:105] Iteration 126160, lr = 0.00196655
I1028 03:53:38.272577  9023 solver.cpp:222] Iteration 126200 (1.25613 iter/s, 31.8439s/40 iters), loss = 1.40156
I1028 03:53:38.272804  9023 solver.cpp:241]     Train net output #0: loss = 1.40156 (* 1 = 1.40156 loss)
I1028 03:53:38.272826  9023 sgd_solver.cpp:105] Iteration 126200, lr = 0.0019644
I1028 03:54:09.663108  9023 solver.cpp:222] Iteration 126240 (1.27433 iter/s, 31.3891s/40 iters), loss = 1.473
I1028 03:54:09.663319  9023 solver.cpp:241]     Train net output #0: loss = 1.473 (* 1 = 1.473 loss)
I1028 03:54:09.663336  9023 sgd_solver.cpp:105] Iteration 126240, lr = 0.00196225
I1028 03:54:40.996305  9023 solver.cpp:222] Iteration 126280 (1.27666 iter/s, 31.3318s/40 iters), loss = 1.30461
I1028 03:54:40.996493  9023 solver.cpp:241]     Train net output #0: loss = 1.30461 (* 1 = 1.30461 loss)
I1028 03:54:40.996510  9023 sgd_solver.cpp:105] Iteration 126280, lr = 0.0019601
I1028 03:55:59.895906  9023 solver.cpp:222] Iteration 126320 (0.506994 iter/s, 78.8965s/40 iters), loss = 1.7039
I1028 03:55:59.896114  9023 solver.cpp:241]     Train net output #0: loss = 1.7039 (* 1 = 1.7039 loss)
I1028 03:55:59.896131  9023 sgd_solver.cpp:105] Iteration 126320, lr = 0.00195794
I1028 03:56:30.150884  9023 solver.cpp:222] Iteration 126360 (1.32215 iter/s, 30.2536s/40 iters), loss = 1.41017
I1028 03:56:30.151060  9023 solver.cpp:241]     Train net output #0: loss = 1.41017 (* 1 = 1.41017 loss)
I1028 03:56:30.151075  9023 sgd_solver.cpp:105] Iteration 126360, lr = 0.00195579
I1028 03:57:00.783793  9023 solver.cpp:222] Iteration 126400 (1.30584 iter/s, 30.6316s/40 iters), loss = 1.83149
I1028 03:57:00.783983  9023 solver.cpp:241]     Train net output #0: loss = 1.83149 (* 1 = 1.83149 loss)
I1028 03:57:00.784000  9023 sgd_solver.cpp:105] Iteration 126400, lr = 0.00195364
I1028 03:57:31.428488  9023 solver.cpp:222] Iteration 126440 (1.30534 iter/s, 30.6433s/40 iters), loss = 1.2129
I1028 03:57:31.428678  9023 solver.cpp:241]     Train net output #0: loss = 1.2129 (* 1 = 1.2129 loss)
I1028 03:57:31.428694  9023 sgd_solver.cpp:105] Iteration 126440, lr = 0.00195149
I1028 03:58:02.368516  9023 solver.cpp:222] Iteration 126480 (1.29288 iter/s, 30.9387s/40 iters), loss = 1.66401
I1028 03:58:02.368690  9023 solver.cpp:241]     Train net output #0: loss = 1.66401 (* 1 = 1.66401 loss)
I1028 03:58:02.368706  9023 sgd_solver.cpp:105] Iteration 126480, lr = 0.00194934
I1028 03:58:17.513711  9023 solver.cpp:334] Iteration 126500, Testing net (#0)
I1028 03:58:48.958768  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5696
I1028 03:58:48.958961  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79828
I1028 03:58:48.958976  9023 solver.cpp:401]     Test net output #2: loss = 1.91232 (* 1 = 1.91232 loss)
I1028 03:59:05.080574  9023 solver.cpp:222] Iteration 126520 (0.637862 iter/s, 62.7095s/40 iters), loss = 1.25192
I1028 03:59:05.080641  9023 solver.cpp:241]     Train net output #0: loss = 1.25192 (* 1 = 1.25192 loss)
I1028 03:59:05.080655  9023 sgd_solver.cpp:105] Iteration 126520, lr = 0.00194719
I1028 03:59:36.093799  9023 solver.cpp:222] Iteration 126560 (1.28982 iter/s, 31.012s/40 iters), loss = 1.61821
I1028 03:59:36.094066  9023 solver.cpp:241]     Train net output #0: loss = 1.61821 (* 1 = 1.61821 loss)
I1028 03:59:36.094092  9023 sgd_solver.cpp:105] Iteration 126560, lr = 0.00194504
I1028 04:00:07.370591  9023 solver.cpp:222] Iteration 126600 (1.27896 iter/s, 31.2754s/40 iters), loss = 1.37097
I1028 04:00:07.370767  9023 solver.cpp:241]     Train net output #0: loss = 1.37097 (* 1 = 1.37097 loss)
I1028 04:00:07.370784  9023 sgd_solver.cpp:105] Iteration 126600, lr = 0.00194289
I1028 04:00:38.636807  9023 solver.cpp:222] Iteration 126640 (1.27939 iter/s, 31.2649s/40 iters), loss = 1.78208
I1028 04:00:38.636992  9023 solver.cpp:241]     Train net output #0: loss = 1.78208 (* 1 = 1.78208 loss)
I1028 04:00:38.637022  9023 sgd_solver.cpp:105] Iteration 126640, lr = 0.00194074
I1028 04:01:10.474037  9023 solver.cpp:222] Iteration 126680 (1.25645 iter/s, 31.8358s/40 iters), loss = 1.52895
I1028 04:01:10.474313  9023 solver.cpp:241]     Train net output #0: loss = 1.52895 (* 1 = 1.52895 loss)
I1028 04:01:10.474330  9023 sgd_solver.cpp:105] Iteration 126680, lr = 0.0019386
I1028 04:01:41.589982  9023 solver.cpp:222] Iteration 126720 (1.28557 iter/s, 31.1145s/40 iters), loss = 1.46154
I1028 04:01:41.590191  9023 solver.cpp:241]     Train net output #0: loss = 1.46154 (* 1 = 1.46154 loss)
I1028 04:01:41.590209  9023 sgd_solver.cpp:105] Iteration 126720, lr = 0.00193645
I1028 04:02:13.300711  9023 solver.cpp:222] Iteration 126760 (1.26146 iter/s, 31.7093s/40 iters), loss = 1.81296
I1028 04:02:13.300897  9023 solver.cpp:241]     Train net output #0: loss = 1.81296 (* 1 = 1.81296 loss)
I1028 04:02:13.300917  9023 sgd_solver.cpp:105] Iteration 126760, lr = 0.0019343
I1028 04:02:44.356196  9023 solver.cpp:222] Iteration 126800 (1.28807 iter/s, 31.0541s/40 iters), loss = 1.78331
I1028 04:02:44.356403  9023 solver.cpp:241]     Train net output #0: loss = 1.78331 (* 1 = 1.78331 loss)
I1028 04:02:44.356421  9023 sgd_solver.cpp:105] Iteration 126800, lr = 0.00193215
I1028 04:03:15.326467  9023 solver.cpp:222] Iteration 126840 (1.29162 iter/s, 30.9689s/40 iters), loss = 1.47156
I1028 04:03:15.326640  9023 solver.cpp:241]     Train net output #0: loss = 1.47156 (* 1 = 1.47156 loss)
I1028 04:03:15.326656  9023 sgd_solver.cpp:105] Iteration 126840, lr = 0.00193001
I1028 04:03:46.308821  9023 solver.cpp:222] Iteration 126880 (1.29111 iter/s, 30.981s/40 iters), loss = 1.54281
I1028 04:03:46.309034  9023 solver.cpp:241]     Train net output #0: loss = 1.54281 (* 1 = 1.54281 loss)
I1028 04:03:46.309054  9023 sgd_solver.cpp:105] Iteration 126880, lr = 0.00192786
I1028 04:04:17.166738  9023 solver.cpp:222] Iteration 126920 (1.29632 iter/s, 30.8565s/40 iters), loss = 1.72241
I1028 04:04:17.166940  9023 solver.cpp:241]     Train net output #0: loss = 1.72241 (* 1 = 1.72241 loss)
I1028 04:04:17.166956  9023 sgd_solver.cpp:105] Iteration 126920, lr = 0.00192572
I1028 04:04:52.316437  9023 solver.cpp:222] Iteration 126960 (1.13804 iter/s, 35.1482s/40 iters), loss = 1.66997
I1028 04:04:52.316643  9023 solver.cpp:241]     Train net output #0: loss = 1.66997 (* 1 = 1.66997 loss)
I1028 04:04:52.316659  9023 sgd_solver.cpp:105] Iteration 126960, lr = 0.00192357
I1028 04:05:22.472797  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_127000.caffemodel
I1028 04:05:22.506841  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_127000.solverstate
I1028 04:05:22.525416  9023 solver.cpp:334] Iteration 127000, Testing net (#0)
I1028 04:05:53.637189  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 04:05:53.845976  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5662
I1028 04:05:53.846038  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79976
I1028 04:05:53.846052  9023 solver.cpp:401]     Test net output #2: loss = 1.9107 (* 1 = 1.9107 loss)
I1028 04:05:54.620780  9023 solver.cpp:222] Iteration 127000 (0.642036 iter/s, 62.3018s/40 iters), loss = 1.33654
I1028 04:05:54.620847  9023 solver.cpp:241]     Train net output #0: loss = 1.33654 (* 1 = 1.33654 loss)
I1028 04:05:54.620863  9023 sgd_solver.cpp:105] Iteration 127000, lr = 0.00192142
I1028 04:06:25.655622  9023 solver.cpp:222] Iteration 127040 (1.28893 iter/s, 31.0336s/40 iters), loss = 1.44785
I1028 04:06:25.655791  9023 solver.cpp:241]     Train net output #0: loss = 1.44785 (* 1 = 1.44785 loss)
I1028 04:06:25.655807  9023 sgd_solver.cpp:105] Iteration 127040, lr = 0.00191928
I1028 04:06:35.127080  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1028 04:06:56.731091  9023 solver.cpp:222] Iteration 127080 (1.28724 iter/s, 31.0741s/40 iters), loss = 1.79568
I1028 04:06:56.731258  9023 solver.cpp:241]     Train net output #0: loss = 1.79568 (* 1 = 1.79568 loss)
I1028 04:06:56.731307  9023 sgd_solver.cpp:105] Iteration 127080, lr = 0.00191714
I1028 04:07:27.850203  9023 solver.cpp:222] Iteration 127120 (1.28544 iter/s, 31.1178s/40 iters), loss = 1.46625
I1028 04:07:27.850464  9023 solver.cpp:241]     Train net output #0: loss = 1.46625 (* 1 = 1.46625 loss)
I1028 04:07:27.850484  9023 sgd_solver.cpp:105] Iteration 127120, lr = 0.00191499
I1028 04:07:59.158354  9023 solver.cpp:222] Iteration 127160 (1.27768 iter/s, 31.3067s/40 iters), loss = 1.49362
I1028 04:07:59.158553  9023 solver.cpp:241]     Train net output #0: loss = 1.49362 (* 1 = 1.49362 loss)
I1028 04:07:59.158571  9023 sgd_solver.cpp:105] Iteration 127160, lr = 0.00191285
I1028 04:08:30.460571  9023 solver.cpp:222] Iteration 127200 (1.27792 iter/s, 31.3008s/40 iters), loss = 1.51798
I1028 04:08:30.460753  9023 solver.cpp:241]     Train net output #0: loss = 1.51798 (* 1 = 1.51798 loss)
I1028 04:08:30.460769  9023 sgd_solver.cpp:105] Iteration 127200, lr = 0.00191071
I1028 04:09:01.876624  9023 solver.cpp:222] Iteration 127240 (1.27329 iter/s, 31.4147s/40 iters), loss = 1.60807
I1028 04:09:01.876839  9023 solver.cpp:241]     Train net output #0: loss = 1.60807 (* 1 = 1.60807 loss)
I1028 04:09:01.876864  9023 sgd_solver.cpp:105] Iteration 127240, lr = 0.00190856
I1028 04:09:32.960017  9023 solver.cpp:222] Iteration 127280 (1.28692 iter/s, 31.082s/40 iters), loss = 1.87344
I1028 04:09:32.960189  9023 solver.cpp:241]     Train net output #0: loss = 1.87344 (* 1 = 1.87344 loss)
I1028 04:09:32.960206  9023 sgd_solver.cpp:105] Iteration 127280, lr = 0.00190642
I1028 04:10:03.939501  9023 solver.cpp:222] Iteration 127320 (1.29123 iter/s, 30.9781s/40 iters), loss = 1.82236
I1028 04:10:03.939672  9023 solver.cpp:241]     Train net output #0: loss = 1.82236 (* 1 = 1.82236 loss)
I1028 04:10:03.939688  9023 sgd_solver.cpp:105] Iteration 127320, lr = 0.00190428
I1028 04:10:34.754465  9023 solver.cpp:222] Iteration 127360 (1.29813 iter/s, 30.8136s/40 iters), loss = 1.343
I1028 04:10:34.754647  9023 solver.cpp:241]     Train net output #0: loss = 1.343 (* 1 = 1.343 loss)
I1028 04:10:34.754663  9023 sgd_solver.cpp:105] Iteration 127360, lr = 0.00190214
I1028 04:11:10.154171  9023 solver.cpp:222] Iteration 127400 (1.13 iter/s, 35.3982s/40 iters), loss = 1.24983
I1028 04:11:10.154438  9023 solver.cpp:241]     Train net output #0: loss = 1.24983 (* 1 = 1.24983 loss)
I1028 04:11:10.154469  9023 sgd_solver.cpp:105] Iteration 127400, lr = 0.0019
I1028 04:11:42.374970  9023 solver.cpp:222] Iteration 127440 (1.24149 iter/s, 32.2193s/40 iters), loss = 1.4576
I1028 04:11:42.375183  9023 solver.cpp:241]     Train net output #0: loss = 1.4576 (* 1 = 1.4576 loss)
I1028 04:11:42.375201  9023 sgd_solver.cpp:105] Iteration 127440, lr = 0.00189786
I1028 04:12:13.264777  9023 solver.cpp:222] Iteration 127480 (1.29498 iter/s, 30.8884s/40 iters), loss = 1.2464
I1028 04:12:13.264957  9023 solver.cpp:241]     Train net output #0: loss = 1.2464 (* 1 = 1.2464 loss)
I1028 04:12:13.264973  9023 sgd_solver.cpp:105] Iteration 127480, lr = 0.00189572
I1028 04:12:28.008399  9023 solver.cpp:334] Iteration 127500, Testing net (#0)
I1028 04:12:59.437072  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57452
I1028 04:12:59.437263  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8004
I1028 04:12:59.437279  9023 solver.cpp:401]     Test net output #2: loss = 1.88796 (* 1 = 1.88796 loss)
I1028 04:13:15.672433  9023 solver.cpp:222] Iteration 127520 (0.640973 iter/s, 62.4051s/40 iters), loss = 1.50954
I1028 04:13:15.672505  9023 solver.cpp:241]     Train net output #0: loss = 1.50954 (* 1 = 1.50954 loss)
I1028 04:13:15.672520  9023 sgd_solver.cpp:105] Iteration 127520, lr = 0.00189358
I1028 04:13:46.674433  9023 solver.cpp:222] Iteration 127560 (1.29029 iter/s, 31.0008s/40 iters), loss = 1.70782
I1028 04:13:46.674631  9023 solver.cpp:241]     Train net output #0: loss = 1.70782 (* 1 = 1.70782 loss)
I1028 04:13:46.674646  9023 sgd_solver.cpp:105] Iteration 127560, lr = 0.00189144
I1028 04:14:17.464756  9023 solver.cpp:222] Iteration 127600 (1.29917 iter/s, 30.789s/40 iters), loss = 1.34989
I1028 04:14:17.465090  9023 solver.cpp:241]     Train net output #0: loss = 1.34989 (* 1 = 1.34989 loss)
I1028 04:14:17.465126  9023 sgd_solver.cpp:105] Iteration 127600, lr = 0.0018893
I1028 04:14:48.391865  9023 solver.cpp:222] Iteration 127640 (1.29343 iter/s, 30.9256s/40 iters), loss = 1.52364
I1028 04:14:48.392052  9023 solver.cpp:241]     Train net output #0: loss = 1.52364 (* 1 = 1.52364 loss)
I1028 04:14:48.392067  9023 sgd_solver.cpp:105] Iteration 127640, lr = 0.00188716
I1028 04:15:19.450989  9023 solver.cpp:222] Iteration 127680 (1.28792 iter/s, 31.0578s/40 iters), loss = 1.54328
I1028 04:15:19.451174  9023 solver.cpp:241]     Train net output #0: loss = 1.54328 (* 1 = 1.54328 loss)
I1028 04:15:19.451189  9023 sgd_solver.cpp:105] Iteration 127680, lr = 0.00188502
I1028 04:15:50.237378  9023 solver.cpp:222] Iteration 127720 (1.29933 iter/s, 30.785s/40 iters), loss = 1.49951
I1028 04:15:50.237555  9023 solver.cpp:241]     Train net output #0: loss = 1.49951 (* 1 = 1.49951 loss)
I1028 04:15:50.237571  9023 sgd_solver.cpp:105] Iteration 127720, lr = 0.00188288
I1028 04:16:21.358417  9023 solver.cpp:222] Iteration 127760 (1.28536 iter/s, 31.1197s/40 iters), loss = 1.61401
I1028 04:16:21.358613  9023 solver.cpp:241]     Train net output #0: loss = 1.61401 (* 1 = 1.61401 loss)
I1028 04:16:21.358628  9023 sgd_solver.cpp:105] Iteration 127760, lr = 0.00188075
I1028 04:16:53.200687  9023 solver.cpp:222] Iteration 127800 (1.25625 iter/s, 31.8409s/40 iters), loss = 1.29439
I1028 04:16:53.200876  9023 solver.cpp:241]     Train net output #0: loss = 1.29439 (* 1 = 1.29439 loss)
I1028 04:16:53.200892  9023 sgd_solver.cpp:105] Iteration 127800, lr = 0.00187861
I1028 04:17:25.281908  9023 solver.cpp:222] Iteration 127840 (1.24689 iter/s, 32.0798s/40 iters), loss = 1.36997
I1028 04:17:25.282142  9023 solver.cpp:241]     Train net output #0: loss = 1.36997 (* 1 = 1.36997 loss)
I1028 04:17:25.282166  9023 sgd_solver.cpp:105] Iteration 127840, lr = 0.00187647
I1028 04:17:56.790017  9023 solver.cpp:222] Iteration 127880 (1.26957 iter/s, 31.5067s/40 iters), loss = 1.56937
I1028 04:17:56.790230  9023 solver.cpp:241]     Train net output #0: loss = 1.56937 (* 1 = 1.56937 loss)
I1028 04:17:56.790246  9023 sgd_solver.cpp:105] Iteration 127880, lr = 0.00187434
I1028 04:18:27.939863  9023 solver.cpp:222] Iteration 127920 (1.28417 iter/s, 31.1485s/40 iters), loss = 1.67505
I1028 04:18:27.940032  9023 solver.cpp:241]     Train net output #0: loss = 1.67505 (* 1 = 1.67505 loss)
I1028 04:18:27.940050  9023 sgd_solver.cpp:105] Iteration 127920, lr = 0.0018722
I1028 04:18:59.093153  9023 solver.cpp:222] Iteration 127960 (1.28403 iter/s, 31.152s/40 iters), loss = 1.2049
I1028 04:18:59.093339  9023 solver.cpp:241]     Train net output #0: loss = 1.2049 (* 1 = 1.2049 loss)
I1028 04:18:59.093356  9023 sgd_solver.cpp:105] Iteration 127960, lr = 0.00187006
I1028 04:19:29.536872  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_128000.caffemodel
I1028 04:19:29.569744  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_128000.solverstate
I1028 04:19:29.590565  9023 solver.cpp:334] Iteration 128000, Testing net (#0)
I1028 04:20:00.816377  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 04:20:01.027120  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56708
I1028 04:20:01.027181  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80012
I1028 04:20:01.027195  9023 solver.cpp:401]     Test net output #2: loss = 1.88832 (* 1 = 1.88832 loss)
I1028 04:20:01.794945  9023 solver.cpp:222] Iteration 128000 (0.637966 iter/s, 62.6993s/40 iters), loss = 1.54655
I1028 04:20:01.795001  9023 solver.cpp:241]     Train net output #0: loss = 1.54655 (* 1 = 1.54655 loss)
I1028 04:20:01.795017  9023 sgd_solver.cpp:105] Iteration 128000, lr = 0.00186793
I1028 04:20:33.078567  9023 solver.cpp:222] Iteration 128040 (1.27868 iter/s, 31.2824s/40 iters), loss = 1.3449
I1028 04:20:33.078852  9023 solver.cpp:241]     Train net output #0: loss = 1.3449 (* 1 = 1.3449 loss)
I1028 04:20:33.078878  9023 sgd_solver.cpp:105] Iteration 128040, lr = 0.00186579
I1028 04:21:04.666618  9023 solver.cpp:222] Iteration 128080 (1.26636 iter/s, 31.5866s/40 iters), loss = 1.45226
I1028 04:21:04.666828  9023 solver.cpp:241]     Train net output #0: loss = 1.45226 (* 1 = 1.45226 loss)
I1028 04:21:04.666844  9023 sgd_solver.cpp:105] Iteration 128080, lr = 0.00186366
I1028 04:21:36.036922  9023 solver.cpp:222] Iteration 128120 (1.27515 iter/s, 31.3689s/40 iters), loss = 1.25988
I1028 04:21:36.037149  9023 solver.cpp:241]     Train net output #0: loss = 1.25988 (* 1 = 1.25988 loss)
I1028 04:21:36.037174  9023 sgd_solver.cpp:105] Iteration 128120, lr = 0.00186153
I1028 04:22:07.461776  9023 solver.cpp:222] Iteration 128160 (1.27294 iter/s, 31.4234s/40 iters), loss = 1.34177
I1028 04:22:07.461957  9023 solver.cpp:241]     Train net output #0: loss = 1.34177 (* 1 = 1.34177 loss)
I1028 04:22:07.461974  9023 sgd_solver.cpp:105] Iteration 128160, lr = 0.00185939
I1028 04:22:38.182396  9023 solver.cpp:222] Iteration 128200 (1.30211 iter/s, 30.7193s/40 iters), loss = 1.42304
I1028 04:22:38.182561  9023 solver.cpp:241]     Train net output #0: loss = 1.42304 (* 1 = 1.42304 loss)
I1028 04:22:38.182579  9023 sgd_solver.cpp:105] Iteration 128200, lr = 0.00185726
I1028 04:23:09.358798  9023 solver.cpp:222] Iteration 128240 (1.28308 iter/s, 31.1751s/40 iters), loss = 1.25463
I1028 04:23:09.358958  9023 solver.cpp:241]     Train net output #0: loss = 1.25463 (* 1 = 1.25463 loss)
I1028 04:23:09.358975  9023 sgd_solver.cpp:105] Iteration 128240, lr = 0.00185513
I1028 04:23:40.916043  9023 solver.cpp:222] Iteration 128280 (1.26759 iter/s, 31.5559s/40 iters), loss = 1.37256
I1028 04:23:40.916200  9023 solver.cpp:241]     Train net output #0: loss = 1.37256 (* 1 = 1.37256 loss)
I1028 04:23:40.916216  9023 sgd_solver.cpp:105] Iteration 128280, lr = 0.001853
I1028 04:24:12.619199  9023 solver.cpp:222] Iteration 128320 (1.26176 iter/s, 31.7018s/40 iters), loss = 1.34653
I1028 04:24:12.619390  9023 solver.cpp:241]     Train net output #0: loss = 1.34653 (* 1 = 1.34653 loss)
I1028 04:24:12.619406  9023 sgd_solver.cpp:105] Iteration 128320, lr = 0.00185086
I1028 04:24:43.819103  9023 solver.cpp:222] Iteration 128360 (1.28211 iter/s, 31.1985s/40 iters), loss = 1.36829
I1028 04:24:43.819300  9023 solver.cpp:241]     Train net output #0: loss = 1.36829 (* 1 = 1.36829 loss)
I1028 04:24:43.819317  9023 sgd_solver.cpp:105] Iteration 128360, lr = 0.00184873
I1028 04:25:14.963266  9023 solver.cpp:222] Iteration 128400 (1.28441 iter/s, 31.1428s/40 iters), loss = 1.37929
I1028 04:25:14.963462  9023 solver.cpp:241]     Train net output #0: loss = 1.37929 (* 1 = 1.37929 loss)
I1028 04:25:14.963479  9023 sgd_solver.cpp:105] Iteration 128400, lr = 0.0018466
I1028 04:25:49.273185  9023 solver.cpp:222] Iteration 128440 (1.16589 iter/s, 34.3084s/40 iters), loss = 1.62486
I1028 04:25:49.273387  9023 solver.cpp:241]     Train net output #0: loss = 1.62486 (* 1 = 1.62486 loss)
I1028 04:25:49.273411  9023 sgd_solver.cpp:105] Iteration 128440, lr = 0.00184447
I1028 04:26:22.545037  9023 solver.cpp:222] Iteration 128480 (1.20227 iter/s, 33.2704s/40 iters), loss = 1.73062
I1028 04:26:22.545254  9023 solver.cpp:241]     Train net output #0: loss = 1.73062 (* 1 = 1.73062 loss)
I1028 04:26:22.545271  9023 sgd_solver.cpp:105] Iteration 128480, lr = 0.00184234
I1028 04:26:36.931150  9023 solver.cpp:334] Iteration 128500, Testing net (#0)
I1028 04:27:08.260398  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57164
I1028 04:27:08.260588  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80056
I1028 04:27:08.260603  9023 solver.cpp:401]     Test net output #2: loss = 1.90521 (* 1 = 1.90521 loss)
I1028 04:27:24.602363  9023 solver.cpp:222] Iteration 128520 (0.644592 iter/s, 62.0548s/40 iters), loss = 1.8322
I1028 04:27:24.602448  9023 solver.cpp:241]     Train net output #0: loss = 1.8322 (* 1 = 1.8322 loss)
I1028 04:27:24.602491  9023 sgd_solver.cpp:105] Iteration 128520, lr = 0.00184021
I1028 04:28:09.757731  9023 solver.cpp:222] Iteration 128560 (0.885866 iter/s, 45.1536s/40 iters), loss = 1.57258
I1028 04:28:09.757964  9023 solver.cpp:241]     Train net output #0: loss = 1.57258 (* 1 = 1.57258 loss)
I1028 04:28:09.757982  9023 sgd_solver.cpp:105] Iteration 128560, lr = 0.00183808
I1028 04:28:40.964282  9023 solver.cpp:222] Iteration 128600 (1.28184 iter/s, 31.2051s/40 iters), loss = 1.11638
I1028 04:28:40.964473  9023 solver.cpp:241]     Train net output #0: loss = 1.11638 (* 1 = 1.11638 loss)
I1028 04:28:40.964489  9023 sgd_solver.cpp:105] Iteration 128600, lr = 0.00183595
I1028 04:29:12.311609  9023 solver.cpp:222] Iteration 128640 (1.27608 iter/s, 31.346s/40 iters), loss = 1.14381
I1028 04:29:12.311774  9023 solver.cpp:241]     Train net output #0: loss = 1.14381 (* 1 = 1.14381 loss)
I1028 04:29:12.311790  9023 sgd_solver.cpp:105] Iteration 128640, lr = 0.00183383
I1028 04:29:55.990262  9023 solver.cpp:222] Iteration 128680 (0.915817 iter/s, 43.6768s/40 iters), loss = 1.60277
I1028 04:29:55.990459  9023 solver.cpp:241]     Train net output #0: loss = 1.60277 (* 1 = 1.60277 loss)
I1028 04:29:55.990475  9023 sgd_solver.cpp:105] Iteration 128680, lr = 0.0018317
I1028 04:30:26.965879  9023 solver.cpp:222] Iteration 128720 (1.29139 iter/s, 30.9743s/40 iters), loss = 1.4527
I1028 04:30:26.966092  9023 solver.cpp:241]     Train net output #0: loss = 1.4527 (* 1 = 1.4527 loss)
I1028 04:30:26.966111  9023 sgd_solver.cpp:105] Iteration 128720, lr = 0.00182957
I1028 04:30:57.490036  9023 solver.cpp:222] Iteration 128760 (1.3105 iter/s, 30.5228s/40 iters), loss = 1.30199
I1028 04:30:57.490205  9023 solver.cpp:241]     Train net output #0: loss = 1.30199 (* 1 = 1.30199 loss)
I1028 04:30:57.490221  9023 sgd_solver.cpp:105] Iteration 128760, lr = 0.00182744
I1028 04:31:28.537489  9023 solver.cpp:222] Iteration 128800 (1.28841 iter/s, 31.0461s/40 iters), loss = 1.60189
I1028 04:31:28.537701  9023 solver.cpp:241]     Train net output #0: loss = 1.60189 (* 1 = 1.60189 loss)
I1028 04:31:28.537717  9023 sgd_solver.cpp:105] Iteration 128800, lr = 0.00182532
I1028 04:31:59.703371  9023 solver.cpp:222] Iteration 128840 (1.28351 iter/s, 31.1645s/40 iters), loss = 1.5291
I1028 04:31:59.703579  9023 solver.cpp:241]     Train net output #0: loss = 1.5291 (* 1 = 1.5291 loss)
I1028 04:31:59.703595  9023 sgd_solver.cpp:105] Iteration 128840, lr = 0.00182319
I1028 04:32:30.997365  9023 solver.cpp:222] Iteration 128880 (1.27826 iter/s, 31.2926s/40 iters), loss = 1.26777
I1028 04:32:30.997553  9023 solver.cpp:241]     Train net output #0: loss = 1.26777 (* 1 = 1.26777 loss)
I1028 04:32:30.997570  9023 sgd_solver.cpp:105] Iteration 128880, lr = 0.00182106
I1028 04:33:02.038478  9023 solver.cpp:222] Iteration 128920 (1.28867 iter/s, 31.0398s/40 iters), loss = 1.99145
I1028 04:33:02.038676  9023 solver.cpp:241]     Train net output #0: loss = 1.99145 (* 1 = 1.99145 loss)
I1028 04:33:02.038692  9023 sgd_solver.cpp:105] Iteration 128920, lr = 0.00181894
I1028 04:33:33.248354  9023 solver.cpp:222] Iteration 128960 (1.2817 iter/s, 31.2085s/40 iters), loss = 1.43822
I1028 04:33:33.248543  9023 solver.cpp:241]     Train net output #0: loss = 1.43822 (* 1 = 1.43822 loss)
I1028 04:33:33.248561  9023 sgd_solver.cpp:105] Iteration 128960, lr = 0.00181681
I1028 04:34:03.693773  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_129000.caffemodel
I1028 04:34:03.726779  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_129000.solverstate
I1028 04:34:03.744850  9023 solver.cpp:334] Iteration 129000, Testing net (#0)
I1028 04:34:34.978039  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 04:34:35.185912  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56732
I1028 04:34:35.185969  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.799439
I1028 04:34:35.185983  9023 solver.cpp:401]     Test net output #2: loss = 1.90964 (* 1 = 1.90964 loss)
I1028 04:34:35.955198  9023 solver.cpp:222] Iteration 129000 (0.637915 iter/s, 62.7043s/40 iters), loss = 1.73366
I1028 04:34:35.955262  9023 solver.cpp:241]     Train net output #0: loss = 1.73366 (* 1 = 1.73366 loss)
I1028 04:34:35.955278  9023 sgd_solver.cpp:105] Iteration 129000, lr = 0.00181469
I1028 04:35:07.326164  9023 solver.cpp:222] Iteration 129040 (1.27512 iter/s, 31.3697s/40 iters), loss = 1.72156
I1028 04:35:07.326561  9023 solver.cpp:241]     Train net output #0: loss = 1.72156 (* 1 = 1.72156 loss)
I1028 04:35:07.326578  9023 sgd_solver.cpp:105] Iteration 129040, lr = 0.00181256
I1028 04:35:38.300617  9023 solver.cpp:222] Iteration 129080 (1.29145 iter/s, 30.9729s/40 iters), loss = 1.39499
I1028 04:35:38.300791  9023 solver.cpp:241]     Train net output #0: loss = 1.39499 (* 1 = 1.39499 loss)
I1028 04:35:38.300807  9023 sgd_solver.cpp:105] Iteration 129080, lr = 0.00181044
I1028 04:36:09.367869  9023 solver.cpp:222] Iteration 129120 (1.28759 iter/s, 31.0659s/40 iters), loss = 1.41405
I1028 04:36:09.368057  9023 solver.cpp:241]     Train net output #0: loss = 1.41405 (* 1 = 1.41405 loss)
I1028 04:36:09.368072  9023 sgd_solver.cpp:105] Iteration 129120, lr = 0.00180832
I1028 04:36:40.382315  9023 solver.cpp:222] Iteration 129160 (1.28978 iter/s, 31.0131s/40 iters), loss = 1.45953
I1028 04:36:40.382498  9023 solver.cpp:241]     Train net output #0: loss = 1.45953 (* 1 = 1.45953 loss)
I1028 04:36:40.382514  9023 sgd_solver.cpp:105] Iteration 129160, lr = 0.00180619
I1028 04:37:11.171970  9023 solver.cpp:222] Iteration 129200 (1.29919 iter/s, 30.7883s/40 iters), loss = 1.6677
I1028 04:37:11.172142  9023 solver.cpp:241]     Train net output #0: loss = 1.6677 (* 1 = 1.6677 loss)
I1028 04:37:11.172158  9023 sgd_solver.cpp:105] Iteration 129200, lr = 0.00180407
I1028 04:37:41.976351  9023 solver.cpp:222] Iteration 129240 (1.29857 iter/s, 30.8031s/40 iters), loss = 1.71431
I1028 04:37:41.976514  9023 solver.cpp:241]     Train net output #0: loss = 1.71431 (* 1 = 1.71431 loss)
I1028 04:37:41.976536  9023 sgd_solver.cpp:105] Iteration 129240, lr = 0.00180195
I1028 04:38:13.088485  9023 solver.cpp:222] Iteration 129280 (1.28573 iter/s, 31.1108s/40 iters), loss = 1.32615
I1028 04:38:13.088665  9023 solver.cpp:241]     Train net output #0: loss = 1.32615 (* 1 = 1.32615 loss)
I1028 04:38:13.088683  9023 sgd_solver.cpp:105] Iteration 129280, lr = 0.00179983
I1028 04:38:44.199954  9023 solver.cpp:222] Iteration 129320 (1.28576 iter/s, 31.1101s/40 iters), loss = 1.47442
I1028 04:38:44.200143  9023 solver.cpp:241]     Train net output #0: loss = 1.47442 (* 1 = 1.47442 loss)
I1028 04:38:44.200160  9023 sgd_solver.cpp:105] Iteration 129320, lr = 0.0017977
I1028 04:39:15.549412  9023 solver.cpp:222] Iteration 129360 (1.276 iter/s, 31.3481s/40 iters), loss = 1.53609
I1028 04:39:15.549604  9023 solver.cpp:241]     Train net output #0: loss = 1.53609 (* 1 = 1.53609 loss)
I1028 04:39:15.549620  9023 sgd_solver.cpp:105] Iteration 129360, lr = 0.00179558
I1028 04:39:46.873257  9023 solver.cpp:222] Iteration 129400 (1.27704 iter/s, 31.3224s/40 iters), loss = 1.3265
I1028 04:39:46.873468  9023 solver.cpp:241]     Train net output #0: loss = 1.3265 (* 1 = 1.3265 loss)
I1028 04:39:46.873492  9023 sgd_solver.cpp:105] Iteration 129400, lr = 0.00179346
I1028 04:40:18.392529  9023 solver.cpp:222] Iteration 129440 (1.26912 iter/s, 31.5179s/40 iters), loss = 1.54544
I1028 04:40:18.392717  9023 solver.cpp:241]     Train net output #0: loss = 1.54544 (* 1 = 1.54544 loss)
I1028 04:40:18.392734  9023 sgd_solver.cpp:105] Iteration 129440, lr = 0.00179134
I1028 04:40:49.995489  9023 solver.cpp:222] Iteration 129480 (1.26576 iter/s, 31.6016s/40 iters), loss = 1.60657
I1028 04:40:49.995661  9023 solver.cpp:241]     Train net output #0: loss = 1.60657 (* 1 = 1.60657 loss)
I1028 04:40:49.995679  9023 sgd_solver.cpp:105] Iteration 129480, lr = 0.00178922
I1028 04:41:05.037605  9023 solver.cpp:334] Iteration 129500, Testing net (#0)
I1028 04:41:43.479703  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56968
I1028 04:41:43.479979  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79764
I1028 04:41:43.480000  9023 solver.cpp:401]     Test net output #2: loss = 1.89617 (* 1 = 1.89617 loss)
I1028 04:41:59.532634  9023 solver.cpp:222] Iteration 129520 (0.575255 iter/s, 69.5344s/40 iters), loss = 1.45964
I1028 04:41:59.532701  9023 solver.cpp:241]     Train net output #0: loss = 1.45964 (* 1 = 1.45964 loss)
I1028 04:41:59.532716  9023 sgd_solver.cpp:105] Iteration 129520, lr = 0.0017871
I1028 04:42:26.139087  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1028 04:42:29.851716  9023 solver.cpp:222] Iteration 129560 (1.31935 iter/s, 30.3179s/40 iters), loss = 1.72944
I1028 04:42:29.851788  9023 solver.cpp:241]     Train net output #0: loss = 1.72944 (* 1 = 1.72944 loss)
I1028 04:42:29.851804  9023 sgd_solver.cpp:105] Iteration 129560, lr = 0.00178499
I1028 04:43:00.500753  9023 solver.cpp:222] Iteration 129600 (1.30515 iter/s, 30.6478s/40 iters), loss = 1.63916
I1028 04:43:00.500954  9023 solver.cpp:241]     Train net output #0: loss = 1.63916 (* 1 = 1.63916 loss)
I1028 04:43:00.500970  9023 sgd_solver.cpp:105] Iteration 129600, lr = 0.00178287
I1028 04:43:31.242429  9023 solver.cpp:222] Iteration 129640 (1.30122 iter/s, 30.7403s/40 iters), loss = 1.57313
I1028 04:43:31.242620  9023 solver.cpp:241]     Train net output #0: loss = 1.57313 (* 1 = 1.57313 loss)
I1028 04:43:31.242645  9023 sgd_solver.cpp:105] Iteration 129640, lr = 0.00178075
I1028 04:44:02.261374  9023 solver.cpp:222] Iteration 129680 (1.28959 iter/s, 31.0176s/40 iters), loss = 1.45082
I1028 04:44:02.261543  9023 solver.cpp:241]     Train net output #0: loss = 1.45082 (* 1 = 1.45082 loss)
I1028 04:44:02.261560  9023 sgd_solver.cpp:105] Iteration 129680, lr = 0.00177863
I1028 04:44:33.005421  9023 solver.cpp:222] Iteration 129720 (1.30112 iter/s, 30.7427s/40 iters), loss = 1.60013
I1028 04:44:33.005612  9023 solver.cpp:241]     Train net output #0: loss = 1.60013 (* 1 = 1.60013 loss)
I1028 04:44:33.005630  9023 sgd_solver.cpp:105] Iteration 129720, lr = 0.00177651
I1028 04:45:03.861402  9023 solver.cpp:222] Iteration 129760 (1.2964 iter/s, 30.8546s/40 iters), loss = 1.70455
I1028 04:45:03.861584  9023 solver.cpp:241]     Train net output #0: loss = 1.70455 (* 1 = 1.70455 loss)
I1028 04:45:03.861601  9023 sgd_solver.cpp:105] Iteration 129760, lr = 0.0017744
I1028 04:45:35.516208  9023 solver.cpp:222] Iteration 129800 (1.26369 iter/s, 31.6534s/40 iters), loss = 1.61478
I1028 04:45:35.516396  9023 solver.cpp:241]     Train net output #0: loss = 1.61478 (* 1 = 1.61478 loss)
I1028 04:45:35.516417  9023 sgd_solver.cpp:105] Iteration 129800, lr = 0.00177228
I1028 04:46:06.234838  9023 solver.cpp:222] Iteration 129840 (1.3022 iter/s, 30.7173s/40 iters), loss = 1.3911
I1028 04:46:06.235023  9023 solver.cpp:241]     Train net output #0: loss = 1.3911 (* 1 = 1.3911 loss)
I1028 04:46:06.235039  9023 sgd_solver.cpp:105] Iteration 129840, lr = 0.00177017
I1028 04:46:36.862941  9023 solver.cpp:222] Iteration 129880 (1.30605 iter/s, 30.6268s/40 iters), loss = 1.57525
I1028 04:46:36.863109  9023 solver.cpp:241]     Train net output #0: loss = 1.57525 (* 1 = 1.57525 loss)
I1028 04:46:36.863126  9023 sgd_solver.cpp:105] Iteration 129880, lr = 0.00176805
I1028 04:47:07.618125  9023 solver.cpp:222] Iteration 129920 (1.30065 iter/s, 30.7539s/40 iters), loss = 1.56007
I1028 04:47:07.618335  9023 solver.cpp:241]     Train net output #0: loss = 1.56007 (* 1 = 1.56007 loss)
I1028 04:47:07.618353  9023 sgd_solver.cpp:105] Iteration 129920, lr = 0.00176593
I1028 04:47:39.143354  9023 solver.cpp:222] Iteration 129960 (1.26888 iter/s, 31.5238s/40 iters), loss = 1.59223
I1028 04:47:39.143523  9023 solver.cpp:241]     Train net output #0: loss = 1.59223 (* 1 = 1.59223 loss)
I1028 04:47:39.143539  9023 sgd_solver.cpp:105] Iteration 129960, lr = 0.00176382
I1028 04:48:09.682818  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_130000.caffemodel
I1028 04:48:09.725106  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_130000.solverstate
I1028 04:48:09.742179  9023 solver.cpp:334] Iteration 130000, Testing net (#0)
I1028 04:48:40.821738  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 04:48:41.031530  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57144
I1028 04:48:41.031592  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.803639
I1028 04:48:41.031606  9023 solver.cpp:401]     Test net output #2: loss = 1.90088 (* 1 = 1.90088 loss)
I1028 04:48:41.797849  9023 solver.cpp:222] Iteration 130000 (0.638447 iter/s, 62.652s/40 iters), loss = 1.40329
I1028 04:48:41.797911  9023 solver.cpp:241]     Train net output #0: loss = 1.40329 (* 1 = 1.40329 loss)
I1028 04:48:41.797926  9023 sgd_solver.cpp:105] Iteration 130000, lr = 0.00176171
I1028 04:49:13.434856  9023 solver.cpp:222] Iteration 130040 (1.26439 iter/s, 31.6357s/40 iters), loss = 1.58233
I1028 04:49:13.435093  9023 solver.cpp:241]     Train net output #0: loss = 1.58233 (* 1 = 1.58233 loss)
I1028 04:49:13.435117  9023 sgd_solver.cpp:105] Iteration 130040, lr = 0.00175959
I1028 04:49:45.031534  9023 solver.cpp:222] Iteration 130080 (1.26601 iter/s, 31.5952s/40 iters), loss = 1.39014
I1028 04:49:45.031751  9023 solver.cpp:241]     Train net output #0: loss = 1.39014 (* 1 = 1.39014 loss)
I1028 04:49:45.031767  9023 sgd_solver.cpp:105] Iteration 130080, lr = 0.00175748
I1028 04:50:16.426285  9023 solver.cpp:222] Iteration 130120 (1.27416 iter/s, 31.3933s/40 iters), loss = 1.73939
I1028 04:50:16.426487  9023 solver.cpp:241]     Train net output #0: loss = 1.73939 (* 1 = 1.73939 loss)
I1028 04:50:16.426504  9023 sgd_solver.cpp:105] Iteration 130120, lr = 0.00175536
I1028 04:50:48.699003  9023 solver.cpp:222] Iteration 130160 (1.23949 iter/s, 32.2713s/40 iters), loss = 1.32783
I1028 04:50:48.699164  9023 solver.cpp:241]     Train net output #0: loss = 1.32783 (* 1 = 1.32783 loss)
I1028 04:50:48.699180  9023 sgd_solver.cpp:105] Iteration 130160, lr = 0.00175325
I1028 04:51:19.432751  9023 solver.cpp:222] Iteration 130200 (1.30156 iter/s, 30.7324s/40 iters), loss = 1.81771
I1028 04:51:19.432941  9023 solver.cpp:241]     Train net output #0: loss = 1.81771 (* 1 = 1.81771 loss)
I1028 04:51:19.432957  9023 sgd_solver.cpp:105] Iteration 130200, lr = 0.00175114
I1028 04:51:50.144402  9023 solver.cpp:222] Iteration 130240 (1.30249 iter/s, 30.7103s/40 iters), loss = 1.44625
I1028 04:51:50.144575  9023 solver.cpp:241]     Train net output #0: loss = 1.44625 (* 1 = 1.44625 loss)
I1028 04:51:50.144592  9023 sgd_solver.cpp:105] Iteration 130240, lr = 0.00174903
I1028 04:52:20.846909  9023 solver.cpp:222] Iteration 130280 (1.30288 iter/s, 30.7012s/40 iters), loss = 1.60213
I1028 04:52:20.847074  9023 solver.cpp:241]     Train net output #0: loss = 1.60213 (* 1 = 1.60213 loss)
I1028 04:52:20.847090  9023 sgd_solver.cpp:105] Iteration 130280, lr = 0.00174692
I1028 04:52:51.435475  9023 solver.cpp:222] Iteration 130320 (1.30773 iter/s, 30.5872s/40 iters), loss = 1.36083
I1028 04:52:51.435637  9023 solver.cpp:241]     Train net output #0: loss = 1.36083 (* 1 = 1.36083 loss)
I1028 04:52:51.435653  9023 sgd_solver.cpp:105] Iteration 130320, lr = 0.00174481
I1028 04:53:22.141997  9023 solver.cpp:222] Iteration 130360 (1.30271 iter/s, 30.7052s/40 iters), loss = 1.46863
I1028 04:53:22.142155  9023 solver.cpp:241]     Train net output #0: loss = 1.46863 (* 1 = 1.46863 loss)
I1028 04:53:22.142171  9023 sgd_solver.cpp:105] Iteration 130360, lr = 0.0017427
I1028 04:53:53.011124  9023 solver.cpp:222] Iteration 130400 (1.29585 iter/s, 30.8678s/40 iters), loss = 1.50375
I1028 04:53:53.011313  9023 solver.cpp:241]     Train net output #0: loss = 1.50375 (* 1 = 1.50375 loss)
I1028 04:53:53.011330  9023 sgd_solver.cpp:105] Iteration 130400, lr = 0.00174059
I1028 04:54:24.036217  9023 solver.cpp:222] Iteration 130440 (1.28934 iter/s, 31.0237s/40 iters), loss = 1.48386
I1028 04:54:24.036412  9023 solver.cpp:241]     Train net output #0: loss = 1.48386 (* 1 = 1.48386 loss)
I1028 04:54:24.036442  9023 sgd_solver.cpp:105] Iteration 130440, lr = 0.00173848
I1028 04:54:54.683993  9023 solver.cpp:222] Iteration 130480 (1.30521 iter/s, 30.6464s/40 iters), loss = 1.34502
I1028 04:54:54.684175  9023 solver.cpp:241]     Train net output #0: loss = 1.34502 (* 1 = 1.34502 loss)
I1028 04:54:54.684191  9023 sgd_solver.cpp:105] Iteration 130480, lr = 0.00173637
I1028 04:55:09.277700  9023 solver.cpp:334] Iteration 130500, Testing net (#0)
I1028 04:55:40.809384  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57176
I1028 04:55:40.809561  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79772
I1028 04:55:40.809577  9023 solver.cpp:401]     Test net output #2: loss = 1.87361 (* 1 = 1.87361 loss)
I1028 04:55:57.641798  9023 solver.cpp:222] Iteration 130520 (0.635372 iter/s, 62.9553s/40 iters), loss = 1.3222
I1028 04:55:57.641870  9023 solver.cpp:241]     Train net output #0: loss = 1.3222 (* 1 = 1.3222 loss)
I1028 04:55:57.641886  9023 sgd_solver.cpp:105] Iteration 130520, lr = 0.00173426
I1028 04:56:28.729261  9023 solver.cpp:222] Iteration 130560 (1.28674 iter/s, 31.0862s/40 iters), loss = 1.5867
I1028 04:56:28.729454  9023 solver.cpp:241]     Train net output #0: loss = 1.5867 (* 1 = 1.5867 loss)
I1028 04:56:28.729470  9023 sgd_solver.cpp:105] Iteration 130560, lr = 0.00173215
I1028 04:57:00.240301  9023 solver.cpp:222] Iteration 130600 (1.26945 iter/s, 31.5096s/40 iters), loss = 1.2437
I1028 04:57:00.240495  9023 solver.cpp:241]     Train net output #0: loss = 1.2437 (* 1 = 1.2437 loss)
I1028 04:57:00.240512  9023 sgd_solver.cpp:105] Iteration 130600, lr = 0.00173004
I1028 04:57:34.630645  9023 solver.cpp:222] Iteration 130640 (1.16317 iter/s, 34.3888s/40 iters), loss = 1.49402
I1028 04:57:34.630867  9023 solver.cpp:241]     Train net output #0: loss = 1.49402 (* 1 = 1.49402 loss)
I1028 04:57:34.630892  9023 sgd_solver.cpp:105] Iteration 130640, lr = 0.00172793
I1028 04:58:06.780443  9023 solver.cpp:222] Iteration 130680 (1.24423 iter/s, 32.1484s/40 iters), loss = 1.88781
I1028 04:58:06.780655  9023 solver.cpp:241]     Train net output #0: loss = 1.88781 (* 1 = 1.88781 loss)
I1028 04:58:06.780676  9023 sgd_solver.cpp:105] Iteration 130680, lr = 0.00172583
I1028 04:58:38.178323  9023 solver.cpp:222] Iteration 130720 (1.27403 iter/s, 31.3965s/40 iters), loss = 1.42043
I1028 04:58:38.178544  9023 solver.cpp:241]     Train net output #0: loss = 1.42043 (* 1 = 1.42043 loss)
I1028 04:58:38.178560  9023 sgd_solver.cpp:105] Iteration 130720, lr = 0.00172372
I1028 04:59:08.959640  9023 solver.cpp:222] Iteration 130760 (1.29955 iter/s, 30.7799s/40 iters), loss = 1.49588
I1028 04:59:08.959800  9023 solver.cpp:241]     Train net output #0: loss = 1.49588 (* 1 = 1.49588 loss)
I1028 04:59:08.959816  9023 sgd_solver.cpp:105] Iteration 130760, lr = 0.00172161
I1028 04:59:40.088229  9023 solver.cpp:222] Iteration 130800 (1.28505 iter/s, 31.1272s/40 iters), loss = 1.33696
I1028 04:59:40.088402  9023 solver.cpp:241]     Train net output #0: loss = 1.33696 (* 1 = 1.33696 loss)
I1028 04:59:40.088418  9023 sgd_solver.cpp:105] Iteration 130800, lr = 0.00171951
I1028 05:00:12.991168  9023 solver.cpp:222] Iteration 130840 (1.21575 iter/s, 32.9015s/40 iters), loss = 1.4715
I1028 05:00:12.991518  9023 solver.cpp:241]     Train net output #0: loss = 1.4715 (* 1 = 1.4715 loss)
I1028 05:00:12.991540  9023 sgd_solver.cpp:105] Iteration 130840, lr = 0.0017174
I1028 05:00:45.413452  9023 solver.cpp:222] Iteration 130880 (1.23378 iter/s, 32.4207s/40 iters), loss = 1.65967
I1028 05:00:45.413640  9023 solver.cpp:241]     Train net output #0: loss = 1.65967 (* 1 = 1.65967 loss)
I1028 05:00:45.413657  9023 sgd_solver.cpp:105] Iteration 130880, lr = 0.0017153
I1028 05:01:29.030905  9023 solver.cpp:222] Iteration 130920 (0.917103 iter/s, 43.6156s/40 iters), loss = 1.68754
I1028 05:01:29.031168  9023 solver.cpp:241]     Train net output #0: loss = 1.68754 (* 1 = 1.68754 loss)
I1028 05:01:29.031190  9023 sgd_solver.cpp:105] Iteration 130920, lr = 0.00171319
I1028 05:01:59.825613  9023 solver.cpp:222] Iteration 130960 (1.29898 iter/s, 30.7933s/40 iters), loss = 1.62477
I1028 05:01:59.825839  9023 solver.cpp:241]     Train net output #0: loss = 1.62477 (* 1 = 1.62477 loss)
I1028 05:01:59.825858  9023 sgd_solver.cpp:105] Iteration 130960, lr = 0.00171109
I1028 05:02:34.656682  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_131000.caffemodel
I1028 05:02:34.688711  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_131000.solverstate
I1028 05:02:34.705682  9023 solver.cpp:334] Iteration 131000, Testing net (#0)
I1028 05:03:06.121137  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 05:03:06.332511  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57436
I1028 05:03:06.332576  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.806119
I1028 05:03:06.332590  9023 solver.cpp:401]     Test net output #2: loss = 1.89775 (* 1 = 1.89775 loss)
I1028 05:03:07.108414  9023 solver.cpp:222] Iteration 131000 (0.59453 iter/s, 67.2801s/40 iters), loss = 1.21472
I1028 05:03:07.108481  9023 solver.cpp:241]     Train net output #0: loss = 1.21472 (* 1 = 1.21472 loss)
I1028 05:03:07.108497  9023 sgd_solver.cpp:105] Iteration 131000, lr = 0.00170899
I1028 05:03:38.803460  9023 solver.cpp:222] Iteration 131040 (1.26208 iter/s, 31.6938s/40 iters), loss = 1.6502
I1028 05:03:38.803676  9023 solver.cpp:241]     Train net output #0: loss = 1.6502 (* 1 = 1.6502 loss)
I1028 05:03:38.803696  9023 sgd_solver.cpp:105] Iteration 131040, lr = 0.00170688
I1028 05:04:10.745033  9023 solver.cpp:222] Iteration 131080 (1.25234 iter/s, 31.9402s/40 iters), loss = 1.25347
I1028 05:04:10.745206  9023 solver.cpp:241]     Train net output #0: loss = 1.25347 (* 1 = 1.25347 loss)
I1028 05:04:10.745223  9023 sgd_solver.cpp:105] Iteration 131080, lr = 0.00170478
I1028 05:04:42.248980  9023 solver.cpp:222] Iteration 131120 (1.26974 iter/s, 31.5026s/40 iters), loss = 1.36964
I1028 05:04:42.249161  9023 solver.cpp:241]     Train net output #0: loss = 1.36964 (* 1 = 1.36964 loss)
I1028 05:04:42.249176  9023 sgd_solver.cpp:105] Iteration 131120, lr = 0.00170268
I1028 05:05:13.143736  9023 solver.cpp:222] Iteration 131160 (1.29477 iter/s, 30.8934s/40 iters), loss = 1.54397
I1028 05:05:13.143923  9023 solver.cpp:241]     Train net output #0: loss = 1.54397 (* 1 = 1.54397 loss)
I1028 05:05:13.143939  9023 sgd_solver.cpp:105] Iteration 131160, lr = 0.00170058
I1028 05:05:44.322196  9023 solver.cpp:222] Iteration 131200 (1.28299 iter/s, 31.1771s/40 iters), loss = 1.41612
I1028 05:05:44.322410  9023 solver.cpp:241]     Train net output #0: loss = 1.41612 (* 1 = 1.41612 loss)
I1028 05:05:44.322427  9023 sgd_solver.cpp:105] Iteration 131200, lr = 0.00169848
I1028 05:06:15.298918  9023 solver.cpp:222] Iteration 131240 (1.29135 iter/s, 30.9754s/40 iters), loss = 1.52961
I1028 05:06:15.299089  9023 solver.cpp:241]     Train net output #0: loss = 1.52961 (* 1 = 1.52961 loss)
I1028 05:06:15.299106  9023 sgd_solver.cpp:105] Iteration 131240, lr = 0.00169637
I1028 05:06:46.349846  9023 solver.cpp:222] Iteration 131280 (1.28826 iter/s, 31.0496s/40 iters), loss = 1.5869
I1028 05:06:46.350019  9023 solver.cpp:241]     Train net output #0: loss = 1.5869 (* 1 = 1.5869 loss)
I1028 05:06:46.350036  9023 sgd_solver.cpp:105] Iteration 131280, lr = 0.00169427
I1028 05:07:17.256961  9023 solver.cpp:222] Iteration 131320 (1.29426 iter/s, 30.9058s/40 iters), loss = 1.52548
I1028 05:07:17.257155  9023 solver.cpp:241]     Train net output #0: loss = 1.52548 (* 1 = 1.52548 loss)
I1028 05:07:17.257171  9023 sgd_solver.cpp:105] Iteration 131320, lr = 0.00169217
I1028 05:07:48.011549  9023 solver.cpp:222] Iteration 131360 (1.30068 iter/s, 30.7532s/40 iters), loss = 1.23576
I1028 05:07:48.011723  9023 solver.cpp:241]     Train net output #0: loss = 1.23576 (* 1 = 1.23576 loss)
I1028 05:07:48.011740  9023 sgd_solver.cpp:105] Iteration 131360, lr = 0.00169007
I1028 05:08:18.982236  9023 solver.cpp:222] Iteration 131400 (1.2916 iter/s, 30.9693s/40 iters), loss = 1.75171
I1028 05:08:18.982542  9023 solver.cpp:241]     Train net output #0: loss = 1.75171 (* 1 = 1.75171 loss)
I1028 05:08:18.982568  9023 sgd_solver.cpp:105] Iteration 131400, lr = 0.00168798
I1028 05:08:51.111719  9023 solver.cpp:222] Iteration 131440 (1.24502 iter/s, 32.128s/40 iters), loss = 1.66205
I1028 05:08:51.111912  9023 solver.cpp:241]     Train net output #0: loss = 1.66205 (* 1 = 1.66205 loss)
I1028 05:08:51.111927  9023 sgd_solver.cpp:105] Iteration 131440, lr = 0.00168588
I1028 05:09:22.410464  9023 solver.cpp:222] Iteration 131480 (1.27806 iter/s, 31.2974s/40 iters), loss = 1.02194
I1028 05:09:22.410651  9023 solver.cpp:241]     Train net output #0: loss = 1.02194 (* 1 = 1.02194 loss)
I1028 05:09:22.410667  9023 sgd_solver.cpp:105] Iteration 131480, lr = 0.00168378
I1028 05:09:37.550417  9023 solver.cpp:334] Iteration 131500, Testing net (#0)
I1028 05:10:09.138440  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5712
I1028 05:10:09.138619  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.799199
I1028 05:10:09.138635  9023 solver.cpp:401]     Test net output #2: loss = 1.89668 (* 1 = 1.89668 loss)
I1028 05:10:25.316884  9023 solver.cpp:222] Iteration 131520 (0.635891 iter/s, 62.9039s/40 iters), loss = 1.61461
I1028 05:10:25.316958  9023 solver.cpp:241]     Train net output #0: loss = 1.61461 (* 1 = 1.61461 loss)
I1028 05:10:25.316973  9023 sgd_solver.cpp:105] Iteration 131520, lr = 0.00168168
I1028 05:10:56.446497  9023 solver.cpp:222] Iteration 131560 (1.285 iter/s, 31.1284s/40 iters), loss = 1.13502
I1028 05:10:56.446701  9023 solver.cpp:241]     Train net output #0: loss = 1.13502 (* 1 = 1.13502 loss)
I1028 05:10:56.446717  9023 sgd_solver.cpp:105] Iteration 131560, lr = 0.00167958
I1028 05:11:27.950567  9023 solver.cpp:222] Iteration 131600 (1.26973 iter/s, 31.5027s/40 iters), loss = 1.62989
I1028 05:11:27.950781  9023 solver.cpp:241]     Train net output #0: loss = 1.62989 (* 1 = 1.62989 loss)
I1028 05:11:27.950798  9023 sgd_solver.cpp:105] Iteration 131600, lr = 0.00167749
I1028 05:11:58.996474  9023 solver.cpp:222] Iteration 131640 (1.28847 iter/s, 31.0445s/40 iters), loss = 1.66296
I1028 05:11:58.996668  9023 solver.cpp:241]     Train net output #0: loss = 1.66296 (* 1 = 1.66296 loss)
I1028 05:11:58.996685  9023 sgd_solver.cpp:105] Iteration 131640, lr = 0.00167539
I1028 05:12:30.353618  9023 solver.cpp:222] Iteration 131680 (1.27568 iter/s, 31.3558s/40 iters), loss = 1.32655
I1028 05:12:30.353793  9023 solver.cpp:241]     Train net output #0: loss = 1.32655 (* 1 = 1.32655 loss)
I1028 05:12:30.353811  9023 sgd_solver.cpp:105] Iteration 131680, lr = 0.00167329
I1028 05:13:01.506268  9023 solver.cpp:222] Iteration 131720 (1.28406 iter/s, 31.1513s/40 iters), loss = 1.66932
I1028 05:13:01.506496  9023 solver.cpp:241]     Train net output #0: loss = 1.66932 (* 1 = 1.66932 loss)
I1028 05:13:01.506518  9023 sgd_solver.cpp:105] Iteration 131720, lr = 0.0016712
I1028 05:13:33.540755  9023 solver.cpp:222] Iteration 131760 (1.24871 iter/s, 32.0331s/40 iters), loss = 1.53371
I1028 05:13:33.540997  9023 solver.cpp:241]     Train net output #0: loss = 1.53371 (* 1 = 1.53371 loss)
I1028 05:13:33.541019  9023 sgd_solver.cpp:105] Iteration 131760, lr = 0.0016691
I1028 05:14:05.030150  9023 solver.cpp:222] Iteration 131800 (1.27033 iter/s, 31.488s/40 iters), loss = 1.43923
I1028 05:14:05.030344  9023 solver.cpp:241]     Train net output #0: loss = 1.43923 (* 1 = 1.43923 loss)
I1028 05:14:05.030361  9023 sgd_solver.cpp:105] Iteration 131800, lr = 0.00166701
I1028 05:14:35.787127  9023 solver.cpp:222] Iteration 131840 (1.30058 iter/s, 30.7556s/40 iters), loss = 1.81661
I1028 05:14:35.787328  9023 solver.cpp:241]     Train net output #0: loss = 1.81661 (* 1 = 1.81661 loss)
I1028 05:14:35.787345  9023 sgd_solver.cpp:105] Iteration 131840, lr = 0.00166491
I1028 05:15:06.554615  9023 solver.cpp:222] Iteration 131880 (1.30013 iter/s, 30.7661s/40 iters), loss = 1.77852
I1028 05:15:06.554783  9023 solver.cpp:241]     Train net output #0: loss = 1.77852 (* 1 = 1.77852 loss)
I1028 05:15:06.554800  9023 sgd_solver.cpp:105] Iteration 131880, lr = 0.00166282
I1028 05:15:37.286654  9023 solver.cpp:222] Iteration 131920 (1.30163 iter/s, 30.7307s/40 iters), loss = 1.54904
I1028 05:15:37.286873  9023 solver.cpp:241]     Train net output #0: loss = 1.54904 (* 1 = 1.54904 loss)
I1028 05:15:37.286890  9023 sgd_solver.cpp:105] Iteration 131920, lr = 0.00166072
I1028 05:16:08.951165  9023 solver.cpp:222] Iteration 131960 (1.2633 iter/s, 31.6631s/40 iters), loss = 1.67922
I1028 05:16:08.951421  9023 solver.cpp:241]     Train net output #0: loss = 1.67922 (* 1 = 1.67922 loss)
I1028 05:16:08.951447  9023 sgd_solver.cpp:105] Iteration 131960, lr = 0.00165863
I1028 05:16:39.189345  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_132000.caffemodel
I1028 05:16:39.220903  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_132000.solverstate
I1028 05:16:39.238277  9023 solver.cpp:334] Iteration 132000, Testing net (#0)
I1028 05:17:10.401371  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 05:17:10.612629  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56776
I1028 05:17:10.612689  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.801519
I1028 05:17:10.612704  9023 solver.cpp:401]     Test net output #2: loss = 1.92991 (* 1 = 1.92991 loss)
I1028 05:17:11.387610  9023 solver.cpp:222] Iteration 132000 (0.640678 iter/s, 62.4339s/40 iters), loss = 1.64983
I1028 05:17:11.387676  9023 solver.cpp:241]     Train net output #0: loss = 1.64983 (* 1 = 1.64983 loss)
I1028 05:17:11.387691  9023 sgd_solver.cpp:105] Iteration 132000, lr = 0.00165654
I1028 05:17:41.962924  9023 solver.cpp:222] Iteration 132040 (1.3083 iter/s, 30.5741s/40 iters), loss = 1.26329
I1028 05:17:41.963099  9023 solver.cpp:241]     Train net output #0: loss = 1.26329 (* 1 = 1.26329 loss)
I1028 05:17:41.963115  9023 sgd_solver.cpp:105] Iteration 132040, lr = 0.00165445
I1028 05:17:55.030380  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1028 05:18:12.513936  9023 solver.cpp:222] Iteration 132080 (1.30934 iter/s, 30.5497s/40 iters), loss = 1.83951
I1028 05:18:12.514096  9023 solver.cpp:241]     Train net output #0: loss = 1.83951 (* 1 = 1.83951 loss)
I1028 05:18:12.514112  9023 sgd_solver.cpp:105] Iteration 132080, lr = 0.00165235
I1028 05:18:43.921777  9023 solver.cpp:222] Iteration 132120 (1.27362 iter/s, 31.4065s/40 iters), loss = 1.34872
I1028 05:18:43.921944  9023 solver.cpp:241]     Train net output #0: loss = 1.34872 (* 1 = 1.34872 loss)
I1028 05:18:43.921960  9023 sgd_solver.cpp:105] Iteration 132120, lr = 0.00165026
I1028 05:19:15.015275  9023 solver.cpp:222] Iteration 132160 (1.2865 iter/s, 31.0922s/40 iters), loss = 1.45949
I1028 05:19:15.015455  9023 solver.cpp:241]     Train net output #0: loss = 1.45949 (* 1 = 1.45949 loss)
I1028 05:19:15.015471  9023 sgd_solver.cpp:105] Iteration 132160, lr = 0.00164817
I1028 05:19:46.496850  9023 solver.cpp:222] Iteration 132200 (1.27064 iter/s, 31.4802s/40 iters), loss = 1.75647
I1028 05:19:46.497021  9023 solver.cpp:241]     Train net output #0: loss = 1.75647 (* 1 = 1.75647 loss)
I1028 05:19:46.497037  9023 sgd_solver.cpp:105] Iteration 132200, lr = 0.00164608
I1028 05:20:18.180989  9023 solver.cpp:222] Iteration 132240 (1.26252 iter/s, 31.6828s/40 iters), loss = 1.60967
I1028 05:20:18.181221  9023 solver.cpp:241]     Train net output #0: loss = 1.60967 (* 1 = 1.60967 loss)
I1028 05:20:18.181237  9023 sgd_solver.cpp:105] Iteration 132240, lr = 0.00164399
I1028 05:20:49.473692  9023 solver.cpp:222] Iteration 132280 (1.27831 iter/s, 31.2913s/40 iters), loss = 1.36373
I1028 05:20:49.473912  9023 solver.cpp:241]     Train net output #0: loss = 1.36373 (* 1 = 1.36373 loss)
I1028 05:20:49.473927  9023 sgd_solver.cpp:105] Iteration 132280, lr = 0.0016419
I1028 05:21:20.594857  9023 solver.cpp:222] Iteration 132320 (1.28536 iter/s, 31.1198s/40 iters), loss = 1.70603
I1028 05:21:20.595067  9023 solver.cpp:241]     Train net output #0: loss = 1.70603 (* 1 = 1.70603 loss)
I1028 05:21:20.595098  9023 sgd_solver.cpp:105] Iteration 132320, lr = 0.00163981
I1028 05:21:51.631608  9023 solver.cpp:222] Iteration 132360 (1.28885 iter/s, 31.0354s/40 iters), loss = 1.6953
I1028 05:21:51.631868  9023 solver.cpp:241]     Train net output #0: loss = 1.6953 (* 1 = 1.6953 loss)
I1028 05:21:51.631889  9023 sgd_solver.cpp:105] Iteration 132360, lr = 0.00163772
I1028 05:22:22.501273  9023 solver.cpp:222] Iteration 132400 (1.29583 iter/s, 30.8683s/40 iters), loss = 1.43706
I1028 05:22:22.501456  9023 solver.cpp:241]     Train net output #0: loss = 1.43706 (* 1 = 1.43706 loss)
I1028 05:22:22.501473  9023 sgd_solver.cpp:105] Iteration 132400, lr = 0.00163564
I1028 05:22:53.658860  9023 solver.cpp:222] Iteration 132440 (1.28385 iter/s, 31.1562s/40 iters), loss = 1.82212
I1028 05:22:53.659049  9023 solver.cpp:241]     Train net output #0: loss = 1.82212 (* 1 = 1.82212 loss)
I1028 05:22:53.659066  9023 sgd_solver.cpp:105] Iteration 132440, lr = 0.00163355
I1028 05:23:24.710974  9023 solver.cpp:222] Iteration 132480 (1.28821 iter/s, 31.0508s/40 iters), loss = 1.46909
I1028 05:23:24.711159  9023 solver.cpp:241]     Train net output #0: loss = 1.46909 (* 1 = 1.46909 loss)
I1028 05:23:24.711175  9023 sgd_solver.cpp:105] Iteration 132480, lr = 0.00163146
I1028 05:23:39.589617  9023 solver.cpp:334] Iteration 132500, Testing net (#0)
I1028 05:24:11.035653  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57384
I1028 05:24:11.035843  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80084
I1028 05:24:11.035859  9023 solver.cpp:401]     Test net output #2: loss = 1.89313 (* 1 = 1.89313 loss)
I1028 05:24:27.282984  9023 solver.cpp:222] Iteration 132520 (0.639289 iter/s, 62.5695s/40 iters), loss = 1.41534
I1028 05:24:27.283054  9023 solver.cpp:241]     Train net output #0: loss = 1.41534 (* 1 = 1.41534 loss)
I1028 05:24:27.283071  9023 sgd_solver.cpp:105] Iteration 132520, lr = 0.00162937
I1028 05:24:58.127090  9023 solver.cpp:222] Iteration 132560 (1.2969 iter/s, 30.8429s/40 iters), loss = 1.30945
I1028 05:24:58.127287  9023 solver.cpp:241]     Train net output #0: loss = 1.30945 (* 1 = 1.30945 loss)
I1028 05:24:58.127307  9023 sgd_solver.cpp:105] Iteration 132560, lr = 0.00162729
I1028 05:25:29.247292  9023 solver.cpp:222] Iteration 132600 (1.2854 iter/s, 31.1188s/40 iters), loss = 1.60676
I1028 05:25:29.247462  9023 solver.cpp:241]     Train net output #0: loss = 1.60676 (* 1 = 1.60676 loss)
I1028 05:25:29.247484  9023 sgd_solver.cpp:105] Iteration 132600, lr = 0.0016252
I1028 05:26:00.375475  9023 solver.cpp:222] Iteration 132640 (1.28506 iter/s, 31.1268s/40 iters), loss = 1.29843
I1028 05:26:00.375699  9023 solver.cpp:241]     Train net output #0: loss = 1.29843 (* 1 = 1.29843 loss)
I1028 05:26:00.375715  9023 sgd_solver.cpp:105] Iteration 132640, lr = 0.00162312
I1028 05:26:31.028219  9023 solver.cpp:222] Iteration 132680 (1.305 iter/s, 30.6513s/40 iters), loss = 1.75622
I1028 05:26:31.028373  9023 solver.cpp:241]     Train net output #0: loss = 1.75622 (* 1 = 1.75622 loss)
I1028 05:26:31.028388  9023 sgd_solver.cpp:105] Iteration 132680, lr = 0.00162103
I1028 05:27:02.298246  9023 solver.cpp:222] Iteration 132720 (1.27923 iter/s, 31.2687s/40 iters), loss = 1.59694
I1028 05:27:02.298446  9023 solver.cpp:241]     Train net output #0: loss = 1.59694 (* 1 = 1.59694 loss)
I1028 05:27:02.298466  9023 sgd_solver.cpp:105] Iteration 132720, lr = 0.00161895
I1028 05:27:40.826844  9023 solver.cpp:222] Iteration 132760 (1.03823 iter/s, 38.527s/40 iters), loss = 1.37158
I1028 05:27:40.827018  9023 solver.cpp:241]     Train net output #0: loss = 1.37158 (* 1 = 1.37158 loss)
I1028 05:27:40.827034  9023 sgd_solver.cpp:105] Iteration 132760, lr = 0.00161686
I1028 05:28:12.211876  9023 solver.cpp:222] Iteration 132800 (1.27455 iter/s, 31.3837s/40 iters), loss = 1.90174
I1028 05:28:12.212060  9023 solver.cpp:241]     Train net output #0: loss = 1.90174 (* 1 = 1.90174 loss)
I1028 05:28:12.213089  9023 sgd_solver.cpp:105] Iteration 132800, lr = 0.00161478
I1028 05:28:43.419103  9023 solver.cpp:222] Iteration 132840 (1.28181 iter/s, 31.2059s/40 iters), loss = 1.61473
I1028 05:28:43.419332  9023 solver.cpp:241]     Train net output #0: loss = 1.61473 (* 1 = 1.61473 loss)
I1028 05:28:43.419358  9023 sgd_solver.cpp:105] Iteration 132840, lr = 0.00161269
I1028 05:29:14.918447  9023 solver.cpp:222] Iteration 132880 (1.26993 iter/s, 31.4979s/40 iters), loss = 1.54473
I1028 05:29:14.918658  9023 solver.cpp:241]     Train net output #0: loss = 1.54473 (* 1 = 1.54473 loss)
I1028 05:29:14.918681  9023 sgd_solver.cpp:105] Iteration 132880, lr = 0.00161061
I1028 05:29:46.316381  9023 solver.cpp:222] Iteration 132920 (1.27403 iter/s, 31.3965s/40 iters), loss = 1.68248
I1028 05:29:46.316573  9023 solver.cpp:241]     Train net output #0: loss = 1.68248 (* 1 = 1.68248 loss)
I1028 05:29:46.316589  9023 sgd_solver.cpp:105] Iteration 132920, lr = 0.00160853
I1028 05:30:17.648499  9023 solver.cpp:222] Iteration 132960 (1.2767 iter/s, 31.3307s/40 iters), loss = 1.27533
I1028 05:30:17.648703  9023 solver.cpp:241]     Train net output #0: loss = 1.27533 (* 1 = 1.27533 loss)
I1028 05:30:17.648720  9023 sgd_solver.cpp:105] Iteration 132960, lr = 0.00160645
I1028 05:30:48.233067  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_133000.caffemodel
I1028 05:30:48.270575  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_133000.solverstate
I1028 05:30:48.287777  9023 solver.cpp:334] Iteration 133000, Testing net (#0)
I1028 05:31:19.587270  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 05:31:19.799070  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57064
I1028 05:31:19.799134  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.803519
I1028 05:31:19.799147  9023 solver.cpp:401]     Test net output #2: loss = 1.90547 (* 1 = 1.90547 loss)
I1028 05:31:20.575536  9023 solver.cpp:222] Iteration 133000 (0.635683 iter/s, 62.9245s/40 iters), loss = 1.94637
I1028 05:31:20.575605  9023 solver.cpp:241]     Train net output #0: loss = 1.94637 (* 1 = 1.94637 loss)
I1028 05:31:20.575620  9023 sgd_solver.cpp:105] Iteration 133000, lr = 0.00160437
I1028 05:31:51.874698  9023 solver.cpp:222] Iteration 133040 (1.27804 iter/s, 31.2979s/40 iters), loss = 1.61003
I1028 05:31:51.874909  9023 solver.cpp:241]     Train net output #0: loss = 1.61003 (* 1 = 1.61003 loss)
I1028 05:31:51.874927  9023 sgd_solver.cpp:105] Iteration 133040, lr = 0.00160228
I1028 05:32:22.975767  9023 solver.cpp:222] Iteration 133080 (1.28619 iter/s, 31.0997s/40 iters), loss = 1.29639
I1028 05:32:22.975950  9023 solver.cpp:241]     Train net output #0: loss = 1.29639 (* 1 = 1.29639 loss)
I1028 05:32:22.975965  9023 sgd_solver.cpp:105] Iteration 133080, lr = 0.0016002
I1028 05:32:53.934849  9023 solver.cpp:222] Iteration 133120 (1.29208 iter/s, 30.9577s/40 iters), loss = 1.6505
I1028 05:32:53.935014  9023 solver.cpp:241]     Train net output #0: loss = 1.6505 (* 1 = 1.6505 loss)
I1028 05:32:53.935029  9023 sgd_solver.cpp:105] Iteration 133120, lr = 0.00159812
I1028 05:33:25.201747  9023 solver.cpp:222] Iteration 133160 (1.27936 iter/s, 31.2656s/40 iters), loss = 1.36509
I1028 05:33:25.201925  9023 solver.cpp:241]     Train net output #0: loss = 1.36509 (* 1 = 1.36509 loss)
I1028 05:33:25.201941  9023 sgd_solver.cpp:105] Iteration 133160, lr = 0.00159604
I1028 05:33:56.211066  9023 solver.cpp:222] Iteration 133200 (1.28999 iter/s, 31.008s/40 iters), loss = 1.50673
I1028 05:33:56.211244  9023 solver.cpp:241]     Train net output #0: loss = 1.50673 (* 1 = 1.50673 loss)
I1028 05:33:56.211261  9023 sgd_solver.cpp:105] Iteration 133200, lr = 0.00159396
I1028 05:34:26.916360  9023 solver.cpp:222] Iteration 133240 (1.30276 iter/s, 30.704s/40 iters), loss = 1.54259
I1028 05:34:26.916548  9023 solver.cpp:241]     Train net output #0: loss = 1.54259 (* 1 = 1.54259 loss)
I1028 05:34:26.916565  9023 sgd_solver.cpp:105] Iteration 133240, lr = 0.00159189
I1028 05:34:57.983963  9023 solver.cpp:222] Iteration 133280 (1.28757 iter/s, 31.0662s/40 iters), loss = 1.54111
I1028 05:34:57.984217  9023 solver.cpp:241]     Train net output #0: loss = 1.54111 (* 1 = 1.54111 loss)
I1028 05:34:57.984235  9023 sgd_solver.cpp:105] Iteration 133280, lr = 0.00158981
I1028 05:35:29.117499  9023 solver.cpp:222] Iteration 133320 (1.28485 iter/s, 31.1321s/40 iters), loss = 1.50055
I1028 05:35:29.117696  9023 solver.cpp:241]     Train net output #0: loss = 1.50055 (* 1 = 1.50055 loss)
I1028 05:35:29.117712  9023 sgd_solver.cpp:105] Iteration 133320, lr = 0.00158773
I1028 05:36:00.075392  9023 solver.cpp:222] Iteration 133360 (1.29213 iter/s, 30.9565s/40 iters), loss = 1.45754
I1028 05:36:00.075572  9023 solver.cpp:241]     Train net output #0: loss = 1.45754 (* 1 = 1.45754 loss)
I1028 05:36:00.075587  9023 sgd_solver.cpp:105] Iteration 133360, lr = 0.00158565
I1028 05:36:30.717505  9023 solver.cpp:222] Iteration 133400 (1.30545 iter/s, 30.6408s/40 iters), loss = 1.51656
I1028 05:36:30.717679  9023 solver.cpp:241]     Train net output #0: loss = 1.51656 (* 1 = 1.51656 loss)
I1028 05:36:30.717695  9023 sgd_solver.cpp:105] Iteration 133400, lr = 0.00158357
I1028 05:37:01.060611  9023 solver.cpp:222] Iteration 133440 (1.31831 iter/s, 30.3418s/40 iters), loss = 1.60112
I1028 05:37:01.060786  9023 solver.cpp:241]     Train net output #0: loss = 1.60112 (* 1 = 1.60112 loss)
I1028 05:37:01.060801  9023 sgd_solver.cpp:105] Iteration 133440, lr = 0.0015815
I1028 05:37:31.912976  9023 solver.cpp:222] Iteration 133480 (1.29655 iter/s, 30.851s/40 iters), loss = 1.32622
I1028 05:37:31.913158  9023 solver.cpp:241]     Train net output #0: loss = 1.32622 (* 1 = 1.32622 loss)
I1028 05:37:31.913180  9023 sgd_solver.cpp:105] Iteration 133480, lr = 0.00157942
I1028 05:37:55.254765  9023 solver.cpp:334] Iteration 133500, Testing net (#0)
I1028 05:38:27.023680  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5754
I1028 05:38:27.023859  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80184
I1028 05:38:27.023874  9023 solver.cpp:401]     Test net output #2: loss = 1.86784 (* 1 = 1.86784 loss)
I1028 05:38:43.172631  9023 solver.cpp:222] Iteration 133520 (0.56135 iter/s, 71.2568s/40 iters), loss = 1.57057
I1028 05:38:43.172703  9023 solver.cpp:241]     Train net output #0: loss = 1.57057 (* 1 = 1.57057 loss)
I1028 05:38:43.172719  9023 sgd_solver.cpp:105] Iteration 133520, lr = 0.00157735
I1028 05:39:13.954035  9023 solver.cpp:222] Iteration 133560 (1.29954 iter/s, 30.7802s/40 iters), loss = 1.23237
I1028 05:39:13.954241  9023 solver.cpp:241]     Train net output #0: loss = 1.23237 (* 1 = 1.23237 loss)
I1028 05:39:13.954257  9023 sgd_solver.cpp:105] Iteration 133560, lr = 0.00157527
I1028 05:39:44.543050  9023 solver.cpp:222] Iteration 133600 (1.30772 iter/s, 30.5877s/40 iters), loss = 1.43253
I1028 05:39:44.543205  9023 solver.cpp:241]     Train net output #0: loss = 1.43253 (* 1 = 1.43253 loss)
I1028 05:39:44.543220  9023 sgd_solver.cpp:105] Iteration 133600, lr = 0.0015732
I1028 05:40:15.183504  9023 solver.cpp:222] Iteration 133640 (1.30552 iter/s, 30.6391s/40 iters), loss = 2.07723
I1028 05:40:15.183671  9023 solver.cpp:241]     Train net output #0: loss = 2.07723 (* 1 = 2.07723 loss)
I1028 05:40:15.183687  9023 sgd_solver.cpp:105] Iteration 133640, lr = 0.00157112
I1028 05:40:45.886961  9023 solver.cpp:222] Iteration 133680 (1.30284 iter/s, 30.7021s/40 iters), loss = 1.61038
I1028 05:40:45.887132  9023 solver.cpp:241]     Train net output #0: loss = 1.61038 (* 1 = 1.61038 loss)
I1028 05:40:45.887148  9023 sgd_solver.cpp:105] Iteration 133680, lr = 0.00156905
I1028 05:41:16.632870  9023 solver.cpp:222] Iteration 133720 (1.30104 iter/s, 30.7446s/40 iters), loss = 1.82443
I1028 05:41:16.633102  9023 solver.cpp:241]     Train net output #0: loss = 1.82443 (* 1 = 1.82443 loss)
I1028 05:41:16.633118  9023 sgd_solver.cpp:105] Iteration 133720, lr = 0.00156697
I1028 05:41:48.786240  9023 solver.cpp:222] Iteration 133760 (1.24409 iter/s, 32.1519s/40 iters), loss = 1.58126
I1028 05:41:48.786468  9023 solver.cpp:241]     Train net output #0: loss = 1.58126 (* 1 = 1.58126 loss)
I1028 05:41:48.786511  9023 sgd_solver.cpp:105] Iteration 133760, lr = 0.0015649
I1028 05:42:25.430176  9023 solver.cpp:222] Iteration 133800 (1.09163 iter/s, 36.6423s/40 iters), loss = 1.44978
I1028 05:42:25.430563  9023 solver.cpp:241]     Train net output #0: loss = 1.44978 (* 1 = 1.44978 loss)
I1028 05:42:25.430632  9023 sgd_solver.cpp:105] Iteration 133800, lr = 0.00156283
I1028 05:42:57.366346  9023 solver.cpp:222] Iteration 133840 (1.25256 iter/s, 31.9346s/40 iters), loss = 1.53787
I1028 05:42:57.366518  9023 solver.cpp:241]     Train net output #0: loss = 1.53787 (* 1 = 1.53787 loss)
I1028 05:42:57.366534  9023 sgd_solver.cpp:105] Iteration 133840, lr = 0.00156076
I1028 05:43:27.995167  9023 solver.cpp:222] Iteration 133880 (1.30602 iter/s, 30.6275s/40 iters), loss = 1.44022
I1028 05:43:27.995342  9023 solver.cpp:241]     Train net output #0: loss = 1.44022 (* 1 = 1.44022 loss)
I1028 05:43:27.995357  9023 sgd_solver.cpp:105] Iteration 133880, lr = 0.00155869
I1028 05:43:58.710280  9023 solver.cpp:222] Iteration 133920 (1.30235 iter/s, 30.7138s/40 iters), loss = 1.58502
I1028 05:43:58.710464  9023 solver.cpp:241]     Train net output #0: loss = 1.58502 (* 1 = 1.58502 loss)
I1028 05:43:58.710480  9023 sgd_solver.cpp:105] Iteration 133920, lr = 0.00155661
I1028 05:44:29.649087  9023 solver.cpp:222] Iteration 133960 (1.29293 iter/s, 30.9374s/40 iters), loss = 1.24272
I1028 05:44:29.649291  9023 solver.cpp:241]     Train net output #0: loss = 1.24272 (* 1 = 1.24272 loss)
I1028 05:44:29.649312  9023 sgd_solver.cpp:105] Iteration 133960, lr = 0.00155454
I1028 05:45:00.063763  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_134000.caffemodel
I1028 05:45:00.096590  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_134000.solverstate
I1028 05:45:00.114491  9023 solver.cpp:334] Iteration 134000, Testing net (#0)
I1028 05:45:31.272742  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 05:45:31.485318  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57548
I1028 05:45:31.485381  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.805759
I1028 05:45:31.485396  9023 solver.cpp:401]     Test net output #2: loss = 1.88932 (* 1 = 1.88932 loss)
I1028 05:45:32.256821  9023 solver.cpp:222] Iteration 134000 (0.638925 iter/s, 62.6052s/40 iters), loss = 1.3225
I1028 05:45:32.256888  9023 solver.cpp:241]     Train net output #0: loss = 1.3225 (* 1 = 1.3225 loss)
I1028 05:45:32.256904  9023 sgd_solver.cpp:105] Iteration 134000, lr = 0.00155247
I1028 05:46:03.461587  9023 solver.cpp:222] Iteration 134040 (1.28191 iter/s, 31.2035s/40 iters), loss = 1.54943
I1028 05:46:03.461779  9023 solver.cpp:241]     Train net output #0: loss = 1.54943 (* 1 = 1.54943 loss)
I1028 05:46:03.461796  9023 sgd_solver.cpp:105] Iteration 134040, lr = 0.0015504
I1028 05:46:34.276640  9023 solver.cpp:222] Iteration 134080 (1.29812 iter/s, 30.8137s/40 iters), loss = 1.44601
I1028 05:46:34.276828  9023 solver.cpp:241]     Train net output #0: loss = 1.44601 (* 1 = 1.44601 loss)
I1028 05:46:34.276844  9023 sgd_solver.cpp:105] Iteration 134080, lr = 0.00154833
I1028 05:47:05.103830  9023 solver.cpp:222] Iteration 134120 (1.29761 iter/s, 30.8258s/40 iters), loss = 1.46533
I1028 05:47:05.104038  9023 solver.cpp:241]     Train net output #0: loss = 1.46533 (* 1 = 1.46533 loss)
I1028 05:47:05.104054  9023 sgd_solver.cpp:105] Iteration 134120, lr = 0.00154627
I1028 05:47:36.212285  9023 solver.cpp:222] Iteration 134160 (1.28588 iter/s, 31.1071s/40 iters), loss = 1.6162
I1028 05:47:36.212497  9023 solver.cpp:241]     Train net output #0: loss = 1.6162 (* 1 = 1.6162 loss)
I1028 05:47:36.212514  9023 sgd_solver.cpp:105] Iteration 134160, lr = 0.0015442
I1028 05:48:07.488154  9023 solver.cpp:222] Iteration 134200 (1.279 iter/s, 31.2745s/40 iters), loss = 1.69268
I1028 05:48:07.488384  9023 solver.cpp:241]     Train net output #0: loss = 1.69268 (* 1 = 1.69268 loss)
I1028 05:48:07.488400  9023 sgd_solver.cpp:105] Iteration 134200, lr = 0.00154213
I1028 05:48:38.860388  9023 solver.cpp:222] Iteration 134240 (1.27507 iter/s, 31.3708s/40 iters), loss = 1.69596
I1028 05:48:38.860632  9023 solver.cpp:241]     Train net output #0: loss = 1.69596 (* 1 = 1.69596 loss)
I1028 05:48:38.860668  9023 sgd_solver.cpp:105] Iteration 134240, lr = 0.00154006
I1028 05:49:09.922358  9023 solver.cpp:222] Iteration 134280 (1.28781 iter/s, 31.0606s/40 iters), loss = 1.54032
I1028 05:49:09.922477  9023 solver.cpp:241]     Train net output #0: loss = 1.54032 (* 1 = 1.54032 loss)
I1028 05:49:09.922493  9023 sgd_solver.cpp:105] Iteration 134280, lr = 0.001538
I1028 05:49:41.169330  9023 solver.cpp:222] Iteration 134320 (1.28018 iter/s, 31.2457s/40 iters), loss = 1.54166
I1028 05:49:41.169488  9023 solver.cpp:241]     Train net output #0: loss = 1.54166 (* 1 = 1.54166 loss)
I1028 05:49:41.169504  9023 sgd_solver.cpp:105] Iteration 134320, lr = 0.00153593
I1028 05:50:12.494400  9023 solver.cpp:222] Iteration 134360 (1.27699 iter/s, 31.3237s/40 iters), loss = 1.31664
I1028 05:50:12.494601  9023 solver.cpp:241]     Train net output #0: loss = 1.31664 (* 1 = 1.31664 loss)
I1028 05:50:12.494616  9023 sgd_solver.cpp:105] Iteration 134360, lr = 0.00153386
I1028 05:50:43.205319  9023 solver.cpp:222] Iteration 134400 (1.30253 iter/s, 30.7096s/40 iters), loss = 1.57655
I1028 05:50:43.205489  9023 solver.cpp:241]     Train net output #0: loss = 1.57655 (* 1 = 1.57655 loss)
I1028 05:50:43.205505  9023 sgd_solver.cpp:105] Iteration 134400, lr = 0.0015318
I1028 05:51:16.326272  9023 solver.cpp:222] Iteration 134440 (1.20775 iter/s, 33.1195s/40 iters), loss = 1.60603
I1028 05:51:16.326512  9023 solver.cpp:241]     Train net output #0: loss = 1.60603 (* 1 = 1.60603 loss)
I1028 05:51:16.326539  9023 sgd_solver.cpp:105] Iteration 134440, lr = 0.00152973
I1028 05:51:48.103997  9023 solver.cpp:222] Iteration 134480 (1.2588 iter/s, 31.7763s/40 iters), loss = 1.36523
I1028 05:51:48.104162  9023 solver.cpp:241]     Train net output #0: loss = 1.36523 (* 1 = 1.36523 loss)
I1028 05:51:48.104178  9023 sgd_solver.cpp:105] Iteration 134480, lr = 0.00152767
I1028 05:52:02.652663  9023 solver.cpp:334] Iteration 134500, Testing net (#0)
I1028 05:52:34.059099  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.574
I1028 05:52:34.059283  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.803199
I1028 05:52:34.059303  9023 solver.cpp:401]     Test net output #2: loss = 1.91439 (* 1 = 1.91439 loss)
I1028 05:52:50.228437  9023 solver.cpp:222] Iteration 134520 (0.643895 iter/s, 62.1219s/40 iters), loss = 1.40295
I1028 05:52:50.228534  9023 solver.cpp:241]     Train net output #0: loss = 1.40295 (* 1 = 1.40295 loss)
I1028 05:52:50.228554  9023 sgd_solver.cpp:105] Iteration 134520, lr = 0.0015256
I1028 05:53:21.324343  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1028 05:53:21.503840  9023 solver.cpp:222] Iteration 134560 (1.27901 iter/s, 31.2741s/40 iters), loss = 1.41333
I1028 05:53:21.503909  9023 solver.cpp:241]     Train net output #0: loss = 1.41333 (* 1 = 1.41333 loss)
I1028 05:53:21.503924  9023 sgd_solver.cpp:105] Iteration 134560, lr = 0.00152354
I1028 05:54:04.803488  9023 solver.cpp:222] Iteration 134600 (0.923831 iter/s, 43.2979s/40 iters), loss = 1.65705
I1028 05:54:04.803706  9023 solver.cpp:241]     Train net output #0: loss = 1.65705 (* 1 = 1.65705 loss)
I1028 05:54:04.803722  9023 sgd_solver.cpp:105] Iteration 134600, lr = 0.00152148
I1028 05:54:37.360674  9023 solver.cpp:222] Iteration 134640 (1.22866 iter/s, 32.5557s/40 iters), loss = 1.108
I1028 05:54:37.360895  9023 solver.cpp:241]     Train net output #0: loss = 1.108 (* 1 = 1.108 loss)
I1028 05:54:37.360916  9023 sgd_solver.cpp:105] Iteration 134640, lr = 0.00151941
I1028 05:55:09.303975  9023 solver.cpp:222] Iteration 134680 (1.25227 iter/s, 31.9419s/40 iters), loss = 1.36635
I1028 05:55:09.304183  9023 solver.cpp:241]     Train net output #0: loss = 1.36635 (* 1 = 1.36635 loss)
I1028 05:55:09.304205  9023 sgd_solver.cpp:105] Iteration 134680, lr = 0.00151735
I1028 05:55:40.792395  9023 solver.cpp:222] Iteration 134720 (1.27036 iter/s, 31.487s/40 iters), loss = 1.62875
I1028 05:55:40.792651  9023 solver.cpp:241]     Train net output #0: loss = 1.62875 (* 1 = 1.62875 loss)
I1028 05:55:40.792668  9023 sgd_solver.cpp:105] Iteration 134720, lr = 0.00151529
I1028 05:56:11.566146  9023 solver.cpp:222] Iteration 134760 (1.29987 iter/s, 30.7723s/40 iters), loss = 1.33223
I1028 05:56:11.566376  9023 solver.cpp:241]     Train net output #0: loss = 1.33223 (* 1 = 1.33223 loss)
I1028 05:56:11.566391  9023 sgd_solver.cpp:105] Iteration 134760, lr = 0.00151323
I1028 05:56:43.242616  9023 solver.cpp:222] Iteration 134800 (1.26282 iter/s, 31.6751s/40 iters), loss = 1.35012
I1028 05:56:43.242786  9023 solver.cpp:241]     Train net output #0: loss = 1.35012 (* 1 = 1.35012 loss)
I1028 05:56:43.242802  9023 sgd_solver.cpp:105] Iteration 134800, lr = 0.00151117
I1028 05:57:14.121626  9023 solver.cpp:222] Iteration 134840 (1.29543 iter/s, 30.8777s/40 iters), loss = 1.522
I1028 05:57:14.121784  9023 solver.cpp:241]     Train net output #0: loss = 1.522 (* 1 = 1.522 loss)
I1028 05:57:14.121800  9023 sgd_solver.cpp:105] Iteration 134840, lr = 0.00150911
I1028 05:57:45.153617  9023 solver.cpp:222] Iteration 134880 (1.28905 iter/s, 31.0307s/40 iters), loss = 1.47837
I1028 05:57:45.153800  9023 solver.cpp:241]     Train net output #0: loss = 1.47837 (* 1 = 1.47837 loss)
I1028 05:57:45.153816  9023 sgd_solver.cpp:105] Iteration 134880, lr = 0.00150705
I1028 05:58:15.888921  9023 solver.cpp:222] Iteration 134920 (1.30149 iter/s, 30.734s/40 iters), loss = 1.52639
I1028 05:58:15.889130  9023 solver.cpp:241]     Train net output #0: loss = 1.52639 (* 1 = 1.52639 loss)
I1028 05:58:15.889147  9023 sgd_solver.cpp:105] Iteration 134920, lr = 0.00150499
I1028 05:58:47.535255  9023 solver.cpp:222] Iteration 134960 (1.26403 iter/s, 31.6449s/40 iters), loss = 1.17526
I1028 05:58:47.535434  9023 solver.cpp:241]     Train net output #0: loss = 1.17526 (* 1 = 1.17526 loss)
I1028 05:58:47.535449  9023 sgd_solver.cpp:105] Iteration 134960, lr = 0.00150293
I1028 05:59:17.953989  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_135000.caffemodel
I1028 05:59:17.991322  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_135000.solverstate
I1028 05:59:18.007942  9023 solver.cpp:334] Iteration 135000, Testing net (#0)
I1028 05:59:49.301929  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 05:59:49.510455  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57112
I1028 05:59:49.510509  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.805799
I1028 05:59:49.510524  9023 solver.cpp:401]     Test net output #2: loss = 1.89082 (* 1 = 1.89082 loss)
I1028 05:59:50.278185  9023 solver.cpp:222] Iteration 135000 (0.637548 iter/s, 62.7404s/40 iters), loss = 1.41812
I1028 05:59:50.278252  9023 solver.cpp:241]     Train net output #0: loss = 1.41812 (* 1 = 1.41812 loss)
I1028 05:59:50.278268  9023 sgd_solver.cpp:105] Iteration 135000, lr = 0.00150087
I1028 06:00:20.995563  9023 solver.cpp:222] Iteration 135040 (1.30225 iter/s, 30.7161s/40 iters), loss = 1.49245
I1028 06:00:20.995754  9023 solver.cpp:241]     Train net output #0: loss = 1.49245 (* 1 = 1.49245 loss)
I1028 06:00:20.995780  9023 sgd_solver.cpp:105] Iteration 135040, lr = 0.00149881
I1028 06:00:51.828074  9023 solver.cpp:222] Iteration 135080 (1.29739 iter/s, 30.8312s/40 iters), loss = 1.22512
I1028 06:00:51.828244  9023 solver.cpp:241]     Train net output #0: loss = 1.22512 (* 1 = 1.22512 loss)
I1028 06:00:51.828259  9023 sgd_solver.cpp:105] Iteration 135080, lr = 0.00149675
I1028 06:01:23.086082  9023 solver.cpp:222] Iteration 135120 (1.27973 iter/s, 31.2567s/40 iters), loss = 1.34605
I1028 06:01:23.086282  9023 solver.cpp:241]     Train net output #0: loss = 1.34605 (* 1 = 1.34605 loss)
I1028 06:01:23.086302  9023 sgd_solver.cpp:105] Iteration 135120, lr = 0.0014947
I1028 06:01:54.177611  9023 solver.cpp:222] Iteration 135160 (1.28658 iter/s, 31.0902s/40 iters), loss = 1.71464
I1028 06:01:54.177866  9023 solver.cpp:241]     Train net output #0: loss = 1.71464 (* 1 = 1.71464 loss)
I1028 06:01:54.177883  9023 sgd_solver.cpp:105] Iteration 135160, lr = 0.00149264
I1028 06:02:25.317410  9023 solver.cpp:222] Iteration 135200 (1.28459 iter/s, 31.1384s/40 iters), loss = 1.44658
I1028 06:02:25.317608  9023 solver.cpp:241]     Train net output #0: loss = 1.44658 (* 1 = 1.44658 loss)
I1028 06:02:25.317625  9023 sgd_solver.cpp:105] Iteration 135200, lr = 0.00149058
I1028 06:02:56.184777  9023 solver.cpp:222] Iteration 135240 (1.29592 iter/s, 30.866s/40 iters), loss = 1.34207
I1028 06:02:56.184979  9023 solver.cpp:241]     Train net output #0: loss = 1.34207 (* 1 = 1.34207 loss)
I1028 06:02:56.184995  9023 sgd_solver.cpp:105] Iteration 135240, lr = 0.00148853
I1028 06:03:26.855931  9023 solver.cpp:222] Iteration 135280 (1.30421 iter/s, 30.6698s/40 iters), loss = 1.33715
I1028 06:03:26.856092  9023 solver.cpp:241]     Train net output #0: loss = 1.33715 (* 1 = 1.33715 loss)
I1028 06:03:26.856108  9023 sgd_solver.cpp:105] Iteration 135280, lr = 0.00148647
I1028 06:03:57.943784  9023 solver.cpp:222] Iteration 135320 (1.28673 iter/s, 31.0865s/40 iters), loss = 1.35406
I1028 06:03:57.943964  9023 solver.cpp:241]     Train net output #0: loss = 1.35406 (* 1 = 1.35406 loss)
I1028 06:03:57.943980  9023 sgd_solver.cpp:105] Iteration 135320, lr = 0.00148442
I1028 06:04:30.021780  9023 solver.cpp:222] Iteration 135360 (1.24702 iter/s, 32.0766s/40 iters), loss = 1.47345
I1028 06:04:30.022049  9023 solver.cpp:241]     Train net output #0: loss = 1.47345 (* 1 = 1.47345 loss)
I1028 06:04:30.022078  9023 sgd_solver.cpp:105] Iteration 135360, lr = 0.00148236
I1028 06:05:01.945556  9023 solver.cpp:222] Iteration 135400 (1.25304 iter/s, 31.9223s/40 iters), loss = 1.45269
I1028 06:05:01.945822  9023 solver.cpp:241]     Train net output #0: loss = 1.45269 (* 1 = 1.45269 loss)
I1028 06:05:01.945857  9023 sgd_solver.cpp:105] Iteration 135400, lr = 0.00148031
I1028 06:05:32.826429  9023 solver.cpp:222] Iteration 135440 (1.29536 iter/s, 30.8794s/40 iters), loss = 1.38426
I1028 06:05:32.826628  9023 solver.cpp:241]     Train net output #0: loss = 1.38426 (* 1 = 1.38426 loss)
I1028 06:05:32.826644  9023 sgd_solver.cpp:105] Iteration 135440, lr = 0.00147826
I1028 06:06:03.595693  9023 solver.cpp:222] Iteration 135480 (1.30006 iter/s, 30.7679s/40 iters), loss = 1.31841
I1028 06:06:03.595890  9023 solver.cpp:241]     Train net output #0: loss = 1.31841 (* 1 = 1.31841 loss)
I1028 06:06:03.595904  9023 sgd_solver.cpp:105] Iteration 135480, lr = 0.0014762
I1028 06:06:18.843051  9023 solver.cpp:334] Iteration 135500, Testing net (#0)
I1028 06:06:50.280828  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57632
I1028 06:06:50.281020  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80236
I1028 06:06:50.281035  9023 solver.cpp:401]     Test net output #2: loss = 1.90557 (* 1 = 1.90557 loss)
I1028 06:07:06.794960  9023 solver.cpp:222] Iteration 135520 (0.632945 iter/s, 63.1967s/40 iters), loss = 1.71875
I1028 06:07:06.795027  9023 solver.cpp:241]     Train net output #0: loss = 1.71875 (* 1 = 1.71875 loss)
I1028 06:07:06.795044  9023 sgd_solver.cpp:105] Iteration 135520, lr = 0.00147415
I1028 06:07:37.982471  9023 solver.cpp:222] Iteration 135560 (1.28262 iter/s, 31.1863s/40 iters), loss = 1.51213
I1028 06:07:37.982684  9023 solver.cpp:241]     Train net output #0: loss = 1.51213 (* 1 = 1.51213 loss)
I1028 06:07:37.982702  9023 sgd_solver.cpp:105] Iteration 135560, lr = 0.0014721
I1028 06:08:09.243604  9023 solver.cpp:222] Iteration 135600 (1.2796 iter/s, 31.2597s/40 iters), loss = 1.4331
I1028 06:08:09.243821  9023 solver.cpp:241]     Train net output #0: loss = 1.4331 (* 1 = 1.4331 loss)
I1028 06:08:09.243839  9023 sgd_solver.cpp:105] Iteration 135600, lr = 0.00147005
I1028 06:08:40.740339  9023 solver.cpp:222] Iteration 135640 (1.27003 iter/s, 31.4953s/40 iters), loss = 1.35297
I1028 06:08:40.740517  9023 solver.cpp:241]     Train net output #0: loss = 1.35297 (* 1 = 1.35297 loss)
I1028 06:08:40.740553  9023 sgd_solver.cpp:105] Iteration 135640, lr = 0.001468
I1028 06:09:11.718250  9023 solver.cpp:222] Iteration 135680 (1.2913 iter/s, 30.9766s/40 iters), loss = 1.4575
I1028 06:09:11.718518  9023 solver.cpp:241]     Train net output #0: loss = 1.4575 (* 1 = 1.4575 loss)
I1028 06:09:11.718565  9023 sgd_solver.cpp:105] Iteration 135680, lr = 0.00146595
I1028 06:09:43.216092  9023 solver.cpp:222] Iteration 135720 (1.26999 iter/s, 31.4964s/40 iters), loss = 1.60791
I1028 06:09:43.216276  9023 solver.cpp:241]     Train net output #0: loss = 1.60791 (* 1 = 1.60791 loss)
I1028 06:09:43.216294  9023 sgd_solver.cpp:105] Iteration 135720, lr = 0.0014639
I1028 06:10:18.751998  9023 solver.cpp:222] Iteration 135760 (1.12567 iter/s, 35.5344s/40 iters), loss = 1.31501
I1028 06:10:18.752189  9023 solver.cpp:241]     Train net output #0: loss = 1.31501 (* 1 = 1.31501 loss)
I1028 06:10:18.752212  9023 sgd_solver.cpp:105] Iteration 135760, lr = 0.00146185
I1028 06:11:04.732333  9023 solver.cpp:222] Iteration 135800 (0.869973 iter/s, 45.9784s/40 iters), loss = 1.66897
I1028 06:11:04.732513  9023 solver.cpp:241]     Train net output #0: loss = 1.66897 (* 1 = 1.66897 loss)
I1028 06:11:04.732529  9023 sgd_solver.cpp:105] Iteration 135800, lr = 0.0014598
I1028 06:11:35.648041  9023 solver.cpp:222] Iteration 135840 (1.2939 iter/s, 30.9144s/40 iters), loss = 1.58901
I1028 06:11:35.648243  9023 solver.cpp:241]     Train net output #0: loss = 1.58901 (* 1 = 1.58901 loss)
I1028 06:11:35.648269  9023 sgd_solver.cpp:105] Iteration 135840, lr = 0.00145775
I1028 06:12:09.425612  9023 solver.cpp:222] Iteration 135880 (1.18427 iter/s, 33.7761s/40 iters), loss = 1.08562
I1028 06:12:09.425814  9023 solver.cpp:241]     Train net output #0: loss = 1.08562 (* 1 = 1.08562 loss)
I1028 06:12:09.425830  9023 sgd_solver.cpp:105] Iteration 135880, lr = 0.0014557
I1028 06:12:39.527333  9023 solver.cpp:222] Iteration 135920 (1.32889 iter/s, 30.1004s/40 iters), loss = 1.64937
I1028 06:12:39.527541  9023 solver.cpp:241]     Train net output #0: loss = 1.64937 (* 1 = 1.64937 loss)
I1028 06:12:39.527557  9023 sgd_solver.cpp:105] Iteration 135920, lr = 0.00145365
I1028 06:13:10.418087  9023 solver.cpp:222] Iteration 135960 (1.29494 iter/s, 30.8894s/40 iters), loss = 1.4726
I1028 06:13:10.418256  9023 solver.cpp:241]     Train net output #0: loss = 1.4726 (* 1 = 1.4726 loss)
I1028 06:13:10.418272  9023 sgd_solver.cpp:105] Iteration 135960, lr = 0.00145161
I1028 06:13:40.588980  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_136000.caffemodel
I1028 06:13:40.620640  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_136000.solverstate
I1028 06:13:40.637262  9023 solver.cpp:334] Iteration 136000, Testing net (#0)
I1028 06:14:11.655519  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 06:14:11.866753  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57156
I1028 06:14:11.866816  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.804559
I1028 06:14:11.866829  9023 solver.cpp:401]     Test net output #2: loss = 1.89222 (* 1 = 1.89222 loss)
I1028 06:14:12.638797  9023 solver.cpp:222] Iteration 136000 (0.642898 iter/s, 62.2182s/40 iters), loss = 1.31727
I1028 06:14:12.638864  9023 solver.cpp:241]     Train net output #0: loss = 1.31727 (* 1 = 1.31727 loss)
I1028 06:14:12.638878  9023 sgd_solver.cpp:105] Iteration 136000, lr = 0.00144956
I1028 06:14:43.607184  9023 solver.cpp:222] Iteration 136040 (1.29169 iter/s, 30.9671s/40 iters), loss = 1.35099
I1028 06:14:43.607368  9023 solver.cpp:241]     Train net output #0: loss = 1.35099 (* 1 = 1.35099 loss)
I1028 06:14:43.607384  9023 sgd_solver.cpp:105] Iteration 136040, lr = 0.00144751
I1028 06:15:17.127238  9023 solver.cpp:222] Iteration 136080 (1.19337 iter/s, 33.5186s/40 iters), loss = 1.58643
I1028 06:15:17.127511  9023 solver.cpp:241]     Train net output #0: loss = 1.58643 (* 1 = 1.58643 loss)
I1028 06:15:17.127554  9023 sgd_solver.cpp:105] Iteration 136080, lr = 0.00144547
I1028 06:15:50.012766  9023 solver.cpp:222] Iteration 136120 (1.2164 iter/s, 32.884s/40 iters), loss = 1.44082
I1028 06:15:50.013041  9023 solver.cpp:241]     Train net output #0: loss = 1.44082 (* 1 = 1.44082 loss)
I1028 06:15:50.013062  9023 sgd_solver.cpp:105] Iteration 136120, lr = 0.00144342
I1028 06:16:21.067680  9023 solver.cpp:222] Iteration 136160 (1.2881 iter/s, 31.0535s/40 iters), loss = 1.42559
I1028 06:16:21.067869  9023 solver.cpp:241]     Train net output #0: loss = 1.42559 (* 1 = 1.42559 loss)
I1028 06:16:21.067886  9023 sgd_solver.cpp:105] Iteration 136160, lr = 0.00144138
I1028 06:16:52.230504  9023 solver.cpp:222] Iteration 136200 (1.28364 iter/s, 31.1615s/40 iters), loss = 1.717
I1028 06:16:52.230684  9023 solver.cpp:241]     Train net output #0: loss = 1.717 (* 1 = 1.717 loss)
I1028 06:16:52.230700  9023 sgd_solver.cpp:105] Iteration 136200, lr = 0.00143933
I1028 06:17:23.263406  9023 solver.cpp:222] Iteration 136240 (1.28901 iter/s, 31.0316s/40 iters), loss = 1.237
I1028 06:17:23.263576  9023 solver.cpp:241]     Train net output #0: loss = 1.237 (* 1 = 1.237 loss)
I1028 06:17:23.263592  9023 sgd_solver.cpp:105] Iteration 136240, lr = 0.00143729
I1028 06:17:54.452668  9023 solver.cpp:222] Iteration 136280 (1.28255 iter/s, 31.1879s/40 iters), loss = 1.35422
I1028 06:17:54.452847  9023 solver.cpp:241]     Train net output #0: loss = 1.35422 (* 1 = 1.35422 loss)
I1028 06:17:54.452862  9023 sgd_solver.cpp:105] Iteration 136280, lr = 0.00143525
I1028 06:18:25.443909  9023 solver.cpp:222] Iteration 136320 (1.29074 iter/s, 30.9899s/40 iters), loss = 1.61584
I1028 06:18:25.444103  9023 solver.cpp:241]     Train net output #0: loss = 1.61584 (* 1 = 1.61584 loss)
I1028 06:18:25.444119  9023 sgd_solver.cpp:105] Iteration 136320, lr = 0.0014332
I1028 06:18:56.296898  9023 solver.cpp:222] Iteration 136360 (1.29653 iter/s, 30.8516s/40 iters), loss = 1.14889
I1028 06:18:56.297073  9023 solver.cpp:241]     Train net output #0: loss = 1.14889 (* 1 = 1.14889 loss)
I1028 06:18:56.297089  9023 sgd_solver.cpp:105] Iteration 136360, lr = 0.00143116
I1028 06:19:27.129484  9023 solver.cpp:222] Iteration 136400 (1.29739 iter/s, 30.8312s/40 iters), loss = 1.30669
I1028 06:19:27.129652  9023 solver.cpp:241]     Train net output #0: loss = 1.30669 (* 1 = 1.30669 loss)
I1028 06:19:27.129669  9023 sgd_solver.cpp:105] Iteration 136400, lr = 0.00142912
I1028 06:19:58.164556  9023 solver.cpp:222] Iteration 136440 (1.28892 iter/s, 31.0337s/40 iters), loss = 1.39811
I1028 06:19:58.164762  9023 solver.cpp:241]     Train net output #0: loss = 1.39811 (* 1 = 1.39811 loss)
I1028 06:19:58.164788  9023 sgd_solver.cpp:105] Iteration 136440, lr = 0.00142708
I1028 06:20:29.083211  9023 solver.cpp:222] Iteration 136480 (1.29377 iter/s, 30.9173s/40 iters), loss = 1.33112
I1028 06:20:29.083395  9023 solver.cpp:241]     Train net output #0: loss = 1.33112 (* 1 = 1.33112 loss)
I1028 06:20:29.083411  9023 sgd_solver.cpp:105] Iteration 136480, lr = 0.00142504
I1028 06:20:43.759465  9023 solver.cpp:334] Iteration 136500, Testing net (#0)
I1028 06:21:15.105026  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57316
I1028 06:21:15.105226  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.803159
I1028 06:21:15.105242  9023 solver.cpp:401]     Test net output #2: loss = 1.88612 (* 1 = 1.88612 loss)
I1028 06:21:31.326097  9023 solver.cpp:222] Iteration 136520 (0.64267 iter/s, 62.2404s/40 iters), loss = 1.69702
I1028 06:21:31.326166  9023 solver.cpp:241]     Train net output #0: loss = 1.69702 (* 1 = 1.69702 loss)
I1028 06:21:31.326182  9023 sgd_solver.cpp:105] Iteration 136520, lr = 0.001423
I1028 06:22:02.186866  9023 solver.cpp:222] Iteration 136560 (1.2962 iter/s, 30.8595s/40 iters), loss = 1.5051
I1028 06:22:02.187043  9023 solver.cpp:241]     Train net output #0: loss = 1.5051 (* 1 = 1.5051 loss)
I1028 06:22:02.187058  9023 sgd_solver.cpp:105] Iteration 136560, lr = 0.00142096
I1028 06:22:33.390617  9023 solver.cpp:222] Iteration 136600 (1.28195 iter/s, 31.2024s/40 iters), loss = 1.38126
I1028 06:22:33.390889  9023 solver.cpp:241]     Train net output #0: loss = 1.38126 (* 1 = 1.38126 loss)
I1028 06:22:33.390934  9023 sgd_solver.cpp:105] Iteration 136600, lr = 0.00141892
I1028 06:23:04.380915  9023 solver.cpp:222] Iteration 136640 (1.29079 iter/s, 30.9889s/40 iters), loss = 1.74773
I1028 06:23:04.381119  9023 solver.cpp:241]     Train net output #0: loss = 1.74773 (* 1 = 1.74773 loss)
I1028 06:23:04.381134  9023 sgd_solver.cpp:105] Iteration 136640, lr = 0.00141688
I1028 06:23:35.967211  9023 solver.cpp:222] Iteration 136680 (1.26643 iter/s, 31.5849s/40 iters), loss = 1.52502
I1028 06:23:35.967473  9023 solver.cpp:241]     Train net output #0: loss = 1.52502 (* 1 = 1.52502 loss)
I1028 06:23:35.967509  9023 sgd_solver.cpp:105] Iteration 136680, lr = 0.00141484
I1028 06:24:07.483712  9023 solver.cpp:222] Iteration 136720 (1.26923 iter/s, 31.5151s/40 iters), loss = 1.55208
I1028 06:24:07.483898  9023 solver.cpp:241]     Train net output #0: loss = 1.55208 (* 1 = 1.55208 loss)
I1028 06:24:07.483914  9023 sgd_solver.cpp:105] Iteration 136720, lr = 0.0014128
I1028 06:24:38.768986  9023 solver.cpp:222] Iteration 136760 (1.27861 iter/s, 31.2839s/40 iters), loss = 1.3022
I1028 06:24:38.769177  9023 solver.cpp:241]     Train net output #0: loss = 1.3022 (* 1 = 1.3022 loss)
I1028 06:24:38.769194  9023 sgd_solver.cpp:105] Iteration 136760, lr = 0.00141076
I1028 06:25:09.678751  9023 solver.cpp:222] Iteration 136800 (1.29415 iter/s, 30.9084s/40 iters), loss = 1.84287
I1028 06:25:09.678931  9023 solver.cpp:241]     Train net output #0: loss = 1.84287 (* 1 = 1.84287 loss)
I1028 06:25:09.678948  9023 sgd_solver.cpp:105] Iteration 136800, lr = 0.00140873
I1028 06:25:40.480253  9023 solver.cpp:222] Iteration 136840 (1.29869 iter/s, 30.8002s/40 iters), loss = 1.36999
I1028 06:25:40.480430  9023 solver.cpp:241]     Train net output #0: loss = 1.36999 (* 1 = 1.36999 loss)
I1028 06:25:40.480448  9023 sgd_solver.cpp:105] Iteration 136840, lr = 0.00140669
I1028 06:26:11.159382  9023 solver.cpp:222] Iteration 136880 (1.30388 iter/s, 30.6778s/40 iters), loss = 1.76484
I1028 06:26:11.159551  9023 solver.cpp:241]     Train net output #0: loss = 1.76484 (* 1 = 1.76484 loss)
I1028 06:26:11.159567  9023 sgd_solver.cpp:105] Iteration 136880, lr = 0.00140465
I1028 06:26:41.702952  9023 solver.cpp:222] Iteration 136920 (1.30966 iter/s, 30.5422s/40 iters), loss = 1.64824
I1028 06:26:41.703131  9023 solver.cpp:241]     Train net output #0: loss = 1.64824 (* 1 = 1.64824 loss)
I1028 06:26:41.703147  9023 sgd_solver.cpp:105] Iteration 136920, lr = 0.00140262
I1028 06:27:12.482702  9023 solver.cpp:222] Iteration 136960 (1.29961 iter/s, 30.7784s/40 iters), loss = 1.42095
I1028 06:27:12.482888  9023 solver.cpp:241]     Train net output #0: loss = 1.42095 (* 1 = 1.42095 loss)
I1028 06:27:12.482905  9023 sgd_solver.cpp:105] Iteration 136960, lr = 0.00140058
I1028 06:27:42.473417  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_137000.caffemodel
I1028 06:27:42.509500  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_137000.solverstate
I1028 06:27:42.531507  9023 solver.cpp:334] Iteration 137000, Testing net (#0)
I1028 06:28:14.153666  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 06:28:14.368585  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57604
I1028 06:28:14.368646  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80432
I1028 06:28:14.368659  9023 solver.cpp:401]     Test net output #2: loss = 1.89091 (* 1 = 1.89091 loss)
I1028 06:28:15.137125  9023 solver.cpp:222] Iteration 137000 (0.638448 iter/s, 62.6519s/40 iters), loss = 1.52301
I1028 06:28:15.137192  9023 solver.cpp:241]     Train net output #0: loss = 1.52301 (* 1 = 1.52301 loss)
I1028 06:28:15.137207  9023 sgd_solver.cpp:105] Iteration 137000, lr = 0.00139855
I1028 06:28:45.861063  9023 solver.cpp:222] Iteration 137040 (1.30197 iter/s, 30.7227s/40 iters), loss = 1.67901
I1028 06:28:45.861577  9023 solver.cpp:241]     Train net output #0: loss = 1.67901 (* 1 = 1.67901 loss)
I1028 06:28:45.861611  9023 sgd_solver.cpp:105] Iteration 137040, lr = 0.00139652
I1028 06:29:02.825362  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1028 06:29:16.570024  9023 solver.cpp:222] Iteration 137080 (1.30262 iter/s, 30.7073s/40 iters), loss = 0.988098
I1028 06:29:16.570212  9023 solver.cpp:241]     Train net output #0: loss = 0.988098 (* 1 = 0.988098 loss)
I1028 06:29:16.570230  9023 sgd_solver.cpp:105] Iteration 137080, lr = 0.00139448
I1028 06:29:47.504483  9023 solver.cpp:222] Iteration 137120 (1.29311 iter/s, 30.9331s/40 iters), loss = 1.51049
I1028 06:29:47.504688  9023 solver.cpp:241]     Train net output #0: loss = 1.51049 (* 1 = 1.51049 loss)
I1028 06:29:47.504704  9023 sgd_solver.cpp:105] Iteration 137120, lr = 0.00139245
I1028 06:30:18.216521  9023 solver.cpp:222] Iteration 137160 (1.30248 iter/s, 30.7107s/40 iters), loss = 1.37264
I1028 06:30:18.216702  9023 solver.cpp:241]     Train net output #0: loss = 1.37264 (* 1 = 1.37264 loss)
I1028 06:30:18.216728  9023 sgd_solver.cpp:105] Iteration 137160, lr = 0.00139042
I1028 06:30:48.915832  9023 solver.cpp:222] Iteration 137200 (1.30302 iter/s, 30.698s/40 iters), loss = 1.88653
I1028 06:30:48.916015  9023 solver.cpp:241]     Train net output #0: loss = 1.88653 (* 1 = 1.88653 loss)
I1028 06:30:48.916031  9023 sgd_solver.cpp:105] Iteration 137200, lr = 0.00138838
I1028 06:31:19.702559  9023 solver.cpp:222] Iteration 137240 (1.29932 iter/s, 30.7854s/40 iters), loss = 1.33112
I1028 06:31:19.702764  9023 solver.cpp:241]     Train net output #0: loss = 1.33112 (* 1 = 1.33112 loss)
I1028 06:31:19.702780  9023 sgd_solver.cpp:105] Iteration 137240, lr = 0.00138635
I1028 06:31:50.565213  9023 solver.cpp:222] Iteration 137280 (1.29612 iter/s, 30.8613s/40 iters), loss = 1.57156
I1028 06:31:50.565413  9023 solver.cpp:241]     Train net output #0: loss = 1.57156 (* 1 = 1.57156 loss)
I1028 06:31:50.565429  9023 sgd_solver.cpp:105] Iteration 137280, lr = 0.00138432
I1028 06:32:21.301856  9023 solver.cpp:222] Iteration 137320 (1.30144 iter/s, 30.7353s/40 iters), loss = 1.55322
I1028 06:32:21.302016  9023 solver.cpp:241]     Train net output #0: loss = 1.55322 (* 1 = 1.55322 loss)
I1028 06:32:21.302032  9023 sgd_solver.cpp:105] Iteration 137320, lr = 0.00138229
I1028 06:32:54.082063  9023 solver.cpp:222] Iteration 137360 (1.2203 iter/s, 32.7788s/40 iters), loss = 1.58816
I1028 06:32:54.082265  9023 solver.cpp:241]     Train net output #0: loss = 1.58816 (* 1 = 1.58816 loss)
I1028 06:32:54.082288  9023 sgd_solver.cpp:105] Iteration 137360, lr = 0.00138026
I1028 06:33:25.533287  9023 solver.cpp:222] Iteration 137400 (1.27187 iter/s, 31.4498s/40 iters), loss = 1.52726
I1028 06:33:25.533489  9023 solver.cpp:241]     Train net output #0: loss = 1.52726 (* 1 = 1.52726 loss)
I1028 06:33:25.533506  9023 sgd_solver.cpp:105] Iteration 137400, lr = 0.00137823
I1028 06:33:56.261119  9023 solver.cpp:222] Iteration 137440 (1.30181 iter/s, 30.7265s/40 iters), loss = 1.36313
I1028 06:33:56.261287  9023 solver.cpp:241]     Train net output #0: loss = 1.36313 (* 1 = 1.36313 loss)
I1028 06:33:56.261309  9023 sgd_solver.cpp:105] Iteration 137440, lr = 0.0013762
I1028 06:34:27.233475  9023 solver.cpp:222] Iteration 137480 (1.29153 iter/s, 30.971s/40 iters), loss = 1.6597
I1028 06:34:27.233667  9023 solver.cpp:241]     Train net output #0: loss = 1.6597 (* 1 = 1.6597 loss)
I1028 06:34:27.233683  9023 sgd_solver.cpp:105] Iteration 137480, lr = 0.00137417
I1028 06:34:41.952342  9023 solver.cpp:334] Iteration 137500, Testing net (#0)
I1028 06:35:13.675456  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57512
I1028 06:35:13.675635  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80384
I1028 06:35:13.675652  9023 solver.cpp:401]     Test net output #2: loss = 1.86777 (* 1 = 1.86777 loss)
I1028 06:35:29.789829  9023 solver.cpp:222] Iteration 137520 (0.639449 iter/s, 62.5538s/40 iters), loss = 1.4432
I1028 06:35:29.789898  9023 solver.cpp:241]     Train net output #0: loss = 1.4432 (* 1 = 1.4432 loss)
I1028 06:35:29.789928  9023 sgd_solver.cpp:105] Iteration 137520, lr = 0.00137215
I1028 06:36:00.694679  9023 solver.cpp:222] Iteration 137560 (1.29435 iter/s, 30.9036s/40 iters), loss = 1.23387
I1028 06:36:00.694937  9023 solver.cpp:241]     Train net output #0: loss = 1.23387 (* 1 = 1.23387 loss)
I1028 06:36:00.694962  9023 sgd_solver.cpp:105] Iteration 137560, lr = 0.00137012
I1028 06:36:31.419966  9023 solver.cpp:222] Iteration 137600 (1.30192 iter/s, 30.7239s/40 iters), loss = 1.44378
I1028 06:36:31.420148  9023 solver.cpp:241]     Train net output #0: loss = 1.44378 (* 1 = 1.44378 loss)
I1028 06:36:31.420166  9023 sgd_solver.cpp:105] Iteration 137600, lr = 0.00136809
I1028 06:37:02.043315  9023 solver.cpp:222] Iteration 137640 (1.30625 iter/s, 30.622s/40 iters), loss = 1.72428
I1028 06:37:02.043464  9023 solver.cpp:241]     Train net output #0: loss = 1.72428 (* 1 = 1.72428 loss)
I1028 06:37:02.043480  9023 sgd_solver.cpp:105] Iteration 137640, lr = 0.00136607
I1028 06:37:32.662060  9023 solver.cpp:222] Iteration 137680 (1.30645 iter/s, 30.6174s/40 iters), loss = 1.61412
I1028 06:37:32.662219  9023 solver.cpp:241]     Train net output #0: loss = 1.61412 (* 1 = 1.61412 loss)
I1028 06:37:32.662235  9023 sgd_solver.cpp:105] Iteration 137680, lr = 0.00136404
I1028 06:38:03.409545  9023 solver.cpp:222] Iteration 137720 (1.30098 iter/s, 30.7462s/40 iters), loss = 1.44553
I1028 06:38:03.409732  9023 solver.cpp:241]     Train net output #0: loss = 1.44553 (* 1 = 1.44553 loss)
I1028 06:38:03.409749  9023 sgd_solver.cpp:105] Iteration 137720, lr = 0.00136201
I1028 06:38:34.228021  9023 solver.cpp:222] Iteration 137760 (1.29798 iter/s, 30.8171s/40 iters), loss = 1.78883
I1028 06:38:34.228219  9023 solver.cpp:241]     Train net output #0: loss = 1.78883 (* 1 = 1.78883 loss)
I1028 06:38:34.228235  9023 sgd_solver.cpp:105] Iteration 137760, lr = 0.00135999
I1028 06:39:05.585577  9023 solver.cpp:222] Iteration 137800 (1.27567 iter/s, 31.3562s/40 iters), loss = 1.34377
I1028 06:39:05.585752  9023 solver.cpp:241]     Train net output #0: loss = 1.34377 (* 1 = 1.34377 loss)
I1028 06:39:05.585770  9023 sgd_solver.cpp:105] Iteration 137800, lr = 0.00135796
I1028 06:39:36.468814  9023 solver.cpp:222] Iteration 137840 (1.29526 iter/s, 30.8819s/40 iters), loss = 1.39592
I1028 06:39:36.469003  9023 solver.cpp:241]     Train net output #0: loss = 1.39592 (* 1 = 1.39592 loss)
I1028 06:39:36.469019  9023 sgd_solver.cpp:105] Iteration 137840, lr = 0.00135594
I1028 06:40:07.653537  9023 solver.cpp:222] Iteration 137880 (1.28274 iter/s, 31.1833s/40 iters), loss = 1.35212
I1028 06:40:07.653720  9023 solver.cpp:241]     Train net output #0: loss = 1.35212 (* 1 = 1.35212 loss)
I1028 06:40:07.653736  9023 sgd_solver.cpp:105] Iteration 137880, lr = 0.00135392
I1028 06:40:38.495100  9023 solver.cpp:222] Iteration 137920 (1.29701 iter/s, 30.8402s/40 iters), loss = 1.53441
I1028 06:40:38.495270  9023 solver.cpp:241]     Train net output #0: loss = 1.53441 (* 1 = 1.53441 loss)
I1028 06:40:38.495286  9023 sgd_solver.cpp:105] Iteration 137920, lr = 0.00135189
I1028 06:41:24.558291  9023 solver.cpp:222] Iteration 137960 (0.868408 iter/s, 46.0613s/40 iters), loss = 1.66141
I1028 06:41:24.558562  9023 solver.cpp:241]     Train net output #0: loss = 1.66141 (* 1 = 1.66141 loss)
I1028 06:41:24.558593  9023 sgd_solver.cpp:105] Iteration 137960, lr = 0.00134987
I1028 06:41:57.330245  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_138000.caffemodel
I1028 06:42:17.092900  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_138000.solverstate
I1028 06:42:17.727354  9023 solver.cpp:334] Iteration 138000, Testing net (#0)
I1028 06:42:49.440343  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 06:42:49.654038  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57316
I1028 06:42:49.654095  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.806559
I1028 06:42:49.654119  9023 solver.cpp:401]     Test net output #2: loss = 1.89626 (* 1 = 1.89626 loss)
I1028 06:42:50.411191  9023 solver.cpp:222] Iteration 138000 (0.465932 iter/s, 85.8495s/40 iters), loss = 0.974795
I1028 06:42:50.411239  9023 solver.cpp:241]     Train net output #0: loss = 0.974795 (* 1 = 0.974795 loss)
I1028 06:42:50.411254  9023 sgd_solver.cpp:105] Iteration 138000, lr = 0.00134785
I1028 06:43:22.156029  9023 solver.cpp:222] Iteration 138040 (1.2601 iter/s, 31.7436s/40 iters), loss = 1.4465
I1028 06:43:22.156288  9023 solver.cpp:241]     Train net output #0: loss = 1.4465 (* 1 = 1.4465 loss)
I1028 06:43:22.156311  9023 sgd_solver.cpp:105] Iteration 138040, lr = 0.00134583
I1028 06:43:53.850334  9023 solver.cpp:222] Iteration 138080 (1.26211 iter/s, 31.6929s/40 iters), loss = 1.56451
I1028 06:43:53.850505  9023 solver.cpp:241]     Train net output #0: loss = 1.56451 (* 1 = 1.56451 loss)
I1028 06:43:53.850522  9023 sgd_solver.cpp:105] Iteration 138080, lr = 0.00134381
I1028 06:44:25.330720  9023 solver.cpp:222] Iteration 138120 (1.27069 iter/s, 31.479s/40 iters), loss = 1.63619
I1028 06:44:25.330909  9023 solver.cpp:241]     Train net output #0: loss = 1.63619 (* 1 = 1.63619 loss)
I1028 06:44:25.330925  9023 sgd_solver.cpp:105] Iteration 138120, lr = 0.00134179
I1028 06:44:56.440096  9023 solver.cpp:222] Iteration 138160 (1.28584 iter/s, 31.108s/40 iters), loss = 1.44074
I1028 06:44:56.440274  9023 solver.cpp:241]     Train net output #0: loss = 1.44074 (* 1 = 1.44074 loss)
I1028 06:44:56.440289  9023 sgd_solver.cpp:105] Iteration 138160, lr = 0.00133977
I1028 06:45:27.590862  9023 solver.cpp:222] Iteration 138200 (1.28413 iter/s, 31.1494s/40 iters), loss = 1.26725
I1028 06:45:27.591049  9023 solver.cpp:241]     Train net output #0: loss = 1.26725 (* 1 = 1.26725 loss)
I1028 06:45:27.591066  9023 sgd_solver.cpp:105] Iteration 138200, lr = 0.00133775
I1028 06:45:59.323567  9023 solver.cpp:222] Iteration 138240 (1.26058 iter/s, 31.7313s/40 iters), loss = 1.38846
I1028 06:45:59.323771  9023 solver.cpp:241]     Train net output #0: loss = 1.38846 (* 1 = 1.38846 loss)
I1028 06:45:59.323786  9023 sgd_solver.cpp:105] Iteration 138240, lr = 0.00133573
I1028 06:46:30.806946  9023 solver.cpp:222] Iteration 138280 (1.27057 iter/s, 31.482s/40 iters), loss = 1.81051
I1028 06:46:30.807157  9023 solver.cpp:241]     Train net output #0: loss = 1.81051 (* 1 = 1.81051 loss)
I1028 06:46:30.807171  9023 sgd_solver.cpp:105] Iteration 138280, lr = 0.00133371
I1028 06:47:01.559069  9023 solver.cpp:222] Iteration 138320 (1.30078 iter/s, 30.7507s/40 iters), loss = 1.24417
I1028 06:47:01.559231  9023 solver.cpp:241]     Train net output #0: loss = 1.24417 (* 1 = 1.24417 loss)
I1028 06:47:01.559247  9023 sgd_solver.cpp:105] Iteration 138320, lr = 0.00133169
I1028 06:47:32.452145  9023 solver.cpp:222] Iteration 138360 (1.29484 iter/s, 30.8918s/40 iters), loss = 1.18789
I1028 06:47:32.452327  9023 solver.cpp:241]     Train net output #0: loss = 1.18789 (* 1 = 1.18789 loss)
I1028 06:47:32.452344  9023 sgd_solver.cpp:105] Iteration 138360, lr = 0.00132967
I1028 06:48:03.829162  9023 solver.cpp:222] Iteration 138400 (1.27487 iter/s, 31.3757s/40 iters), loss = 1.3517
I1028 06:48:03.829344  9023 solver.cpp:241]     Train net output #0: loss = 1.3517 (* 1 = 1.3517 loss)
I1028 06:48:03.829360  9023 sgd_solver.cpp:105] Iteration 138400, lr = 0.00132766
I1028 06:48:36.147209  9023 solver.cpp:222] Iteration 138440 (1.23775 iter/s, 32.3166s/40 iters), loss = 1.50521
I1028 06:48:36.147450  9023 solver.cpp:241]     Train net output #0: loss = 1.50521 (* 1 = 1.50521 loss)
I1028 06:48:36.147475  9023 sgd_solver.cpp:105] Iteration 138440, lr = 0.00132564
I1028 06:49:08.130836  9023 solver.cpp:222] Iteration 138480 (1.2507 iter/s, 31.9822s/40 iters), loss = 1.33822
I1028 06:49:08.131002  9023 solver.cpp:241]     Train net output #0: loss = 1.33822 (* 1 = 1.33822 loss)
I1028 06:49:08.131018  9023 sgd_solver.cpp:105] Iteration 138480, lr = 0.00132362
I1028 06:49:23.197479  9023 solver.cpp:334] Iteration 138500, Testing net (#0)
I1028 06:49:54.605309  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57812
I1028 06:49:54.605568  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80396
I1028 06:49:54.605587  9023 solver.cpp:401]     Test net output #2: loss = 1.86223 (* 1 = 1.86223 loss)
I1028 06:50:10.892953  9023 solver.cpp:222] Iteration 138520 (0.637353 iter/s, 62.7596s/40 iters), loss = 1.39343
I1028 06:50:10.893019  9023 solver.cpp:241]     Train net output #0: loss = 1.39343 (* 1 = 1.39343 loss)
I1028 06:50:10.893033  9023 sgd_solver.cpp:105] Iteration 138520, lr = 0.00132161
I1028 06:50:42.132251  9023 solver.cpp:222] Iteration 138560 (1.28049 iter/s, 31.238s/40 iters), loss = 1.61728
I1028 06:50:42.132464  9023 solver.cpp:241]     Train net output #0: loss = 1.61728 (* 1 = 1.61728 loss)
I1028 06:50:42.132483  9023 sgd_solver.cpp:105] Iteration 138560, lr = 0.00131959
I1028 06:51:12.631291  9023 solver.cpp:222] Iteration 138600 (1.31158 iter/s, 30.4977s/40 iters), loss = 1.61933
I1028 06:51:12.631467  9023 solver.cpp:241]     Train net output #0: loss = 1.61933 (* 1 = 1.61933 loss)
I1028 06:51:12.631484  9023 sgd_solver.cpp:105] Iteration 138600, lr = 0.00131758
I1028 06:51:43.502624  9023 solver.cpp:222] Iteration 138640 (1.29576 iter/s, 30.87s/40 iters), loss = 1.47934
I1028 06:51:43.502806  9023 solver.cpp:241]     Train net output #0: loss = 1.47934 (* 1 = 1.47934 loss)
I1028 06:51:43.502822  9023 sgd_solver.cpp:105] Iteration 138640, lr = 0.00131557
I1028 06:52:14.290971  9023 solver.cpp:222] Iteration 138680 (1.29925 iter/s, 30.787s/40 iters), loss = 1.73749
I1028 06:52:14.291146  9023 solver.cpp:241]     Train net output #0: loss = 1.73749 (* 1 = 1.73749 loss)
I1028 06:52:14.291163  9023 sgd_solver.cpp:105] Iteration 138680, lr = 0.00131355
I1028 06:52:44.974815  9023 solver.cpp:222] Iteration 138720 (1.30367 iter/s, 30.6825s/40 iters), loss = 1.46025
I1028 06:52:44.974967  9023 solver.cpp:241]     Train net output #0: loss = 1.46025 (* 1 = 1.46025 loss)
I1028 06:52:44.974983  9023 sgd_solver.cpp:105] Iteration 138720, lr = 0.00131154
I1028 06:53:15.870878  9023 solver.cpp:222] Iteration 138760 (1.29472 iter/s, 30.8947s/40 iters), loss = 1.18152
I1028 06:53:15.871044  9023 solver.cpp:241]     Train net output #0: loss = 1.18152 (* 1 = 1.18152 loss)
I1028 06:53:15.871062  9023 sgd_solver.cpp:105] Iteration 138760, lr = 0.00130953
I1028 06:53:47.086902  9023 solver.cpp:222] Iteration 138800 (1.28145 iter/s, 31.2147s/40 iters), loss = 1.56442
I1028 06:53:47.087054  9023 solver.cpp:241]     Train net output #0: loss = 1.56442 (* 1 = 1.56442 loss)
I1028 06:53:47.087070  9023 sgd_solver.cpp:105] Iteration 138800, lr = 0.00130752
I1028 06:54:18.276551  9023 solver.cpp:222] Iteration 138840 (1.28253 iter/s, 31.1883s/40 iters), loss = 1.39194
I1028 06:54:18.276702  9023 solver.cpp:241]     Train net output #0: loss = 1.39194 (* 1 = 1.39194 loss)
I1028 06:54:18.276718  9023 sgd_solver.cpp:105] Iteration 138840, lr = 0.0013055
I1028 06:54:50.896289  9023 solver.cpp:222] Iteration 138880 (1.2263 iter/s, 32.6183s/40 iters), loss = 1.25167
I1028 06:54:50.896503  9023 solver.cpp:241]     Train net output #0: loss = 1.25167 (* 1 = 1.25167 loss)
I1028 06:54:50.896519  9023 sgd_solver.cpp:105] Iteration 138880, lr = 0.00130349
I1028 06:55:21.924656  9023 solver.cpp:222] Iteration 138920 (1.2892 iter/s, 31.027s/40 iters), loss = 1.51231
I1028 06:55:21.924837  9023 solver.cpp:241]     Train net output #0: loss = 1.51231 (* 1 = 1.51231 loss)
I1028 06:55:21.924854  9023 sgd_solver.cpp:105] Iteration 138920, lr = 0.00130148
I1028 06:55:53.072705  9023 solver.cpp:222] Iteration 138960 (1.28425 iter/s, 31.1467s/40 iters), loss = 1.27802
I1028 06:55:53.072895  9023 solver.cpp:241]     Train net output #0: loss = 1.27802 (* 1 = 1.27802 loss)
I1028 06:55:53.072911  9023 sgd_solver.cpp:105] Iteration 138960, lr = 0.00129947
I1028 06:56:23.767494  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_139000.caffemodel
I1028 06:56:23.799506  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_139000.solverstate
I1028 06:56:23.817322  9023 solver.cpp:334] Iteration 139000, Testing net (#0)
I1028 06:56:55.234838  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 06:56:55.445374  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5778
I1028 06:56:55.445436  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.807799
I1028 06:56:55.445451  9023 solver.cpp:401]     Test net output #2: loss = 1.85617 (* 1 = 1.85617 loss)
I1028 06:56:56.206130  9023 solver.cpp:222] Iteration 139000 (0.633604 iter/s, 63.1309s/40 iters), loss = 1.56081
I1028 06:56:56.206197  9023 solver.cpp:241]     Train net output #0: loss = 1.56081 (* 1 = 1.56081 loss)
I1028 06:56:56.206210  9023 sgd_solver.cpp:105] Iteration 139000, lr = 0.00129746
I1028 06:57:27.477536  9023 solver.cpp:222] Iteration 139040 (1.27918 iter/s, 31.2701s/40 iters), loss = 1.50844
I1028 06:57:27.477737  9023 solver.cpp:241]     Train net output #0: loss = 1.50844 (* 1 = 1.50844 loss)
I1028 06:57:27.477753  9023 sgd_solver.cpp:105] Iteration 139040, lr = 0.00129546
I1028 06:57:58.252681  9023 solver.cpp:222] Iteration 139080 (1.29981 iter/s, 30.7738s/40 iters), loss = 1.26827
I1028 06:57:58.252876  9023 solver.cpp:241]     Train net output #0: loss = 1.26827 (* 1 = 1.26827 loss)
I1028 06:57:58.252892  9023 sgd_solver.cpp:105] Iteration 139080, lr = 0.00129345
I1028 06:58:29.803216  9023 solver.cpp:222] Iteration 139120 (1.26786 iter/s, 31.5491s/40 iters), loss = 1.66182
I1028 06:58:29.803459  9023 solver.cpp:241]     Train net output #0: loss = 1.66182 (* 1 = 1.66182 loss)
I1028 06:58:29.803484  9023 sgd_solver.cpp:105] Iteration 139120, lr = 0.00129144
I1028 06:59:01.838938  9023 solver.cpp:222] Iteration 139160 (1.24866 iter/s, 32.0343s/40 iters), loss = 1.2862
I1028 06:59:01.839179  9023 solver.cpp:241]     Train net output #0: loss = 1.2862 (* 1 = 1.2862 loss)
I1028 06:59:01.839200  9023 sgd_solver.cpp:105] Iteration 139160, lr = 0.00128943
I1028 06:59:32.919353  9023 solver.cpp:222] Iteration 139200 (1.28704 iter/s, 31.079s/40 iters), loss = 1.58235
I1028 06:59:32.919534  9023 solver.cpp:241]     Train net output #0: loss = 1.58235 (* 1 = 1.58235 loss)
I1028 06:59:32.919551  9023 sgd_solver.cpp:105] Iteration 139200, lr = 0.00128743
I1028 07:00:03.834900  9023 solver.cpp:222] Iteration 139240 (1.2939 iter/s, 30.9142s/40 iters), loss = 1.48936
I1028 07:00:03.835106  9023 solver.cpp:241]     Train net output #0: loss = 1.48936 (* 1 = 1.48936 loss)
I1028 07:00:03.835216  9023 sgd_solver.cpp:105] Iteration 139240, lr = 0.00128542
I1028 07:00:36.125833  9023 solver.cpp:222] Iteration 139280 (1.23879 iter/s, 32.2895s/40 iters), loss = 1.60729
I1028 07:00:36.126056  9023 solver.cpp:241]     Train net output #0: loss = 1.60729 (* 1 = 1.60729 loss)
I1028 07:00:36.126080  9023 sgd_solver.cpp:105] Iteration 139280, lr = 0.00128341
I1028 07:01:07.161989  9023 solver.cpp:222] Iteration 139320 (1.28888 iter/s, 31.0347s/40 iters), loss = 1.36995
I1028 07:01:07.162194  9023 solver.cpp:241]     Train net output #0: loss = 1.36995 (* 1 = 1.36995 loss)
I1028 07:01:07.162212  9023 sgd_solver.cpp:105] Iteration 139320, lr = 0.00128141
I1028 07:01:38.006983  9023 solver.cpp:222] Iteration 139360 (1.29687 iter/s, 30.8436s/40 iters), loss = 1.52782
I1028 07:01:38.007175  9023 solver.cpp:241]     Train net output #0: loss = 1.52782 (* 1 = 1.52782 loss)
I1028 07:01:38.007191  9023 sgd_solver.cpp:105] Iteration 139360, lr = 0.0012794
I1028 07:02:09.172653  9023 solver.cpp:222] Iteration 139400 (1.28352 iter/s, 31.1643s/40 iters), loss = 1.65551
I1028 07:02:09.172869  9023 solver.cpp:241]     Train net output #0: loss = 1.65551 (* 1 = 1.65551 loss)
I1028 07:02:09.172885  9023 sgd_solver.cpp:105] Iteration 139400, lr = 0.0012774
I1028 07:02:39.997272  9023 solver.cpp:222] Iteration 139440 (1.29772 iter/s, 30.8232s/40 iters), loss = 1.50147
I1028 07:02:39.997521  9023 solver.cpp:241]     Train net output #0: loss = 1.50147 (* 1 = 1.50147 loss)
I1028 07:02:39.997545  9023 sgd_solver.cpp:105] Iteration 139440, lr = 0.0012754
I1028 07:03:11.086280  9023 solver.cpp:222] Iteration 139480 (1.28669 iter/s, 31.0876s/40 iters), loss = 2.09597
I1028 07:03:11.086539  9023 solver.cpp:241]     Train net output #0: loss = 2.09597 (* 1 = 2.09597 loss)
I1028 07:03:11.086572  9023 sgd_solver.cpp:105] Iteration 139480, lr = 0.00127339
I1028 07:03:26.025678  9023 solver.cpp:334] Iteration 139500, Testing net (#0)
I1028 07:03:57.557170  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57536
I1028 07:03:57.557528  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80356
I1028 07:03:57.557545  9023 solver.cpp:401]     Test net output #2: loss = 1.86777 (* 1 = 1.86777 loss)
I1028 07:04:13.708829  9023 solver.cpp:222] Iteration 139520 (0.638774 iter/s, 62.62s/40 iters), loss = 1.70131
I1028 07:04:13.708906  9023 solver.cpp:241]     Train net output #0: loss = 1.70131 (* 1 = 1.70131 loss)
I1028 07:04:13.708927  9023 sgd_solver.cpp:105] Iteration 139520, lr = 0.00127139
I1028 07:04:44.529057  9023 solver.cpp:222] Iteration 139560 (1.2979 iter/s, 30.819s/40 iters), loss = 1.10582
I1028 07:04:44.529258  9023 solver.cpp:241]     Train net output #0: loss = 1.10582 (* 1 = 1.10582 loss)
I1028 07:04:44.529274  9023 sgd_solver.cpp:105] Iteration 139560, lr = 0.00126939
I1028 07:04:47.653102  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1028 07:05:15.278060  9023 solver.cpp:222] Iteration 139600 (1.30091 iter/s, 30.7476s/40 iters), loss = 1.39072
I1028 07:05:15.278252  9023 solver.cpp:241]     Train net output #0: loss = 1.39072 (* 1 = 1.39072 loss)
I1028 07:05:15.278272  9023 sgd_solver.cpp:105] Iteration 139600, lr = 0.00126739
I1028 07:05:46.141706  9023 solver.cpp:222] Iteration 139640 (1.29608 iter/s, 30.8623s/40 iters), loss = 1.32433
I1028 07:05:46.141882  9023 solver.cpp:241]     Train net output #0: loss = 1.32433 (* 1 = 1.32433 loss)
I1028 07:05:46.141898  9023 sgd_solver.cpp:105] Iteration 139640, lr = 0.00126539
I1028 07:06:17.252147  9023 solver.cpp:222] Iteration 139680 (1.2858 iter/s, 31.1091s/40 iters), loss = 1.2822
I1028 07:06:17.252540  9023 solver.cpp:241]     Train net output #0: loss = 1.2822 (* 1 = 1.2822 loss)
I1028 07:06:17.252558  9023 sgd_solver.cpp:105] Iteration 139680, lr = 0.00126339
I1028 07:06:48.285782  9023 solver.cpp:222] Iteration 139720 (1.28899 iter/s, 31.0321s/40 iters), loss = 1.94461
I1028 07:06:48.285948  9023 solver.cpp:241]     Train net output #0: loss = 1.94461 (* 1 = 1.94461 loss)
I1028 07:06:48.285964  9023 sgd_solver.cpp:105] Iteration 139720, lr = 0.00126139
I1028 07:07:19.610965  9023 solver.cpp:222] Iteration 139760 (1.27698 iter/s, 31.3238s/40 iters), loss = 1.54015
I1028 07:07:19.611158  9023 solver.cpp:241]     Train net output #0: loss = 1.54015 (* 1 = 1.54015 loss)
I1028 07:07:19.611176  9023 sgd_solver.cpp:105] Iteration 139760, lr = 0.00125939
I1028 07:07:51.238250  9023 solver.cpp:222] Iteration 139800 (1.26479 iter/s, 31.6259s/40 iters), loss = 1.83216
I1028 07:07:51.238436  9023 solver.cpp:241]     Train net output #0: loss = 1.83216 (* 1 = 1.83216 loss)
I1028 07:07:51.238453  9023 sgd_solver.cpp:105] Iteration 139800, lr = 0.00125739
I1028 07:08:22.168730  9023 solver.cpp:222] Iteration 139840 (1.29328 iter/s, 30.9291s/40 iters), loss = 1.46083
I1028 07:08:22.168920  9023 solver.cpp:241]     Train net output #0: loss = 1.46083 (* 1 = 1.46083 loss)
I1028 07:08:22.168939  9023 sgd_solver.cpp:105] Iteration 139840, lr = 0.00125539
I1028 07:08:54.037881  9023 solver.cpp:222] Iteration 139880 (1.25519 iter/s, 31.8678s/40 iters), loss = 1.33761
I1028 07:08:54.038059  9023 solver.cpp:241]     Train net output #0: loss = 1.33761 (* 1 = 1.33761 loss)
I1028 07:08:54.038077  9023 sgd_solver.cpp:105] Iteration 139880, lr = 0.00125339
I1028 07:09:24.986681  9023 solver.cpp:222] Iteration 139920 (1.29251 iter/s, 30.9475s/40 iters), loss = 1.44321
I1028 07:09:24.986865  9023 solver.cpp:241]     Train net output #0: loss = 1.44321 (* 1 = 1.44321 loss)
I1028 07:09:24.986882  9023 sgd_solver.cpp:105] Iteration 139920, lr = 0.0012514
I1028 07:09:56.045166  9023 solver.cpp:222] Iteration 139960 (1.28795 iter/s, 31.0571s/40 iters), loss = 1.50452
I1028 07:09:56.045444  9023 solver.cpp:241]     Train net output #0: loss = 1.50452 (* 1 = 1.50452 loss)
I1028 07:09:56.045477  9023 sgd_solver.cpp:105] Iteration 139960, lr = 0.0012494
I1028 07:10:26.169667  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_140000.caffemodel
I1028 07:10:26.202378  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_140000.solverstate
I1028 07:10:26.224580  9023 solver.cpp:334] Iteration 140000, Testing net (#0)
I1028 07:10:57.558141  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 07:10:57.768400  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5758
I1028 07:10:57.768467  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80572
I1028 07:10:57.768482  9023 solver.cpp:401]     Test net output #2: loss = 1.88112 (* 1 = 1.88112 loss)
I1028 07:10:58.538306  9023 solver.cpp:222] Iteration 140000 (0.640097 iter/s, 62.4905s/40 iters), loss = 1.41883
I1028 07:10:58.538369  9023 solver.cpp:241]     Train net output #0: loss = 1.41883 (* 1 = 1.41883 loss)
I1028 07:10:58.538384  9023 sgd_solver.cpp:105] Iteration 140000, lr = 0.0012474
I1028 07:11:29.360891  9023 solver.cpp:222] Iteration 140040 (1.2978 iter/s, 30.8214s/40 iters), loss = 1.47709
I1028 07:11:29.361101  9023 solver.cpp:241]     Train net output #0: loss = 1.47709 (* 1 = 1.47709 loss)
I1028 07:11:29.361119  9023 sgd_solver.cpp:105] Iteration 140040, lr = 0.00124541
I1028 07:12:00.032650  9023 solver.cpp:222] Iteration 140080 (1.30419 iter/s, 30.6704s/40 iters), loss = 1.31096
I1028 07:12:00.032840  9023 solver.cpp:241]     Train net output #0: loss = 1.31096 (* 1 = 1.31096 loss)
I1028 07:12:00.032855  9023 sgd_solver.cpp:105] Iteration 140080, lr = 0.00124341
I1028 07:12:31.179395  9023 solver.cpp:222] Iteration 140120 (1.2843 iter/s, 31.1454s/40 iters), loss = 1.7046
I1028 07:12:31.179581  9023 solver.cpp:241]     Train net output #0: loss = 1.7046 (* 1 = 1.7046 loss)
I1028 07:12:31.179597  9023 sgd_solver.cpp:105] Iteration 140120, lr = 0.00124142
I1028 07:13:03.567456  9023 solver.cpp:222] Iteration 140160 (1.23508 iter/s, 32.3867s/40 iters), loss = 1.44904
I1028 07:13:03.567654  9023 solver.cpp:241]     Train net output #0: loss = 1.44904 (* 1 = 1.44904 loss)
I1028 07:13:03.567672  9023 sgd_solver.cpp:105] Iteration 140160, lr = 0.00123942
I1028 07:13:35.099321  9023 solver.cpp:222] Iteration 140200 (1.26861 iter/s, 31.5305s/40 iters), loss = 1.65091
I1028 07:13:35.099514  9023 solver.cpp:241]     Train net output #0: loss = 1.65091 (* 1 = 1.65091 loss)
I1028 07:13:35.099531  9023 sgd_solver.cpp:105] Iteration 140200, lr = 0.00123743
I1028 07:14:08.372465  9023 solver.cpp:222] Iteration 140240 (1.20222 iter/s, 33.2717s/40 iters), loss = 1.65588
I1028 07:14:08.372695  9023 solver.cpp:241]     Train net output #0: loss = 1.65588 (* 1 = 1.65588 loss)
I1028 07:14:08.372719  9023 sgd_solver.cpp:105] Iteration 140240, lr = 0.00123544
I1028 07:14:40.281821  9023 solver.cpp:222] Iteration 140280 (1.25361 iter/s, 31.9079s/40 iters), loss = 1.72354
I1028 07:14:40.282008  9023 solver.cpp:241]     Train net output #0: loss = 1.72354 (* 1 = 1.72354 loss)
I1028 07:14:40.282025  9023 sgd_solver.cpp:105] Iteration 140280, lr = 0.00123345
I1028 07:15:11.904258  9023 solver.cpp:222] Iteration 140320 (1.26498 iter/s, 31.6211s/40 iters), loss = 1.32394
I1028 07:15:11.904466  9023 solver.cpp:241]     Train net output #0: loss = 1.32394 (* 1 = 1.32394 loss)
I1028 07:15:11.904484  9023 sgd_solver.cpp:105] Iteration 140320, lr = 0.00123145
I1028 07:15:43.687814  9023 solver.cpp:222] Iteration 140360 (1.25857 iter/s, 31.7822s/40 iters), loss = 1.43547
I1028 07:15:43.688027  9023 solver.cpp:241]     Train net output #0: loss = 1.43547 (* 1 = 1.43547 loss)
I1028 07:15:43.688045  9023 sgd_solver.cpp:105] Iteration 140360, lr = 0.00122946
I1028 07:16:19.299432  9023 solver.cpp:222] Iteration 140400 (1.12328 iter/s, 35.6101s/40 iters), loss = 1.36314
I1028 07:16:19.299692  9023 solver.cpp:241]     Train net output #0: loss = 1.36314 (* 1 = 1.36314 loss)
I1028 07:16:19.299715  9023 sgd_solver.cpp:105] Iteration 140400, lr = 0.00122747
I1028 07:17:01.937006  9023 solver.cpp:222] Iteration 140440 (0.938181 iter/s, 42.6357s/40 iters), loss = 1.29255
I1028 07:17:01.937242  9023 solver.cpp:241]     Train net output #0: loss = 1.29255 (* 1 = 1.29255 loss)
I1028 07:17:01.937268  9023 sgd_solver.cpp:105] Iteration 140440, lr = 0.00122548
I1028 07:17:33.212713  9023 solver.cpp:222] Iteration 140480 (1.27901 iter/s, 31.2743s/40 iters), loss = 1.43357
I1028 07:17:33.212913  9023 solver.cpp:241]     Train net output #0: loss = 1.43357 (* 1 = 1.43357 loss)
I1028 07:17:33.212930  9023 sgd_solver.cpp:105] Iteration 140480, lr = 0.00122349
I1028 07:17:47.838241  9023 solver.cpp:334] Iteration 140500, Testing net (#0)
I1028 07:18:19.185505  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57772
I1028 07:18:19.185708  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8044
I1028 07:18:19.185722  9023 solver.cpp:401]     Test net output #2: loss = 1.86091 (* 1 = 1.86091 loss)
I1028 07:18:35.384059  9023 solver.cpp:222] Iteration 140520 (0.643409 iter/s, 62.1688s/40 iters), loss = 1.03377
I1028 07:18:35.384132  9023 solver.cpp:241]     Train net output #0: loss = 1.03377 (* 1 = 1.03377 loss)
I1028 07:18:35.384148  9023 sgd_solver.cpp:105] Iteration 140520, lr = 0.0012215
I1028 07:19:06.171536  9023 solver.cpp:222] Iteration 140560 (1.29928 iter/s, 30.7862s/40 iters), loss = 1.54204
I1028 07:19:06.171726  9023 solver.cpp:241]     Train net output #0: loss = 1.54204 (* 1 = 1.54204 loss)
I1028 07:19:06.171747  9023 sgd_solver.cpp:105] Iteration 140560, lr = 0.00121951
I1028 07:19:37.271693  9023 solver.cpp:222] Iteration 140600 (1.28622 iter/s, 31.0988s/40 iters), loss = 1.51702
I1028 07:19:37.271873  9023 solver.cpp:241]     Train net output #0: loss = 1.51702 (* 1 = 1.51702 loss)
I1028 07:19:37.271889  9023 sgd_solver.cpp:105] Iteration 140600, lr = 0.00121753
I1028 07:20:08.024119  9023 solver.cpp:222] Iteration 140640 (1.30077 iter/s, 30.7511s/40 iters), loss = 1.38796
I1028 07:20:08.024291  9023 solver.cpp:241]     Train net output #0: loss = 1.38796 (* 1 = 1.38796 loss)
I1028 07:20:08.024315  9023 sgd_solver.cpp:105] Iteration 140640, lr = 0.00121554
I1028 07:20:39.723264  9023 solver.cpp:222] Iteration 140680 (1.26192 iter/s, 31.6978s/40 iters), loss = 1.61144
I1028 07:20:39.723477  9023 solver.cpp:241]     Train net output #0: loss = 1.61144 (* 1 = 1.61144 loss)
I1028 07:20:39.729306  9023 sgd_solver.cpp:105] Iteration 140680, lr = 0.00121355
I1028 07:21:12.949936  9023 solver.cpp:222] Iteration 140720 (1.2039 iter/s, 33.2252s/40 iters), loss = 1.69154
I1028 07:21:12.950151  9023 solver.cpp:241]     Train net output #0: loss = 1.69154 (* 1 = 1.69154 loss)
I1028 07:21:12.950170  9023 sgd_solver.cpp:105] Iteration 140720, lr = 0.00121156
I1028 07:21:43.606509  9023 solver.cpp:222] Iteration 140760 (1.30484 iter/s, 30.6552s/40 iters), loss = 1.68413
I1028 07:21:43.606699  9023 solver.cpp:241]     Train net output #0: loss = 1.68413 (* 1 = 1.68413 loss)
I1028 07:21:43.606716  9023 sgd_solver.cpp:105] Iteration 140760, lr = 0.00120958
I1028 07:22:14.361214  9023 solver.cpp:222] Iteration 140800 (1.30067 iter/s, 30.7534s/40 iters), loss = 1.41688
I1028 07:22:14.361408  9023 solver.cpp:241]     Train net output #0: loss = 1.41688 (* 1 = 1.41688 loss)
I1028 07:22:14.361431  9023 sgd_solver.cpp:105] Iteration 140800, lr = 0.00120759
I1028 07:22:45.718551  9023 solver.cpp:222] Iteration 140840 (1.27567 iter/s, 31.356s/40 iters), loss = 1.52867
I1028 07:22:45.718735  9023 solver.cpp:241]     Train net output #0: loss = 1.52867 (* 1 = 1.52867 loss)
I1028 07:22:45.718751  9023 sgd_solver.cpp:105] Iteration 140840, lr = 0.00120561
I1028 07:23:16.670814  9023 solver.cpp:222] Iteration 140880 (1.29237 iter/s, 30.9509s/40 iters), loss = 1.37753
I1028 07:23:16.671005  9023 solver.cpp:241]     Train net output #0: loss = 1.37753 (* 1 = 1.37753 loss)
I1028 07:23:16.671036  9023 sgd_solver.cpp:105] Iteration 140880, lr = 0.00120362
I1028 07:23:47.982709  9023 solver.cpp:222] Iteration 140920 (1.27753 iter/s, 31.3105s/40 iters), loss = 1.72166
I1028 07:23:47.982985  9023 solver.cpp:241]     Train net output #0: loss = 1.72166 (* 1 = 1.72166 loss)
I1028 07:23:47.983011  9023 sgd_solver.cpp:105] Iteration 140920, lr = 0.00120164
I1028 07:24:19.249876  9023 solver.cpp:222] Iteration 140960 (1.27936 iter/s, 31.2657s/40 iters), loss = 1.50197
I1028 07:24:19.250072  9023 solver.cpp:241]     Train net output #0: loss = 1.50197 (* 1 = 1.50197 loss)
I1028 07:24:19.250089  9023 sgd_solver.cpp:105] Iteration 140960, lr = 0.00119966
I1028 07:24:49.736773  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_141000.caffemodel
I1028 07:24:49.769276  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_141000.solverstate
I1028 07:24:49.787711  9023 solver.cpp:334] Iteration 141000, Testing net (#0)
I1028 07:25:20.996407  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 07:25:21.207118  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57836
I1028 07:25:21.207180  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.808599
I1028 07:25:21.207198  9023 solver.cpp:401]     Test net output #2: loss = 1.86254 (* 1 = 1.86254 loss)
I1028 07:25:21.980644  9023 solver.cpp:222] Iteration 141000 (0.637671 iter/s, 62.7282s/40 iters), loss = 1.38322
I1028 07:25:21.980710  9023 solver.cpp:241]     Train net output #0: loss = 1.38322 (* 1 = 1.38322 loss)
I1028 07:25:21.980728  9023 sgd_solver.cpp:105] Iteration 141000, lr = 0.00119767
I1028 07:25:52.846601  9023 solver.cpp:222] Iteration 141040 (1.29598 iter/s, 30.8647s/40 iters), loss = 1.30024
I1028 07:25:52.846784  9023 solver.cpp:241]     Train net output #0: loss = 1.30024 (* 1 = 1.30024 loss)
I1028 07:25:52.846801  9023 sgd_solver.cpp:105] Iteration 141040, lr = 0.00119569
I1028 07:26:24.145776  9023 solver.cpp:222] Iteration 141080 (1.27805 iter/s, 31.2978s/40 iters), loss = 1.72591
I1028 07:26:24.145965  9023 solver.cpp:241]     Train net output #0: loss = 1.72591 (* 1 = 1.72591 loss)
I1028 07:26:24.145982  9023 sgd_solver.cpp:105] Iteration 141080, lr = 0.00119371
I1028 07:26:55.537904  9023 solver.cpp:222] Iteration 141120 (1.27426 iter/s, 31.3908s/40 iters), loss = 1.35777
I1028 07:26:55.538108  9023 solver.cpp:241]     Train net output #0: loss = 1.35777 (* 1 = 1.35777 loss)
I1028 07:26:55.538125  9023 sgd_solver.cpp:105] Iteration 141120, lr = 0.00119173
I1028 07:27:26.622755  9023 solver.cpp:222] Iteration 141160 (1.28686 iter/s, 31.0835s/40 iters), loss = 1.36008
I1028 07:27:26.623013  9023 solver.cpp:241]     Train net output #0: loss = 1.36008 (* 1 = 1.36008 loss)
I1028 07:27:26.623041  9023 sgd_solver.cpp:105] Iteration 141160, lr = 0.00118975
I1028 07:27:57.390559  9023 solver.cpp:222] Iteration 141200 (1.30012 iter/s, 30.7664s/40 iters), loss = 1.35704
I1028 07:27:57.390745  9023 solver.cpp:241]     Train net output #0: loss = 1.35704 (* 1 = 1.35704 loss)
I1028 07:27:57.390763  9023 sgd_solver.cpp:105] Iteration 141200, lr = 0.00118777
I1028 07:28:28.497431  9023 solver.cpp:222] Iteration 141240 (1.28595 iter/s, 31.1055s/40 iters), loss = 1.55678
I1028 07:28:28.497635  9023 solver.cpp:241]     Train net output #0: loss = 1.55678 (* 1 = 1.55678 loss)
I1028 07:28:28.497653  9023 sgd_solver.cpp:105] Iteration 141240, lr = 0.00118579
I1028 07:28:59.642740  9023 solver.cpp:222] Iteration 141280 (1.28436 iter/s, 31.1439s/40 iters), loss = 1.38859
I1028 07:28:59.642927  9023 solver.cpp:241]     Train net output #0: loss = 1.38859 (* 1 = 1.38859 loss)
I1028 07:28:59.642946  9023 sgd_solver.cpp:105] Iteration 141280, lr = 0.00118381
I1028 07:29:30.662245  9023 solver.cpp:222] Iteration 141320 (1.28957 iter/s, 31.0182s/40 iters), loss = 2.0734
I1028 07:29:30.662413  9023 solver.cpp:241]     Train net output #0: loss = 2.0734 (* 1 = 2.0734 loss)
I1028 07:29:30.662433  9023 sgd_solver.cpp:105] Iteration 141320, lr = 0.00118183
I1028 07:30:01.592720  9023 solver.cpp:222] Iteration 141360 (1.29328 iter/s, 30.9291s/40 iters), loss = 1.25241
I1028 07:30:01.592932  9023 solver.cpp:241]     Train net output #0: loss = 1.25241 (* 1 = 1.25241 loss)
I1028 07:30:01.592957  9023 sgd_solver.cpp:105] Iteration 141360, lr = 0.00117986
I1028 07:30:32.470809  9023 solver.cpp:222] Iteration 141400 (1.29547 iter/s, 30.8767s/40 iters), loss = 1.62905
I1028 07:30:32.470994  9023 solver.cpp:241]     Train net output #0: loss = 1.62905 (* 1 = 1.62905 loss)
I1028 07:30:32.471011  9023 sgd_solver.cpp:105] Iteration 141400, lr = 0.00117788
I1028 07:31:03.536005  9023 solver.cpp:222] Iteration 141440 (1.28767 iter/s, 31.0638s/40 iters), loss = 1.82999
I1028 07:31:03.536190  9023 solver.cpp:241]     Train net output #0: loss = 1.82999 (* 1 = 1.82999 loss)
I1028 07:31:03.536206  9023 sgd_solver.cpp:105] Iteration 141440, lr = 0.0011759
I1028 07:31:34.342826  9023 solver.cpp:222] Iteration 141480 (1.29847 iter/s, 30.8055s/40 iters), loss = 1.30703
I1028 07:31:34.343042  9023 solver.cpp:241]     Train net output #0: loss = 1.30703 (* 1 = 1.30703 loss)
I1028 07:31:34.343065  9023 sgd_solver.cpp:105] Iteration 141480, lr = 0.00117393
I1028 07:31:49.069542  9023 solver.cpp:334] Iteration 141500, Testing net (#0)
I1028 07:32:20.492281  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57656
I1028 07:32:20.492488  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80428
I1028 07:32:20.492506  9023 solver.cpp:401]     Test net output #2: loss = 1.85898 (* 1 = 1.85898 loss)
I1028 07:32:36.935950  9023 solver.cpp:222] Iteration 141520 (0.639074 iter/s, 62.5906s/40 iters), loss = 1.32065
I1028 07:32:36.936024  9023 solver.cpp:241]     Train net output #0: loss = 1.32065 (* 1 = 1.32065 loss)
I1028 07:32:36.936041  9023 sgd_solver.cpp:105] Iteration 141520, lr = 0.00117195
I1028 07:33:08.006096  9023 solver.cpp:222] Iteration 141560 (1.28746 iter/s, 31.0689s/40 iters), loss = 1.36734
I1028 07:33:08.006304  9023 solver.cpp:241]     Train net output #0: loss = 1.36734 (* 1 = 1.36734 loss)
I1028 07:33:08.006322  9023 sgd_solver.cpp:105] Iteration 141560, lr = 0.00116998
I1028 07:33:40.683516  9023 solver.cpp:222] Iteration 141600 (1.22414 iter/s, 32.676s/40 iters), loss = 1.40456
I1028 07:33:40.683758  9023 solver.cpp:241]     Train net output #0: loss = 1.40456 (* 1 = 1.40456 loss)
I1028 07:33:40.683787  9023 sgd_solver.cpp:105] Iteration 141600, lr = 0.001168
I1028 07:34:12.078586  9023 solver.cpp:222] Iteration 141640 (1.27414 iter/s, 31.3936s/40 iters), loss = 1.69394
I1028 07:34:12.078769  9023 solver.cpp:241]     Train net output #0: loss = 1.69394 (* 1 = 1.69394 loss)
I1028 07:34:12.078785  9023 sgd_solver.cpp:105] Iteration 141640, lr = 0.00116603
I1028 07:34:43.253568  9023 solver.cpp:222] Iteration 141680 (1.28314 iter/s, 31.1736s/40 iters), loss = 1.30893
I1028 07:34:43.253744  9023 solver.cpp:241]     Train net output #0: loss = 1.30893 (* 1 = 1.30893 loss)
I1028 07:34:43.253763  9023 sgd_solver.cpp:105] Iteration 141680, lr = 0.00116405
I1028 07:35:14.635641  9023 solver.cpp:222] Iteration 141720 (1.27467 iter/s, 31.3807s/40 iters), loss = 1.57085
I1028 07:35:14.635907  9023 solver.cpp:241]     Train net output #0: loss = 1.57085 (* 1 = 1.57085 loss)
I1028 07:35:14.635933  9023 sgd_solver.cpp:105] Iteration 141720, lr = 0.00116208
I1028 07:35:47.354934  9023 solver.cpp:222] Iteration 141760 (1.22258 iter/s, 32.7178s/40 iters), loss = 1.20598
I1028 07:35:47.355105  9023 solver.cpp:241]     Train net output #0: loss = 1.20598 (* 1 = 1.20598 loss)
I1028 07:35:47.355123  9023 sgd_solver.cpp:105] Iteration 141760, lr = 0.00116011
I1028 07:36:18.153980  9023 solver.cpp:222] Iteration 141800 (1.2988 iter/s, 30.7977s/40 iters), loss = 1.22447
I1028 07:36:18.154191  9023 solver.cpp:241]     Train net output #0: loss = 1.22447 (* 1 = 1.22447 loss)
I1028 07:36:18.154209  9023 sgd_solver.cpp:105] Iteration 141800, lr = 0.00115814
I1028 07:36:48.812700  9023 solver.cpp:222] Iteration 141840 (1.30474 iter/s, 30.6573s/40 iters), loss = 1.19318
I1028 07:36:48.812939  9023 solver.cpp:241]     Train net output #0: loss = 1.19318 (* 1 = 1.19318 loss)
I1028 07:36:48.812963  9023 sgd_solver.cpp:105] Iteration 141840, lr = 0.00115617
I1028 07:37:19.902432  9023 solver.cpp:222] Iteration 141880 (1.28666 iter/s, 31.0883s/40 iters), loss = 1.4907
I1028 07:37:19.902654  9023 solver.cpp:241]     Train net output #0: loss = 1.4907 (* 1 = 1.4907 loss)
I1028 07:37:19.902673  9023 sgd_solver.cpp:105] Iteration 141880, lr = 0.0011542
I1028 07:37:50.595129  9023 solver.cpp:222] Iteration 141920 (1.3033 iter/s, 30.6913s/40 iters), loss = 1.72512
I1028 07:37:50.595317  9023 solver.cpp:241]     Train net output #0: loss = 1.72512 (* 1 = 1.72512 loss)
I1028 07:37:50.595335  9023 sgd_solver.cpp:105] Iteration 141920, lr = 0.00115223
I1028 07:38:21.371299  9023 solver.cpp:222] Iteration 141960 (1.29976 iter/s, 30.7748s/40 iters), loss = 1.39435
I1028 07:38:21.371489  9023 solver.cpp:241]     Train net output #0: loss = 1.39435 (* 1 = 1.39435 loss)
I1028 07:38:21.371505  9023 sgd_solver.cpp:105] Iteration 141960, lr = 0.00115026
I1028 07:38:51.261282  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_142000.caffemodel
I1028 07:38:51.293427  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_142000.solverstate
I1028 07:38:51.311770  9023 solver.cpp:334] Iteration 142000, Testing net (#0)
I1028 07:39:22.527590  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 07:39:22.739468  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57668
I1028 07:39:22.739531  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80884
I1028 07:39:22.739544  9023 solver.cpp:401]     Test net output #2: loss = 1.86779 (* 1 = 1.86779 loss)
I1028 07:39:23.509125  9023 solver.cpp:222] Iteration 142000 (0.643756 iter/s, 62.1353s/40 iters), loss = 1.34583
I1028 07:39:23.509191  9023 solver.cpp:241]     Train net output #0: loss = 1.34583 (* 1 = 1.34583 loss)
I1028 07:39:23.509207  9023 sgd_solver.cpp:105] Iteration 142000, lr = 0.00114829
I1028 07:39:54.090826  9023 solver.cpp:222] Iteration 142040 (1.30802 iter/s, 30.5805s/40 iters), loss = 1.34311
I1028 07:39:54.090991  9023 solver.cpp:241]     Train net output #0: loss = 1.34311 (* 1 = 1.34311 loss)
I1028 07:39:54.091009  9023 sgd_solver.cpp:105] Iteration 142040, lr = 0.00114632
I1028 07:40:14.587215  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1028 07:40:26.021315  9023 solver.cpp:222] Iteration 142080 (1.25278 iter/s, 31.9291s/40 iters), loss = 1.79436
I1028 07:40:26.021564  9023 solver.cpp:241]     Train net output #0: loss = 1.79436 (* 1 = 1.79436 loss)
I1028 07:40:26.021594  9023 sgd_solver.cpp:105] Iteration 142080, lr = 0.00114435
I1028 07:40:58.450224  9023 solver.cpp:222] Iteration 142120 (1.23352 iter/s, 32.4274s/40 iters), loss = 1.51229
I1028 07:40:58.450404  9023 solver.cpp:241]     Train net output #0: loss = 1.51229 (* 1 = 1.51229 loss)
I1028 07:40:58.450422  9023 sgd_solver.cpp:105] Iteration 142120, lr = 0.00114238
I1028 07:41:29.282248  9023 solver.cpp:222] Iteration 142160 (1.29741 iter/s, 30.8307s/40 iters), loss = 1.50145
I1028 07:41:29.282446  9023 solver.cpp:241]     Train net output #0: loss = 1.50145 (* 1 = 1.50145 loss)
I1028 07:41:29.282464  9023 sgd_solver.cpp:105] Iteration 142160, lr = 0.00114042
I1028 07:42:00.227360  9023 solver.cpp:222] Iteration 142200 (1.29267 iter/s, 30.9437s/40 iters), loss = 1.47625
I1028 07:42:00.227562  9023 solver.cpp:241]     Train net output #0: loss = 1.47625 (* 1 = 1.47625 loss)
I1028 07:42:00.227578  9023 sgd_solver.cpp:105] Iteration 142200, lr = 0.00113845
I1028 07:42:31.436058  9023 solver.cpp:222] Iteration 142240 (1.28175 iter/s, 31.2073s/40 iters), loss = 1.49673
I1028 07:42:31.436242  9023 solver.cpp:241]     Train net output #0: loss = 1.49673 (* 1 = 1.49673 loss)
I1028 07:42:31.436273  9023 sgd_solver.cpp:105] Iteration 142240, lr = 0.00113649
I1028 07:43:02.494259  9023 solver.cpp:222] Iteration 142280 (1.28796 iter/s, 31.0568s/40 iters), loss = 1.60966
I1028 07:43:02.494540  9023 solver.cpp:241]     Train net output #0: loss = 1.60966 (* 1 = 1.60966 loss)
I1028 07:43:02.494561  9023 sgd_solver.cpp:105] Iteration 142280, lr = 0.00113452
I1028 07:43:33.213251  9023 solver.cpp:222] Iteration 142320 (1.30219 iter/s, 30.7176s/40 iters), loss = 1.61784
I1028 07:43:33.213454  9023 solver.cpp:241]     Train net output #0: loss = 1.61784 (* 1 = 1.61784 loss)
I1028 07:43:33.213471  9023 sgd_solver.cpp:105] Iteration 142320, lr = 0.00113256
I1028 07:44:03.938247  9023 solver.cpp:222] Iteration 142360 (1.30193 iter/s, 30.7236s/40 iters), loss = 1.57704
I1028 07:44:03.938428  9023 solver.cpp:241]     Train net output #0: loss = 1.57704 (* 1 = 1.57704 loss)
I1028 07:44:03.938446  9023 sgd_solver.cpp:105] Iteration 142360, lr = 0.00113059
I1028 07:44:35.575197  9023 solver.cpp:222] Iteration 142400 (1.2644 iter/s, 31.6356s/40 iters), loss = 1.52538
I1028 07:44:35.575450  9023 solver.cpp:241]     Train net output #0: loss = 1.52538 (* 1 = 1.52538 loss)
I1028 07:44:35.575479  9023 sgd_solver.cpp:105] Iteration 142400, lr = 0.00112863
I1028 07:45:09.339821  9023 solver.cpp:222] Iteration 142440 (1.18472 iter/s, 33.7631s/40 iters), loss = 1.89222
I1028 07:45:09.340067  9023 solver.cpp:241]     Train net output #0: loss = 1.89222 (* 1 = 1.89222 loss)
I1028 07:45:09.340097  9023 sgd_solver.cpp:105] Iteration 142440, lr = 0.00112667
I1028 07:45:40.862908  9023 solver.cpp:222] Iteration 142480 (1.26897 iter/s, 31.5217s/40 iters), loss = 1.51286
I1028 07:45:40.863091  9023 solver.cpp:241]     Train net output #0: loss = 1.51286 (* 1 = 1.51286 loss)
I1028 07:45:40.863109  9023 sgd_solver.cpp:105] Iteration 142480, lr = 0.00112471
I1028 07:45:55.312646  9023 solver.cpp:334] Iteration 142500, Testing net (#0)
I1028 07:46:26.617974  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5782
I1028 07:46:26.618149  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.803999
I1028 07:46:26.618165  9023 solver.cpp:401]     Test net output #2: loss = 1.86397 (* 1 = 1.86397 loss)
I1028 07:46:42.881635  9023 solver.cpp:222] Iteration 142520 (0.644993 iter/s, 62.0162s/40 iters), loss = 1.44998
I1028 07:46:42.881707  9023 solver.cpp:241]     Train net output #0: loss = 1.44998 (* 1 = 1.44998 loss)
I1028 07:46:42.881722  9023 sgd_solver.cpp:105] Iteration 142520, lr = 0.00112275
I1028 07:47:14.119572  9023 solver.cpp:222] Iteration 142560 (1.28055 iter/s, 31.2367s/40 iters), loss = 1.49329
I1028 07:47:14.119770  9023 solver.cpp:241]     Train net output #0: loss = 1.49329 (* 1 = 1.49329 loss)
I1028 07:47:14.119787  9023 sgd_solver.cpp:105] Iteration 142560, lr = 0.00112078
I1028 07:47:45.762892  9023 solver.cpp:222] Iteration 142600 (1.26415 iter/s, 31.6419s/40 iters), loss = 1.67116
I1028 07:47:45.763074  9023 solver.cpp:241]     Train net output #0: loss = 1.67116 (* 1 = 1.67116 loss)
I1028 07:47:45.763092  9023 sgd_solver.cpp:105] Iteration 142600, lr = 0.00111882
I1028 07:48:17.139328  9023 solver.cpp:222] Iteration 142640 (1.2749 iter/s, 31.3751s/40 iters), loss = 1.54707
I1028 07:48:17.139531  9023 solver.cpp:241]     Train net output #0: loss = 1.54707 (* 1 = 1.54707 loss)
I1028 07:48:17.139550  9023 sgd_solver.cpp:105] Iteration 142640, lr = 0.00111686
I1028 07:48:47.943640  9023 solver.cpp:222] Iteration 142680 (1.29858 iter/s, 30.8029s/40 iters), loss = 1.45703
I1028 07:48:47.943831  9023 solver.cpp:241]     Train net output #0: loss = 1.45703 (* 1 = 1.45703 loss)
I1028 07:48:47.943850  9023 sgd_solver.cpp:105] Iteration 142680, lr = 0.00111491
I1028 07:49:19.303849  9023 solver.cpp:222] Iteration 142720 (1.27556 iter/s, 31.3588s/40 iters), loss = 1.61614
I1028 07:49:19.304059  9023 solver.cpp:241]     Train net output #0: loss = 1.61614 (* 1 = 1.61614 loss)
I1028 07:49:19.304075  9023 sgd_solver.cpp:105] Iteration 142720, lr = 0.00111295
I1028 07:49:50.604918  9023 solver.cpp:222] Iteration 142760 (1.27797 iter/s, 31.2997s/40 iters), loss = 1.39049
I1028 07:49:50.605134  9023 solver.cpp:241]     Train net output #0: loss = 1.39049 (* 1 = 1.39049 loss)
I1028 07:49:50.605167  9023 sgd_solver.cpp:105] Iteration 142760, lr = 0.00111099
I1028 07:50:21.946164  9023 solver.cpp:222] Iteration 142800 (1.27633 iter/s, 31.3398s/40 iters), loss = 1.35997
I1028 07:50:21.946466  9023 solver.cpp:241]     Train net output #0: loss = 1.35997 (* 1 = 1.35997 loss)
I1028 07:50:21.946494  9023 sgd_solver.cpp:105] Iteration 142800, lr = 0.00110903
I1028 07:50:53.248215  9023 solver.cpp:222] Iteration 142840 (1.27793 iter/s, 31.3006s/40 iters), loss = 1.3864
I1028 07:50:53.248417  9023 solver.cpp:241]     Train net output #0: loss = 1.3864 (* 1 = 1.3864 loss)
I1028 07:50:53.248435  9023 sgd_solver.cpp:105] Iteration 142840, lr = 0.00110707
I1028 07:51:24.118199  9023 solver.cpp:222] Iteration 142880 (1.29582 iter/s, 30.8685s/40 iters), loss = 1.44109
I1028 07:51:24.118422  9023 solver.cpp:241]     Train net output #0: loss = 1.44109 (* 1 = 1.44109 loss)
I1028 07:51:24.118440  9023 sgd_solver.cpp:105] Iteration 142880, lr = 0.00110512
I1028 07:51:55.534418  9023 solver.cpp:222] Iteration 142920 (1.27328 iter/s, 31.4148s/40 iters), loss = 1.80829
I1028 07:51:55.534622  9023 solver.cpp:241]     Train net output #0: loss = 1.80829 (* 1 = 1.80829 loss)
I1028 07:51:55.534641  9023 sgd_solver.cpp:105] Iteration 142920, lr = 0.00110316
I1028 07:52:26.827538  9023 solver.cpp:222] Iteration 142960 (1.27829 iter/s, 31.2917s/40 iters), loss = 1.40724
I1028 07:52:26.827744  9023 solver.cpp:241]     Train net output #0: loss = 1.40724 (* 1 = 1.40724 loss)
I1028 07:52:26.827762  9023 sgd_solver.cpp:105] Iteration 142960, lr = 0.00110121
I1028 07:52:57.893756  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_143000.caffemodel
I1028 07:52:57.926841  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_143000.solverstate
I1028 07:52:57.944984  9023 solver.cpp:334] Iteration 143000, Testing net (#0)
I1028 07:53:29.140352  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 07:53:29.351562  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57432
I1028 07:53:29.351625  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.808719
I1028 07:53:29.351642  9023 solver.cpp:401]     Test net output #2: loss = 1.87076 (* 1 = 1.87076 loss)
I1028 07:53:30.115793  9023 solver.cpp:222] Iteration 143000 (0.632055 iter/s, 63.2857s/40 iters), loss = 1.86761
I1028 07:53:30.115859  9023 solver.cpp:241]     Train net output #0: loss = 1.86761 (* 1 = 1.86761 loss)
I1028 07:53:30.115876  9023 sgd_solver.cpp:105] Iteration 143000, lr = 0.00109925
I1028 07:54:01.139546  9023 solver.cpp:222] Iteration 143040 (1.28939 iter/s, 31.0225s/40 iters), loss = 1.48211
I1028 07:54:01.139761  9023 solver.cpp:241]     Train net output #0: loss = 1.48211 (* 1 = 1.48211 loss)
I1028 07:54:01.139780  9023 sgd_solver.cpp:105] Iteration 143040, lr = 0.0010973
I1028 07:54:32.670799  9023 solver.cpp:222] Iteration 143080 (1.26864 iter/s, 31.5298s/40 iters), loss = 1.64215
I1028 07:54:32.670992  9023 solver.cpp:241]     Train net output #0: loss = 1.64215 (* 1 = 1.64215 loss)
I1028 07:54:32.671015  9023 sgd_solver.cpp:105] Iteration 143080, lr = 0.00109535
I1028 07:55:03.515373  9023 solver.cpp:222] Iteration 143120 (1.29688 iter/s, 30.8432s/40 iters), loss = 1.29
I1028 07:55:03.515560  9023 solver.cpp:241]     Train net output #0: loss = 1.29 (* 1 = 1.29 loss)
I1028 07:55:03.515578  9023 sgd_solver.cpp:105] Iteration 143120, lr = 0.00109339
I1028 07:55:34.056396  9023 solver.cpp:222] Iteration 143160 (1.30977 iter/s, 30.5397s/40 iters), loss = 1.56587
I1028 07:55:34.056569  9023 solver.cpp:241]     Train net output #0: loss = 1.56587 (* 1 = 1.56587 loss)
I1028 07:55:34.056586  9023 sgd_solver.cpp:105] Iteration 143160, lr = 0.00109144
I1028 07:56:04.667342  9023 solver.cpp:222] Iteration 143200 (1.30678 iter/s, 30.6096s/40 iters), loss = 1.32749
I1028 07:56:04.667516  9023 solver.cpp:241]     Train net output #0: loss = 1.32749 (* 1 = 1.32749 loss)
I1028 07:56:04.667556  9023 sgd_solver.cpp:105] Iteration 143200, lr = 0.00108949
I1028 07:56:35.174142  9023 solver.cpp:222] Iteration 143240 (1.31124 iter/s, 30.5055s/40 iters), loss = 1.4198
I1028 07:56:35.174343  9023 solver.cpp:241]     Train net output #0: loss = 1.4198 (* 1 = 1.4198 loss)
I1028 07:56:35.174362  9023 sgd_solver.cpp:105] Iteration 143240, lr = 0.00108754
I1028 07:57:12.138084  9023 solver.cpp:222] Iteration 143280 (1.08218 iter/s, 36.9623s/40 iters), loss = 1.31893
I1028 07:57:12.138559  9023 solver.cpp:241]     Train net output #0: loss = 1.31893 (* 1 = 1.31893 loss)
I1028 07:57:12.138593  9023 sgd_solver.cpp:105] Iteration 143280, lr = 0.00108559
I1028 07:57:43.062096  9023 solver.cpp:222] Iteration 143320 (1.29356 iter/s, 30.9224s/40 iters), loss = 1.31437
I1028 07:57:43.062269  9023 solver.cpp:241]     Train net output #0: loss = 1.31437 (* 1 = 1.31437 loss)
I1028 07:57:43.062290  9023 sgd_solver.cpp:105] Iteration 143320, lr = 0.00108364
I1028 07:58:15.872076  9023 solver.cpp:222] Iteration 143360 (1.21919 iter/s, 32.8086s/40 iters), loss = 1.39558
I1028 07:58:15.872340  9023 solver.cpp:241]     Train net output #0: loss = 1.39558 (* 1 = 1.39558 loss)
I1028 07:58:15.872367  9023 sgd_solver.cpp:105] Iteration 143360, lr = 0.00108169
I1028 07:58:47.511596  9023 solver.cpp:222] Iteration 143400 (1.2643 iter/s, 31.6381s/40 iters), loss = 1.51032
I1028 07:58:47.511823  9023 solver.cpp:241]     Train net output #0: loss = 1.51032 (* 1 = 1.51032 loss)
I1028 07:58:47.511840  9023 sgd_solver.cpp:105] Iteration 143400, lr = 0.00107974
I1028 07:59:18.232358  9023 solver.cpp:222] Iteration 143440 (1.30211 iter/s, 30.7194s/40 iters), loss = 1.34405
I1028 07:59:18.232553  9023 solver.cpp:241]     Train net output #0: loss = 1.34405 (* 1 = 1.34405 loss)
I1028 07:59:18.232569  9023 sgd_solver.cpp:105] Iteration 143440, lr = 0.00107779
I1028 07:59:49.446549  9023 solver.cpp:222] Iteration 143480 (1.28152 iter/s, 31.2128s/40 iters), loss = 1.53505
I1028 07:59:49.446744  9023 solver.cpp:241]     Train net output #0: loss = 1.53505 (* 1 = 1.53505 loss)
I1028 07:59:49.446763  9023 sgd_solver.cpp:105] Iteration 143480, lr = 0.00107584
I1028 08:00:03.991510  9023 solver.cpp:334] Iteration 143500, Testing net (#0)
I1028 08:00:35.473997  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58104
I1028 08:00:35.474191  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80428
I1028 08:00:35.474208  9023 solver.cpp:401]     Test net output #2: loss = 1.86255 (* 1 = 1.86255 loss)
I1028 08:00:51.637643  9023 solver.cpp:222] Iteration 143520 (0.643205 iter/s, 62.1886s/40 iters), loss = 1.66578
I1028 08:00:51.637720  9023 solver.cpp:241]     Train net output #0: loss = 1.66578 (* 1 = 1.66578 loss)
I1028 08:00:51.637737  9023 sgd_solver.cpp:105] Iteration 143520, lr = 0.0010739
I1028 08:01:22.810369  9023 solver.cpp:222] Iteration 143560 (1.28322 iter/s, 31.1715s/40 iters), loss = 1.52768
I1028 08:01:22.810578  9023 solver.cpp:241]     Train net output #0: loss = 1.52768 (* 1 = 1.52768 loss)
I1028 08:01:22.810596  9023 sgd_solver.cpp:105] Iteration 143560, lr = 0.00107195
I1028 08:01:53.891886  9023 solver.cpp:222] Iteration 143600 (1.287 iter/s, 31.0801s/40 iters), loss = 1.23299
I1028 08:01:53.892069  9023 solver.cpp:241]     Train net output #0: loss = 1.23299 (* 1 = 1.23299 loss)
I1028 08:01:53.892086  9023 sgd_solver.cpp:105] Iteration 143600, lr = 0.00107001
I1028 08:02:25.038105  9023 solver.cpp:222] Iteration 143640 (1.28432 iter/s, 31.1449s/40 iters), loss = 1.39785
I1028 08:02:25.038316  9023 solver.cpp:241]     Train net output #0: loss = 1.39785 (* 1 = 1.39785 loss)
I1028 08:02:25.038339  9023 sgd_solver.cpp:105] Iteration 143640, lr = 0.00106806
I1028 08:02:55.787447  9023 solver.cpp:222] Iteration 143680 (1.3009 iter/s, 30.748s/40 iters), loss = 1.50259
I1028 08:02:55.787708  9023 solver.cpp:241]     Train net output #0: loss = 1.50259 (* 1 = 1.50259 loss)
I1028 08:02:55.787734  9023 sgd_solver.cpp:105] Iteration 143680, lr = 0.00106612
I1028 08:03:26.807541  9023 solver.cpp:222] Iteration 143720 (1.28955 iter/s, 31.0187s/40 iters), loss = 1.49028
I1028 08:03:26.807864  9023 solver.cpp:241]     Train net output #0: loss = 1.49028 (* 1 = 1.49028 loss)
I1028 08:03:26.807904  9023 sgd_solver.cpp:105] Iteration 143720, lr = 0.00106417
I1028 08:03:57.721293  9023 solver.cpp:222] Iteration 143760 (1.29398 iter/s, 30.9123s/40 iters), loss = 1.20465
I1028 08:03:57.721504  9023 solver.cpp:241]     Train net output #0: loss = 1.20465 (* 1 = 1.20465 loss)
I1028 08:03:57.721523  9023 sgd_solver.cpp:105] Iteration 143760, lr = 0.00106223
I1028 08:04:28.603055  9023 solver.cpp:222] Iteration 143800 (1.29532 iter/s, 30.8804s/40 iters), loss = 1.21551
I1028 08:04:28.603250  9023 solver.cpp:241]     Train net output #0: loss = 1.21551 (* 1 = 1.21551 loss)
I1028 08:04:28.603267  9023 sgd_solver.cpp:105] Iteration 143800, lr = 0.00106029
I1028 08:05:04.606750  9023 solver.cpp:222] Iteration 143840 (1.11105 iter/s, 36.0021s/40 iters), loss = 1.46195
I1028 08:05:04.606956  9023 solver.cpp:241]     Train net output #0: loss = 1.46195 (* 1 = 1.46195 loss)
I1028 08:05:04.606974  9023 sgd_solver.cpp:105] Iteration 143840, lr = 0.00105834
I1028 08:05:35.456305  9023 solver.cpp:222] Iteration 143880 (1.29667 iter/s, 30.8482s/40 iters), loss = 1.49153
I1028 08:05:35.456496  9023 solver.cpp:241]     Train net output #0: loss = 1.49153 (* 1 = 1.49153 loss)
I1028 08:05:35.456516  9023 sgd_solver.cpp:105] Iteration 143880, lr = 0.0010564
I1028 08:06:06.638406  9023 solver.cpp:222] Iteration 143920 (1.28284 iter/s, 31.1807s/40 iters), loss = 2.12466
I1028 08:06:06.638622  9023 solver.cpp:241]     Train net output #0: loss = 2.12466 (* 1 = 2.12466 loss)
I1028 08:06:06.638640  9023 sgd_solver.cpp:105] Iteration 143920, lr = 0.00105446
I1028 08:06:38.768146  9023 solver.cpp:222] Iteration 143960 (1.24501 iter/s, 32.1283s/40 iters), loss = 1.28001
I1028 08:06:38.768379  9023 solver.cpp:241]     Train net output #0: loss = 1.28001 (* 1 = 1.28001 loss)
I1028 08:06:38.768402  9023 sgd_solver.cpp:105] Iteration 143960, lr = 0.00105252
I1028 08:07:09.127295  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_144000.caffemodel
I1028 08:07:09.158305  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_144000.solverstate
I1028 08:07:09.175581  9023 solver.cpp:334] Iteration 144000, Testing net (#0)
I1028 08:07:40.580554  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 08:07:40.790598  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57656
I1028 08:07:40.790664  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.809719
I1028 08:07:40.790679  9023 solver.cpp:401]     Test net output #2: loss = 1.86844 (* 1 = 1.86844 loss)
I1028 08:07:41.564458  9023 solver.cpp:222] Iteration 144000 (0.637006 iter/s, 62.7937s/40 iters), loss = 1.15008
I1028 08:07:41.564522  9023 solver.cpp:241]     Train net output #0: loss = 1.15008 (* 1 = 1.15008 loss)
I1028 08:07:41.564538  9023 sgd_solver.cpp:105] Iteration 144000, lr = 0.00105058
I1028 08:08:12.671758  9023 solver.cpp:222] Iteration 144040 (1.28592 iter/s, 31.1061s/40 iters), loss = 1.58974
I1028 08:08:12.671944  9023 solver.cpp:241]     Train net output #0: loss = 1.58974 (* 1 = 1.58974 loss)
I1028 08:08:12.671962  9023 sgd_solver.cpp:105] Iteration 144040, lr = 0.00104864
I1028 08:08:43.892905  9023 solver.cpp:222] Iteration 144080 (1.28124 iter/s, 31.2198s/40 iters), loss = 1.44845
I1028 08:08:43.893106  9023 solver.cpp:241]     Train net output #0: loss = 1.44845 (* 1 = 1.44845 loss)
I1028 08:08:43.893123  9023 sgd_solver.cpp:105] Iteration 144080, lr = 0.0010467
I1028 08:09:14.789376  9023 solver.cpp:222] Iteration 144120 (1.2947 iter/s, 30.8951s/40 iters), loss = 1.70545
I1028 08:09:14.789582  9023 solver.cpp:241]     Train net output #0: loss = 1.70545 (* 1 = 1.70545 loss)
I1028 08:09:14.789598  9023 sgd_solver.cpp:105] Iteration 144120, lr = 0.00104476
I1028 08:09:45.838279  9023 solver.cpp:222] Iteration 144160 (1.28835 iter/s, 31.0475s/40 iters), loss = 1.32623
I1028 08:09:45.838553  9023 solver.cpp:241]     Train net output #0: loss = 1.32623 (* 1 = 1.32623 loss)
I1028 08:09:45.838572  9023 sgd_solver.cpp:105] Iteration 144160, lr = 0.00104283
I1028 08:10:16.726645  9023 solver.cpp:222] Iteration 144200 (1.29505 iter/s, 30.8869s/40 iters), loss = 1.72268
I1028 08:10:16.726835  9023 solver.cpp:241]     Train net output #0: loss = 1.72268 (* 1 = 1.72268 loss)
I1028 08:10:16.726855  9023 sgd_solver.cpp:105] Iteration 144200, lr = 0.00104089
I1028 08:10:47.649338  9023 solver.cpp:222] Iteration 144240 (1.29361 iter/s, 30.9213s/40 iters), loss = 1.48172
I1028 08:10:47.649521  9023 solver.cpp:241]     Train net output #0: loss = 1.48172 (* 1 = 1.48172 loss)
I1028 08:10:47.649538  9023 sgd_solver.cpp:105] Iteration 144240, lr = 0.00103895
I1028 08:11:18.554733  9023 solver.cpp:222] Iteration 144280 (1.29433 iter/s, 30.904s/40 iters), loss = 1.29067
I1028 08:11:18.554960  9023 solver.cpp:241]     Train net output #0: loss = 1.29067 (* 1 = 1.29067 loss)
I1028 08:11:18.554980  9023 sgd_solver.cpp:105] Iteration 144280, lr = 0.00103702
I1028 08:11:49.439067  9023 solver.cpp:222] Iteration 144320 (1.29521 iter/s, 30.8829s/40 iters), loss = 1.16046
I1028 08:11:49.439267  9023 solver.cpp:241]     Train net output #0: loss = 1.16046 (* 1 = 1.16046 loss)
I1028 08:11:49.439283  9023 sgd_solver.cpp:105] Iteration 144320, lr = 0.00103508
I1028 08:12:20.382432  9023 solver.cpp:222] Iteration 144360 (1.29274 iter/s, 30.942s/40 iters), loss = 1.64571
I1028 08:12:20.382622  9023 solver.cpp:241]     Train net output #0: loss = 1.64571 (* 1 = 1.64571 loss)
I1028 08:12:20.382637  9023 sgd_solver.cpp:105] Iteration 144360, lr = 0.00103315
I1028 08:12:51.519299  9023 solver.cpp:222] Iteration 144400 (1.28471 iter/s, 31.1355s/40 iters), loss = 1.30038
I1028 08:12:51.519484  9023 solver.cpp:241]     Train net output #0: loss = 1.30038 (* 1 = 1.30038 loss)
I1028 08:12:51.519501  9023 sgd_solver.cpp:105] Iteration 144400, lr = 0.00103121
I1028 08:13:23.282279  9023 solver.cpp:222] Iteration 144440 (1.25938 iter/s, 31.7616s/40 iters), loss = 1.41494
I1028 08:13:23.282512  9023 solver.cpp:241]     Train net output #0: loss = 1.41494 (* 1 = 1.41494 loss)
I1028 08:13:23.282537  9023 sgd_solver.cpp:105] Iteration 144440, lr = 0.00102928
I1028 08:13:54.959914  9023 solver.cpp:222] Iteration 144480 (1.26278 iter/s, 31.6762s/40 iters), loss = 1.21374
I1028 08:13:54.960114  9023 solver.cpp:241]     Train net output #0: loss = 1.21374 (* 1 = 1.21374 loss)
I1028 08:13:54.960130  9023 sgd_solver.cpp:105] Iteration 144480, lr = 0.00102735
I1028 08:14:09.535289  9023 solver.cpp:334] Iteration 144500, Testing net (#0)
I1028 08:14:41.887383  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58312
I1028 08:14:41.887578  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80632
I1028 08:14:41.887595  9023 solver.cpp:401]     Test net output #2: loss = 1.87319 (* 1 = 1.87319 loss)
I1028 08:14:58.069659  9023 solver.cpp:222] Iteration 144520 (0.633842 iter/s, 63.1072s/40 iters), loss = 1.24582
I1028 08:14:58.069728  9023 solver.cpp:241]     Train net output #0: loss = 1.24582 (* 1 = 1.24582 loss)
I1028 08:14:58.069744  9023 sgd_solver.cpp:105] Iteration 144520, lr = 0.00102542
I1028 08:15:29.939915  9023 solver.cpp:222] Iteration 144560 (1.25514 iter/s, 31.869s/40 iters), loss = 1.30668
I1028 08:15:29.940129  9023 solver.cpp:241]     Train net output #0: loss = 1.30668 (* 1 = 1.30668 loss)
I1028 08:15:29.940146  9023 sgd_solver.cpp:105] Iteration 144560, lr = 0.00102349
I1028 08:15:36.784178  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1028 08:16:01.236316  9023 solver.cpp:222] Iteration 144600 (1.27816 iter/s, 31.295s/40 iters), loss = 1.12128
I1028 08:16:01.236505  9023 solver.cpp:241]     Train net output #0: loss = 1.12128 (* 1 = 1.12128 loss)
I1028 08:16:01.236521  9023 sgd_solver.cpp:105] Iteration 144600, lr = 0.00102155
I1028 08:16:32.865521  9023 solver.cpp:222] Iteration 144640 (1.26471 iter/s, 31.6278s/40 iters), loss = 1.34407
I1028 08:16:32.865733  9023 solver.cpp:241]     Train net output #0: loss = 1.34407 (* 1 = 1.34407 loss)
I1028 08:16:32.865751  9023 sgd_solver.cpp:105] Iteration 144640, lr = 0.00101962
I1028 08:17:04.009423  9023 solver.cpp:222] Iteration 144680 (1.28442 iter/s, 31.1425s/40 iters), loss = 1.39916
I1028 08:17:04.009646  9023 solver.cpp:241]     Train net output #0: loss = 1.39916 (* 1 = 1.39916 loss)
I1028 08:17:04.009665  9023 sgd_solver.cpp:105] Iteration 144680, lr = 0.00101769
I1028 08:17:35.462641  9023 solver.cpp:222] Iteration 144720 (1.27179 iter/s, 31.4518s/40 iters), loss = 1.62288
I1028 08:17:35.462822  9023 solver.cpp:241]     Train net output #0: loss = 1.62288 (* 1 = 1.62288 loss)
I1028 08:17:35.462839  9023 sgd_solver.cpp:105] Iteration 144720, lr = 0.00101577
I1028 08:18:06.527345  9023 solver.cpp:222] Iteration 144760 (1.28769 iter/s, 31.0633s/40 iters), loss = 1.54617
I1028 08:18:06.527511  9023 solver.cpp:241]     Train net output #0: loss = 1.54617 (* 1 = 1.54617 loss)
I1028 08:18:06.527531  9023 sgd_solver.cpp:105] Iteration 144760, lr = 0.00101384
I1028 08:18:37.641815  9023 solver.cpp:222] Iteration 144800 (1.28563 iter/s, 31.1131s/40 iters), loss = 1.40069
I1028 08:18:37.641984  9023 solver.cpp:241]     Train net output #0: loss = 1.40069 (* 1 = 1.40069 loss)
I1028 08:18:37.642001  9023 sgd_solver.cpp:105] Iteration 144800, lr = 0.00101191
I1028 08:19:08.548336  9023 solver.cpp:222] Iteration 144840 (1.29428 iter/s, 30.9052s/40 iters), loss = 1.45772
I1028 08:19:08.548516  9023 solver.cpp:241]     Train net output #0: loss = 1.45772 (* 1 = 1.45772 loss)
I1028 08:19:08.548532  9023 sgd_solver.cpp:105] Iteration 144840, lr = 0.00100998
I1028 08:19:39.788334  9023 solver.cpp:222] Iteration 144880 (1.28047 iter/s, 31.2386s/40 iters), loss = 1.24937
I1028 08:19:39.788530  9023 solver.cpp:241]     Train net output #0: loss = 1.24937 (* 1 = 1.24937 loss)
I1028 08:19:39.788552  9023 sgd_solver.cpp:105] Iteration 144880, lr = 0.00100806
I1028 08:20:11.708214  9023 solver.cpp:222] Iteration 144920 (1.25319 iter/s, 31.9185s/40 iters), loss = 1.25507
I1028 08:20:11.708406  9023 solver.cpp:241]     Train net output #0: loss = 1.25507 (* 1 = 1.25507 loss)
I1028 08:20:11.708423  9023 sgd_solver.cpp:105] Iteration 144920, lr = 0.00100613
I1028 08:20:43.102708  9023 solver.cpp:222] Iteration 144960 (1.27416 iter/s, 31.3931s/40 iters), loss = 1.19188
I1028 08:20:43.102910  9023 solver.cpp:241]     Train net output #0: loss = 1.19188 (* 1 = 1.19188 loss)
I1028 08:20:43.102929  9023 sgd_solver.cpp:105] Iteration 144960, lr = 0.0010042
I1028 08:21:22.169800  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_145000.caffemodel
I1028 08:21:22.212818  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_145000.solverstate
I1028 08:21:22.236202  9023 solver.cpp:334] Iteration 145000, Testing net (#0)
I1028 08:21:53.990453  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 08:21:54.204540  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57744
I1028 08:21:54.204604  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8082
I1028 08:21:54.204618  9023 solver.cpp:401]     Test net output #2: loss = 1.86152 (* 1 = 1.86152 loss)
I1028 08:21:54.972450  9023 solver.cpp:222] Iteration 145000 (0.556585 iter/s, 71.8669s/40 iters), loss = 1.61087
I1028 08:21:54.972515  9023 solver.cpp:241]     Train net output #0: loss = 1.61087 (* 1 = 1.61087 loss)
I1028 08:21:54.972530  9023 sgd_solver.cpp:105] Iteration 145000, lr = 0.00100228
I1028 08:22:26.353469  9023 solver.cpp:222] Iteration 145040 (1.27471 iter/s, 31.3798s/40 iters), loss = 1.52229
I1028 08:22:26.353637  9023 solver.cpp:241]     Train net output #0: loss = 1.52229 (* 1 = 1.52229 loss)
I1028 08:22:26.353655  9023 sgd_solver.cpp:105] Iteration 145040, lr = 0.00100036
I1028 08:22:57.936501  9023 solver.cpp:222] Iteration 145080 (1.26656 iter/s, 31.5817s/40 iters), loss = 1.55512
I1028 08:22:57.936693  9023 solver.cpp:241]     Train net output #0: loss = 1.55512 (* 1 = 1.55512 loss)
I1028 08:22:57.936722  9023 sgd_solver.cpp:105] Iteration 145080, lr = 0.000998433
I1028 08:23:29.353932  9023 solver.cpp:222] Iteration 145120 (1.27323 iter/s, 31.4161s/40 iters), loss = 1.59528
I1028 08:23:29.354151  9023 solver.cpp:241]     Train net output #0: loss = 1.59528 (* 1 = 1.59528 loss)
I1028 08:23:29.354167  9023 sgd_solver.cpp:105] Iteration 145120, lr = 0.00099651
I1028 08:24:00.638768  9023 solver.cpp:222] Iteration 145160 (1.27863 iter/s, 31.2834s/40 iters), loss = 1.6165
I1028 08:24:00.638955  9023 solver.cpp:241]     Train net output #0: loss = 1.6165 (* 1 = 1.6165 loss)
I1028 08:24:00.638973  9023 sgd_solver.cpp:105] Iteration 145160, lr = 0.000994588
I1028 08:24:31.913312  9023 solver.cpp:222] Iteration 145200 (1.27905 iter/s, 31.2732s/40 iters), loss = 1.38153
I1028 08:24:31.913506  9023 solver.cpp:241]     Train net output #0: loss = 1.38153 (* 1 = 1.38153 loss)
I1028 08:24:31.913524  9023 sgd_solver.cpp:105] Iteration 145200, lr = 0.000992666
I1028 08:25:03.832041  9023 solver.cpp:222] Iteration 145240 (1.25324 iter/s, 31.9173s/40 iters), loss = 1.45275
I1028 08:25:03.832239  9023 solver.cpp:241]     Train net output #0: loss = 1.45275 (* 1 = 1.45275 loss)
I1028 08:25:03.832255  9023 sgd_solver.cpp:105] Iteration 145240, lr = 0.000990745
I1028 08:25:35.048137  9023 solver.cpp:222] Iteration 145280 (1.28145 iter/s, 31.2147s/40 iters), loss = 1.10399
I1028 08:25:35.048367  9023 solver.cpp:241]     Train net output #0: loss = 1.10399 (* 1 = 1.10399 loss)
I1028 08:25:35.048393  9023 sgd_solver.cpp:105] Iteration 145280, lr = 0.000988825
I1028 08:26:06.312379  9023 solver.cpp:222] Iteration 145320 (1.27947 iter/s, 31.2628s/40 iters), loss = 1.49756
I1028 08:26:06.312562  9023 solver.cpp:241]     Train net output #0: loss = 1.49756 (* 1 = 1.49756 loss)
I1028 08:26:06.312579  9023 sgd_solver.cpp:105] Iteration 145320, lr = 0.000986905
I1028 08:26:37.524667  9023 solver.cpp:222] Iteration 145360 (1.2816 iter/s, 31.2109s/40 iters), loss = 1.43722
I1028 08:26:37.524885  9023 solver.cpp:241]     Train net output #0: loss = 1.43722 (* 1 = 1.43722 loss)
I1028 08:26:37.524904  9023 sgd_solver.cpp:105] Iteration 145360, lr = 0.000984986
I1028 08:27:08.181437  9023 solver.cpp:222] Iteration 145400 (1.30483 iter/s, 30.6554s/40 iters), loss = 1.32563
I1028 08:27:08.181599  9023 solver.cpp:241]     Train net output #0: loss = 1.32563 (* 1 = 1.32563 loss)
I1028 08:27:08.181615  9023 sgd_solver.cpp:105] Iteration 145400, lr = 0.000983068
I1028 08:27:39.216069  9023 solver.cpp:222] Iteration 145440 (1.28894 iter/s, 31.0333s/40 iters), loss = 1.23087
I1028 08:27:39.216279  9023 solver.cpp:241]     Train net output #0: loss = 1.23087 (* 1 = 1.23087 loss)
I1028 08:27:39.216303  9023 sgd_solver.cpp:105] Iteration 145440, lr = 0.00098115
I1028 08:28:11.084446  9023 solver.cpp:222] Iteration 145480 (1.25522 iter/s, 31.8669s/40 iters), loss = 1.35315
I1028 08:28:11.084712  9023 solver.cpp:241]     Train net output #0: loss = 1.35315 (* 1 = 1.35315 loss)
I1028 08:28:11.084731  9023 sgd_solver.cpp:105] Iteration 145480, lr = 0.000979233
I1028 08:28:25.728106  9023 solver.cpp:334] Iteration 145500, Testing net (#0)
I1028 08:28:57.035069  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57796
I1028 08:28:57.035269  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80372
I1028 08:28:57.035285  9023 solver.cpp:401]     Test net output #2: loss = 1.86279 (* 1 = 1.86279 loss)
I1028 08:29:13.758483  9023 solver.cpp:222] Iteration 145520 (0.638249 iter/s, 62.6714s/40 iters), loss = 1.53945
I1028 08:29:13.758590  9023 solver.cpp:241]     Train net output #0: loss = 1.53945 (* 1 = 1.53945 loss)
I1028 08:29:13.758617  9023 sgd_solver.cpp:105] Iteration 145520, lr = 0.000977316
I1028 08:29:45.175956  9023 solver.cpp:222] Iteration 145560 (1.27323 iter/s, 31.4162s/40 iters), loss = 1.54567
I1028 08:29:45.176163  9023 solver.cpp:241]     Train net output #0: loss = 1.54567 (* 1 = 1.54567 loss)
I1028 08:29:45.176180  9023 sgd_solver.cpp:105] Iteration 145560, lr = 0.0009754
I1028 08:30:16.496848  9023 solver.cpp:222] Iteration 145600 (1.27716 iter/s, 31.3195s/40 iters), loss = 1.58286
I1028 08:30:16.497094  9023 solver.cpp:241]     Train net output #0: loss = 1.58286 (* 1 = 1.58286 loss)
I1028 08:30:16.497112  9023 sgd_solver.cpp:105] Iteration 145600, lr = 0.000973485
I1028 08:30:47.610126  9023 solver.cpp:222] Iteration 145640 (1.28568 iter/s, 31.1119s/40 iters), loss = 1.41101
I1028 08:30:47.610313  9023 solver.cpp:241]     Train net output #0: loss = 1.41101 (* 1 = 1.41101 loss)
I1028 08:30:47.610332  9023 sgd_solver.cpp:105] Iteration 145640, lr = 0.00097157
I1028 08:31:18.670910  9023 solver.cpp:222] Iteration 145680 (1.28785 iter/s, 31.0594s/40 iters), loss = 1.37102
I1028 08:31:18.671114  9023 solver.cpp:241]     Train net output #0: loss = 1.37102 (* 1 = 1.37102 loss)
I1028 08:31:18.671133  9023 sgd_solver.cpp:105] Iteration 145680, lr = 0.000969656
I1028 08:31:49.586802  9023 solver.cpp:222] Iteration 145720 (1.29389 iter/s, 30.9145s/40 iters), loss = 1.53409
I1028 08:31:49.586999  9023 solver.cpp:241]     Train net output #0: loss = 1.53409 (* 1 = 1.53409 loss)
I1028 08:31:49.587016  9023 sgd_solver.cpp:105] Iteration 145720, lr = 0.000967742
I1028 08:32:20.981397  9023 solver.cpp:222] Iteration 145760 (1.27416 iter/s, 31.3932s/40 iters), loss = 1.41964
I1028 08:32:20.981571  9023 solver.cpp:241]     Train net output #0: loss = 1.41964 (* 1 = 1.41964 loss)
I1028 08:32:20.981588  9023 sgd_solver.cpp:105] Iteration 145760, lr = 0.000965829
I1028 08:32:52.345499  9023 solver.cpp:222] Iteration 145800 (1.2754 iter/s, 31.3628s/40 iters), loss = 1.67049
I1028 08:32:52.345685  9023 solver.cpp:241]     Train net output #0: loss = 1.67049 (* 1 = 1.67049 loss)
I1028 08:32:52.345702  9023 sgd_solver.cpp:105] Iteration 145800, lr = 0.000963917
I1028 08:33:23.156466  9023 solver.cpp:222] Iteration 145840 (1.2983 iter/s, 30.8096s/40 iters), loss = 1.8145
I1028 08:33:23.156632  9023 solver.cpp:241]     Train net output #0: loss = 1.8145 (* 1 = 1.8145 loss)
I1028 08:33:23.156651  9023 sgd_solver.cpp:105] Iteration 145840, lr = 0.000962005
I1028 08:33:54.137784  9023 solver.cpp:222] Iteration 145880 (1.29116 iter/s, 30.98s/40 iters), loss = 1.44666
I1028 08:33:54.137969  9023 solver.cpp:241]     Train net output #0: loss = 1.44666 (* 1 = 1.44666 loss)
I1028 08:33:54.137986  9023 sgd_solver.cpp:105] Iteration 145880, lr = 0.000960095
I1028 08:34:24.980399  9023 solver.cpp:222] Iteration 145920 (1.29696 iter/s, 30.8413s/40 iters), loss = 1.82586
I1028 08:34:24.980583  9023 solver.cpp:241]     Train net output #0: loss = 1.82586 (* 1 = 1.82586 loss)
I1028 08:34:24.980599  9023 sgd_solver.cpp:105] Iteration 145920, lr = 0.000958184
I1028 08:34:56.609885  9023 solver.cpp:222] Iteration 145960 (1.2647 iter/s, 31.6281s/40 iters), loss = 1.92267
I1028 08:34:56.610054  9023 solver.cpp:241]     Train net output #0: loss = 1.92267 (* 1 = 1.92267 loss)
I1028 08:34:56.610070  9023 sgd_solver.cpp:105] Iteration 145960, lr = 0.000956275
I1028 08:35:27.002988  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_146000.caffemodel
I1028 08:35:27.034312  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_146000.solverstate
I1028 08:35:27.051509  9023 solver.cpp:334] Iteration 146000, Testing net (#0)
I1028 08:35:58.461632  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 08:35:58.668941  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57676
I1028 08:35:58.669003  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80932
I1028 08:35:58.669015  9023 solver.cpp:401]     Test net output #2: loss = 1.86865 (* 1 = 1.86865 loss)
I1028 08:35:59.438778  9023 solver.cpp:222] Iteration 146000 (0.636675 iter/s, 62.8264s/40 iters), loss = 1.33976
I1028 08:35:59.438843  9023 solver.cpp:241]     Train net output #0: loss = 1.33976 (* 1 = 1.33976 loss)
I1028 08:35:59.438858  9023 sgd_solver.cpp:105] Iteration 146000, lr = 0.000954365
I1028 08:36:35.500056  9023 solver.cpp:222] Iteration 146040 (1.10927 iter/s, 36.0599s/40 iters), loss = 1.28578
I1028 08:36:35.500419  9023 solver.cpp:241]     Train net output #0: loss = 1.28578 (* 1 = 1.28578 loss)
I1028 08:36:35.500458  9023 sgd_solver.cpp:105] Iteration 146040, lr = 0.000952457
I1028 08:37:06.338359  9023 solver.cpp:222] Iteration 146080 (1.29715 iter/s, 30.8368s/40 iters), loss = 1.34291
I1028 08:37:06.338567  9023 solver.cpp:241]     Train net output #0: loss = 1.34291 (* 1 = 1.34291 loss)
I1028 08:37:06.338584  9023 sgd_solver.cpp:105] Iteration 146080, lr = 0.000950549
I1028 08:37:37.261782  9023 solver.cpp:222] Iteration 146120 (1.29358 iter/s, 30.922s/40 iters), loss = 1.443
I1028 08:37:37.261968  9023 solver.cpp:241]     Train net output #0: loss = 1.443 (* 1 = 1.443 loss)
I1028 08:37:37.261986  9023 sgd_solver.cpp:105] Iteration 146120, lr = 0.000948642
I1028 08:38:08.607643  9023 solver.cpp:222] Iteration 146160 (1.27614 iter/s, 31.3445s/40 iters), loss = 1.57554
I1028 08:38:08.607836  9023 solver.cpp:241]     Train net output #0: loss = 1.57554 (* 1 = 1.57554 loss)
I1028 08:38:08.607856  9023 sgd_solver.cpp:105] Iteration 146160, lr = 0.000946736
I1028 08:38:39.914916  9023 solver.cpp:222] Iteration 146200 (1.27771 iter/s, 31.3059s/40 iters), loss = 1.5592
I1028 08:38:39.915107  9023 solver.cpp:241]     Train net output #0: loss = 1.5592 (* 1 = 1.5592 loss)
I1028 08:38:39.915128  9023 sgd_solver.cpp:105] Iteration 146200, lr = 0.00094483
I1028 08:39:10.943640  9023 solver.cpp:222] Iteration 146240 (1.28919 iter/s, 31.0274s/40 iters), loss = 1.13056
I1028 08:39:10.943825  9023 solver.cpp:241]     Train net output #0: loss = 1.13056 (* 1 = 1.13056 loss)
I1028 08:39:10.943842  9023 sgd_solver.cpp:105] Iteration 146240, lr = 0.000942925
I1028 08:39:41.944720  9023 solver.cpp:222] Iteration 146280 (1.29033 iter/s, 30.9997s/40 iters), loss = 1.20319
I1028 08:39:41.944905  9023 solver.cpp:241]     Train net output #0: loss = 1.20319 (* 1 = 1.20319 loss)
I1028 08:39:41.944922  9023 sgd_solver.cpp:105] Iteration 146280, lr = 0.00094102
I1028 08:40:13.383700  9023 solver.cpp:222] Iteration 146320 (1.27236 iter/s, 31.4376s/40 iters), loss = 1.80485
I1028 08:40:13.383891  9023 solver.cpp:241]     Train net output #0: loss = 1.80485 (* 1 = 1.80485 loss)
I1028 08:40:13.383908  9023 sgd_solver.cpp:105] Iteration 146320, lr = 0.000939116
I1028 08:40:44.283939  9023 solver.cpp:222] Iteration 146360 (1.29455 iter/s, 30.8989s/40 iters), loss = 1.72254
I1028 08:40:44.284132  9023 solver.cpp:241]     Train net output #0: loss = 1.72254 (* 1 = 1.72254 loss)
I1028 08:40:44.284148  9023 sgd_solver.cpp:105] Iteration 146360, lr = 0.000937213
I1028 08:41:15.282397  9023 solver.cpp:222] Iteration 146400 (1.29044 iter/s, 30.9971s/40 iters), loss = 1.66399
I1028 08:41:15.282593  9023 solver.cpp:241]     Train net output #0: loss = 1.66399 (* 1 = 1.66399 loss)
I1028 08:41:15.282610  9023 sgd_solver.cpp:105] Iteration 146400, lr = 0.00093531
I1028 08:41:46.107522  9023 solver.cpp:222] Iteration 146440 (1.2977 iter/s, 30.8238s/40 iters), loss = 1.5747
I1028 08:41:46.107702  9023 solver.cpp:241]     Train net output #0: loss = 1.5747 (* 1 = 1.5747 loss)
I1028 08:41:46.107717  9023 sgd_solver.cpp:105] Iteration 146440, lr = 0.000933408
I1028 08:42:16.516783  9023 solver.cpp:222] Iteration 146480 (1.31545 iter/s, 30.4079s/40 iters), loss = 1.37811
I1028 08:42:16.516918  9023 solver.cpp:241]     Train net output #0: loss = 1.37811 (* 1 = 1.37811 loss)
I1028 08:42:16.516934  9023 sgd_solver.cpp:105] Iteration 146480, lr = 0.000931507
I1028 08:42:30.992631  9023 solver.cpp:334] Iteration 146500, Testing net (#0)
I1028 08:43:02.435700  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57956
I1028 08:43:02.435878  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8062
I1028 08:43:02.435894  9023 solver.cpp:401]     Test net output #2: loss = 1.86978 (* 1 = 1.86978 loss)
I1028 08:43:18.294901  9023 solver.cpp:222] Iteration 146520 (0.647504 iter/s, 61.7757s/40 iters), loss = 1.42193
I1028 08:43:18.294970  9023 solver.cpp:241]     Train net output #0: loss = 1.42193 (* 1 = 1.42193 loss)
I1028 08:43:18.295006  9023 sgd_solver.cpp:105] Iteration 146520, lr = 0.000929606
I1028 08:43:48.620066  9023 solver.cpp:222] Iteration 146560 (1.31909 iter/s, 30.324s/40 iters), loss = 1.41532
I1028 08:43:48.620312  9023 solver.cpp:241]     Train net output #0: loss = 1.41532 (* 1 = 1.41532 loss)
I1028 08:43:48.620335  9023 sgd_solver.cpp:105] Iteration 146560, lr = 0.000927706
I1028 08:44:19.981107  9023 solver.cpp:222] Iteration 146600 (1.27553 iter/s, 31.3596s/40 iters), loss = 1.69597
I1028 08:44:19.981295  9023 solver.cpp:241]     Train net output #0: loss = 1.69597 (* 1 = 1.69597 loss)
I1028 08:44:19.981317  9023 sgd_solver.cpp:105] Iteration 146600, lr = 0.000925806
I1028 08:44:50.583032  9023 solver.cpp:222] Iteration 146640 (1.30716 iter/s, 30.6006s/40 iters), loss = 1.54309
I1028 08:44:50.583205  9023 solver.cpp:241]     Train net output #0: loss = 1.54309 (* 1 = 1.54309 loss)
I1028 08:44:50.583222  9023 sgd_solver.cpp:105] Iteration 146640, lr = 0.000923908
I1028 08:45:21.680975  9023 solver.cpp:222] Iteration 146680 (1.28631 iter/s, 31.0966s/40 iters), loss = 1.21406
I1028 08:45:21.681188  9023 solver.cpp:241]     Train net output #0: loss = 1.21406 (* 1 = 1.21406 loss)
I1028 08:45:21.681213  9023 sgd_solver.cpp:105] Iteration 146680, lr = 0.00092201
I1028 08:45:53.351747  9023 solver.cpp:222] Iteration 146720 (1.26305 iter/s, 31.6694s/40 iters), loss = 1.30533
I1028 08:45:53.351954  9023 solver.cpp:241]     Train net output #0: loss = 1.30533 (* 1 = 1.30533 loss)
I1028 08:45:53.351975  9023 sgd_solver.cpp:105] Iteration 146720, lr = 0.000920112
I1028 08:46:24.258431  9023 solver.cpp:222] Iteration 146760 (1.29428 iter/s, 30.9053s/40 iters), loss = 1.21189
I1028 08:46:24.258601  9023 solver.cpp:241]     Train net output #0: loss = 1.21189 (* 1 = 1.21189 loss)
I1028 08:46:24.258620  9023 sgd_solver.cpp:105] Iteration 146760, lr = 0.000918215
I1028 08:46:54.966334  9023 solver.cpp:222] Iteration 146800 (1.30265 iter/s, 30.7066s/40 iters), loss = 1.37286
I1028 08:46:54.966497  9023 solver.cpp:241]     Train net output #0: loss = 1.37286 (* 1 = 1.37286 loss)
I1028 08:46:54.966514  9023 sgd_solver.cpp:105] Iteration 146800, lr = 0.000916319
I1028 08:47:27.541764  9023 solver.cpp:222] Iteration 146840 (1.22797 iter/s, 32.574s/40 iters), loss = 1.25087
I1028 08:47:27.541937  9023 solver.cpp:241]     Train net output #0: loss = 1.25087 (* 1 = 1.25087 loss)
I1028 08:47:27.541954  9023 sgd_solver.cpp:105] Iteration 146840, lr = 0.000914424
I1028 08:47:59.332052  9023 solver.cpp:222] Iteration 146880 (1.2583 iter/s, 31.7889s/40 iters), loss = 1.14572
I1028 08:47:59.332221  9023 solver.cpp:241]     Train net output #0: loss = 1.14572 (* 1 = 1.14572 loss)
I1028 08:47:59.332238  9023 sgd_solver.cpp:105] Iteration 146880, lr = 0.000912529
I1028 08:48:33.182596  9023 solver.cpp:222] Iteration 146920 (1.18172 iter/s, 33.8491s/40 iters), loss = 1.46476
I1028 08:48:33.182796  9023 solver.cpp:241]     Train net output #0: loss = 1.46476 (* 1 = 1.46476 loss)
I1028 08:48:33.182812  9023 sgd_solver.cpp:105] Iteration 146920, lr = 0.000910635
I1028 08:49:04.526579  9023 solver.cpp:222] Iteration 146960 (1.27622 iter/s, 31.3426s/40 iters), loss = 1.13336
I1028 08:49:04.526752  9023 solver.cpp:241]     Train net output #0: loss = 1.13336 (* 1 = 1.13336 loss)
I1028 08:49:04.526769  9023 sgd_solver.cpp:105] Iteration 146960, lr = 0.000908741
I1028 08:49:34.716151  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_147000.caffemodel
I1028 08:49:34.747323  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_147000.solverstate
I1028 08:49:34.764286  9023 solver.cpp:334] Iteration 147000, Testing net (#0)
I1028 08:50:05.782675  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 08:50:05.993757  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58
I1028 08:50:05.993824  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81124
I1028 08:50:05.993855  9023 solver.cpp:401]     Test net output #2: loss = 1.86975 (* 1 = 1.86975 loss)
I1028 08:50:06.767056  9023 solver.cpp:222] Iteration 147000 (0.642694 iter/s, 62.238s/40 iters), loss = 1.5963
I1028 08:50:06.767125  9023 solver.cpp:241]     Train net output #0: loss = 1.5963 (* 1 = 1.5963 loss)
I1028 08:50:06.767141  9023 sgd_solver.cpp:105] Iteration 147000, lr = 0.000906848
I1028 08:50:37.712026  9023 solver.cpp:222] Iteration 147040 (1.29267 iter/s, 30.9437s/40 iters), loss = 1.39815
I1028 08:50:37.712265  9023 solver.cpp:241]     Train net output #0: loss = 1.39815 (* 1 = 1.39815 loss)
I1028 08:50:37.712290  9023 sgd_solver.cpp:105] Iteration 147040, lr = 0.000904956
I1028 08:51:01.631108  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1028 08:51:08.555910  9023 solver.cpp:222] Iteration 147080 (1.29691 iter/s, 30.8425s/40 iters), loss = 1.59488
I1028 08:51:08.556126  9023 solver.cpp:241]     Train net output #0: loss = 1.59488 (* 1 = 1.59488 loss)
I1028 08:51:08.556143  9023 sgd_solver.cpp:105] Iteration 147080, lr = 0.000903064
I1028 08:51:39.821643  9023 solver.cpp:222] Iteration 147120 (1.27941 iter/s, 31.2643s/40 iters), loss = 1.3823
I1028 08:51:39.821867  9023 solver.cpp:241]     Train net output #0: loss = 1.3823 (* 1 = 1.3823 loss)
I1028 08:51:39.821893  9023 sgd_solver.cpp:105] Iteration 147120, lr = 0.000901174
I1028 08:52:12.646437  9023 solver.cpp:222] Iteration 147160 (1.21865 iter/s, 32.8233s/40 iters), loss = 1.40701
I1028 08:52:12.646622  9023 solver.cpp:241]     Train net output #0: loss = 1.40701 (* 1 = 1.40701 loss)
I1028 08:52:12.646641  9023 sgd_solver.cpp:105] Iteration 147160, lr = 0.000899283
I1028 08:52:43.232152  9023 solver.cpp:222] Iteration 147200 (1.30786 iter/s, 30.5844s/40 iters), loss = 1.32668
I1028 08:52:43.232334  9023 solver.cpp:241]     Train net output #0: loss = 1.32668 (* 1 = 1.32668 loss)
I1028 08:52:43.232352  9023 sgd_solver.cpp:105] Iteration 147200, lr = 0.000897394
I1028 08:53:14.743814  9023 solver.cpp:222] Iteration 147240 (1.26943 iter/s, 31.5103s/40 iters), loss = 1.66839
I1028 08:53:14.744050  9023 solver.cpp:241]     Train net output #0: loss = 1.66839 (* 1 = 1.66839 loss)
I1028 08:53:14.744076  9023 sgd_solver.cpp:105] Iteration 147240, lr = 0.000895505
I1028 08:53:47.173202  9023 solver.cpp:222] Iteration 147280 (1.2335 iter/s, 32.4279s/40 iters), loss = 1.66664
I1028 08:53:47.173370  9023 solver.cpp:241]     Train net output #0: loss = 1.66664 (* 1 = 1.66664 loss)
I1028 08:53:47.173387  9023 sgd_solver.cpp:105] Iteration 147280, lr = 0.000893617
I1028 08:54:18.653512  9023 solver.cpp:222] Iteration 147320 (1.27069 iter/s, 31.479s/40 iters), loss = 1.44681
I1028 08:54:18.653710  9023 solver.cpp:241]     Train net output #0: loss = 1.44681 (* 1 = 1.44681 loss)
I1028 08:54:18.653726  9023 sgd_solver.cpp:105] Iteration 147320, lr = 0.000891729
I1028 08:54:50.159714  9023 solver.cpp:222] Iteration 147360 (1.26965 iter/s, 31.5048s/40 iters), loss = 1.20327
I1028 08:54:50.159927  9023 solver.cpp:241]     Train net output #0: loss = 1.20327 (* 1 = 1.20327 loss)
I1028 08:54:50.159945  9023 sgd_solver.cpp:105] Iteration 147360, lr = 0.000889842
I1028 08:55:21.393581  9023 solver.cpp:222] Iteration 147400 (1.28072 iter/s, 31.2325s/40 iters), loss = 1.15624
I1028 08:55:21.393784  9023 solver.cpp:241]     Train net output #0: loss = 1.15624 (* 1 = 1.15624 loss)
I1028 08:55:21.394218  9023 sgd_solver.cpp:105] Iteration 147400, lr = 0.000887956
I1028 08:55:52.721467  9023 solver.cpp:222] Iteration 147440 (1.27687 iter/s, 31.3265s/40 iters), loss = 1.69859
I1028 08:55:52.721626  9023 solver.cpp:241]     Train net output #0: loss = 1.69859 (* 1 = 1.69859 loss)
I1028 08:55:52.721642  9023 sgd_solver.cpp:105] Iteration 147440, lr = 0.00088607
I1028 08:56:23.817149  9023 solver.cpp:222] Iteration 147480 (1.28641 iter/s, 31.0943s/40 iters), loss = 1.33159
I1028 08:56:23.817334  9023 solver.cpp:241]     Train net output #0: loss = 1.33159 (* 1 = 1.33159 loss)
I1028 08:56:23.817354  9023 sgd_solver.cpp:105] Iteration 147480, lr = 0.000884185
I1028 08:56:38.519842  9023 solver.cpp:334] Iteration 147500, Testing net (#0)
I1028 08:57:10.017992  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58156
I1028 08:57:10.018244  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.807039
I1028 08:57:10.018263  9023 solver.cpp:401]     Test net output #2: loss = 1.85087 (* 1 = 1.85087 loss)
I1028 08:57:26.201117  9023 solver.cpp:222] Iteration 147520 (0.641216 iter/s, 62.3814s/40 iters), loss = 1.88747
I1028 08:57:26.201191  9023 solver.cpp:241]     Train net output #0: loss = 1.88747 (* 1 = 1.88747 loss)
I1028 08:57:26.201207  9023 sgd_solver.cpp:105] Iteration 147520, lr = 0.000882301
I1028 08:57:57.273466  9023 solver.cpp:222] Iteration 147560 (1.28737 iter/s, 31.0711s/40 iters), loss = 1.48391
I1028 08:57:57.273659  9023 solver.cpp:241]     Train net output #0: loss = 1.48391 (* 1 = 1.48391 loss)
I1028 08:57:57.273675  9023 sgd_solver.cpp:105] Iteration 147560, lr = 0.000880418
I1028 08:58:28.414227  9023 solver.cpp:222] Iteration 147600 (1.28455 iter/s, 31.1394s/40 iters), loss = 1.31151
I1028 08:58:28.414420  9023 solver.cpp:241]     Train net output #0: loss = 1.31151 (* 1 = 1.31151 loss)
I1028 08:58:28.414438  9023 sgd_solver.cpp:105] Iteration 147600, lr = 0.000878535
I1028 08:58:59.349858  9023 solver.cpp:222] Iteration 147640 (1.29306 iter/s, 30.9343s/40 iters), loss = 1.64414
I1028 08:58:59.350042  9023 solver.cpp:241]     Train net output #0: loss = 1.64414 (* 1 = 1.64414 loss)
I1028 08:58:59.350060  9023 sgd_solver.cpp:105] Iteration 147640, lr = 0.000876652
I1028 08:59:30.472038  9023 solver.cpp:222] Iteration 147680 (1.28531 iter/s, 31.1208s/40 iters), loss = 1.21852
I1028 08:59:30.472246  9023 solver.cpp:241]     Train net output #0: loss = 1.21852 (* 1 = 1.21852 loss)
I1028 08:59:30.472263  9023 sgd_solver.cpp:105] Iteration 147680, lr = 0.000874771
I1028 09:00:01.674824  9023 solver.cpp:222] Iteration 147720 (1.28199 iter/s, 31.2014s/40 iters), loss = 1.4756
I1028 09:00:01.675016  9023 solver.cpp:241]     Train net output #0: loss = 1.4756 (* 1 = 1.4756 loss)
I1028 09:00:01.675034  9023 sgd_solver.cpp:105] Iteration 147720, lr = 0.00087289
I1028 09:00:32.683923  9023 solver.cpp:222] Iteration 147760 (1.29 iter/s, 31.0077s/40 iters), loss = 1.44442
I1028 09:00:32.684114  9023 solver.cpp:241]     Train net output #0: loss = 1.44442 (* 1 = 1.44442 loss)
I1028 09:00:32.684130  9023 sgd_solver.cpp:105] Iteration 147760, lr = 0.00087101
I1028 09:01:03.519460  9023 solver.cpp:222] Iteration 147800 (1.29726 iter/s, 30.8342s/40 iters), loss = 1.54476
I1028 09:01:03.519646  9023 solver.cpp:241]     Train net output #0: loss = 1.54476 (* 1 = 1.54476 loss)
I1028 09:01:03.519665  9023 sgd_solver.cpp:105] Iteration 147800, lr = 0.00086913
I1028 09:01:34.539608  9023 solver.cpp:222] Iteration 147840 (1.28954 iter/s, 31.0188s/40 iters), loss = 1.50134
I1028 09:01:34.539813  9023 solver.cpp:241]     Train net output #0: loss = 1.50134 (* 1 = 1.50134 loss)
I1028 09:01:34.539829  9023 sgd_solver.cpp:105] Iteration 147840, lr = 0.000867251
I1028 09:02:05.712126  9023 solver.cpp:222] Iteration 147880 (1.28324 iter/s, 31.1711s/40 iters), loss = 1.68262
I1028 09:02:05.712339  9023 solver.cpp:241]     Train net output #0: loss = 1.68262 (* 1 = 1.68262 loss)
I1028 09:02:05.712359  9023 sgd_solver.cpp:105] Iteration 147880, lr = 0.000865373
I1028 09:02:37.777710  9023 solver.cpp:222] Iteration 147920 (1.2475 iter/s, 32.0642s/40 iters), loss = 1.44495
I1028 09:02:37.777912  9023 solver.cpp:241]     Train net output #0: loss = 1.44495 (* 1 = 1.44495 loss)
I1028 09:02:37.777928  9023 sgd_solver.cpp:105] Iteration 147920, lr = 0.000863495
I1028 09:03:09.296780  9023 solver.cpp:222] Iteration 147960 (1.26913 iter/s, 31.5177s/40 iters), loss = 1.28232
I1028 09:03:09.296958  9023 solver.cpp:241]     Train net output #0: loss = 1.28232 (* 1 = 1.28232 loss)
I1028 09:03:09.296975  9023 sgd_solver.cpp:105] Iteration 147960, lr = 0.000861619
I1028 09:03:39.518961  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_148000.caffemodel
I1028 09:03:39.550606  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_148000.solverstate
I1028 09:03:39.567250  9023 solver.cpp:334] Iteration 148000, Testing net (#0)
I1028 09:04:10.946377  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 09:04:11.158293  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57836
I1028 09:04:11.158359  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80912
I1028 09:04:11.158372  9023 solver.cpp:401]     Test net output #2: loss = 1.87343 (* 1 = 1.87343 loss)
I1028 09:04:11.928876  9023 solver.cpp:222] Iteration 148000 (0.638676 iter/s, 62.6296s/40 iters), loss = 1.35688
I1028 09:04:11.928943  9023 solver.cpp:241]     Train net output #0: loss = 1.35688 (* 1 = 1.35688 loss)
I1028 09:04:11.928958  9023 sgd_solver.cpp:105] Iteration 148000, lr = 0.000859743
I1028 09:04:43.132112  9023 solver.cpp:222] Iteration 148040 (1.28197 iter/s, 31.202s/40 iters), loss = 1.22246
I1028 09:04:43.132347  9023 solver.cpp:241]     Train net output #0: loss = 1.22246 (* 1 = 1.22246 loss)
I1028 09:04:43.132364  9023 sgd_solver.cpp:105] Iteration 148040, lr = 0.000857867
I1028 09:05:14.505920  9023 solver.cpp:222] Iteration 148080 (1.27501 iter/s, 31.3724s/40 iters), loss = 1.58177
I1028 09:05:14.506119  9023 solver.cpp:241]     Train net output #0: loss = 1.58177 (* 1 = 1.58177 loss)
I1028 09:05:14.506136  9023 sgd_solver.cpp:105] Iteration 148080, lr = 0.000855992
I1028 09:05:45.546432  9023 solver.cpp:222] Iteration 148120 (1.2887 iter/s, 31.0391s/40 iters), loss = 1.20579
I1028 09:05:45.546646  9023 solver.cpp:241]     Train net output #0: loss = 1.20579 (* 1 = 1.20579 loss)
I1028 09:05:45.546664  9023 sgd_solver.cpp:105] Iteration 148120, lr = 0.000854118
I1028 09:06:17.544906  9023 solver.cpp:222] Iteration 148160 (1.25011 iter/s, 31.9971s/40 iters), loss = 1.77996
I1028 09:06:17.545096  9023 solver.cpp:241]     Train net output #0: loss = 1.77996 (* 1 = 1.77996 loss)
I1028 09:06:17.545112  9023 sgd_solver.cpp:105] Iteration 148160, lr = 0.000852245
I1028 09:06:48.614902  9023 solver.cpp:222] Iteration 148200 (1.28747 iter/s, 31.0686s/40 iters), loss = 1.571
I1028 09:06:48.615072  9023 solver.cpp:241]     Train net output #0: loss = 1.571 (* 1 = 1.571 loss)
I1028 09:06:48.615576  9023 sgd_solver.cpp:105] Iteration 148200, lr = 0.000850372
I1028 09:07:19.423213  9023 solver.cpp:222] Iteration 148240 (1.29841 iter/s, 30.807s/40 iters), loss = 1.79382
I1028 09:07:19.423390  9023 solver.cpp:241]     Train net output #0: loss = 1.79382 (* 1 = 1.79382 loss)
I1028 09:07:19.423406  9023 sgd_solver.cpp:105] Iteration 148240, lr = 0.0008485
I1028 09:07:50.591855  9023 solver.cpp:222] Iteration 148280 (1.2834 iter/s, 31.1673s/40 iters), loss = 1.76978
I1028 09:07:50.592033  9023 solver.cpp:241]     Train net output #0: loss = 1.76978 (* 1 = 1.76978 loss)
I1028 09:07:50.592051  9023 sgd_solver.cpp:105] Iteration 148280, lr = 0.000846629
I1028 09:08:21.731104  9023 solver.cpp:222] Iteration 148320 (1.28461 iter/s, 31.1379s/40 iters), loss = 1.35877
I1028 09:08:21.731287  9023 solver.cpp:241]     Train net output #0: loss = 1.35877 (* 1 = 1.35877 loss)
I1028 09:08:21.731307  9023 sgd_solver.cpp:105] Iteration 148320, lr = 0.000844758
I1028 09:08:52.825976  9023 solver.cpp:222] Iteration 148360 (1.28644 iter/s, 31.0935s/40 iters), loss = 1.54677
I1028 09:08:52.826164  9023 solver.cpp:241]     Train net output #0: loss = 1.54677 (* 1 = 1.54677 loss)
I1028 09:08:52.826180  9023 sgd_solver.cpp:105] Iteration 148360, lr = 0.000842888
I1028 09:09:26.336345  9023 solver.cpp:222] Iteration 148400 (1.19371 iter/s, 33.5089s/40 iters), loss = 1.35176
I1028 09:09:26.336522  9023 solver.cpp:241]     Train net output #0: loss = 1.35176 (* 1 = 1.35176 loss)
I1028 09:09:26.336630  9023 sgd_solver.cpp:105] Iteration 148400, lr = 0.000841019
I1028 09:09:57.237285  9023 solver.cpp:222] Iteration 148440 (1.29452 iter/s, 30.8996s/40 iters), loss = 1.46671
I1028 09:09:57.237480  9023 solver.cpp:241]     Train net output #0: loss = 1.46671 (* 1 = 1.46671 loss)
I1028 09:09:57.237525  9023 sgd_solver.cpp:105] Iteration 148440, lr = 0.00083915
I1028 09:10:28.538753  9023 solver.cpp:222] Iteration 148480 (1.27795 iter/s, 31.3001s/40 iters), loss = 1.70294
I1028 09:10:28.539016  9023 solver.cpp:241]     Train net output #0: loss = 1.70294 (* 1 = 1.70294 loss)
I1028 09:10:28.539055  9023 sgd_solver.cpp:105] Iteration 148480, lr = 0.000837282
I1028 09:10:43.412725  9023 solver.cpp:334] Iteration 148500, Testing net (#0)
I1028 09:11:14.853826  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58036
I1028 09:11:14.854035  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80468
I1028 09:11:14.854053  9023 solver.cpp:401]     Test net output #2: loss = 1.88853 (* 1 = 1.88853 loss)
I1028 09:11:31.072609  9023 solver.cpp:222] Iteration 148520 (0.63968 iter/s, 62.5313s/40 iters), loss = 1.78401
I1028 09:11:31.072677  9023 solver.cpp:241]     Train net output #0: loss = 1.78401 (* 1 = 1.78401 loss)
I1028 09:11:31.072698  9023 sgd_solver.cpp:105] Iteration 148520, lr = 0.000835415
I1028 09:12:02.127696  9023 solver.cpp:222] Iteration 148560 (1.28809 iter/s, 31.0538s/40 iters), loss = 1.24345
I1028 09:12:02.127949  9023 solver.cpp:241]     Train net output #0: loss = 1.24345 (* 1 = 1.24345 loss)
I1028 09:12:02.127975  9023 sgd_solver.cpp:105] Iteration 148560, lr = 0.000833549
I1028 09:12:33.073563  9023 solver.cpp:222] Iteration 148600 (1.29264 iter/s, 30.9444s/40 iters), loss = 1.53494
I1028 09:12:33.073752  9023 solver.cpp:241]     Train net output #0: loss = 1.53494 (* 1 = 1.53494 loss)
I1028 09:12:33.073768  9023 sgd_solver.cpp:105] Iteration 148600, lr = 0.000831683
I1028 09:13:03.740283  9023 solver.cpp:222] Iteration 148640 (1.3044 iter/s, 30.6654s/40 iters), loss = 1.34359
I1028 09:13:03.740448  9023 solver.cpp:241]     Train net output #0: loss = 1.34359 (* 1 = 1.34359 loss)
I1028 09:13:03.740465  9023 sgd_solver.cpp:105] Iteration 148640, lr = 0.000829818
I1028 09:13:34.538758  9023 solver.cpp:222] Iteration 148680 (1.29882 iter/s, 30.7971s/40 iters), loss = 1.36805
I1028 09:13:34.538933  9023 solver.cpp:241]     Train net output #0: loss = 1.36805 (* 1 = 1.36805 loss)
I1028 09:13:34.538950  9023 sgd_solver.cpp:105] Iteration 148680, lr = 0.000827953
I1028 09:14:05.534054  9023 solver.cpp:222] Iteration 148720 (1.29057 iter/s, 30.9939s/40 iters), loss = 1.44591
I1028 09:14:05.534282  9023 solver.cpp:241]     Train net output #0: loss = 1.44591 (* 1 = 1.44591 loss)
I1028 09:14:05.534313  9023 sgd_solver.cpp:105] Iteration 148720, lr = 0.00082609
I1028 09:14:36.424108  9023 solver.cpp:222] Iteration 148760 (1.29497 iter/s, 30.8887s/40 iters), loss = 1.47397
I1028 09:14:36.424329  9023 solver.cpp:241]     Train net output #0: loss = 1.47397 (* 1 = 1.47397 loss)
I1028 09:14:36.424347  9023 sgd_solver.cpp:105] Iteration 148760, lr = 0.000824227
I1028 09:15:07.804666  9023 solver.cpp:222] Iteration 148800 (1.27473 iter/s, 31.3792s/40 iters), loss = 1.56374
I1028 09:15:07.804855  9023 solver.cpp:241]     Train net output #0: loss = 1.56374 (* 1 = 1.56374 loss)
I1028 09:15:07.804872  9023 sgd_solver.cpp:105] Iteration 148800, lr = 0.000822365
I1028 09:15:38.949398  9023 solver.cpp:222] Iteration 148840 (1.28438 iter/s, 31.1434s/40 iters), loss = 1.43065
I1028 09:15:38.949592  9023 solver.cpp:241]     Train net output #0: loss = 1.43065 (* 1 = 1.43065 loss)
I1028 09:15:38.949610  9023 sgd_solver.cpp:105] Iteration 148840, lr = 0.000820503
I1028 09:16:09.763386  9023 solver.cpp:222] Iteration 148880 (1.29817 iter/s, 30.8126s/40 iters), loss = 1.39477
I1028 09:16:09.763573  9023 solver.cpp:241]     Train net output #0: loss = 1.39477 (* 1 = 1.39477 loss)
I1028 09:16:09.763588  9023 sgd_solver.cpp:105] Iteration 148880, lr = 0.000818642
I1028 09:16:40.666715  9023 solver.cpp:222] Iteration 148920 (1.29442 iter/s, 30.902s/40 iters), loss = 1.28266
I1028 09:16:40.666906  9023 solver.cpp:241]     Train net output #0: loss = 1.28266 (* 1 = 1.28266 loss)
I1028 09:16:40.666923  9023 sgd_solver.cpp:105] Iteration 148920, lr = 0.000816782
I1028 09:17:12.591969  9023 solver.cpp:222] Iteration 148960 (1.25298 iter/s, 31.9239s/40 iters), loss = 1.5292
I1028 09:17:12.592217  9023 solver.cpp:241]     Train net output #0: loss = 1.5292 (* 1 = 1.5292 loss)
I1028 09:17:12.592238  9023 sgd_solver.cpp:105] Iteration 148960, lr = 0.000814922
I1028 09:17:43.308686  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_149000.caffemodel
I1028 09:17:43.339723  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_149000.solverstate
I1028 09:17:43.356171  9023 solver.cpp:334] Iteration 149000, Testing net (#0)
I1028 09:18:14.574085  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 09:18:14.783815  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57676
I1028 09:18:14.783884  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.809599
I1028 09:18:14.783896  9023 solver.cpp:401]     Test net output #2: loss = 1.86157 (* 1 = 1.86157 loss)
I1028 09:18:15.556872  9023 solver.cpp:222] Iteration 149000 (0.635301 iter/s, 62.9623s/40 iters), loss = 1.33087
I1028 09:18:15.556941  9023 solver.cpp:241]     Train net output #0: loss = 1.33087 (* 1 = 1.33087 loss)
I1028 09:18:15.556957  9023 sgd_solver.cpp:105] Iteration 149000, lr = 0.000813064
I1028 09:19:03.118409  9023 solver.cpp:222] Iteration 149040 (0.841049 iter/s, 47.5597s/40 iters), loss = 1.44041
I1028 09:19:03.118638  9023 solver.cpp:241]     Train net output #0: loss = 1.44041 (* 1 = 1.44041 loss)
I1028 09:19:03.118662  9023 sgd_solver.cpp:105] Iteration 149040, lr = 0.000811205
I1028 09:19:34.748607  9023 solver.cpp:222] Iteration 149080 (1.26467 iter/s, 31.6288s/40 iters), loss = 1.73368
I1028 09:19:34.748792  9023 solver.cpp:241]     Train net output #0: loss = 1.73368 (* 1 = 1.73368 loss)
I1028 09:19:34.748809  9023 sgd_solver.cpp:105] Iteration 149080, lr = 0.000809348
I1028 09:20:05.928593  9023 solver.cpp:222] Iteration 149120 (1.28293 iter/s, 31.1786s/40 iters), loss = 1.4976
I1028 09:20:05.928822  9023 solver.cpp:241]     Train net output #0: loss = 1.4976 (* 1 = 1.4976 loss)
I1028 09:20:05.928845  9023 sgd_solver.cpp:105] Iteration 149120, lr = 0.000807491
I1028 09:20:37.591598  9023 solver.cpp:222] Iteration 149160 (1.26336 iter/s, 31.6616s/40 iters), loss = 1.5871
I1028 09:20:37.591804  9023 solver.cpp:241]     Train net output #0: loss = 1.5871 (* 1 = 1.5871 loss)
I1028 09:20:37.591820  9023 sgd_solver.cpp:105] Iteration 149160, lr = 0.000805635
I1028 09:21:08.726933  9023 solver.cpp:222] Iteration 149200 (1.28477 iter/s, 31.134s/40 iters), loss = 1.38529
I1028 09:21:08.727129  9023 solver.cpp:241]     Train net output #0: loss = 1.38529 (* 1 = 1.38529 loss)
I1028 09:21:08.727149  9023 sgd_solver.cpp:105] Iteration 149200, lr = 0.00080378
I1028 09:21:39.596793  9023 solver.cpp:222] Iteration 149240 (1.29582 iter/s, 30.8685s/40 iters), loss = 1.33357
I1028 09:21:39.596963  9023 solver.cpp:241]     Train net output #0: loss = 1.33357 (* 1 = 1.33357 loss)
I1028 09:21:39.596979  9023 sgd_solver.cpp:105] Iteration 149240, lr = 0.000801925
I1028 09:22:10.572960  9023 solver.cpp:222] Iteration 149280 (1.29137 iter/s, 30.9748s/40 iters), loss = 1.78601
I1028 09:22:10.573143  9023 solver.cpp:241]     Train net output #0: loss = 1.78601 (* 1 = 1.78601 loss)
I1028 09:22:10.573160  9023 sgd_solver.cpp:105] Iteration 149280, lr = 0.000800072
I1028 09:22:41.445797  9023 solver.cpp:222] Iteration 149320 (1.29569 iter/s, 30.8715s/40 iters), loss = 1.35668
I1028 09:22:41.446007  9023 solver.cpp:241]     Train net output #0: loss = 1.35668 (* 1 = 1.35668 loss)
I1028 09:22:41.446024  9023 sgd_solver.cpp:105] Iteration 149320, lr = 0.000798219
I1028 09:23:12.122256  9023 solver.cpp:222] Iteration 149360 (1.30399 iter/s, 30.6751s/40 iters), loss = 1.37187
I1028 09:23:12.122442  9023 solver.cpp:241]     Train net output #0: loss = 1.37187 (* 1 = 1.37187 loss)
I1028 09:23:12.122460  9023 sgd_solver.cpp:105] Iteration 149360, lr = 0.000796366
I1028 09:23:42.920928  9023 solver.cpp:222] Iteration 149400 (1.29881 iter/s, 30.7973s/40 iters), loss = 1.39228
I1028 09:23:42.921190  9023 solver.cpp:241]     Train net output #0: loss = 1.39228 (* 1 = 1.39228 loss)
I1028 09:23:42.921211  9023 sgd_solver.cpp:105] Iteration 149400, lr = 0.000794515
I1028 09:24:13.956671  9023 solver.cpp:222] Iteration 149440 (1.2889 iter/s, 31.0343s/40 iters), loss = 1.50677
I1028 09:24:13.956871  9023 solver.cpp:241]     Train net output #0: loss = 1.50677 (* 1 = 1.50677 loss)
I1028 09:24:13.956887  9023 sgd_solver.cpp:105] Iteration 149440, lr = 0.000792664
I1028 09:24:44.995689  9023 solver.cpp:222] Iteration 149480 (1.28876 iter/s, 31.0376s/40 iters), loss = 1.56958
I1028 09:24:44.995924  9023 solver.cpp:241]     Train net output #0: loss = 1.56958 (* 1 = 1.56958 loss)
I1028 09:24:44.995949  9023 sgd_solver.cpp:105] Iteration 149480, lr = 0.000790814
I1028 09:24:59.896183  9023 solver.cpp:334] Iteration 149500, Testing net (#0)
I1028 09:25:31.443786  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58076
I1028 09:25:31.443992  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.807519
I1028 09:25:31.444013  9023 solver.cpp:401]     Test net output #2: loss = 1.84593 (* 1 = 1.84593 loss)
I1028 09:25:47.878173  9023 solver.cpp:222] Iteration 149520 (0.636133 iter/s, 62.8799s/40 iters), loss = 1.31282
I1028 09:25:47.878250  9023 solver.cpp:241]     Train net output #0: loss = 1.31282 (* 1 = 1.31282 loss)
I1028 09:25:47.878267  9023 sgd_solver.cpp:105] Iteration 149520, lr = 0.000788964
I1028 09:26:18.833351  9023 solver.cpp:222] Iteration 149560 (1.29224 iter/s, 30.9539s/40 iters), loss = 1.46005
I1028 09:26:18.833559  9023 solver.cpp:241]     Train net output #0: loss = 1.46005 (* 1 = 1.46005 loss)
I1028 09:26:18.833580  9023 sgd_solver.cpp:105] Iteration 149560, lr = 0.000787115
I1028 09:26:29.009698  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1028 09:26:51.459410  9023 solver.cpp:222] Iteration 149600 (1.22607 iter/s, 32.6246s/40 iters), loss = 1.55468
I1028 09:26:51.459647  9023 solver.cpp:241]     Train net output #0: loss = 1.55468 (* 1 = 1.55468 loss)
I1028 09:26:51.459673  9023 sgd_solver.cpp:105] Iteration 149600, lr = 0.000785267
I1028 09:27:24.384969  9023 solver.cpp:222] Iteration 149640 (1.21492 iter/s, 32.9241s/40 iters), loss = 1.37387
I1028 09:27:24.385152  9023 solver.cpp:241]     Train net output #0: loss = 1.37387 (* 1 = 1.37387 loss)
I1028 09:27:24.385169  9023 sgd_solver.cpp:105] Iteration 149640, lr = 0.00078342
I1028 09:27:56.066951  9023 solver.cpp:222] Iteration 149680 (1.2626 iter/s, 31.6806s/40 iters), loss = 1.78636
I1028 09:27:56.067194  9023 solver.cpp:241]     Train net output #0: loss = 1.78636 (* 1 = 1.78636 loss)
I1028 09:27:56.067221  9023 sgd_solver.cpp:105] Iteration 149680, lr = 0.000781573
I1028 09:28:28.172286  9023 solver.cpp:222] Iteration 149720 (1.24596 iter/s, 32.1039s/40 iters), loss = 1.29152
I1028 09:28:28.172507  9023 solver.cpp:241]     Train net output #0: loss = 1.29152 (* 1 = 1.29152 loss)
I1028 09:28:28.172524  9023 sgd_solver.cpp:105] Iteration 149720, lr = 0.000779727
I1028 09:28:59.250026  9023 solver.cpp:222] Iteration 149760 (1.28715 iter/s, 31.0763s/40 iters), loss = 1.58423
I1028 09:28:59.250195  9023 solver.cpp:241]     Train net output #0: loss = 1.58423 (* 1 = 1.58423 loss)
I1028 09:28:59.250211  9023 sgd_solver.cpp:105] Iteration 149760, lr = 0.000777882
I1028 09:29:30.526159  9023 solver.cpp:222] Iteration 149800 (1.27899 iter/s, 31.2748s/40 iters), loss = 1.30103
I1028 09:29:30.526343  9023 solver.cpp:241]     Train net output #0: loss = 1.30103 (* 1 = 1.30103 loss)
I1028 09:29:30.526360  9023 sgd_solver.cpp:105] Iteration 149800, lr = 0.000776038
I1028 09:30:01.231516  9023 solver.cpp:222] Iteration 149840 (1.30276 iter/s, 30.704s/40 iters), loss = 1.16998
I1028 09:30:01.231678  9023 solver.cpp:241]     Train net output #0: loss = 1.16998 (* 1 = 1.16998 loss)
I1028 09:30:01.231695  9023 sgd_solver.cpp:105] Iteration 149840, lr = 0.000774194
I1028 09:30:32.314014  9023 solver.cpp:222] Iteration 149880 (1.28695 iter/s, 31.0812s/40 iters), loss = 1.38031
I1028 09:30:32.314271  9023 solver.cpp:241]     Train net output #0: loss = 1.38031 (* 1 = 1.38031 loss)
I1028 09:30:32.314290  9023 sgd_solver.cpp:105] Iteration 149880, lr = 0.000772351
I1028 09:31:03.406774  9023 solver.cpp:222] Iteration 149920 (1.28653 iter/s, 31.0913s/40 iters), loss = 1.3144
I1028 09:31:03.406977  9023 solver.cpp:241]     Train net output #0: loss = 1.3144 (* 1 = 1.3144 loss)
I1028 09:31:03.406993  9023 sgd_solver.cpp:105] Iteration 149920, lr = 0.000770509
I1028 09:31:34.558244  9023 solver.cpp:222] Iteration 149960 (1.28411 iter/s, 31.1501s/40 iters), loss = 1.68206
I1028 09:31:34.558431  9023 solver.cpp:241]     Train net output #0: loss = 1.68206 (* 1 = 1.68206 loss)
I1028 09:31:34.558449  9023 sgd_solver.cpp:105] Iteration 149960, lr = 0.000768668
I1028 09:32:04.699627  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_150000.caffemodel
I1028 09:32:04.732626  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_150000.solverstate
I1028 09:32:04.755134  9023 solver.cpp:334] Iteration 150000, Testing net (#0)
I1028 09:32:36.105576  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 09:32:36.314054  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57932
I1028 09:32:36.314126  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80972
I1028 09:32:36.314141  9023 solver.cpp:401]     Test net output #2: loss = 1.86148 (* 1 = 1.86148 loss)
I1028 09:32:37.082435  9023 solver.cpp:222] Iteration 150000 (0.639778 iter/s, 62.5217s/40 iters), loss = 1.55536
I1028 09:32:37.082499  9023 solver.cpp:241]     Train net output #0: loss = 1.55536 (* 1 = 1.55536 loss)
I1028 09:32:37.082515  9023 sgd_solver.cpp:105] Iteration 150000, lr = 0.000766827
I1028 09:33:07.914587  9023 solver.cpp:222] Iteration 150040 (1.2974 iter/s, 30.8309s/40 iters), loss = 1.51501
I1028 09:33:07.914774  9023 solver.cpp:241]     Train net output #0: loss = 1.51501 (* 1 = 1.51501 loss)
I1028 09:33:07.914790  9023 sgd_solver.cpp:105] Iteration 150040, lr = 0.000764987
I1028 09:33:38.625104  9023 solver.cpp:222] Iteration 150080 (1.30254 iter/s, 30.7092s/40 iters), loss = 1.4355
I1028 09:33:38.625289  9023 solver.cpp:241]     Train net output #0: loss = 1.4355 (* 1 = 1.4355 loss)
I1028 09:33:38.625310  9023 sgd_solver.cpp:105] Iteration 150080, lr = 0.000763147
I1028 09:34:08.970158  9023 solver.cpp:222] Iteration 150120 (1.31823 iter/s, 30.3437s/40 iters), loss = 1.21487
I1028 09:34:08.970398  9023 solver.cpp:241]     Train net output #0: loss = 1.21487 (* 1 = 1.21487 loss)
I1028 09:34:08.970417  9023 sgd_solver.cpp:105] Iteration 150120, lr = 0.000761309
I1028 09:34:40.701293  9023 solver.cpp:222] Iteration 150160 (1.26065 iter/s, 31.7297s/40 iters), loss = 1.4409
I1028 09:34:40.701512  9023 solver.cpp:241]     Train net output #0: loss = 1.4409 (* 1 = 1.4409 loss)
I1028 09:34:40.701531  9023 sgd_solver.cpp:105] Iteration 150160, lr = 0.000759471
I1028 09:35:10.937193  9023 solver.cpp:222] Iteration 150200 (1.32299 iter/s, 30.2345s/40 iters), loss = 1.47198
I1028 09:35:10.937381  9023 solver.cpp:241]     Train net output #0: loss = 1.47198 (* 1 = 1.47198 loss)
I1028 09:35:10.937397  9023 sgd_solver.cpp:105] Iteration 150200, lr = 0.000757634
I1028 09:35:41.839717  9023 solver.cpp:222] Iteration 150240 (1.29445 iter/s, 30.9012s/40 iters), loss = 1.3494
I1028 09:35:41.839926  9023 solver.cpp:241]     Train net output #0: loss = 1.3494 (* 1 = 1.3494 loss)
I1028 09:35:41.839946  9023 sgd_solver.cpp:105] Iteration 150240, lr = 0.000755798
I1028 09:36:12.234354  9023 solver.cpp:222] Iteration 150280 (1.31608 iter/s, 30.3933s/40 iters), loss = 1.68833
I1028 09:36:12.234531  9023 solver.cpp:241]     Train net output #0: loss = 1.68833 (* 1 = 1.68833 loss)
I1028 09:36:12.234549  9023 sgd_solver.cpp:105] Iteration 150280, lr = 0.000753962
I1028 09:36:43.174669  9023 solver.cpp:222] Iteration 150320 (1.29287 iter/s, 30.939s/40 iters), loss = 1.20931
I1028 09:36:43.174950  9023 solver.cpp:241]     Train net output #0: loss = 1.20931 (* 1 = 1.20931 loss)
I1028 09:36:43.174986  9023 sgd_solver.cpp:105] Iteration 150320, lr = 0.000752127
I1028 09:37:14.128942  9023 solver.cpp:222] Iteration 150360 (1.29229 iter/s, 30.9528s/40 iters), loss = 1.2931
I1028 09:37:14.129153  9023 solver.cpp:241]     Train net output #0: loss = 1.2931 (* 1 = 1.2931 loss)
I1028 09:37:14.129169  9023 sgd_solver.cpp:105] Iteration 150360, lr = 0.000750293
I1028 09:37:44.937310  9023 solver.cpp:222] Iteration 150400 (1.29841 iter/s, 30.807s/40 iters), loss = 1.31944
I1028 09:37:44.937484  9023 solver.cpp:241]     Train net output #0: loss = 1.31944 (* 1 = 1.31944 loss)
I1028 09:37:44.937500  9023 sgd_solver.cpp:105] Iteration 150400, lr = 0.00074846
I1028 09:38:17.828385  9023 solver.cpp:222] Iteration 150440 (1.21619 iter/s, 32.8897s/40 iters), loss = 1.27669
I1028 09:38:17.828611  9023 solver.cpp:241]     Train net output #0: loss = 1.27669 (* 1 = 1.27669 loss)
I1028 09:38:17.828637  9023 sgd_solver.cpp:105] Iteration 150440, lr = 0.000746627
I1028 09:38:49.068972  9023 solver.cpp:222] Iteration 150480 (1.28044 iter/s, 31.2392s/40 iters), loss = 1.3767
I1028 09:38:49.069159  9023 solver.cpp:241]     Train net output #0: loss = 1.3767 (* 1 = 1.3767 loss)
I1028 09:38:49.069175  9023 sgd_solver.cpp:105] Iteration 150480, lr = 0.000744795
I1028 09:39:03.931134  9023 solver.cpp:334] Iteration 150500, Testing net (#0)
I1028 09:39:35.344089  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58068
I1028 09:39:35.344276  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8066
I1028 09:39:35.344292  9023 solver.cpp:401]     Test net output #2: loss = 1.85089 (* 1 = 1.85089 loss)
I1028 09:39:51.461402  9023 solver.cpp:222] Iteration 150520 (0.641129 iter/s, 62.3899s/40 iters), loss = 1.57684
I1028 09:39:51.461472  9023 solver.cpp:241]     Train net output #0: loss = 1.57684 (* 1 = 1.57684 loss)
I1028 09:39:51.461488  9023 sgd_solver.cpp:105] Iteration 150520, lr = 0.000742965
I1028 09:40:22.507076  9023 solver.cpp:222] Iteration 150560 (1.28848 iter/s, 31.0444s/40 iters), loss = 1.29586
I1028 09:40:22.507266  9023 solver.cpp:241]     Train net output #0: loss = 1.29586 (* 1 = 1.29586 loss)
I1028 09:40:22.507283  9023 sgd_solver.cpp:105] Iteration 150560, lr = 0.000741134
I1028 09:40:53.510735  9023 solver.cpp:222] Iteration 150600 (1.29023 iter/s, 31.0023s/40 iters), loss = 1.68936
I1028 09:40:53.510917  9023 solver.cpp:241]     Train net output #0: loss = 1.68936 (* 1 = 1.68936 loss)
I1028 09:40:53.510936  9023 sgd_solver.cpp:105] Iteration 150600, lr = 0.000739304
I1028 09:41:24.607025  9023 solver.cpp:222] Iteration 150640 (1.28638 iter/s, 31.0949s/40 iters), loss = 1.34433
I1028 09:41:24.607236  9023 solver.cpp:241]     Train net output #0: loss = 1.34433 (* 1 = 1.34433 loss)
I1028 09:41:24.607254  9023 sgd_solver.cpp:105] Iteration 150640, lr = 0.000737476
I1028 09:41:55.784435  9023 solver.cpp:222] Iteration 150680 (1.28304 iter/s, 31.176s/40 iters), loss = 1.1548
I1028 09:41:55.784632  9023 solver.cpp:241]     Train net output #0: loss = 1.1548 (* 1 = 1.1548 loss)
I1028 09:41:55.784649  9023 sgd_solver.cpp:105] Iteration 150680, lr = 0.000735647
I1028 09:42:26.842232  9023 solver.cpp:222] Iteration 150720 (1.28798 iter/s, 31.0564s/40 iters), loss = 1.276
I1028 09:42:26.842404  9023 solver.cpp:241]     Train net output #0: loss = 1.276 (* 1 = 1.276 loss)
I1028 09:42:26.842851  9023 sgd_solver.cpp:105] Iteration 150720, lr = 0.00073382
I1028 09:42:58.140681  9023 solver.cpp:222] Iteration 150760 (1.27807 iter/s, 31.2971s/40 iters), loss = 1.39288
I1028 09:42:58.140857  9023 solver.cpp:241]     Train net output #0: loss = 1.39288 (* 1 = 1.39288 loss)
I1028 09:42:58.140873  9023 sgd_solver.cpp:105] Iteration 150760, lr = 0.000731994
I1028 09:43:29.101653  9023 solver.cpp:222] Iteration 150800 (1.29201 iter/s, 30.9596s/40 iters), loss = 1.42441
I1028 09:43:29.101824  9023 solver.cpp:241]     Train net output #0: loss = 1.42441 (* 1 = 1.42441 loss)
I1028 09:43:29.101855  9023 sgd_solver.cpp:105] Iteration 150800, lr = 0.000730168
I1028 09:44:00.538076  9023 solver.cpp:222] Iteration 150840 (1.27246 iter/s, 31.4351s/40 iters), loss = 1.64505
I1028 09:44:00.538370  9023 solver.cpp:241]     Train net output #0: loss = 1.64505 (* 1 = 1.64505 loss)
I1028 09:44:00.538400  9023 sgd_solver.cpp:105] Iteration 150840, lr = 0.000728343
I1028 09:44:34.080373  9023 solver.cpp:222] Iteration 150880 (1.19258 iter/s, 33.5407s/40 iters), loss = 1.30934
I1028 09:44:34.080580  9023 solver.cpp:241]     Train net output #0: loss = 1.30934 (* 1 = 1.30934 loss)
I1028 09:44:34.080605  9023 sgd_solver.cpp:105] Iteration 150880, lr = 0.000726518
I1028 09:45:05.218713  9023 solver.cpp:222] Iteration 150920 (1.28465 iter/s, 31.137s/40 iters), loss = 1.11935
I1028 09:45:05.218886  9023 solver.cpp:241]     Train net output #0: loss = 1.11935 (* 1 = 1.11935 loss)
I1028 09:45:05.218904  9023 sgd_solver.cpp:105] Iteration 150920, lr = 0.000724695
I1028 09:45:37.473141  9023 solver.cpp:222] Iteration 150960 (1.24019 iter/s, 32.253s/40 iters), loss = 1.29543
I1028 09:45:37.473331  9023 solver.cpp:241]     Train net output #0: loss = 1.29543 (* 1 = 1.29543 loss)
I1028 09:45:37.473351  9023 sgd_solver.cpp:105] Iteration 150960, lr = 0.000722872
I1028 09:46:07.894124  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_151000.caffemodel
I1028 09:46:07.926903  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_151000.solverstate
I1028 09:46:07.948421  9023 solver.cpp:334] Iteration 151000, Testing net (#0)
I1028 09:46:39.034446  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 09:46:39.247135  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5792
I1028 09:46:39.247200  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81104
I1028 09:46:39.247217  9023 solver.cpp:401]     Test net output #2: loss = 1.85319 (* 1 = 1.85319 loss)
I1028 09:46:40.021991  9023 solver.cpp:222] Iteration 151000 (0.639526 iter/s, 62.5463s/40 iters), loss = 1.30011
I1028 09:46:40.022059  9023 solver.cpp:241]     Train net output #0: loss = 1.30011 (* 1 = 1.30011 loss)
I1028 09:46:40.022075  9023 sgd_solver.cpp:105] Iteration 151000, lr = 0.00072105
I1028 09:47:10.760462  9023 solver.cpp:222] Iteration 151040 (1.30135 iter/s, 30.7372s/40 iters), loss = 1.59166
I1028 09:47:10.760664  9023 solver.cpp:241]     Train net output #0: loss = 1.59166 (* 1 = 1.59166 loss)
I1028 09:47:10.760684  9023 sgd_solver.cpp:105] Iteration 151040, lr = 0.000719229
I1028 09:47:41.744212  9023 solver.cpp:222] Iteration 151080 (1.29106 iter/s, 30.9824s/40 iters), loss = 1.37376
I1028 09:47:41.744526  9023 solver.cpp:241]     Train net output #0: loss = 1.37376 (* 1 = 1.37376 loss)
I1028 09:47:41.744545  9023 sgd_solver.cpp:105] Iteration 151080, lr = 0.000717408
I1028 09:48:13.020236  9023 solver.cpp:222] Iteration 151120 (1.279 iter/s, 31.2745s/40 iters), loss = 1.71046
I1028 09:48:13.020416  9023 solver.cpp:241]     Train net output #0: loss = 1.71046 (* 1 = 1.71046 loss)
I1028 09:48:13.020432  9023 sgd_solver.cpp:105] Iteration 151120, lr = 0.000715589
I1028 09:48:44.062125  9023 solver.cpp:222] Iteration 151160 (1.28864 iter/s, 31.0405s/40 iters), loss = 1.40376
I1028 09:48:44.062309  9023 solver.cpp:241]     Train net output #0: loss = 1.40376 (* 1 = 1.40376 loss)
I1028 09:48:44.062326  9023 sgd_solver.cpp:105] Iteration 151160, lr = 0.00071377
I1028 09:49:15.282521  9023 solver.cpp:222] Iteration 151200 (1.28127 iter/s, 31.219s/40 iters), loss = 1.55026
I1028 09:49:15.282688  9023 solver.cpp:241]     Train net output #0: loss = 1.55026 (* 1 = 1.55026 loss)
I1028 09:49:15.282706  9023 sgd_solver.cpp:105] Iteration 151200, lr = 0.000711952
I1028 09:49:54.596407  9023 solver.cpp:222] Iteration 151240 (1.01749 iter/s, 39.3122s/40 iters), loss = 1.13494
I1028 09:49:54.596599  9023 solver.cpp:241]     Train net output #0: loss = 1.13494 (* 1 = 1.13494 loss)
I1028 09:49:54.596627  9023 sgd_solver.cpp:105] Iteration 151240, lr = 0.000710135
I1028 09:50:26.100900  9023 solver.cpp:222] Iteration 151280 (1.26972 iter/s, 31.5031s/40 iters), loss = 1.19425
I1028 09:50:26.101179  9023 solver.cpp:241]     Train net output #0: loss = 1.19425 (* 1 = 1.19425 loss)
I1028 09:50:26.101210  9023 sgd_solver.cpp:105] Iteration 151280, lr = 0.000708318
I1028 09:50:58.155889  9023 solver.cpp:222] Iteration 151320 (1.24791 iter/s, 32.0535s/40 iters), loss = 1.5639
I1028 09:50:58.156045  9023 solver.cpp:241]     Train net output #0: loss = 1.5639 (* 1 = 1.5639 loss)
I1028 09:50:58.156066  9023 sgd_solver.cpp:105] Iteration 151320, lr = 0.000706502
I1028 09:51:36.803555  9023 solver.cpp:222] Iteration 151360 (1.03503 iter/s, 38.6461s/40 iters), loss = 1.84335
I1028 09:51:36.803756  9023 solver.cpp:241]     Train net output #0: loss = 1.84335 (* 1 = 1.84335 loss)
I1028 09:51:36.803774  9023 sgd_solver.cpp:105] Iteration 151360, lr = 0.000704687
I1028 09:52:07.833230  9023 solver.cpp:222] Iteration 151400 (1.28915 iter/s, 31.0283s/40 iters), loss = 1.29933
I1028 09:52:07.833408  9023 solver.cpp:241]     Train net output #0: loss = 1.29933 (* 1 = 1.29933 loss)
I1028 09:52:07.833425  9023 sgd_solver.cpp:105] Iteration 151400, lr = 0.000702873
I1028 09:52:38.892022  9023 solver.cpp:222] Iteration 151440 (1.28794 iter/s, 31.0574s/40 iters), loss = 1.30269
I1028 09:52:38.892231  9023 solver.cpp:241]     Train net output #0: loss = 1.30269 (* 1 = 1.30269 loss)
I1028 09:52:38.892254  9023 sgd_solver.cpp:105] Iteration 151440, lr = 0.000701059
I1028 09:53:10.549186  9023 solver.cpp:222] Iteration 151480 (1.26359 iter/s, 31.6558s/40 iters), loss = 1.2771
I1028 09:53:10.549374  9023 solver.cpp:241]     Train net output #0: loss = 1.2771 (* 1 = 1.2771 loss)
I1028 09:53:10.549391  9023 sgd_solver.cpp:105] Iteration 151480, lr = 0.000699247
I1028 09:53:25.227886  9023 solver.cpp:334] Iteration 151500, Testing net (#0)
I1028 09:53:56.681150  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5828
I1028 09:53:56.681337  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.806199
I1028 09:53:56.681354  9023 solver.cpp:401]     Test net output #2: loss = 1.84777 (* 1 = 1.84777 loss)
I1028 09:54:13.101150  9023 solver.cpp:222] Iteration 151520 (0.639494 iter/s, 62.5494s/40 iters), loss = 1.70717
I1028 09:54:13.101220  9023 solver.cpp:241]     Train net output #0: loss = 1.70717 (* 1 = 1.70717 loss)
I1028 09:54:13.101235  9023 sgd_solver.cpp:105] Iteration 151520, lr = 0.000697435
I1028 09:54:44.242928  9023 solver.cpp:222] Iteration 151560 (1.2845 iter/s, 31.1405s/40 iters), loss = 1.5871
I1028 09:54:44.243130  9023 solver.cpp:241]     Train net output #0: loss = 1.5871 (* 1 = 1.5871 loss)
I1028 09:54:44.243147  9023 sgd_solver.cpp:105] Iteration 151560, lr = 0.000695623
I1028 09:55:15.055552  9023 solver.cpp:222] Iteration 151600 (1.29823 iter/s, 30.8113s/40 iters), loss = 1.44408
I1028 09:55:15.055742  9023 solver.cpp:241]     Train net output #0: loss = 1.44408 (* 1 = 1.44408 loss)
I1028 09:55:15.055758  9023 sgd_solver.cpp:105] Iteration 151600, lr = 0.000693813
I1028 09:55:47.654486  9023 solver.cpp:222] Iteration 151640 (1.22709 iter/s, 32.5975s/40 iters), loss = 1.56098
I1028 09:55:47.654676  9023 solver.cpp:241]     Train net output #0: loss = 1.56098 (* 1 = 1.56098 loss)
I1028 09:55:47.654693  9023 sgd_solver.cpp:105] Iteration 151640, lr = 0.000692004
I1028 09:56:19.523948  9023 solver.cpp:222] Iteration 151680 (1.25517 iter/s, 31.8681s/40 iters), loss = 1.73153
I1028 09:56:19.524143  9023 solver.cpp:241]     Train net output #0: loss = 1.73153 (* 1 = 1.73153 loss)
I1028 09:56:19.524161  9023 sgd_solver.cpp:105] Iteration 151680, lr = 0.000690195
I1028 09:56:50.862869  9023 solver.cpp:222] Iteration 151720 (1.27642 iter/s, 31.3376s/40 iters), loss = 1.39803
I1028 09:56:50.863054  9023 solver.cpp:241]     Train net output #0: loss = 1.39803 (* 1 = 1.39803 loss)
I1028 09:56:50.863072  9023 sgd_solver.cpp:105] Iteration 151720, lr = 0.000688387
I1028 09:57:22.585265  9023 solver.cpp:222] Iteration 151760 (1.26099 iter/s, 31.721s/40 iters), loss = 1.37534
I1028 09:57:22.585561  9023 solver.cpp:241]     Train net output #0: loss = 1.37534 (* 1 = 1.37534 loss)
I1028 09:57:22.585584  9023 sgd_solver.cpp:105] Iteration 151760, lr = 0.00068658
I1028 09:57:53.873164  9023 solver.cpp:222] Iteration 151800 (1.27851 iter/s, 31.2864s/40 iters), loss = 1.3633
I1028 09:57:53.873348  9023 solver.cpp:241]     Train net output #0: loss = 1.3633 (* 1 = 1.3633 loss)
I1028 09:57:53.873365  9023 sgd_solver.cpp:105] Iteration 151800, lr = 0.000684773
I1028 09:58:24.869010  9023 solver.cpp:222] Iteration 151840 (1.29055 iter/s, 30.9945s/40 iters), loss = 1.41573
I1028 09:58:24.869194  9023 solver.cpp:241]     Train net output #0: loss = 1.41573 (* 1 = 1.41573 loss)
I1028 09:58:24.869217  9023 sgd_solver.cpp:105] Iteration 151840, lr = 0.000682968
I1028 09:58:56.115540  9023 solver.cpp:222] Iteration 151880 (1.2802 iter/s, 31.2452s/40 iters), loss = 1.47623
I1028 09:58:56.115718  9023 solver.cpp:241]     Train net output #0: loss = 1.47623 (* 1 = 1.47623 loss)
I1028 09:58:56.115736  9023 sgd_solver.cpp:105] Iteration 151880, lr = 0.000681163
I1028 09:59:27.501283  9023 solver.cpp:222] Iteration 151920 (1.27452 iter/s, 31.3844s/40 iters), loss = 1.38788
I1028 09:59:27.501468  9023 solver.cpp:241]     Train net output #0: loss = 1.38788 (* 1 = 1.38788 loss)
I1028 09:59:27.501485  9023 sgd_solver.cpp:105] Iteration 151920, lr = 0.000679359
I1028 09:59:58.552266  9023 solver.cpp:222] Iteration 151960 (1.28826 iter/s, 31.0496s/40 iters), loss = 1.76348
I1028 09:59:58.552456  9023 solver.cpp:241]     Train net output #0: loss = 1.76348 (* 1 = 1.76348 loss)
I1028 09:59:58.552477  9023 sgd_solver.cpp:105] Iteration 151960, lr = 0.000677556
I1028 10:00:28.894673  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_152000.caffemodel
I1028 10:00:28.929239  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_152000.solverstate
I1028 10:00:28.951719  9023 solver.cpp:334] Iteration 152000, Testing net (#0)
I1028 10:01:00.417632  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 10:01:00.626063  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58104
I1028 10:01:00.626123  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81068
I1028 10:01:00.626137  9023 solver.cpp:401]     Test net output #2: loss = 1.84467 (* 1 = 1.84467 loss)
I1028 10:01:01.395640  9023 solver.cpp:222] Iteration 152000 (0.636529 iter/s, 62.8408s/40 iters), loss = 0.979152
I1028 10:01:01.395704  9023 solver.cpp:241]     Train net output #0: loss = 0.979152 (* 1 = 0.979152 loss)
I1028 10:01:01.395720  9023 sgd_solver.cpp:105] Iteration 152000, lr = 0.000675753
I1028 10:01:32.193889  9023 solver.cpp:222] Iteration 152040 (1.29883 iter/s, 30.797s/40 iters), loss = 1.39208
I1028 10:01:32.194103  9023 solver.cpp:241]     Train net output #0: loss = 1.39208 (* 1 = 1.39208 loss)
I1028 10:01:32.194120  9023 sgd_solver.cpp:105] Iteration 152040, lr = 0.000673952
I1028 10:01:59.367753  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1028 10:02:03.135226  9023 solver.cpp:222] Iteration 152080 (1.29283 iter/s, 30.94s/40 iters), loss = 1.61997
I1028 10:02:03.135438  9023 solver.cpp:241]     Train net output #0: loss = 1.61997 (* 1 = 1.61997 loss)
I1028 10:02:03.135457  9023 sgd_solver.cpp:105] Iteration 152080, lr = 0.000672151
I1028 10:02:34.167863  9023 solver.cpp:222] Iteration 152120 (1.28902 iter/s, 31.0313s/40 iters), loss = 1.43409
I1028 10:02:34.168068  9023 solver.cpp:241]     Train net output #0: loss = 1.43409 (* 1 = 1.43409 loss)
I1028 10:02:34.168084  9023 sgd_solver.cpp:105] Iteration 152120, lr = 0.000670351
I1028 10:03:05.028507  9023 solver.cpp:222] Iteration 152160 (1.29621 iter/s, 30.8593s/40 iters), loss = 1.35966
I1028 10:03:05.028692  9023 solver.cpp:241]     Train net output #0: loss = 1.35966 (* 1 = 1.35966 loss)
I1028 10:03:05.028707  9023 sgd_solver.cpp:105] Iteration 152160, lr = 0.000668552
I1028 10:03:35.748617  9023 solver.cpp:222] Iteration 152200 (1.30214 iter/s, 30.7188s/40 iters), loss = 1.41221
I1028 10:03:35.748848  9023 solver.cpp:241]     Train net output #0: loss = 1.41221 (* 1 = 1.41221 loss)
I1028 10:03:35.748868  9023 sgd_solver.cpp:105] Iteration 152200, lr = 0.000666753
I1028 10:04:06.464635  9023 solver.cpp:222] Iteration 152240 (1.30231 iter/s, 30.7146s/40 iters), loss = 1.41384
I1028 10:04:06.464807  9023 solver.cpp:241]     Train net output #0: loss = 1.41384 (* 1 = 1.41384 loss)
I1028 10:04:06.464823  9023 sgd_solver.cpp:105] Iteration 152240, lr = 0.000664956
I1028 10:04:37.184512  9023 solver.cpp:222] Iteration 152280 (1.30214 iter/s, 30.7186s/40 iters), loss = 1.41484
I1028 10:04:37.184676  9023 solver.cpp:241]     Train net output #0: loss = 1.41484 (* 1 = 1.41484 loss)
I1028 10:04:37.184692  9023 sgd_solver.cpp:105] Iteration 152280, lr = 0.000663159
I1028 10:05:07.808320  9023 solver.cpp:222] Iteration 152320 (1.30623 iter/s, 30.6225s/40 iters), loss = 1.16094
I1028 10:05:07.808476  9023 solver.cpp:241]     Train net output #0: loss = 1.16094 (* 1 = 1.16094 loss)
I1028 10:05:07.808492  9023 sgd_solver.cpp:105] Iteration 152320, lr = 0.000661363
I1028 10:05:38.727716  9023 solver.cpp:222] Iteration 152360 (1.29374 iter/s, 30.9181s/40 iters), loss = 1.34445
I1028 10:05:38.727915  9023 solver.cpp:241]     Train net output #0: loss = 1.34445 (* 1 = 1.34445 loss)
I1028 10:05:38.727932  9023 sgd_solver.cpp:105] Iteration 152360, lr = 0.000659568
I1028 10:06:09.849303  9023 solver.cpp:222] Iteration 152400 (1.28534 iter/s, 31.1202s/40 iters), loss = 1.31636
I1028 10:06:09.849478  9023 solver.cpp:241]     Train net output #0: loss = 1.31636 (* 1 = 1.31636 loss)
I1028 10:06:09.849496  9023 sgd_solver.cpp:105] Iteration 152400, lr = 0.000657773
I1028 10:06:41.171205  9023 solver.cpp:222] Iteration 152440 (1.27712 iter/s, 31.3205s/40 iters), loss = 1.55509
I1028 10:06:41.171402  9023 solver.cpp:241]     Train net output #0: loss = 1.55509 (* 1 = 1.55509 loss)
I1028 10:06:41.171422  9023 sgd_solver.cpp:105] Iteration 152440, lr = 0.00065598
I1028 10:07:12.722802  9023 solver.cpp:222] Iteration 152480 (1.26782 iter/s, 31.5502s/40 iters), loss = 1.74012
I1028 10:07:12.722993  9023 solver.cpp:241]     Train net output #0: loss = 1.74012 (* 1 = 1.74012 loss)
I1028 10:07:12.723011  9023 sgd_solver.cpp:105] Iteration 152480, lr = 0.000654187
I1028 10:07:27.630931  9023 solver.cpp:334] Iteration 152500, Testing net (#0)
I1028 10:07:59.537453  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58324
I1028 10:07:59.537647  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.807879
I1028 10:07:59.537662  9023 solver.cpp:401]     Test net output #2: loss = 1.85525 (* 1 = 1.85525 loss)
I1028 10:08:15.732084  9023 solver.cpp:222] Iteration 152520 (0.634853 iter/s, 63.0067s/40 iters), loss = 1.21267
I1028 10:08:15.732161  9023 solver.cpp:241]     Train net output #0: loss = 1.21267 (* 1 = 1.21267 loss)
I1028 10:08:15.732177  9023 sgd_solver.cpp:105] Iteration 152520, lr = 0.000652396
I1028 10:08:47.102694  9023 solver.cpp:222] Iteration 152560 (1.27513 iter/s, 31.3694s/40 iters), loss = 1.49502
I1028 10:08:47.102890  9023 solver.cpp:241]     Train net output #0: loss = 1.49502 (* 1 = 1.49502 loss)
I1028 10:08:47.102908  9023 sgd_solver.cpp:105] Iteration 152560, lr = 0.000650604
I1028 10:09:18.468024  9023 solver.cpp:222] Iteration 152600 (1.27535 iter/s, 31.364s/40 iters), loss = 1.63085
I1028 10:09:18.468192  9023 solver.cpp:241]     Train net output #0: loss = 1.63085 (* 1 = 1.63085 loss)
I1028 10:09:18.468209  9023 sgd_solver.cpp:105] Iteration 152600, lr = 0.000648814
I1028 10:09:49.716981  9023 solver.cpp:222] Iteration 152640 (1.2801 iter/s, 31.2476s/40 iters), loss = 1.74999
I1028 10:09:49.717167  9023 solver.cpp:241]     Train net output #0: loss = 1.74999 (* 1 = 1.74999 loss)
I1028 10:09:49.717183  9023 sgd_solver.cpp:105] Iteration 152640, lr = 0.000647025
I1028 10:10:20.768693  9023 solver.cpp:222] Iteration 152680 (1.28823 iter/s, 31.0504s/40 iters), loss = 1.54033
I1028 10:10:20.768914  9023 solver.cpp:241]     Train net output #0: loss = 1.54033 (* 1 = 1.54033 loss)
I1028 10:10:20.768932  9023 sgd_solver.cpp:105] Iteration 152680, lr = 0.000645236
I1028 10:10:51.946802  9023 solver.cpp:222] Iteration 152720 (1.28301 iter/s, 31.1767s/40 iters), loss = 1.7474
I1028 10:10:51.947058  9023 solver.cpp:241]     Train net output #0: loss = 1.7474 (* 1 = 1.7474 loss)
I1028 10:10:51.947099  9023 sgd_solver.cpp:105] Iteration 152720, lr = 0.000643449
I1028 10:11:23.100388  9023 solver.cpp:222] Iteration 152760 (1.28402 iter/s, 31.1522s/40 iters), loss = 1.39557
I1028 10:11:23.100610  9023 solver.cpp:241]     Train net output #0: loss = 1.39557 (* 1 = 1.39557 loss)
I1028 10:11:23.100628  9023 sgd_solver.cpp:105] Iteration 152760, lr = 0.000641661
I1028 10:11:54.198467  9023 solver.cpp:222] Iteration 152800 (1.28631 iter/s, 31.0967s/40 iters), loss = 1.82469
I1028 10:11:54.198693  9023 solver.cpp:241]     Train net output #0: loss = 1.82469 (* 1 = 1.82469 loss)
I1028 10:11:54.198711  9023 sgd_solver.cpp:105] Iteration 152800, lr = 0.000639876
I1028 10:12:25.230578  9023 solver.cpp:222] Iteration 152840 (1.28905 iter/s, 31.0307s/40 iters), loss = 1.63518
I1028 10:12:25.230764  9023 solver.cpp:241]     Train net output #0: loss = 1.63518 (* 1 = 1.63518 loss)
I1028 10:12:25.230782  9023 sgd_solver.cpp:105] Iteration 152840, lr = 0.00063809
I1028 10:12:56.133359  9023 solver.cpp:222] Iteration 152880 (1.29444 iter/s, 30.9014s/40 iters), loss = 1.42077
I1028 10:12:56.133527  9023 solver.cpp:241]     Train net output #0: loss = 1.42077 (* 1 = 1.42077 loss)
I1028 10:12:56.133543  9023 sgd_solver.cpp:105] Iteration 152880, lr = 0.000636305
I1028 10:13:27.307888  9023 solver.cpp:222] Iteration 152920 (1.28315 iter/s, 31.1732s/40 iters), loss = 1.25357
I1028 10:13:27.308061  9023 solver.cpp:241]     Train net output #0: loss = 1.25357 (* 1 = 1.25357 loss)
I1028 10:13:27.308079  9023 sgd_solver.cpp:105] Iteration 152920, lr = 0.000634522
I1028 10:13:57.934047  9023 solver.cpp:222] Iteration 152960 (1.30613 iter/s, 30.6248s/40 iters), loss = 1.49988
I1028 10:13:57.934237  9023 solver.cpp:241]     Train net output #0: loss = 1.49988 (* 1 = 1.49988 loss)
I1028 10:13:57.934255  9023 sgd_solver.cpp:105] Iteration 152960, lr = 0.000632739
I1028 10:14:28.438603  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_153000.caffemodel
I1028 10:14:28.470305  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_153000.solverstate
I1028 10:14:28.487980  9023 solver.cpp:334] Iteration 153000, Testing net (#0)
I1028 10:14:59.499855  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 10:14:59.711043  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58112
I1028 10:14:59.711107  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.811559
I1028 10:14:59.711120  9023 solver.cpp:401]     Test net output #2: loss = 1.84668 (* 1 = 1.84668 loss)
I1028 10:15:00.483512  9023 solver.cpp:222] Iteration 153000 (0.63952 iter/s, 62.5469s/40 iters), loss = 1.23751
I1028 10:15:00.483582  9023 solver.cpp:241]     Train net output #0: loss = 1.23751 (* 1 = 1.23751 loss)
I1028 10:15:00.483598  9023 sgd_solver.cpp:105] Iteration 153000, lr = 0.000630957
I1028 10:15:31.530628  9023 solver.cpp:222] Iteration 153040 (1.28842 iter/s, 31.0459s/40 iters), loss = 1.46944
I1028 10:15:31.530791  9023 solver.cpp:241]     Train net output #0: loss = 1.46944 (* 1 = 1.46944 loss)
I1028 10:15:31.530807  9023 sgd_solver.cpp:105] Iteration 153040, lr = 0.000629176
I1028 10:16:02.633102  9023 solver.cpp:222] Iteration 153080 (1.28613 iter/s, 31.1011s/40 iters), loss = 1.60482
I1028 10:16:02.633288  9023 solver.cpp:241]     Train net output #0: loss = 1.60482 (* 1 = 1.60482 loss)
I1028 10:16:02.633311  9023 sgd_solver.cpp:105] Iteration 153080, lr = 0.000627396
I1028 10:16:33.394665  9023 solver.cpp:222] Iteration 153120 (1.30038 iter/s, 30.7602s/40 iters), loss = 1.65773
I1028 10:16:33.394834  9023 solver.cpp:241]     Train net output #0: loss = 1.65773 (* 1 = 1.65773 loss)
I1028 10:16:33.394870  9023 sgd_solver.cpp:105] Iteration 153120, lr = 0.000625617
I1028 10:17:05.036334  9023 solver.cpp:222] Iteration 153160 (1.26421 iter/s, 31.6403s/40 iters), loss = 1.74257
I1028 10:17:05.036628  9023 solver.cpp:241]     Train net output #0: loss = 1.74257 (* 1 = 1.74257 loss)
I1028 10:17:05.036669  9023 sgd_solver.cpp:105] Iteration 153160, lr = 0.000623838
I1028 10:17:39.268551  9023 solver.cpp:222] Iteration 153200 (1.16854 iter/s, 34.2306s/40 iters), loss = 1.67935
I1028 10:17:39.268779  9023 solver.cpp:241]     Train net output #0: loss = 1.67935 (* 1 = 1.67935 loss)
I1028 10:17:39.268795  9023 sgd_solver.cpp:105] Iteration 153200, lr = 0.00062206
I1028 10:18:10.445972  9023 solver.cpp:222] Iteration 153240 (1.28304 iter/s, 31.176s/40 iters), loss = 1.69615
I1028 10:18:10.446149  9023 solver.cpp:241]     Train net output #0: loss = 1.69615 (* 1 = 1.69615 loss)
I1028 10:18:10.446166  9023 sgd_solver.cpp:105] Iteration 153240, lr = 0.000620283
I1028 10:18:41.627810  9023 solver.cpp:222] Iteration 153280 (1.28285 iter/s, 31.1805s/40 iters), loss = 1.48774
I1028 10:18:41.627988  9023 solver.cpp:241]     Train net output #0: loss = 1.48774 (* 1 = 1.48774 loss)
I1028 10:18:41.628005  9023 sgd_solver.cpp:105] Iteration 153280, lr = 0.000618507
I1028 10:19:12.937961  9023 solver.cpp:222] Iteration 153320 (1.2776 iter/s, 31.3088s/40 iters), loss = 1.65249
I1028 10:19:12.938148  9023 solver.cpp:241]     Train net output #0: loss = 1.65249 (* 1 = 1.65249 loss)
I1028 10:19:12.938165  9023 sgd_solver.cpp:105] Iteration 153320, lr = 0.000616732
I1028 10:19:43.835191  9023 solver.cpp:222] Iteration 153360 (1.29467 iter/s, 30.8959s/40 iters), loss = 1.53948
I1028 10:19:43.835377  9023 solver.cpp:241]     Train net output #0: loss = 1.53948 (* 1 = 1.53948 loss)
I1028 10:19:43.835393  9023 sgd_solver.cpp:105] Iteration 153360, lr = 0.000614957
I1028 10:20:40.476635  9023 solver.cpp:222] Iteration 153400 (0.706226 iter/s, 56.6391s/40 iters), loss = 1.43134
I1028 10:20:40.476879  9023 solver.cpp:241]     Train net output #0: loss = 1.43134 (* 1 = 1.43134 loss)
I1028 10:20:40.476907  9023 sgd_solver.cpp:105] Iteration 153400, lr = 0.000613184
I1028 10:21:12.856987  9023 solver.cpp:222] Iteration 153440 (1.23537 iter/s, 32.3789s/40 iters), loss = 1.40659
I1028 10:21:12.857210  9023 solver.cpp:241]     Train net output #0: loss = 1.40659 (* 1 = 1.40659 loss)
I1028 10:21:12.857228  9023 sgd_solver.cpp:105] Iteration 153440, lr = 0.000611411
I1028 10:21:43.300760  9023 solver.cpp:222] Iteration 153480 (1.31396 iter/s, 30.4424s/40 iters), loss = 1.47904
I1028 10:21:43.300952  9023 solver.cpp:241]     Train net output #0: loss = 1.47904 (* 1 = 1.47904 loss)
I1028 10:21:43.300973  9023 sgd_solver.cpp:105] Iteration 153480, lr = 0.00060964
I1028 10:21:58.169127  9023 solver.cpp:334] Iteration 153500, Testing net (#0)
I1028 10:22:29.410720  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58376
I1028 10:22:29.410933  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.806239
I1028 10:22:29.410948  9023 solver.cpp:401]     Test net output #2: loss = 1.8399 (* 1 = 1.8399 loss)
I1028 10:22:45.775910  9023 solver.cpp:222] Iteration 153520 (0.64028 iter/s, 62.4726s/40 iters), loss = 1.265
I1028 10:22:45.775985  9023 solver.cpp:241]     Train net output #0: loss = 1.265 (* 1 = 1.265 loss)
I1028 10:22:45.776000  9023 sgd_solver.cpp:105] Iteration 153520, lr = 0.000607869
I1028 10:23:17.090194  9023 solver.cpp:222] Iteration 153560 (1.27742 iter/s, 31.313s/40 iters), loss = 1.23506
I1028 10:23:17.090627  9023 solver.cpp:241]     Train net output #0: loss = 1.23506 (* 1 = 1.23506 loss)
I1028 10:23:17.090646  9023 sgd_solver.cpp:105] Iteration 153560, lr = 0.000606099
I1028 10:23:48.378901  9023 solver.cpp:222] Iteration 153600 (1.27848 iter/s, 31.2871s/40 iters), loss = 1.48044
I1028 10:23:48.379089  9023 solver.cpp:241]     Train net output #0: loss = 1.48044 (* 1 = 1.48044 loss)
I1028 10:23:48.379106  9023 sgd_solver.cpp:105] Iteration 153600, lr = 0.00060433
I1028 10:24:19.541288  9023 solver.cpp:222] Iteration 153640 (1.28365 iter/s, 31.161s/40 iters), loss = 1.73491
I1028 10:24:19.541541  9023 solver.cpp:241]     Train net output #0: loss = 1.73491 (* 1 = 1.73491 loss)
I1028 10:24:19.541564  9023 sgd_solver.cpp:105] Iteration 153640, lr = 0.000602561
I1028 10:24:50.483858  9023 solver.cpp:222] Iteration 153680 (1.29278 iter/s, 30.9412s/40 iters), loss = 1.39659
I1028 10:24:50.484098  9023 solver.cpp:241]     Train net output #0: loss = 1.39659 (* 1 = 1.39659 loss)
I1028 10:24:50.484123  9023 sgd_solver.cpp:105] Iteration 153680, lr = 0.000600794
I1028 10:25:21.901141  9023 solver.cpp:222] Iteration 153720 (1.27324 iter/s, 31.4159s/40 iters), loss = 1.36426
I1028 10:25:21.901465  9023 solver.cpp:241]     Train net output #0: loss = 1.36426 (* 1 = 1.36426 loss)
I1028 10:25:21.901484  9023 sgd_solver.cpp:105] Iteration 153720, lr = 0.000599027
I1028 10:25:52.818878  9023 solver.cpp:222] Iteration 153760 (1.29382 iter/s, 30.9163s/40 iters), loss = 1.19651
I1028 10:25:52.819064  9023 solver.cpp:241]     Train net output #0: loss = 1.19651 (* 1 = 1.19651 loss)
I1028 10:25:52.819082  9023 sgd_solver.cpp:105] Iteration 153760, lr = 0.000597262
I1028 10:26:24.695288  9023 solver.cpp:222] Iteration 153800 (1.2549 iter/s, 31.875s/40 iters), loss = 1.20563
I1028 10:26:24.695500  9023 solver.cpp:241]     Train net output #0: loss = 1.20563 (* 1 = 1.20563 loss)
I1028 10:26:24.695518  9023 sgd_solver.cpp:105] Iteration 153800, lr = 0.000595497
I1028 10:26:55.462939  9023 solver.cpp:222] Iteration 153840 (1.30012 iter/s, 30.7663s/40 iters), loss = 1.48291
I1028 10:26:55.463124  9023 solver.cpp:241]     Train net output #0: loss = 1.48291 (* 1 = 1.48291 loss)
I1028 10:26:55.463140  9023 sgd_solver.cpp:105] Iteration 153840, lr = 0.000593732
I1028 10:27:26.823480  9023 solver.cpp:222] Iteration 153880 (1.27554 iter/s, 31.3592s/40 iters), loss = 1.63088
I1028 10:27:26.823701  9023 solver.cpp:241]     Train net output #0: loss = 1.63088 (* 1 = 1.63088 loss)
I1028 10:27:26.823729  9023 sgd_solver.cpp:105] Iteration 153880, lr = 0.00059197
I1028 10:27:58.748471  9023 solver.cpp:222] Iteration 153920 (1.25299 iter/s, 31.9236s/40 iters), loss = 1.64495
I1028 10:27:58.748656  9023 solver.cpp:241]     Train net output #0: loss = 1.64495 (* 1 = 1.64495 loss)
I1028 10:27:58.748673  9023 sgd_solver.cpp:105] Iteration 153920, lr = 0.000590207
I1028 10:28:29.923733  9023 solver.cpp:222] Iteration 153960 (1.28312 iter/s, 31.1739s/40 iters), loss = 1.5968
I1028 10:28:29.923908  9023 solver.cpp:241]     Train net output #0: loss = 1.5968 (* 1 = 1.5968 loss)
I1028 10:28:29.923926  9023 sgd_solver.cpp:105] Iteration 153960, lr = 0.000588446
I1028 10:29:00.861609  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_154000.caffemodel
I1028 10:29:00.893254  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_154000.solverstate
I1028 10:29:00.910203  9023 solver.cpp:334] Iteration 154000, Testing net (#0)
I1028 10:29:31.989519  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 10:29:32.198371  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5818
I1028 10:29:32.198437  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81428
I1028 10:29:32.198451  9023 solver.cpp:401]     Test net output #2: loss = 1.84594 (* 1 = 1.84594 loss)
I1028 10:29:32.962479  9023 solver.cpp:222] Iteration 154000 (0.634556 iter/s, 63.0362s/40 iters), loss = 1.22327
I1028 10:29:32.962550  9023 solver.cpp:241]     Train net output #0: loss = 1.22327 (* 1 = 1.22327 loss)
I1028 10:29:32.962566  9023 sgd_solver.cpp:105] Iteration 154000, lr = 0.000586685
I1028 10:30:22.808861  9023 solver.cpp:222] Iteration 154040 (0.802497 iter/s, 49.8444s/40 iters), loss = 1.59936
I1028 10:30:22.809069  9023 solver.cpp:241]     Train net output #0: loss = 1.59936 (* 1 = 1.59936 loss)
I1028 10:30:22.809087  9023 sgd_solver.cpp:105] Iteration 154040, lr = 0.000584926
I1028 10:30:53.872051  9023 solver.cpp:222] Iteration 154080 (1.28776 iter/s, 31.0618s/40 iters), loss = 1.58189
I1028 10:30:53.872280  9023 solver.cpp:241]     Train net output #0: loss = 1.58189 (* 1 = 1.58189 loss)
I1028 10:30:53.872304  9023 sgd_solver.cpp:105] Iteration 154080, lr = 0.000583167
I1028 10:31:25.052248  9023 solver.cpp:222] Iteration 154120 (1.28292 iter/s, 31.1788s/40 iters), loss = 1.56478
I1028 10:31:25.052465  9023 solver.cpp:241]     Train net output #0: loss = 1.56478 (* 1 = 1.56478 loss)
I1028 10:31:25.052484  9023 sgd_solver.cpp:105] Iteration 154120, lr = 0.000581409
I1028 10:31:56.334457  9023 solver.cpp:222] Iteration 154160 (1.27874 iter/s, 31.2808s/40 iters), loss = 1.23997
I1028 10:31:56.334673  9023 solver.cpp:241]     Train net output #0: loss = 1.23997 (* 1 = 1.23997 loss)
I1028 10:31:56.334692  9023 sgd_solver.cpp:105] Iteration 154160, lr = 0.000579652
I1028 10:32:27.261342  9023 solver.cpp:222] Iteration 154200 (1.29343 iter/s, 30.9255s/40 iters), loss = 1.57038
I1028 10:32:27.261546  9023 solver.cpp:241]     Train net output #0: loss = 1.57038 (* 1 = 1.57038 loss)
I1028 10:32:27.261566  9023 sgd_solver.cpp:105] Iteration 154200, lr = 0.000577896
I1028 10:32:58.130056  9023 solver.cpp:222] Iteration 154240 (1.29587 iter/s, 30.8673s/40 iters), loss = 1.58674
I1028 10:32:58.130240  9023 solver.cpp:241]     Train net output #0: loss = 1.58674 (* 1 = 1.58674 loss)
I1028 10:32:58.130261  9023 sgd_solver.cpp:105] Iteration 154240, lr = 0.000576141
I1028 10:33:28.855607  9023 solver.cpp:222] Iteration 154280 (1.3019 iter/s, 30.7242s/40 iters), loss = 1.50776
I1028 10:33:28.855783  9023 solver.cpp:241]     Train net output #0: loss = 1.50776 (* 1 = 1.50776 loss)
I1028 10:33:28.855800  9023 sgd_solver.cpp:105] Iteration 154280, lr = 0.000574387
I1028 10:33:59.672546  9023 solver.cpp:222] Iteration 154320 (1.29804 iter/s, 30.8156s/40 iters), loss = 1.58442
I1028 10:33:59.672757  9023 solver.cpp:241]     Train net output #0: loss = 1.58442 (* 1 = 1.58442 loss)
I1028 10:33:59.672788  9023 sgd_solver.cpp:105] Iteration 154320, lr = 0.000572633
I1028 10:34:30.549995  9023 solver.cpp:222] Iteration 154360 (1.2955 iter/s, 30.8761s/40 iters), loss = 1.6018
I1028 10:34:30.550194  9023 solver.cpp:241]     Train net output #0: loss = 1.6018 (* 1 = 1.6018 loss)
I1028 10:34:30.550212  9023 sgd_solver.cpp:105] Iteration 154360, lr = 0.000570881
I1028 10:35:01.150576  9023 solver.cpp:222] Iteration 154400 (1.30722 iter/s, 30.5992s/40 iters), loss = 1.82842
I1028 10:35:01.150750  9023 solver.cpp:241]     Train net output #0: loss = 1.82842 (* 1 = 1.82842 loss)
I1028 10:35:01.150766  9023 sgd_solver.cpp:105] Iteration 154400, lr = 0.000569129
I1028 10:35:32.305888  9023 solver.cpp:222] Iteration 154440 (1.28395 iter/s, 31.154s/40 iters), loss = 1.6943
I1028 10:35:32.306077  9023 solver.cpp:241]     Train net output #0: loss = 1.6943 (* 1 = 1.6943 loss)
I1028 10:35:32.306094  9023 sgd_solver.cpp:105] Iteration 154440, lr = 0.000567378
I1028 10:36:04.005957  9023 solver.cpp:222] Iteration 154480 (1.26188 iter/s, 31.6987s/40 iters), loss = 1.12162
I1028 10:36:04.006124  9023 solver.cpp:241]     Train net output #0: loss = 1.12162 (* 1 = 1.12162 loss)
I1028 10:36:04.006140  9023 sgd_solver.cpp:105] Iteration 154480, lr = 0.000565628
I1028 10:36:19.089052  9023 solver.cpp:334] Iteration 154500, Testing net (#0)
I1028 10:36:50.607079  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.583
I1028 10:36:50.607247  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81068
I1028 10:36:50.607265  9023 solver.cpp:401]     Test net output #2: loss = 1.83525 (* 1 = 1.83525 loss)
I1028 10:37:07.519472  9023 solver.cpp:222] Iteration 154520 (0.629813 iter/s, 63.511s/40 iters), loss = 1.42933
I1028 10:37:07.519577  9023 solver.cpp:241]     Train net output #0: loss = 1.42933 (* 1 = 1.42933 loss)
I1028 10:37:07.519601  9023 sgd_solver.cpp:105] Iteration 154520, lr = 0.00056388
I1028 10:37:38.796473  9023 solver.cpp:222] Iteration 154560 (1.27895 iter/s, 31.2757s/40 iters), loss = 1.36883
I1028 10:37:38.796690  9023 solver.cpp:241]     Train net output #0: loss = 1.36883 (* 1 = 1.36883 loss)
I1028 10:37:38.796723  9023 sgd_solver.cpp:105] Iteration 154560, lr = 0.000562132
I1028 10:37:52.898551  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1028 10:38:09.881078  9023 solver.cpp:222] Iteration 154600 (1.28687 iter/s, 31.0832s/40 iters), loss = 1.40468
I1028 10:38:09.881359  9023 solver.cpp:241]     Train net output #0: loss = 1.40468 (* 1 = 1.40468 loss)
I1028 10:38:09.881381  9023 sgd_solver.cpp:105] Iteration 154600, lr = 0.000560384
I1028 10:38:41.234863  9023 solver.cpp:222] Iteration 154640 (1.27582 iter/s, 31.3523s/40 iters), loss = 1.55128
I1028 10:38:41.235101  9023 solver.cpp:241]     Train net output #0: loss = 1.55128 (* 1 = 1.55128 loss)
I1028 10:38:41.235129  9023 sgd_solver.cpp:105] Iteration 154640, lr = 0.000558638
I1028 10:39:12.891600  9023 solver.cpp:222] Iteration 154680 (1.26361 iter/s, 31.6553s/40 iters), loss = 1.16972
I1028 10:39:12.891820  9023 solver.cpp:241]     Train net output #0: loss = 1.16972 (* 1 = 1.16972 loss)
I1028 10:39:12.891839  9023 sgd_solver.cpp:105] Iteration 154680, lr = 0.000556893
I1028 10:39:44.464418  9023 solver.cpp:222] Iteration 154720 (1.26697 iter/s, 31.5714s/40 iters), loss = 1.25892
I1028 10:39:44.464587  9023 solver.cpp:241]     Train net output #0: loss = 1.25892 (* 1 = 1.25892 loss)
I1028 10:39:44.464604  9023 sgd_solver.cpp:105] Iteration 154720, lr = 0.000555149
I1028 10:40:15.555111  9023 solver.cpp:222] Iteration 154760 (1.28661 iter/s, 31.0893s/40 iters), loss = 1.55267
I1028 10:40:15.555316  9023 solver.cpp:241]     Train net output #0: loss = 1.55267 (* 1 = 1.55267 loss)
I1028 10:40:15.555336  9023 sgd_solver.cpp:105] Iteration 154760, lr = 0.000553405
I1028 10:40:46.835129  9023 solver.cpp:222] Iteration 154800 (1.27883 iter/s, 31.2786s/40 iters), loss = 1.44557
I1028 10:40:46.835340  9023 solver.cpp:241]     Train net output #0: loss = 1.44557 (* 1 = 1.44557 loss)
I1028 10:40:46.835358  9023 sgd_solver.cpp:105] Iteration 154800, lr = 0.000551662
I1028 10:41:17.911116  9023 solver.cpp:222] Iteration 154840 (1.28722 iter/s, 31.0746s/40 iters), loss = 1.66505
I1028 10:41:17.911317  9023 solver.cpp:241]     Train net output #0: loss = 1.66505 (* 1 = 1.66505 loss)
I1028 10:41:17.911334  9023 sgd_solver.cpp:105] Iteration 154840, lr = 0.000549921
I1028 10:41:48.788990  9023 solver.cpp:222] Iteration 154880 (1.29548 iter/s, 30.8765s/40 iters), loss = 1.39458
I1028 10:41:48.789182  9023 solver.cpp:241]     Train net output #0: loss = 1.39458 (* 1 = 1.39458 loss)
I1028 10:41:48.789199  9023 sgd_solver.cpp:105] Iteration 154880, lr = 0.00054818
I1028 10:42:20.152184  9023 solver.cpp:222] Iteration 154920 (1.27544 iter/s, 31.3618s/40 iters), loss = 1.42057
I1028 10:42:20.152374  9023 solver.cpp:241]     Train net output #0: loss = 1.42057 (* 1 = 1.42057 loss)
I1028 10:42:20.152390  9023 sgd_solver.cpp:105] Iteration 154920, lr = 0.000546441
I1028 10:42:51.212201  9023 solver.cpp:222] Iteration 154960 (1.28789 iter/s, 31.0587s/40 iters), loss = 1.42316
I1028 10:42:51.212412  9023 solver.cpp:241]     Train net output #0: loss = 1.42316 (* 1 = 1.42316 loss)
I1028 10:42:51.212435  9023 sgd_solver.cpp:105] Iteration 154960, lr = 0.000544702
I1028 10:43:21.592466  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_155000.caffemodel
I1028 10:43:21.625368  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_155000.solverstate
I1028 10:43:21.643784  9023 solver.cpp:334] Iteration 155000, Testing net (#0)
I1028 10:43:53.066967  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 10:43:53.277570  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58176
I1028 10:43:53.277635  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.811199
I1028 10:43:53.277649  9023 solver.cpp:401]     Test net output #2: loss = 1.84015 (* 1 = 1.84015 loss)
I1028 10:43:54.047511  9023 solver.cpp:222] Iteration 155000 (0.636611 iter/s, 62.8327s/40 iters), loss = 1.51912
I1028 10:43:54.047595  9023 solver.cpp:241]     Train net output #0: loss = 1.51912 (* 1 = 1.51912 loss)
I1028 10:43:54.047610  9023 sgd_solver.cpp:105] Iteration 155000, lr = 0.000542964
I1028 10:44:24.849465  9023 solver.cpp:222] Iteration 155040 (1.29867 iter/s, 30.8007s/40 iters), loss = 1.56429
I1028 10:44:24.849685  9023 solver.cpp:241]     Train net output #0: loss = 1.56429 (* 1 = 1.56429 loss)
I1028 10:44:24.849705  9023 sgd_solver.cpp:105] Iteration 155040, lr = 0.000541227
I1028 10:44:55.723809  9023 solver.cpp:222] Iteration 155080 (1.29563 iter/s, 30.873s/40 iters), loss = 1.25785
I1028 10:44:55.723989  9023 solver.cpp:241]     Train net output #0: loss = 1.25785 (* 1 = 1.25785 loss)
I1028 10:44:55.724005  9023 sgd_solver.cpp:105] Iteration 155080, lr = 0.00053949
I1028 10:45:26.795532  9023 solver.cpp:222] Iteration 155120 (1.2874 iter/s, 31.0704s/40 iters), loss = 1.31979
I1028 10:45:26.795722  9023 solver.cpp:241]     Train net output #0: loss = 1.31979 (* 1 = 1.31979 loss)
I1028 10:45:26.795737  9023 sgd_solver.cpp:105] Iteration 155120, lr = 0.000537755
I1028 10:45:57.931082  9023 solver.cpp:222] Iteration 155160 (1.28476 iter/s, 31.1342s/40 iters), loss = 1.46235
I1028 10:45:57.931268  9023 solver.cpp:241]     Train net output #0: loss = 1.46235 (* 1 = 1.46235 loss)
I1028 10:45:57.931301  9023 sgd_solver.cpp:105] Iteration 155160, lr = 0.000536021
I1028 10:46:28.832165  9023 solver.cpp:222] Iteration 155200 (1.29451 iter/s, 30.8997s/40 iters), loss = 1.14848
I1028 10:46:28.832609  9023 solver.cpp:241]     Train net output #0: loss = 1.14848 (* 1 = 1.14848 loss)
I1028 10:46:28.832628  9023 sgd_solver.cpp:105] Iteration 155200, lr = 0.000534288
I1028 10:46:59.888525  9023 solver.cpp:222] Iteration 155240 (1.28805 iter/s, 31.0547s/40 iters), loss = 1.64294
I1028 10:46:59.888694  9023 solver.cpp:241]     Train net output #0: loss = 1.64294 (* 1 = 1.64294 loss)
I1028 10:46:59.888710  9023 sgd_solver.cpp:105] Iteration 155240, lr = 0.000532555
I1028 10:47:31.243819  9023 solver.cpp:222] Iteration 155280 (1.27576 iter/s, 31.3539s/40 iters), loss = 1.39053
I1028 10:47:31.244005  9023 solver.cpp:241]     Train net output #0: loss = 1.39053 (* 1 = 1.39053 loss)
I1028 10:47:31.244024  9023 sgd_solver.cpp:105] Iteration 155280, lr = 0.000530824
I1028 10:48:01.950021  9023 solver.cpp:222] Iteration 155320 (1.30273 iter/s, 30.7049s/40 iters), loss = 1.56065
I1028 10:48:01.950202  9023 solver.cpp:241]     Train net output #0: loss = 1.56065 (* 1 = 1.56065 loss)
I1028 10:48:01.950218  9023 sgd_solver.cpp:105] Iteration 155320, lr = 0.000529094
I1028 10:48:32.531972  9023 solver.cpp:222] Iteration 155360 (1.30802 iter/s, 30.5806s/40 iters), loss = 1.53779
I1028 10:48:32.532145  9023 solver.cpp:241]     Train net output #0: loss = 1.53779 (* 1 = 1.53779 loss)
I1028 10:48:32.532160  9023 sgd_solver.cpp:105] Iteration 155360, lr = 0.000527364
I1028 10:49:03.134444  9023 solver.cpp:222] Iteration 155400 (1.30714 iter/s, 30.6011s/40 iters), loss = 1.7587
I1028 10:49:03.134620  9023 solver.cpp:241]     Train net output #0: loss = 1.7587 (* 1 = 1.7587 loss)
I1028 10:49:03.134636  9023 sgd_solver.cpp:105] Iteration 155400, lr = 0.000525636
I1028 10:49:34.102774  9023 solver.cpp:222] Iteration 155440 (1.2917 iter/s, 30.967s/40 iters), loss = 1.34604
I1028 10:49:34.102965  9023 solver.cpp:241]     Train net output #0: loss = 1.34604 (* 1 = 1.34604 loss)
I1028 10:49:34.102984  9023 sgd_solver.cpp:105] Iteration 155440, lr = 0.000523908
I1028 10:50:04.933354  9023 solver.cpp:222] Iteration 155480 (1.29747 iter/s, 30.8292s/40 iters), loss = 1.29794
I1028 10:50:04.933552  9023 solver.cpp:241]     Train net output #0: loss = 1.29794 (* 1 = 1.29794 loss)
I1028 10:50:04.933568  9023 sgd_solver.cpp:105] Iteration 155480, lr = 0.000522181
I1028 10:50:19.806737  9023 solver.cpp:334] Iteration 155500, Testing net (#0)
I1028 10:50:51.449829  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58388
I1028 10:50:51.450013  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.808519
I1028 10:50:51.450047  9023 solver.cpp:401]     Test net output #2: loss = 1.83951 (* 1 = 1.83951 loss)
I1028 10:51:07.640743  9023 solver.cpp:222] Iteration 155520 (0.637909 iter/s, 62.7048s/40 iters), loss = 1.81587
I1028 10:51:07.640816  9023 solver.cpp:241]     Train net output #0: loss = 1.81587 (* 1 = 1.81587 loss)
I1028 10:51:07.640833  9023 sgd_solver.cpp:105] Iteration 155520, lr = 0.000520455
I1028 10:51:38.684216  9023 solver.cpp:222] Iteration 155560 (1.28857 iter/s, 31.0422s/40 iters), loss = 1.36292
I1028 10:51:38.684465  9023 solver.cpp:241]     Train net output #0: loss = 1.36292 (* 1 = 1.36292 loss)
I1028 10:51:38.684489  9023 sgd_solver.cpp:105] Iteration 155560, lr = 0.00051873
I1028 10:52:10.632270  9023 solver.cpp:222] Iteration 155600 (1.25209 iter/s, 31.9466s/40 iters), loss = 1.61387
I1028 10:52:10.632500  9023 solver.cpp:241]     Train net output #0: loss = 1.61387 (* 1 = 1.61387 loss)
I1028 10:52:10.632526  9023 sgd_solver.cpp:105] Iteration 155600, lr = 0.000517007
I1028 10:52:43.921139  9023 solver.cpp:222] Iteration 155640 (1.20166 iter/s, 33.2874s/40 iters), loss = 1.57272
I1028 10:52:43.921314  9023 solver.cpp:241]     Train net output #0: loss = 1.57272 (* 1 = 1.57272 loss)
I1028 10:52:43.921339  9023 sgd_solver.cpp:105] Iteration 155640, lr = 0.000515284
I1028 10:53:15.161867  9023 solver.cpp:222] Iteration 155680 (1.28044 iter/s, 31.2394s/40 iters), loss = 1.35575
I1028 10:53:15.162048  9023 solver.cpp:241]     Train net output #0: loss = 1.35575 (* 1 = 1.35575 loss)
I1028 10:53:15.162065  9023 sgd_solver.cpp:105] Iteration 155680, lr = 0.000513562
I1028 10:53:46.066084  9023 solver.cpp:222] Iteration 155720 (1.29438 iter/s, 30.9029s/40 iters), loss = 1.28653
I1028 10:53:46.066254  9023 solver.cpp:241]     Train net output #0: loss = 1.28653 (* 1 = 1.28653 loss)
I1028 10:53:46.066280  9023 sgd_solver.cpp:105] Iteration 155720, lr = 0.000511841
I1028 10:54:17.049927  9023 solver.cpp:222] Iteration 155760 (1.29105 iter/s, 30.9825s/40 iters), loss = 1.1657
I1028 10:54:17.050115  9023 solver.cpp:241]     Train net output #0: loss = 1.1657 (* 1 = 1.1657 loss)
I1028 10:54:17.050134  9023 sgd_solver.cpp:105] Iteration 155760, lr = 0.000510121
I1028 10:54:48.115593  9023 solver.cpp:222] Iteration 155800 (1.28765 iter/s, 31.0643s/40 iters), loss = 1.09814
I1028 10:54:48.115803  9023 solver.cpp:241]     Train net output #0: loss = 1.09814 (* 1 = 1.09814 loss)
I1028 10:54:48.115821  9023 sgd_solver.cpp:105] Iteration 155800, lr = 0.000508402
I1028 10:55:19.114831  9023 solver.cpp:222] Iteration 155840 (1.29041 iter/s, 30.9979s/40 iters), loss = 1.46332
I1028 10:55:19.115036  9023 solver.cpp:241]     Train net output #0: loss = 1.46332 (* 1 = 1.46332 loss)
I1028 10:55:19.115053  9023 sgd_solver.cpp:105] Iteration 155840, lr = 0.000506684
I1028 10:55:51.331171  9023 solver.cpp:222] Iteration 155880 (1.24166 iter/s, 32.2149s/40 iters), loss = 1.49121
I1028 10:55:51.331387  9023 solver.cpp:241]     Train net output #0: loss = 1.49121 (* 1 = 1.49121 loss)
I1028 10:55:51.331411  9023 sgd_solver.cpp:105] Iteration 155880, lr = 0.000504967
I1028 10:56:22.274359  9023 solver.cpp:222] Iteration 155920 (1.29275 iter/s, 30.9418s/40 iters), loss = 1.14465
I1028 10:56:22.274538  9023 solver.cpp:241]     Train net output #0: loss = 1.14465 (* 1 = 1.14465 loss)
I1028 10:56:22.274555  9023 sgd_solver.cpp:105] Iteration 155920, lr = 0.000503251
I1028 10:56:55.201577  9023 solver.cpp:222] Iteration 155960 (1.21485 iter/s, 32.9258s/40 iters), loss = 1.27389
I1028 10:56:55.201753  9023 solver.cpp:241]     Train net output #0: loss = 1.27389 (* 1 = 1.27389 loss)
I1028 10:56:55.201771  9023 sgd_solver.cpp:105] Iteration 155960, lr = 0.000501536
I1028 10:57:25.161689  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_156000.caffemodel
I1028 10:57:25.194669  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_156000.solverstate
I1028 10:57:25.215597  9023 solver.cpp:334] Iteration 156000, Testing net (#0)
I1028 10:57:56.683197  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 10:57:56.897163  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58196
I1028 10:57:56.897228  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81276
I1028 10:57:56.897241  9023 solver.cpp:401]     Test net output #2: loss = 1.84379 (* 1 = 1.84379 loss)
I1028 10:57:57.671900  9023 solver.cpp:222] Iteration 156000 (0.64033 iter/s, 62.4678s/40 iters), loss = 1.47461
I1028 10:57:57.671967  9023 solver.cpp:241]     Train net output #0: loss = 1.47461 (* 1 = 1.47461 loss)
I1028 10:57:57.671982  9023 sgd_solver.cpp:105] Iteration 156000, lr = 0.000499821
I1028 10:58:29.324251  9023 solver.cpp:222] Iteration 156040 (1.26378 iter/s, 31.6511s/40 iters), loss = 1.40863
I1028 10:58:29.324499  9023 solver.cpp:241]     Train net output #0: loss = 1.40863 (* 1 = 1.40863 loss)
I1028 10:58:29.324524  9023 sgd_solver.cpp:105] Iteration 156040, lr = 0.000498108
I1028 10:59:00.197685  9023 solver.cpp:222] Iteration 156080 (1.29567 iter/s, 30.872s/40 iters), loss = 1.33823
I1028 10:59:00.197870  9023 solver.cpp:241]     Train net output #0: loss = 1.33823 (* 1 = 1.33823 loss)
I1028 10:59:00.197888  9023 sgd_solver.cpp:105] Iteration 156080, lr = 0.000496396
I1028 10:59:31.388742  9023 solver.cpp:222] Iteration 156120 (1.28248 iter/s, 31.1897s/40 iters), loss = 1.31518
I1028 10:59:31.388918  9023 solver.cpp:241]     Train net output #0: loss = 1.31518 (* 1 = 1.31518 loss)
I1028 10:59:31.388936  9023 sgd_solver.cpp:105] Iteration 156120, lr = 0.000494685
I1028 11:00:02.656040  9023 solver.cpp:222] Iteration 156160 (1.27935 iter/s, 31.2659s/40 iters), loss = 1.30845
I1028 11:00:02.656241  9023 solver.cpp:241]     Train net output #0: loss = 1.30845 (* 1 = 1.30845 loss)
I1028 11:00:02.656260  9023 sgd_solver.cpp:105] Iteration 156160, lr = 0.000492975
I1028 11:00:33.929471  9023 solver.cpp:222] Iteration 156200 (1.2791 iter/s, 31.272s/40 iters), loss = 1.40779
I1028 11:00:33.929674  9023 solver.cpp:241]     Train net output #0: loss = 1.40779 (* 1 = 1.40779 loss)
I1028 11:00:33.929692  9023 sgd_solver.cpp:105] Iteration 156200, lr = 0.000491265
I1028 11:01:05.048264  9023 solver.cpp:222] Iteration 156240 (1.28545 iter/s, 31.1174s/40 iters), loss = 1.22466
I1028 11:01:05.048490  9023 solver.cpp:241]     Train net output #0: loss = 1.22466 (* 1 = 1.22466 loss)
I1028 11:01:05.048512  9023 sgd_solver.cpp:105] Iteration 156240, lr = 0.000489557
I1028 11:01:36.129248  9023 solver.cpp:222] Iteration 156280 (1.28702 iter/s, 31.0796s/40 iters), loss = 1.55488
I1028 11:01:36.129443  9023 solver.cpp:241]     Train net output #0: loss = 1.55488 (* 1 = 1.55488 loss)
I1028 11:01:36.129461  9023 sgd_solver.cpp:105] Iteration 156280, lr = 0.00048785
I1028 11:02:07.169456  9023 solver.cpp:222] Iteration 156320 (1.28871 iter/s, 31.0388s/40 iters), loss = 1.25857
I1028 11:02:07.169657  9023 solver.cpp:241]     Train net output #0: loss = 1.25857 (* 1 = 1.25857 loss)
I1028 11:02:07.169675  9023 sgd_solver.cpp:105] Iteration 156320, lr = 0.000486143
I1028 11:02:39.413584  9023 solver.cpp:222] Iteration 156360 (1.24059 iter/s, 32.2427s/40 iters), loss = 1.43917
I1028 11:02:39.413851  9023 solver.cpp:241]     Train net output #0: loss = 1.43917 (* 1 = 1.43917 loss)
I1028 11:02:39.413877  9023 sgd_solver.cpp:105] Iteration 156360, lr = 0.000484438
I1028 11:03:11.152547  9023 solver.cpp:222] Iteration 156400 (1.26034 iter/s, 31.7375s/40 iters), loss = 1.7972
I1028 11:03:11.152734  9023 solver.cpp:241]     Train net output #0: loss = 1.7972 (* 1 = 1.7972 loss)
I1028 11:03:11.152755  9023 sgd_solver.cpp:105] Iteration 156400, lr = 0.000482734
I1028 11:04:10.915704  9023 solver.cpp:222] Iteration 156440 (0.669336 iter/s, 59.7607s/40 iters), loss = 1.28164
I1028 11:04:10.915966  9023 solver.cpp:241]     Train net output #0: loss = 1.28164 (* 1 = 1.28164 loss)
I1028 11:04:10.915990  9023 sgd_solver.cpp:105] Iteration 156440, lr = 0.000481031
I1028 11:04:42.028177  9023 solver.cpp:222] Iteration 156480 (1.28572 iter/s, 31.1111s/40 iters), loss = 1.61104
I1028 11:04:42.028445  9023 solver.cpp:241]     Train net output #0: loss = 1.61104 (* 1 = 1.61104 loss)
I1028 11:04:42.028463  9023 sgd_solver.cpp:105] Iteration 156480, lr = 0.000479328
I1028 11:04:56.752882  9023 solver.cpp:334] Iteration 156500, Testing net (#0)
I1028 11:05:28.211143  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58512
I1028 11:05:28.211442  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.808159
I1028 11:05:28.211459  9023 solver.cpp:401]     Test net output #2: loss = 1.83958 (* 1 = 1.83958 loss)
I1028 11:05:44.348937  9023 solver.cpp:222] Iteration 156520 (0.641867 iter/s, 62.3182s/40 iters), loss = 1.42667
I1028 11:05:44.349014  9023 solver.cpp:241]     Train net output #0: loss = 1.42667 (* 1 = 1.42667 loss)
I1028 11:05:44.349030  9023 sgd_solver.cpp:105] Iteration 156520, lr = 0.000477627
I1028 11:06:14.820061  9023 solver.cpp:222] Iteration 156560 (1.31277 iter/s, 30.4699s/40 iters), loss = 1.35512
I1028 11:06:14.820266  9023 solver.cpp:241]     Train net output #0: loss = 1.35512 (* 1 = 1.35512 loss)
I1028 11:06:14.820284  9023 sgd_solver.cpp:105] Iteration 156560, lr = 0.000475927
I1028 11:06:45.568202  9023 solver.cpp:222] Iteration 156600 (1.30095 iter/s, 30.7468s/40 iters), loss = 1.21545
I1028 11:06:45.568387  9023 solver.cpp:241]     Train net output #0: loss = 1.21545 (* 1 = 1.21545 loss)
I1028 11:06:45.568409  9023 sgd_solver.cpp:105] Iteration 156600, lr = 0.000474228
I1028 11:07:16.242317  9023 solver.cpp:222] Iteration 156640 (1.30409 iter/s, 30.6728s/40 iters), loss = 1.17263
I1028 11:07:16.242508  9023 solver.cpp:241]     Train net output #0: loss = 1.17263 (* 1 = 1.17263 loss)
I1028 11:07:16.242527  9023 sgd_solver.cpp:105] Iteration 156640, lr = 0.00047253
I1028 11:07:47.834460  9023 solver.cpp:222] Iteration 156680 (1.26619 iter/s, 31.5908s/40 iters), loss = 1.49593
I1028 11:07:47.834666  9023 solver.cpp:241]     Train net output #0: loss = 1.49593 (* 1 = 1.49593 loss)
I1028 11:07:47.834688  9023 sgd_solver.cpp:105] Iteration 156680, lr = 0.000470832
I1028 11:08:19.660342  9023 solver.cpp:222] Iteration 156720 (1.25689 iter/s, 31.8245s/40 iters), loss = 1.60667
I1028 11:08:19.660531  9023 solver.cpp:241]     Train net output #0: loss = 1.60667 (* 1 = 1.60667 loss)
I1028 11:08:19.660547  9023 sgd_solver.cpp:105] Iteration 156720, lr = 0.000469136
I1028 11:08:52.041723  9023 solver.cpp:222] Iteration 156760 (1.23533 iter/s, 32.38s/40 iters), loss = 1.78553
I1028 11:08:52.041925  9023 solver.cpp:241]     Train net output #0: loss = 1.78553 (* 1 = 1.78553 loss)
I1028 11:08:52.041945  9023 sgd_solver.cpp:105] Iteration 156760, lr = 0.000467441
I1028 11:09:23.933331  9023 solver.cpp:222] Iteration 156800 (1.2543 iter/s, 31.8902s/40 iters), loss = 1.22139
I1028 11:09:23.933535  9023 solver.cpp:241]     Train net output #0: loss = 1.22139 (* 1 = 1.22139 loss)
I1028 11:09:23.933554  9023 sgd_solver.cpp:105] Iteration 156800, lr = 0.000465747
I1028 11:09:55.226089  9023 solver.cpp:222] Iteration 156840 (1.27831 iter/s, 31.2914s/40 iters), loss = 1.62937
I1028 11:09:55.226274  9023 solver.cpp:241]     Train net output #0: loss = 1.62937 (* 1 = 1.62937 loss)
I1028 11:09:55.226308  9023 sgd_solver.cpp:105] Iteration 156840, lr = 0.000464054
I1028 11:10:26.513605  9023 solver.cpp:222] Iteration 156880 (1.27852 iter/s, 31.2861s/40 iters), loss = 1.75981
I1028 11:10:26.513808  9023 solver.cpp:241]     Train net output #0: loss = 1.75981 (* 1 = 1.75981 loss)
I1028 11:10:26.513829  9023 sgd_solver.cpp:105] Iteration 156880, lr = 0.000462362
I1028 11:10:57.785362  9023 solver.cpp:222] Iteration 156920 (1.27917 iter/s, 31.2704s/40 iters), loss = 1.4251
I1028 11:10:57.785570  9023 solver.cpp:241]     Train net output #0: loss = 1.4251 (* 1 = 1.4251 loss)
I1028 11:10:57.785589  9023 sgd_solver.cpp:105] Iteration 156920, lr = 0.000460671
I1028 11:11:28.772301  9023 solver.cpp:222] Iteration 156960 (1.29092 iter/s, 30.9856s/40 iters), loss = 1.42177
I1028 11:11:28.772524  9023 solver.cpp:241]     Train net output #0: loss = 1.42177 (* 1 = 1.42177 loss)
I1028 11:11:28.772541  9023 sgd_solver.cpp:105] Iteration 156960, lr = 0.000458981
I1028 11:11:59.262053  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_157000.caffemodel
I1028 11:11:59.305318  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_157000.solverstate
I1028 11:11:59.331676  9023 solver.cpp:334] Iteration 157000, Testing net (#0)
I1028 11:12:30.343616  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 11:12:30.552361  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58316
I1028 11:12:30.552431  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813199
I1028 11:12:30.552445  9023 solver.cpp:401]     Test net output #2: loss = 1.85824 (* 1 = 1.85824 loss)
I1028 11:12:31.327901  9023 solver.cpp:222] Iteration 157000 (0.639457 iter/s, 62.553s/40 iters), loss = 1.23107
I1028 11:12:31.327966  9023 solver.cpp:241]     Train net output #0: loss = 1.23107 (* 1 = 1.23107 loss)
I1028 11:12:31.327981  9023 sgd_solver.cpp:105] Iteration 157000, lr = 0.000457292
I1028 11:13:02.391572  9023 solver.cpp:222] Iteration 157040 (1.28773 iter/s, 31.0624s/40 iters), loss = 1.38972
I1028 11:13:02.391760  9023 solver.cpp:241]     Train net output #0: loss = 1.38972 (* 1 = 1.38972 loss)
I1028 11:13:02.391778  9023 sgd_solver.cpp:105] Iteration 157040, lr = 0.000455604
I1028 11:13:33.385555  9023 solver.cpp:222] Iteration 157080 (1.29063 iter/s, 30.9926s/40 iters), loss = 1.49494
I1028 11:13:33.385730  9023 solver.cpp:241]     Train net output #0: loss = 1.49494 (* 1 = 1.49494 loss)
I1028 11:13:33.385746  9023 sgd_solver.cpp:105] Iteration 157080, lr = 0.000453917
I1028 11:13:33.443974  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1028 11:14:04.329701  9023 solver.cpp:222] Iteration 157120 (1.29271 iter/s, 30.9428s/40 iters), loss = 1.38505
I1028 11:14:04.329897  9023 solver.cpp:241]     Train net output #0: loss = 1.38505 (* 1 = 1.38505 loss)
I1028 11:14:04.329915  9023 sgd_solver.cpp:105] Iteration 157120, lr = 0.000452231
I1028 11:14:35.306679  9023 solver.cpp:222] Iteration 157160 (1.29134 iter/s, 30.9756s/40 iters), loss = 1.31644
I1028 11:14:35.306857  9023 solver.cpp:241]     Train net output #0: loss = 1.31644 (* 1 = 1.31644 loss)
I1028 11:14:35.306880  9023 sgd_solver.cpp:105] Iteration 157160, lr = 0.000450546
I1028 11:15:05.960350  9023 solver.cpp:222] Iteration 157200 (1.30496 iter/s, 30.6523s/40 iters), loss = 1.46682
I1028 11:15:05.960528  9023 solver.cpp:241]     Train net output #0: loss = 1.46682 (* 1 = 1.46682 loss)
I1028 11:15:05.960544  9023 sgd_solver.cpp:105] Iteration 157200, lr = 0.000448862
I1028 11:15:36.771337  9023 solver.cpp:222] Iteration 157240 (1.2983 iter/s, 30.8096s/40 iters), loss = 1.66027
I1028 11:15:36.771517  9023 solver.cpp:241]     Train net output #0: loss = 1.66027 (* 1 = 1.66027 loss)
I1028 11:15:36.771536  9023 sgd_solver.cpp:105] Iteration 157240, lr = 0.00044718
I1028 11:16:07.607455  9023 solver.cpp:222] Iteration 157280 (1.29724 iter/s, 30.8348s/40 iters), loss = 1.3277
I1028 11:16:07.607637  9023 solver.cpp:241]     Train net output #0: loss = 1.3277 (* 1 = 1.3277 loss)
I1028 11:16:07.607653  9023 sgd_solver.cpp:105] Iteration 157280, lr = 0.000445498
I1028 11:16:38.393390  9023 solver.cpp:222] Iteration 157320 (1.29935 iter/s, 30.7846s/40 iters), loss = 1.26607
I1028 11:16:38.393568  9023 solver.cpp:241]     Train net output #0: loss = 1.26607 (* 1 = 1.26607 loss)
I1028 11:16:38.393586  9023 sgd_solver.cpp:105] Iteration 157320, lr = 0.000443817
I1028 11:17:09.450322  9023 solver.cpp:222] Iteration 157360 (1.28801 iter/s, 31.0556s/40 iters), loss = 1.11975
I1028 11:17:09.450512  9023 solver.cpp:241]     Train net output #0: loss = 1.11975 (* 1 = 1.11975 loss)
I1028 11:17:09.450529  9023 sgd_solver.cpp:105] Iteration 157360, lr = 0.000442138
I1028 11:17:40.382419  9023 solver.cpp:222] Iteration 157400 (1.29321 iter/s, 30.9307s/40 iters), loss = 1.30139
I1028 11:17:40.382601  9023 solver.cpp:241]     Train net output #0: loss = 1.30139 (* 1 = 1.30139 loss)
I1028 11:17:40.382645  9023 sgd_solver.cpp:105] Iteration 157400, lr = 0.000440459
I1028 11:18:11.288769  9023 solver.cpp:222] Iteration 157440 (1.29429 iter/s, 30.905s/40 iters), loss = 1.18645
I1028 11:18:11.289021  9023 solver.cpp:241]     Train net output #0: loss = 1.18645 (* 1 = 1.18645 loss)
I1028 11:18:11.289042  9023 sgd_solver.cpp:105] Iteration 157440, lr = 0.000438782
I1028 11:18:42.056659  9023 solver.cpp:222] Iteration 157480 (1.30012 iter/s, 30.7665s/40 iters), loss = 1.28028
I1028 11:18:42.056828  9023 solver.cpp:241]     Train net output #0: loss = 1.28028 (* 1 = 1.28028 loss)
I1028 11:18:42.056845  9023 sgd_solver.cpp:105] Iteration 157480, lr = 0.000437106
I1028 11:18:56.668386  9023 solver.cpp:334] Iteration 157500, Testing net (#0)
I1028 11:19:28.086308  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58604
I1028 11:19:28.086460  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80864
I1028 11:19:28.086475  9023 solver.cpp:401]     Test net output #2: loss = 1.83166 (* 1 = 1.83166 loss)
I1028 11:19:44.597695  9023 solver.cpp:222] Iteration 157520 (0.639606 iter/s, 62.5385s/40 iters), loss = 1.28295
I1028 11:19:44.597769  9023 solver.cpp:241]     Train net output #0: loss = 1.28295 (* 1 = 1.28295 loss)
I1028 11:19:44.597785  9023 sgd_solver.cpp:105] Iteration 157520, lr = 0.00043543
I1028 11:20:15.631616  9023 solver.cpp:222] Iteration 157560 (1.28896 iter/s, 31.0327s/40 iters), loss = 1.39739
I1028 11:20:15.631824  9023 solver.cpp:241]     Train net output #0: loss = 1.39739 (* 1 = 1.39739 loss)
I1028 11:20:15.631844  9023 sgd_solver.cpp:105] Iteration 157560, lr = 0.000433756
I1028 11:20:46.420182  9023 solver.cpp:222] Iteration 157600 (1.29924 iter/s, 30.7872s/40 iters), loss = 1.51218
I1028 11:20:46.420373  9023 solver.cpp:241]     Train net output #0: loss = 1.51218 (* 1 = 1.51218 loss)
I1028 11:20:46.420398  9023 sgd_solver.cpp:105] Iteration 157600, lr = 0.000432083
I1028 11:21:17.322065  9023 solver.cpp:222] Iteration 157640 (1.29448 iter/s, 30.9005s/40 iters), loss = 1.33716
I1028 11:21:17.322259  9023 solver.cpp:241]     Train net output #0: loss = 1.33716 (* 1 = 1.33716 loss)
I1028 11:21:17.322278  9023 sgd_solver.cpp:105] Iteration 157640, lr = 0.000430411
I1028 11:21:48.192049  9023 solver.cpp:222] Iteration 157680 (1.29581 iter/s, 30.8686s/40 iters), loss = 1.41536
I1028 11:21:48.192224  9023 solver.cpp:241]     Train net output #0: loss = 1.41536 (* 1 = 1.41536 loss)
I1028 11:21:48.192245  9023 sgd_solver.cpp:105] Iteration 157680, lr = 0.00042874
I1028 11:22:19.801910  9023 solver.cpp:222] Iteration 157720 (1.26548 iter/s, 31.6085s/40 iters), loss = 1.23307
I1028 11:22:19.802126  9023 solver.cpp:241]     Train net output #0: loss = 1.23307 (* 1 = 1.23307 loss)
I1028 11:22:19.802145  9023 sgd_solver.cpp:105] Iteration 157720, lr = 0.00042707
I1028 11:22:49.868132  9023 solver.cpp:222] Iteration 157760 (1.33046 iter/s, 30.0649s/40 iters), loss = 1.44033
I1028 11:22:49.868322  9023 solver.cpp:241]     Train net output #0: loss = 1.44033 (* 1 = 1.44033 loss)
I1028 11:22:49.868343  9023 sgd_solver.cpp:105] Iteration 157760, lr = 0.000425402
I1028 11:23:20.514883  9023 solver.cpp:222] Iteration 157800 (1.30525 iter/s, 30.6454s/40 iters), loss = 1.66273
I1028 11:23:20.515048  9023 solver.cpp:241]     Train net output #0: loss = 1.66273 (* 1 = 1.66273 loss)
I1028 11:23:20.515064  9023 sgd_solver.cpp:105] Iteration 157800, lr = 0.000423734
I1028 11:23:51.771937  9023 solver.cpp:222] Iteration 157840 (1.27977 iter/s, 31.2557s/40 iters), loss = 1.25796
I1028 11:23:51.772116  9023 solver.cpp:241]     Train net output #0: loss = 1.25796 (* 1 = 1.25796 loss)
I1028 11:23:51.772133  9023 sgd_solver.cpp:105] Iteration 157840, lr = 0.000422067
I1028 11:24:22.807663  9023 solver.cpp:222] Iteration 157880 (1.28889 iter/s, 31.0344s/40 iters), loss = 1.48895
I1028 11:24:22.807857  9023 solver.cpp:241]     Train net output #0: loss = 1.48895 (* 1 = 1.48895 loss)
I1028 11:24:22.807875  9023 sgd_solver.cpp:105] Iteration 157880, lr = 0.000420402
I1028 11:24:54.259438  9023 solver.cpp:222] Iteration 157920 (1.27184 iter/s, 31.4504s/40 iters), loss = 1.54036
I1028 11:24:54.259665  9023 solver.cpp:241]     Train net output #0: loss = 1.54036 (* 1 = 1.54036 loss)
I1028 11:24:54.259686  9023 sgd_solver.cpp:105] Iteration 157920, lr = 0.000418737
I1028 11:25:25.313417  9023 solver.cpp:222] Iteration 157960 (1.28814 iter/s, 31.0526s/40 iters), loss = 1.33619
I1028 11:25:25.313612  9023 solver.cpp:241]     Train net output #0: loss = 1.33619 (* 1 = 1.33619 loss)
I1028 11:25:25.313634  9023 sgd_solver.cpp:105] Iteration 157960, lr = 0.000417074
I1028 11:25:56.468716  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_158000.caffemodel
I1028 11:25:56.745448  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_158000.solverstate
I1028 11:25:56.771632  9023 solver.cpp:334] Iteration 158000, Testing net (#0)
I1028 11:26:29.140158  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 11:26:29.352591  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58408
I1028 11:26:29.352663  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81208
I1028 11:26:29.352677  9023 solver.cpp:401]     Test net output #2: loss = 1.83633 (* 1 = 1.83633 loss)
I1028 11:26:30.119014  9023 solver.cpp:222] Iteration 158000 (0.617256 iter/s, 64.803s/40 iters), loss = 1.22755
I1028 11:26:30.119084  9023 solver.cpp:241]     Train net output #0: loss = 1.22755 (* 1 = 1.22755 loss)
I1028 11:26:30.119102  9023 sgd_solver.cpp:105] Iteration 158000, lr = 0.000415412
I1028 11:27:06.424424  9023 solver.cpp:222] Iteration 158040 (1.10181 iter/s, 36.304s/40 iters), loss = 1.37714
I1028 11:27:06.424608  9023 solver.cpp:241]     Train net output #0: loss = 1.37714 (* 1 = 1.37714 loss)
I1028 11:27:06.424626  9023 sgd_solver.cpp:105] Iteration 158040, lr = 0.00041375
I1028 11:27:39.786569  9023 solver.cpp:222] Iteration 158080 (1.19902 iter/s, 33.3607s/40 iters), loss = 1.28247
I1028 11:27:39.786794  9023 solver.cpp:241]     Train net output #0: loss = 1.28247 (* 1 = 1.28247 loss)
I1028 11:27:39.786818  9023 sgd_solver.cpp:105] Iteration 158080, lr = 0.000412091
I1028 11:28:12.650728  9023 solver.cpp:222] Iteration 158120 (1.21719 iter/s, 32.8627s/40 iters), loss = 1.36756
I1028 11:28:12.650928  9023 solver.cpp:241]     Train net output #0: loss = 1.36756 (* 1 = 1.36756 loss)
I1028 11:28:12.650944  9023 sgd_solver.cpp:105] Iteration 158120, lr = 0.000410432
I1028 11:28:43.699069  9023 solver.cpp:222] Iteration 158160 (1.28837 iter/s, 31.047s/40 iters), loss = 1.08419
I1028 11:28:43.699311  9023 solver.cpp:241]     Train net output #0: loss = 1.08419 (* 1 = 1.08419 loss)
I1028 11:28:43.699340  9023 sgd_solver.cpp:105] Iteration 158160, lr = 0.000408774
I1028 11:29:15.324208  9023 solver.cpp:222] Iteration 158200 (1.26487 iter/s, 31.6237s/40 iters), loss = 1.66638
I1028 11:29:15.324388  9023 solver.cpp:241]     Train net output #0: loss = 1.66638 (* 1 = 1.66638 loss)
I1028 11:29:15.324405  9023 sgd_solver.cpp:105] Iteration 158200, lr = 0.000407117
I1028 11:29:46.506528  9023 solver.cpp:222] Iteration 158240 (1.28283 iter/s, 31.181s/40 iters), loss = 1.47602
I1028 11:29:46.506753  9023 solver.cpp:241]     Train net output #0: loss = 1.47602 (* 1 = 1.47602 loss)
I1028 11:29:46.506772  9023 sgd_solver.cpp:105] Iteration 158240, lr = 0.000405462
I1028 11:30:17.784656  9023 solver.cpp:222] Iteration 158280 (1.27891 iter/s, 31.2767s/40 iters), loss = 1.31553
I1028 11:30:17.784867  9023 solver.cpp:241]     Train net output #0: loss = 1.31553 (* 1 = 1.31553 loss)
I1028 11:30:17.784884  9023 sgd_solver.cpp:105] Iteration 158280, lr = 0.000403807
I1028 11:30:49.203352  9023 solver.cpp:222] Iteration 158320 (1.27318 iter/s, 31.4173s/40 iters), loss = 1.16062
I1028 11:30:49.203567  9023 solver.cpp:241]     Train net output #0: loss = 1.16062 (* 1 = 1.16062 loss)
I1028 11:30:49.203594  9023 sgd_solver.cpp:105] Iteration 158320, lr = 0.000402154
I1028 11:31:20.212098  9023 solver.cpp:222] Iteration 158360 (1.29002 iter/s, 31.0074s/40 iters), loss = 1.30945
I1028 11:31:20.212530  9023 solver.cpp:241]     Train net output #0: loss = 1.30945 (* 1 = 1.30945 loss)
I1028 11:31:20.212553  9023 sgd_solver.cpp:105] Iteration 158360, lr = 0.000400502
I1028 11:31:51.205852  9023 solver.cpp:222] Iteration 158400 (1.29065 iter/s, 30.9922s/40 iters), loss = 1.32819
I1028 11:31:51.206053  9023 solver.cpp:241]     Train net output #0: loss = 1.32819 (* 1 = 1.32819 loss)
I1028 11:31:51.206070  9023 sgd_solver.cpp:105] Iteration 158400, lr = 0.000398851
I1028 11:32:22.107929  9023 solver.cpp:222] Iteration 158440 (1.29447 iter/s, 30.9007s/40 iters), loss = 1.35407
I1028 11:32:22.108120  9023 solver.cpp:241]     Train net output #0: loss = 1.35407 (* 1 = 1.35407 loss)
I1028 11:32:22.108137  9023 sgd_solver.cpp:105] Iteration 158440, lr = 0.000397201
I1028 11:32:52.848623  9023 solver.cpp:222] Iteration 158480 (1.30126 iter/s, 30.7393s/40 iters), loss = 1.22067
I1028 11:32:52.848801  9023 solver.cpp:241]     Train net output #0: loss = 1.22067 (* 1 = 1.22067 loss)
I1028 11:32:52.848817  9023 sgd_solver.cpp:105] Iteration 158480, lr = 0.000395553
I1028 11:33:07.634829  9023 solver.cpp:334] Iteration 158500, Testing net (#0)
I1028 11:33:38.914793  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58392
I1028 11:33:38.914991  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.807
I1028 11:33:38.915009  9023 solver.cpp:401]     Test net output #2: loss = 1.82518 (* 1 = 1.82518 loss)
I1028 11:33:55.399242  9023 solver.cpp:222] Iteration 158520 (0.639508 iter/s, 62.5481s/40 iters), loss = 1.59079
I1028 11:33:55.399322  9023 solver.cpp:241]     Train net output #0: loss = 1.59079 (* 1 = 1.59079 loss)
I1028 11:33:55.399338  9023 sgd_solver.cpp:105] Iteration 158520, lr = 0.000393905
I1028 11:34:26.620616  9023 solver.cpp:222] Iteration 158560 (1.28123 iter/s, 31.2201s/40 iters), loss = 1.50739
I1028 11:34:26.620832  9023 solver.cpp:241]     Train net output #0: loss = 1.50739 (* 1 = 1.50739 loss)
I1028 11:34:26.620851  9023 sgd_solver.cpp:105] Iteration 158560, lr = 0.000392259
I1028 11:34:57.614442  9023 solver.cpp:222] Iteration 158600 (1.29064 iter/s, 30.9924s/40 iters), loss = 1.7456
I1028 11:34:57.614619  9023 solver.cpp:241]     Train net output #0: loss = 1.7456 (* 1 = 1.7456 loss)
I1028 11:34:57.614634  9023 sgd_solver.cpp:105] Iteration 158600, lr = 0.000390613
I1028 11:35:28.569646  9023 solver.cpp:222] Iteration 158640 (1.29225 iter/s, 30.9539s/40 iters), loss = 1.54583
I1028 11:35:28.569845  9023 solver.cpp:241]     Train net output #0: loss = 1.54583 (* 1 = 1.54583 loss)
I1028 11:35:28.569864  9023 sgd_solver.cpp:105] Iteration 158640, lr = 0.000388969
I1028 11:35:59.870870  9023 solver.cpp:222] Iteration 158680 (1.27796 iter/s, 31.2998s/40 iters), loss = 1.48694
I1028 11:35:59.871057  9023 solver.cpp:241]     Train net output #0: loss = 1.48694 (* 1 = 1.48694 loss)
I1028 11:35:59.871073  9023 sgd_solver.cpp:105] Iteration 158680, lr = 0.000387326
I1028 11:36:30.799687  9023 solver.cpp:222] Iteration 158720 (1.29335 iter/s, 30.9275s/40 iters), loss = 1.46955
I1028 11:36:30.799875  9023 solver.cpp:241]     Train net output #0: loss = 1.46955 (* 1 = 1.46955 loss)
I1028 11:36:30.799890  9023 sgd_solver.cpp:105] Iteration 158720, lr = 0.000385685
I1028 11:37:02.543717  9023 solver.cpp:222] Iteration 158760 (1.26013 iter/s, 31.7426s/40 iters), loss = 1.39597
I1028 11:37:02.543895  9023 solver.cpp:241]     Train net output #0: loss = 1.39597 (* 1 = 1.39597 loss)
I1028 11:37:02.543911  9023 sgd_solver.cpp:105] Iteration 158760, lr = 0.000384044
I1028 11:37:33.735749  9023 solver.cpp:222] Iteration 158800 (1.28243 iter/s, 31.1907s/40 iters), loss = 1.81294
I1028 11:37:33.735930  9023 solver.cpp:241]     Train net output #0: loss = 1.81294 (* 1 = 1.81294 loss)
I1028 11:37:33.735947  9023 sgd_solver.cpp:105] Iteration 158800, lr = 0.000382404
I1028 11:38:05.514091  9023 solver.cpp:222] Iteration 158840 (1.25877 iter/s, 31.777s/40 iters), loss = 1.47775
I1028 11:38:05.514359  9023 solver.cpp:241]     Train net output #0: loss = 1.47775 (* 1 = 1.47775 loss)
I1028 11:38:05.514405  9023 sgd_solver.cpp:105] Iteration 158840, lr = 0.000380766
I1028 11:38:37.515518  9023 solver.cpp:222] Iteration 158880 (1.25 iter/s, 32s/40 iters), loss = 1.61258
I1028 11:38:37.515785  9023 solver.cpp:241]     Train net output #0: loss = 1.61258 (* 1 = 1.61258 loss)
I1028 11:38:37.515803  9023 sgd_solver.cpp:105] Iteration 158880, lr = 0.000379129
I1028 11:39:08.420866  9023 solver.cpp:222] Iteration 158920 (1.29433 iter/s, 30.9039s/40 iters), loss = 1.93817
I1028 11:39:08.421041  9023 solver.cpp:241]     Train net output #0: loss = 1.93817 (* 1 = 1.93817 loss)
I1028 11:39:08.421057  9023 sgd_solver.cpp:105] Iteration 158920, lr = 0.000377493
I1028 11:39:40.369835  9023 solver.cpp:222] Iteration 158960 (1.25205 iter/s, 31.9476s/40 iters), loss = 1.29787
I1028 11:39:40.370087  9023 solver.cpp:241]     Train net output #0: loss = 1.29787 (* 1 = 1.29787 loss)
I1028 11:39:40.370118  9023 sgd_solver.cpp:105] Iteration 158960, lr = 0.000375858
I1028 11:40:10.892053  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_159000.caffemodel
I1028 11:40:10.933713  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_159000.solverstate
I1028 11:40:10.955909  9023 solver.cpp:334] Iteration 159000, Testing net (#0)
I1028 11:40:42.092417  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 11:40:42.300662  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58388
I1028 11:40:42.300727  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81448
I1028 11:40:42.300741  9023 solver.cpp:401]     Test net output #2: loss = 1.84251 (* 1 = 1.84251 loss)
I1028 11:40:43.068689  9023 solver.cpp:222] Iteration 159000 (0.637997 iter/s, 62.6963s/40 iters), loss = 1.24286
I1028 11:40:43.068753  9023 solver.cpp:241]     Train net output #0: loss = 1.24286 (* 1 = 1.24286 loss)
I1028 11:40:43.068768  9023 sgd_solver.cpp:105] Iteration 159000, lr = 0.000374225
I1028 11:41:14.046275  9023 solver.cpp:222] Iteration 159040 (1.29131 iter/s, 30.9763s/40 iters), loss = 1.17997
I1028 11:41:14.046504  9023 solver.cpp:241]     Train net output #0: loss = 1.17997 (* 1 = 1.17997 loss)
I1028 11:41:14.046522  9023 sgd_solver.cpp:105] Iteration 159040, lr = 0.000372592
I1028 11:41:45.057250  9023 solver.cpp:222] Iteration 159080 (1.28992 iter/s, 31.0096s/40 iters), loss = 1.19896
I1028 11:41:45.057453  9023 solver.cpp:241]     Train net output #0: loss = 1.19896 (* 1 = 1.19896 loss)
I1028 11:41:45.057472  9023 sgd_solver.cpp:105] Iteration 159080, lr = 0.000370961
I1028 11:42:15.993957  9023 solver.cpp:222] Iteration 159120 (1.29302 iter/s, 30.9353s/40 iters), loss = 1.19959
I1028 11:42:15.994130  9023 solver.cpp:241]     Train net output #0: loss = 1.19959 (* 1 = 1.19959 loss)
I1028 11:42:15.994146  9023 sgd_solver.cpp:105] Iteration 159120, lr = 0.000369331
I1028 11:42:46.831812  9023 solver.cpp:222] Iteration 159160 (1.29716 iter/s, 30.8365s/40 iters), loss = 1.45569
I1028 11:42:46.831982  9023 solver.cpp:241]     Train net output #0: loss = 1.45569 (* 1 = 1.45569 loss)
I1028 11:42:46.832000  9023 sgd_solver.cpp:105] Iteration 159160, lr = 0.000367702
I1028 11:43:17.638528  9023 solver.cpp:222] Iteration 159200 (1.29847 iter/s, 30.8054s/40 iters), loss = 1.75397
I1028 11:43:17.638695  9023 solver.cpp:241]     Train net output #0: loss = 1.75397 (* 1 = 1.75397 loss)
I1028 11:43:17.638711  9023 sgd_solver.cpp:105] Iteration 159200, lr = 0.000366075
I1028 11:43:49.337159  9023 solver.cpp:222] Iteration 159240 (1.26194 iter/s, 31.6973s/40 iters), loss = 1.48022
I1028 11:43:49.337347  9023 solver.cpp:241]     Train net output #0: loss = 1.48022 (* 1 = 1.48022 loss)
I1028 11:43:49.337364  9023 sgd_solver.cpp:105] Iteration 159240, lr = 0.000364448
I1028 11:44:20.097371  9023 solver.cpp:222] Iteration 159280 (1.30044 iter/s, 30.7589s/40 iters), loss = 1.56534
I1028 11:44:20.097550  9023 solver.cpp:241]     Train net output #0: loss = 1.56534 (* 1 = 1.56534 loss)
I1028 11:44:20.097580  9023 sgd_solver.cpp:105] Iteration 159280, lr = 0.000362823
I1028 11:44:50.775081  9023 solver.cpp:222] Iteration 159320 (1.30394 iter/s, 30.6764s/40 iters), loss = 1.38032
I1028 11:44:50.775426  9023 solver.cpp:241]     Train net output #0: loss = 1.38032 (* 1 = 1.38032 loss)
I1028 11:44:50.775449  9023 sgd_solver.cpp:105] Iteration 159320, lr = 0.000361199
I1028 11:45:21.451998  9023 solver.cpp:222] Iteration 159360 (1.30398 iter/s, 30.6754s/40 iters), loss = 1.67268
I1028 11:45:21.452175  9023 solver.cpp:241]     Train net output #0: loss = 1.67268 (* 1 = 1.67268 loss)
I1028 11:45:21.452191  9023 sgd_solver.cpp:105] Iteration 159360, lr = 0.000359576
I1028 11:45:52.336307  9023 solver.cpp:222] Iteration 159400 (1.29521 iter/s, 30.883s/40 iters), loss = 1.51442
I1028 11:45:52.336486  9023 solver.cpp:241]     Train net output #0: loss = 1.51442 (* 1 = 1.51442 loss)
I1028 11:45:52.336504  9023 sgd_solver.cpp:105] Iteration 159400, lr = 0.000357955
I1028 11:46:23.226547  9023 solver.cpp:222] Iteration 159440 (1.29496 iter/s, 30.8889s/40 iters), loss = 1.65329
I1028 11:46:23.226727  9023 solver.cpp:241]     Train net output #0: loss = 1.65329 (* 1 = 1.65329 loss)
I1028 11:46:23.226743  9023 sgd_solver.cpp:105] Iteration 159440, lr = 0.000356334
I1028 11:46:54.392973  9023 solver.cpp:222] Iteration 159480 (1.28349 iter/s, 31.165s/40 iters), loss = 1.61461
I1028 11:46:54.393142  9023 solver.cpp:241]     Train net output #0: loss = 1.61461 (* 1 = 1.61461 loss)
I1028 11:46:54.393159  9023 sgd_solver.cpp:105] Iteration 159480, lr = 0.000354716
I1028 11:47:09.161361  9023 solver.cpp:334] Iteration 159500, Testing net (#0)
I1028 11:47:40.736354  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58476
I1028 11:47:40.736541  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.808799
I1028 11:47:40.736557  9023 solver.cpp:401]     Test net output #2: loss = 1.84555 (* 1 = 1.84555 loss)
I1028 11:47:56.900923  9023 solver.cpp:222] Iteration 159520 (0.639944 iter/s, 62.5054s/40 iters), loss = 1.35369
I1028 11:47:56.900997  9023 solver.cpp:241]     Train net output #0: loss = 1.35369 (* 1 = 1.35369 loss)
I1028 11:47:56.901016  9023 sgd_solver.cpp:105] Iteration 159520, lr = 0.000353098
I1028 11:48:28.185389  9023 solver.cpp:222] Iteration 159560 (1.27864 iter/s, 31.2832s/40 iters), loss = 1.3518
I1028 11:48:28.185565  9023 solver.cpp:241]     Train net output #0: loss = 1.3518 (* 1 = 1.3518 loss)
I1028 11:48:28.185582  9023 sgd_solver.cpp:105] Iteration 159560, lr = 0.000351481
I1028 11:48:45.618564  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1028 11:48:59.231045  9023 solver.cpp:222] Iteration 159600 (1.28848 iter/s, 31.0443s/40 iters), loss = 1.08602
I1028 11:48:59.231214  9023 solver.cpp:241]     Train net output #0: loss = 1.08602 (* 1 = 1.08602 loss)
I1028 11:48:59.231230  9023 sgd_solver.cpp:105] Iteration 159600, lr = 0.000349866
I1028 11:49:30.245270  9023 solver.cpp:222] Iteration 159640 (1.28979 iter/s, 31.0129s/40 iters), loss = 1.35075
I1028 11:49:30.245471  9023 solver.cpp:241]     Train net output #0: loss = 1.35075 (* 1 = 1.35075 loss)
I1028 11:49:30.245489  9023 sgd_solver.cpp:105] Iteration 159640, lr = 0.000348251
I1028 11:50:01.342489  9023 solver.cpp:222] Iteration 159680 (1.28635 iter/s, 31.0959s/40 iters), loss = 1.4219
I1028 11:50:01.342658  9023 solver.cpp:241]     Train net output #0: loss = 1.4219 (* 1 = 1.4219 loss)
I1028 11:50:01.342679  9023 sgd_solver.cpp:105] Iteration 159680, lr = 0.000346639
I1028 11:50:32.420861  9023 solver.cpp:222] Iteration 159720 (1.28712 iter/s, 31.077s/40 iters), loss = 1.28967
I1028 11:50:32.421073  9023 solver.cpp:241]     Train net output #0: loss = 1.28967 (* 1 = 1.28967 loss)
I1028 11:50:32.421092  9023 sgd_solver.cpp:105] Iteration 159720, lr = 0.000345027
I1028 11:51:03.527896  9023 solver.cpp:222] Iteration 159760 (1.28594 iter/s, 31.1057s/40 iters), loss = 1.18069
I1028 11:51:03.528101  9023 solver.cpp:241]     Train net output #0: loss = 1.18069 (* 1 = 1.18069 loss)
I1028 11:51:03.528133  9023 sgd_solver.cpp:105] Iteration 159760, lr = 0.000343417
I1028 11:51:34.825588  9023 solver.cpp:222] Iteration 159800 (1.27811 iter/s, 31.2963s/40 iters), loss = 1.11694
I1028 11:51:34.825811  9023 solver.cpp:241]     Train net output #0: loss = 1.11694 (* 1 = 1.11694 loss)
I1028 11:51:34.825829  9023 sgd_solver.cpp:105] Iteration 159800, lr = 0.000341807
I1028 11:52:05.930249  9023 solver.cpp:222] Iteration 159840 (1.28604 iter/s, 31.1033s/40 iters), loss = 1.19363
I1028 11:52:05.930426  9023 solver.cpp:241]     Train net output #0: loss = 1.19363 (* 1 = 1.19363 loss)
I1028 11:52:05.930444  9023 sgd_solver.cpp:105] Iteration 159840, lr = 0.000340199
I1028 11:52:36.915998  9023 solver.cpp:222] Iteration 159880 (1.29097 iter/s, 30.9844s/40 iters), loss = 1.51064
I1028 11:52:36.916162  9023 solver.cpp:241]     Train net output #0: loss = 1.51064 (* 1 = 1.51064 loss)
I1028 11:52:36.916178  9023 sgd_solver.cpp:105] Iteration 159880, lr = 0.000338593
I1028 11:53:07.832267  9023 solver.cpp:222] Iteration 159920 (1.29387 iter/s, 30.9149s/40 iters), loss = 1.55017
I1028 11:53:07.832444  9023 solver.cpp:241]     Train net output #0: loss = 1.55017 (* 1 = 1.55017 loss)
I1028 11:53:07.832460  9023 sgd_solver.cpp:105] Iteration 159920, lr = 0.000336987
I1028 11:53:38.592526  9023 solver.cpp:222] Iteration 159960 (1.30044 iter/s, 30.7589s/40 iters), loss = 1.31756
I1028 11:53:38.592699  9023 solver.cpp:241]     Train net output #0: loss = 1.31756 (* 1 = 1.31756 loss)
I1028 11:53:38.592715  9023 sgd_solver.cpp:105] Iteration 159960, lr = 0.000335384
I1028 11:54:08.891921  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_160000.caffemodel
I1028 11:54:08.923591  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_160000.solverstate
I1028 11:54:08.940376  9023 solver.cpp:334] Iteration 160000, Testing net (#0)
I1028 11:54:40.423130  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 11:54:40.634696  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58344
I1028 11:54:40.634759  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81212
I1028 11:54:40.634773  9023 solver.cpp:401]     Test net output #2: loss = 1.84424 (* 1 = 1.84424 loss)
I1028 11:54:41.403376  9023 solver.cpp:222] Iteration 160000 (0.636858 iter/s, 62.8083s/40 iters), loss = 1.40935
I1028 11:54:41.403443  9023 solver.cpp:241]     Train net output #0: loss = 1.40935 (* 1 = 1.40935 loss)
I1028 11:54:41.403460  9023 sgd_solver.cpp:105] Iteration 160000, lr = 0.000333781
I1028 11:55:12.243923  9023 solver.cpp:222] Iteration 160040 (1.29705 iter/s, 30.8393s/40 iters), loss = 1.89741
I1028 11:55:12.244120  9023 solver.cpp:241]     Train net output #0: loss = 1.89741 (* 1 = 1.89741 loss)
I1028 11:55:12.244141  9023 sgd_solver.cpp:105] Iteration 160040, lr = 0.000332179
I1028 11:55:43.362483  9023 solver.cpp:222] Iteration 160080 (1.28546 iter/s, 31.1172s/40 iters), loss = 1.2806
I1028 11:55:43.362681  9023 solver.cpp:241]     Train net output #0: loss = 1.2806 (* 1 = 1.2806 loss)
I1028 11:55:43.362699  9023 sgd_solver.cpp:105] Iteration 160080, lr = 0.000330579
I1028 11:56:14.688063  9023 solver.cpp:222] Iteration 160120 (1.27697 iter/s, 31.3242s/40 iters), loss = 1.12441
I1028 11:56:14.688266  9023 solver.cpp:241]     Train net output #0: loss = 1.12441 (* 1 = 1.12441 loss)
I1028 11:56:14.688284  9023 sgd_solver.cpp:105] Iteration 160120, lr = 0.00032898
I1028 11:56:55.769457  9023 solver.cpp:222] Iteration 160160 (0.973718 iter/s, 41.0797s/40 iters), loss = 1.29911
I1028 11:56:55.769645  9023 solver.cpp:241]     Train net output #0: loss = 1.29911 (* 1 = 1.29911 loss)
I1028 11:56:55.769662  9023 sgd_solver.cpp:105] Iteration 160160, lr = 0.000327383
I1028 11:57:27.202375  9023 solver.cpp:222] Iteration 160200 (1.27261 iter/s, 31.4315s/40 iters), loss = 1.07021
I1028 11:57:27.202550  9023 solver.cpp:241]     Train net output #0: loss = 1.07021 (* 1 = 1.07021 loss)
I1028 11:57:27.202566  9023 sgd_solver.cpp:105] Iteration 160200, lr = 0.000325786
I1028 11:57:58.175448  9023 solver.cpp:222] Iteration 160240 (1.2915 iter/s, 30.9717s/40 iters), loss = 1.58852
I1028 11:57:58.175689  9023 solver.cpp:241]     Train net output #0: loss = 1.58852 (* 1 = 1.58852 loss)
I1028 11:57:58.175712  9023 sgd_solver.cpp:105] Iteration 160240, lr = 0.000324191
I1028 11:58:29.492766  9023 solver.cpp:222] Iteration 160280 (1.27731 iter/s, 31.3159s/40 iters), loss = 1.27432
I1028 11:58:29.493032  9023 solver.cpp:241]     Train net output #0: loss = 1.27432 (* 1 = 1.27432 loss)
I1028 11:58:29.493058  9023 sgd_solver.cpp:105] Iteration 160280, lr = 0.000322597
I1028 11:59:02.656069  9023 solver.cpp:222] Iteration 160320 (1.20621 iter/s, 33.1618s/40 iters), loss = 1.37184
I1028 11:59:02.656355  9023 solver.cpp:241]     Train net output #0: loss = 1.37184 (* 1 = 1.37184 loss)
I1028 11:59:02.656384  9023 sgd_solver.cpp:105] Iteration 160320, lr = 0.000321005
I1028 11:59:35.131454  9023 solver.cpp:222] Iteration 160360 (1.23176 iter/s, 32.4739s/40 iters), loss = 1.62208
I1028 11:59:35.131642  9023 solver.cpp:241]     Train net output #0: loss = 1.62208 (* 1 = 1.62208 loss)
I1028 11:59:35.131659  9023 sgd_solver.cpp:105] Iteration 160360, lr = 0.000319414
I1028 12:00:06.578362  9023 solver.cpp:222] Iteration 160400 (1.27204 iter/s, 31.4455s/40 iters), loss = 1.32251
I1028 12:00:06.578553  9023 solver.cpp:241]     Train net output #0: loss = 1.32251 (* 1 = 1.32251 loss)
I1028 12:00:06.578573  9023 sgd_solver.cpp:105] Iteration 160400, lr = 0.000317824
I1028 12:00:39.035830  9023 solver.cpp:222] Iteration 160440 (1.23244 iter/s, 32.456s/40 iters), loss = 1.48195
I1028 12:00:39.036088  9023 solver.cpp:241]     Train net output #0: loss = 1.48195 (* 1 = 1.48195 loss)
I1028 12:00:39.036118  9023 sgd_solver.cpp:105] Iteration 160440, lr = 0.000316236
I1028 12:01:11.673740  9023 solver.cpp:222] Iteration 160480 (1.22562 iter/s, 32.6364s/40 iters), loss = 1.1957
I1028 12:01:11.674006  9023 solver.cpp:241]     Train net output #0: loss = 1.1957 (* 1 = 1.1957 loss)
I1028 12:01:11.674034  9023 sgd_solver.cpp:105] Iteration 160480, lr = 0.000314648
I1028 12:01:27.220182  9023 solver.cpp:334] Iteration 160500, Testing net (#0)
I1028 12:01:58.610014  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58588
I1028 12:01:58.610210  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80924
I1028 12:01:58.610225  9023 solver.cpp:401]     Test net output #2: loss = 1.82855 (* 1 = 1.82855 loss)
I1028 12:02:14.803519  9023 solver.cpp:222] Iteration 160520 (0.633642 iter/s, 63.1272s/40 iters), loss = 1.42261
I1028 12:02:14.803591  9023 solver.cpp:241]     Train net output #0: loss = 1.42261 (* 1 = 1.42261 loss)
I1028 12:02:14.803607  9023 sgd_solver.cpp:105] Iteration 160520, lr = 0.000313063
I1028 12:02:45.984096  9023 solver.cpp:222] Iteration 160560 (1.2829 iter/s, 31.1793s/40 iters), loss = 1.48992
I1028 12:02:45.984311  9023 solver.cpp:241]     Train net output #0: loss = 1.48992 (* 1 = 1.48992 loss)
I1028 12:02:45.984329  9023 sgd_solver.cpp:105] Iteration 160560, lr = 0.000311478
I1028 12:03:16.986187  9023 solver.cpp:222] Iteration 160600 (1.29029 iter/s, 31.0007s/40 iters), loss = 1.50505
I1028 12:03:16.986363  9023 solver.cpp:241]     Train net output #0: loss = 1.50505 (* 1 = 1.50505 loss)
I1028 12:03:16.986382  9023 sgd_solver.cpp:105] Iteration 160600, lr = 0.000309895
I1028 12:03:48.101192  9023 solver.cpp:222] Iteration 160640 (1.28561 iter/s, 31.1137s/40 iters), loss = 1.3191
I1028 12:03:48.101413  9023 solver.cpp:241]     Train net output #0: loss = 1.3191 (* 1 = 1.3191 loss)
I1028 12:03:48.101428  9023 sgd_solver.cpp:105] Iteration 160640, lr = 0.000308313
I1028 12:04:19.556835  9023 solver.cpp:222] Iteration 160680 (1.27169 iter/s, 31.4542s/40 iters), loss = 1.37999
I1028 12:04:19.557026  9023 solver.cpp:241]     Train net output #0: loss = 1.37999 (* 1 = 1.37999 loss)
I1028 12:04:19.557044  9023 sgd_solver.cpp:105] Iteration 160680, lr = 0.000306733
I1028 12:04:50.408401  9023 solver.cpp:222] Iteration 160720 (1.29659 iter/s, 30.8502s/40 iters), loss = 1.32163
I1028 12:04:50.408671  9023 solver.cpp:241]     Train net output #0: loss = 1.32163 (* 1 = 1.32163 loss)
I1028 12:04:50.408689  9023 sgd_solver.cpp:105] Iteration 160720, lr = 0.000305154
I1028 12:05:21.465874  9023 solver.cpp:222] Iteration 160760 (1.28799 iter/s, 31.056s/40 iters), loss = 1.65401
I1028 12:05:21.466068  9023 solver.cpp:241]     Train net output #0: loss = 1.65401 (* 1 = 1.65401 loss)
I1028 12:05:21.466085  9023 sgd_solver.cpp:105] Iteration 160760, lr = 0.000303576
I1028 12:05:52.336735  9023 solver.cpp:222] Iteration 160800 (1.29578 iter/s, 30.8695s/40 iters), loss = 1.17015
I1028 12:05:52.336916  9023 solver.cpp:241]     Train net output #0: loss = 1.17015 (* 1 = 1.17015 loss)
I1028 12:05:52.336933  9023 sgd_solver.cpp:105] Iteration 160800, lr = 0.000302
I1028 12:06:23.097228  9023 solver.cpp:222] Iteration 160840 (1.30043 iter/s, 30.7591s/40 iters), loss = 1.43244
I1028 12:06:23.097404  9023 solver.cpp:241]     Train net output #0: loss = 1.43244 (* 1 = 1.43244 loss)
I1028 12:06:23.097426  9023 sgd_solver.cpp:105] Iteration 160840, lr = 0.000300425
I1028 12:06:54.725235  9023 solver.cpp:222] Iteration 160880 (1.26476 iter/s, 31.6266s/40 iters), loss = 1.02372
I1028 12:06:54.725426  9023 solver.cpp:241]     Train net output #0: loss = 1.02372 (* 1 = 1.02372 loss)
I1028 12:06:54.725443  9023 sgd_solver.cpp:105] Iteration 160880, lr = 0.000298851
I1028 12:07:25.422946  9023 solver.cpp:222] Iteration 160920 (1.30309 iter/s, 30.6964s/40 iters), loss = 1.1861
I1028 12:07:25.423127  9023 solver.cpp:241]     Train net output #0: loss = 1.1861 (* 1 = 1.1861 loss)
I1028 12:07:25.423144  9023 sgd_solver.cpp:105] Iteration 160920, lr = 0.000297279
I1028 12:07:56.482041  9023 solver.cpp:222] Iteration 160960 (1.28792 iter/s, 31.0577s/40 iters), loss = 1.28525
I1028 12:07:56.482237  9023 solver.cpp:241]     Train net output #0: loss = 1.28525 (* 1 = 1.28525 loss)
I1028 12:07:56.482254  9023 sgd_solver.cpp:105] Iteration 160960, lr = 0.000295708
I1028 12:08:26.932770  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_161000.caffemodel
I1028 12:08:26.965626  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_161000.solverstate
I1028 12:08:26.983546  9023 solver.cpp:334] Iteration 161000, Testing net (#0)
I1028 12:08:58.346312  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 12:08:58.557894  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5846
I1028 12:08:58.557960  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81448
I1028 12:08:58.557976  9023 solver.cpp:401]     Test net output #2: loss = 1.8319 (* 1 = 1.8319 loss)
I1028 12:08:59.342804  9023 solver.cpp:222] Iteration 161000 (0.636353 iter/s, 62.8582s/40 iters), loss = 1.19941
I1028 12:08:59.342872  9023 solver.cpp:241]     Train net output #0: loss = 1.19941 (* 1 = 1.19941 loss)
I1028 12:08:59.342890  9023 sgd_solver.cpp:105] Iteration 161000, lr = 0.000294139
I1028 12:09:30.670042  9023 solver.cpp:222] Iteration 161040 (1.2769 iter/s, 31.326s/40 iters), loss = 1.63771
I1028 12:09:30.670236  9023 solver.cpp:241]     Train net output #0: loss = 1.63771 (* 1 = 1.63771 loss)
I1028 12:09:30.670253  9023 sgd_solver.cpp:105] Iteration 161040, lr = 0.000292571
I1028 12:10:01.614459  9023 solver.cpp:222] Iteration 161080 (1.2927 iter/s, 30.9431s/40 iters), loss = 1.48621
I1028 12:10:01.614629  9023 solver.cpp:241]     Train net output #0: loss = 1.48621 (* 1 = 1.48621 loss)
I1028 12:10:01.614646  9023 sgd_solver.cpp:105] Iteration 161080, lr = 0.000291004
I1028 12:10:33.065657  9023 solver.cpp:222] Iteration 161120 (1.27187 iter/s, 31.4498s/40 iters), loss = 1.24493
I1028 12:10:33.065861  9023 solver.cpp:241]     Train net output #0: loss = 1.24493 (* 1 = 1.24493 loss)
I1028 12:10:33.065879  9023 sgd_solver.cpp:105] Iteration 161120, lr = 0.000289439
I1028 12:11:04.337107  9023 solver.cpp:222] Iteration 161160 (1.27918 iter/s, 31.2701s/40 iters), loss = 1.32159
I1028 12:11:04.337393  9023 solver.cpp:241]     Train net output #0: loss = 1.32159 (* 1 = 1.32159 loss)
I1028 12:11:04.337409  9023 sgd_solver.cpp:105] Iteration 161160, lr = 0.000287875
I1028 12:11:35.787106  9023 solver.cpp:222] Iteration 161200 (1.27192 iter/s, 31.4485s/40 iters), loss = 1.21634
I1028 12:11:35.787292  9023 solver.cpp:241]     Train net output #0: loss = 1.21634 (* 1 = 1.21634 loss)
I1028 12:11:35.787313  9023 sgd_solver.cpp:105] Iteration 161200, lr = 0.000286313
I1028 12:12:07.426339  9023 solver.cpp:222] Iteration 161240 (1.26431 iter/s, 31.6379s/40 iters), loss = 1.12025
I1028 12:12:07.426532  9023 solver.cpp:241]     Train net output #0: loss = 1.12025 (* 1 = 1.12025 loss)
I1028 12:12:07.426548  9023 sgd_solver.cpp:105] Iteration 161240, lr = 0.000284752
I1028 12:12:38.677803  9023 solver.cpp:222] Iteration 161280 (1.28 iter/s, 31.2501s/40 iters), loss = 1.24155
I1028 12:12:38.677991  9023 solver.cpp:241]     Train net output #0: loss = 1.24155 (* 1 = 1.24155 loss)
I1028 12:12:38.678007  9023 sgd_solver.cpp:105] Iteration 161280, lr = 0.000283192
I1028 12:13:10.268709  9023 solver.cpp:222] Iteration 161320 (1.26624 iter/s, 31.5895s/40 iters), loss = 1.45038
I1028 12:13:10.268932  9023 solver.cpp:241]     Train net output #0: loss = 1.45038 (* 1 = 1.45038 loss)
I1028 12:13:10.268955  9023 sgd_solver.cpp:105] Iteration 161320, lr = 0.000281634
I1028 12:13:41.416220  9023 solver.cpp:222] Iteration 161360 (1.28427 iter/s, 31.1461s/40 iters), loss = 1.3225
I1028 12:13:41.416396  9023 solver.cpp:241]     Train net output #0: loss = 1.3225 (* 1 = 1.3225 loss)
I1028 12:13:41.416414  9023 sgd_solver.cpp:105] Iteration 161360, lr = 0.000280077
I1028 12:14:12.214706  9023 solver.cpp:222] Iteration 161400 (1.29882 iter/s, 30.7971s/40 iters), loss = 1.53279
I1028 12:14:12.214885  9023 solver.cpp:241]     Train net output #0: loss = 1.53279 (* 1 = 1.53279 loss)
I1028 12:14:12.214902  9023 sgd_solver.cpp:105] Iteration 161400, lr = 0.000278522
I1028 12:14:44.166890  9023 solver.cpp:222] Iteration 161440 (1.25192 iter/s, 31.9508s/40 iters), loss = 1.2867
I1028 12:14:44.167109  9023 solver.cpp:241]     Train net output #0: loss = 1.2867 (* 1 = 1.2867 loss)
I1028 12:14:44.167132  9023 sgd_solver.cpp:105] Iteration 161440, lr = 0.000276968
I1028 12:15:15.563869  9023 solver.cpp:222] Iteration 161480 (1.27406 iter/s, 31.3956s/40 iters), loss = 1.36955
I1028 12:15:15.564055  9023 solver.cpp:241]     Train net output #0: loss = 1.36955 (* 1 = 1.36955 loss)
I1028 12:15:15.564074  9023 sgd_solver.cpp:105] Iteration 161480, lr = 0.000275416
I1028 12:15:30.339526  9023 solver.cpp:334] Iteration 161500, Testing net (#0)
I1028 12:16:01.881011  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58708
I1028 12:16:01.881208  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8096
I1028 12:16:01.881230  9023 solver.cpp:401]     Test net output #2: loss = 1.82363 (* 1 = 1.82363 loss)
I1028 12:16:18.039222  9023 solver.cpp:222] Iteration 161520 (0.640278 iter/s, 62.4728s/40 iters), loss = 1.50745
I1028 12:16:18.039294  9023 solver.cpp:241]     Train net output #0: loss = 1.50745 (* 1 = 1.50745 loss)
I1028 12:16:18.039315  9023 sgd_solver.cpp:105] Iteration 161520, lr = 0.000273865
I1028 12:16:48.890360  9023 solver.cpp:222] Iteration 161560 (1.2966 iter/s, 30.8499s/40 iters), loss = 1.50054
I1028 12:16:48.890576  9023 solver.cpp:241]     Train net output #0: loss = 1.50054 (* 1 = 1.50054 loss)
I1028 12:16:48.890600  9023 sgd_solver.cpp:105] Iteration 161560, lr = 0.000272315
I1028 12:17:19.683255  9023 solver.cpp:222] Iteration 161600 (1.29906 iter/s, 30.7915s/40 iters), loss = 1.14606
I1028 12:17:19.683854  9023 solver.cpp:241]     Train net output #0: loss = 1.14606 (* 1 = 1.14606 loss)
I1028 12:17:19.683871  9023 sgd_solver.cpp:105] Iteration 161600, lr = 0.000270767
I1028 12:17:50.715737  9023 solver.cpp:222] Iteration 161640 (1.28905 iter/s, 31.0307s/40 iters), loss = 1.16258
I1028 12:17:50.715934  9023 solver.cpp:241]     Train net output #0: loss = 1.16258 (* 1 = 1.16258 loss)
I1028 12:17:50.715950  9023 sgd_solver.cpp:105] Iteration 161640, lr = 0.000269221
I1028 12:18:21.531225  9023 solver.cpp:222] Iteration 161680 (1.29811 iter/s, 30.8141s/40 iters), loss = 1.43202
I1028 12:18:21.531474  9023 solver.cpp:241]     Train net output #0: loss = 1.43202 (* 1 = 1.43202 loss)
I1028 12:18:21.531496  9023 sgd_solver.cpp:105] Iteration 161680, lr = 0.000267676
I1028 12:18:52.448333  9023 solver.cpp:222] Iteration 161720 (1.29384 iter/s, 30.9157s/40 iters), loss = 1.22247
I1028 12:18:52.448496  9023 solver.cpp:241]     Train net output #0: loss = 1.22247 (* 1 = 1.22247 loss)
I1028 12:18:52.448515  9023 sgd_solver.cpp:105] Iteration 161720, lr = 0.000266132
I1028 12:19:23.531524  9023 solver.cpp:222] Iteration 161760 (1.28692 iter/s, 31.0819s/40 iters), loss = 1.40907
I1028 12:19:23.531703  9023 solver.cpp:241]     Train net output #0: loss = 1.40907 (* 1 = 1.40907 loss)
I1028 12:19:23.531724  9023 sgd_solver.cpp:105] Iteration 161760, lr = 0.00026459
I1028 12:19:54.729537  9023 solver.cpp:222] Iteration 161800 (1.28219 iter/s, 31.1967s/40 iters), loss = 1.45125
I1028 12:19:54.729717  9023 solver.cpp:241]     Train net output #0: loss = 1.45125 (* 1 = 1.45125 loss)
I1028 12:19:54.729737  9023 sgd_solver.cpp:105] Iteration 161800, lr = 0.00026305
I1028 12:20:26.426442  9023 solver.cpp:222] Iteration 161840 (1.26201 iter/s, 31.6955s/40 iters), loss = 1.30926
I1028 12:20:26.426681  9023 solver.cpp:241]     Train net output #0: loss = 1.30926 (* 1 = 1.30926 loss)
I1028 12:20:26.426705  9023 sgd_solver.cpp:105] Iteration 161840, lr = 0.000261511
I1028 12:21:00.876590  9023 solver.cpp:222] Iteration 161880 (1.16115 iter/s, 34.4486s/40 iters), loss = 1.40718
I1028 12:21:00.876785  9023 solver.cpp:241]     Train net output #0: loss = 1.40718 (* 1 = 1.40718 loss)
I1028 12:21:00.876806  9023 sgd_solver.cpp:105] Iteration 161880, lr = 0.000259973
I1028 12:21:37.030637  9023 solver.cpp:222] Iteration 161920 (1.10642 iter/s, 36.1525s/40 iters), loss = 1.55869
I1028 12:21:37.030854  9023 solver.cpp:241]     Train net output #0: loss = 1.55869 (* 1 = 1.55869 loss)
I1028 12:21:37.030872  9023 sgd_solver.cpp:105] Iteration 161920, lr = 0.000258437
I1028 12:22:07.944897  9023 solver.cpp:222] Iteration 161960 (1.29396 iter/s, 30.9129s/40 iters), loss = 1.12516
I1028 12:22:07.945071  9023 solver.cpp:241]     Train net output #0: loss = 1.12516 (* 1 = 1.12516 loss)
I1028 12:22:07.945088  9023 sgd_solver.cpp:105] Iteration 161960, lr = 0.000256903
I1028 12:22:38.144040  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_162000.caffemodel
I1028 12:22:38.176507  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_162000.solverstate
I1028 12:22:38.193253  9023 solver.cpp:334] Iteration 162000, Testing net (#0)
I1028 12:23:09.265935  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 12:23:09.474423  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58492
I1028 12:23:09.474488  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.815199
I1028 12:23:09.474503  9023 solver.cpp:401]     Test net output #2: loss = 1.83724 (* 1 = 1.83724 loss)
I1028 12:23:10.245425  9023 solver.cpp:222] Iteration 162000 (0.642075 iter/s, 62.298s/40 iters), loss = 1.28777
I1028 12:23:10.245499  9023 solver.cpp:241]     Train net output #0: loss = 1.28777 (* 1 = 1.28777 loss)
I1028 12:23:10.245515  9023 sgd_solver.cpp:105] Iteration 162000, lr = 0.00025537
I1028 12:23:41.107662  9023 solver.cpp:222] Iteration 162040 (1.29613 iter/s, 30.861s/40 iters), loss = 1.36563
I1028 12:23:41.107847  9023 solver.cpp:241]     Train net output #0: loss = 1.36563 (* 1 = 1.36563 loss)
I1028 12:23:41.107862  9023 sgd_solver.cpp:105] Iteration 162040, lr = 0.000253838
I1028 12:24:11.776165  9023 solver.cpp:222] Iteration 162080 (1.30433 iter/s, 30.6672s/40 iters), loss = 1.58203
I1028 12:24:11.776345  9023 solver.cpp:241]     Train net output #0: loss = 1.58203 (* 1 = 1.58203 loss)
I1028 12:24:11.776361  9023 sgd_solver.cpp:105] Iteration 162080, lr = 0.000252308
I1028 12:24:14.958196  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1028 12:24:42.532344  9023 solver.cpp:222] Iteration 162120 (1.30061 iter/s, 30.7548s/40 iters), loss = 1.21377
I1028 12:24:42.532595  9023 solver.cpp:241]     Train net output #0: loss = 1.21377 (* 1 = 1.21377 loss)
I1028 12:24:42.532613  9023 sgd_solver.cpp:105] Iteration 162120, lr = 0.00025078
I1028 12:25:13.552845  9023 solver.cpp:222] Iteration 162160 (1.28953 iter/s, 31.0191s/40 iters), loss = 1.37206
I1028 12:25:13.553055  9023 solver.cpp:241]     Train net output #0: loss = 1.37206 (* 1 = 1.37206 loss)
I1028 12:25:13.553071  9023 sgd_solver.cpp:105] Iteration 162160, lr = 0.000249253
I1028 12:25:44.323233  9023 solver.cpp:222] Iteration 162200 (1.30001 iter/s, 30.769s/40 iters), loss = 1.55072
I1028 12:25:44.323412  9023 solver.cpp:241]     Train net output #0: loss = 1.55072 (* 1 = 1.55072 loss)
I1028 12:25:44.323428  9023 sgd_solver.cpp:105] Iteration 162200, lr = 0.000247728
I1028 12:26:15.154062  9023 solver.cpp:222] Iteration 162240 (1.29746 iter/s, 30.8295s/40 iters), loss = 1.52355
I1028 12:26:15.154259  9023 solver.cpp:241]     Train net output #0: loss = 1.52355 (* 1 = 1.52355 loss)
I1028 12:26:15.154276  9023 sgd_solver.cpp:105] Iteration 162240, lr = 0.000246204
I1028 12:26:46.542625  9023 solver.cpp:222] Iteration 162280 (1.27441 iter/s, 31.3872s/40 iters), loss = 1.23254
I1028 12:26:46.542817  9023 solver.cpp:241]     Train net output #0: loss = 1.23254 (* 1 = 1.23254 loss)
I1028 12:26:46.542834  9023 sgd_solver.cpp:105] Iteration 162280, lr = 0.000244682
I1028 12:27:17.327632  9023 solver.cpp:222] Iteration 162320 (1.29939 iter/s, 30.7837s/40 iters), loss = 1.35465
I1028 12:27:17.327824  9023 solver.cpp:241]     Train net output #0: loss = 1.35465 (* 1 = 1.35465 loss)
I1028 12:27:17.327843  9023 sgd_solver.cpp:105] Iteration 162320, lr = 0.000243161
I1028 12:27:58.692677  9078 blocking_queue.cpp:49] Waiting for data
I1028 12:28:11.976069  9023 solver.cpp:222] Iteration 162360 (0.731981 iter/s, 54.6462s/40 iters), loss = 1.09387
I1028 12:28:11.976143  9023 solver.cpp:241]     Train net output #0: loss = 1.09387 (* 1 = 1.09387 loss)
I1028 12:28:11.976160  9023 sgd_solver.cpp:105] Iteration 162360, lr = 0.000241643
I1028 12:28:43.458966  9023 solver.cpp:222] Iteration 162400 (1.27058 iter/s, 31.4816s/40 iters), loss = 1.19426
I1028 12:28:43.459161  9023 solver.cpp:241]     Train net output #0: loss = 1.19426 (* 1 = 1.19426 loss)
I1028 12:28:43.459177  9023 sgd_solver.cpp:105] Iteration 162400, lr = 0.000240125
I1028 12:29:14.367044  9023 solver.cpp:222] Iteration 162440 (1.29422 iter/s, 30.9067s/40 iters), loss = 1.32334
I1028 12:29:14.367208  9023 solver.cpp:241]     Train net output #0: loss = 1.32334 (* 1 = 1.32334 loss)
I1028 12:29:14.367224  9023 sgd_solver.cpp:105] Iteration 162440, lr = 0.000238609
I1028 12:29:45.358080  9023 solver.cpp:222] Iteration 162480 (1.29075 iter/s, 30.9897s/40 iters), loss = 0.958616
I1028 12:29:45.358256  9023 solver.cpp:241]     Train net output #0: loss = 0.958616 (* 1 = 0.958616 loss)
I1028 12:29:45.358273  9023 sgd_solver.cpp:105] Iteration 162480, lr = 0.000237095
I1028 12:30:00.019680  9023 solver.cpp:334] Iteration 162500, Testing net (#0)
I1028 12:30:31.463021  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58808
I1028 12:30:31.463205  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80948
I1028 12:30:31.463222  9023 solver.cpp:401]     Test net output #2: loss = 1.82802 (* 1 = 1.82802 loss)
I1028 12:30:48.479863  9023 solver.cpp:222] Iteration 162520 (0.633721 iter/s, 63.1193s/40 iters), loss = 1.75515
I1028 12:30:48.479943  9023 solver.cpp:241]     Train net output #0: loss = 1.75515 (* 1 = 1.75515 loss)
I1028 12:30:48.479957  9023 sgd_solver.cpp:105] Iteration 162520, lr = 0.000235583
I1028 12:31:29.810328  9023 solver.cpp:222] Iteration 162560 (0.967847 iter/s, 41.3288s/40 iters), loss = 1.37055
I1028 12:31:29.810555  9023 solver.cpp:241]     Train net output #0: loss = 1.37055 (* 1 = 1.37055 loss)
I1028 12:31:29.810590  9023 sgd_solver.cpp:105] Iteration 162560, lr = 0.000234072
I1028 12:32:02.498395  9023 solver.cpp:222] Iteration 162600 (1.22374 iter/s, 32.6866s/40 iters), loss = 1.24291
I1028 12:32:02.498636  9023 solver.cpp:241]     Train net output #0: loss = 1.24291 (* 1 = 1.24291 loss)
I1028 12:32:02.498656  9023 sgd_solver.cpp:105] Iteration 162600, lr = 0.000232562
I1028 12:32:34.240456  9023 solver.cpp:222] Iteration 162640 (1.26021 iter/s, 31.7406s/40 iters), loss = 1.37407
I1028 12:32:34.240662  9023 solver.cpp:241]     Train net output #0: loss = 1.37407 (* 1 = 1.37407 loss)
I1028 12:32:34.240680  9023 sgd_solver.cpp:105] Iteration 162640, lr = 0.000231055
I1028 12:33:05.362339  9023 solver.cpp:222] Iteration 162680 (1.28533 iter/s, 31.1205s/40 iters), loss = 1.69679
I1028 12:33:05.362532  9023 solver.cpp:241]     Train net output #0: loss = 1.69679 (* 1 = 1.69679 loss)
I1028 12:33:05.362550  9023 sgd_solver.cpp:105] Iteration 162680, lr = 0.000229548
I1028 12:33:37.026028  9023 solver.cpp:222] Iteration 162720 (1.26333 iter/s, 31.6623s/40 iters), loss = 1.58489
I1028 12:33:37.026204  9023 solver.cpp:241]     Train net output #0: loss = 1.58489 (* 1 = 1.58489 loss)
I1028 12:33:37.026221  9023 sgd_solver.cpp:105] Iteration 162720, lr = 0.000228044
I1028 12:34:13.466931  9023 solver.cpp:222] Iteration 162760 (1.09771 iter/s, 36.4394s/40 iters), loss = 1.48413
I1028 12:34:13.467133  9023 solver.cpp:241]     Train net output #0: loss = 1.48413 (* 1 = 1.48413 loss)
I1028 12:34:13.467149  9023 sgd_solver.cpp:105] Iteration 162760, lr = 0.000226541
I1028 12:34:50.263517  9023 solver.cpp:222] Iteration 162800 (1.0871 iter/s, 36.795s/40 iters), loss = 1.32749
I1028 12:34:50.263701  9023 solver.cpp:241]     Train net output #0: loss = 1.32749 (* 1 = 1.32749 loss)
I1028 12:34:50.263722  9023 sgd_solver.cpp:105] Iteration 162800, lr = 0.00022504
I1028 12:35:23.268177  9023 solver.cpp:222] Iteration 162840 (1.212 iter/s, 33.0032s/40 iters), loss = 1.172
I1028 12:35:23.268378  9023 solver.cpp:241]     Train net output #0: loss = 1.172 (* 1 = 1.172 loss)
I1028 12:35:23.268393  9023 sgd_solver.cpp:105] Iteration 162840, lr = 0.000223541
I1028 12:35:53.849961  9023 solver.cpp:222] Iteration 162880 (1.30803 iter/s, 30.5804s/40 iters), loss = 1.64392
I1028 12:35:53.850162  9023 solver.cpp:241]     Train net output #0: loss = 1.64392 (* 1 = 1.64392 loss)
I1028 12:35:53.850179  9023 sgd_solver.cpp:105] Iteration 162880, lr = 0.000222043
I1028 12:36:24.363548  9023 solver.cpp:222] Iteration 162920 (1.31095 iter/s, 30.5122s/40 iters), loss = 1.31876
I1028 12:36:24.363723  9023 solver.cpp:241]     Train net output #0: loss = 1.31876 (* 1 = 1.31876 loss)
I1028 12:36:24.363739  9023 sgd_solver.cpp:105] Iteration 162920, lr = 0.000220547
I1028 12:36:55.192910  9023 solver.cpp:222] Iteration 162960 (1.29752 iter/s, 30.828s/40 iters), loss = 1.50299
I1028 12:36:55.193075  9023 solver.cpp:241]     Train net output #0: loss = 1.50299 (* 1 = 1.50299 loss)
I1028 12:36:55.193091  9023 sgd_solver.cpp:105] Iteration 162960, lr = 0.000219053
I1028 12:37:25.300675  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_163000.caffemodel
I1028 12:37:25.333490  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_163000.solverstate
I1028 12:37:25.350898  9023 solver.cpp:334] Iteration 163000, Testing net (#0)
I1028 12:37:56.478613  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 12:37:56.687111  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58616
I1028 12:37:56.687176  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81464
I1028 12:37:56.687191  9023 solver.cpp:401]     Test net output #2: loss = 1.84174 (* 1 = 1.84174 loss)
I1028 12:37:57.464392  9023 solver.cpp:222] Iteration 163000 (0.642374 iter/s, 62.269s/40 iters), loss = 1.24067
I1028 12:37:57.464462  9023 solver.cpp:241]     Train net output #0: loss = 1.24067 (* 1 = 1.24067 loss)
I1028 12:37:57.464478  9023 sgd_solver.cpp:105] Iteration 163000, lr = 0.00021756
I1028 12:38:28.288338  9023 solver.cpp:222] Iteration 163040 (1.29774 iter/s, 30.8227s/40 iters), loss = 1.55365
I1028 12:38:28.288584  9023 solver.cpp:241]     Train net output #0: loss = 1.55365 (* 1 = 1.55365 loss)
I1028 12:38:28.288602  9023 sgd_solver.cpp:105] Iteration 163040, lr = 0.000216069
I1028 12:38:59.079977  9023 solver.cpp:222] Iteration 163080 (1.29911 iter/s, 30.7902s/40 iters), loss = 1.528
I1028 12:38:59.080170  9023 solver.cpp:241]     Train net output #0: loss = 1.528 (* 1 = 1.528 loss)
I1028 12:38:59.080186  9023 sgd_solver.cpp:105] Iteration 163080, lr = 0.00021458
I1028 12:39:30.406262  9023 solver.cpp:222] Iteration 163120 (1.27694 iter/s, 31.3249s/40 iters), loss = 1.41904
I1028 12:39:30.406452  9023 solver.cpp:241]     Train net output #0: loss = 1.41904 (* 1 = 1.41904 loss)
I1028 12:39:30.406471  9023 sgd_solver.cpp:105] Iteration 163120, lr = 0.000213092
I1028 12:40:01.642866  9023 solver.cpp:222] Iteration 163160 (1.2806 iter/s, 31.2352s/40 iters), loss = 1.34557
I1028 12:40:01.643050  9023 solver.cpp:241]     Train net output #0: loss = 1.34557 (* 1 = 1.34557 loss)
I1028 12:40:01.643066  9023 sgd_solver.cpp:105] Iteration 163160, lr = 0.000211606
I1028 12:40:32.951858  9023 solver.cpp:222] Iteration 163200 (1.27764 iter/s, 31.3076s/40 iters), loss = 1.46186
I1028 12:40:32.952059  9023 solver.cpp:241]     Train net output #0: loss = 1.46186 (* 1 = 1.46186 loss)
I1028 12:40:32.952076  9023 sgd_solver.cpp:105] Iteration 163200, lr = 0.000210122
I1028 12:41:03.964943  9023 solver.cpp:222] Iteration 163240 (1.28984 iter/s, 31.0117s/40 iters), loss = 1.4981
I1028 12:41:03.965152  9023 solver.cpp:241]     Train net output #0: loss = 1.4981 (* 1 = 1.4981 loss)
I1028 12:41:03.965170  9023 sgd_solver.cpp:105] Iteration 163240, lr = 0.00020864
I1028 12:41:35.958436  9023 solver.cpp:222] Iteration 163280 (1.25031 iter/s, 31.9921s/40 iters), loss = 1.03329
I1028 12:41:35.958662  9023 solver.cpp:241]     Train net output #0: loss = 1.03329 (* 1 = 1.03329 loss)
I1028 12:41:35.958684  9023 sgd_solver.cpp:105] Iteration 163280, lr = 0.000207159
I1028 12:42:07.155560  9023 solver.cpp:222] Iteration 163320 (1.28223 iter/s, 31.1957s/40 iters), loss = 1.44125
I1028 12:42:07.155737  9023 solver.cpp:241]     Train net output #0: loss = 1.44125 (* 1 = 1.44125 loss)
I1028 12:42:07.155755  9023 sgd_solver.cpp:105] Iteration 163320, lr = 0.00020568
I1028 12:42:37.972611  9023 solver.cpp:222] Iteration 163360 (1.29804 iter/s, 30.8157s/40 iters), loss = 1.4215
I1028 12:42:37.972791  9023 solver.cpp:241]     Train net output #0: loss = 1.4215 (* 1 = 1.4215 loss)
I1028 12:42:37.972811  9023 sgd_solver.cpp:105] Iteration 163360, lr = 0.000204203
I1028 12:43:08.808828  9023 solver.cpp:222] Iteration 163400 (1.29723 iter/s, 30.8349s/40 iters), loss = 1.40807
I1028 12:43:08.809027  9023 solver.cpp:241]     Train net output #0: loss = 1.40807 (* 1 = 1.40807 loss)
I1028 12:43:08.809044  9023 sgd_solver.cpp:105] Iteration 163400, lr = 0.000202728
I1028 12:43:40.213847  9023 solver.cpp:222] Iteration 163440 (1.27374 iter/s, 31.4036s/40 iters), loss = 1.1518
I1028 12:43:40.214012  9023 solver.cpp:241]     Train net output #0: loss = 1.1518 (* 1 = 1.1518 loss)
I1028 12:43:40.214028  9023 sgd_solver.cpp:105] Iteration 163440, lr = 0.000201255
I1028 12:44:11.218945  9023 solver.cpp:222] Iteration 163480 (1.29017 iter/s, 31.0038s/40 iters), loss = 0.971233
I1028 12:44:11.219141  9023 solver.cpp:241]     Train net output #0: loss = 0.971233 (* 1 = 0.971233 loss)
I1028 12:44:11.219158  9023 sgd_solver.cpp:105] Iteration 163480, lr = 0.000199783
I1028 12:44:26.012085  9023 solver.cpp:334] Iteration 163500, Testing net (#0)
I1028 12:44:57.405123  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58864
I1028 12:44:57.405315  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.811399
I1028 12:44:57.405333  9023 solver.cpp:401]     Test net output #2: loss = 1.82832 (* 1 = 1.82832 loss)
I1028 12:45:13.741528  9023 solver.cpp:222] Iteration 163520 (0.639795 iter/s, 62.5201s/40 iters), loss = 1.4752
I1028 12:45:13.741616  9023 solver.cpp:241]     Train net output #0: loss = 1.4752 (* 1 = 1.4752 loss)
I1028 12:45:13.741636  9023 sgd_solver.cpp:105] Iteration 163520, lr = 0.000198313
I1028 12:45:44.802292  9023 solver.cpp:222] Iteration 163560 (1.28785 iter/s, 31.0595s/40 iters), loss = 1.41666
I1028 12:45:44.802580  9023 solver.cpp:241]     Train net output #0: loss = 1.41666 (* 1 = 1.41666 loss)
I1028 12:45:44.802609  9023 sgd_solver.cpp:105] Iteration 163560, lr = 0.000196845
I1028 12:46:15.802286  9023 solver.cpp:222] Iteration 163600 (1.29038 iter/s, 30.9985s/40 iters), loss = 1.60617
I1028 12:46:15.802487  9023 solver.cpp:241]     Train net output #0: loss = 1.60617 (* 1 = 1.60617 loss)
I1028 12:46:15.802505  9023 sgd_solver.cpp:105] Iteration 163600, lr = 0.000195379
I1028 12:46:47.074427  9023 solver.cpp:222] Iteration 163640 (1.27915 iter/s, 31.2708s/40 iters), loss = 1.63486
I1028 12:46:47.074599  9023 solver.cpp:241]     Train net output #0: loss = 1.63486 (* 1 = 1.63486 loss)
I1028 12:46:47.074617  9023 sgd_solver.cpp:105] Iteration 163640, lr = 0.000193914
I1028 12:47:17.715852  9023 solver.cpp:222] Iteration 163680 (1.30548 iter/s, 30.6401s/40 iters), loss = 1.12407
I1028 12:47:17.716029  9023 solver.cpp:241]     Train net output #0: loss = 1.12407 (* 1 = 1.12407 loss)
I1028 12:47:17.716048  9023 sgd_solver.cpp:105] Iteration 163680, lr = 0.000192452
I1028 12:47:48.319607  9023 solver.cpp:222] Iteration 163720 (1.30709 iter/s, 30.6024s/40 iters), loss = 1.08505
I1028 12:47:48.319769  9023 solver.cpp:241]     Train net output #0: loss = 1.08505 (* 1 = 1.08505 loss)
I1028 12:47:48.319788  9023 sgd_solver.cpp:105] Iteration 163720, lr = 0.000190991
I1028 12:48:18.914839  9023 solver.cpp:222] Iteration 163760 (1.30745 iter/s, 30.5939s/40 iters), loss = 1.47222
I1028 12:48:18.915014  9023 solver.cpp:241]     Train net output #0: loss = 1.47222 (* 1 = 1.47222 loss)
I1028 12:48:18.915030  9023 sgd_solver.cpp:105] Iteration 163760, lr = 0.000189532
I1028 12:48:49.746232  9023 solver.cpp:222] Iteration 163800 (1.29744 iter/s, 30.83s/40 iters), loss = 1.43231
I1028 12:48:49.746392  9023 solver.cpp:241]     Train net output #0: loss = 1.43231 (* 1 = 1.43231 loss)
I1028 12:48:49.746408  9023 sgd_solver.cpp:105] Iteration 163800, lr = 0.000188075
I1028 12:49:20.607053  9023 solver.cpp:222] Iteration 163840 (1.2962 iter/s, 30.8595s/40 iters), loss = 1.73173
I1028 12:49:20.607254  9023 solver.cpp:241]     Train net output #0: loss = 1.73173 (* 1 = 1.73173 loss)
I1028 12:49:20.607273  9023 sgd_solver.cpp:105] Iteration 163840, lr = 0.00018662
I1028 12:49:51.584820  9023 solver.cpp:222] Iteration 163880 (1.29131 iter/s, 30.9764s/40 iters), loss = 1.36283
I1028 12:49:51.585047  9023 solver.cpp:241]     Train net output #0: loss = 1.36283 (* 1 = 1.36283 loss)
I1028 12:49:51.585065  9023 sgd_solver.cpp:105] Iteration 163880, lr = 0.000185167
I1028 12:50:22.332820  9023 solver.cpp:222] Iteration 163920 (1.30096 iter/s, 30.7466s/40 iters), loss = 1.35661
I1028 12:50:22.333020  9023 solver.cpp:241]     Train net output #0: loss = 1.35661 (* 1 = 1.35661 loss)
I1028 12:50:22.333036  9023 sgd_solver.cpp:105] Iteration 163920, lr = 0.000183715
I1028 12:50:53.558039  9023 solver.cpp:222] Iteration 163960 (1.28107 iter/s, 31.2238s/40 iters), loss = 1.53979
I1028 12:50:53.558239  9023 solver.cpp:241]     Train net output #0: loss = 1.53979 (* 1 = 1.53979 loss)
I1028 12:50:53.558257  9023 sgd_solver.cpp:105] Iteration 163960, lr = 0.000182266
I1028 12:51:24.410506  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_164000.caffemodel
I1028 12:51:24.453954  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_164000.solverstate
I1028 12:51:24.477380  9023 solver.cpp:334] Iteration 164000, Testing net (#0)
I1028 12:51:55.936565  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 12:51:56.147756  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58632
I1028 12:51:56.147821  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81568
I1028 12:51:56.147850  9023 solver.cpp:401]     Test net output #2: loss = 1.83337 (* 1 = 1.83337 loss)
I1028 12:51:56.918722  9023 solver.cpp:222] Iteration 164000 (0.631332 iter/s, 63.3581s/40 iters), loss = 1.51285
I1028 12:51:56.918787  9023 solver.cpp:241]     Train net output #0: loss = 1.51285 (* 1 = 1.51285 loss)
I1028 12:51:56.918802  9023 sgd_solver.cpp:105] Iteration 164000, lr = 0.000180818
I1028 12:52:29.907385  9023 solver.cpp:222] Iteration 164040 (1.21259 iter/s, 32.9873s/40 iters), loss = 1.61476
I1028 12:52:29.907713  9023 solver.cpp:241]     Train net output #0: loss = 1.61476 (* 1 = 1.61476 loss)
I1028 12:52:29.907742  9023 sgd_solver.cpp:105] Iteration 164040, lr = 0.000179373
I1028 12:53:01.851014  9023 solver.cpp:222] Iteration 164080 (1.25227 iter/s, 31.9421s/40 iters), loss = 1.58145
I1028 12:53:01.851248  9023 solver.cpp:241]     Train net output #0: loss = 1.58145 (* 1 = 1.58145 loss)
I1028 12:53:01.851267  9023 sgd_solver.cpp:105] Iteration 164080, lr = 0.000177929
I1028 12:53:32.016814  9023 solver.cpp:222] Iteration 164120 (1.32607 iter/s, 30.1644s/40 iters), loss = 1.17189
I1028 12:53:32.016993  9023 solver.cpp:241]     Train net output #0: loss = 1.17189 (* 1 = 1.17189 loss)
I1028 12:53:32.017009  9023 sgd_solver.cpp:105] Iteration 164120, lr = 0.000176487
I1028 12:54:03.000612  9023 solver.cpp:222] Iteration 164160 (1.29105 iter/s, 30.9824s/40 iters), loss = 1.33409
I1028 12:54:03.000787  9023 solver.cpp:241]     Train net output #0: loss = 1.33409 (* 1 = 1.33409 loss)
I1028 12:54:03.000804  9023 sgd_solver.cpp:105] Iteration 164160, lr = 0.000175048
I1028 12:54:34.322067  9023 solver.cpp:222] Iteration 164200 (1.27714 iter/s, 31.3201s/40 iters), loss = 1.20441
I1028 12:54:34.322257  9023 solver.cpp:241]     Train net output #0: loss = 1.20441 (* 1 = 1.20441 loss)
I1028 12:54:34.322279  9023 sgd_solver.cpp:105] Iteration 164200, lr = 0.00017361
I1028 12:55:05.748157  9023 solver.cpp:222] Iteration 164240 (1.27288 iter/s, 31.4247s/40 iters), loss = 1.22563
I1028 12:55:05.748373  9023 solver.cpp:241]     Train net output #0: loss = 1.22563 (* 1 = 1.22563 loss)
I1028 12:55:05.748390  9023 sgd_solver.cpp:105] Iteration 164240, lr = 0.000172174
I1028 12:55:36.393777  9023 solver.cpp:222] Iteration 164280 (1.3053 iter/s, 30.6442s/40 iters), loss = 1.47015
I1028 12:55:36.393966  9023 solver.cpp:241]     Train net output #0: loss = 1.47015 (* 1 = 1.47015 loss)
I1028 12:55:36.393982  9023 sgd_solver.cpp:105] Iteration 164280, lr = 0.00017074
I1028 12:56:07.619853  9023 solver.cpp:222] Iteration 164320 (1.28104 iter/s, 31.2247s/40 iters), loss = 1.47621
I1028 12:56:07.620064  9023 solver.cpp:241]     Train net output #0: loss = 1.47621 (* 1 = 1.47621 loss)
I1028 12:56:07.620084  9023 sgd_solver.cpp:105] Iteration 164320, lr = 0.000169309
I1028 12:56:38.325215  9023 solver.cpp:222] Iteration 164360 (1.30276 iter/s, 30.704s/40 iters), loss = 1.31271
I1028 12:56:38.325397  9023 solver.cpp:241]     Train net output #0: loss = 1.31271 (* 1 = 1.31271 loss)
I1028 12:56:38.325417  9023 sgd_solver.cpp:105] Iteration 164360, lr = 0.000167879
I1028 12:57:09.025382  9023 solver.cpp:222] Iteration 164400 (1.30298 iter/s, 30.6988s/40 iters), loss = 1.61392
I1028 12:57:09.025565  9023 solver.cpp:241]     Train net output #0: loss = 1.61392 (* 1 = 1.61392 loss)
I1028 12:57:09.025588  9023 sgd_solver.cpp:105] Iteration 164400, lr = 0.000166451
I1028 12:57:40.455653  9023 solver.cpp:222] Iteration 164440 (1.27271 iter/s, 31.4289s/40 iters), loss = 1.4755
I1028 12:57:40.455837  9023 solver.cpp:241]     Train net output #0: loss = 1.4755 (* 1 = 1.4755 loss)
I1028 12:57:40.455853  9023 sgd_solver.cpp:105] Iteration 164440, lr = 0.000165026
I1028 12:58:11.756361  9023 solver.cpp:222] Iteration 164480 (1.27798 iter/s, 31.2993s/40 iters), loss = 1.44271
I1028 12:58:11.756536  9023 solver.cpp:241]     Train net output #0: loss = 1.44271 (* 1 = 1.44271 loss)
I1028 12:58:11.756553  9023 sgd_solver.cpp:105] Iteration 164480, lr = 0.000163602
I1028 12:58:26.902498  9023 solver.cpp:334] Iteration 164500, Testing net (#0)
I1028 12:58:58.243225  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58892
I1028 12:58:58.243505  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.811119
I1028 12:58:58.243544  9023 solver.cpp:401]     Test net output #2: loss = 1.82181 (* 1 = 1.82181 loss)
I1028 12:59:14.841105  9023 solver.cpp:222] Iteration 164520 (0.634093 iter/s, 63.0822s/40 iters), loss = 1.65669
I1028 12:59:14.841181  9023 solver.cpp:241]     Train net output #0: loss = 1.65669 (* 1 = 1.65669 loss)
I1028 12:59:14.841200  9023 sgd_solver.cpp:105] Iteration 164520, lr = 0.00016218
I1028 12:59:46.977466  9023 solver.cpp:222] Iteration 164560 (1.24475 iter/s, 32.1351s/40 iters), loss = 1.27203
I1028 12:59:46.977696  9023 solver.cpp:241]     Train net output #0: loss = 1.27203 (* 1 = 1.27203 loss)
I1028 12:59:46.977718  9023 sgd_solver.cpp:105] Iteration 164560, lr = 0.000160761
I1028 13:00:20.253808  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1028 13:00:30.378854  9023 solver.cpp:222] Iteration 164600 (0.921669 iter/s, 43.3995s/40 iters), loss = 1.15313
I1028 13:00:30.378973  9023 solver.cpp:241]     Train net output #0: loss = 1.15313 (* 1 = 1.15313 loss)
I1028 13:00:30.379001  9023 sgd_solver.cpp:105] Iteration 164600, lr = 0.000159343
I1028 13:01:01.732882  9023 solver.cpp:222] Iteration 164640 (1.27581 iter/s, 31.3527s/40 iters), loss = 1.35461
I1028 13:01:01.733055  9023 solver.cpp:241]     Train net output #0: loss = 1.35461 (* 1 = 1.35461 loss)
I1028 13:01:01.733073  9023 sgd_solver.cpp:105] Iteration 164640, lr = 0.000157928
I1028 13:01:32.798629  9023 solver.cpp:222] Iteration 164680 (1.28765 iter/s, 31.0644s/40 iters), loss = 1.19739
I1028 13:01:32.798820  9023 solver.cpp:241]     Train net output #0: loss = 1.19739 (* 1 = 1.19739 loss)
I1028 13:01:32.798836  9023 sgd_solver.cpp:105] Iteration 164680, lr = 0.000156515
I1028 13:02:03.931885  9023 solver.cpp:222] Iteration 164720 (1.28486 iter/s, 31.1319s/40 iters), loss = 1.25872
I1028 13:02:03.932080  9023 solver.cpp:241]     Train net output #0: loss = 1.25872 (* 1 = 1.25872 loss)
I1028 13:02:03.932098  9023 sgd_solver.cpp:105] Iteration 164720, lr = 0.000155104
I1028 13:02:35.089594  9023 solver.cpp:222] Iteration 164760 (1.28385 iter/s, 31.1563s/40 iters), loss = 1.05951
I1028 13:02:35.089792  9023 solver.cpp:241]     Train net output #0: loss = 1.05951 (* 1 = 1.05951 loss)
I1028 13:02:35.089809  9023 sgd_solver.cpp:105] Iteration 164760, lr = 0.000153695
I1028 13:03:06.881141  9023 solver.cpp:222] Iteration 164800 (1.25825 iter/s, 31.7902s/40 iters), loss = 1.69542
I1028 13:03:06.881621  9023 solver.cpp:241]     Train net output #0: loss = 1.69542 (* 1 = 1.69542 loss)
I1028 13:03:06.881649  9023 sgd_solver.cpp:105] Iteration 164800, lr = 0.000152288
I1028 13:03:38.198366  9023 solver.cpp:222] Iteration 164840 (1.27732 iter/s, 31.3156s/40 iters), loss = 1.32407
I1028 13:03:38.198550  9023 solver.cpp:241]     Train net output #0: loss = 1.32407 (* 1 = 1.32407 loss)
I1028 13:03:38.198566  9023 sgd_solver.cpp:105] Iteration 164840, lr = 0.000150883
I1028 13:04:09.002977  9023 solver.cpp:222] Iteration 164880 (1.29856 iter/s, 30.8033s/40 iters), loss = 1.48603
I1028 13:04:09.003162  9023 solver.cpp:241]     Train net output #0: loss = 1.48603 (* 1 = 1.48603 loss)
I1028 13:04:09.003180  9023 sgd_solver.cpp:105] Iteration 164880, lr = 0.000149481
I1028 13:04:39.951019  9023 solver.cpp:222] Iteration 164920 (1.29255 iter/s, 30.9467s/40 iters), loss = 1.27726
I1028 13:04:39.951205  9023 solver.cpp:241]     Train net output #0: loss = 1.27726 (* 1 = 1.27726 loss)
I1028 13:04:39.951222  9023 sgd_solver.cpp:105] Iteration 164920, lr = 0.000148081
I1028 13:05:11.036623  9023 solver.cpp:222] Iteration 164960 (1.28683 iter/s, 31.0843s/40 iters), loss = 1.46036
I1028 13:05:11.036798  9023 solver.cpp:241]     Train net output #0: loss = 1.46036 (* 1 = 1.46036 loss)
I1028 13:05:11.036813  9023 sgd_solver.cpp:105] Iteration 164960, lr = 0.000146682
I1028 13:05:41.955387  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_165000.caffemodel
I1028 13:05:41.988783  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_165000.solverstate
I1028 13:05:42.007886  9023 solver.cpp:334] Iteration 165000, Testing net (#0)
I1028 13:06:13.161231  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 13:06:13.372524  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58784
I1028 13:06:13.372577  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.814399
I1028 13:06:13.372591  9023 solver.cpp:401]     Test net output #2: loss = 1.82538 (* 1 = 1.82538 loss)
I1028 13:06:14.141686  9023 solver.cpp:222] Iteration 165000 (0.633889 iter/s, 63.1025s/40 iters), loss = 1.44813
I1028 13:06:14.141727  9023 solver.cpp:241]     Train net output #0: loss = 1.44813 (* 1 = 1.44813 loss)
I1028 13:06:14.141742  9023 sgd_solver.cpp:105] Iteration 165000, lr = 0.000145287
I1028 13:06:45.287914  9023 solver.cpp:222] Iteration 165040 (1.28432 iter/s, 31.145s/40 iters), loss = 1.2876
I1028 13:06:45.288106  9023 solver.cpp:241]     Train net output #0: loss = 1.2876 (* 1 = 1.2876 loss)
I1028 13:06:45.288125  9023 sgd_solver.cpp:105] Iteration 165040, lr = 0.000143893
I1028 13:07:17.585059  9023 solver.cpp:222] Iteration 165080 (1.23855 iter/s, 32.2957s/40 iters), loss = 1.43616
I1028 13:07:17.585278  9023 solver.cpp:241]     Train net output #0: loss = 1.43616 (* 1 = 1.43616 loss)
I1028 13:07:17.585307  9023 sgd_solver.cpp:105] Iteration 165080, lr = 0.000142501
I1028 13:07:48.799156  9023 solver.cpp:222] Iteration 165120 (1.28153 iter/s, 31.2127s/40 iters), loss = 1.25302
I1028 13:07:48.799340  9023 solver.cpp:241]     Train net output #0: loss = 1.25302 (* 1 = 1.25302 loss)
I1028 13:07:48.799360  9023 sgd_solver.cpp:105] Iteration 165120, lr = 0.000141112
I1028 13:08:19.833511  9023 solver.cpp:222] Iteration 165160 (1.28895 iter/s, 31.033s/40 iters), loss = 1.48854
I1028 13:08:19.833700  9023 solver.cpp:241]     Train net output #0: loss = 1.48854 (* 1 = 1.48854 loss)
I1028 13:08:19.833716  9023 sgd_solver.cpp:105] Iteration 165160, lr = 0.000139725
I1028 13:08:50.990322  9023 solver.cpp:222] Iteration 165200 (1.28388 iter/s, 31.1555s/40 iters), loss = 1.37935
I1028 13:08:50.990497  9023 solver.cpp:241]     Train net output #0: loss = 1.37935 (* 1 = 1.37935 loss)
I1028 13:08:50.990514  9023 sgd_solver.cpp:105] Iteration 165200, lr = 0.000138341
I1028 13:09:21.932785  9023 solver.cpp:222] Iteration 165240 (1.29278 iter/s, 30.9411s/40 iters), loss = 1.1164
I1028 13:09:21.932947  9023 solver.cpp:241]     Train net output #0: loss = 1.1164 (* 1 = 1.1164 loss)
I1028 13:09:21.932963  9023 sgd_solver.cpp:105] Iteration 165240, lr = 0.000136959
I1028 13:09:52.977408  9023 solver.cpp:222] Iteration 165280 (1.28852 iter/s, 31.0433s/40 iters), loss = 1.64823
I1028 13:09:52.977620  9023 solver.cpp:241]     Train net output #0: loss = 1.64823 (* 1 = 1.64823 loss)
I1028 13:09:52.977643  9023 sgd_solver.cpp:105] Iteration 165280, lr = 0.000135579
I1028 13:10:23.717875  9023 solver.cpp:222] Iteration 165320 (1.30127 iter/s, 30.7391s/40 iters), loss = 1.26855
I1028 13:10:23.718065  9023 solver.cpp:241]     Train net output #0: loss = 1.26855 (* 1 = 1.26855 loss)
I1028 13:10:23.718081  9023 sgd_solver.cpp:105] Iteration 165320, lr = 0.000134201
I1028 13:10:54.211088  9023 solver.cpp:222] Iteration 165360 (1.31183 iter/s, 30.4919s/40 iters), loss = 1.12672
I1028 13:10:54.211264  9023 solver.cpp:241]     Train net output #0: loss = 1.12672 (* 1 = 1.12672 loss)
I1028 13:10:54.211282  9023 sgd_solver.cpp:105] Iteration 165360, lr = 0.000132826
I1028 13:11:24.780856  9023 solver.cpp:222] Iteration 165400 (1.30854 iter/s, 30.5684s/40 iters), loss = 1.31326
I1028 13:11:24.781064  9023 solver.cpp:241]     Train net output #0: loss = 1.31326 (* 1 = 1.31326 loss)
I1028 13:11:24.781085  9023 sgd_solver.cpp:105] Iteration 165400, lr = 0.000131453
I1028 13:11:55.442312  9023 solver.cpp:222] Iteration 165440 (1.30463 iter/s, 30.6601s/40 iters), loss = 1.19979
I1028 13:11:55.442530  9023 solver.cpp:241]     Train net output #0: loss = 1.19979 (* 1 = 1.19979 loss)
I1028 13:11:55.442548  9023 sgd_solver.cpp:105] Iteration 165440, lr = 0.000130082
I1028 13:12:26.101254  9023 solver.cpp:222] Iteration 165480 (1.30473 iter/s, 30.6576s/40 iters), loss = 1.57185
I1028 13:12:26.101379  9023 solver.cpp:241]     Train net output #0: loss = 1.57185 (* 1 = 1.57185 loss)
I1028 13:12:26.101395  9023 sgd_solver.cpp:105] Iteration 165480, lr = 0.000128715
I1028 13:12:40.762867  9023 solver.cpp:334] Iteration 165500, Testing net (#0)
I1028 13:13:12.311496  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.587679
I1028 13:13:12.311681  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.809159
I1028 13:13:12.311697  9023 solver.cpp:401]     Test net output #2: loss = 1.83055 (* 1 = 1.83055 loss)
I1028 13:13:28.441900  9023 solver.cpp:222] Iteration 165520 (0.641661 iter/s, 62.3382s/40 iters), loss = 1.50761
I1028 13:13:28.441973  9023 solver.cpp:241]     Train net output #0: loss = 1.50761 (* 1 = 1.50761 loss)
I1028 13:13:28.441989  9023 sgd_solver.cpp:105] Iteration 165520, lr = 0.000127349
I1028 13:13:59.426518  9023 solver.cpp:222] Iteration 165560 (1.29102 iter/s, 30.9834s/40 iters), loss = 1.4309
I1028 13:13:59.426707  9023 solver.cpp:241]     Train net output #0: loss = 1.4309 (* 1 = 1.4309 loss)
I1028 13:13:59.426724  9023 sgd_solver.cpp:105] Iteration 165560, lr = 0.000125985
I1028 13:14:30.398138  9023 solver.cpp:222] Iteration 165600 (1.29156 iter/s, 30.9703s/40 iters), loss = 1.51287
I1028 13:14:30.398326  9023 solver.cpp:241]     Train net output #0: loss = 1.51287 (* 1 = 1.51287 loss)
I1028 13:14:30.398344  9023 sgd_solver.cpp:105] Iteration 165600, lr = 0.000124625
I1028 13:15:01.674950  9023 solver.cpp:222] Iteration 165640 (1.27896 iter/s, 31.2754s/40 iters), loss = 1.41503
I1028 13:15:01.675127  9023 solver.cpp:241]     Train net output #0: loss = 1.41503 (* 1 = 1.41503 loss)
I1028 13:15:01.675143  9023 sgd_solver.cpp:105] Iteration 165640, lr = 0.000123266
I1028 13:15:32.646718  9023 solver.cpp:222] Iteration 165680 (1.29155 iter/s, 30.9704s/40 iters), loss = 1.436
I1028 13:15:32.646910  9023 solver.cpp:241]     Train net output #0: loss = 1.436 (* 1 = 1.436 loss)
I1028 13:15:32.646929  9023 sgd_solver.cpp:105] Iteration 165680, lr = 0.000121911
I1028 13:16:03.781852  9023 solver.cpp:222] Iteration 165720 (1.28478 iter/s, 31.1338s/40 iters), loss = 1.18327
I1028 13:16:03.782025  9023 solver.cpp:241]     Train net output #0: loss = 1.18327 (* 1 = 1.18327 loss)
I1028 13:16:03.782042  9023 sgd_solver.cpp:105] Iteration 165720, lr = 0.000120557
I1028 13:16:34.791165  9023 solver.cpp:222] Iteration 165760 (1.28999 iter/s, 31.008s/40 iters), loss = 1.41673
I1028 13:16:34.791343  9023 solver.cpp:241]     Train net output #0: loss = 1.41673 (* 1 = 1.41673 loss)
I1028 13:16:34.791360  9023 sgd_solver.cpp:105] Iteration 165760, lr = 0.000119207
I1028 13:17:05.838028  9023 solver.cpp:222] Iteration 165800 (1.28843 iter/s, 31.0455s/40 iters), loss = 1.26915
I1028 13:17:05.838222  9023 solver.cpp:241]     Train net output #0: loss = 1.26915 (* 1 = 1.26915 loss)
I1028 13:17:05.838238  9023 sgd_solver.cpp:105] Iteration 165800, lr = 0.000117858
I1028 13:17:37.365067  9023 solver.cpp:222] Iteration 165840 (1.26881 iter/s, 31.5257s/40 iters), loss = 1.14753
I1028 13:17:37.365260  9023 solver.cpp:241]     Train net output #0: loss = 1.14753 (* 1 = 1.14753 loss)
I1028 13:17:37.365278  9023 sgd_solver.cpp:105] Iteration 165840, lr = 0.000116513
I1028 13:18:09.263615  9023 solver.cpp:222] Iteration 165880 (1.25403 iter/s, 31.8972s/40 iters), loss = 1.4419
I1028 13:18:09.263803  9023 solver.cpp:241]     Train net output #0: loss = 1.4419 (* 1 = 1.4419 loss)
I1028 13:18:09.263820  9023 sgd_solver.cpp:105] Iteration 165880, lr = 0.00011517
I1028 13:18:39.959103  9023 solver.cpp:222] Iteration 165920 (1.30318 iter/s, 30.6941s/40 iters), loss = 1.3616
I1028 13:18:39.959266  9023 solver.cpp:241]     Train net output #0: loss = 1.3616 (* 1 = 1.3616 loss)
I1028 13:18:39.959302  9023 sgd_solver.cpp:105] Iteration 165920, lr = 0.000113829
I1028 13:19:10.600008  9023 solver.cpp:222] Iteration 165960 (1.3055 iter/s, 30.6396s/40 iters), loss = 1.32448
I1028 13:19:10.600236  9023 solver.cpp:241]     Train net output #0: loss = 1.32448 (* 1 = 1.32448 loss)
I1028 13:19:10.600291  9023 sgd_solver.cpp:105] Iteration 165960, lr = 0.000112491
I1028 13:19:40.714081  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_166000.caffemodel
I1028 13:19:40.746176  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_166000.solverstate
I1028 13:19:40.762953  9023 solver.cpp:334] Iteration 166000, Testing net (#0)
I1028 13:20:12.199947  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 13:20:12.412585  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58736
I1028 13:20:12.412654  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.815879
I1028 13:20:12.412669  9023 solver.cpp:401]     Test net output #2: loss = 1.82913 (* 1 = 1.82913 loss)
I1028 13:20:13.187031  9023 solver.cpp:222] Iteration 166000 (0.639136 iter/s, 62.5844s/40 iters), loss = 1.46524
I1028 13:20:13.187099  9023 solver.cpp:241]     Train net output #0: loss = 1.46524 (* 1 = 1.46524 loss)
I1028 13:20:13.187114  9023 sgd_solver.cpp:105] Iteration 166000, lr = 0.000111156
I1028 13:20:43.997463  9023 solver.cpp:222] Iteration 166040 (1.29831 iter/s, 30.8092s/40 iters), loss = 1.27943
I1028 13:20:43.997627  9023 solver.cpp:241]     Train net output #0: loss = 1.27943 (* 1 = 1.27943 loss)
I1028 13:20:43.997644  9023 sgd_solver.cpp:105] Iteration 166040, lr = 0.000109823
I1028 13:21:15.468538  9023 solver.cpp:222] Iteration 166080 (1.27106 iter/s, 31.4697s/40 iters), loss = 1.40239
I1028 13:21:15.468727  9023 solver.cpp:241]     Train net output #0: loss = 1.40239 (* 1 = 1.40239 loss)
I1028 13:21:15.468745  9023 sgd_solver.cpp:105] Iteration 166080, lr = 0.000108494
I1028 13:21:46.748885  9023 solver.cpp:222] Iteration 166120 (1.27881 iter/s, 31.279s/40 iters), loss = 1.40977
I1028 13:21:46.749068  9023 solver.cpp:241]     Train net output #0: loss = 1.40977 (* 1 = 1.40977 loss)
I1028 13:21:46.749085  9023 sgd_solver.cpp:105] Iteration 166120, lr = 0.000107166
I1028 13:22:17.463130  9023 solver.cpp:222] Iteration 166160 (1.30238 iter/s, 30.7129s/40 iters), loss = 1.37721
I1028 13:22:17.463313  9023 solver.cpp:241]     Train net output #0: loss = 1.37721 (* 1 = 1.37721 loss)
I1028 13:22:17.463330  9023 sgd_solver.cpp:105] Iteration 166160, lr = 0.000105842
I1028 13:22:48.696454  9023 solver.cpp:222] Iteration 166200 (1.28074 iter/s, 31.232s/40 iters), loss = 1.26984
I1028 13:22:48.696632  9023 solver.cpp:241]     Train net output #0: loss = 1.26984 (* 1 = 1.26984 loss)
I1028 13:22:48.696653  9023 sgd_solver.cpp:105] Iteration 166200, lr = 0.00010452
I1028 13:23:33.961463  9023 solver.cpp:222] Iteration 166240 (0.883721 iter/s, 45.2631s/40 iters), loss = 1.47812
I1028 13:23:33.961680  9023 solver.cpp:241]     Train net output #0: loss = 1.47812 (* 1 = 1.47812 loss)
I1028 13:23:33.961699  9023 sgd_solver.cpp:105] Iteration 166240, lr = 0.000103202
I1028 13:24:05.717963  9023 solver.cpp:222] Iteration 166280 (1.25964 iter/s, 31.7551s/40 iters), loss = 1.38224
I1028 13:24:05.718156  9023 solver.cpp:241]     Train net output #0: loss = 1.38224 (* 1 = 1.38224 loss)
I1028 13:24:05.718174  9023 sgd_solver.cpp:105] Iteration 166280, lr = 0.000101886
I1028 13:24:36.765926  9023 solver.cpp:222] Iteration 166320 (1.28839 iter/s, 31.0466s/40 iters), loss = 1.33809
I1028 13:24:36.766118  9023 solver.cpp:241]     Train net output #0: loss = 1.33809 (* 1 = 1.33809 loss)
I1028 13:24:36.766135  9023 sgd_solver.cpp:105] Iteration 166320, lr = 0.000100572
I1028 13:25:09.094607  9023 solver.cpp:222] Iteration 166360 (1.23735 iter/s, 32.3273s/40 iters), loss = 1.43146
I1028 13:25:09.094779  9023 solver.cpp:241]     Train net output #0: loss = 1.43146 (* 1 = 1.43146 loss)
I1028 13:25:09.094810  9023 sgd_solver.cpp:105] Iteration 166360, lr = 9.9262e-05
I1028 13:25:39.795346  9023 solver.cpp:222] Iteration 166400 (1.30296 iter/s, 30.6994s/40 iters), loss = 1.25696
I1028 13:25:39.795608  9023 solver.cpp:241]     Train net output #0: loss = 1.25696 (* 1 = 1.25696 loss)
I1028 13:25:39.795629  9023 sgd_solver.cpp:105] Iteration 166400, lr = 9.79544e-05
I1028 13:26:10.773813  9023 solver.cpp:222] Iteration 166440 (1.29128 iter/s, 30.977s/40 iters), loss = 1.18651
I1028 13:26:10.774013  9023 solver.cpp:241]     Train net output #0: loss = 1.18651 (* 1 = 1.18651 loss)
I1028 13:26:10.774039  9023 sgd_solver.cpp:105] Iteration 166440, lr = 9.665e-05
I1028 13:26:41.722126  9023 solver.cpp:222] Iteration 166480 (1.29253 iter/s, 30.947s/40 iters), loss = 1.22573
I1028 13:26:41.722316  9023 solver.cpp:241]     Train net output #0: loss = 1.22573 (* 1 = 1.22573 loss)
I1028 13:26:41.722334  9023 sgd_solver.cpp:105] Iteration 166480, lr = 9.53482e-05
I1028 13:26:56.424998  9023 solver.cpp:334] Iteration 166500, Testing net (#0)
I1028 13:27:27.689870  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58928
I1028 13:27:27.690057  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.810279
I1028 13:27:27.690078  9023 solver.cpp:401]     Test net output #2: loss = 1.82955 (* 1 = 1.82955 loss)
I1028 13:27:43.910614  9023 solver.cpp:222] Iteration 166520 (0.643232 iter/s, 62.186s/40 iters), loss = 1.54793
I1028 13:27:43.910686  9023 solver.cpp:241]     Train net output #0: loss = 1.54793 (* 1 = 1.54793 loss)
I1028 13:27:43.910704  9023 sgd_solver.cpp:105] Iteration 166520, lr = 9.40493e-05
I1028 13:28:14.793875  9023 solver.cpp:222] Iteration 166560 (1.29525 iter/s, 30.882s/40 iters), loss = 1.4364
I1028 13:28:14.794070  9023 solver.cpp:241]     Train net output #0: loss = 1.4364 (* 1 = 1.4364 loss)
I1028 13:28:14.794087  9023 sgd_solver.cpp:105] Iteration 166560, lr = 9.27538e-05
I1028 13:28:45.885881  9023 solver.cpp:222] Iteration 166600 (1.28656 iter/s, 31.0906s/40 iters), loss = 1.31256
I1028 13:28:45.886068  9023 solver.cpp:241]     Train net output #0: loss = 1.31256 (* 1 = 1.31256 loss)
I1028 13:28:45.886086  9023 sgd_solver.cpp:105] Iteration 166600, lr = 9.14609e-05
I1028 13:29:17.660534  9023 solver.cpp:222] Iteration 166640 (1.25892 iter/s, 31.7733s/40 iters), loss = 1.60913
I1028 13:29:17.660748  9023 solver.cpp:241]     Train net output #0: loss = 1.60913 (* 1 = 1.60913 loss)
I1028 13:29:17.660773  9023 sgd_solver.cpp:105] Iteration 166640, lr = 9.01714e-05
I1028 13:29:49.766386  9023 solver.cpp:222] Iteration 166680 (1.24593 iter/s, 32.1044s/40 iters), loss = 1.54776
I1028 13:29:49.766558  9023 solver.cpp:241]     Train net output #0: loss = 1.54776 (* 1 = 1.54776 loss)
I1028 13:29:49.766575  9023 sgd_solver.cpp:105] Iteration 166680, lr = 8.88846e-05
I1028 13:30:21.263861  9023 solver.cpp:222] Iteration 166720 (1.27 iter/s, 31.4961s/40 iters), loss = 1.3669
I1028 13:30:21.264050  9023 solver.cpp:241]     Train net output #0: loss = 1.3669 (* 1 = 1.3669 loss)
I1028 13:30:21.264067  9023 sgd_solver.cpp:105] Iteration 166720, lr = 8.76013e-05
I1028 13:31:16.120745  9023 solver.cpp:222] Iteration 166760 (0.7292 iter/s, 54.8546s/40 iters), loss = 1.37143
I1028 13:31:16.121063  9023 solver.cpp:241]     Train net output #0: loss = 1.37143 (* 1 = 1.37143 loss)
I1028 13:31:16.121093  9023 sgd_solver.cpp:105] Iteration 166760, lr = 8.63208e-05
I1028 13:31:50.177273  9023 solver.cpp:222] Iteration 166800 (1.17457 iter/s, 34.0549s/40 iters), loss = 1.4068
I1028 13:31:50.177484  9023 solver.cpp:241]     Train net output #0: loss = 1.4068 (* 1 = 1.4068 loss)
I1028 13:31:50.177502  9023 sgd_solver.cpp:105] Iteration 166800, lr = 8.50434e-05
I1028 13:32:21.109052  9023 solver.cpp:222] Iteration 166840 (1.29323 iter/s, 30.9304s/40 iters), loss = 1.28477
I1028 13:32:21.109246  9023 solver.cpp:241]     Train net output #0: loss = 1.28477 (* 1 = 1.28477 loss)
I1028 13:32:21.109264  9023 sgd_solver.cpp:105] Iteration 166840, lr = 8.37695e-05
I1028 13:32:52.283056  9023 solver.cpp:222] Iteration 166880 (1.28318 iter/s, 31.1726s/40 iters), loss = 1.28223
I1028 13:32:52.283291  9023 solver.cpp:241]     Train net output #0: loss = 1.28223 (* 1 = 1.28223 loss)
I1028 13:32:52.283314  9023 sgd_solver.cpp:105] Iteration 166880, lr = 8.24985e-05
I1028 13:33:23.772336  9023 solver.cpp:222] Iteration 166920 (1.27033 iter/s, 31.4879s/40 iters), loss = 1.27277
I1028 13:33:23.772522  9023 solver.cpp:241]     Train net output #0: loss = 1.27277 (* 1 = 1.27277 loss)
I1028 13:33:23.772541  9023 sgd_solver.cpp:105] Iteration 166920, lr = 8.12312e-05
I1028 13:33:55.331634  9023 solver.cpp:222] Iteration 166960 (1.26751 iter/s, 31.5579s/40 iters), loss = 1.32243
I1028 13:33:55.331857  9023 solver.cpp:241]     Train net output #0: loss = 1.32243 (* 1 = 1.32243 loss)
I1028 13:33:55.331883  9023 sgd_solver.cpp:105] Iteration 166960, lr = 7.99667e-05
I1028 13:34:26.292881  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_167000.caffemodel
I1028 13:34:26.324569  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_167000.solverstate
I1028 13:34:26.342406  9023 solver.cpp:334] Iteration 167000, Testing net (#0)
I1028 13:34:57.496140  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 13:34:57.708632  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58652
I1028 13:34:57.708680  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81608
I1028 13:34:57.708695  9023 solver.cpp:401]     Test net output #2: loss = 1.82394 (* 1 = 1.82394 loss)
I1028 13:34:58.487190  9023 solver.cpp:222] Iteration 167000 (0.633383 iter/s, 63.153s/40 iters), loss = 1.41837
I1028 13:34:58.487241  9023 solver.cpp:241]     Train net output #0: loss = 1.41837 (* 1 = 1.41837 loss)
I1028 13:34:58.487259  9023 sgd_solver.cpp:105] Iteration 167000, lr = 7.87059e-05
I1028 13:35:29.882428  9023 solver.cpp:222] Iteration 167040 (1.27413 iter/s, 31.394s/40 iters), loss = 1.17577
I1028 13:35:29.882623  9023 solver.cpp:241]     Train net output #0: loss = 1.17577 (* 1 = 1.17577 loss)
I1028 13:35:29.882642  9023 sgd_solver.cpp:105] Iteration 167040, lr = 7.74482e-05
I1028 13:36:00.666463  9023 solver.cpp:222] Iteration 167080 (1.29943 iter/s, 30.7827s/40 iters), loss = 1.44319
I1028 13:36:00.666666  9023 solver.cpp:241]     Train net output #0: loss = 1.44319 (* 1 = 1.44319 loss)
I1028 13:36:00.666682  9023 sgd_solver.cpp:105] Iteration 167080, lr = 7.61939e-05
I1028 13:36:07.712944  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1028 13:36:31.499596  9023 solver.cpp:222] Iteration 167120 (1.29736 iter/s, 30.8318s/40 iters), loss = 1.38662
I1028 13:36:31.499816  9023 solver.cpp:241]     Train net output #0: loss = 1.38662 (* 1 = 1.38662 loss)
I1028 13:36:31.499833  9023 sgd_solver.cpp:105] Iteration 167120, lr = 7.49433e-05
I1028 13:37:02.618871  9023 solver.cpp:222] Iteration 167160 (1.28543 iter/s, 31.1179s/40 iters), loss = 1.45227
I1028 13:37:02.619045  9023 solver.cpp:241]     Train net output #0: loss = 1.45227 (* 1 = 1.45227 loss)
I1028 13:37:02.619060  9023 sgd_solver.cpp:105] Iteration 167160, lr = 7.36958e-05
I1028 13:37:33.417369  9023 solver.cpp:222] Iteration 167200 (1.29882 iter/s, 30.7971s/40 iters), loss = 1.41315
I1028 13:37:33.417541  9023 solver.cpp:241]     Train net output #0: loss = 1.41315 (* 1 = 1.41315 loss)
I1028 13:37:33.417558  9023 sgd_solver.cpp:105] Iteration 167200, lr = 7.24522e-05
I1028 13:38:04.044173  9023 solver.cpp:222] Iteration 167240 (1.3061 iter/s, 30.6255s/40 iters), loss = 1.21185
I1028 13:38:04.044425  9023 solver.cpp:241]     Train net output #0: loss = 1.21185 (* 1 = 1.21185 loss)
I1028 13:38:04.044441  9023 sgd_solver.cpp:105] Iteration 167240, lr = 7.12118e-05
I1028 13:38:34.752912  9023 solver.cpp:222] Iteration 167280 (1.30262 iter/s, 30.7073s/40 iters), loss = 1.29166
I1028 13:38:34.753079  9023 solver.cpp:241]     Train net output #0: loss = 1.29166 (* 1 = 1.29166 loss)
I1028 13:38:34.753096  9023 sgd_solver.cpp:105] Iteration 167280, lr = 6.9975e-05
I1028 13:39:05.345533  9023 solver.cpp:222] Iteration 167320 (1.30756 iter/s, 30.5913s/40 iters), loss = 1.02065
I1028 13:39:05.345734  9023 solver.cpp:241]     Train net output #0: loss = 1.02065 (* 1 = 1.02065 loss)
I1028 13:39:05.345755  9023 sgd_solver.cpp:105] Iteration 167320, lr = 6.87422e-05
I1028 13:39:36.028642  9023 solver.cpp:222] Iteration 167360 (1.30371 iter/s, 30.6818s/40 iters), loss = 1.24225
I1028 13:39:36.028807  9023 solver.cpp:241]     Train net output #0: loss = 1.24225 (* 1 = 1.24225 loss)
I1028 13:39:36.028825  9023 sgd_solver.cpp:105] Iteration 167360, lr = 6.75127e-05
I1028 13:40:06.864876  9023 solver.cpp:222] Iteration 167400 (1.29723 iter/s, 30.8349s/40 iters), loss = 1.11727
I1028 13:40:06.865061  9023 solver.cpp:241]     Train net output #0: loss = 1.11727 (* 1 = 1.11727 loss)
I1028 13:40:06.865082  9023 sgd_solver.cpp:105] Iteration 167400, lr = 6.62872e-05
I1028 13:40:37.875239  9023 solver.cpp:222] Iteration 167440 (1.28995 iter/s, 31.009s/40 iters), loss = 1.30895
I1028 13:40:37.875432  9023 solver.cpp:241]     Train net output #0: loss = 1.30895 (* 1 = 1.30895 loss)
I1028 13:40:37.875449  9023 sgd_solver.cpp:105] Iteration 167440, lr = 6.50652e-05
I1028 13:41:08.920002  9023 solver.cpp:222] Iteration 167480 (1.28852 iter/s, 31.0434s/40 iters), loss = 1.26881
I1028 13:41:08.920189  9023 solver.cpp:241]     Train net output #0: loss = 1.26881 (* 1 = 1.26881 loss)
I1028 13:41:08.920207  9023 sgd_solver.cpp:105] Iteration 167480, lr = 6.38473e-05
I1028 13:41:23.792058  9023 solver.cpp:334] Iteration 167500, Testing net (#0)
I1028 13:41:55.170627  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5896
I1028 13:41:55.170837  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8108
I1028 13:41:55.170852  9023 solver.cpp:401]     Test net output #2: loss = 1.82574 (* 1 = 1.82574 loss)
I1028 13:42:11.504093  9023 solver.cpp:222] Iteration 167520 (0.639166 iter/s, 62.5816s/40 iters), loss = 1.27758
I1028 13:42:11.504164  9023 solver.cpp:241]     Train net output #0: loss = 1.27758 (* 1 = 1.27758 loss)
I1028 13:42:11.504180  9023 sgd_solver.cpp:105] Iteration 167520, lr = 6.2633e-05
I1028 13:42:42.733239  9023 solver.cpp:222] Iteration 167560 (1.28091 iter/s, 31.2279s/40 iters), loss = 1.46138
I1028 13:42:42.733422  9023 solver.cpp:241]     Train net output #0: loss = 1.46138 (* 1 = 1.46138 loss)
I1028 13:42:42.733446  9023 sgd_solver.cpp:105] Iteration 167560, lr = 6.14226e-05
I1028 13:43:13.975904  9023 solver.cpp:222] Iteration 167600 (1.28036 iter/s, 31.2413s/40 iters), loss = 1.78036
I1028 13:43:13.976089  9023 solver.cpp:241]     Train net output #0: loss = 1.78036 (* 1 = 1.78036 loss)
I1028 13:43:13.976104  9023 sgd_solver.cpp:105] Iteration 167600, lr = 6.02164e-05
I1028 13:43:45.178544  9023 solver.cpp:222] Iteration 167640 (1.282 iter/s, 31.2013s/40 iters), loss = 1.48569
I1028 13:43:45.178719  9023 solver.cpp:241]     Train net output #0: loss = 1.48569 (* 1 = 1.48569 loss)
I1028 13:43:45.178735  9023 sgd_solver.cpp:105] Iteration 167640, lr = 5.9014e-05
I1028 13:44:16.220710  9023 solver.cpp:222] Iteration 167680 (1.28863 iter/s, 31.0408s/40 iters), loss = 1.05575
I1028 13:44:16.220866  9023 solver.cpp:241]     Train net output #0: loss = 1.05575 (* 1 = 1.05575 loss)
I1028 13:44:16.220887  9023 sgd_solver.cpp:105] Iteration 167680, lr = 5.78159e-05
I1028 13:44:47.215159  9023 solver.cpp:222] Iteration 167720 (1.29061 iter/s, 30.9931s/40 iters), loss = 1.06828
I1028 13:44:47.215338  9023 solver.cpp:241]     Train net output #0: loss = 1.06828 (* 1 = 1.06828 loss)
I1028 13:44:47.215361  9023 sgd_solver.cpp:105] Iteration 167720, lr = 5.66217e-05
I1028 13:45:18.604593  9023 solver.cpp:222] Iteration 167760 (1.27437 iter/s, 31.3881s/40 iters), loss = 1.40019
I1028 13:45:18.604766  9023 solver.cpp:241]     Train net output #0: loss = 1.40019 (* 1 = 1.40019 loss)
I1028 13:45:18.604784  9023 sgd_solver.cpp:105] Iteration 167760, lr = 5.54316e-05
I1028 13:45:49.728924  9023 solver.cpp:222] Iteration 167800 (1.28522 iter/s, 31.123s/40 iters), loss = 1.03824
I1028 13:45:49.729135  9023 solver.cpp:241]     Train net output #0: loss = 1.03824 (* 1 = 1.03824 loss)
I1028 13:45:49.729151  9023 sgd_solver.cpp:105] Iteration 167800, lr = 5.42461e-05
I1028 13:46:20.848462  9023 solver.cpp:222] Iteration 167840 (1.28542 iter/s, 31.1182s/40 iters), loss = 1.53651
I1028 13:46:20.848681  9023 solver.cpp:241]     Train net output #0: loss = 1.53651 (* 1 = 1.53651 loss)
I1028 13:46:20.848698  9023 sgd_solver.cpp:105] Iteration 167840, lr = 5.30646e-05
I1028 13:46:51.663211  9023 solver.cpp:222] Iteration 167880 (1.29814 iter/s, 30.8134s/40 iters), loss = 1.26077
I1028 13:46:51.663396  9023 solver.cpp:241]     Train net output #0: loss = 1.26077 (* 1 = 1.26077 loss)
I1028 13:46:51.663414  9023 sgd_solver.cpp:105] Iteration 167880, lr = 5.18877e-05
I1028 13:47:22.445396  9023 solver.cpp:222] Iteration 167920 (1.29951 iter/s, 30.7808s/40 iters), loss = 1.35569
I1028 13:47:22.445560  9023 solver.cpp:241]     Train net output #0: loss = 1.35569 (* 1 = 1.35569 loss)
I1028 13:47:22.445576  9023 sgd_solver.cpp:105] Iteration 167920, lr = 5.0715e-05
I1028 13:47:53.188832  9023 solver.cpp:222] Iteration 167960 (1.30115 iter/s, 30.7421s/40 iters), loss = 1.44802
I1028 13:47:53.189019  9023 solver.cpp:241]     Train net output #0: loss = 1.44802 (* 1 = 1.44802 loss)
I1028 13:47:53.189036  9023 sgd_solver.cpp:105] Iteration 167960, lr = 4.95471e-05
I1028 13:48:23.275404  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_168000.caffemodel
I1028 13:48:23.307510  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_168000.solverstate
I1028 13:48:23.325762  9023 solver.cpp:334] Iteration 168000, Testing net (#0)
I1028 13:48:54.739413  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 13:48:54.949878  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58804
I1028 13:48:54.949944  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.815479
I1028 13:48:54.949959  9023 solver.cpp:401]     Test net output #2: loss = 1.82572 (* 1 = 1.82572 loss)
I1028 13:48:55.723363  9023 solver.cpp:222] Iteration 168000 (0.639672 iter/s, 62.532s/40 iters), loss = 1.33063
I1028 13:48:55.723431  9023 solver.cpp:241]     Train net output #0: loss = 1.33063 (* 1 = 1.33063 loss)
I1028 13:48:55.723446  9023 sgd_solver.cpp:105] Iteration 168000, lr = 4.83835e-05
I1028 13:49:26.435750  9023 solver.cpp:222] Iteration 168040 (1.30246 iter/s, 30.7112s/40 iters), loss = 1.25459
I1028 13:49:26.435921  9023 solver.cpp:241]     Train net output #0: loss = 1.25459 (* 1 = 1.25459 loss)
I1028 13:49:26.435940  9023 sgd_solver.cpp:105] Iteration 168040, lr = 4.72245e-05
I1028 13:49:57.454051  9023 solver.cpp:222] Iteration 168080 (1.28962 iter/s, 31.017s/40 iters), loss = 1.28744
I1028 13:49:57.454224  9023 solver.cpp:241]     Train net output #0: loss = 1.28744 (* 1 = 1.28744 loss)
I1028 13:49:57.454242  9023 sgd_solver.cpp:105] Iteration 168080, lr = 4.60705e-05
I1028 13:50:28.518898  9023 solver.cpp:222] Iteration 168120 (1.28769 iter/s, 31.0635s/40 iters), loss = 1.43248
I1028 13:50:28.519098  9023 solver.cpp:241]     Train net output #0: loss = 1.43248 (* 1 = 1.43248 loss)
I1028 13:50:28.519115  9023 sgd_solver.cpp:105] Iteration 168120, lr = 4.4921e-05
I1028 13:51:00.511358  9023 solver.cpp:222] Iteration 168160 (1.25035 iter/s, 31.991s/40 iters), loss = 1.23442
I1028 13:51:00.511567  9023 solver.cpp:241]     Train net output #0: loss = 1.23442 (* 1 = 1.23442 loss)
I1028 13:51:00.511593  9023 sgd_solver.cpp:105] Iteration 168160, lr = 4.37767e-05
I1028 13:51:32.463127  9023 solver.cpp:222] Iteration 168200 (1.25194 iter/s, 31.9504s/40 iters), loss = 1.52201
I1028 13:51:32.463501  9023 solver.cpp:241]     Train net output #0: loss = 1.52201 (* 1 = 1.52201 loss)
I1028 13:51:32.463527  9023 sgd_solver.cpp:105] Iteration 168200, lr = 4.26371e-05
I1028 13:52:03.960017  9023 solver.cpp:222] Iteration 168240 (1.27003 iter/s, 31.4953s/40 iters), loss = 1.43682
I1028 13:52:03.960189  9023 solver.cpp:241]     Train net output #0: loss = 1.43682 (* 1 = 1.43682 loss)
I1028 13:52:03.960220  9023 sgd_solver.cpp:105] Iteration 168240, lr = 4.15028e-05
I1028 13:52:34.982746  9023 solver.cpp:222] Iteration 168280 (1.28943 iter/s, 31.0214s/40 iters), loss = 1.28677
I1028 13:52:34.982954  9023 solver.cpp:241]     Train net output #0: loss = 1.28677 (* 1 = 1.28677 loss)
I1028 13:52:34.982972  9023 sgd_solver.cpp:105] Iteration 168280, lr = 4.03734e-05
I1028 13:53:07.857017  9023 solver.cpp:222] Iteration 168320 (1.21681 iter/s, 32.8728s/40 iters), loss = 1.41658
I1028 13:53:07.857203  9023 solver.cpp:241]     Train net output #0: loss = 1.41658 (* 1 = 1.41658 loss)
I1028 13:53:07.857219  9023 sgd_solver.cpp:105] Iteration 168320, lr = 3.92492e-05
I1028 13:53:39.162144  9023 solver.cpp:222] Iteration 168360 (1.2778 iter/s, 31.3038s/40 iters), loss = 1.53118
I1028 13:53:39.162334  9023 solver.cpp:241]     Train net output #0: loss = 1.53118 (* 1 = 1.53118 loss)
I1028 13:53:39.162351  9023 sgd_solver.cpp:105] Iteration 168360, lr = 3.81307e-05
I1028 13:54:10.691519  9023 solver.cpp:222] Iteration 168400 (1.26871 iter/s, 31.528s/40 iters), loss = 1.35751
I1028 13:54:10.691689  9023 solver.cpp:241]     Train net output #0: loss = 1.35751 (* 1 = 1.35751 loss)
I1028 13:54:10.691706  9023 sgd_solver.cpp:105] Iteration 168400, lr = 3.70173e-05
I1028 13:54:42.243103  9023 solver.cpp:222] Iteration 168440 (1.26782 iter/s, 31.5502s/40 iters), loss = 1.67319
I1028 13:54:42.243288  9023 solver.cpp:241]     Train net output #0: loss = 1.67319 (* 1 = 1.67319 loss)
I1028 13:54:42.243309  9023 sgd_solver.cpp:105] Iteration 168440, lr = 3.59097e-05
I1028 13:55:13.204172  9023 solver.cpp:222] Iteration 168480 (1.292 iter/s, 30.9597s/40 iters), loss = 1.34152
I1028 13:55:13.204346  9023 solver.cpp:241]     Train net output #0: loss = 1.34152 (* 1 = 1.34152 loss)
I1028 13:55:13.204365  9023 sgd_solver.cpp:105] Iteration 168480, lr = 3.48075e-05
I1028 13:55:28.034253  9023 solver.cpp:334] Iteration 168500, Testing net (#0)
I1028 13:55:59.480165  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58968
I1028 13:55:59.480402  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81096
I1028 13:55:59.480420  9023 solver.cpp:401]     Test net output #2: loss = 1.81965 (* 1 = 1.81965 loss)
I1028 13:56:15.689607  9023 solver.cpp:222] Iteration 168520 (0.640175 iter/s, 62.4829s/40 iters), loss = 1.50758
I1028 13:56:15.689715  9023 solver.cpp:241]     Train net output #0: loss = 1.50758 (* 1 = 1.50758 loss)
I1028 13:56:15.689738  9023 sgd_solver.cpp:105] Iteration 168520, lr = 3.37111e-05
I1028 13:56:47.184222  9023 solver.cpp:222] Iteration 168560 (1.27011 iter/s, 31.4933s/40 iters), loss = 1.22145
I1028 13:56:47.184412  9023 solver.cpp:241]     Train net output #0: loss = 1.22145 (* 1 = 1.22145 loss)
I1028 13:56:47.184428  9023 sgd_solver.cpp:105] Iteration 168560, lr = 3.26209e-05
I1028 13:57:18.471094  9023 solver.cpp:222] Iteration 168600 (1.27855 iter/s, 31.2855s/40 iters), loss = 1.41593
I1028 13:57:18.471266  9023 solver.cpp:241]     Train net output #0: loss = 1.41593 (* 1 = 1.41593 loss)
I1028 13:57:18.471282  9023 sgd_solver.cpp:105] Iteration 168600, lr = 3.15365e-05
I1028 13:57:49.662158  9023 solver.cpp:222] Iteration 168640 (1.28247 iter/s, 31.1897s/40 iters), loss = 1.35827
I1028 13:57:49.662335  9023 solver.cpp:241]     Train net output #0: loss = 1.35827 (* 1 = 1.35827 loss)
I1028 13:57:49.662353  9023 sgd_solver.cpp:105] Iteration 168640, lr = 3.04585e-05
I1028 13:58:20.903132  9023 solver.cpp:222] Iteration 168680 (1.28043 iter/s, 31.2396s/40 iters), loss = 1.67006
I1028 13:58:20.903306  9023 solver.cpp:241]     Train net output #0: loss = 1.67006 (* 1 = 1.67006 loss)
I1028 13:58:20.903323  9023 sgd_solver.cpp:105] Iteration 168680, lr = 2.93866e-05
I1028 13:58:52.060436  9023 solver.cpp:222] Iteration 168720 (1.28386 iter/s, 31.156s/40 iters), loss = 1.24431
I1028 13:58:52.060622  9023 solver.cpp:241]     Train net output #0: loss = 1.24431 (* 1 = 1.24431 loss)
I1028 13:58:52.060642  9023 sgd_solver.cpp:105] Iteration 168720, lr = 2.83214e-05
I1028 13:59:23.833474  9023 solver.cpp:222] Iteration 168760 (1.25898 iter/s, 31.7717s/40 iters), loss = 1.37975
I1028 13:59:23.833724  9023 solver.cpp:241]     Train net output #0: loss = 1.37975 (* 1 = 1.37975 loss)
I1028 13:59:23.833762  9023 sgd_solver.cpp:105] Iteration 168760, lr = 2.72626e-05
I1028 13:59:54.689895  9023 solver.cpp:222] Iteration 168800 (1.29639 iter/s, 30.855s/40 iters), loss = 1.38971
I1028 13:59:54.690088  9023 solver.cpp:241]     Train net output #0: loss = 1.38971 (* 1 = 1.38971 loss)
I1028 13:59:54.690507  9023 sgd_solver.cpp:105] Iteration 168800, lr = 2.62106e-05
I1028 14:00:25.936122  9023 solver.cpp:222] Iteration 168840 (1.28021 iter/s, 31.2449s/40 iters), loss = 1.3074
I1028 14:00:25.936319  9023 solver.cpp:241]     Train net output #0: loss = 1.3074 (* 1 = 1.3074 loss)
I1028 14:00:25.936342  9023 sgd_solver.cpp:105] Iteration 168840, lr = 2.51658e-05
I1028 14:00:56.811873  9023 solver.cpp:222] Iteration 168880 (1.29557 iter/s, 30.8744s/40 iters), loss = 1.31158
I1028 14:00:56.812052  9023 solver.cpp:241]     Train net output #0: loss = 1.31158 (* 1 = 1.31158 loss)
I1028 14:00:56.812068  9023 sgd_solver.cpp:105] Iteration 168880, lr = 2.4128e-05
I1028 14:01:27.972261  9023 solver.cpp:222] Iteration 168920 (1.28374 iter/s, 31.159s/40 iters), loss = 1.31331
I1028 14:01:27.972462  9023 solver.cpp:241]     Train net output #0: loss = 1.31331 (* 1 = 1.31331 loss)
I1028 14:01:27.972481  9023 sgd_solver.cpp:105] Iteration 168920, lr = 2.30978e-05
I1028 14:01:59.408025  9023 solver.cpp:222] Iteration 168960 (1.27249 iter/s, 31.4344s/40 iters), loss = 1.33697
I1028 14:01:59.408224  9023 solver.cpp:241]     Train net output #0: loss = 1.33697 (* 1 = 1.33697 loss)
I1028 14:01:59.408241  9023 sgd_solver.cpp:105] Iteration 168960, lr = 2.2075e-05
I1028 14:02:30.689035  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_169000.caffemodel
I1028 14:02:30.721983  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_169000.solverstate
I1028 14:02:30.740871  9023 solver.cpp:334] Iteration 169000, Testing net (#0)
I1028 14:03:02.208274  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:03:02.417062  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58744
I1028 14:03:02.417125  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.816
I1028 14:03:02.417138  9023 solver.cpp:401]     Test net output #2: loss = 1.82435 (* 1 = 1.82435 loss)
I1028 14:03:03.189431  9023 solver.cpp:222] Iteration 169000 (0.627167 iter/s, 63.7788s/40 iters), loss = 1.2898
I1028 14:03:03.189498  9023 solver.cpp:241]     Train net output #0: loss = 1.2898 (* 1 = 1.2898 loss)
I1028 14:03:03.189512  9023 sgd_solver.cpp:105] Iteration 169000, lr = 2.10603e-05
I1028 14:03:34.582355  9023 solver.cpp:222] Iteration 169040 (1.27422 iter/s, 31.3917s/40 iters), loss = 1.38565
I1028 14:03:34.582587  9023 solver.cpp:241]     Train net output #0: loss = 1.38565 (* 1 = 1.38565 loss)
I1028 14:03:34.582609  9023 sgd_solver.cpp:105] Iteration 169040, lr = 2.00534e-05
I1028 14:04:06.523386  9023 solver.cpp:222] Iteration 169080 (1.25236 iter/s, 31.9396s/40 iters), loss = 1.32235
I1028 14:04:06.523597  9023 solver.cpp:241]     Train net output #0: loss = 1.32235 (* 1 = 1.32235 loss)
I1028 14:04:06.523613  9023 sgd_solver.cpp:105] Iteration 169080, lr = 1.90548e-05
I1028 14:04:37.473675  9023 solver.cpp:222] Iteration 169120 (1.29245 iter/s, 30.9489s/40 iters), loss = 1.46929
I1028 14:04:37.473855  9023 solver.cpp:241]     Train net output #0: loss = 1.46929 (* 1 = 1.46929 loss)
I1028 14:04:37.473873  9023 sgd_solver.cpp:105] Iteration 169120, lr = 1.80652e-05
I1028 14:05:08.529369  9023 solver.cpp:222] Iteration 169160 (1.28806 iter/s, 31.0543s/40 iters), loss = 1.53523
I1028 14:05:08.529566  9023 solver.cpp:241]     Train net output #0: loss = 1.53523 (* 1 = 1.53523 loss)
I1028 14:05:08.529582  9023 sgd_solver.cpp:105] Iteration 169160, lr = 1.70842e-05
I1028 14:05:40.441829  9023 solver.cpp:222] Iteration 169200 (1.25348 iter/s, 31.9111s/40 iters), loss = 1.37449
I1028 14:05:40.442163  9023 solver.cpp:241]     Train net output #0: loss = 1.37449 (* 1 = 1.37449 loss)
I1028 14:05:40.442191  9023 sgd_solver.cpp:105] Iteration 169200, lr = 1.61128e-05
I1028 14:06:13.588153  9023 solver.cpp:222] Iteration 169240 (1.20683 iter/s, 33.1447s/40 iters), loss = 1.56251
I1028 14:06:13.588472  9023 solver.cpp:241]     Train net output #0: loss = 1.56251 (* 1 = 1.56251 loss)
I1028 14:06:13.588502  9023 sgd_solver.cpp:105] Iteration 169240, lr = 1.51509e-05
I1028 14:06:45.846483  9023 solver.cpp:222] Iteration 169280 (1.24005 iter/s, 32.2568s/40 iters), loss = 1.27781
I1028 14:06:45.846669  9023 solver.cpp:241]     Train net output #0: loss = 1.27781 (* 1 = 1.27781 loss)
I1028 14:06:45.846685  9023 sgd_solver.cpp:105] Iteration 169280, lr = 1.4199e-05
I1028 14:07:16.660941  9023 solver.cpp:222] Iteration 169320 (1.29815 iter/s, 30.8131s/40 iters), loss = 1.11946
I1028 14:07:16.661128  9023 solver.cpp:241]     Train net output #0: loss = 1.11946 (* 1 = 1.11946 loss)
I1028 14:07:16.661144  9023 sgd_solver.cpp:105] Iteration 169320, lr = 1.32578e-05
I1028 14:07:47.353292  9023 solver.cpp:222] Iteration 169360 (1.30331 iter/s, 30.691s/40 iters), loss = 1.49357
I1028 14:07:47.353473  9023 solver.cpp:241]     Train net output #0: loss = 1.49357 (* 1 = 1.49357 loss)
I1028 14:07:47.353489  9023 sgd_solver.cpp:105] Iteration 169360, lr = 1.23275e-05
I1028 14:08:18.064326  9023 solver.cpp:222] Iteration 169400 (1.30252 iter/s, 30.7097s/40 iters), loss = 1.12962
I1028 14:08:18.064488  9023 solver.cpp:241]     Train net output #0: loss = 1.12962 (* 1 = 1.12962 loss)
I1028 14:08:18.064507  9023 sgd_solver.cpp:105] Iteration 169400, lr = 1.14089e-05
I1028 14:08:49.012181  9023 solver.cpp:222] Iteration 169440 (1.29255 iter/s, 30.9465s/40 iters), loss = 1.28018
I1028 14:08:49.012367  9023 solver.cpp:241]     Train net output #0: loss = 1.28018 (* 1 = 1.28018 loss)
I1028 14:08:49.012382  9023 sgd_solver.cpp:105] Iteration 169440, lr = 1.05023e-05
I1028 14:09:20.378484  9023 solver.cpp:222] Iteration 169480 (1.27531 iter/s, 31.3649s/40 iters), loss = 1.41043
I1028 14:09:20.378634  9023 solver.cpp:241]     Train net output #0: loss = 1.41043 (* 1 = 1.41043 loss)
I1028 14:09:20.378654  9023 sgd_solver.cpp:105] Iteration 169480, lr = 9.60881e-06
I1028 14:09:35.004834  9023 solver.cpp:334] Iteration 169500, Testing net (#0)
I1028 14:10:06.590764  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5902
I1028 14:10:06.590953  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.811319
I1028 14:10:06.590970  9023 solver.cpp:401]     Test net output #2: loss = 1.81681 (* 1 = 1.81681 loss)
I1028 14:10:22.891108  9023 solver.cpp:222] Iteration 169520 (0.639896 iter/s, 62.5101s/40 iters), loss = 1.01323
I1028 14:10:22.891216  9023 solver.cpp:241]     Train net output #0: loss = 1.01323 (* 1 = 1.01323 loss)
I1028 14:10:22.891240  9023 sgd_solver.cpp:105] Iteration 169520, lr = 8.72873e-06
I1028 14:10:54.152704  9023 solver.cpp:222] Iteration 169560 (1.27958 iter/s, 31.2603s/40 iters), loss = 1.27383
I1028 14:10:54.152894  9023 solver.cpp:241]     Train net output #0: loss = 1.27383 (* 1 = 1.27383 loss)
I1028 14:10:54.152910  9023 sgd_solver.cpp:105] Iteration 169560, lr = 7.86321e-06
I1028 14:11:18.505075  9074 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:11:25.085535  9023 solver.cpp:222] Iteration 169600 (1.29318 iter/s, 30.9315s/40 iters), loss = 1.49738
I1028 14:11:25.085732  9023 solver.cpp:241]     Train net output #0: loss = 1.49738 (* 1 = 1.49738 loss)
I1028 14:11:25.085753  9023 sgd_solver.cpp:105] Iteration 169600, lr = 7.01352e-06
I1028 14:11:56.324864  9023 solver.cpp:222] Iteration 169640 (1.28049 iter/s, 31.2379s/40 iters), loss = 1.34136
I1028 14:11:56.325048  9023 solver.cpp:241]     Train net output #0: loss = 1.34136 (* 1 = 1.34136 loss)
I1028 14:11:56.325065  9023 sgd_solver.cpp:105] Iteration 169640, lr = 6.18046e-06
I1028 14:12:28.315680  9023 solver.cpp:222] Iteration 169680 (1.25041 iter/s, 31.9894s/40 iters), loss = 1.2319
I1028 14:12:28.315933  9023 solver.cpp:241]     Train net output #0: loss = 1.2319 (* 1 = 1.2319 loss)
I1028 14:12:28.315956  9023 sgd_solver.cpp:105] Iteration 169680, lr = 5.36596e-06
I1028 14:12:59.709614  9023 solver.cpp:222] Iteration 169720 (1.27419 iter/s, 31.3925s/40 iters), loss = 1.67295
I1028 14:12:59.709801  9023 solver.cpp:241]     Train net output #0: loss = 1.67295 (* 1 = 1.67295 loss)
I1028 14:12:59.709817  9023 sgd_solver.cpp:105] Iteration 169720, lr = 4.5714e-06
I1028 14:13:31.428212  9023 solver.cpp:222] Iteration 169760 (1.26115 iter/s, 31.7172s/40 iters), loss = 1.11373
I1028 14:13:31.428432  9023 solver.cpp:241]     Train net output #0: loss = 1.11373 (* 1 = 1.11373 loss)
I1028 14:13:31.428450  9023 sgd_solver.cpp:105] Iteration 169760, lr = 3.7993e-06
I1028 14:14:02.820468  9023 solver.cpp:222] Iteration 169800 (1.27426 iter/s, 31.3908s/40 iters), loss = 1.27849
I1028 14:14:02.820668  9023 solver.cpp:241]     Train net output #0: loss = 1.27849 (* 1 = 1.27849 loss)
I1028 14:14:02.820684  9023 sgd_solver.cpp:105] Iteration 169800, lr = 3.05281e-06
I1028 14:14:33.757886  9023 solver.cpp:222] Iteration 169840 (1.29299 iter/s, 30.936s/40 iters), loss = 1.38889
I1028 14:14:33.758098  9023 solver.cpp:241]     Train net output #0: loss = 1.38889 (* 1 = 1.38889 loss)
I1028 14:14:33.758114  9023 sgd_solver.cpp:105] Iteration 169840, lr = 2.33558e-06
I1028 14:15:04.420032  9023 solver.cpp:222] Iteration 169880 (1.3046 iter/s, 30.6608s/40 iters), loss = 1.64737
I1028 14:15:04.420241  9023 solver.cpp:241]     Train net output #0: loss = 1.64737 (* 1 = 1.64737 loss)
I1028 14:15:04.420259  9023 sgd_solver.cpp:105] Iteration 169880, lr = 1.65383e-06
I1028 14:15:35.354764  9023 solver.cpp:222] Iteration 169920 (1.2931 iter/s, 30.9334s/40 iters), loss = 1.25613
I1028 14:15:35.354965  9023 solver.cpp:241]     Train net output #0: loss = 1.25613 (* 1 = 1.25613 loss)
I1028 14:15:35.354984  9023 sgd_solver.cpp:105] Iteration 169920, lr = 1.01662e-06
I1028 14:16:06.156535  9023 solver.cpp:222] Iteration 169960 (1.29868 iter/s, 30.8004s/40 iters), loss = 1.14271
I1028 14:16:06.156718  9023 solver.cpp:241]     Train net output #0: loss = 1.14271 (* 1 = 1.14271 loss)
I1028 14:16:06.156734  9023 sgd_solver.cpp:105] Iteration 169960, lr = 4.42577e-07
I1028 14:16:36.365566  9023 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_170000.caffemodel
I1028 14:16:36.397891  9023 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_0_20_iter_170000.solverstate
I1028 14:16:36.569383  9023 solver.cpp:314] Iteration 170000, loss = 1.63606
I1028 14:16:36.569433  9023 solver.cpp:334] Iteration 170000, Testing net (#0)
I1028 14:17:07.578661  9075 data_layer.cpp:73] Restarting data prefetching from start.
I1028 14:17:07.789013  9023 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58852
I1028 14:17:07.789079  9023 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81604
I1028 14:17:07.789093  9023 solver.cpp:401]     Test net output #2: loss = 1.82451 (* 1 = 1.82451 loss)
I1028 14:17:07.789100  9023 solver.cpp:319] Optimization Done.
I1028 14:17:23.687402  9023 caffe.cpp:259] Optimization Done.
