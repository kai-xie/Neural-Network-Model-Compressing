nohup: ignoring input
I1029 20:59:19.314592 27430 caffe.cpp:218] Using GPUs 0, 1, 2, 3
I1029 20:59:19.315752 27430 caffe.cpp:223] GPU 0: Tesla P40
I1029 20:59:19.316347 27430 caffe.cpp:223] GPU 1: Tesla P40
I1029 20:59:19.316902 27430 caffe.cpp:223] GPU 2: Tesla P40
I1029 20:59:19.317461 27430 caffe.cpp:223] GPU 3: Tesla P40
I1029 20:59:20.073609 27430 solver.cpp:44] Initializing solver from parameters: 
test_iter: 500
test_interval: 500
base_lr: 0.01
display: 40
max_iter: 50000
lr_policy: "exp"
gamma: 0.999876
momentum: 0.9
weight_decay: 0.0002
snapshot: 500
snapshot_prefix: "SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80"
solver_mode: GPU
device_id: 0
random_seed: 42
net: "SqueezeNet/SqueezeNet_v1.1/train_val_inq_60-80.prototxt"
train_state {
  level: 0
  stage: ""
}
I1029 20:59:20.075016 27430 solver.cpp:87] Creating training net from net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_60-80.prototxt
I1029 20:59:20.078172 27430 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1029 20:59:20.078260 27430 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top1
I1029 20:59:20.078269 27430 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top5
I1029 20:59:20.079270 27430 net.cpp:51] Initializing net from parameters: 
name: "SqueezeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/data/caffe-imagenet/ilsvrc12_train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "INQConvolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "fire3/concat"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire4/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool3"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "fire5/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire4/concat"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "fire5/concat"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire6/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool5"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "fire9/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire8/concat"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "INQConvolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "pool10"
  bottom: "label"
  top: "loss"
}
I1029 20:59:20.079849 27430 layer_factory.hpp:77] Creating layer data
I1029 20:59:20.086684 27430 db_lmdb.cpp:35] Opened lmdb /home/data/caffe-imagenet/ilsvrc12_train_lmdb
I1029 20:59:20.086779 27430 net.cpp:84] Creating Layer data
I1029 20:59:20.086802 27430 net.cpp:387] data -> data
I1029 20:59:20.086849 27430 net.cpp:387] data -> label
I1029 20:59:20.089712 27430 data_layer.cpp:45] output data size: 128,3,227,227
I1029 20:59:20.321405 27430 net.cpp:127] Setting up data
I1029 20:59:20.321449 27430 net.cpp:136] Top shape: 128 3 227 227 (19787136)
I1029 20:59:20.321456 27430 net.cpp:136] Top shape: 128 (128)
I1029 20:59:20.321460 27430 net.cpp:144] Memory required for data: 79149056
I1029 20:59:20.321475 27430 layer_factory.hpp:77] Creating layer conv1
I1029 20:59:20.321498 27430 net.cpp:84] Creating Layer conv1
I1029 20:59:20.321507 27430 net.cpp:413] conv1 <- data
I1029 20:59:20.321527 27430 net.cpp:387] conv1 -> conv1
I1029 20:59:20.324710 27430 net.cpp:127] Setting up conv1
I1029 20:59:20.324728 27430 net.cpp:136] Top shape: 128 64 113 113 (104603648)
I1029 20:59:20.324731 27430 net.cpp:144] Memory required for data: 497563648
I1029 20:59:20.324751 27430 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1029 20:59:20.324762 27430 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1029 20:59:20.324770 27430 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1029 20:59:20.324776 27430 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1029 20:59:20.324780 27430 layer_factory.hpp:77] Creating layer relu_conv1
I1029 20:59:20.324796 27430 net.cpp:84] Creating Layer relu_conv1
I1029 20:59:20.324800 27430 net.cpp:413] relu_conv1 <- conv1
I1029 20:59:20.324807 27430 net.cpp:374] relu_conv1 -> conv1 (in-place)
I1029 20:59:20.765384 27430 net.cpp:127] Setting up relu_conv1
I1029 20:59:20.765434 27430 net.cpp:136] Top shape: 128 64 113 113 (104603648)
I1029 20:59:20.765444 27430 net.cpp:144] Memory required for data: 915978240
I1029 20:59:20.765455 27430 layer_factory.hpp:77] Creating layer pool1
I1029 20:59:20.765478 27430 net.cpp:84] Creating Layer pool1
I1029 20:59:20.765487 27430 net.cpp:413] pool1 <- conv1
I1029 20:59:20.765502 27430 net.cpp:387] pool1 -> pool1
I1029 20:59:20.765630 27430 net.cpp:127] Setting up pool1
I1029 20:59:20.765682 27430 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1029 20:59:20.765689 27430 net.cpp:144] Memory required for data: 1018738688
I1029 20:59:20.765697 27430 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I1029 20:59:20.765722 27430 net.cpp:84] Creating Layer fire2/squeeze1x1
I1029 20:59:20.765728 27430 net.cpp:413] fire2/squeeze1x1 <- pool1
I1029 20:59:20.765740 27430 net.cpp:387] fire2/squeeze1x1 -> fire2/squeeze1x1
I1029 20:59:20.768142 27430 net.cpp:127] Setting up fire2/squeeze1x1
I1029 20:59:20.768167 27430 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1029 20:59:20.768175 27430 net.cpp:144] Memory required for data: 1044428800
I1029 20:59:20.768193 27430 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1029 20:59:20.768206 27430 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1029 20:59:20.768215 27430 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1029 20:59:20.768224 27430 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1029 20:59:20.768230 27430 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I1029 20:59:20.768244 27430 net.cpp:84] Creating Layer fire2/relu_squeeze1x1
I1029 20:59:20.768251 27430 net.cpp:413] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I1029 20:59:20.768260 27430 net.cpp:374] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I1029 20:59:20.770210 27430 net.cpp:127] Setting up fire2/relu_squeeze1x1
I1029 20:59:20.770234 27430 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1029 20:59:20.770241 27430 net.cpp:144] Memory required for data: 1070118912
I1029 20:59:20.770249 27430 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1029 20:59:20.770265 27430 net.cpp:84] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1029 20:59:20.770273 27430 net.cpp:413] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I1029 20:59:20.770284 27430 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1029 20:59:20.770298 27430 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1029 20:59:20.770371 27430 net.cpp:127] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1029 20:59:20.770383 27430 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1029 20:59:20.770392 27430 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1029 20:59:20.770398 27430 net.cpp:144] Memory required for data: 1121499136
I1029 20:59:20.770404 27430 layer_factory.hpp:77] Creating layer fire2/expand1x1
I1029 20:59:20.770419 27430 net.cpp:84] Creating Layer fire2/expand1x1
I1029 20:59:20.770426 27430 net.cpp:413] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1029 20:59:20.770437 27430 net.cpp:387] fire2/expand1x1 -> fire2/expand1x1
I1029 20:59:20.770933 27430 net.cpp:127] Setting up fire2/expand1x1
I1029 20:59:20.770949 27430 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1029 20:59:20.770956 27430 net.cpp:144] Memory required for data: 1224259584
I1029 20:59:20.770969 27430 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1029 20:59:20.770982 27430 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1029 20:59:20.770990 27430 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1029 20:59:20.770999 27430 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1029 20:59:20.771006 27430 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I1029 20:59:20.771019 27430 net.cpp:84] Creating Layer fire2/relu_expand1x1
I1029 20:59:20.771026 27430 net.cpp:413] fire2/relu_expand1x1 <- fire2/expand1x1
I1029 20:59:20.771035 27430 net.cpp:374] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I1029 20:59:20.771332 27430 net.cpp:127] Setting up fire2/relu_expand1x1
I1029 20:59:20.771347 27430 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1029 20:59:20.771358 27430 net.cpp:144] Memory required for data: 1327020032
I1029 20:59:20.771384 27430 layer_factory.hpp:77] Creating layer fire2/expand3x3
I1029 20:59:20.771400 27430 net.cpp:84] Creating Layer fire2/expand3x3
I1029 20:59:20.771409 27430 net.cpp:413] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1029 20:59:20.771420 27430 net.cpp:387] fire2/expand3x3 -> fire2/expand3x3
I1029 20:59:20.772042 27430 net.cpp:127] Setting up fire2/expand3x3
I1029 20:59:20.772059 27430 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1029 20:59:20.772065 27430 net.cpp:144] Memory required for data: 1429780480
I1029 20:59:20.772075 27430 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1029 20:59:20.772085 27430 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1029 20:59:20.772094 27430 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1029 20:59:20.772119 27430 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1029 20:59:20.772126 27430 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I1029 20:59:20.772136 27430 net.cpp:84] Creating Layer fire2/relu_expand3x3
I1029 20:59:20.772143 27430 net.cpp:413] fire2/relu_expand3x3 <- fire2/expand3x3
I1029 20:59:20.772151 27430 net.cpp:374] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I1029 20:59:20.772428 27430 net.cpp:127] Setting up fire2/relu_expand3x3
I1029 20:59:20.772441 27430 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1029 20:59:20.772447 27430 net.cpp:144] Memory required for data: 1532540928
I1029 20:59:20.772454 27430 layer_factory.hpp:77] Creating layer fire2/concat
I1029 20:59:20.772469 27430 net.cpp:84] Creating Layer fire2/concat
I1029 20:59:20.772475 27430 net.cpp:413] fire2/concat <- fire2/expand1x1
I1029 20:59:20.772482 27430 net.cpp:413] fire2/concat <- fire2/expand3x3
I1029 20:59:20.772491 27430 net.cpp:387] fire2/concat -> fire2/concat
I1029 20:59:20.772536 27430 net.cpp:127] Setting up fire2/concat
I1029 20:59:20.772547 27430 net.cpp:136] Top shape: 128 128 56 56 (51380224)
I1029 20:59:20.772553 27430 net.cpp:144] Memory required for data: 1738061824
I1029 20:59:20.772558 27430 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I1029 20:59:20.772572 27430 net.cpp:84] Creating Layer fire3/squeeze1x1
I1029 20:59:20.772578 27430 net.cpp:413] fire3/squeeze1x1 <- fire2/concat
I1029 20:59:20.772588 27430 net.cpp:387] fire3/squeeze1x1 -> fire3/squeeze1x1
I1029 20:59:20.773052 27430 net.cpp:127] Setting up fire3/squeeze1x1
I1029 20:59:20.773066 27430 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1029 20:59:20.773072 27430 net.cpp:144] Memory required for data: 1763751936
I1029 20:59:20.773084 27430 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1029 20:59:20.773095 27430 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1029 20:59:20.773103 27430 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1029 20:59:20.773111 27430 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1029 20:59:20.773118 27430 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I1029 20:59:20.773126 27430 net.cpp:84] Creating Layer fire3/relu_squeeze1x1
I1029 20:59:20.773133 27430 net.cpp:413] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I1029 20:59:20.773141 27430 net.cpp:374] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I1029 20:59:20.775089 27430 net.cpp:127] Setting up fire3/relu_squeeze1x1
I1029 20:59:20.775110 27430 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1029 20:59:20.775117 27430 net.cpp:144] Memory required for data: 1789442048
I1029 20:59:20.775125 27430 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1029 20:59:20.775136 27430 net.cpp:84] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1029 20:59:20.775143 27430 net.cpp:413] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I1029 20:59:20.775159 27430 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1029 20:59:20.775190 27430 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1029 20:59:20.775259 27430 net.cpp:127] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1029 20:59:20.775270 27430 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1029 20:59:20.775279 27430 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1029 20:59:20.775285 27430 net.cpp:144] Memory required for data: 1840822272
I1029 20:59:20.775290 27430 layer_factory.hpp:77] Creating layer fire3/expand1x1
I1029 20:59:20.775303 27430 net.cpp:84] Creating Layer fire3/expand1x1
I1029 20:59:20.775310 27430 net.cpp:413] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1029 20:59:20.775321 27430 net.cpp:387] fire3/expand1x1 -> fire3/expand1x1
I1029 20:59:20.775764 27430 net.cpp:127] Setting up fire3/expand1x1
I1029 20:59:20.775777 27430 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1029 20:59:20.775784 27430 net.cpp:144] Memory required for data: 1943582720
I1029 20:59:20.775794 27430 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1029 20:59:20.775802 27430 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1029 20:59:20.775810 27430 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1029 20:59:20.775817 27430 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1029 20:59:20.775823 27430 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I1029 20:59:20.775835 27430 net.cpp:84] Creating Layer fire3/relu_expand1x1
I1029 20:59:20.775842 27430 net.cpp:413] fire3/relu_expand1x1 <- fire3/expand1x1
I1029 20:59:20.775851 27430 net.cpp:374] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I1029 20:59:20.776134 27430 net.cpp:127] Setting up fire3/relu_expand1x1
I1029 20:59:20.776149 27430 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1029 20:59:20.776155 27430 net.cpp:144] Memory required for data: 2046343168
I1029 20:59:20.776162 27430 layer_factory.hpp:77] Creating layer fire3/expand3x3
I1029 20:59:20.776175 27430 net.cpp:84] Creating Layer fire3/expand3x3
I1029 20:59:20.776182 27430 net.cpp:413] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1029 20:59:20.776193 27430 net.cpp:387] fire3/expand3x3 -> fire3/expand3x3
I1029 20:59:20.776748 27430 net.cpp:127] Setting up fire3/expand3x3
I1029 20:59:20.776762 27430 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1029 20:59:20.776768 27430 net.cpp:144] Memory required for data: 2149103616
I1029 20:59:20.776777 27430 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1029 20:59:20.776787 27430 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1029 20:59:20.776794 27430 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1029 20:59:20.776803 27430 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1029 20:59:20.776808 27430 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I1029 20:59:20.776818 27430 net.cpp:84] Creating Layer fire3/relu_expand3x3
I1029 20:59:20.776824 27430 net.cpp:413] fire3/relu_expand3x3 <- fire3/expand3x3
I1029 20:59:20.776834 27430 net.cpp:374] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I1029 20:59:20.777118 27430 net.cpp:127] Setting up fire3/relu_expand3x3
I1029 20:59:20.777132 27430 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1029 20:59:20.777138 27430 net.cpp:144] Memory required for data: 2251864064
I1029 20:59:20.777144 27430 layer_factory.hpp:77] Creating layer fire3/concat
I1029 20:59:20.777155 27430 net.cpp:84] Creating Layer fire3/concat
I1029 20:59:20.777161 27430 net.cpp:413] fire3/concat <- fire3/expand1x1
I1029 20:59:20.777169 27430 net.cpp:413] fire3/concat <- fire3/expand3x3
I1029 20:59:20.777178 27430 net.cpp:387] fire3/concat -> fire3/concat
I1029 20:59:20.777225 27430 net.cpp:127] Setting up fire3/concat
I1029 20:59:20.777235 27430 net.cpp:136] Top shape: 128 128 56 56 (51380224)
I1029 20:59:20.777257 27430 net.cpp:144] Memory required for data: 2457384960
I1029 20:59:20.777264 27430 layer_factory.hpp:77] Creating layer pool3
I1029 20:59:20.777276 27430 net.cpp:84] Creating Layer pool3
I1029 20:59:20.777281 27430 net.cpp:413] pool3 <- fire3/concat
I1029 20:59:20.777290 27430 net.cpp:387] pool3 -> pool3
I1029 20:59:20.777353 27430 net.cpp:127] Setting up pool3
I1029 20:59:20.777364 27430 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1029 20:59:20.777369 27430 net.cpp:144] Memory required for data: 2508765184
I1029 20:59:20.777375 27430 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I1029 20:59:20.777387 27430 net.cpp:84] Creating Layer fire4/squeeze1x1
I1029 20:59:20.777395 27430 net.cpp:413] fire4/squeeze1x1 <- pool3
I1029 20:59:20.777405 27430 net.cpp:387] fire4/squeeze1x1 -> fire4/squeeze1x1
I1029 20:59:20.777892 27430 net.cpp:127] Setting up fire4/squeeze1x1
I1029 20:59:20.777906 27430 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1029 20:59:20.777912 27430 net.cpp:144] Memory required for data: 2521610240
I1029 20:59:20.777930 27430 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1029 20:59:20.777938 27430 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1029 20:59:20.777946 27430 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1029 20:59:20.777953 27430 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1029 20:59:20.777961 27430 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I1029 20:59:20.777971 27430 net.cpp:84] Creating Layer fire4/relu_squeeze1x1
I1029 20:59:20.777977 27430 net.cpp:413] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I1029 20:59:20.777986 27430 net.cpp:374] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I1029 20:59:20.778265 27430 net.cpp:127] Setting up fire4/relu_squeeze1x1
I1029 20:59:20.778280 27430 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1029 20:59:20.778286 27430 net.cpp:144] Memory required for data: 2534455296
I1029 20:59:20.778292 27430 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1029 20:59:20.778302 27430 net.cpp:84] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1029 20:59:20.778308 27430 net.cpp:413] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I1029 20:59:20.778317 27430 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1029 20:59:20.778328 27430 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1029 20:59:20.778389 27430 net.cpp:127] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1029 20:59:20.778399 27430 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1029 20:59:20.778408 27430 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1029 20:59:20.778412 27430 net.cpp:144] Memory required for data: 2560145408
I1029 20:59:20.778419 27430 layer_factory.hpp:77] Creating layer fire4/expand1x1
I1029 20:59:20.778430 27430 net.cpp:84] Creating Layer fire4/expand1x1
I1029 20:59:20.778436 27430 net.cpp:413] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1029 20:59:20.778446 27430 net.cpp:387] fire4/expand1x1 -> fire4/expand1x1
I1029 20:59:20.778915 27430 net.cpp:127] Setting up fire4/expand1x1
I1029 20:59:20.778936 27430 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1029 20:59:20.778942 27430 net.cpp:144] Memory required for data: 2611525632
I1029 20:59:20.778956 27430 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1029 20:59:20.778969 27430 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1029 20:59:20.778977 27430 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1029 20:59:20.778985 27430 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1029 20:59:20.778995 27430 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I1029 20:59:20.779021 27430 net.cpp:84] Creating Layer fire4/relu_expand1x1
I1029 20:59:20.779029 27430 net.cpp:413] fire4/relu_expand1x1 <- fire4/expand1x1
I1029 20:59:20.779037 27430 net.cpp:374] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I1029 20:59:20.780980 27430 net.cpp:127] Setting up fire4/relu_expand1x1
I1029 20:59:20.781002 27430 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1029 20:59:20.781009 27430 net.cpp:144] Memory required for data: 2662905856
I1029 20:59:20.781016 27430 layer_factory.hpp:77] Creating layer fire4/expand3x3
I1029 20:59:20.781031 27430 net.cpp:84] Creating Layer fire4/expand3x3
I1029 20:59:20.781038 27430 net.cpp:413] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1029 20:59:20.781050 27430 net.cpp:387] fire4/expand3x3 -> fire4/expand3x3
I1029 20:59:20.783545 27430 net.cpp:127] Setting up fire4/expand3x3
I1029 20:59:20.783566 27430 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1029 20:59:20.783572 27430 net.cpp:144] Memory required for data: 2714286080
I1029 20:59:20.783582 27430 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1029 20:59:20.783591 27430 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1029 20:59:20.783598 27430 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1029 20:59:20.783605 27430 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1029 20:59:20.783612 27430 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I1029 20:59:20.783622 27430 net.cpp:84] Creating Layer fire4/relu_expand3x3
I1029 20:59:20.783628 27430 net.cpp:413] fire4/relu_expand3x3 <- fire4/expand3x3
I1029 20:59:20.783638 27430 net.cpp:374] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I1029 20:59:20.783910 27430 net.cpp:127] Setting up fire4/relu_expand3x3
I1029 20:59:20.783931 27430 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1029 20:59:20.783937 27430 net.cpp:144] Memory required for data: 2765666304
I1029 20:59:20.783943 27430 layer_factory.hpp:77] Creating layer fire4/concat
I1029 20:59:20.783953 27430 net.cpp:84] Creating Layer fire4/concat
I1029 20:59:20.783960 27430 net.cpp:413] fire4/concat <- fire4/expand1x1
I1029 20:59:20.783967 27430 net.cpp:413] fire4/concat <- fire4/expand3x3
I1029 20:59:20.783975 27430 net.cpp:387] fire4/concat -> fire4/concat
I1029 20:59:20.784018 27430 net.cpp:127] Setting up fire4/concat
I1029 20:59:20.784027 27430 net.cpp:136] Top shape: 128 256 28 28 (25690112)
I1029 20:59:20.784032 27430 net.cpp:144] Memory required for data: 2868426752
I1029 20:59:20.784037 27430 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I1029 20:59:20.784050 27430 net.cpp:84] Creating Layer fire5/squeeze1x1
I1029 20:59:20.784056 27430 net.cpp:413] fire5/squeeze1x1 <- fire4/concat
I1029 20:59:20.784065 27430 net.cpp:387] fire5/squeeze1x1 -> fire5/squeeze1x1
I1029 20:59:20.784580 27430 net.cpp:127] Setting up fire5/squeeze1x1
I1029 20:59:20.784593 27430 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1029 20:59:20.784600 27430 net.cpp:144] Memory required for data: 2881271808
I1029 20:59:20.784608 27430 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1029 20:59:20.784616 27430 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1029 20:59:20.784623 27430 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1029 20:59:20.784631 27430 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1029 20:59:20.784636 27430 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I1029 20:59:20.784646 27430 net.cpp:84] Creating Layer fire5/relu_squeeze1x1
I1029 20:59:20.784651 27430 net.cpp:413] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I1029 20:59:20.784659 27430 net.cpp:374] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I1029 20:59:20.784934 27430 net.cpp:127] Setting up fire5/relu_squeeze1x1
I1029 20:59:20.784953 27430 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1029 20:59:20.784976 27430 net.cpp:144] Memory required for data: 2894116864
I1029 20:59:20.784983 27430 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1029 20:59:20.784992 27430 net.cpp:84] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1029 20:59:20.784998 27430 net.cpp:413] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I1029 20:59:20.785007 27430 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1029 20:59:20.785018 27430 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1029 20:59:20.785080 27430 net.cpp:127] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1029 20:59:20.785091 27430 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1029 20:59:20.785099 27430 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1029 20:59:20.785104 27430 net.cpp:144] Memory required for data: 2919806976
I1029 20:59:20.785109 27430 layer_factory.hpp:77] Creating layer fire5/expand1x1
I1029 20:59:20.785125 27430 net.cpp:84] Creating Layer fire5/expand1x1
I1029 20:59:20.785131 27430 net.cpp:413] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1029 20:59:20.785141 27430 net.cpp:387] fire5/expand1x1 -> fire5/expand1x1
I1029 20:59:20.785589 27430 net.cpp:127] Setting up fire5/expand1x1
I1029 20:59:20.785601 27430 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1029 20:59:20.785607 27430 net.cpp:144] Memory required for data: 2971187200
I1029 20:59:20.785616 27430 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1029 20:59:20.785624 27430 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1029 20:59:20.785631 27430 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1029 20:59:20.785639 27430 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1029 20:59:20.785645 27430 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I1029 20:59:20.785653 27430 net.cpp:84] Creating Layer fire5/relu_expand1x1
I1029 20:59:20.785660 27430 net.cpp:413] fire5/relu_expand1x1 <- fire5/expand1x1
I1029 20:59:20.785667 27430 net.cpp:374] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I1029 20:59:20.785944 27430 net.cpp:127] Setting up fire5/relu_expand1x1
I1029 20:59:20.785959 27430 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1029 20:59:20.785964 27430 net.cpp:144] Memory required for data: 3022567424
I1029 20:59:20.785969 27430 layer_factory.hpp:77] Creating layer fire5/expand3x3
I1029 20:59:20.785982 27430 net.cpp:84] Creating Layer fire5/expand3x3
I1029 20:59:20.785989 27430 net.cpp:413] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1029 20:59:20.786000 27430 net.cpp:387] fire5/expand3x3 -> fire5/expand3x3
I1029 20:59:20.786804 27430 net.cpp:127] Setting up fire5/expand3x3
I1029 20:59:20.786818 27430 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1029 20:59:20.786824 27430 net.cpp:144] Memory required for data: 3073947648
I1029 20:59:20.786833 27430 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1029 20:59:20.786840 27430 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1029 20:59:20.786849 27430 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1029 20:59:20.786854 27430 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1029 20:59:20.786860 27430 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I1029 20:59:20.786870 27430 net.cpp:84] Creating Layer fire5/relu_expand3x3
I1029 20:59:20.786876 27430 net.cpp:413] fire5/relu_expand3x3 <- fire5/expand3x3
I1029 20:59:20.786885 27430 net.cpp:374] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I1029 20:59:20.788743 27430 net.cpp:127] Setting up fire5/relu_expand3x3
I1029 20:59:20.788763 27430 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1029 20:59:20.788774 27430 net.cpp:144] Memory required for data: 3125327872
I1029 20:59:20.788797 27430 layer_factory.hpp:77] Creating layer fire5/concat
I1029 20:59:20.788810 27430 net.cpp:84] Creating Layer fire5/concat
I1029 20:59:20.788816 27430 net.cpp:413] fire5/concat <- fire5/expand1x1
I1029 20:59:20.788825 27430 net.cpp:413] fire5/concat <- fire5/expand3x3
I1029 20:59:20.788833 27430 net.cpp:387] fire5/concat -> fire5/concat
I1029 20:59:20.788880 27430 net.cpp:127] Setting up fire5/concat
I1029 20:59:20.788890 27430 net.cpp:136] Top shape: 128 256 28 28 (25690112)
I1029 20:59:20.788897 27430 net.cpp:144] Memory required for data: 3228088320
I1029 20:59:20.788902 27430 layer_factory.hpp:77] Creating layer pool5
I1029 20:59:20.788913 27430 net.cpp:84] Creating Layer pool5
I1029 20:59:20.788926 27430 net.cpp:413] pool5 <- fire5/concat
I1029 20:59:20.788934 27430 net.cpp:387] pool5 -> pool5
I1029 20:59:20.788992 27430 net.cpp:127] Setting up pool5
I1029 20:59:20.789002 27430 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1029 20:59:20.789007 27430 net.cpp:144] Memory required for data: 3253778432
I1029 20:59:20.789013 27430 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I1029 20:59:20.789026 27430 net.cpp:84] Creating Layer fire6/squeeze1x1
I1029 20:59:20.789032 27430 net.cpp:413] fire6/squeeze1x1 <- pool5
I1029 20:59:20.789041 27430 net.cpp:387] fire6/squeeze1x1 -> fire6/squeeze1x1
I1029 20:59:20.789604 27430 net.cpp:127] Setting up fire6/squeeze1x1
I1029 20:59:20.789618 27430 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1029 20:59:20.789623 27430 net.cpp:144] Memory required for data: 3258595328
I1029 20:59:20.789633 27430 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1029 20:59:20.789641 27430 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1029 20:59:20.789649 27430 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1029 20:59:20.789655 27430 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1029 20:59:20.789661 27430 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I1029 20:59:20.789670 27430 net.cpp:84] Creating Layer fire6/relu_squeeze1x1
I1029 20:59:20.789677 27430 net.cpp:413] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I1029 20:59:20.789685 27430 net.cpp:374] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I1029 20:59:20.789950 27430 net.cpp:127] Setting up fire6/relu_squeeze1x1
I1029 20:59:20.789963 27430 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1029 20:59:20.789968 27430 net.cpp:144] Memory required for data: 3263412224
I1029 20:59:20.789974 27430 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1029 20:59:20.789984 27430 net.cpp:84] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1029 20:59:20.789990 27430 net.cpp:413] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I1029 20:59:20.789999 27430 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1029 20:59:20.790010 27430 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1029 20:59:20.790079 27430 net.cpp:127] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1029 20:59:20.790089 27430 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1029 20:59:20.790098 27430 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1029 20:59:20.790103 27430 net.cpp:144] Memory required for data: 3273046016
I1029 20:59:20.790108 27430 layer_factory.hpp:77] Creating layer fire6/expand1x1
I1029 20:59:20.790120 27430 net.cpp:84] Creating Layer fire6/expand1x1
I1029 20:59:20.790127 27430 net.cpp:413] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1029 20:59:20.790136 27430 net.cpp:387] fire6/expand1x1 -> fire6/expand1x1
I1029 20:59:20.790645 27430 net.cpp:127] Setting up fire6/expand1x1
I1029 20:59:20.790658 27430 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1029 20:59:20.790669 27430 net.cpp:144] Memory required for data: 3292313600
I1029 20:59:20.790693 27430 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1029 20:59:20.790701 27430 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1029 20:59:20.790709 27430 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1029 20:59:20.790716 27430 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1029 20:59:20.790721 27430 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I1029 20:59:20.790730 27430 net.cpp:84] Creating Layer fire6/relu_expand1x1
I1029 20:59:20.790737 27430 net.cpp:413] fire6/relu_expand1x1 <- fire6/expand1x1
I1029 20:59:20.790745 27430 net.cpp:374] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I1029 20:59:20.791013 27430 net.cpp:127] Setting up fire6/relu_expand1x1
I1029 20:59:20.791026 27430 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1029 20:59:20.791033 27430 net.cpp:144] Memory required for data: 3311581184
I1029 20:59:20.791038 27430 layer_factory.hpp:77] Creating layer fire6/expand3x3
I1029 20:59:20.791051 27430 net.cpp:84] Creating Layer fire6/expand3x3
I1029 20:59:20.791059 27430 net.cpp:413] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1029 20:59:20.791069 27430 net.cpp:387] fire6/expand3x3 -> fire6/expand3x3
I1029 20:59:20.793987 27430 net.cpp:127] Setting up fire6/expand3x3
I1029 20:59:20.794006 27430 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1029 20:59:20.794013 27430 net.cpp:144] Memory required for data: 3330848768
I1029 20:59:20.794021 27430 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1029 20:59:20.794029 27430 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1029 20:59:20.794036 27430 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1029 20:59:20.794044 27430 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1029 20:59:20.794049 27430 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I1029 20:59:20.794059 27430 net.cpp:84] Creating Layer fire6/relu_expand3x3
I1029 20:59:20.794064 27430 net.cpp:413] fire6/relu_expand3x3 <- fire6/expand3x3
I1029 20:59:20.794073 27430 net.cpp:374] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I1029 20:59:20.794343 27430 net.cpp:127] Setting up fire6/relu_expand3x3
I1029 20:59:20.794358 27430 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1029 20:59:20.794363 27430 net.cpp:144] Memory required for data: 3350116352
I1029 20:59:20.794368 27430 layer_factory.hpp:77] Creating layer fire6/concat
I1029 20:59:20.794378 27430 net.cpp:84] Creating Layer fire6/concat
I1029 20:59:20.794385 27430 net.cpp:413] fire6/concat <- fire6/expand1x1
I1029 20:59:20.794392 27430 net.cpp:413] fire6/concat <- fire6/expand3x3
I1029 20:59:20.794400 27430 net.cpp:387] fire6/concat -> fire6/concat
I1029 20:59:20.794441 27430 net.cpp:127] Setting up fire6/concat
I1029 20:59:20.794450 27430 net.cpp:136] Top shape: 128 384 14 14 (9633792)
I1029 20:59:20.794456 27430 net.cpp:144] Memory required for data: 3388651520
I1029 20:59:20.794461 27430 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I1029 20:59:20.794472 27430 net.cpp:84] Creating Layer fire7/squeeze1x1
I1029 20:59:20.794478 27430 net.cpp:413] fire7/squeeze1x1 <- fire6/concat
I1029 20:59:20.794486 27430 net.cpp:387] fire7/squeeze1x1 -> fire7/squeeze1x1
I1029 20:59:20.795071 27430 net.cpp:127] Setting up fire7/squeeze1x1
I1029 20:59:20.795084 27430 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1029 20:59:20.795089 27430 net.cpp:144] Memory required for data: 3393468416
I1029 20:59:20.795104 27430 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1029 20:59:20.795116 27430 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1029 20:59:20.795123 27430 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1029 20:59:20.795130 27430 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1029 20:59:20.795141 27430 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I1029 20:59:20.795171 27430 net.cpp:84] Creating Layer fire7/relu_squeeze1x1
I1029 20:59:20.795178 27430 net.cpp:413] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I1029 20:59:20.795186 27430 net.cpp:374] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I1029 20:59:20.796924 27430 net.cpp:127] Setting up fire7/relu_squeeze1x1
I1029 20:59:20.796943 27430 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1029 20:59:20.796950 27430 net.cpp:144] Memory required for data: 3398285312
I1029 20:59:20.796957 27430 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1029 20:59:20.796967 27430 net.cpp:84] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1029 20:59:20.796973 27430 net.cpp:413] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I1029 20:59:20.796983 27430 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1029 20:59:20.796994 27430 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1029 20:59:20.797056 27430 net.cpp:127] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1029 20:59:20.797066 27430 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1029 20:59:20.797073 27430 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1029 20:59:20.797078 27430 net.cpp:144] Memory required for data: 3407919104
I1029 20:59:20.797085 27430 layer_factory.hpp:77] Creating layer fire7/expand1x1
I1029 20:59:20.797096 27430 net.cpp:84] Creating Layer fire7/expand1x1
I1029 20:59:20.797102 27430 net.cpp:413] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1029 20:59:20.797111 27430 net.cpp:387] fire7/expand1x1 -> fire7/expand1x1
I1029 20:59:20.797595 27430 net.cpp:127] Setting up fire7/expand1x1
I1029 20:59:20.797607 27430 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1029 20:59:20.797612 27430 net.cpp:144] Memory required for data: 3427186688
I1029 20:59:20.797621 27430 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1029 20:59:20.797629 27430 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1029 20:59:20.797636 27430 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1029 20:59:20.797642 27430 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1029 20:59:20.797648 27430 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I1029 20:59:20.797657 27430 net.cpp:84] Creating Layer fire7/relu_expand1x1
I1029 20:59:20.797662 27430 net.cpp:413] fire7/relu_expand1x1 <- fire7/expand1x1
I1029 20:59:20.797670 27430 net.cpp:374] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I1029 20:59:20.797912 27430 net.cpp:127] Setting up fire7/relu_expand1x1
I1029 20:59:20.797932 27430 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1029 20:59:20.797937 27430 net.cpp:144] Memory required for data: 3446454272
I1029 20:59:20.797943 27430 layer_factory.hpp:77] Creating layer fire7/expand3x3
I1029 20:59:20.797955 27430 net.cpp:84] Creating Layer fire7/expand3x3
I1029 20:59:20.797962 27430 net.cpp:413] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1029 20:59:20.797971 27430 net.cpp:387] fire7/expand3x3 -> fire7/expand3x3
I1029 20:59:20.799216 27430 net.cpp:127] Setting up fire7/expand3x3
I1029 20:59:20.799229 27430 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1029 20:59:20.799235 27430 net.cpp:144] Memory required for data: 3465721856
I1029 20:59:20.799244 27430 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1029 20:59:20.799253 27430 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1029 20:59:20.799259 27430 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1029 20:59:20.799266 27430 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1029 20:59:20.799278 27430 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I1029 20:59:20.799302 27430 net.cpp:84] Creating Layer fire7/relu_expand3x3
I1029 20:59:20.799309 27430 net.cpp:413] fire7/relu_expand3x3 <- fire7/expand3x3
I1029 20:59:20.799317 27430 net.cpp:374] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I1029 20:59:20.799559 27430 net.cpp:127] Setting up fire7/relu_expand3x3
I1029 20:59:20.799572 27430 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1029 20:59:20.799578 27430 net.cpp:144] Memory required for data: 3484989440
I1029 20:59:20.799583 27430 layer_factory.hpp:77] Creating layer fire7/concat
I1029 20:59:20.799593 27430 net.cpp:84] Creating Layer fire7/concat
I1029 20:59:20.799598 27430 net.cpp:413] fire7/concat <- fire7/expand1x1
I1029 20:59:20.799605 27430 net.cpp:413] fire7/concat <- fire7/expand3x3
I1029 20:59:20.799613 27430 net.cpp:387] fire7/concat -> fire7/concat
I1029 20:59:20.799652 27430 net.cpp:127] Setting up fire7/concat
I1029 20:59:20.799662 27430 net.cpp:136] Top shape: 128 384 14 14 (9633792)
I1029 20:59:20.799667 27430 net.cpp:144] Memory required for data: 3523524608
I1029 20:59:20.799672 27430 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I1029 20:59:20.799685 27430 net.cpp:84] Creating Layer fire8/squeeze1x1
I1029 20:59:20.799690 27430 net.cpp:413] fire8/squeeze1x1 <- fire7/concat
I1029 20:59:20.799698 27430 net.cpp:387] fire8/squeeze1x1 -> fire8/squeeze1x1
I1029 20:59:20.800338 27430 net.cpp:127] Setting up fire8/squeeze1x1
I1029 20:59:20.800350 27430 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1029 20:59:20.800356 27430 net.cpp:144] Memory required for data: 3529947136
I1029 20:59:20.800364 27430 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1029 20:59:20.800372 27430 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1029 20:59:20.800379 27430 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1029 20:59:20.800385 27430 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1029 20:59:20.800390 27430 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I1029 20:59:20.800400 27430 net.cpp:84] Creating Layer fire8/relu_squeeze1x1
I1029 20:59:20.800405 27430 net.cpp:413] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I1029 20:59:20.800412 27430 net.cpp:374] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I1029 20:59:20.802007 27430 net.cpp:127] Setting up fire8/relu_squeeze1x1
I1029 20:59:20.802026 27430 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1029 20:59:20.802033 27430 net.cpp:144] Memory required for data: 3536369664
I1029 20:59:20.802039 27430 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1029 20:59:20.802049 27430 net.cpp:84] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1029 20:59:20.802055 27430 net.cpp:413] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I1029 20:59:20.802064 27430 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1029 20:59:20.802075 27430 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1029 20:59:20.802146 27430 net.cpp:127] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1029 20:59:20.802155 27430 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1029 20:59:20.802162 27430 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1029 20:59:20.802166 27430 net.cpp:144] Memory required for data: 3549214720
I1029 20:59:20.802171 27430 layer_factory.hpp:77] Creating layer fire8/expand1x1
I1029 20:59:20.802183 27430 net.cpp:84] Creating Layer fire8/expand1x1
I1029 20:59:20.802189 27430 net.cpp:413] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1029 20:59:20.802197 27430 net.cpp:387] fire8/expand1x1 -> fire8/expand1x1
I1029 20:59:20.802719 27430 net.cpp:127] Setting up fire8/expand1x1
I1029 20:59:20.802731 27430 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1029 20:59:20.802742 27430 net.cpp:144] Memory required for data: 3574904832
I1029 20:59:20.802764 27430 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1029 20:59:20.802773 27430 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1029 20:59:20.802779 27430 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1029 20:59:20.802785 27430 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1029 20:59:20.802791 27430 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I1029 20:59:20.802799 27430 net.cpp:84] Creating Layer fire8/relu_expand1x1
I1029 20:59:20.802805 27430 net.cpp:413] fire8/relu_expand1x1 <- fire8/expand1x1
I1029 20:59:20.802814 27430 net.cpp:374] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I1029 20:59:20.803050 27430 net.cpp:127] Setting up fire8/relu_expand1x1
I1029 20:59:20.803062 27430 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1029 20:59:20.803067 27430 net.cpp:144] Memory required for data: 3600594944
I1029 20:59:20.803072 27430 layer_factory.hpp:77] Creating layer fire8/expand3x3
I1029 20:59:20.803084 27430 net.cpp:84] Creating Layer fire8/expand3x3
I1029 20:59:20.803091 27430 net.cpp:413] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1029 20:59:20.803099 27430 net.cpp:387] fire8/expand3x3 -> fire8/expand3x3
I1029 20:59:20.806391 27430 net.cpp:127] Setting up fire8/expand3x3
I1029 20:59:20.806411 27430 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1029 20:59:20.806416 27430 net.cpp:144] Memory required for data: 3626285056
I1029 20:59:20.806424 27430 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1029 20:59:20.806432 27430 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1029 20:59:20.806439 27430 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1029 20:59:20.806445 27430 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1029 20:59:20.806450 27430 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I1029 20:59:20.806459 27430 net.cpp:84] Creating Layer fire8/relu_expand3x3
I1029 20:59:20.806465 27430 net.cpp:413] fire8/relu_expand3x3 <- fire8/expand3x3
I1029 20:59:20.806473 27430 net.cpp:374] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I1029 20:59:20.806715 27430 net.cpp:127] Setting up fire8/relu_expand3x3
I1029 20:59:20.806727 27430 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1029 20:59:20.806732 27430 net.cpp:144] Memory required for data: 3651975168
I1029 20:59:20.806738 27430 layer_factory.hpp:77] Creating layer fire8/concat
I1029 20:59:20.806747 27430 net.cpp:84] Creating Layer fire8/concat
I1029 20:59:20.806752 27430 net.cpp:413] fire8/concat <- fire8/expand1x1
I1029 20:59:20.806759 27430 net.cpp:413] fire8/concat <- fire8/expand3x3
I1029 20:59:20.806766 27430 net.cpp:387] fire8/concat -> fire8/concat
I1029 20:59:20.806805 27430 net.cpp:127] Setting up fire8/concat
I1029 20:59:20.806814 27430 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1029 20:59:20.806819 27430 net.cpp:144] Memory required for data: 3703355392
I1029 20:59:20.806824 27430 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I1029 20:59:20.806836 27430 net.cpp:84] Creating Layer fire9/squeeze1x1
I1029 20:59:20.806841 27430 net.cpp:413] fire9/squeeze1x1 <- fire8/concat
I1029 20:59:20.806850 27430 net.cpp:387] fire9/squeeze1x1 -> fire9/squeeze1x1
I1029 20:59:20.807539 27430 net.cpp:127] Setting up fire9/squeeze1x1
I1029 20:59:20.807552 27430 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1029 20:59:20.807557 27430 net.cpp:144] Memory required for data: 3709777920
I1029 20:59:20.807565 27430 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1029 20:59:20.807572 27430 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1029 20:59:20.807579 27430 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1029 20:59:20.807585 27430 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1029 20:59:20.807613 27430 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I1029 20:59:20.807623 27430 net.cpp:84] Creating Layer fire9/relu_squeeze1x1
I1029 20:59:20.807629 27430 net.cpp:413] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I1029 20:59:20.807636 27430 net.cpp:374] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I1029 20:59:20.807873 27430 net.cpp:127] Setting up fire9/relu_squeeze1x1
I1029 20:59:20.807885 27430 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1029 20:59:20.807890 27430 net.cpp:144] Memory required for data: 3716200448
I1029 20:59:20.807895 27430 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1029 20:59:20.807910 27430 net.cpp:84] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1029 20:59:20.807916 27430 net.cpp:413] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I1029 20:59:20.807931 27430 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1029 20:59:20.807941 27430 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1029 20:59:20.807997 27430 net.cpp:127] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1029 20:59:20.808007 27430 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1029 20:59:20.808012 27430 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1029 20:59:20.808017 27430 net.cpp:144] Memory required for data: 3729045504
I1029 20:59:20.808023 27430 layer_factory.hpp:77] Creating layer fire9/expand1x1
I1029 20:59:20.808034 27430 net.cpp:84] Creating Layer fire9/expand1x1
I1029 20:59:20.808039 27430 net.cpp:413] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1029 20:59:20.808048 27430 net.cpp:387] fire9/expand1x1 -> fire9/expand1x1
I1029 20:59:20.808570 27430 net.cpp:127] Setting up fire9/expand1x1
I1029 20:59:20.808583 27430 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1029 20:59:20.808588 27430 net.cpp:144] Memory required for data: 3754735616
I1029 20:59:20.808594 27430 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1029 20:59:20.808603 27430 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1029 20:59:20.808609 27430 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1029 20:59:20.808615 27430 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1029 20:59:20.808620 27430 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I1029 20:59:20.808629 27430 net.cpp:84] Creating Layer fire9/relu_expand1x1
I1029 20:59:20.808634 27430 net.cpp:413] fire9/relu_expand1x1 <- fire9/expand1x1
I1029 20:59:20.808641 27430 net.cpp:374] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I1029 20:59:20.810309 27430 net.cpp:127] Setting up fire9/relu_expand1x1
I1029 20:59:20.810329 27430 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1029 20:59:20.810334 27430 net.cpp:144] Memory required for data: 3780425728
I1029 20:59:20.810340 27430 layer_factory.hpp:77] Creating layer fire9/expand3x3
I1029 20:59:20.810353 27430 net.cpp:84] Creating Layer fire9/expand3x3
I1029 20:59:20.810359 27430 net.cpp:413] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1029 20:59:20.810369 27430 net.cpp:387] fire9/expand3x3 -> fire9/expand3x3
I1029 20:59:20.812183 27430 net.cpp:127] Setting up fire9/expand3x3
I1029 20:59:20.812197 27430 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1029 20:59:20.812202 27430 net.cpp:144] Memory required for data: 3806115840
I1029 20:59:20.812209 27430 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1029 20:59:20.812217 27430 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1029 20:59:20.812224 27430 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1029 20:59:20.812230 27430 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1029 20:59:20.812240 27430 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I1029 20:59:20.812263 27430 net.cpp:84] Creating Layer fire9/relu_expand3x3
I1029 20:59:20.812270 27430 net.cpp:413] fire9/relu_expand3x3 <- fire9/expand3x3
I1029 20:59:20.812278 27430 net.cpp:374] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I1029 20:59:20.812530 27430 net.cpp:127] Setting up fire9/relu_expand3x3
I1029 20:59:20.812541 27430 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1029 20:59:20.812546 27430 net.cpp:144] Memory required for data: 3831805952
I1029 20:59:20.812551 27430 layer_factory.hpp:77] Creating layer fire9/concat
I1029 20:59:20.812559 27430 net.cpp:84] Creating Layer fire9/concat
I1029 20:59:20.812566 27430 net.cpp:413] fire9/concat <- fire9/expand1x1
I1029 20:59:20.812572 27430 net.cpp:413] fire9/concat <- fire9/expand3x3
I1029 20:59:20.812578 27430 net.cpp:387] fire9/concat -> fire9/concat
I1029 20:59:20.812614 27430 net.cpp:127] Setting up fire9/concat
I1029 20:59:20.812623 27430 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1029 20:59:20.812628 27430 net.cpp:144] Memory required for data: 3883186176
I1029 20:59:20.812633 27430 layer_factory.hpp:77] Creating layer drop9
I1029 20:59:20.812645 27430 net.cpp:84] Creating Layer drop9
I1029 20:59:20.812650 27430 net.cpp:413] drop9 <- fire9/concat
I1029 20:59:20.812657 27430 net.cpp:374] drop9 -> fire9/concat (in-place)
I1029 20:59:20.812695 27430 net.cpp:127] Setting up drop9
I1029 20:59:20.812703 27430 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1029 20:59:20.812707 27430 net.cpp:144] Memory required for data: 3934566400
I1029 20:59:20.812712 27430 layer_factory.hpp:77] Creating layer conv10
I1029 20:59:20.812722 27430 net.cpp:84] Creating Layer conv10
I1029 20:59:20.812727 27430 net.cpp:413] conv10 <- fire9/concat
I1029 20:59:20.812736 27430 net.cpp:387] conv10 -> conv10
I1029 20:59:20.826284 27430 net.cpp:127] Setting up conv10
I1029 20:59:20.826303 27430 net.cpp:136] Top shape: 128 1000 14 14 (25088000)
I1029 20:59:20.826308 27430 net.cpp:144] Memory required for data: 4034918400
I1029 20:59:20.826315 27430 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1029 20:59:20.826323 27430 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1029 20:59:20.826329 27430 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1029 20:59:20.826334 27430 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1029 20:59:20.826339 27430 layer_factory.hpp:77] Creating layer relu_conv10
I1029 20:59:20.826347 27430 net.cpp:84] Creating Layer relu_conv10
I1029 20:59:20.826354 27430 net.cpp:413] relu_conv10 <- conv10
I1029 20:59:20.826360 27430 net.cpp:374] relu_conv10 -> conv10 (in-place)
I1029 20:59:20.826591 27430 net.cpp:127] Setting up relu_conv10
I1029 20:59:20.826603 27430 net.cpp:136] Top shape: 128 1000 14 14 (25088000)
I1029 20:59:20.826608 27430 net.cpp:144] Memory required for data: 4135270400
I1029 20:59:20.826613 27430 layer_factory.hpp:77] Creating layer pool10
I1029 20:59:20.826622 27430 net.cpp:84] Creating Layer pool10
I1029 20:59:20.826627 27430 net.cpp:413] pool10 <- conv10
I1029 20:59:20.826634 27430 net.cpp:387] pool10 -> pool10
I1029 20:59:20.826882 27430 net.cpp:127] Setting up pool10
I1029 20:59:20.826894 27430 net.cpp:136] Top shape: 128 1000 1 1 (128000)
I1029 20:59:20.826898 27430 net.cpp:144] Memory required for data: 4135782400
I1029 20:59:20.826903 27430 layer_factory.hpp:77] Creating layer loss
I1029 20:59:20.826913 27430 net.cpp:84] Creating Layer loss
I1029 20:59:20.826925 27430 net.cpp:413] loss <- pool10
I1029 20:59:20.826932 27430 net.cpp:413] loss <- label
I1029 20:59:20.826941 27430 net.cpp:387] loss -> loss
I1029 20:59:20.826956 27430 layer_factory.hpp:77] Creating layer loss
I1029 20:59:20.830091 27430 net.cpp:127] Setting up loss
I1029 20:59:20.830109 27430 net.cpp:136] Top shape: (1)
I1029 20:59:20.830114 27430 net.cpp:139]     with loss weight 1
I1029 20:59:20.830144 27430 net.cpp:144] Memory required for data: 4135782404
I1029 20:59:20.830154 27430 net.cpp:205] loss needs backward computation.
I1029 20:59:20.830173 27430 net.cpp:205] pool10 needs backward computation.
I1029 20:59:20.830178 27430 net.cpp:205] relu_conv10 needs backward computation.
I1029 20:59:20.830183 27430 net.cpp:205] conv10 needs backward computation.
I1029 20:59:20.830188 27430 net.cpp:205] drop9 needs backward computation.
I1029 20:59:20.830191 27430 net.cpp:205] fire9/concat needs backward computation.
I1029 20:59:20.830198 27430 net.cpp:205] fire9/relu_expand3x3 needs backward computation.
I1029 20:59:20.830201 27430 net.cpp:205] fire9/expand3x3 needs backward computation.
I1029 20:59:20.830205 27430 net.cpp:205] fire9/relu_expand1x1 needs backward computation.
I1029 20:59:20.830209 27430 net.cpp:205] fire9/expand1x1 needs backward computation.
I1029 20:59:20.830214 27430 net.cpp:205] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I1029 20:59:20.830220 27430 net.cpp:205] fire9/relu_squeeze1x1 needs backward computation.
I1029 20:59:20.830224 27430 net.cpp:205] fire9/squeeze1x1 needs backward computation.
I1029 20:59:20.830229 27430 net.cpp:205] fire8/concat needs backward computation.
I1029 20:59:20.830234 27430 net.cpp:205] fire8/relu_expand3x3 needs backward computation.
I1029 20:59:20.830237 27430 net.cpp:205] fire8/expand3x3 needs backward computation.
I1029 20:59:20.830242 27430 net.cpp:205] fire8/relu_expand1x1 needs backward computation.
I1029 20:59:20.830246 27430 net.cpp:205] fire8/expand1x1 needs backward computation.
I1029 20:59:20.830250 27430 net.cpp:205] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I1029 20:59:20.830255 27430 net.cpp:205] fire8/relu_squeeze1x1 needs backward computation.
I1029 20:59:20.830260 27430 net.cpp:205] fire8/squeeze1x1 needs backward computation.
I1029 20:59:20.830265 27430 net.cpp:205] fire7/concat needs backward computation.
I1029 20:59:20.830269 27430 net.cpp:205] fire7/relu_expand3x3 needs backward computation.
I1029 20:59:20.830273 27430 net.cpp:205] fire7/expand3x3 needs backward computation.
I1029 20:59:20.830277 27430 net.cpp:205] fire7/relu_expand1x1 needs backward computation.
I1029 20:59:20.830281 27430 net.cpp:205] fire7/expand1x1 needs backward computation.
I1029 20:59:20.830286 27430 net.cpp:205] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I1029 20:59:20.830291 27430 net.cpp:205] fire7/relu_squeeze1x1 needs backward computation.
I1029 20:59:20.830294 27430 net.cpp:205] fire7/squeeze1x1 needs backward computation.
I1029 20:59:20.830298 27430 net.cpp:205] fire6/concat needs backward computation.
I1029 20:59:20.830302 27430 net.cpp:205] fire6/relu_expand3x3 needs backward computation.
I1029 20:59:20.830307 27430 net.cpp:205] fire6/expand3x3 needs backward computation.
I1029 20:59:20.830312 27430 net.cpp:205] fire6/relu_expand1x1 needs backward computation.
I1029 20:59:20.830315 27430 net.cpp:205] fire6/expand1x1 needs backward computation.
I1029 20:59:20.830319 27430 net.cpp:205] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I1029 20:59:20.830323 27430 net.cpp:205] fire6/relu_squeeze1x1 needs backward computation.
I1029 20:59:20.830327 27430 net.cpp:205] fire6/squeeze1x1 needs backward computation.
I1029 20:59:20.830332 27430 net.cpp:205] pool5 needs backward computation.
I1029 20:59:20.830337 27430 net.cpp:205] fire5/concat needs backward computation.
I1029 20:59:20.830341 27430 net.cpp:205] fire5/relu_expand3x3 needs backward computation.
I1029 20:59:20.830345 27430 net.cpp:205] fire5/expand3x3 needs backward computation.
I1029 20:59:20.830349 27430 net.cpp:205] fire5/relu_expand1x1 needs backward computation.
I1029 20:59:20.830353 27430 net.cpp:205] fire5/expand1x1 needs backward computation.
I1029 20:59:20.830358 27430 net.cpp:205] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I1029 20:59:20.830363 27430 net.cpp:205] fire5/relu_squeeze1x1 needs backward computation.
I1029 20:59:20.830366 27430 net.cpp:205] fire5/squeeze1x1 needs backward computation.
I1029 20:59:20.830374 27430 net.cpp:205] fire4/concat needs backward computation.
I1029 20:59:20.830379 27430 net.cpp:205] fire4/relu_expand3x3 needs backward computation.
I1029 20:59:20.830387 27430 net.cpp:205] fire4/expand3x3 needs backward computation.
I1029 20:59:20.830391 27430 net.cpp:205] fire4/relu_expand1x1 needs backward computation.
I1029 20:59:20.830396 27430 net.cpp:205] fire4/expand1x1 needs backward computation.
I1029 20:59:20.830400 27430 net.cpp:205] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I1029 20:59:20.830404 27430 net.cpp:205] fire4/relu_squeeze1x1 needs backward computation.
I1029 20:59:20.830409 27430 net.cpp:205] fire4/squeeze1x1 needs backward computation.
I1029 20:59:20.830413 27430 net.cpp:205] pool3 needs backward computation.
I1029 20:59:20.830418 27430 net.cpp:205] fire3/concat needs backward computation.
I1029 20:59:20.830422 27430 net.cpp:205] fire3/relu_expand3x3 needs backward computation.
I1029 20:59:20.830426 27430 net.cpp:205] fire3/expand3x3 needs backward computation.
I1029 20:59:20.830431 27430 net.cpp:205] fire3/relu_expand1x1 needs backward computation.
I1029 20:59:20.830435 27430 net.cpp:205] fire3/expand1x1 needs backward computation.
I1029 20:59:20.830440 27430 net.cpp:205] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I1029 20:59:20.830444 27430 net.cpp:205] fire3/relu_squeeze1x1 needs backward computation.
I1029 20:59:20.830448 27430 net.cpp:205] fire3/squeeze1x1 needs backward computation.
I1029 20:59:20.830452 27430 net.cpp:205] fire2/concat needs backward computation.
I1029 20:59:20.830457 27430 net.cpp:205] fire2/relu_expand3x3 needs backward computation.
I1029 20:59:20.830462 27430 net.cpp:205] fire2/expand3x3 needs backward computation.
I1029 20:59:20.830466 27430 net.cpp:205] fire2/relu_expand1x1 needs backward computation.
I1029 20:59:20.830471 27430 net.cpp:205] fire2/expand1x1 needs backward computation.
I1029 20:59:20.830474 27430 net.cpp:205] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I1029 20:59:20.830479 27430 net.cpp:205] fire2/relu_squeeze1x1 needs backward computation.
I1029 20:59:20.830483 27430 net.cpp:205] fire2/squeeze1x1 needs backward computation.
I1029 20:59:20.830488 27430 net.cpp:205] pool1 needs backward computation.
I1029 20:59:20.830492 27430 net.cpp:205] relu_conv1 needs backward computation.
I1029 20:59:20.830497 27430 net.cpp:205] conv1 needs backward computation.
I1029 20:59:20.830502 27430 net.cpp:207] data does not need backward computation.
I1029 20:59:20.830507 27430 net.cpp:249] This network produces output loss
I1029 20:59:20.830561 27430 net.cpp:262] Network initialization done.
I1029 20:59:20.833691 27430 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_60-80.prototxt
I1029 20:59:20.833879 27430 net.cpp:301] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1029 20:59:20.835214 27430 net.cpp:51] Initializing net from parameters: 
name: "SqueezeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/data/caffe-imagenet/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "INQConvolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "fire3/concat"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire4/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool3"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "fire5/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire4/concat"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "fire5/concat"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire6/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool5"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "fire9/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire8/concat"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "INQConvolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
  inq_convolution_param {
    portion: 0.6
    portion: 0.8
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "pool10"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy_top1"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy_top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy_top5"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy_top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I1029 20:59:20.835846 27430 layer_factory.hpp:77] Creating layer data
I1029 20:59:20.835973 27430 db_lmdb.cpp:35] Opened lmdb /home/data/caffe-imagenet/ilsvrc12_val_lmdb
I1029 20:59:20.836009 27430 net.cpp:84] Creating Layer data
I1029 20:59:20.836022 27430 net.cpp:387] data -> data
I1029 20:59:20.836045 27430 net.cpp:387] data -> label
I1029 20:59:20.836450 27430 data_layer.cpp:45] output data size: 50,3,227,227
I1029 20:59:20.934432 27430 net.cpp:127] Setting up data
I1029 20:59:20.934473 27430 net.cpp:136] Top shape: 50 3 227 227 (7729350)
I1029 20:59:20.934481 27430 net.cpp:136] Top shape: 50 (50)
I1029 20:59:20.934485 27430 net.cpp:144] Memory required for data: 30917600
I1029 20:59:20.934494 27430 layer_factory.hpp:77] Creating layer label_data_1_split
I1029 20:59:20.934511 27430 net.cpp:84] Creating Layer label_data_1_split
I1029 20:59:20.934517 27430 net.cpp:413] label_data_1_split <- label
I1029 20:59:20.934530 27430 net.cpp:387] label_data_1_split -> label_data_1_split_0
I1029 20:59:20.934541 27430 net.cpp:387] label_data_1_split -> label_data_1_split_1
I1029 20:59:20.934548 27430 net.cpp:387] label_data_1_split -> label_data_1_split_2
I1029 20:59:20.934643 27430 net.cpp:127] Setting up label_data_1_split
I1029 20:59:20.934651 27430 net.cpp:136] Top shape: 50 (50)
I1029 20:59:20.934656 27430 net.cpp:136] Top shape: 50 (50)
I1029 20:59:20.934662 27430 net.cpp:136] Top shape: 50 (50)
I1029 20:59:20.934666 27430 net.cpp:144] Memory required for data: 30918200
I1029 20:59:20.934670 27430 layer_factory.hpp:77] Creating layer conv1
I1029 20:59:20.934686 27430 net.cpp:84] Creating Layer conv1
I1029 20:59:20.934690 27430 net.cpp:413] conv1 <- data
I1029 20:59:20.934701 27430 net.cpp:387] conv1 -> conv1
I1029 20:59:20.935138 27430 net.cpp:127] Setting up conv1
I1029 20:59:20.935148 27430 net.cpp:136] Top shape: 50 64 113 113 (40860800)
I1029 20:59:20.935153 27430 net.cpp:144] Memory required for data: 194361400
I1029 20:59:20.935163 27430 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1029 20:59:20.935171 27430 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1029 20:59:20.935178 27430 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1029 20:59:20.935185 27430 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1029 20:59:20.935189 27430 layer_factory.hpp:77] Creating layer relu_conv1
I1029 20:59:20.935197 27430 net.cpp:84] Creating Layer relu_conv1
I1029 20:59:20.935202 27430 net.cpp:413] relu_conv1 <- conv1
I1029 20:59:20.935209 27430 net.cpp:374] relu_conv1 -> conv1 (in-place)
I1029 20:59:20.935468 27430 net.cpp:127] Setting up relu_conv1
I1029 20:59:20.935478 27430 net.cpp:136] Top shape: 50 64 113 113 (40860800)
I1029 20:59:20.935482 27430 net.cpp:144] Memory required for data: 357804600
I1029 20:59:20.935487 27430 layer_factory.hpp:77] Creating layer pool1
I1029 20:59:20.935498 27430 net.cpp:84] Creating Layer pool1
I1029 20:59:20.935503 27430 net.cpp:413] pool1 <- conv1
I1029 20:59:20.935509 27430 net.cpp:387] pool1 -> pool1
I1029 20:59:20.935562 27430 net.cpp:127] Setting up pool1
I1029 20:59:20.935570 27430 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1029 20:59:20.935573 27430 net.cpp:144] Memory required for data: 397945400
I1029 20:59:20.935577 27430 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I1029 20:59:20.935587 27430 net.cpp:84] Creating Layer fire2/squeeze1x1
I1029 20:59:20.935591 27430 net.cpp:413] fire2/squeeze1x1 <- pool1
I1029 20:59:20.935598 27430 net.cpp:387] fire2/squeeze1x1 -> fire2/squeeze1x1
I1029 20:59:20.935963 27430 net.cpp:127] Setting up fire2/squeeze1x1
I1029 20:59:20.935972 27430 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1029 20:59:20.935977 27430 net.cpp:144] Memory required for data: 407980600
I1029 20:59:20.935986 27430 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1029 20:59:20.935993 27430 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1029 20:59:20.935999 27430 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1029 20:59:20.936004 27430 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1029 20:59:20.936008 27430 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I1029 20:59:20.936015 27430 net.cpp:84] Creating Layer fire2/relu_squeeze1x1
I1029 20:59:20.936024 27430 net.cpp:413] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I1029 20:59:20.936058 27430 net.cpp:374] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I1029 20:59:20.936292 27430 net.cpp:127] Setting up fire2/relu_squeeze1x1
I1029 20:59:20.936302 27430 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1029 20:59:20.936306 27430 net.cpp:144] Memory required for data: 418015800
I1029 20:59:20.936311 27430 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1029 20:59:20.936317 27430 net.cpp:84] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1029 20:59:20.936321 27430 net.cpp:413] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I1029 20:59:20.936328 27430 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1029 20:59:20.936337 27430 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1029 20:59:20.936386 27430 net.cpp:127] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1029 20:59:20.936393 27430 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1029 20:59:20.936398 27430 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1029 20:59:20.936403 27430 net.cpp:144] Memory required for data: 438086200
I1029 20:59:20.936405 27430 layer_factory.hpp:77] Creating layer fire2/expand1x1
I1029 20:59:20.936417 27430 net.cpp:84] Creating Layer fire2/expand1x1
I1029 20:59:20.936421 27430 net.cpp:413] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1029 20:59:20.936430 27430 net.cpp:387] fire2/expand1x1 -> fire2/expand1x1
I1029 20:59:20.939319 27430 net.cpp:127] Setting up fire2/expand1x1
I1029 20:59:20.939338 27430 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1029 20:59:20.939343 27430 net.cpp:144] Memory required for data: 478227000
I1029 20:59:20.939352 27430 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1029 20:59:20.939363 27430 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1029 20:59:20.939368 27430 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1029 20:59:20.939373 27430 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1029 20:59:20.939376 27430 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I1029 20:59:20.939385 27430 net.cpp:84] Creating Layer fire2/relu_expand1x1
I1029 20:59:20.939390 27430 net.cpp:413] fire2/relu_expand1x1 <- fire2/expand1x1
I1029 20:59:20.939399 27430 net.cpp:374] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I1029 20:59:20.941057 27430 net.cpp:127] Setting up fire2/relu_expand1x1
I1029 20:59:20.941083 27430 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1029 20:59:20.941092 27430 net.cpp:144] Memory required for data: 518367800
I1029 20:59:20.941099 27430 layer_factory.hpp:77] Creating layer fire2/expand3x3
I1029 20:59:20.941119 27430 net.cpp:84] Creating Layer fire2/expand3x3
I1029 20:59:20.941128 27430 net.cpp:413] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1029 20:59:20.941143 27430 net.cpp:387] fire2/expand3x3 -> fire2/expand3x3
I1029 20:59:20.941653 27430 net.cpp:127] Setting up fire2/expand3x3
I1029 20:59:20.941661 27430 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1029 20:59:20.941665 27430 net.cpp:144] Memory required for data: 558508600
I1029 20:59:20.941673 27430 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1029 20:59:20.941679 27430 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1029 20:59:20.941684 27430 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1029 20:59:20.941687 27430 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1029 20:59:20.941691 27430 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I1029 20:59:20.941699 27430 net.cpp:84] Creating Layer fire2/relu_expand3x3
I1029 20:59:20.941704 27430 net.cpp:413] fire2/relu_expand3x3 <- fire2/expand3x3
I1029 20:59:20.941715 27430 net.cpp:374] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I1029 20:59:20.941953 27430 net.cpp:127] Setting up fire2/relu_expand3x3
I1029 20:59:20.941963 27430 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1029 20:59:20.941967 27430 net.cpp:144] Memory required for data: 598649400
I1029 20:59:20.941972 27430 layer_factory.hpp:77] Creating layer fire2/concat
I1029 20:59:20.941979 27430 net.cpp:84] Creating Layer fire2/concat
I1029 20:59:20.941984 27430 net.cpp:413] fire2/concat <- fire2/expand1x1
I1029 20:59:20.941989 27430 net.cpp:413] fire2/concat <- fire2/expand3x3
I1029 20:59:20.941996 27430 net.cpp:387] fire2/concat -> fire2/concat
I1029 20:59:20.942030 27430 net.cpp:127] Setting up fire2/concat
I1029 20:59:20.942037 27430 net.cpp:136] Top shape: 50 128 56 56 (20070400)
I1029 20:59:20.942041 27430 net.cpp:144] Memory required for data: 678931000
I1029 20:59:20.942044 27430 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I1029 20:59:20.942054 27430 net.cpp:84] Creating Layer fire3/squeeze1x1
I1029 20:59:20.942059 27430 net.cpp:413] fire3/squeeze1x1 <- fire2/concat
I1029 20:59:20.942065 27430 net.cpp:387] fire3/squeeze1x1 -> fire3/squeeze1x1
I1029 20:59:20.942421 27430 net.cpp:127] Setting up fire3/squeeze1x1
I1029 20:59:20.942430 27430 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1029 20:59:20.942433 27430 net.cpp:144] Memory required for data: 688966200
I1029 20:59:20.942445 27430 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1029 20:59:20.942453 27430 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1029 20:59:20.942458 27430 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1029 20:59:20.942463 27430 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1029 20:59:20.942467 27430 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I1029 20:59:20.942476 27430 net.cpp:84] Creating Layer fire3/relu_squeeze1x1
I1029 20:59:20.942479 27430 net.cpp:413] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I1029 20:59:20.942487 27430 net.cpp:374] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I1029 20:59:20.942689 27430 net.cpp:127] Setting up fire3/relu_squeeze1x1
I1029 20:59:20.942698 27430 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1029 20:59:20.942703 27430 net.cpp:144] Memory required for data: 699001400
I1029 20:59:20.942706 27430 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1029 20:59:20.942714 27430 net.cpp:84] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1029 20:59:20.942718 27430 net.cpp:413] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I1029 20:59:20.942725 27430 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1029 20:59:20.942734 27430 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1029 20:59:20.942781 27430 net.cpp:127] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1029 20:59:20.942787 27430 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1029 20:59:20.942792 27430 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1029 20:59:20.942796 27430 net.cpp:144] Memory required for data: 719071800
I1029 20:59:20.942800 27430 layer_factory.hpp:77] Creating layer fire3/expand1x1
I1029 20:59:20.942811 27430 net.cpp:84] Creating Layer fire3/expand1x1
I1029 20:59:20.942816 27430 net.cpp:413] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1029 20:59:20.942823 27430 net.cpp:387] fire3/expand1x1 -> fire3/expand1x1
I1029 20:59:20.943178 27430 net.cpp:127] Setting up fire3/expand1x1
I1029 20:59:20.943188 27430 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1029 20:59:20.943192 27430 net.cpp:144] Memory required for data: 759212600
I1029 20:59:20.943198 27430 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1029 20:59:20.943203 27430 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1029 20:59:20.943212 27430 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1029 20:59:20.943226 27430 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1029 20:59:20.943230 27430 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I1029 20:59:20.943238 27430 net.cpp:84] Creating Layer fire3/relu_expand1x1
I1029 20:59:20.943243 27430 net.cpp:413] fire3/relu_expand1x1 <- fire3/expand1x1
I1029 20:59:20.943248 27430 net.cpp:374] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I1029 20:59:20.943451 27430 net.cpp:127] Setting up fire3/relu_expand1x1
I1029 20:59:20.943460 27430 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1029 20:59:20.943464 27430 net.cpp:144] Memory required for data: 799353400
I1029 20:59:20.943469 27430 layer_factory.hpp:77] Creating layer fire3/expand3x3
I1029 20:59:20.943480 27430 net.cpp:84] Creating Layer fire3/expand3x3
I1029 20:59:20.943483 27430 net.cpp:413] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1029 20:59:20.943491 27430 net.cpp:387] fire3/expand3x3 -> fire3/expand3x3
I1029 20:59:20.943914 27430 net.cpp:127] Setting up fire3/expand3x3
I1029 20:59:20.943928 27430 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1029 20:59:20.943933 27430 net.cpp:144] Memory required for data: 839494200
I1029 20:59:20.943938 27430 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1029 20:59:20.943943 27430 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1029 20:59:20.943948 27430 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1029 20:59:20.943953 27430 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1029 20:59:20.943955 27430 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I1029 20:59:20.943964 27430 net.cpp:84] Creating Layer fire3/relu_expand3x3
I1029 20:59:20.943969 27430 net.cpp:413] fire3/relu_expand3x3 <- fire3/expand3x3
I1029 20:59:20.943974 27430 net.cpp:374] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I1029 20:59:20.945385 27430 net.cpp:127] Setting up fire3/relu_expand3x3
I1029 20:59:20.945400 27430 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1029 20:59:20.945405 27430 net.cpp:144] Memory required for data: 879635000
I1029 20:59:20.945410 27430 layer_factory.hpp:77] Creating layer fire3/concat
I1029 20:59:20.945418 27430 net.cpp:84] Creating Layer fire3/concat
I1029 20:59:20.945422 27430 net.cpp:413] fire3/concat <- fire3/expand1x1
I1029 20:59:20.945430 27430 net.cpp:413] fire3/concat <- fire3/expand3x3
I1029 20:59:20.945436 27430 net.cpp:387] fire3/concat -> fire3/concat
I1029 20:59:20.945472 27430 net.cpp:127] Setting up fire3/concat
I1029 20:59:20.945478 27430 net.cpp:136] Top shape: 50 128 56 56 (20070400)
I1029 20:59:20.945482 27430 net.cpp:144] Memory required for data: 959916600
I1029 20:59:20.945485 27430 layer_factory.hpp:77] Creating layer pool3
I1029 20:59:20.945494 27430 net.cpp:84] Creating Layer pool3
I1029 20:59:20.945498 27430 net.cpp:413] pool3 <- fire3/concat
I1029 20:59:20.945505 27430 net.cpp:387] pool3 -> pool3
I1029 20:59:20.945550 27430 net.cpp:127] Setting up pool3
I1029 20:59:20.945556 27430 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1029 20:59:20.945560 27430 net.cpp:144] Memory required for data: 979987000
I1029 20:59:20.945564 27430 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I1029 20:59:20.945574 27430 net.cpp:84] Creating Layer fire4/squeeze1x1
I1029 20:59:20.945577 27430 net.cpp:413] fire4/squeeze1x1 <- pool3
I1029 20:59:20.945586 27430 net.cpp:387] fire4/squeeze1x1 -> fire4/squeeze1x1
I1029 20:59:20.945976 27430 net.cpp:127] Setting up fire4/squeeze1x1
I1029 20:59:20.945986 27430 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1029 20:59:20.945989 27430 net.cpp:144] Memory required for data: 985004600
I1029 20:59:20.945996 27430 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1029 20:59:20.946002 27430 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1029 20:59:20.946010 27430 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1029 20:59:20.946027 27430 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1029 20:59:20.946029 27430 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I1029 20:59:20.946038 27430 net.cpp:84] Creating Layer fire4/relu_squeeze1x1
I1029 20:59:20.946041 27430 net.cpp:413] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I1029 20:59:20.946048 27430 net.cpp:374] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I1029 20:59:20.946251 27430 net.cpp:127] Setting up fire4/relu_squeeze1x1
I1029 20:59:20.946260 27430 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1029 20:59:20.946265 27430 net.cpp:144] Memory required for data: 990022200
I1029 20:59:20.946269 27430 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1029 20:59:20.946276 27430 net.cpp:84] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1029 20:59:20.946280 27430 net.cpp:413] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I1029 20:59:20.946290 27430 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1029 20:59:20.946296 27430 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1029 20:59:20.946344 27430 net.cpp:127] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1029 20:59:20.946350 27430 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1029 20:59:20.946355 27430 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1029 20:59:20.946359 27430 net.cpp:144] Memory required for data: 1000057400
I1029 20:59:20.946362 27430 layer_factory.hpp:77] Creating layer fire4/expand1x1
I1029 20:59:20.946372 27430 net.cpp:84] Creating Layer fire4/expand1x1
I1029 20:59:20.946377 27430 net.cpp:413] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1029 20:59:20.946384 27430 net.cpp:387] fire4/expand1x1 -> fire4/expand1x1
I1029 20:59:20.946744 27430 net.cpp:127] Setting up fire4/expand1x1
I1029 20:59:20.946753 27430 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1029 20:59:20.946758 27430 net.cpp:144] Memory required for data: 1020127800
I1029 20:59:20.946768 27430 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1029 20:59:20.946776 27430 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1029 20:59:20.946781 27430 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1029 20:59:20.946786 27430 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1029 20:59:20.946790 27430 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I1029 20:59:20.946797 27430 net.cpp:84] Creating Layer fire4/relu_expand1x1
I1029 20:59:20.946802 27430 net.cpp:413] fire4/relu_expand1x1 <- fire4/expand1x1
I1029 20:59:20.946808 27430 net.cpp:374] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I1029 20:59:20.947016 27430 net.cpp:127] Setting up fire4/relu_expand1x1
I1029 20:59:20.947024 27430 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1029 20:59:20.947029 27430 net.cpp:144] Memory required for data: 1040198200
I1029 20:59:20.947033 27430 layer_factory.hpp:77] Creating layer fire4/expand3x3
I1029 20:59:20.947044 27430 net.cpp:84] Creating Layer fire4/expand3x3
I1029 20:59:20.947048 27430 net.cpp:413] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1029 20:59:20.947057 27430 net.cpp:387] fire4/expand3x3 -> fire4/expand3x3
I1029 20:59:20.947705 27430 net.cpp:127] Setting up fire4/expand3x3
I1029 20:59:20.947713 27430 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1029 20:59:20.947717 27430 net.cpp:144] Memory required for data: 1060268600
I1029 20:59:20.947723 27430 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1029 20:59:20.947728 27430 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1029 20:59:20.947737 27430 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1029 20:59:20.947751 27430 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1029 20:59:20.947755 27430 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I1029 20:59:20.947762 27430 net.cpp:84] Creating Layer fire4/relu_expand3x3
I1029 20:59:20.947767 27430 net.cpp:413] fire4/relu_expand3x3 <- fire4/expand3x3
I1029 20:59:20.947773 27430 net.cpp:374] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I1029 20:59:20.947983 27430 net.cpp:127] Setting up fire4/relu_expand3x3
I1029 20:59:20.947991 27430 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1029 20:59:20.947995 27430 net.cpp:144] Memory required for data: 1080339000
I1029 20:59:20.947999 27430 layer_factory.hpp:77] Creating layer fire4/concat
I1029 20:59:20.948007 27430 net.cpp:84] Creating Layer fire4/concat
I1029 20:59:20.948012 27430 net.cpp:413] fire4/concat <- fire4/expand1x1
I1029 20:59:20.948017 27430 net.cpp:413] fire4/concat <- fire4/expand3x3
I1029 20:59:20.948024 27430 net.cpp:387] fire4/concat -> fire4/concat
I1029 20:59:20.948055 27430 net.cpp:127] Setting up fire4/concat
I1029 20:59:20.948060 27430 net.cpp:136] Top shape: 50 256 28 28 (10035200)
I1029 20:59:20.948065 27430 net.cpp:144] Memory required for data: 1120479800
I1029 20:59:20.948068 27430 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I1029 20:59:20.948077 27430 net.cpp:84] Creating Layer fire5/squeeze1x1
I1029 20:59:20.948081 27430 net.cpp:413] fire5/squeeze1x1 <- fire4/concat
I1029 20:59:20.948089 27430 net.cpp:387] fire5/squeeze1x1 -> fire5/squeeze1x1
I1029 20:59:20.948494 27430 net.cpp:127] Setting up fire5/squeeze1x1
I1029 20:59:20.948503 27430 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1029 20:59:20.948508 27430 net.cpp:144] Memory required for data: 1125497400
I1029 20:59:20.948513 27430 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1029 20:59:20.948518 27430 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1029 20:59:20.948523 27430 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1029 20:59:20.948527 27430 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1029 20:59:20.948530 27430 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I1029 20:59:20.948537 27430 net.cpp:84] Creating Layer fire5/relu_squeeze1x1
I1029 20:59:20.948542 27430 net.cpp:413] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I1029 20:59:20.948549 27430 net.cpp:374] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I1029 20:59:20.949986 27430 net.cpp:127] Setting up fire5/relu_squeeze1x1
I1029 20:59:20.950001 27430 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1029 20:59:20.950006 27430 net.cpp:144] Memory required for data: 1130515000
I1029 20:59:20.950011 27430 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1029 20:59:20.950023 27430 net.cpp:84] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1029 20:59:20.950028 27430 net.cpp:413] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I1029 20:59:20.950037 27430 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1029 20:59:20.950045 27430 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1029 20:59:20.950096 27430 net.cpp:127] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1029 20:59:20.950103 27430 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1029 20:59:20.950107 27430 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1029 20:59:20.950111 27430 net.cpp:144] Memory required for data: 1140550200
I1029 20:59:20.950114 27430 layer_factory.hpp:77] Creating layer fire5/expand1x1
I1029 20:59:20.950125 27430 net.cpp:84] Creating Layer fire5/expand1x1
I1029 20:59:20.950130 27430 net.cpp:413] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1029 20:59:20.950137 27430 net.cpp:387] fire5/expand1x1 -> fire5/expand1x1
I1029 20:59:20.950511 27430 net.cpp:127] Setting up fire5/expand1x1
I1029 20:59:20.950532 27430 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1029 20:59:20.950536 27430 net.cpp:144] Memory required for data: 1160620600
I1029 20:59:20.950542 27430 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1029 20:59:20.950548 27430 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1029 20:59:20.950553 27430 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1029 20:59:20.950557 27430 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1029 20:59:20.950562 27430 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I1029 20:59:20.950567 27430 net.cpp:84] Creating Layer fire5/relu_expand1x1
I1029 20:59:20.950572 27430 net.cpp:413] fire5/relu_expand1x1 <- fire5/expand1x1
I1029 20:59:20.950578 27430 net.cpp:374] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I1029 20:59:20.950796 27430 net.cpp:127] Setting up fire5/relu_expand1x1
I1029 20:59:20.950806 27430 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1029 20:59:20.950810 27430 net.cpp:144] Memory required for data: 1180691000
I1029 20:59:20.950814 27430 layer_factory.hpp:77] Creating layer fire5/expand3x3
I1029 20:59:20.950824 27430 net.cpp:84] Creating Layer fire5/expand3x3
I1029 20:59:20.950829 27430 net.cpp:413] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1029 20:59:20.950839 27430 net.cpp:387] fire5/expand3x3 -> fire5/expand3x3
I1029 20:59:20.951545 27430 net.cpp:127] Setting up fire5/expand3x3
I1029 20:59:20.951555 27430 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1029 20:59:20.951558 27430 net.cpp:144] Memory required for data: 1200761400
I1029 20:59:20.951565 27430 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1029 20:59:20.951570 27430 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1029 20:59:20.951575 27430 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1029 20:59:20.951581 27430 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1029 20:59:20.951584 27430 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I1029 20:59:20.951591 27430 net.cpp:84] Creating Layer fire5/relu_expand3x3
I1029 20:59:20.951596 27430 net.cpp:413] fire5/relu_expand3x3 <- fire5/expand3x3
I1029 20:59:20.951603 27430 net.cpp:374] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I1029 20:59:20.951817 27430 net.cpp:127] Setting up fire5/relu_expand3x3
I1029 20:59:20.951825 27430 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1029 20:59:20.951830 27430 net.cpp:144] Memory required for data: 1220831800
I1029 20:59:20.951834 27430 layer_factory.hpp:77] Creating layer fire5/concat
I1029 20:59:20.951841 27430 net.cpp:84] Creating Layer fire5/concat
I1029 20:59:20.951845 27430 net.cpp:413] fire5/concat <- fire5/expand1x1
I1029 20:59:20.951850 27430 net.cpp:413] fire5/concat <- fire5/expand3x3
I1029 20:59:20.951858 27430 net.cpp:387] fire5/concat -> fire5/concat
I1029 20:59:20.951889 27430 net.cpp:127] Setting up fire5/concat
I1029 20:59:20.951895 27430 net.cpp:136] Top shape: 50 256 28 28 (10035200)
I1029 20:59:20.951900 27430 net.cpp:144] Memory required for data: 1260972600
I1029 20:59:20.951903 27430 layer_factory.hpp:77] Creating layer pool5
I1029 20:59:20.951910 27430 net.cpp:84] Creating Layer pool5
I1029 20:59:20.951915 27430 net.cpp:413] pool5 <- fire5/concat
I1029 20:59:20.951927 27430 net.cpp:387] pool5 -> pool5
I1029 20:59:20.951979 27430 net.cpp:127] Setting up pool5
I1029 20:59:20.951987 27430 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1029 20:59:20.951990 27430 net.cpp:144] Memory required for data: 1271007800
I1029 20:59:20.951994 27430 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I1029 20:59:20.952004 27430 net.cpp:84] Creating Layer fire6/squeeze1x1
I1029 20:59:20.952008 27430 net.cpp:413] fire6/squeeze1x1 <- pool5
I1029 20:59:20.952019 27430 net.cpp:387] fire6/squeeze1x1 -> fire6/squeeze1x1
I1029 20:59:20.952466 27430 net.cpp:127] Setting up fire6/squeeze1x1
I1029 20:59:20.952486 27430 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1029 20:59:20.952491 27430 net.cpp:144] Memory required for data: 1272889400
I1029 20:59:20.952497 27430 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1029 20:59:20.952502 27430 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1029 20:59:20.952507 27430 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1029 20:59:20.952510 27430 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1029 20:59:20.952514 27430 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I1029 20:59:20.952522 27430 net.cpp:84] Creating Layer fire6/relu_squeeze1x1
I1029 20:59:20.952525 27430 net.cpp:413] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I1029 20:59:20.952531 27430 net.cpp:374] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I1029 20:59:20.952733 27430 net.cpp:127] Setting up fire6/relu_squeeze1x1
I1029 20:59:20.952742 27430 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1029 20:59:20.952746 27430 net.cpp:144] Memory required for data: 1274771000
I1029 20:59:20.952750 27430 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1029 20:59:20.952757 27430 net.cpp:84] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1029 20:59:20.952761 27430 net.cpp:413] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I1029 20:59:20.952767 27430 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1029 20:59:20.952775 27430 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1029 20:59:20.952831 27430 net.cpp:127] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1029 20:59:20.952837 27430 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1029 20:59:20.952842 27430 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1029 20:59:20.952847 27430 net.cpp:144] Memory required for data: 1278534200
I1029 20:59:20.952850 27430 layer_factory.hpp:77] Creating layer fire6/expand1x1
I1029 20:59:20.952859 27430 net.cpp:84] Creating Layer fire6/expand1x1
I1029 20:59:20.952863 27430 net.cpp:413] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1029 20:59:20.952870 27430 net.cpp:387] fire6/expand1x1 -> fire6/expand1x1
I1029 20:59:20.953280 27430 net.cpp:127] Setting up fire6/expand1x1
I1029 20:59:20.953289 27430 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1029 20:59:20.953291 27430 net.cpp:144] Memory required for data: 1286060600
I1029 20:59:20.953297 27430 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1029 20:59:20.953303 27430 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1029 20:59:20.953307 27430 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1029 20:59:20.953312 27430 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1029 20:59:20.953316 27430 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I1029 20:59:20.953322 27430 net.cpp:84] Creating Layer fire6/relu_expand1x1
I1029 20:59:20.953326 27430 net.cpp:413] fire6/relu_expand1x1 <- fire6/expand1x1
I1029 20:59:20.953333 27430 net.cpp:374] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I1029 20:59:20.954733 27430 net.cpp:127] Setting up fire6/relu_expand1x1
I1029 20:59:20.954747 27430 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1029 20:59:20.954751 27430 net.cpp:144] Memory required for data: 1293587000
I1029 20:59:20.954756 27430 layer_factory.hpp:77] Creating layer fire6/expand3x3
I1029 20:59:20.954768 27430 net.cpp:84] Creating Layer fire6/expand3x3
I1029 20:59:20.954773 27430 net.cpp:413] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1029 20:59:20.954782 27430 net.cpp:387] fire6/expand3x3 -> fire6/expand3x3
I1029 20:59:20.955847 27430 net.cpp:127] Setting up fire6/expand3x3
I1029 20:59:20.955857 27430 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1029 20:59:20.955876 27430 net.cpp:144] Memory required for data: 1301113400
I1029 20:59:20.955883 27430 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1029 20:59:20.955889 27430 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1029 20:59:20.955893 27430 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1029 20:59:20.955898 27430 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1029 20:59:20.955901 27430 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I1029 20:59:20.955909 27430 net.cpp:84] Creating Layer fire6/relu_expand3x3
I1029 20:59:20.955914 27430 net.cpp:413] fire6/relu_expand3x3 <- fire6/expand3x3
I1029 20:59:20.955924 27430 net.cpp:374] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I1029 20:59:20.956128 27430 net.cpp:127] Setting up fire6/relu_expand3x3
I1029 20:59:20.956137 27430 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1029 20:59:20.956141 27430 net.cpp:144] Memory required for data: 1308639800
I1029 20:59:20.956146 27430 layer_factory.hpp:77] Creating layer fire6/concat
I1029 20:59:20.956153 27430 net.cpp:84] Creating Layer fire6/concat
I1029 20:59:20.956157 27430 net.cpp:413] fire6/concat <- fire6/expand1x1
I1029 20:59:20.956162 27430 net.cpp:413] fire6/concat <- fire6/expand3x3
I1029 20:59:20.956168 27430 net.cpp:387] fire6/concat -> fire6/concat
I1029 20:59:20.956202 27430 net.cpp:127] Setting up fire6/concat
I1029 20:59:20.956207 27430 net.cpp:136] Top shape: 50 384 14 14 (3763200)
I1029 20:59:20.956212 27430 net.cpp:144] Memory required for data: 1323692600
I1029 20:59:20.956215 27430 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I1029 20:59:20.956224 27430 net.cpp:84] Creating Layer fire7/squeeze1x1
I1029 20:59:20.956228 27430 net.cpp:413] fire7/squeeze1x1 <- fire6/concat
I1029 20:59:20.956236 27430 net.cpp:387] fire7/squeeze1x1 -> fire7/squeeze1x1
I1029 20:59:20.956728 27430 net.cpp:127] Setting up fire7/squeeze1x1
I1029 20:59:20.956737 27430 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1029 20:59:20.956740 27430 net.cpp:144] Memory required for data: 1325574200
I1029 20:59:20.956753 27430 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1029 20:59:20.956763 27430 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1029 20:59:20.956768 27430 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1029 20:59:20.956773 27430 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1029 20:59:20.956776 27430 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I1029 20:59:20.956784 27430 net.cpp:84] Creating Layer fire7/relu_squeeze1x1
I1029 20:59:20.956789 27430 net.cpp:413] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I1029 20:59:20.956794 27430 net.cpp:374] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I1029 20:59:20.957001 27430 net.cpp:127] Setting up fire7/relu_squeeze1x1
I1029 20:59:20.957011 27430 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1029 20:59:20.957015 27430 net.cpp:144] Memory required for data: 1327455800
I1029 20:59:20.957020 27430 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1029 20:59:20.957026 27430 net.cpp:84] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1029 20:59:20.957031 27430 net.cpp:413] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I1029 20:59:20.957037 27430 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1029 20:59:20.957046 27430 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1029 20:59:20.957094 27430 net.cpp:127] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1029 20:59:20.957100 27430 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1029 20:59:20.957109 27430 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1029 20:59:20.957123 27430 net.cpp:144] Memory required for data: 1331219000
I1029 20:59:20.957126 27430 layer_factory.hpp:77] Creating layer fire7/expand1x1
I1029 20:59:20.957135 27430 net.cpp:84] Creating Layer fire7/expand1x1
I1029 20:59:20.957140 27430 net.cpp:413] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1029 20:59:20.957149 27430 net.cpp:387] fire7/expand1x1 -> fire7/expand1x1
I1029 20:59:20.957561 27430 net.cpp:127] Setting up fire7/expand1x1
I1029 20:59:20.957568 27430 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1029 20:59:20.957572 27430 net.cpp:144] Memory required for data: 1338745400
I1029 20:59:20.957578 27430 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1029 20:59:20.957583 27430 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1029 20:59:20.957588 27430 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1029 20:59:20.957592 27430 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1029 20:59:20.957597 27430 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I1029 20:59:20.957602 27430 net.cpp:84] Creating Layer fire7/relu_expand1x1
I1029 20:59:20.957607 27430 net.cpp:413] fire7/relu_expand1x1 <- fire7/expand1x1
I1029 20:59:20.957612 27430 net.cpp:374] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I1029 20:59:20.959014 27430 net.cpp:127] Setting up fire7/relu_expand1x1
I1029 20:59:20.959029 27430 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1029 20:59:20.959033 27430 net.cpp:144] Memory required for data: 1346271800
I1029 20:59:20.959038 27430 layer_factory.hpp:77] Creating layer fire7/expand3x3
I1029 20:59:20.959049 27430 net.cpp:84] Creating Layer fire7/expand3x3
I1029 20:59:20.959053 27430 net.cpp:413] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1029 20:59:20.959064 27430 net.cpp:387] fire7/expand3x3 -> fire7/expand3x3
I1029 20:59:20.960117 27430 net.cpp:127] Setting up fire7/expand3x3
I1029 20:59:20.960126 27430 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1029 20:59:20.960130 27430 net.cpp:144] Memory required for data: 1353798200
I1029 20:59:20.960136 27430 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1029 20:59:20.960142 27430 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1029 20:59:20.960147 27430 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1029 20:59:20.960151 27430 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1029 20:59:20.960155 27430 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I1029 20:59:20.960162 27430 net.cpp:84] Creating Layer fire7/relu_expand3x3
I1029 20:59:20.960166 27430 net.cpp:413] fire7/relu_expand3x3 <- fire7/expand3x3
I1029 20:59:20.960172 27430 net.cpp:374] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I1029 20:59:20.960374 27430 net.cpp:127] Setting up fire7/relu_expand3x3
I1029 20:59:20.960383 27430 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1029 20:59:20.960388 27430 net.cpp:144] Memory required for data: 1361324600
I1029 20:59:20.960392 27430 layer_factory.hpp:77] Creating layer fire7/concat
I1029 20:59:20.960399 27430 net.cpp:84] Creating Layer fire7/concat
I1029 20:59:20.960403 27430 net.cpp:413] fire7/concat <- fire7/expand1x1
I1029 20:59:20.960408 27430 net.cpp:413] fire7/concat <- fire7/expand3x3
I1029 20:59:20.960414 27430 net.cpp:387] fire7/concat -> fire7/concat
I1029 20:59:20.960448 27430 net.cpp:127] Setting up fire7/concat
I1029 20:59:20.960454 27430 net.cpp:136] Top shape: 50 384 14 14 (3763200)
I1029 20:59:20.960458 27430 net.cpp:144] Memory required for data: 1376377400
I1029 20:59:20.960461 27430 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I1029 20:59:20.960469 27430 net.cpp:84] Creating Layer fire8/squeeze1x1
I1029 20:59:20.960474 27430 net.cpp:413] fire8/squeeze1x1 <- fire7/concat
I1029 20:59:20.960480 27430 net.cpp:387] fire8/squeeze1x1 -> fire8/squeeze1x1
I1029 20:59:20.962427 27430 net.cpp:127] Setting up fire8/squeeze1x1
I1029 20:59:20.962453 27430 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1029 20:59:20.962458 27430 net.cpp:144] Memory required for data: 1378886200
I1029 20:59:20.962466 27430 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1029 20:59:20.962471 27430 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1029 20:59:20.962476 27430 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1029 20:59:20.962481 27430 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1029 20:59:20.962484 27430 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I1029 20:59:20.962492 27430 net.cpp:84] Creating Layer fire8/relu_squeeze1x1
I1029 20:59:20.962497 27430 net.cpp:413] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I1029 20:59:20.962504 27430 net.cpp:374] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I1029 20:59:20.962720 27430 net.cpp:127] Setting up fire8/relu_squeeze1x1
I1029 20:59:20.962729 27430 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1029 20:59:20.962733 27430 net.cpp:144] Memory required for data: 1381395000
I1029 20:59:20.962738 27430 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1029 20:59:20.962744 27430 net.cpp:84] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1029 20:59:20.962749 27430 net.cpp:413] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I1029 20:59:20.962756 27430 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1029 20:59:20.962764 27430 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1029 20:59:20.962813 27430 net.cpp:127] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1029 20:59:20.962821 27430 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1029 20:59:20.962826 27430 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1029 20:59:20.962828 27430 net.cpp:144] Memory required for data: 1386412600
I1029 20:59:20.962832 27430 layer_factory.hpp:77] Creating layer fire8/expand1x1
I1029 20:59:20.962842 27430 net.cpp:84] Creating Layer fire8/expand1x1
I1029 20:59:20.962847 27430 net.cpp:413] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1029 20:59:20.962855 27430 net.cpp:387] fire8/expand1x1 -> fire8/expand1x1
I1029 20:59:20.963338 27430 net.cpp:127] Setting up fire8/expand1x1
I1029 20:59:20.963347 27430 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1029 20:59:20.963351 27430 net.cpp:144] Memory required for data: 1396447800
I1029 20:59:20.963357 27430 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1029 20:59:20.963362 27430 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1029 20:59:20.963367 27430 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1029 20:59:20.963371 27430 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1029 20:59:20.963376 27430 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I1029 20:59:20.963382 27430 net.cpp:84] Creating Layer fire8/relu_expand1x1
I1029 20:59:20.963387 27430 net.cpp:413] fire8/relu_expand1x1 <- fire8/expand1x1
I1029 20:59:20.963392 27430 net.cpp:374] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I1029 20:59:20.963599 27430 net.cpp:127] Setting up fire8/relu_expand1x1
I1029 20:59:20.963608 27430 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1029 20:59:20.963613 27430 net.cpp:144] Memory required for data: 1406483000
I1029 20:59:20.963616 27430 layer_factory.hpp:77] Creating layer fire8/expand3x3
I1029 20:59:20.963626 27430 net.cpp:84] Creating Layer fire8/expand3x3
I1029 20:59:20.963630 27430 net.cpp:413] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1029 20:59:20.963639 27430 net.cpp:387] fire8/expand3x3 -> fire8/expand3x3
I1029 20:59:20.966512 27430 net.cpp:127] Setting up fire8/expand3x3
I1029 20:59:20.966531 27430 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1029 20:59:20.966547 27430 net.cpp:144] Memory required for data: 1416518200
I1029 20:59:20.966553 27430 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1029 20:59:20.966559 27430 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1029 20:59:20.966564 27430 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1029 20:59:20.966568 27430 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1029 20:59:20.966572 27430 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I1029 20:59:20.966580 27430 net.cpp:84] Creating Layer fire8/relu_expand3x3
I1029 20:59:20.966585 27430 net.cpp:413] fire8/relu_expand3x3 <- fire8/expand3x3
I1029 20:59:20.966593 27430 net.cpp:374] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I1029 20:59:20.968014 27430 net.cpp:127] Setting up fire8/relu_expand3x3
I1029 20:59:20.968029 27430 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1029 20:59:20.968032 27430 net.cpp:144] Memory required for data: 1426553400
I1029 20:59:20.968037 27430 layer_factory.hpp:77] Creating layer fire8/concat
I1029 20:59:20.968046 27430 net.cpp:84] Creating Layer fire8/concat
I1029 20:59:20.968051 27430 net.cpp:413] fire8/concat <- fire8/expand1x1
I1029 20:59:20.968056 27430 net.cpp:413] fire8/concat <- fire8/expand3x3
I1029 20:59:20.968062 27430 net.cpp:387] fire8/concat -> fire8/concat
I1029 20:59:20.968101 27430 net.cpp:127] Setting up fire8/concat
I1029 20:59:20.968108 27430 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1029 20:59:20.968111 27430 net.cpp:144] Memory required for data: 1446623800
I1029 20:59:20.968116 27430 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I1029 20:59:20.968125 27430 net.cpp:84] Creating Layer fire9/squeeze1x1
I1029 20:59:20.968129 27430 net.cpp:413] fire9/squeeze1x1 <- fire8/concat
I1029 20:59:20.968137 27430 net.cpp:387] fire9/squeeze1x1 -> fire9/squeeze1x1
I1029 20:59:20.968744 27430 net.cpp:127] Setting up fire9/squeeze1x1
I1029 20:59:20.968755 27430 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1029 20:59:20.968758 27430 net.cpp:144] Memory required for data: 1449132600
I1029 20:59:20.968765 27430 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1029 20:59:20.968770 27430 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1029 20:59:20.968775 27430 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1029 20:59:20.968778 27430 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1029 20:59:20.968782 27430 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I1029 20:59:20.968796 27430 net.cpp:84] Creating Layer fire9/relu_squeeze1x1
I1029 20:59:20.968801 27430 net.cpp:413] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I1029 20:59:20.968806 27430 net.cpp:374] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I1029 20:59:20.969018 27430 net.cpp:127] Setting up fire9/relu_squeeze1x1
I1029 20:59:20.969028 27430 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1029 20:59:20.969033 27430 net.cpp:144] Memory required for data: 1451641400
I1029 20:59:20.969036 27430 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1029 20:59:20.969044 27430 net.cpp:84] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1029 20:59:20.969048 27430 net.cpp:413] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I1029 20:59:20.969055 27430 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1029 20:59:20.969063 27430 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1029 20:59:20.969112 27430 net.cpp:127] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1029 20:59:20.969120 27430 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1029 20:59:20.969125 27430 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1029 20:59:20.969130 27430 net.cpp:144] Memory required for data: 1456659000
I1029 20:59:20.969146 27430 layer_factory.hpp:77] Creating layer fire9/expand1x1
I1029 20:59:20.969154 27430 net.cpp:84] Creating Layer fire9/expand1x1
I1029 20:59:20.969159 27430 net.cpp:413] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1029 20:59:20.969167 27430 net.cpp:387] fire9/expand1x1 -> fire9/expand1x1
I1029 20:59:20.969640 27430 net.cpp:127] Setting up fire9/expand1x1
I1029 20:59:20.969650 27430 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1029 20:59:20.969653 27430 net.cpp:144] Memory required for data: 1466694200
I1029 20:59:20.969660 27430 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1029 20:59:20.969665 27430 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1029 20:59:20.969669 27430 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1029 20:59:20.969673 27430 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1029 20:59:20.969677 27430 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I1029 20:59:20.969683 27430 net.cpp:84] Creating Layer fire9/relu_expand1x1
I1029 20:59:20.969688 27430 net.cpp:413] fire9/relu_expand1x1 <- fire9/expand1x1
I1029 20:59:20.969693 27430 net.cpp:374] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I1029 20:59:20.969911 27430 net.cpp:127] Setting up fire9/relu_expand1x1
I1029 20:59:20.969925 27430 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1029 20:59:20.969929 27430 net.cpp:144] Memory required for data: 1476729400
I1029 20:59:20.969933 27430 layer_factory.hpp:77] Creating layer fire9/expand3x3
I1029 20:59:20.969949 27430 net.cpp:84] Creating Layer fire9/expand3x3
I1029 20:59:20.969955 27430 net.cpp:413] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1029 20:59:20.969962 27430 net.cpp:387] fire9/expand3x3 -> fire9/expand3x3
I1029 20:59:20.972844 27430 net.cpp:127] Setting up fire9/expand3x3
I1029 20:59:20.972859 27430 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1029 20:59:20.972863 27430 net.cpp:144] Memory required for data: 1486764600
I1029 20:59:20.972870 27430 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1029 20:59:20.972875 27430 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1029 20:59:20.972880 27430 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1029 20:59:20.972884 27430 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1029 20:59:20.972890 27430 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I1029 20:59:20.972898 27430 net.cpp:84] Creating Layer fire9/relu_expand3x3
I1029 20:59:20.972903 27430 net.cpp:413] fire9/relu_expand3x3 <- fire9/expand3x3
I1029 20:59:20.972910 27430 net.cpp:374] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I1029 20:59:20.973146 27430 net.cpp:127] Setting up fire9/relu_expand3x3
I1029 20:59:20.973156 27430 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1029 20:59:20.973160 27430 net.cpp:144] Memory required for data: 1496799800
I1029 20:59:20.973165 27430 layer_factory.hpp:77] Creating layer fire9/concat
I1029 20:59:20.973171 27430 net.cpp:84] Creating Layer fire9/concat
I1029 20:59:20.973176 27430 net.cpp:413] fire9/concat <- fire9/expand1x1
I1029 20:59:20.973181 27430 net.cpp:413] fire9/concat <- fire9/expand3x3
I1029 20:59:20.973187 27430 net.cpp:387] fire9/concat -> fire9/concat
I1029 20:59:20.973222 27430 net.cpp:127] Setting up fire9/concat
I1029 20:59:20.973227 27430 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1029 20:59:20.973232 27430 net.cpp:144] Memory required for data: 1516870200
I1029 20:59:20.973234 27430 layer_factory.hpp:77] Creating layer drop9
I1029 20:59:20.973243 27430 net.cpp:84] Creating Layer drop9
I1029 20:59:20.973248 27430 net.cpp:413] drop9 <- fire9/concat
I1029 20:59:20.973253 27430 net.cpp:374] drop9 -> fire9/concat (in-place)
I1029 20:59:20.973286 27430 net.cpp:127] Setting up drop9
I1029 20:59:20.973292 27430 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1029 20:59:20.973307 27430 net.cpp:144] Memory required for data: 1536940600
I1029 20:59:20.973310 27430 layer_factory.hpp:77] Creating layer conv10
I1029 20:59:20.973321 27430 net.cpp:84] Creating Layer conv10
I1029 20:59:20.973325 27430 net.cpp:413] conv10 <- fire9/concat
I1029 20:59:20.973333 27430 net.cpp:387] conv10 -> conv10
I1029 20:59:20.982879 27430 net.cpp:127] Setting up conv10
I1029 20:59:20.982895 27430 net.cpp:136] Top shape: 50 1000 14 14 (9800000)
I1029 20:59:20.982899 27430 net.cpp:144] Memory required for data: 1576140600
I1029 20:59:20.982906 27430 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1029 20:59:20.982913 27430 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1029 20:59:20.982916 27430 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1029 20:59:20.982926 27430 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1029 20:59:20.982930 27430 layer_factory.hpp:77] Creating layer relu_conv10
I1029 20:59:20.982939 27430 net.cpp:84] Creating Layer relu_conv10
I1029 20:59:20.982942 27430 net.cpp:413] relu_conv10 <- conv10
I1029 20:59:20.982954 27430 net.cpp:374] relu_conv10 -> conv10 (in-place)
I1029 20:59:20.984397 27430 net.cpp:127] Setting up relu_conv10
I1029 20:59:20.984413 27430 net.cpp:136] Top shape: 50 1000 14 14 (9800000)
I1029 20:59:20.984417 27430 net.cpp:144] Memory required for data: 1615340600
I1029 20:59:20.984422 27430 layer_factory.hpp:77] Creating layer pool10
I1029 20:59:20.984432 27430 net.cpp:84] Creating Layer pool10
I1029 20:59:20.984436 27430 net.cpp:413] pool10 <- conv10
I1029 20:59:20.984443 27430 net.cpp:387] pool10 -> pool10
I1029 20:59:20.984680 27430 net.cpp:127] Setting up pool10
I1029 20:59:20.984690 27430 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1029 20:59:20.984694 27430 net.cpp:144] Memory required for data: 1615540600
I1029 20:59:20.984699 27430 layer_factory.hpp:77] Creating layer pool10_pool10_0_split
I1029 20:59:20.984707 27430 net.cpp:84] Creating Layer pool10_pool10_0_split
I1029 20:59:20.984711 27430 net.cpp:413] pool10_pool10_0_split <- pool10
I1029 20:59:20.984717 27430 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_0
I1029 20:59:20.984727 27430 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_1
I1029 20:59:20.984735 27430 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_2
I1029 20:59:20.984797 27430 net.cpp:127] Setting up pool10_pool10_0_split
I1029 20:59:20.984803 27430 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1029 20:59:20.984808 27430 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1029 20:59:20.984812 27430 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1029 20:59:20.984817 27430 net.cpp:144] Memory required for data: 1616140600
I1029 20:59:20.984819 27430 layer_factory.hpp:77] Creating layer loss
I1029 20:59:20.984828 27430 net.cpp:84] Creating Layer loss
I1029 20:59:20.984833 27430 net.cpp:413] loss <- pool10_pool10_0_split_0
I1029 20:59:20.984838 27430 net.cpp:413] loss <- label_data_1_split_0
I1029 20:59:20.984843 27430 net.cpp:387] loss -> loss
I1029 20:59:20.984851 27430 layer_factory.hpp:77] Creating layer loss
I1029 20:59:20.985213 27430 net.cpp:127] Setting up loss
I1029 20:59:20.985224 27430 net.cpp:136] Top shape: (1)
I1029 20:59:20.985227 27430 net.cpp:139]     with loss weight 1
I1029 20:59:20.985242 27430 net.cpp:144] Memory required for data: 1616140604
I1029 20:59:20.985246 27430 layer_factory.hpp:77] Creating layer accuracy_top1
I1029 20:59:20.985258 27430 net.cpp:84] Creating Layer accuracy_top1
I1029 20:59:20.985263 27430 net.cpp:413] accuracy_top1 <- pool10_pool10_0_split_1
I1029 20:59:20.985270 27430 net.cpp:413] accuracy_top1 <- label_data_1_split_1
I1029 20:59:20.985304 27430 net.cpp:387] accuracy_top1 -> accuracy_top1
I1029 20:59:20.985321 27430 net.cpp:127] Setting up accuracy_top1
I1029 20:59:20.985327 27430 net.cpp:136] Top shape: (1)
I1029 20:59:20.985330 27430 net.cpp:144] Memory required for data: 1616140608
I1029 20:59:20.985337 27430 layer_factory.hpp:77] Creating layer accuracy_top5
I1029 20:59:20.985359 27430 net.cpp:84] Creating Layer accuracy_top5
I1029 20:59:20.985364 27430 net.cpp:413] accuracy_top5 <- pool10_pool10_0_split_2
I1029 20:59:20.985369 27430 net.cpp:413] accuracy_top5 <- label_data_1_split_2
I1029 20:59:20.985375 27430 net.cpp:387] accuracy_top5 -> accuracy_top5
I1029 20:59:20.985390 27430 net.cpp:127] Setting up accuracy_top5
I1029 20:59:20.985396 27430 net.cpp:136] Top shape: (1)
I1029 20:59:20.985400 27430 net.cpp:144] Memory required for data: 1616140612
I1029 20:59:20.985404 27430 net.cpp:207] accuracy_top5 does not need backward computation.
I1029 20:59:20.985409 27430 net.cpp:207] accuracy_top1 does not need backward computation.
I1029 20:59:20.985412 27430 net.cpp:205] loss needs backward computation.
I1029 20:59:20.985417 27430 net.cpp:205] pool10_pool10_0_split needs backward computation.
I1029 20:59:20.985421 27430 net.cpp:205] pool10 needs backward computation.
I1029 20:59:20.985425 27430 net.cpp:205] relu_conv10 needs backward computation.
I1029 20:59:20.985429 27430 net.cpp:205] conv10 needs backward computation.
I1029 20:59:20.985432 27430 net.cpp:205] drop9 needs backward computation.
I1029 20:59:20.985436 27430 net.cpp:205] fire9/concat needs backward computation.
I1029 20:59:20.985440 27430 net.cpp:205] fire9/relu_expand3x3 needs backward computation.
I1029 20:59:20.985443 27430 net.cpp:205] fire9/expand3x3 needs backward computation.
I1029 20:59:20.985447 27430 net.cpp:205] fire9/relu_expand1x1 needs backward computation.
I1029 20:59:20.985451 27430 net.cpp:205] fire9/expand1x1 needs backward computation.
I1029 20:59:20.985455 27430 net.cpp:205] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I1029 20:59:20.985460 27430 net.cpp:205] fire9/relu_squeeze1x1 needs backward computation.
I1029 20:59:20.985463 27430 net.cpp:205] fire9/squeeze1x1 needs backward computation.
I1029 20:59:20.985467 27430 net.cpp:205] fire8/concat needs backward computation.
I1029 20:59:20.985471 27430 net.cpp:205] fire8/relu_expand3x3 needs backward computation.
I1029 20:59:20.985476 27430 net.cpp:205] fire8/expand3x3 needs backward computation.
I1029 20:59:20.985479 27430 net.cpp:205] fire8/relu_expand1x1 needs backward computation.
I1029 20:59:20.985482 27430 net.cpp:205] fire8/expand1x1 needs backward computation.
I1029 20:59:20.985486 27430 net.cpp:205] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I1029 20:59:20.985491 27430 net.cpp:205] fire8/relu_squeeze1x1 needs backward computation.
I1029 20:59:20.985493 27430 net.cpp:205] fire8/squeeze1x1 needs backward computation.
I1029 20:59:20.985497 27430 net.cpp:205] fire7/concat needs backward computation.
I1029 20:59:20.985502 27430 net.cpp:205] fire7/relu_expand3x3 needs backward computation.
I1029 20:59:20.985505 27430 net.cpp:205] fire7/expand3x3 needs backward computation.
I1029 20:59:20.985508 27430 net.cpp:205] fire7/relu_expand1x1 needs backward computation.
I1029 20:59:20.985512 27430 net.cpp:205] fire7/expand1x1 needs backward computation.
I1029 20:59:20.985515 27430 net.cpp:205] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I1029 20:59:20.985519 27430 net.cpp:205] fire7/relu_squeeze1x1 needs backward computation.
I1029 20:59:20.985522 27430 net.cpp:205] fire7/squeeze1x1 needs backward computation.
I1029 20:59:20.985527 27430 net.cpp:205] fire6/concat needs backward computation.
I1029 20:59:20.985530 27430 net.cpp:205] fire6/relu_expand3x3 needs backward computation.
I1029 20:59:20.985533 27430 net.cpp:205] fire6/expand3x3 needs backward computation.
I1029 20:59:20.985538 27430 net.cpp:205] fire6/relu_expand1x1 needs backward computation.
I1029 20:59:20.985540 27430 net.cpp:205] fire6/expand1x1 needs backward computation.
I1029 20:59:20.985544 27430 net.cpp:205] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I1029 20:59:20.985548 27430 net.cpp:205] fire6/relu_squeeze1x1 needs backward computation.
I1029 20:59:20.985553 27430 net.cpp:205] fire6/squeeze1x1 needs backward computation.
I1029 20:59:20.985563 27430 net.cpp:205] pool5 needs backward computation.
I1029 20:59:20.985566 27430 net.cpp:205] fire5/concat needs backward computation.
I1029 20:59:20.985572 27430 net.cpp:205] fire5/relu_expand3x3 needs backward computation.
I1029 20:59:20.985576 27430 net.cpp:205] fire5/expand3x3 needs backward computation.
I1029 20:59:20.985579 27430 net.cpp:205] fire5/relu_expand1x1 needs backward computation.
I1029 20:59:20.985584 27430 net.cpp:205] fire5/expand1x1 needs backward computation.
I1029 20:59:20.985586 27430 net.cpp:205] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I1029 20:59:20.985590 27430 net.cpp:205] fire5/relu_squeeze1x1 needs backward computation.
I1029 20:59:20.985594 27430 net.cpp:205] fire5/squeeze1x1 needs backward computation.
I1029 20:59:20.985597 27430 net.cpp:205] fire4/concat needs backward computation.
I1029 20:59:20.985601 27430 net.cpp:205] fire4/relu_expand3x3 needs backward computation.
I1029 20:59:20.985605 27430 net.cpp:205] fire4/expand3x3 needs backward computation.
I1029 20:59:20.985608 27430 net.cpp:205] fire4/relu_expand1x1 needs backward computation.
I1029 20:59:20.985611 27430 net.cpp:205] fire4/expand1x1 needs backward computation.
I1029 20:59:20.985615 27430 net.cpp:205] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I1029 20:59:20.985618 27430 net.cpp:205] fire4/relu_squeeze1x1 needs backward computation.
I1029 20:59:20.985622 27430 net.cpp:205] fire4/squeeze1x1 needs backward computation.
I1029 20:59:20.985625 27430 net.cpp:205] pool3 needs backward computation.
I1029 20:59:20.985630 27430 net.cpp:205] fire3/concat needs backward computation.
I1029 20:59:20.985633 27430 net.cpp:205] fire3/relu_expand3x3 needs backward computation.
I1029 20:59:20.985636 27430 net.cpp:205] fire3/expand3x3 needs backward computation.
I1029 20:59:20.985641 27430 net.cpp:205] fire3/relu_expand1x1 needs backward computation.
I1029 20:59:20.985643 27430 net.cpp:205] fire3/expand1x1 needs backward computation.
I1029 20:59:20.985647 27430 net.cpp:205] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I1029 20:59:20.985651 27430 net.cpp:205] fire3/relu_squeeze1x1 needs backward computation.
I1029 20:59:20.985654 27430 net.cpp:205] fire3/squeeze1x1 needs backward computation.
I1029 20:59:20.985657 27430 net.cpp:205] fire2/concat needs backward computation.
I1029 20:59:20.985661 27430 net.cpp:205] fire2/relu_expand3x3 needs backward computation.
I1029 20:59:20.985666 27430 net.cpp:205] fire2/expand3x3 needs backward computation.
I1029 20:59:20.985668 27430 net.cpp:205] fire2/relu_expand1x1 needs backward computation.
I1029 20:59:20.985671 27430 net.cpp:205] fire2/expand1x1 needs backward computation.
I1029 20:59:20.985676 27430 net.cpp:205] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I1029 20:59:20.985678 27430 net.cpp:205] fire2/relu_squeeze1x1 needs backward computation.
I1029 20:59:20.985682 27430 net.cpp:205] fire2/squeeze1x1 needs backward computation.
I1029 20:59:20.985687 27430 net.cpp:205] pool1 needs backward computation.
I1029 20:59:20.985690 27430 net.cpp:205] relu_conv1 needs backward computation.
I1029 20:59:20.985693 27430 net.cpp:205] conv1 needs backward computation.
I1029 20:59:20.985698 27430 net.cpp:207] label_data_1_split does not need backward computation.
I1029 20:59:20.985703 27430 net.cpp:207] data does not need backward computation.
I1029 20:59:20.985707 27430 net.cpp:249] This network produces output accuracy_top1
I1029 20:59:20.985710 27430 net.cpp:249] This network produces output accuracy_top5
I1029 20:59:20.985714 27430 net.cpp:249] This network produces output loss
I1029 20:59:20.985775 27430 net.cpp:262] Network initialization done.
I1029 20:59:20.986049 27430 solver.cpp:56] Solver scaffolding done.
I1029 20:59:20.990612 27430 caffe.cpp:155] Finetuning from SqueezeNet/SqueezeNet_v1.1/sqznet_inq_60_exp_iter_36000.caffemodel
I1029 20:59:21.022001 27430 caffe.cpp:248] Starting Optimization
I1029 20:59:55.015019 27481 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_60-80.prototxt
I1029 20:59:55.019256 27482 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_60-80.prototxt
I1029 20:59:55.021113 27483 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_60-80.prototxt
I1029 20:59:55.983434 27430 solver.cpp:276] Solving SqueezeNet
I1029 20:59:55.983481 27430 solver.cpp:277] Learning Rate Policy: exp
I1029 20:59:55.983963 27430 solver.cpp:334] Iteration 0, Testing net (#0)
I1029 21:00:27.564630 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58756
I1029 21:00:27.564793 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.807519
I1029 21:00:27.564808 27430 solver.cpp:401]     Test net output #2: loss = 1.84115 (* 1 = 1.84115 loss)
I1029 21:00:27.564903 27430 inq_conv_layer.cu:52] conv1 (INQConvolution):  Shaping the weights...
I1029 21:00:27.564963 27430 inq_conv_layer.cpp:263] Max_power = 0
I1029 21:00:27.564970 27430 inq_conv_layer.cpp:264] Min_power = -6
I1029 21:00:27.564992 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.0116% -> 79.9769%)
I1029 21:00:27.565003 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 1728/1728
I1029 21:00:27.565006 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 345/346/691
I1029 21:00:27.565121 27430 inq_conv_layer.cu:62] conv1 (INQConvolution):  Shaping the bias...
I1029 21:00:27.565152 27430 inq_conv_layer.cpp:263] Max_power = -2
I1029 21:00:27.565156 27430 inq_conv_layer.cpp:264] Min_power = -8
I1029 21:00:27.565162 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.9375% -> 79.6875%)
I1029 21:00:27.565171 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 63/64
I1029 21:00:27.565174 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 12/13/25
I1029 21:00:27.577972 27430 inq_conv_layer.cu:52] fire2/squeeze1x1 (INQConvolution):  Shaping the weights...
I1029 21:00:27.595715 27430 inq_conv_layer.cpp:263] Max_power = 0
I1029 21:00:27.595726 27430 inq_conv_layer.cpp:264] Min_power = -6
I1029 21:00:27.595746 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.0586% -> 79.9805%)
I1029 21:00:27.595757 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 1023/1024
I1029 21:00:27.595762 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 204/205/409
I1029 21:00:27.595826 27430 inq_conv_layer.cu:62] fire2/squeeze1x1 (INQConvolution):  Shaping the bias...
I1029 21:00:27.595855 27430 inq_conv_layer.cpp:263] Max_power = -2
I1029 21:00:27.595860 27430 inq_conv_layer.cpp:264] Min_power = -8
I1029 21:00:27.595866 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 56.25% -> 75%)
I1029 21:00:27.595873 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 18/16
I1029 21:00:27.595877 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 3/4/7
I1029 21:00:27.599265 27430 inq_conv_layer.cu:52] fire2/expand1x1 (INQConvolution):  Shaping the weights...
I1029 21:00:27.599651 27430 inq_conv_layer.cpp:263] Max_power = 0
I1029 21:00:27.599658 27430 inq_conv_layer.cpp:264] Min_power = -6
I1029 21:00:27.599674 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.0586% -> 79.9805%)
I1029 21:00:27.599686 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 1023/1024
I1029 21:00:27.599690 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 204/205/409
I1029 21:00:27.599753 27430 inq_conv_layer.cu:62] fire2/expand1x1 (INQConvolution):  Shaping the bias...
I1029 21:00:27.599781 27430 inq_conv_layer.cpp:263] Max_power = -3
I1029 21:00:27.599784 27430 inq_conv_layer.cpp:264] Min_power = -9
I1029 21:00:27.599792 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.9375% -> 79.6875%)
I1029 21:00:27.599800 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 63/64
I1029 21:00:27.599803 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 12/13/25
I1029 21:00:27.603765 27430 inq_conv_layer.cu:52] fire2/expand3x3 (INQConvolution):  Shaping the weights...
I1029 21:00:27.605075 27430 inq_conv_layer.cpp:263] Max_power = -1
I1029 21:00:27.605082 27430 inq_conv_layer.cpp:264] Min_power = -7
I1029 21:00:27.605159 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 59.9935% -> 79.9913%)
I1029 21:00:27.605172 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 9218/9216
I1029 21:00:27.605176 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 1843/1844/3687
I1029 21:00:27.605770 27430 inq_conv_layer.cu:62] fire2/expand3x3 (INQConvolution):  Shaping the bias...
I1029 21:00:27.605803 27430 inq_conv_layer.cpp:263] Max_power = -4
I1029 21:00:27.605832 27430 inq_conv_layer.cpp:264] Min_power = -10
I1029 21:00:27.605839 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.9375% -> 79.6875%)
I1029 21:00:27.605849 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 63/64
I1029 21:00:27.605851 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 12/13/25
I1029 21:00:27.614753 27430 inq_conv_layer.cu:52] fire3/squeeze1x1 (INQConvolution):  Shaping the weights...
I1029 21:00:27.618469 27430 inq_conv_layer.cpp:263] Max_power = 0
I1029 21:00:27.618476 27430 inq_conv_layer.cpp:264] Min_power = -6
I1029 21:00:27.618500 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.0098% -> 79.9805%)
I1029 21:00:27.618512 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 2048/2048
I1029 21:00:27.618516 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 409/410/819
I1029 21:00:27.618645 27430 inq_conv_layer.cu:62] fire3/squeeze1x1 (INQConvolution):  Shaping the bias...
I1029 21:00:27.618674 27430 inq_conv_layer.cpp:263] Max_power = -2
I1029 21:00:27.618677 27430 inq_conv_layer.cpp:264] Min_power = -8
I1029 21:00:27.618685 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 56.25% -> 75%)
I1029 21:00:27.618692 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 18/16
I1029 21:00:27.618696 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 3/4/7
I1029 21:00:27.622032 27430 inq_conv_layer.cu:52] fire3/expand1x1 (INQConvolution):  Shaping the weights...
I1029 21:00:27.622916 27430 inq_conv_layer.cpp:263] Max_power = 0
I1029 21:00:27.622926 27430 inq_conv_layer.cpp:264] Min_power = -6
I1029 21:00:27.622942 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.0586% -> 79.9805%)
I1029 21:00:27.622954 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 1023/1024
I1029 21:00:27.622957 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 204/205/409
I1029 21:00:27.623021 27430 inq_conv_layer.cu:62] fire3/expand1x1 (INQConvolution):  Shaping the bias...
I1029 21:00:27.623049 27430 inq_conv_layer.cpp:263] Max_power = -2
I1029 21:00:27.623054 27430 inq_conv_layer.cpp:264] Min_power = -8
I1029 21:00:27.623059 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.9375% -> 79.6875%)
I1029 21:00:27.623067 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 63/64
I1029 21:00:27.623071 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 12/13/25
I1029 21:00:27.627017 27430 inq_conv_layer.cu:52] fire3/expand3x3 (INQConvolution):  Shaping the weights...
I1029 21:00:27.628304 27430 inq_conv_layer.cpp:263] Max_power = 0
I1029 21:00:27.628311 27430 inq_conv_layer.cpp:264] Min_power = -6
I1029 21:00:27.628388 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 59.9935% -> 79.9913%)
I1029 21:00:27.628401 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 9218/9216
I1029 21:00:27.628404 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 1843/1844/3687
I1029 21:00:27.628998 27430 inq_conv_layer.cu:62] fire3/expand3x3 (INQConvolution):  Shaping the bias...
I1029 21:00:27.629029 27430 inq_conv_layer.cpp:263] Max_power = -3
I1029 21:00:27.629034 27430 inq_conv_layer.cpp:264] Min_power = -9
I1029 21:00:27.629040 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.9375% -> 79.6875%)
I1029 21:00:27.629055 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 63/64
I1029 21:00:27.629057 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 12/13/25
I1029 21:00:27.641340 27430 inq_conv_layer.cu:52] fire4/squeeze1x1 (INQConvolution):  Shaping the weights...
I1029 21:00:27.643856 27430 inq_conv_layer.cpp:263] Max_power = 0
I1029 21:00:27.643862 27430 inq_conv_layer.cpp:264] Min_power = -6
I1029 21:00:27.643903 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 59.9854% -> 79.9805%)
I1029 21:00:27.643915 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 4098/4096
I1029 21:00:27.643923 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 819/820/1639
I1029 21:00:27.644194 27430 inq_conv_layer.cu:62] fire4/squeeze1x1 (INQConvolution):  Shaping the bias...
I1029 21:00:27.644225 27430 inq_conv_layer.cpp:263] Max_power = -3
I1029 21:00:27.644230 27430 inq_conv_layer.cpp:264] Min_power = -9
I1029 21:00:27.644237 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 59.375% -> 78.125%)
I1029 21:00:27.644245 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 33/32
I1029 21:00:27.644249 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 6/7/13
I1029 21:00:27.647634 27430 inq_conv_layer.cu:52] fire4/expand1x1 (INQConvolution):  Shaping the weights...
I1029 21:00:27.648943 27430 inq_conv_layer.cpp:263] Max_power = -1
I1029 21:00:27.648949 27430 inq_conv_layer.cpp:264] Min_power = -7
I1029 21:00:27.648990 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 59.9854% -> 79.9805%)
I1029 21:00:27.649003 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 4098/4096
I1029 21:00:27.649006 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 819/820/1639
I1029 21:00:27.649265 27430 inq_conv_layer.cu:62] fire4/expand1x1 (INQConvolution):  Shaping the bias...
I1029 21:00:27.649294 27430 inq_conv_layer.cpp:263] Max_power = -4
I1029 21:00:27.649299 27430 inq_conv_layer.cpp:264] Min_power = -10
I1029 21:00:27.649307 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.1562% -> 79.6875%)
I1029 21:00:27.649317 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 128/128
I1029 21:00:27.649319 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 25/26/51
I1029 21:00:27.653023 27430 inq_conv_layer.cu:52] fire4/expand3x3 (INQConvolution):  Shaping the weights...
I1029 21:00:27.654126 27430 inq_conv_layer.cpp:263] Max_power = -1
I1029 21:00:27.654134 27430 inq_conv_layer.cpp:264] Min_power = -7
I1029 21:00:27.654415 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.0016% -> 79.9995%)
I1029 21:00:27.654428 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 36863/36864
I1029 21:00:27.654433 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 7372/7373/14745
I1029 21:00:27.656945 27430 inq_conv_layer.cu:62] fire4/expand3x3 (INQConvolution):  Shaping the bias...
I1029 21:00:27.656982 27430 inq_conv_layer.cpp:263] Max_power = -4
I1029 21:00:27.656987 27430 inq_conv_layer.cpp:264] Min_power = -10
I1029 21:00:27.656994 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.1562% -> 79.6875%)
I1029 21:00:27.657003 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 128/128
I1029 21:00:27.657007 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 25/26/51
I1029 21:00:27.663444 27430 inq_conv_layer.cu:52] fire5/squeeze1x1 (INQConvolution):  Shaping the weights...
I1029 21:00:27.665788 27430 inq_conv_layer.cpp:263] Max_power = -1
I1029 21:00:27.665796 27430 inq_conv_layer.cpp:264] Min_power = -7
I1029 21:00:27.665861 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 59.9976% -> 79.9927%)
I1029 21:00:27.665874 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 8193/8192
I1029 21:00:27.665879 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 1638/1639/3277
I1029 21:00:27.666409 27430 inq_conv_layer.cu:62] fire5/squeeze1x1 (INQConvolution):  Shaping the bias...
I1029 21:00:27.666445 27430 inq_conv_layer.cpp:263] Max_power = -2
I1029 21:00:27.666450 27430 inq_conv_layer.cpp:264] Min_power = -8
I1029 21:00:27.666455 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 59.375% -> 78.125%)
I1029 21:00:27.666465 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 33/32
I1029 21:00:27.666467 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 6/7/13
I1029 21:00:27.671386 27430 inq_conv_layer.cu:52] fire5/expand1x1 (INQConvolution):  Shaping the weights...
I1029 21:00:27.673434 27430 inq_conv_layer.cpp:263] Max_power = -1
I1029 21:00:27.673441 27430 inq_conv_layer.cpp:264] Min_power = -7
I1029 21:00:27.673492 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 59.9854% -> 79.9805%)
I1029 21:00:27.673504 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 4098/4096
I1029 21:00:27.673508 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 819/820/1639
I1029 21:00:27.673768 27430 inq_conv_layer.cu:62] fire5/expand1x1 (INQConvolution):  Shaping the bias...
I1029 21:00:27.673799 27430 inq_conv_layer.cpp:263] Max_power = -3
I1029 21:00:27.673804 27430 inq_conv_layer.cpp:264] Min_power = -9
I1029 21:00:27.673810 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.1562% -> 79.6875%)
I1029 21:00:27.673820 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 128/128
I1029 21:00:27.673822 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 25/26/51
I1029 21:00:27.677528 27430 inq_conv_layer.cu:52] fire5/expand3x3 (INQConvolution):  Shaping the weights...
I1029 21:00:27.678627 27430 inq_conv_layer.cpp:263] Max_power = 0
I1029 21:00:27.678634 27430 inq_conv_layer.cpp:264] Min_power = -6
I1029 21:00:27.678905 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.0016% -> 79.9995%)
I1029 21:00:27.678921 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 36863/36864
I1029 21:00:27.678926 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 7372/7373/14745
I1029 21:00:27.681434 27430 inq_conv_layer.cu:62] fire5/expand3x3 (INQConvolution):  Shaping the bias...
I1029 21:00:27.681468 27430 inq_conv_layer.cpp:263] Max_power = -5
I1029 21:00:27.681473 27430 inq_conv_layer.cpp:264] Min_power = -11
I1029 21:00:27.681480 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.1562% -> 79.6875%)
I1029 21:00:27.681489 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 128/128
I1029 21:00:27.681493 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 25/26/51
I1029 21:00:27.692759 27430 inq_conv_layer.cu:52] fire6/squeeze1x1 (INQConvolution):  Shaping the weights...
I1029 21:00:27.693765 27430 inq_conv_layer.cpp:263] Max_power = -1
I1029 21:00:27.693773 27430 inq_conv_layer.cpp:264] Min_power = -7
I1029 21:00:27.693867 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.0016% -> 79.9967%)
I1029 21:00:27.693879 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 12288/12288
I1029 21:00:27.693883 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 2457/2458/4915
I1029 21:00:27.694691 27430 inq_conv_layer.cu:62] fire6/squeeze1x1 (INQConvolution):  Shaping the bias...
I1029 21:00:27.694722 27430 inq_conv_layer.cpp:263] Max_power = -3
I1029 21:00:27.694727 27430 inq_conv_layer.cpp:264] Min_power = -9
I1029 21:00:27.694733 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.4167% -> 79.1667%)
I1029 21:00:27.694742 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 48/48
I1029 21:00:27.694746 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 9/10/19
I1029 21:00:27.698328 27430 inq_conv_layer.cu:52] fire6/expand1x1 (INQConvolution):  Shaping the weights...
I1029 21:00:27.700814 27430 inq_conv_layer.cpp:263] Max_power = -1
I1029 21:00:27.700820 27430 inq_conv_layer.cpp:264] Min_power = -7
I1029 21:00:27.700893 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 59.9935% -> 79.9913%)
I1029 21:00:27.700909 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 9218/9216
I1029 21:00:27.700913 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 1843/1844/3687
I1029 21:00:27.701514 27430 inq_conv_layer.cu:62] fire6/expand1x1 (INQConvolution):  Shaping the bias...
I1029 21:00:27.701545 27430 inq_conv_layer.cpp:263] Max_power = -5
I1029 21:00:27.701550 27430 inq_conv_layer.cpp:264] Min_power = -11
I1029 21:00:27.701557 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 59.8958% -> 79.6875%)
I1029 21:00:27.701566 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 193/192
I1029 21:00:27.701570 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 38/39/77
I1029 21:00:27.705080 27430 inq_conv_layer.cu:52] fire6/expand3x3 (INQConvolution):  Shaping the weights...
I1029 21:00:27.706346 27430 inq_conv_layer.cpp:263] Max_power = -1
I1029 21:00:27.706353 27430 inq_conv_layer.cpp:264] Min_power = -7
I1029 21:00:27.707021 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.0007% -> 79.9998%)
I1029 21:00:27.707034 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 82943/82944
I1029 21:00:27.707038 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 16588/16589/33177
I1029 21:00:27.712960 27430 inq_conv_layer.cu:62] fire6/expand3x3 (INQConvolution):  Shaping the bias...
I1029 21:00:27.712993 27430 inq_conv_layer.cpp:263] Max_power = -5
I1029 21:00:27.712997 27430 inq_conv_layer.cpp:264] Min_power = -11
I1029 21:00:27.713006 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 59.8958% -> 79.6875%)
I1029 21:00:27.713016 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 193/192
I1029 21:00:27.713018 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 38/39/77
I1029 21:00:27.719180 27430 inq_conv_layer.cu:52] fire7/squeeze1x1 (INQConvolution):  Shaping the weights...
I1029 21:00:27.721457 27430 inq_conv_layer.cpp:263] Max_power = -1
I1029 21:00:27.721463 27430 inq_conv_layer.cpp:264] Min_power = -7
I1029 21:00:27.721598 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 59.9989% -> 79.9967%)
I1029 21:00:27.721611 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 18433/18432
I1029 21:00:27.721616 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 3686/3687/7373
I1029 21:00:27.722841 27430 inq_conv_layer.cu:62] fire7/squeeze1x1 (INQConvolution):  Shaping the bias...
I1029 21:00:27.722873 27430 inq_conv_layer.cpp:263] Max_power = -2
I1029 21:00:27.722878 27430 inq_conv_layer.cpp:264] Min_power = -8
I1029 21:00:27.722884 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.4167% -> 79.1667%)
I1029 21:00:27.722894 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 48/48
I1029 21:00:27.722898 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 9/10/19
I1029 21:00:27.726356 27430 inq_conv_layer.cu:52] fire7/expand1x1 (INQConvolution):  Shaping the weights...
I1029 21:00:27.730060 27430 inq_conv_layer.cpp:263] Max_power = -1
I1029 21:00:27.730067 27430 inq_conv_layer.cpp:264] Min_power = -7
I1029 21:00:27.730140 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 59.9935% -> 79.9913%)
I1029 21:00:27.730152 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 9218/9216
I1029 21:00:27.730156 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 1843/1844/3687
I1029 21:00:27.730752 27430 inq_conv_layer.cu:62] fire7/expand1x1 (INQConvolution):  Shaping the bias...
I1029 21:00:27.730784 27430 inq_conv_layer.cpp:263] Max_power = -2
I1029 21:00:27.730788 27430 inq_conv_layer.cpp:264] Min_power = -8
I1029 21:00:27.730796 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 59.8958% -> 79.6875%)
I1029 21:00:27.730805 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 193/192
I1029 21:00:27.730809 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 38/39/77
I1029 21:00:27.734288 27430 inq_conv_layer.cu:52] fire7/expand3x3 (INQConvolution):  Shaping the weights...
I1029 21:00:27.735565 27430 inq_conv_layer.cpp:263] Max_power = -1
I1029 21:00:27.735574 27430 inq_conv_layer.cpp:264] Min_power = -7
I1029 21:00:27.736176 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.0007% -> 79.9998%)
I1029 21:00:27.736189 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 82943/82944
I1029 21:00:27.736193 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 16588/16589/33177
I1029 21:00:27.742079 27430 inq_conv_layer.cu:62] fire7/expand3x3 (INQConvolution):  Shaping the bias...
I1029 21:00:27.742115 27430 inq_conv_layer.cpp:263] Max_power = -4
I1029 21:00:27.742120 27430 inq_conv_layer.cpp:264] Min_power = -10
I1029 21:00:27.742127 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 59.8958% -> 79.6875%)
I1029 21:00:27.742151 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 193/192
I1029 21:00:27.742156 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 38/39/77
I1029 21:00:27.748303 27430 inq_conv_layer.cu:52] fire8/squeeze1x1 (INQConvolution):  Shaping the weights...
I1029 21:00:27.750649 27430 inq_conv_layer.cpp:263] Max_power = -1
I1029 21:00:27.750658 27430 inq_conv_layer.cpp:264] Min_power = -7
I1029 21:00:27.750835 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 59.9976% -> 79.9967%)
I1029 21:00:27.750849 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 24578/24576
I1029 21:00:27.750852 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 4915/4916/9831
I1029 21:00:27.752485 27430 inq_conv_layer.cu:62] fire8/squeeze1x1 (INQConvolution):  Shaping the bias...
I1029 21:00:27.752519 27430 inq_conv_layer.cpp:263] Max_power = 3
I1029 21:00:27.752523 27430 inq_conv_layer.cpp:264] Min_power = -3
I1029 21:00:27.752530 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.9375% -> 79.6875%)
I1029 21:00:27.752539 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 63/64
I1029 21:00:27.752542 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 12/13/25
I1029 21:00:27.755981 27430 inq_conv_layer.cu:52] fire8/expand1x1 (INQConvolution):  Shaping the weights...
I1029 21:00:27.759846 27430 inq_conv_layer.cpp:263] Max_power = -1
I1029 21:00:27.759853 27430 inq_conv_layer.cpp:264] Min_power = -7
I1029 21:00:27.759976 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.0037% -> 79.9988%)
I1029 21:00:27.759989 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 16383/16384
I1029 21:00:27.759994 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 3276/3277/6553
I1029 21:00:27.761067 27430 inq_conv_layer.cu:62] fire8/expand1x1 (INQConvolution):  Shaping the bias...
I1029 21:00:27.761101 27430 inq_conv_layer.cpp:263] Max_power = -1
I1029 21:00:27.761106 27430 inq_conv_layer.cpp:264] Min_power = -7
I1029 21:00:27.761114 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 59.7656% -> 79.6875%)
I1029 21:00:27.761123 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 258/256
I1029 21:00:27.761127 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 51/52/103
I1029 21:00:27.764669 27430 inq_conv_layer.cu:52] fire8/expand3x3 (INQConvolution):  Shaping the weights...
I1029 21:00:27.766662 27430 inq_conv_layer.cpp:263] Max_power = -1
I1029 21:00:27.766669 27430 inq_conv_layer.cpp:264] Min_power = -7
I1029 21:00:27.767719 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 59.9996% -> 79.9995%)
I1029 21:00:27.767734 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 147458/147456
I1029 21:00:27.767737 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 29491/29492/58983
I1029 21:00:27.778368 27430 inq_conv_layer.cu:62] fire8/expand3x3 (INQConvolution):  Shaping the bias...
I1029 21:00:27.778403 27430 inq_conv_layer.cpp:263] Max_power = -1
I1029 21:00:27.778409 27430 inq_conv_layer.cpp:264] Min_power = -7
I1029 21:00:27.778417 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 59.7656% -> 79.6875%)
I1029 21:00:27.778431 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 258/256
I1029 21:00:27.778435 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 51/52/103
I1029 21:00:27.786656 27430 inq_conv_layer.cu:52] fire9/squeeze1x1 (INQConvolution):  Shaping the weights...
I1029 21:00:27.789487 27430 inq_conv_layer.cpp:263] Max_power = -1
I1029 21:00:27.789494 27430 inq_conv_layer.cpp:264] Min_power = -7
I1029 21:00:27.789746 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.0006% -> 79.9988%)
I1029 21:00:27.789759 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 32768/32768
I1029 21:00:27.789763 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 6553/6554/13107
I1029 21:00:27.792006 27430 inq_conv_layer.cu:62] fire9/squeeze1x1 (INQConvolution):  Shaping the bias...
I1029 21:00:27.792057 27430 inq_conv_layer.cpp:263] Max_power = 0
I1029 21:00:27.792062 27430 inq_conv_layer.cpp:264] Min_power = -6
I1029 21:00:27.792068 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.9375% -> 79.6875%)
I1029 21:00:27.792078 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 63/64
I1029 21:00:27.792081 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 12/13/25
I1029 21:00:27.795678 27430 inq_conv_layer.cu:52] fire9/expand1x1 (INQConvolution):  Shaping the weights...
I1029 21:00:27.800770 27430 inq_conv_layer.cpp:263] Max_power = -1
I1029 21:00:27.800777 27430 inq_conv_layer.cpp:264] Min_power = -7
I1029 21:00:27.800899 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60.0037% -> 79.9988%)
I1029 21:00:27.800912 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 16383/16384
I1029 21:00:27.800916 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 3276/3277/6553
I1029 21:00:27.802001 27430 inq_conv_layer.cu:62] fire9/expand1x1 (INQConvolution):  Shaping the bias...
I1029 21:00:27.802036 27430 inq_conv_layer.cpp:263] Max_power = -4
I1029 21:00:27.802040 27430 inq_conv_layer.cpp:264] Min_power = -10
I1029 21:00:27.802048 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 59.7656% -> 79.6875%)
I1029 21:00:27.802057 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 258/256
I1029 21:00:27.802062 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 51/52/103
I1029 21:00:27.805583 27430 inq_conv_layer.cu:52] fire9/expand3x3 (INQConvolution):  Shaping the weights...
I1029 21:00:27.807545 27430 inq_conv_layer.cpp:263] Max_power = -1
I1029 21:00:27.807552 27430 inq_conv_layer.cpp:264] Min_power = -7
I1029 21:00:27.808615 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 59.9996% -> 79.9995%)
I1029 21:00:27.808629 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 147458/147456
I1029 21:00:27.808632 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 29491/29492/58983
I1029 21:00:27.819298 27430 inq_conv_layer.cu:62] fire9/expand3x3 (INQConvolution):  Shaping the bias...
I1029 21:00:27.819334 27430 inq_conv_layer.cpp:263] Max_power = -5
I1029 21:00:27.819339 27430 inq_conv_layer.cpp:264] Min_power = -11
I1029 21:00:27.819346 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 59.7656% -> 79.6875%)
I1029 21:00:27.819356 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 258/256
I1029 21:00:27.819360 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 51/52/103
I1029 21:00:27.833860 27430 inq_conv_layer.cu:52] conv10 (INQConvolution):  Shaping the weights...
I1029 21:00:27.838884 27430 inq_conv_layer.cpp:263] Max_power = -2
I1029 21:00:27.838892 27430 inq_conv_layer.cpp:264] Min_power = -8
I1029 21:00:27.842816 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60% -> 80%)
I1029 21:00:27.842830 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 512000/512000
I1029 21:00:27.842833 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 102400/102400/204800
I1029 21:00:27.881749 27430 inq_conv_layer.cu:62] conv10 (INQConvolution):  Shaping the bias...
I1029 21:00:27.881798 27430 inq_conv_layer.cpp:263] Max_power = -2
I1029 21:00:27.881803 27430 inq_conv_layer.cpp:264] Min_power = -8
I1029 21:00:27.881817 27430 inq_conv_layer.cpp:307] portions: 60% -> 80% (total: 60% -> 80%)
I1029 21:00:27.881826 27430 inq_conv_layer.cpp:313] init_not_quantized/total: 1000/1000
I1029 21:00:27.881829 27430 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 200/200/400
I1029 21:00:28.785183 27430 solver.cpp:222] Iteration 0 (0 iter/s, 32.7998s/40 iters), loss = 1.65663
I1029 21:00:28.785225 27430 solver.cpp:241]     Train net output #0: loss = 1.65663 (* 1 = 1.65663 loss)
I1029 21:00:28.785240 27430 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I1029 21:01:02.739331 27430 solver.cpp:222] Iteration 40 (1.17809 iter/s, 33.9533s/40 iters), loss = 1.95308
I1029 21:01:02.739565 27430 solver.cpp:241]     Train net output #0: loss = 1.95308 (* 1 = 1.95308 loss)
I1029 21:01:02.739583 27430 sgd_solver.cpp:105] Iteration 40, lr = 0.00995053
I1029 21:01:32.453469 27430 solver.cpp:222] Iteration 80 (1.3462 iter/s, 29.7132s/40 iters), loss = 1.66911
I1029 21:01:32.453527 27430 solver.cpp:241]     Train net output #0: loss = 1.66911 (* 1 = 1.66911 loss)
I1029 21:01:32.453541 27430 sgd_solver.cpp:105] Iteration 80, lr = 0.0099013
I1029 21:02:01.968698 27430 solver.cpp:222] Iteration 120 (1.35527 iter/s, 29.5145s/40 iters), loss = 1.56186
I1029 21:02:01.968878 27430 solver.cpp:241]     Train net output #0: loss = 1.56186 (* 1 = 1.56186 loss)
I1029 21:02:01.968894 27430 sgd_solver.cpp:105] Iteration 120, lr = 0.00985232
I1029 21:02:31.473263 27430 solver.cpp:222] Iteration 160 (1.35576 iter/s, 29.5037s/40 iters), loss = 1.41527
I1029 21:02:31.473321 27430 solver.cpp:241]     Train net output #0: loss = 1.41527 (* 1 = 1.41527 loss)
I1029 21:02:31.473333 27430 sgd_solver.cpp:105] Iteration 160, lr = 0.00980358
I1029 21:03:00.995156 27430 solver.cpp:222] Iteration 200 (1.35496 iter/s, 29.5211s/40 iters), loss = 1.56615
I1029 21:03:00.995317 27430 solver.cpp:241]     Train net output #0: loss = 1.56615 (* 1 = 1.56615 loss)
I1029 21:03:00.995332 27430 sgd_solver.cpp:105] Iteration 200, lr = 0.00975508
I1029 21:03:30.519515 27430 solver.cpp:222] Iteration 240 (1.35485 iter/s, 29.5235s/40 iters), loss = 1.42298
I1029 21:03:30.519569 27430 solver.cpp:241]     Train net output #0: loss = 1.42298 (* 1 = 1.42298 loss)
I1029 21:03:30.519582 27430 sgd_solver.cpp:105] Iteration 240, lr = 0.00970682
I1029 21:03:59.977391 27430 solver.cpp:222] Iteration 280 (1.35791 iter/s, 29.4571s/40 iters), loss = 1.19048
I1029 21:03:59.977550 27430 solver.cpp:241]     Train net output #0: loss = 1.19048 (* 1 = 1.19048 loss)
I1029 21:03:59.977565 27430 sgd_solver.cpp:105] Iteration 280, lr = 0.0096588
I1029 21:04:29.378707 27430 solver.cpp:222] Iteration 320 (1.36052 iter/s, 29.4005s/40 iters), loss = 1.59595
I1029 21:04:29.378764 27430 solver.cpp:241]     Train net output #0: loss = 1.59595 (* 1 = 1.59595 loss)
I1029 21:04:29.378777 27430 sgd_solver.cpp:105] Iteration 320, lr = 0.00961101
I1029 21:04:58.776821 27430 solver.cpp:222] Iteration 360 (1.36067 iter/s, 29.3974s/40 iters), loss = 1.42123
I1029 21:04:58.776993 27430 solver.cpp:241]     Train net output #0: loss = 1.42123 (* 1 = 1.42123 loss)
I1029 21:04:58.777006 27430 sgd_solver.cpp:105] Iteration 360, lr = 0.00956347
I1029 21:05:31.605437 27430 solver.cpp:222] Iteration 400 (1.21848 iter/s, 32.8277s/40 iters), loss = 1.61645
I1029 21:05:31.605590 27430 solver.cpp:241]     Train net output #0: loss = 1.61645 (* 1 = 1.61645 loss)
I1029 21:05:31.605604 27430 sgd_solver.cpp:105] Iteration 400, lr = 0.00951616
I1029 21:06:02.095270 27430 solver.cpp:222] Iteration 440 (1.31195 iter/s, 30.489s/40 iters), loss = 1.45872
I1029 21:06:02.095422 27430 solver.cpp:241]     Train net output #0: loss = 1.45872 (* 1 = 1.45872 loss)
I1029 21:06:02.095435 27430 sgd_solver.cpp:105] Iteration 440, lr = 0.00946908
I1029 21:06:23.704325 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_469.caffemodel
I1029 21:06:23.915859 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_469.solverstate
I1029 21:06:33.216069 27430 solver.cpp:222] Iteration 480 (1.28535 iter/s, 31.1199s/40 iters), loss = 1.25717
I1029 21:06:33.216626 27430 solver.cpp:241]     Train net output #0: loss = 1.25717 (* 1 = 1.25717 loss)
I1029 21:06:33.216655 27430 sgd_solver.cpp:105] Iteration 480, lr = 0.00942223
I1029 21:06:47.781409 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_500.caffemodel
I1029 21:06:47.912730 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_500.solverstate
I1029 21:06:48.025581 27430 solver.cpp:334] Iteration 500, Testing net (#0)
I1029 21:07:18.968905 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1029 21:07:19.177773 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5596
I1029 21:07:19.177811 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.796239
I1029 21:07:19.177842 27430 solver.cpp:401]     Test net output #2: loss = 1.9563 (* 1 = 1.9563 loss)
I1029 21:07:34.780529 27430 solver.cpp:222] Iteration 520 (0.649747 iter/s, 61.5625s/40 iters), loss = 1.48493
I1029 21:07:34.780995 27430 solver.cpp:241]     Train net output #0: loss = 1.48493 (* 1 = 1.48493 loss)
I1029 21:07:34.781039 27430 sgd_solver.cpp:105] Iteration 520, lr = 0.00937562
I1029 21:08:04.424167 27430 solver.cpp:222] Iteration 560 (1.34941 iter/s, 29.6425s/40 iters), loss = 1.69351
I1029 21:08:04.424731 27430 solver.cpp:241]     Train net output #0: loss = 1.69351 (* 1 = 1.69351 loss)
I1029 21:08:04.424778 27430 sgd_solver.cpp:105] Iteration 560, lr = 0.00932924
I1029 21:08:34.063115 27430 solver.cpp:222] Iteration 600 (1.34963 iter/s, 29.6377s/40 iters), loss = 1.36648
I1029 21:08:34.063570 27430 solver.cpp:241]     Train net output #0: loss = 1.36648 (* 1 = 1.36648 loss)
I1029 21:08:34.063618 27430 sgd_solver.cpp:105] Iteration 600, lr = 0.00928308
I1029 21:09:03.545220 27430 solver.cpp:222] Iteration 640 (1.35681 iter/s, 29.481s/40 iters), loss = 1.31203
I1029 21:09:03.545764 27430 solver.cpp:241]     Train net output #0: loss = 1.31203 (* 1 = 1.31203 loss)
I1029 21:09:03.545812 27430 sgd_solver.cpp:105] Iteration 640, lr = 0.00923716
I1029 21:09:32.978690 27430 solver.cpp:222] Iteration 680 (1.35905 iter/s, 29.4323s/40 iters), loss = 1.37825
I1029 21:09:32.979087 27430 solver.cpp:241]     Train net output #0: loss = 1.37825 (* 1 = 1.37825 loss)
I1029 21:09:32.979121 27430 sgd_solver.cpp:105] Iteration 680, lr = 0.00919146
I1029 21:10:02.478910 27430 solver.cpp:222] Iteration 720 (1.35597 iter/s, 29.4991s/40 iters), loss = 1.56704
I1029 21:10:02.479455 27430 solver.cpp:241]     Train net output #0: loss = 1.56704 (* 1 = 1.56704 loss)
I1029 21:10:02.479498 27430 sgd_solver.cpp:105] Iteration 720, lr = 0.00914599
I1029 21:10:32.562877 27430 solver.cpp:222] Iteration 760 (1.32967 iter/s, 30.0827s/40 iters), loss = 1.6453
I1029 21:10:32.563060 27430 solver.cpp:241]     Train net output #0: loss = 1.6453 (* 1 = 1.6453 loss)
I1029 21:10:32.563073 27430 sgd_solver.cpp:105] Iteration 760, lr = 0.00910074
I1029 21:11:01.978750 27430 solver.cpp:222] Iteration 800 (1.35985 iter/s, 29.415s/40 iters), loss = 1.42567
I1029 21:11:01.979220 27430 solver.cpp:241]     Train net output #0: loss = 1.42567 (* 1 = 1.42567 loss)
I1029 21:11:01.979269 27430 sgd_solver.cpp:105] Iteration 800, lr = 0.00905572
I1029 21:11:31.405360 27430 solver.cpp:222] Iteration 840 (1.35937 iter/s, 29.4255s/40 iters), loss = 1.62199
I1029 21:11:31.405932 27430 solver.cpp:241]     Train net output #0: loss = 1.62199 (* 1 = 1.62199 loss)
I1029 21:11:31.405966 27430 sgd_solver.cpp:105] Iteration 840, lr = 0.00901092
I1029 21:12:00.945714 27430 solver.cpp:222] Iteration 880 (1.35414 iter/s, 29.5391s/40 iters), loss = 1.72691
I1029 21:12:00.946202 27430 solver.cpp:241]     Train net output #0: loss = 1.72691 (* 1 = 1.72691 loss)
I1029 21:12:00.946251 27430 sgd_solver.cpp:105] Iteration 880, lr = 0.00896634
I1029 21:12:31.424093 27430 solver.cpp:222] Iteration 920 (1.31246 iter/s, 30.4772s/40 iters), loss = 1.13824
I1029 21:12:31.424651 27430 solver.cpp:241]     Train net output #0: loss = 1.13824 (* 1 = 1.13824 loss)
I1029 21:12:31.424684 27430 sgd_solver.cpp:105] Iteration 920, lr = 0.00892199
I1029 21:13:02.129390 27430 solver.cpp:222] Iteration 960 (1.30276 iter/s, 30.704s/40 iters), loss = 1.60765
I1029 21:13:02.129532 27430 solver.cpp:241]     Train net output #0: loss = 1.60765 (* 1 = 1.60765 loss)
I1029 21:13:02.129547 27430 sgd_solver.cpp:105] Iteration 960, lr = 0.00887785
I1029 21:13:31.529968 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_1000.caffemodel
I1029 21:13:31.674554 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_1000.solverstate
I1029 21:13:31.780866 27430 solver.cpp:334] Iteration 1000, Testing net (#0)
I1029 21:14:03.084563 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56512
I1029 21:14:03.085386 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79572
I1029 21:14:03.085418 27430 solver.cpp:401]     Test net output #2: loss = 1.93185 (* 1 = 1.93185 loss)
I1029 21:14:03.846623 27430 solver.cpp:222] Iteration 1000 (0.648134 iter/s, 61.7156s/40 iters), loss = 0.970671
I1029 21:14:03.846680 27430 solver.cpp:241]     Train net output #0: loss = 0.970671 (* 1 = 0.970671 loss)
I1029 21:14:03.846693 27430 sgd_solver.cpp:105] Iteration 1000, lr = 0.00883393
I1029 21:14:33.329136 27430 solver.cpp:222] Iteration 1040 (1.35677 iter/s, 29.4818s/40 iters), loss = 1.79814
I1029 21:14:33.329690 27430 solver.cpp:241]     Train net output #0: loss = 1.79814 (* 1 = 1.79814 loss)
I1029 21:14:33.329746 27430 sgd_solver.cpp:105] Iteration 1040, lr = 0.00879022
I1029 21:15:02.783082 27430 solver.cpp:222] Iteration 1080 (1.35811 iter/s, 29.4527s/40 iters), loss = 1.73884
I1029 21:15:02.783547 27430 solver.cpp:241]     Train net output #0: loss = 1.73884 (* 1 = 1.73884 loss)
I1029 21:15:02.783594 27430 sgd_solver.cpp:105] Iteration 1080, lr = 0.00874674
I1029 21:15:32.889962 27430 solver.cpp:222] Iteration 1120 (1.32865 iter/s, 30.1057s/40 iters), loss = 1.35617
I1029 21:15:32.890501 27430 solver.cpp:241]     Train net output #0: loss = 1.35617 (* 1 = 1.35617 loss)
I1029 21:15:32.890545 27430 sgd_solver.cpp:105] Iteration 1120, lr = 0.00870347
I1029 21:16:03.564193 27430 solver.cpp:222] Iteration 1160 (1.30408 iter/s, 30.673s/40 iters), loss = 1.47379
I1029 21:16:03.564570 27430 solver.cpp:241]     Train net output #0: loss = 1.47379 (* 1 = 1.47379 loss)
I1029 21:16:03.564590 27430 sgd_solver.cpp:105] Iteration 1160, lr = 0.00866041
I1029 21:16:34.178140 27430 solver.cpp:222] Iteration 1200 (1.30664 iter/s, 30.6128s/40 iters), loss = 1.23304
I1029 21:16:34.178596 27430 solver.cpp:241]     Train net output #0: loss = 1.23304 (* 1 = 1.23304 loss)
I1029 21:16:34.178632 27430 sgd_solver.cpp:105] Iteration 1200, lr = 0.00861757
I1029 21:17:04.358412 27430 solver.cpp:222] Iteration 1240 (1.32542 iter/s, 30.1791s/40 iters), loss = 1.43986
I1029 21:17:04.358917 27430 solver.cpp:241]     Train net output #0: loss = 1.43986 (* 1 = 1.43986 loss)
I1029 21:17:04.358978 27430 sgd_solver.cpp:105] Iteration 1240, lr = 0.00857493
I1029 21:17:34.510154 27430 solver.cpp:222] Iteration 1280 (1.32668 iter/s, 30.1506s/40 iters), loss = 1.39934
I1029 21:17:34.510692 27430 solver.cpp:241]     Train net output #0: loss = 1.39934 (* 1 = 1.39934 loss)
I1029 21:17:34.510740 27430 sgd_solver.cpp:105] Iteration 1280, lr = 0.00853251
I1029 21:18:04.139880 27430 solver.cpp:222] Iteration 1320 (1.35005 iter/s, 29.6285s/40 iters), loss = 1.61035
I1029 21:18:04.140343 27430 solver.cpp:241]     Train net output #0: loss = 1.61035 (* 1 = 1.61035 loss)
I1029 21:18:04.140390 27430 sgd_solver.cpp:105] Iteration 1320, lr = 0.0084903
I1029 21:18:33.933910 27430 solver.cpp:222] Iteration 1360 (1.3426 iter/s, 29.7929s/40 iters), loss = 1.49683
I1029 21:18:33.934576 27430 solver.cpp:241]     Train net output #0: loss = 1.49683 (* 1 = 1.49683 loss)
I1029 21:18:33.934635 27430 sgd_solver.cpp:105] Iteration 1360, lr = 0.0084483
I1029 21:19:03.556501 27430 solver.cpp:222] Iteration 1400 (1.35038 iter/s, 29.6213s/40 iters), loss = 1.43753
I1029 21:19:03.557157 27430 solver.cpp:241]     Train net output #0: loss = 1.43753 (* 1 = 1.43753 loss)
I1029 21:19:03.557209 27430 sgd_solver.cpp:105] Iteration 1400, lr = 0.0084065
I1029 21:19:33.006593 27430 solver.cpp:222] Iteration 1440 (1.35828 iter/s, 29.449s/40 iters), loss = 1.58612
I1029 21:19:33.007112 27430 solver.cpp:241]     Train net output #0: loss = 1.58612 (* 1 = 1.58612 loss)
I1029 21:19:33.007170 27430 sgd_solver.cpp:105] Iteration 1440, lr = 0.00836491
I1029 21:20:02.434432 27430 solver.cpp:222] Iteration 1480 (1.35931 iter/s, 29.4266s/40 iters), loss = 1.60475
I1029 21:20:02.434952 27430 solver.cpp:241]     Train net output #0: loss = 1.60475 (* 1 = 1.60475 loss)
I1029 21:20:02.435000 27430 sgd_solver.cpp:105] Iteration 1480, lr = 0.00832353
I1029 21:20:16.420984 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_1500.caffemodel
I1029 21:20:16.580636 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_1500.solverstate
I1029 21:20:16.695379 27430 solver.cpp:334] Iteration 1500, Testing net (#0)
I1029 21:20:47.796464 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1029 21:20:48.005749 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.56288
I1029 21:20:48.005797 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.799119
I1029 21:20:48.005807 27430 solver.cpp:401]     Test net output #2: loss = 1.95594 (* 1 = 1.95594 loss)
I1029 21:21:03.422577 27430 solver.cpp:222] Iteration 1520 (0.655886 iter/s, 60.9863s/40 iters), loss = 1.707
I1029 21:21:03.423043 27430 solver.cpp:241]     Train net output #0: loss = 1.707 (* 1 = 1.707 loss)
I1029 21:21:03.423091 27430 sgd_solver.cpp:105] Iteration 1520, lr = 0.00828236
I1029 21:21:32.770967 27430 solver.cpp:222] Iteration 1560 (1.36299 iter/s, 29.3473s/40 iters), loss = 1.62518
I1029 21:21:32.771526 27430 solver.cpp:241]     Train net output #0: loss = 1.62518 (* 1 = 1.62518 loss)
I1029 21:21:32.771570 27430 sgd_solver.cpp:105] Iteration 1560, lr = 0.00824138
I1029 21:22:02.607682 27430 solver.cpp:222] Iteration 1600 (1.34069 iter/s, 29.8355s/40 iters), loss = 1.62237
I1029 21:22:02.608551 27430 solver.cpp:241]     Train net output #0: loss = 1.62237 (* 1 = 1.62237 loss)
I1029 21:22:02.608604 27430 sgd_solver.cpp:105] Iteration 1600, lr = 0.00820061
I1029 21:22:32.690810 27430 solver.cpp:222] Iteration 1640 (1.32972 iter/s, 30.0816s/40 iters), loss = 1.57216
I1029 21:22:32.691334 27430 solver.cpp:241]     Train net output #0: loss = 1.57216 (* 1 = 1.57216 loss)
I1029 21:22:32.691354 27430 sgd_solver.cpp:105] Iteration 1640, lr = 0.00816004
I1029 21:23:02.428845 27430 solver.cpp:222] Iteration 1680 (1.34513 iter/s, 29.7368s/40 iters), loss = 1.4806
I1029 21:23:02.429322 27430 solver.cpp:241]     Train net output #0: loss = 1.4806 (* 1 = 1.4806 loss)
I1029 21:23:02.429366 27430 sgd_solver.cpp:105] Iteration 1680, lr = 0.00811967
I1029 21:23:33.534518 27430 solver.cpp:222] Iteration 1720 (1.28599 iter/s, 31.1045s/40 iters), loss = 1.29228
I1029 21:23:33.535035 27430 solver.cpp:241]     Train net output #0: loss = 1.29228 (* 1 = 1.29228 loss)
I1029 21:23:33.535071 27430 sgd_solver.cpp:105] Iteration 1720, lr = 0.0080795
I1029 21:24:04.133250 27430 solver.cpp:222] Iteration 1760 (1.3073 iter/s, 30.5975s/40 iters), loss = 1.56821
I1029 21:24:04.133843 27430 solver.cpp:241]     Train net output #0: loss = 1.56821 (* 1 = 1.56821 loss)
I1029 21:24:04.133889 27430 sgd_solver.cpp:105] Iteration 1760, lr = 0.00803953
I1029 21:24:34.486372 27430 solver.cpp:222] Iteration 1800 (1.31788 iter/s, 30.3518s/40 iters), loss = 1.86348
I1029 21:24:34.486896 27430 solver.cpp:241]     Train net output #0: loss = 1.86348 (* 1 = 1.86348 loss)
I1029 21:24:34.486951 27430 sgd_solver.cpp:105] Iteration 1800, lr = 0.00799976
I1029 21:25:04.758940 27430 solver.cpp:222] Iteration 1840 (1.32138 iter/s, 30.2713s/40 iters), loss = 1.48246
I1029 21:25:04.759593 27430 solver.cpp:241]     Train net output #0: loss = 1.48246 (* 1 = 1.48246 loss)
I1029 21:25:04.759640 27430 sgd_solver.cpp:105] Iteration 1840, lr = 0.00796018
I1029 21:25:34.163815 27430 solver.cpp:222] Iteration 1880 (1.36038 iter/s, 29.4036s/40 iters), loss = 1.51058
I1029 21:25:34.164337 27430 solver.cpp:241]     Train net output #0: loss = 1.51058 (* 1 = 1.51058 loss)
I1029 21:25:34.164384 27430 sgd_solver.cpp:105] Iteration 1880, lr = 0.0079208
I1029 21:26:03.614387 27430 solver.cpp:222] Iteration 1920 (1.35826 iter/s, 29.4494s/40 iters), loss = 1.57754
I1029 21:26:03.614898 27430 solver.cpp:241]     Train net output #0: loss = 1.57754 (* 1 = 1.57754 loss)
I1029 21:26:03.614976 27430 sgd_solver.cpp:105] Iteration 1920, lr = 0.00788162
I1029 21:26:33.127660 27430 solver.cpp:222] Iteration 1960 (1.35538 iter/s, 29.5121s/40 iters), loss = 1.39961
I1029 21:26:33.128108 27430 solver.cpp:241]     Train net output #0: loss = 1.39961 (* 1 = 1.39961 loss)
I1029 21:26:33.128159 27430 sgd_solver.cpp:105] Iteration 1960, lr = 0.00784263
I1029 21:27:02.029855 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_2000.caffemodel
I1029 21:27:02.180608 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_2000.solverstate
I1029 21:27:02.294765 27430 solver.cpp:334] Iteration 2000, Testing net (#0)
I1029 21:27:33.586369 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57272
I1029 21:27:33.586457 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79936
I1029 21:27:33.586470 27430 solver.cpp:401]     Test net output #2: loss = 1.90648 (* 1 = 1.90648 loss)
I1029 21:27:34.353899 27430 solver.cpp:222] Iteration 2000 (0.653334 iter/s, 61.2244s/40 iters), loss = 1.32167
I1029 21:27:34.353973 27430 solver.cpp:241]     Train net output #0: loss = 1.32167 (* 1 = 1.32167 loss)
I1029 21:27:34.353988 27430 sgd_solver.cpp:105] Iteration 2000, lr = 0.00780383
I1029 21:28:03.975250 27430 solver.cpp:222] Iteration 2040 (1.35041 iter/s, 29.6206s/40 iters), loss = 1.71548
I1029 21:28:03.975754 27430 solver.cpp:241]     Train net output #0: loss = 1.71548 (* 1 = 1.71548 loss)
I1029 21:28:03.975800 27430 sgd_solver.cpp:105] Iteration 2040, lr = 0.00776522
I1029 21:28:33.968581 27430 solver.cpp:222] Iteration 2080 (1.33368 iter/s, 29.9921s/40 iters), loss = 1.79265
I1029 21:28:33.969012 27430 solver.cpp:241]     Train net output #0: loss = 1.79265 (* 1 = 1.79265 loss)
I1029 21:28:33.969045 27430 sgd_solver.cpp:105] Iteration 2080, lr = 0.00772681
I1029 21:29:04.808506 27430 solver.cpp:222] Iteration 2120 (1.29707 iter/s, 30.8388s/40 iters), loss = 1.26599
I1029 21:29:04.808698 27430 solver.cpp:241]     Train net output #0: loss = 1.26599 (* 1 = 1.26599 loss)
I1029 21:29:04.808712 27430 sgd_solver.cpp:105] Iteration 2120, lr = 0.00768858
I1029 21:29:14.202325 27430 blocking_queue.cpp:49] Waiting for data
I1029 21:29:37.828055 27430 solver.cpp:222] Iteration 2160 (1.21144 iter/s, 33.0186s/40 iters), loss = 1.41414
I1029 21:29:37.828609 27430 solver.cpp:241]     Train net output #0: loss = 1.41414 (* 1 = 1.41414 loss)
I1029 21:29:37.828658 27430 sgd_solver.cpp:105] Iteration 2160, lr = 0.00765054
I1029 21:30:07.490427 27430 solver.cpp:222] Iteration 2200 (1.34857 iter/s, 29.6611s/40 iters), loss = 1.66675
I1029 21:30:07.490834 27430 solver.cpp:241]     Train net output #0: loss = 1.66675 (* 1 = 1.66675 loss)
I1029 21:30:07.490875 27430 sgd_solver.cpp:105] Iteration 2200, lr = 0.0076127
I1029 21:30:37.692852 27430 solver.cpp:222] Iteration 2240 (1.32445 iter/s, 30.2013s/40 iters), loss = 1.60138
I1029 21:30:37.693533 27430 solver.cpp:241]     Train net output #0: loss = 1.60138 (* 1 = 1.60138 loss)
I1029 21:30:37.693586 27430 sgd_solver.cpp:105] Iteration 2240, lr = 0.00757503
I1029 21:31:56.736218 27430 solver.cpp:222] Iteration 2280 (0.506067 iter/s, 79.0409s/40 iters), loss = 1.28208
I1029 21:31:56.736866 27430 solver.cpp:241]     Train net output #0: loss = 1.28208 (* 1 = 1.28208 loss)
I1029 21:31:56.736909 27430 sgd_solver.cpp:105] Iteration 2280, lr = 0.00753756
I1029 21:32:27.256952 27430 solver.cpp:222] Iteration 2320 (1.31064 iter/s, 30.5194s/40 iters), loss = 1.57734
I1029 21:32:27.257122 27430 solver.cpp:241]     Train net output #0: loss = 1.57734 (* 1 = 1.57734 loss)
I1029 21:32:27.257136 27430 sgd_solver.cpp:105] Iteration 2320, lr = 0.00750027
I1029 21:32:57.372678 27430 solver.cpp:222] Iteration 2360 (1.32825 iter/s, 30.1149s/40 iters), loss = 1.34747
I1029 21:32:57.372871 27430 solver.cpp:241]     Train net output #0: loss = 1.34747 (* 1 = 1.34747 loss)
I1029 21:32:57.372886 27430 sgd_solver.cpp:105] Iteration 2360, lr = 0.00746317
I1029 21:33:26.895316 27430 solver.cpp:222] Iteration 2400 (1.35493 iter/s, 29.5217s/40 iters), loss = 1.37429
I1029 21:33:26.895711 27430 solver.cpp:241]     Train net output #0: loss = 1.37429 (* 1 = 1.37429 loss)
I1029 21:33:26.895757 27430 sgd_solver.cpp:105] Iteration 2400, lr = 0.00742624
I1029 21:33:56.610422 27430 solver.cpp:222] Iteration 2440 (1.34617 iter/s, 29.714s/40 iters), loss = 1.87967
I1029 21:33:56.610986 27430 solver.cpp:241]     Train net output #0: loss = 1.87967 (* 1 = 1.87967 loss)
I1029 21:33:56.611037 27430 sgd_solver.cpp:105] Iteration 2440, lr = 0.00738951
I1029 21:34:26.225081 27430 solver.cpp:222] Iteration 2480 (1.35074 iter/s, 29.6134s/40 iters), loss = 1.57901
I1029 21:34:26.225513 27430 solver.cpp:241]     Train net output #0: loss = 1.57901 (* 1 = 1.57901 loss)
I1029 21:34:26.225553 27430 sgd_solver.cpp:105] Iteration 2480, lr = 0.00735295
I1029 21:34:40.472622 27479 data_layer.cpp:73] Restarting data prefetching from start.
I1029 21:34:41.102663 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_2500.caffemodel
I1029 21:34:41.229753 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_2500.solverstate
I1029 21:34:41.347247 27430 solver.cpp:334] Iteration 2500, Testing net (#0)
I1029 21:35:12.407224 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1029 21:35:12.618052 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.566
I1029 21:35:12.618091 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79828
I1029 21:35:12.618103 27430 solver.cpp:401]     Test net output #2: loss = 1.93722 (* 1 = 1.93722 loss)
I1029 21:35:28.555059 27430 solver.cpp:222] Iteration 2520 (0.641765 iter/s, 62.3281s/40 iters), loss = 1.73074
I1029 21:35:28.555474 27430 solver.cpp:241]     Train net output #0: loss = 1.73074 (* 1 = 1.73074 loss)
I1029 21:35:28.555506 27430 sgd_solver.cpp:105] Iteration 2520, lr = 0.00731657
I1029 21:35:58.086765 27430 solver.cpp:222] Iteration 2560 (1.35453 iter/s, 29.5306s/40 iters), loss = 1.30207
I1029 21:35:58.087332 27430 solver.cpp:241]     Train net output #0: loss = 1.30207 (* 1 = 1.30207 loss)
I1029 21:35:58.087379 27430 sgd_solver.cpp:105] Iteration 2560, lr = 0.00728038
I1029 21:36:27.754772 27430 solver.cpp:222] Iteration 2600 (1.34831 iter/s, 29.6668s/40 iters), loss = 1.61131
I1029 21:36:27.755236 27430 solver.cpp:241]     Train net output #0: loss = 1.61131 (* 1 = 1.61131 loss)
I1029 21:36:27.755286 27430 sgd_solver.cpp:105] Iteration 2600, lr = 0.00724436
I1029 21:36:57.234342 27430 solver.cpp:222] Iteration 2640 (1.35693 iter/s, 29.4784s/40 iters), loss = 1.73654
I1029 21:36:57.234964 27430 solver.cpp:241]     Train net output #0: loss = 1.73654 (* 1 = 1.73654 loss)
I1029 21:36:57.235014 27430 sgd_solver.cpp:105] Iteration 2640, lr = 0.00720852
I1029 21:37:26.719743 27430 solver.cpp:222] Iteration 2680 (1.35666 iter/s, 29.4841s/40 iters), loss = 1.2409
I1029 21:37:26.720160 27430 solver.cpp:241]     Train net output #0: loss = 1.2409 (* 1 = 1.2409 loss)
I1029 21:37:26.720208 27430 sgd_solver.cpp:105] Iteration 2680, lr = 0.00717286
I1029 21:37:56.660183 27430 solver.cpp:222] Iteration 2720 (1.33603 iter/s, 29.9393s/40 iters), loss = 1.29293
I1029 21:37:56.660854 27430 solver.cpp:241]     Train net output #0: loss = 1.29293 (* 1 = 1.29293 loss)
I1029 21:37:56.660897 27430 sgd_solver.cpp:105] Iteration 2720, lr = 0.00713737
I1029 21:38:27.050870 27430 solver.cpp:222] Iteration 2760 (1.31625 iter/s, 30.3893s/40 iters), loss = 1.73086
I1029 21:38:27.051426 27430 solver.cpp:241]     Train net output #0: loss = 1.73086 (* 1 = 1.73086 loss)
I1029 21:38:27.051470 27430 sgd_solver.cpp:105] Iteration 2760, lr = 0.00710206
I1029 21:38:57.172530 27430 solver.cpp:222] Iteration 2800 (1.328 iter/s, 30.1204s/40 iters), loss = 1.31399
I1029 21:38:57.173102 27430 solver.cpp:241]     Train net output #0: loss = 1.31399 (* 1 = 1.31399 loss)
I1029 21:38:57.173152 27430 sgd_solver.cpp:105] Iteration 2800, lr = 0.00706693
I1029 21:39:27.884006 27430 solver.cpp:222] Iteration 2840 (1.3025 iter/s, 30.7102s/40 iters), loss = 1.38001
I1029 21:39:27.884526 27430 solver.cpp:241]     Train net output #0: loss = 1.38001 (* 1 = 1.38001 loss)
I1029 21:39:27.884567 27430 sgd_solver.cpp:105] Iteration 2840, lr = 0.00703197
I1029 21:39:57.855890 27430 solver.cpp:222] Iteration 2880 (1.33464 iter/s, 29.9707s/40 iters), loss = 1.41527
I1029 21:39:57.856320 27430 solver.cpp:241]     Train net output #0: loss = 1.41527 (* 1 = 1.41527 loss)
I1029 21:39:57.856366 27430 sgd_solver.cpp:105] Iteration 2880, lr = 0.00699718
I1029 21:40:27.354981 27430 solver.cpp:222] Iteration 2920 (1.35602 iter/s, 29.498s/40 iters), loss = 1.37677
I1029 21:40:27.355538 27430 solver.cpp:241]     Train net output #0: loss = 1.37677 (* 1 = 1.37677 loss)
I1029 21:40:27.355573 27430 sgd_solver.cpp:105] Iteration 2920, lr = 0.00696256
I1029 21:40:56.785161 27430 solver.cpp:222] Iteration 2960 (1.35921 iter/s, 29.4289s/40 iters), loss = 1.57545
I1029 21:40:56.785622 27430 solver.cpp:241]     Train net output #0: loss = 1.57545 (* 1 = 1.57545 loss)
I1029 21:40:56.785670 27430 sgd_solver.cpp:105] Iteration 2960, lr = 0.00692812
I1029 21:41:25.417181 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_3000.caffemodel
I1029 21:41:25.566943 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_3000.solverstate
I1029 21:41:25.674063 27430 solver.cpp:334] Iteration 3000, Testing net (#0)
I1029 21:41:56.910847 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5698
I1029 21:41:56.910938 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80076
I1029 21:41:56.910949 27430 solver.cpp:401]     Test net output #2: loss = 1.9352 (* 1 = 1.9352 loss)
I1029 21:41:57.675808 27430 solver.cpp:222] Iteration 3000 (0.656935 iter/s, 60.8888s/40 iters), loss = 1.93918
I1029 21:41:57.675873 27430 solver.cpp:241]     Train net output #0: loss = 1.93918 (* 1 = 1.93918 loss)
I1029 21:41:57.675889 27430 sgd_solver.cpp:105] Iteration 3000, lr = 0.00689385
I1029 21:42:27.129153 27430 solver.cpp:222] Iteration 3040 (1.35812 iter/s, 29.4526s/40 iters), loss = 1.5279
I1029 21:42:27.129711 27430 solver.cpp:241]     Train net output #0: loss = 1.5279 (* 1 = 1.5279 loss)
I1029 21:42:27.129763 27430 sgd_solver.cpp:105] Iteration 3040, lr = 0.00685974
I1029 21:42:56.473450 27430 solver.cpp:222] Iteration 3080 (1.36318 iter/s, 29.3431s/40 iters), loss = 1.36292
I1029 21:42:56.473908 27430 solver.cpp:241]     Train net output #0: loss = 1.36292 (* 1 = 1.36292 loss)
I1029 21:42:56.473971 27430 sgd_solver.cpp:105] Iteration 3080, lr = 0.0068258
I1029 21:43:26.006371 27430 solver.cpp:222] Iteration 3120 (1.35447 iter/s, 29.5318s/40 iters), loss = 1.4945
I1029 21:43:26.006955 27430 solver.cpp:241]     Train net output #0: loss = 1.4945 (* 1 = 1.4945 loss)
I1029 21:43:26.007002 27430 sgd_solver.cpp:105] Iteration 3120, lr = 0.00679204
I1029 21:43:56.561158 27430 solver.cpp:222] Iteration 3160 (1.30918 iter/s, 30.5535s/40 iters), loss = 1.57586
I1029 21:43:56.561758 27430 solver.cpp:241]     Train net output #0: loss = 1.57586 (* 1 = 1.57586 loss)
I1029 21:43:56.561805 27430 sgd_solver.cpp:105] Iteration 3160, lr = 0.00675844
I1029 21:44:26.712963 27430 solver.cpp:222] Iteration 3200 (1.32668 iter/s, 30.1505s/40 iters), loss = 1.62834
I1029 21:44:26.713146 27430 solver.cpp:241]     Train net output #0: loss = 1.62834 (* 1 = 1.62834 loss)
I1029 21:44:26.713162 27430 sgd_solver.cpp:105] Iteration 3200, lr = 0.006725
I1029 21:44:56.775382 27430 solver.cpp:222] Iteration 3240 (1.3306 iter/s, 30.0615s/40 iters), loss = 1.80175
I1029 21:44:56.775974 27430 solver.cpp:241]     Train net output #0: loss = 1.80175 (* 1 = 1.80175 loss)
I1029 21:44:56.776016 27430 sgd_solver.cpp:105] Iteration 3240, lr = 0.00669173
I1029 21:45:31.189674 27430 solver.cpp:222] Iteration 3280 (1.16235 iter/s, 34.4129s/40 iters), loss = 1.78456
I1029 21:45:31.190224 27430 solver.cpp:241]     Train net output #0: loss = 1.78456 (* 1 = 1.78456 loss)
I1029 21:45:31.190259 27430 sgd_solver.cpp:105] Iteration 3280, lr = 0.00665863
I1029 21:46:12.541857 27430 solver.cpp:222] Iteration 3320 (0.967336 iter/s, 41.3507s/40 iters), loss = 1.55467
I1029 21:46:12.542469 27430 solver.cpp:241]     Train net output #0: loss = 1.55467 (* 1 = 1.55467 loss)
I1029 21:46:12.542528 27430 sgd_solver.cpp:105] Iteration 3320, lr = 0.00662568
I1029 21:46:42.898155 27430 solver.cpp:222] Iteration 3360 (1.31774 iter/s, 30.355s/40 iters), loss = 1.56532
I1029 21:46:42.898726 27430 solver.cpp:241]     Train net output #0: loss = 1.56532 (* 1 = 1.56532 loss)
I1029 21:46:42.898774 27430 sgd_solver.cpp:105] Iteration 3360, lr = 0.00659291
I1029 21:47:13.732506 27430 solver.cpp:222] Iteration 3400 (1.29731 iter/s, 30.8331s/40 iters), loss = 1.5242
I1029 21:47:13.732695 27430 solver.cpp:241]     Train net output #0: loss = 1.5242 (* 1 = 1.5242 loss)
I1029 21:47:13.732714 27430 sgd_solver.cpp:105] Iteration 3400, lr = 0.00656029
I1029 21:47:44.160589 27430 solver.cpp:222] Iteration 3440 (1.31461 iter/s, 30.4272s/40 iters), loss = 1.46819
I1029 21:47:44.160763 27430 solver.cpp:241]     Train net output #0: loss = 1.46819 (* 1 = 1.46819 loss)
I1029 21:47:44.160778 27430 sgd_solver.cpp:105] Iteration 3440, lr = 0.00652784
I1029 21:48:13.986871 27430 solver.cpp:222] Iteration 3480 (1.34114 iter/s, 29.8254s/40 iters), loss = 1.40527
I1029 21:48:13.987275 27430 solver.cpp:241]     Train net output #0: loss = 1.40527 (* 1 = 1.40527 loss)
I1029 21:48:13.987325 27430 sgd_solver.cpp:105] Iteration 3480, lr = 0.00649554
I1029 21:48:28.117455 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_3500.caffemodel
I1029 21:48:28.267937 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_3500.solverstate
I1029 21:48:28.384783 27430 solver.cpp:334] Iteration 3500, Testing net (#0)
I1029 21:48:59.465466 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1029 21:48:59.677583 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5682
I1029 21:48:59.677635 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80368
I1029 21:48:59.677646 27430 solver.cpp:401]     Test net output #2: loss = 1.90658 (* 1 = 1.90658 loss)
I1029 21:49:15.141803 27430 solver.cpp:222] Iteration 3520 (0.654096 iter/s, 61.1531s/40 iters), loss = 1.47697
I1029 21:49:15.142276 27430 solver.cpp:241]     Train net output #0: loss = 1.47697 (* 1 = 1.47697 loss)
I1029 21:49:15.142324 27430 sgd_solver.cpp:105] Iteration 3520, lr = 0.00646341
I1029 21:49:44.564858 27430 solver.cpp:222] Iteration 3560 (1.35953 iter/s, 29.4219s/40 iters), loss = 1.4985
I1029 21:49:44.565374 27430 solver.cpp:241]     Train net output #0: loss = 1.4985 (* 1 = 1.4985 loss)
I1029 21:49:44.565412 27430 sgd_solver.cpp:105] Iteration 3560, lr = 0.00643143
I1029 21:50:13.969794 27430 solver.cpp:222] Iteration 3600 (1.36037 iter/s, 29.4037s/40 iters), loss = 1.91551
I1029 21:50:13.970190 27430 solver.cpp:241]     Train net output #0: loss = 1.91551 (* 1 = 1.91551 loss)
I1029 21:50:13.970239 27430 sgd_solver.cpp:105] Iteration 3600, lr = 0.00639961
I1029 21:50:43.515816 27430 solver.cpp:222] Iteration 3640 (1.35387 iter/s, 29.545s/40 iters), loss = 1.58911
I1029 21:50:43.516485 27430 solver.cpp:241]     Train net output #0: loss = 1.58911 (* 1 = 1.58911 loss)
I1029 21:50:43.516530 27430 sgd_solver.cpp:105] Iteration 3640, lr = 0.00636796
I1029 21:51:13.174713 27430 solver.cpp:222] Iteration 3680 (1.34873 iter/s, 29.6575s/40 iters), loss = 1.15465
I1029 21:51:13.175153 27430 solver.cpp:241]     Train net output #0: loss = 1.15465 (* 1 = 1.15465 loss)
I1029 21:51:13.175191 27430 sgd_solver.cpp:105] Iteration 3680, lr = 0.00633645
I1029 21:51:42.976048 27430 solver.cpp:222] Iteration 3720 (1.34227 iter/s, 29.8002s/40 iters), loss = 1.62545
I1029 21:51:42.976644 27430 solver.cpp:241]     Train net output #0: loss = 1.62545 (* 1 = 1.62545 loss)
I1029 21:51:42.976696 27430 sgd_solver.cpp:105] Iteration 3720, lr = 0.0063051
I1029 21:52:13.111207 27430 solver.cpp:222] Iteration 3760 (1.32741 iter/s, 30.1339s/40 iters), loss = 1.30861
I1029 21:52:13.111382 27430 solver.cpp:241]     Train net output #0: loss = 1.30861 (* 1 = 1.30861 loss)
I1029 21:52:13.111397 27430 sgd_solver.cpp:105] Iteration 3760, lr = 0.00627391
I1029 21:52:43.079576 27430 solver.cpp:222] Iteration 3800 (1.33478 iter/s, 29.9675s/40 iters), loss = 1.31022
I1029 21:52:43.080052 27430 solver.cpp:241]     Train net output #0: loss = 1.31022 (* 1 = 1.31022 loss)
I1029 21:52:43.080103 27430 sgd_solver.cpp:105] Iteration 3800, lr = 0.00624287
I1029 21:53:13.361109 27430 solver.cpp:222] Iteration 3840 (1.32099 iter/s, 30.2804s/40 iters), loss = 1.26443
I1029 21:53:13.361694 27430 solver.cpp:241]     Train net output #0: loss = 1.26443 (* 1 = 1.26443 loss)
I1029 21:53:13.361747 27430 sgd_solver.cpp:105] Iteration 3840, lr = 0.00621199
I1029 21:53:42.997079 27430 solver.cpp:222] Iteration 3880 (1.34977 iter/s, 29.6347s/40 iters), loss = 1.63444
I1029 21:53:42.997547 27430 solver.cpp:241]     Train net output #0: loss = 1.63444 (* 1 = 1.63444 loss)
I1029 21:53:42.997601 27430 sgd_solver.cpp:105] Iteration 3880, lr = 0.00618126
I1029 21:54:12.524472 27430 solver.cpp:222] Iteration 3920 (1.35473 iter/s, 29.5263s/40 iters), loss = 1.36301
I1029 21:54:12.525012 27430 solver.cpp:241]     Train net output #0: loss = 1.36301 (* 1 = 1.36301 loss)
I1029 21:54:12.525053 27430 sgd_solver.cpp:105] Iteration 3920, lr = 0.00615068
I1029 21:54:42.201934 27430 solver.cpp:222] Iteration 3960 (1.34788 iter/s, 29.6762s/40 iters), loss = 1.38876
I1029 21:54:42.202441 27430 solver.cpp:241]     Train net output #0: loss = 1.38876 (* 1 = 1.38876 loss)
I1029 21:54:42.202492 27430 sgd_solver.cpp:105] Iteration 3960, lr = 0.00612025
I1029 21:55:11.014721 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_4000.caffemodel
I1029 21:55:11.164304 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_4000.solverstate
I1029 21:55:11.281105 27430 solver.cpp:334] Iteration 4000, Testing net (#0)
I1029 21:55:42.582389 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5732
I1029 21:55:42.582545 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.79892
I1029 21:55:42.582557 27430 solver.cpp:401]     Test net output #2: loss = 1.90469 (* 1 = 1.90469 loss)
I1029 21:55:43.333701 27430 solver.cpp:222] Iteration 4000 (0.654345 iter/s, 61.1299s/40 iters), loss = 1.23589
I1029 21:55:43.333756 27430 solver.cpp:241]     Train net output #0: loss = 1.23589 (* 1 = 1.23589 loss)
I1029 21:55:43.333768 27430 sgd_solver.cpp:105] Iteration 4000, lr = 0.00608997
I1029 21:56:12.767442 27430 solver.cpp:222] Iteration 4040 (1.35902 iter/s, 29.433s/40 iters), loss = 1.57235
I1029 21:56:12.768036 27430 solver.cpp:241]     Train net output #0: loss = 1.57235 (* 1 = 1.57235 loss)
I1029 21:56:12.768087 27430 sgd_solver.cpp:105] Iteration 4040, lr = 0.00605985
I1029 21:56:42.559057 27430 solver.cpp:222] Iteration 4080 (1.34272 iter/s, 29.7903s/40 iters), loss = 1.54982
I1029 21:56:42.559500 27430 solver.cpp:241]     Train net output #0: loss = 1.54982 (* 1 = 1.54982 loss)
I1029 21:56:42.559559 27430 sgd_solver.cpp:105] Iteration 4080, lr = 0.00602987
I1029 21:57:12.481351 27430 solver.cpp:222] Iteration 4120 (1.33685 iter/s, 29.9212s/40 iters), loss = 1.5546
I1029 21:57:12.481998 27430 solver.cpp:241]     Train net output #0: loss = 1.5546 (* 1 = 1.5546 loss)
I1029 21:57:12.482051 27430 sgd_solver.cpp:105] Iteration 4120, lr = 0.00600004
I1029 21:57:42.073719 27430 solver.cpp:222] Iteration 4160 (1.35176 iter/s, 29.591s/40 iters), loss = 1.55139
I1029 21:57:42.074148 27430 solver.cpp:241]     Train net output #0: loss = 1.55139 (* 1 = 1.55139 loss)
I1029 21:57:42.074208 27430 sgd_solver.cpp:105] Iteration 4160, lr = 0.00597035
I1029 21:58:11.762789 27430 solver.cpp:222] Iteration 4200 (1.34735 iter/s, 29.688s/40 iters), loss = 1.32221
I1029 21:58:11.763370 27430 solver.cpp:241]     Train net output #0: loss = 1.32221 (* 1 = 1.32221 loss)
I1029 21:58:11.763428 27430 sgd_solver.cpp:105] Iteration 4200, lr = 0.00594082
I1029 21:58:41.820684 27430 solver.cpp:222] Iteration 4240 (1.33082 iter/s, 30.0566s/40 iters), loss = 1.44497
I1029 21:58:41.821267 27430 solver.cpp:241]     Train net output #0: loss = 1.44497 (* 1 = 1.44497 loss)
I1029 21:58:41.821321 27430 sgd_solver.cpp:105] Iteration 4240, lr = 0.00591143
I1029 21:59:11.550005 27430 solver.cpp:222] Iteration 4280 (1.34553 iter/s, 29.7281s/40 iters), loss = 1.32614
I1029 21:59:11.550452 27430 solver.cpp:241]     Train net output #0: loss = 1.32614 (* 1 = 1.32614 loss)
I1029 21:59:11.550508 27430 sgd_solver.cpp:105] Iteration 4280, lr = 0.00588218
I1029 21:59:41.491070 27430 solver.cpp:222] Iteration 4320 (1.33601 iter/s, 29.9399s/40 iters), loss = 1.37901
I1029 21:59:41.491580 27430 solver.cpp:241]     Train net output #0: loss = 1.37901 (* 1 = 1.37901 loss)
I1029 21:59:41.491633 27430 sgd_solver.cpp:105] Iteration 4320, lr = 0.00585308
I1029 22:00:10.902981 27430 solver.cpp:222] Iteration 4360 (1.36005 iter/s, 29.4107s/40 iters), loss = 1.52483
I1029 22:00:10.903417 27430 solver.cpp:241]     Train net output #0: loss = 1.52483 (* 1 = 1.52483 loss)
I1029 22:00:10.903472 27430 sgd_solver.cpp:105] Iteration 4360, lr = 0.00582413
I1029 22:00:40.449182 27430 solver.cpp:222] Iteration 4400 (1.35386 iter/s, 29.5451s/40 iters), loss = 1.57462
I1029 22:00:40.449862 27430 solver.cpp:241]     Train net output #0: loss = 1.57462 (* 1 = 1.57462 loss)
I1029 22:00:40.449913 27430 sgd_solver.cpp:105] Iteration 4400, lr = 0.00579531
I1029 22:01:10.249418 27430 solver.cpp:222] Iteration 4440 (1.34233 iter/s, 29.7989s/40 iters), loss = 1.33204
I1029 22:01:10.249858 27430 solver.cpp:241]     Train net output #0: loss = 1.33204 (* 1 = 1.33204 loss)
I1029 22:01:10.249907 27430 sgd_solver.cpp:105] Iteration 4440, lr = 0.00576664
I1029 22:02:05.830749 27430 solver.cpp:222] Iteration 4480 (0.719688 iter/s, 55.5796s/40 iters), loss = 1.10586
I1029 22:02:05.831382 27430 solver.cpp:241]     Train net output #0: loss = 1.10586 (* 1 = 1.10586 loss)
I1029 22:02:05.831439 27430 sgd_solver.cpp:105] Iteration 4480, lr = 0.00573811
I1029 22:02:39.071548 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_4500.caffemodel
I1029 22:02:39.217290 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_4500.solverstate
I1029 22:02:39.331940 27430 solver.cpp:334] Iteration 4500, Testing net (#0)
I1029 22:03:10.499598 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1029 22:03:10.711527 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57216
I1029 22:03:10.711581 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80324
I1029 22:03:10.711592 27430 solver.cpp:401]     Test net output #2: loss = 1.89236 (* 1 = 1.89236 loss)
I1029 22:03:27.151964 27430 solver.cpp:222] Iteration 4520 (0.491892 iter/s, 81.3187s/40 iters), loss = 1.4392
I1029 22:03:27.152365 27430 solver.cpp:241]     Train net output #0: loss = 1.4392 (* 1 = 1.4392 loss)
I1029 22:03:27.152405 27430 sgd_solver.cpp:105] Iteration 4520, lr = 0.00570973
I1029 22:03:57.613675 27430 solver.cpp:222] Iteration 4560 (1.31317 iter/s, 30.4606s/40 iters), loss = 1.4285
I1029 22:03:57.614333 27430 solver.cpp:241]     Train net output #0: loss = 1.4285 (* 1 = 1.4285 loss)
I1029 22:03:57.614392 27430 sgd_solver.cpp:105] Iteration 4560, lr = 0.00568148
I1029 22:04:27.605875 27430 solver.cpp:222] Iteration 4600 (1.33374 iter/s, 29.9909s/40 iters), loss = 1.50889
I1029 22:04:27.606348 27430 solver.cpp:241]     Train net output #0: loss = 1.50889 (* 1 = 1.50889 loss)
I1029 22:04:27.606400 27430 sgd_solver.cpp:105] Iteration 4600, lr = 0.00565337
I1029 22:05:07.389104 27430 solver.cpp:222] Iteration 4640 (1.00548 iter/s, 39.7819s/40 iters), loss = 1.87335
I1029 22:05:07.389581 27430 solver.cpp:241]     Train net output #0: loss = 1.87335 (* 1 = 1.87335 loss)
I1029 22:05:07.389597 27430 sgd_solver.cpp:105] Iteration 4640, lr = 0.00562541
I1029 22:05:37.609900 27430 solver.cpp:222] Iteration 4680 (1.32364 iter/s, 30.2196s/40 iters), loss = 1.58296
I1029 22:05:37.610021 27430 solver.cpp:241]     Train net output #0: loss = 1.58296 (* 1 = 1.58296 loss)
I1029 22:05:37.610038 27430 sgd_solver.cpp:105] Iteration 4680, lr = 0.00559758
I1029 22:06:07.428970 27430 solver.cpp:222] Iteration 4720 (1.34146 iter/s, 29.8182s/40 iters), loss = 1.406
I1029 22:06:07.429435 27430 solver.cpp:241]     Train net output #0: loss = 1.406 (* 1 = 1.406 loss)
I1029 22:06:07.429484 27430 sgd_solver.cpp:105] Iteration 4720, lr = 0.00556988
I1029 22:06:37.704674 27430 solver.cpp:222] Iteration 4760 (1.32124 iter/s, 30.2746s/40 iters), loss = 1.31051
I1029 22:06:37.705276 27430 solver.cpp:241]     Train net output #0: loss = 1.31051 (* 1 = 1.31051 loss)
I1029 22:06:37.705327 27430 sgd_solver.cpp:105] Iteration 4760, lr = 0.00554233
I1029 22:07:08.216547 27430 solver.cpp:222] Iteration 4800 (1.31102 iter/s, 30.5106s/40 iters), loss = 1.62718
I1029 22:07:08.216755 27430 solver.cpp:241]     Train net output #0: loss = 1.62718 (* 1 = 1.62718 loss)
I1029 22:07:08.216769 27430 sgd_solver.cpp:105] Iteration 4800, lr = 0.00551491
I1029 22:07:37.571388 27430 solver.cpp:222] Iteration 4840 (1.36268 iter/s, 29.3539s/40 iters), loss = 1.40075
I1029 22:07:37.571873 27430 solver.cpp:241]     Train net output #0: loss = 1.40075 (* 1 = 1.40075 loss)
I1029 22:07:37.571949 27430 sgd_solver.cpp:105] Iteration 4840, lr = 0.00548763
I1029 22:08:06.926672 27430 solver.cpp:222] Iteration 4880 (1.36267 iter/s, 29.3541s/40 iters), loss = 1.92767
I1029 22:08:06.927220 27430 solver.cpp:241]     Train net output #0: loss = 1.92767 (* 1 = 1.92767 loss)
I1029 22:08:06.927281 27430 sgd_solver.cpp:105] Iteration 4880, lr = 0.00546048
I1029 22:08:44.762372 27430 solver.cpp:222] Iteration 4920 (1.05724 iter/s, 37.8343s/40 iters), loss = 1.26729
I1029 22:08:44.762976 27430 solver.cpp:241]     Train net output #0: loss = 1.26729 (* 1 = 1.26729 loss)
I1029 22:08:44.763032 27430 sgd_solver.cpp:105] Iteration 4920, lr = 0.00543347
I1029 22:09:14.845965 27430 solver.cpp:222] Iteration 4960 (1.32968 iter/s, 30.0823s/40 iters), loss = 1.43136
I1029 22:09:14.846158 27430 solver.cpp:241]     Train net output #0: loss = 1.43136 (* 1 = 1.43136 loss)
I1029 22:09:14.846173 27430 sgd_solver.cpp:105] Iteration 4960, lr = 0.00540659
I1029 22:09:43.654006 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_5000.caffemodel
I1029 22:09:43.821502 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_5000.solverstate
I1029 22:09:43.940116 27430 solver.cpp:334] Iteration 5000, Testing net (#0)
I1029 22:10:15.200757 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57108
I1029 22:10:15.201287 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80096
I1029 22:10:15.201334 27430 solver.cpp:401]     Test net output #2: loss = 1.88019 (* 1 = 1.88019 loss)
I1029 22:10:15.968768 27430 solver.cpp:222] Iteration 5000 (0.654437 iter/s, 61.1212s/40 iters), loss = 1.80929
I1029 22:10:15.968811 27430 solver.cpp:241]     Train net output #0: loss = 1.80929 (* 1 = 1.80929 loss)
I1029 22:10:15.968824 27430 sgd_solver.cpp:105] Iteration 5000, lr = 0.00537984
I1029 22:10:16.054688 27479 data_layer.cpp:73] Restarting data prefetching from start.
I1029 22:10:45.348702 27430 solver.cpp:222] Iteration 5040 (1.36151 iter/s, 29.3792s/40 iters), loss = 1.47353
I1029 22:10:45.348944 27430 solver.cpp:241]     Train net output #0: loss = 1.47353 (* 1 = 1.47353 loss)
I1029 22:10:45.348961 27430 sgd_solver.cpp:105] Iteration 5040, lr = 0.00535322
I1029 22:11:14.788997 27430 solver.cpp:222] Iteration 5080 (1.35873 iter/s, 29.4394s/40 iters), loss = 1.55689
I1029 22:11:14.789465 27430 solver.cpp:241]     Train net output #0: loss = 1.55689 (* 1 = 1.55689 loss)
I1029 22:11:14.789516 27430 sgd_solver.cpp:105] Iteration 5080, lr = 0.00532674
I1029 22:11:44.646692 27430 solver.cpp:222] Iteration 5120 (1.33974 iter/s, 29.8566s/40 iters), loss = 1.53076
I1029 22:11:44.647286 27430 solver.cpp:241]     Train net output #0: loss = 1.53076 (* 1 = 1.53076 loss)
I1029 22:11:44.647337 27430 sgd_solver.cpp:105] Iteration 5120, lr = 0.00530039
I1029 22:12:14.027686 27430 solver.cpp:222] Iteration 5160 (1.36148 iter/s, 29.3797s/40 iters), loss = 1.82265
I1029 22:12:14.028157 27430 solver.cpp:241]     Train net output #0: loss = 1.82265 (* 1 = 1.82265 loss)
I1029 22:12:14.028213 27430 sgd_solver.cpp:105] Iteration 5160, lr = 0.00527417
I1029 22:13:13.490635 27430 solver.cpp:222] Iteration 5200 (0.672708 iter/s, 59.4611s/40 iters), loss = 1.58279
I1029 22:13:13.491266 27430 solver.cpp:241]     Train net output #0: loss = 1.58279 (* 1 = 1.58279 loss)
I1029 22:13:13.491318 27430 sgd_solver.cpp:105] Iteration 5200, lr = 0.00524807
I1029 22:13:43.410739 27430 solver.cpp:222] Iteration 5240 (1.33695 iter/s, 29.9188s/40 iters), loss = 1.28178
I1029 22:13:43.411170 27430 solver.cpp:241]     Train net output #0: loss = 1.28178 (* 1 = 1.28178 loss)
I1029 22:13:43.411212 27430 sgd_solver.cpp:105] Iteration 5240, lr = 0.00522211
I1029 22:14:13.165555 27430 solver.cpp:222] Iteration 5280 (1.34437 iter/s, 29.7537s/40 iters), loss = 1.72762
I1029 22:14:13.166116 27430 solver.cpp:241]     Train net output #0: loss = 1.72762 (* 1 = 1.72762 loss)
I1029 22:14:13.166169 27430 sgd_solver.cpp:105] Iteration 5280, lr = 0.00519628
I1029 22:14:42.747552 27430 solver.cpp:222] Iteration 5320 (1.35223 iter/s, 29.5808s/40 iters), loss = 1.34537
I1029 22:14:42.748071 27430 solver.cpp:241]     Train net output #0: loss = 1.34537 (* 1 = 1.34537 loss)
I1029 22:14:42.748113 27430 sgd_solver.cpp:105] Iteration 5320, lr = 0.00517057
I1029 22:15:14.694223 27430 solver.cpp:222] Iteration 5360 (1.25214 iter/s, 31.9454s/40 iters), loss = 1.73081
I1029 22:15:14.694815 27430 solver.cpp:241]     Train net output #0: loss = 1.73081 (* 1 = 1.73081 loss)
I1029 22:15:14.694870 27430 sgd_solver.cpp:105] Iteration 5360, lr = 0.00514499
I1029 22:15:44.200348 27430 solver.cpp:222] Iteration 5400 (1.35571 iter/s, 29.5049s/40 iters), loss = 1.73467
I1029 22:15:44.200842 27430 solver.cpp:241]     Train net output #0: loss = 1.73467 (* 1 = 1.73467 loss)
I1029 22:15:44.200899 27430 sgd_solver.cpp:105] Iteration 5400, lr = 0.00511954
I1029 22:16:14.015601 27430 solver.cpp:222] Iteration 5440 (1.34165 iter/s, 29.8141s/40 iters), loss = 1.52287
I1029 22:16:14.016204 27430 solver.cpp:241]     Train net output #0: loss = 1.52287 (* 1 = 1.52287 loss)
I1029 22:16:14.016258 27430 sgd_solver.cpp:105] Iteration 5440, lr = 0.00509421
I1029 22:16:43.906415 27430 solver.cpp:222] Iteration 5480 (1.33826 iter/s, 29.8895s/40 iters), loss = 1.28385
I1029 22:16:43.906889 27430 solver.cpp:241]     Train net output #0: loss = 1.28385 (* 1 = 1.28385 loss)
I1029 22:16:43.906960 27430 sgd_solver.cpp:105] Iteration 5480, lr = 0.00506901
I1029 22:16:58.173954 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_5500.caffemodel
I1029 22:16:58.324443 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_5500.solverstate
I1029 22:16:58.452752 27430 solver.cpp:334] Iteration 5500, Testing net (#0)
I1029 22:17:29.563488 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1029 22:17:29.775401 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57056
I1029 22:17:29.775454 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80348
I1029 22:17:29.775463 27430 solver.cpp:401]     Test net output #2: loss = 1.92866 (* 1 = 1.92866 loss)
I1029 22:17:45.426676 27430 solver.cpp:222] Iteration 5520 (0.650212 iter/s, 61.5184s/40 iters), loss = 1.22359
I1029 22:17:45.427111 27430 solver.cpp:241]     Train net output #0: loss = 1.22359 (* 1 = 1.22359 loss)
I1029 22:17:45.427165 27430 sgd_solver.cpp:105] Iteration 5520, lr = 0.00504393
I1029 22:18:15.211854 27430 solver.cpp:222] Iteration 5560 (1.343 iter/s, 29.7841s/40 iters), loss = 1.38016
I1029 22:18:15.212373 27430 solver.cpp:241]     Train net output #0: loss = 1.38016 (* 1 = 1.38016 loss)
I1029 22:18:15.212411 27430 sgd_solver.cpp:105] Iteration 5560, lr = 0.00501898
I1029 22:18:45.557405 27430 solver.cpp:222] Iteration 5600 (1.3182 iter/s, 30.3443s/40 iters), loss = 1.3214
I1029 22:18:45.558076 27430 solver.cpp:241]     Train net output #0: loss = 1.3214 (* 1 = 1.3214 loss)
I1029 22:18:45.558135 27430 sgd_solver.cpp:105] Iteration 5600, lr = 0.00499415
I1029 22:19:25.766438 27430 solver.cpp:222] Iteration 5640 (0.99484 iter/s, 40.2075s/40 iters), loss = 1.45958
I1029 22:19:25.766948 27430 solver.cpp:241]     Train net output #0: loss = 1.45958 (* 1 = 1.45958 loss)
I1029 22:19:25.767015 27430 sgd_solver.cpp:105] Iteration 5640, lr = 0.00496944
I1029 22:19:55.490936 27430 solver.cpp:222] Iteration 5680 (1.34574 iter/s, 29.7233s/40 iters), loss = 1.62927
I1029 22:19:55.491407 27430 solver.cpp:241]     Train net output #0: loss = 1.62927 (* 1 = 1.62927 loss)
I1029 22:19:55.491464 27430 sgd_solver.cpp:105] Iteration 5680, lr = 0.00494486
I1029 22:20:25.433125 27430 solver.cpp:222] Iteration 5720 (1.33596 iter/s, 29.941s/40 iters), loss = 1.32116
I1029 22:20:25.433727 27430 solver.cpp:241]     Train net output #0: loss = 1.32116 (* 1 = 1.32116 loss)
I1029 22:20:25.433778 27430 sgd_solver.cpp:105] Iteration 5720, lr = 0.0049204
I1029 22:20:58.741842 27430 solver.cpp:222] Iteration 5760 (1.20094 iter/s, 33.3074s/40 iters), loss = 1.3617
I1029 22:20:58.742447 27430 solver.cpp:241]     Train net output #0: loss = 1.3617 (* 1 = 1.3617 loss)
I1029 22:20:58.742485 27430 sgd_solver.cpp:105] Iteration 5760, lr = 0.00489605
I1029 22:21:28.315503 27430 solver.cpp:222] Iteration 5800 (1.35261 iter/s, 29.5724s/40 iters), loss = 1.47046
I1029 22:21:28.315989 27430 solver.cpp:241]     Train net output #0: loss = 1.47046 (* 1 = 1.47046 loss)
I1029 22:21:28.316043 27430 sgd_solver.cpp:105] Iteration 5800, lr = 0.00487183
I1029 22:21:58.127550 27430 solver.cpp:222] Iteration 5840 (1.34179 iter/s, 29.8109s/40 iters), loss = 1.58132
I1029 22:21:58.128196 27430 solver.cpp:241]     Train net output #0: loss = 1.58132 (* 1 = 1.58132 loss)
I1029 22:21:58.128247 27430 sgd_solver.cpp:105] Iteration 5840, lr = 0.00484773
I1029 22:22:27.640892 27430 solver.cpp:222] Iteration 5880 (1.35538 iter/s, 29.512s/40 iters), loss = 1.64404
I1029 22:22:27.641366 27430 solver.cpp:241]     Train net output #0: loss = 1.64404 (* 1 = 1.64404 loss)
I1029 22:22:27.641417 27430 sgd_solver.cpp:105] Iteration 5880, lr = 0.00482375
I1029 22:22:57.057729 27430 solver.cpp:222] Iteration 5920 (1.35982 iter/s, 29.4157s/40 iters), loss = 1.40973
I1029 22:22:57.058300 27430 solver.cpp:241]     Train net output #0: loss = 1.40973 (* 1 = 1.40973 loss)
I1029 22:22:57.058357 27430 sgd_solver.cpp:105] Iteration 5920, lr = 0.00479988
I1029 22:23:26.587735 27430 solver.cpp:222] Iteration 5960 (1.35461 iter/s, 29.5288s/40 iters), loss = 1.55668
I1029 22:23:26.588215 27430 solver.cpp:241]     Train net output #0: loss = 1.55668 (* 1 = 1.55668 loss)
I1029 22:23:26.588271 27430 sgd_solver.cpp:105] Iteration 5960, lr = 0.00477614
I1029 22:23:55.280172 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_6000.caffemodel
I1029 22:23:55.752558 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_6000.solverstate
I1029 22:23:56.741614 27430 solver.cpp:334] Iteration 6000, Testing net (#0)
I1029 22:24:27.965875 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57508
I1029 22:24:27.966035 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.801679
I1029 22:24:27.966048 27430 solver.cpp:401]     Test net output #2: loss = 1.88615 (* 1 = 1.88615 loss)
I1029 22:24:28.712177 27430 solver.cpp:222] Iteration 6000 (0.643889 iter/s, 62.1225s/40 iters), loss = 1.61239
I1029 22:24:28.712648 27430 solver.cpp:241]     Train net output #0: loss = 1.61239 (* 1 = 1.61239 loss)
I1029 22:24:28.712698 27430 sgd_solver.cpp:105] Iteration 6000, lr = 0.00475251
I1029 22:24:58.853756 27430 solver.cpp:222] Iteration 6040 (1.32712 iter/s, 30.1404s/40 iters), loss = 1.46205
I1029 22:24:58.854295 27430 solver.cpp:241]     Train net output #0: loss = 1.46205 (* 1 = 1.46205 loss)
I1029 22:24:58.854344 27430 sgd_solver.cpp:105] Iteration 6040, lr = 0.004729
I1029 22:25:28.498332 27430 solver.cpp:222] Iteration 6080 (1.34937 iter/s, 29.6434s/40 iters), loss = 0.937883
I1029 22:25:28.498661 27430 solver.cpp:241]     Train net output #0: loss = 0.937883 (* 1 = 0.937883 loss)
I1029 22:25:28.498677 27430 sgd_solver.cpp:105] Iteration 6080, lr = 0.0047056
I1029 22:25:58.074175 27430 solver.cpp:222] Iteration 6120 (1.3525 iter/s, 29.5748s/40 iters), loss = 1.37546
I1029 22:25:58.074810 27430 solver.cpp:241]     Train net output #0: loss = 1.37546 (* 1 = 1.37546 loss)
I1029 22:25:58.074867 27430 sgd_solver.cpp:105] Iteration 6120, lr = 0.00468232
I1029 22:26:29.073217 27430 solver.cpp:222] Iteration 6160 (1.29042 iter/s, 30.9977s/40 iters), loss = 1.44953
I1029 22:26:29.073671 27430 solver.cpp:241]     Train net output #0: loss = 1.44953 (* 1 = 1.44953 loss)
I1029 22:26:29.073688 27430 sgd_solver.cpp:105] Iteration 6160, lr = 0.00465916
I1029 22:26:59.822758 27430 solver.cpp:222] Iteration 6200 (1.30088 iter/s, 30.7484s/40 iters), loss = 1.49717
I1029 22:26:59.822958 27430 solver.cpp:241]     Train net output #0: loss = 1.49717 (* 1 = 1.49717 loss)
I1029 22:26:59.822973 27430 sgd_solver.cpp:105] Iteration 6200, lr = 0.00463611
I1029 22:27:29.923171 27430 solver.cpp:222] Iteration 6240 (1.32893 iter/s, 30.0995s/40 iters), loss = 1.29364
I1029 22:27:29.923344 27430 solver.cpp:241]     Train net output #0: loss = 1.29364 (* 1 = 1.29364 loss)
I1029 22:27:29.923359 27430 sgd_solver.cpp:105] Iteration 6240, lr = 0.00461318
I1029 22:27:59.518813 27430 solver.cpp:222] Iteration 6280 (1.35159 iter/s, 29.5948s/40 iters), loss = 1.50241
I1029 22:27:59.519289 27430 solver.cpp:241]     Train net output #0: loss = 1.50241 (* 1 = 1.50241 loss)
I1029 22:27:59.519345 27430 sgd_solver.cpp:105] Iteration 6280, lr = 0.00459035
I1029 22:28:29.255419 27430 solver.cpp:222] Iteration 6320 (1.3452 iter/s, 29.7355s/40 iters), loss = 1.3608
I1029 22:28:29.255991 27430 solver.cpp:241]     Train net output #0: loss = 1.3608 (* 1 = 1.3608 loss)
I1029 22:28:29.256054 27430 sgd_solver.cpp:105] Iteration 6320, lr = 0.00456764
I1029 22:28:58.961694 27430 solver.cpp:222] Iteration 6360 (1.34657 iter/s, 29.705s/40 iters), loss = 1.34107
I1029 22:28:58.962257 27430 solver.cpp:241]     Train net output #0: loss = 1.34107 (* 1 = 1.34107 loss)
I1029 22:28:58.962307 27430 sgd_solver.cpp:105] Iteration 6360, lr = 0.00454505
I1029 22:29:29.188261 27430 solver.cpp:222] Iteration 6400 (1.32339 iter/s, 30.2253s/40 iters), loss = 1.47962
I1029 22:29:29.188828 27430 solver.cpp:241]     Train net output #0: loss = 1.47962 (* 1 = 1.47962 loss)
I1029 22:29:29.188880 27430 sgd_solver.cpp:105] Iteration 6400, lr = 0.00452256
I1029 22:30:42.845000 27430 solver.cpp:222] Iteration 6440 (0.543076 iter/s, 73.6545s/40 iters), loss = 1.50928
I1029 22:30:42.845620 27430 solver.cpp:241]     Train net output #0: loss = 1.50928 (* 1 = 1.50928 loss)
I1029 22:30:42.845705 27430 sgd_solver.cpp:105] Iteration 6440, lr = 0.00450019
I1029 22:31:59.703183 27430 solver.cpp:222] Iteration 6480 (0.520454 iter/s, 76.8559s/40 iters), loss = 1.33431
I1029 22:31:59.703900 27430 solver.cpp:241]     Train net output #0: loss = 1.33431 (* 1 = 1.33431 loss)
I1029 22:31:59.703980 27430 sgd_solver.cpp:105] Iteration 6480, lr = 0.00447793
I1029 22:32:15.014711 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_6500.caffemodel
I1029 22:32:15.184274 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_6500.solverstate
I1029 22:32:15.309718 27430 solver.cpp:334] Iteration 6500, Testing net (#0)
I1029 22:32:46.364698 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1029 22:32:46.573792 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57516
I1029 22:32:46.573840 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.806319
I1029 22:32:46.573851 27430 solver.cpp:401]     Test net output #2: loss = 1.87567 (* 1 = 1.87567 loss)
I1029 22:33:02.070243 27430 solver.cpp:222] Iteration 6520 (0.641386 iter/s, 62.3649s/40 iters), loss = 1.60749
I1029 22:33:02.070752 27430 solver.cpp:241]     Train net output #0: loss = 1.60749 (* 1 = 1.60749 loss)
I1029 22:33:02.070803 27430 sgd_solver.cpp:105] Iteration 6520, lr = 0.00445577
I1029 22:33:31.498517 27430 solver.cpp:222] Iteration 6560 (1.35929 iter/s, 29.4271s/40 iters), loss = 1.59624
I1029 22:33:31.499114 27430 solver.cpp:241]     Train net output #0: loss = 1.59624 (* 1 = 1.59624 loss)
I1029 22:33:31.499166 27430 sgd_solver.cpp:105] Iteration 6560, lr = 0.00443373
I1029 22:34:01.222838 27430 solver.cpp:222] Iteration 6600 (1.34576 iter/s, 29.723s/40 iters), loss = 1.65984
I1029 22:34:01.223278 27430 solver.cpp:241]     Train net output #0: loss = 1.65984 (* 1 = 1.65984 loss)
I1029 22:34:01.223333 27430 sgd_solver.cpp:105] Iteration 6600, lr = 0.0044118
I1029 22:34:30.770200 27430 solver.cpp:222] Iteration 6640 (1.35381 iter/s, 29.5463s/40 iters), loss = 1.41667
I1029 22:34:30.770828 27430 solver.cpp:241]     Train net output #0: loss = 1.41667 (* 1 = 1.41667 loss)
I1029 22:34:30.770890 27430 sgd_solver.cpp:105] Iteration 6640, lr = 0.00438997
I1029 22:35:00.495822 27430 solver.cpp:222] Iteration 6680 (1.3457 iter/s, 29.7243s/40 iters), loss = 1.46935
I1029 22:35:00.496230 27430 solver.cpp:241]     Train net output #0: loss = 1.46935 (* 1 = 1.46935 loss)
I1029 22:35:00.496276 27430 sgd_solver.cpp:105] Iteration 6680, lr = 0.00436825
I1029 22:35:31.146746 27430 solver.cpp:222] Iteration 6720 (1.30507 iter/s, 30.6498s/40 iters), loss = 1.40011
I1029 22:35:31.147753 27430 solver.cpp:241]     Train net output #0: loss = 1.40011 (* 1 = 1.40011 loss)
I1029 22:35:31.147851 27430 sgd_solver.cpp:105] Iteration 6720, lr = 0.00434664
I1029 22:36:01.639351 27430 solver.cpp:222] Iteration 6760 (1.31186 iter/s, 30.4909s/40 iters), loss = 1.51481
I1029 22:36:01.640030 27430 solver.cpp:241]     Train net output #0: loss = 1.51481 (* 1 = 1.51481 loss)
I1029 22:36:01.640082 27430 sgd_solver.cpp:105] Iteration 6760, lr = 0.00432514
I1029 22:36:32.036725 27430 solver.cpp:222] Iteration 6800 (1.31596 iter/s, 30.396s/40 iters), loss = 1.4533
I1029 22:36:32.037421 27430 solver.cpp:241]     Train net output #0: loss = 1.4533 (* 1 = 1.4533 loss)
I1029 22:36:32.037474 27430 sgd_solver.cpp:105] Iteration 6800, lr = 0.00430374
I1029 22:37:02.556481 27430 solver.cpp:222] Iteration 6840 (1.31069 iter/s, 30.5184s/40 iters), loss = 1.34916
I1029 22:37:02.556649 27430 solver.cpp:241]     Train net output #0: loss = 1.34916 (* 1 = 1.34916 loss)
I1029 22:37:02.556663 27430 sgd_solver.cpp:105] Iteration 6840, lr = 0.00428245
I1029 22:37:32.352051 27430 solver.cpp:222] Iteration 6880 (1.34252 iter/s, 29.7947s/40 iters), loss = 1.54672
I1029 22:37:32.352537 27430 solver.cpp:241]     Train net output #0: loss = 1.54672 (* 1 = 1.54672 loss)
I1029 22:37:32.352596 27430 sgd_solver.cpp:105] Iteration 6880, lr = 0.00426126
I1029 22:38:03.137923 27430 solver.cpp:222] Iteration 6920 (1.29935 iter/s, 30.7847s/40 iters), loss = 1.28368
I1029 22:38:03.138577 27430 solver.cpp:241]     Train net output #0: loss = 1.28368 (* 1 = 1.28368 loss)
I1029 22:38:03.138633 27430 sgd_solver.cpp:105] Iteration 6920, lr = 0.00424018
I1029 22:38:33.178916 27430 solver.cpp:222] Iteration 6960 (1.33157 iter/s, 30.0396s/40 iters), loss = 1.2068
I1029 22:38:33.179816 27430 solver.cpp:241]     Train net output #0: loss = 1.2068 (* 1 = 1.2068 loss)
I1029 22:38:33.180042 27430 sgd_solver.cpp:105] Iteration 6960, lr = 0.00421921
I1029 22:39:03.102807 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_7000.caffemodel
I1029 22:39:03.250905 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_7000.solverstate
I1029 22:39:03.362588 27430 solver.cpp:334] Iteration 7000, Testing net (#0)
I1029 22:39:34.699658 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57536
I1029 22:39:34.699739 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80148
I1029 22:39:34.699750 27430 solver.cpp:401]     Test net output #2: loss = 1.89141 (* 1 = 1.89141 loss)
I1029 22:39:35.460952 27430 solver.cpp:222] Iteration 7000 (0.642264 iter/s, 62.2797s/40 iters), loss = 1.45622
I1029 22:39:35.461006 27430 solver.cpp:241]     Train net output #0: loss = 1.45622 (* 1 = 1.45622 loss)
I1029 22:39:35.461019 27430 sgd_solver.cpp:105] Iteration 7000, lr = 0.00419833
I1029 22:40:04.742735 27430 solver.cpp:222] Iteration 7040 (1.36607 iter/s, 29.281s/40 iters), loss = 1.70426
I1029 22:40:04.743274 27430 solver.cpp:241]     Train net output #0: loss = 1.70426 (* 1 = 1.70426 loss)
I1029 22:40:04.743325 27430 sgd_solver.cpp:105] Iteration 7040, lr = 0.00417756
I1029 22:40:34.572966 27430 solver.cpp:222] Iteration 7080 (1.34098 iter/s, 29.829s/40 iters), loss = 1.28627
I1029 22:40:34.573444 27430 solver.cpp:241]     Train net output #0: loss = 1.28627 (* 1 = 1.28627 loss)
I1029 22:40:34.573500 27430 sgd_solver.cpp:105] Iteration 7080, lr = 0.0041569
I1029 22:41:04.745544 27430 solver.cpp:222] Iteration 7120 (1.32576 iter/s, 30.1714s/40 iters), loss = 1.55892
I1029 22:41:04.745749 27430 solver.cpp:241]     Train net output #0: loss = 1.55892 (* 1 = 1.55892 loss)
I1029 22:41:04.745764 27430 sgd_solver.cpp:105] Iteration 7120, lr = 0.00413633
I1029 22:41:34.915356 27430 solver.cpp:222] Iteration 7160 (1.32587 iter/s, 30.1689s/40 iters), loss = 1.70349
I1029 22:41:34.915540 27430 solver.cpp:241]     Train net output #0: loss = 1.70349 (* 1 = 1.70349 loss)
I1029 22:41:34.915556 27430 sgd_solver.cpp:105] Iteration 7160, lr = 0.00411587
I1029 22:42:04.518493 27430 solver.cpp:222] Iteration 7200 (1.35125 iter/s, 29.6022s/40 iters), loss = 1.7053
I1029 22:42:04.518986 27430 solver.cpp:241]     Train net output #0: loss = 1.7053 (* 1 = 1.7053 loss)
I1029 22:42:04.519035 27430 sgd_solver.cpp:105] Iteration 7200, lr = 0.00409551
I1029 22:43:00.244827 27430 solver.cpp:222] Iteration 7240 (0.717816 iter/s, 55.7246s/40 iters), loss = 1.30116
I1029 22:43:00.245431 27430 solver.cpp:241]     Train net output #0: loss = 1.30116 (* 1 = 1.30116 loss)
I1029 22:43:00.245479 27430 sgd_solver.cpp:105] Iteration 7240, lr = 0.00407525
I1029 22:43:30.762346 27430 solver.cpp:222] Iteration 7280 (1.31078 iter/s, 30.5162s/40 iters), loss = 1.60595
I1029 22:43:30.762964 27430 solver.cpp:241]     Train net output #0: loss = 1.60595 (* 1 = 1.60595 loss)
I1029 22:43:30.763010 27430 sgd_solver.cpp:105] Iteration 7280, lr = 0.00405509
I1029 22:44:00.591133 27430 solver.cpp:222] Iteration 7320 (1.34104 iter/s, 29.8275s/40 iters), loss = 1.41834
I1029 22:44:00.591588 27430 solver.cpp:241]     Train net output #0: loss = 1.41834 (* 1 = 1.41834 loss)
I1029 22:44:00.591635 27430 sgd_solver.cpp:105] Iteration 7320, lr = 0.00403502
I1029 22:44:30.441990 27430 solver.cpp:222] Iteration 7360 (1.34005 iter/s, 29.8497s/40 iters), loss = 1.39988
I1029 22:44:30.442621 27430 solver.cpp:241]     Train net output #0: loss = 1.39988 (* 1 = 1.39988 loss)
I1029 22:44:30.442665 27430 sgd_solver.cpp:105] Iteration 7360, lr = 0.00401506
I1029 22:45:00.135797 27430 solver.cpp:222] Iteration 7400 (1.34714 iter/s, 29.6925s/40 iters), loss = 1.75379
I1029 22:45:00.136349 27430 solver.cpp:241]     Train net output #0: loss = 1.75379 (* 1 = 1.75379 loss)
I1029 22:45:00.136405 27430 sgd_solver.cpp:105] Iteration 7400, lr = 0.0039952
I1029 22:45:33.646082 27430 solver.cpp:222] Iteration 7440 (1.19371 iter/s, 33.509s/40 iters), loss = 1.63431
I1029 22:45:33.646750 27430 solver.cpp:241]     Train net output #0: loss = 1.63431 (* 1 = 1.63431 loss)
I1029 22:45:33.646806 27430 sgd_solver.cpp:105] Iteration 7440, lr = 0.00397543
I1029 22:46:03.255884 27430 solver.cpp:222] Iteration 7480 (1.35097 iter/s, 29.6085s/40 iters), loss = 1.57947
I1029 22:46:03.256389 27430 solver.cpp:241]     Train net output #0: loss = 1.57947 (* 1 = 1.57947 loss)
I1029 22:46:03.256440 27430 sgd_solver.cpp:105] Iteration 7480, lr = 0.00395577
I1029 22:46:17.302770 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_7500.caffemodel
I1029 22:46:17.446796 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_7500.solverstate
I1029 22:46:17.575857 27430 solver.cpp:334] Iteration 7500, Testing net (#0)
I1029 22:46:48.635169 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1029 22:46:48.847118 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57376
I1029 22:46:48.847168 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8074
I1029 22:46:48.847179 27430 solver.cpp:401]     Test net output #2: loss = 1.87407 (* 1 = 1.87407 loss)
I1029 22:46:51.188959 27479 data_layer.cpp:73] Restarting data prefetching from start.
I1029 22:47:04.433276 27430 solver.cpp:222] Iteration 7520 (0.653857 iter/s, 61.1755s/40 iters), loss = 1.44794
I1029 22:47:04.433763 27430 solver.cpp:241]     Train net output #0: loss = 1.44794 (* 1 = 1.44794 loss)
I1029 22:47:04.433811 27430 sgd_solver.cpp:105] Iteration 7520, lr = 0.0039362
I1029 22:47:34.359562 27430 solver.cpp:222] Iteration 7560 (1.33667 iter/s, 29.9251s/40 iters), loss = 1.5024
I1029 22:47:34.360162 27430 solver.cpp:241]     Train net output #0: loss = 1.5024 (* 1 = 1.5024 loss)
I1029 22:47:34.360215 27430 sgd_solver.cpp:105] Iteration 7560, lr = 0.00391673
I1029 22:48:13.010483 27430 solver.cpp:222] Iteration 7600 (1.03494 iter/s, 38.6494s/40 iters), loss = 1.5139
I1029 22:48:13.011059 27430 solver.cpp:241]     Train net output #0: loss = 1.5139 (* 1 = 1.5139 loss)
I1029 22:48:13.011108 27430 sgd_solver.cpp:105] Iteration 7600, lr = 0.00389735
I1029 22:48:42.411022 27430 solver.cpp:222] Iteration 7640 (1.36058 iter/s, 29.3993s/40 iters), loss = 1.28207
I1029 22:48:42.411429 27430 solver.cpp:241]     Train net output #0: loss = 1.28207 (* 1 = 1.28207 loss)
I1029 22:48:42.411471 27430 sgd_solver.cpp:105] Iteration 7640, lr = 0.00387807
I1029 22:49:12.022805 27430 solver.cpp:222] Iteration 7680 (1.35086 iter/s, 29.6107s/40 iters), loss = 1.41975
I1029 22:49:12.023507 27430 solver.cpp:241]     Train net output #0: loss = 1.41975 (* 1 = 1.41975 loss)
I1029 22:49:12.023563 27430 sgd_solver.cpp:105] Iteration 7680, lr = 0.00385888
I1029 22:49:41.908303 27430 solver.cpp:222] Iteration 7720 (1.3385 iter/s, 29.8841s/40 iters), loss = 1.47581
I1029 22:49:41.908615 27430 solver.cpp:241]     Train net output #0: loss = 1.47581 (* 1 = 1.47581 loss)
I1029 22:49:41.908634 27430 sgd_solver.cpp:105] Iteration 7720, lr = 0.00383979
I1029 22:50:12.514428 27430 solver.cpp:222] Iteration 7760 (1.30697 iter/s, 30.6051s/40 iters), loss = 1.18429
I1029 22:50:12.515118 27430 solver.cpp:241]     Train net output #0: loss = 1.18429 (* 1 = 1.18429 loss)
I1029 22:50:12.515166 27430 sgd_solver.cpp:105] Iteration 7760, lr = 0.0038208
I1029 22:50:48.097795 27430 solver.cpp:222] Iteration 7800 (1.12417 iter/s, 35.5819s/40 iters), loss = 1.50481
I1029 22:50:48.098482 27430 solver.cpp:241]     Train net output #0: loss = 1.50481 (* 1 = 1.50481 loss)
I1029 22:50:48.098541 27430 sgd_solver.cpp:105] Iteration 7800, lr = 0.00380189
I1029 22:51:17.757160 27430 solver.cpp:222] Iteration 7840 (1.34871 iter/s, 29.658s/40 iters), loss = 1.26011
I1029 22:51:17.757635 27430 solver.cpp:241]     Train net output #0: loss = 1.26011 (* 1 = 1.26011 loss)
I1029 22:51:17.757684 27430 sgd_solver.cpp:105] Iteration 7840, lr = 0.00378309
I1029 22:51:47.533191 27430 solver.cpp:222] Iteration 7880 (1.34341 iter/s, 29.7749s/40 iters), loss = 1.49954
I1029 22:51:47.533757 27430 solver.cpp:241]     Train net output #0: loss = 1.49954 (* 1 = 1.49954 loss)
I1029 22:51:47.533810 27430 sgd_solver.cpp:105] Iteration 7880, lr = 0.00376437
I1029 22:52:17.424876 27430 solver.cpp:222] Iteration 7920 (1.33822 iter/s, 29.8904s/40 iters), loss = 1.42825
I1029 22:52:17.425277 27430 solver.cpp:241]     Train net output #0: loss = 1.42825 (* 1 = 1.42825 loss)
I1029 22:52:17.425325 27430 sgd_solver.cpp:105] Iteration 7920, lr = 0.00374575
I1029 22:52:47.253690 27430 solver.cpp:222] Iteration 7960 (1.34103 iter/s, 29.8277s/40 iters), loss = 1.54645
I1029 22:52:47.254251 27430 solver.cpp:241]     Train net output #0: loss = 1.54645 (* 1 = 1.54645 loss)
I1029 22:52:47.254303 27430 sgd_solver.cpp:105] Iteration 7960, lr = 0.00372722
I1029 22:53:15.922384 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_8000.caffemodel
I1029 22:53:16.073909 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_8000.solverstate
I1029 22:53:16.188195 27430 solver.cpp:334] Iteration 8000, Testing net (#0)
I1029 22:53:47.448096 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5748
I1029 22:53:47.448609 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.804879
I1029 22:53:47.448644 27430 solver.cpp:401]     Test net output #2: loss = 1.88356 (* 1 = 1.88356 loss)
I1029 22:53:48.211536 27430 solver.cpp:222] Iteration 8000 (0.656212 iter/s, 60.9559s/40 iters), loss = 1.90865
I1029 22:53:48.211596 27430 solver.cpp:241]     Train net output #0: loss = 1.90865 (* 1 = 1.90865 loss)
I1029 22:53:48.211607 27430 sgd_solver.cpp:105] Iteration 8000, lr = 0.00370878
I1029 22:54:17.653941 27430 solver.cpp:222] Iteration 8040 (1.35862 iter/s, 29.4416s/40 iters), loss = 1.54765
I1029 22:54:17.654134 27430 solver.cpp:241]     Train net output #0: loss = 1.54765 (* 1 = 1.54765 loss)
I1029 22:54:17.654148 27430 sgd_solver.cpp:105] Iteration 8040, lr = 0.00369043
I1029 22:54:47.114470 27430 solver.cpp:222] Iteration 8080 (1.35779 iter/s, 29.4596s/40 iters), loss = 1.54099
I1029 22:54:47.114946 27430 solver.cpp:241]     Train net output #0: loss = 1.54099 (* 1 = 1.54099 loss)
I1029 22:54:47.114998 27430 sgd_solver.cpp:105] Iteration 8080, lr = 0.00367217
I1029 22:55:16.656160 27430 solver.cpp:222] Iteration 8120 (1.35407 iter/s, 29.5406s/40 iters), loss = 1.37324
I1029 22:55:16.656793 27430 solver.cpp:241]     Train net output #0: loss = 1.37324 (* 1 = 1.37324 loss)
I1029 22:55:16.656846 27430 sgd_solver.cpp:105] Iteration 8120, lr = 0.00365401
I1029 22:55:56.688787 27430 solver.cpp:222] Iteration 8160 (0.999224 iter/s, 40.0311s/40 iters), loss = 1.46766
I1029 22:55:56.689697 27430 solver.cpp:241]     Train net output #0: loss = 1.46766 (* 1 = 1.46766 loss)
I1029 22:55:56.689746 27430 sgd_solver.cpp:105] Iteration 8160, lr = 0.00363593
I1029 22:56:35.907667 27430 solver.cpp:222] Iteration 8200 (1.01996 iter/s, 39.2171s/40 iters), loss = 1.55647
I1029 22:56:35.908251 27430 solver.cpp:241]     Train net output #0: loss = 1.55647 (* 1 = 1.55647 loss)
I1029 22:56:35.908289 27430 sgd_solver.cpp:105] Iteration 8200, lr = 0.00361794
I1029 22:57:07.754122 27430 solver.cpp:222] Iteration 8240 (1.25608 iter/s, 31.8452s/40 iters), loss = 1.35571
I1029 22:57:07.754653 27430 solver.cpp:241]     Train net output #0: loss = 1.35571 (* 1 = 1.35571 loss)
I1029 22:57:07.754701 27430 sgd_solver.cpp:105] Iteration 8240, lr = 0.00360004
I1029 22:57:37.198719 27430 solver.cpp:222] Iteration 8280 (1.35854 iter/s, 29.4434s/40 iters), loss = 1.49332
I1029 22:57:37.199208 27430 solver.cpp:241]     Train net output #0: loss = 1.49332 (* 1 = 1.49332 loss)
I1029 22:57:37.199265 27430 sgd_solver.cpp:105] Iteration 8280, lr = 0.00358223
I1029 22:58:06.954946 27430 solver.cpp:222] Iteration 8320 (1.34431 iter/s, 29.7551s/40 iters), loss = 1.50012
I1029 22:58:06.955564 27430 solver.cpp:241]     Train net output #0: loss = 1.50012 (* 1 = 1.50012 loss)
I1029 22:58:06.955621 27430 sgd_solver.cpp:105] Iteration 8320, lr = 0.00356451
I1029 22:58:37.148972 27430 solver.cpp:222] Iteration 8360 (1.32482 iter/s, 30.1927s/40 iters), loss = 1.51711
I1029 22:58:37.149518 27430 solver.cpp:241]     Train net output #0: loss = 1.51711 (* 1 = 1.51711 loss)
I1029 22:58:37.149571 27430 sgd_solver.cpp:105] Iteration 8360, lr = 0.00354688
I1029 22:59:07.473739 27430 solver.cpp:222] Iteration 8400 (1.31911 iter/s, 30.3235s/40 iters), loss = 1.62782
I1029 22:59:07.473901 27430 solver.cpp:241]     Train net output #0: loss = 1.62782 (* 1 = 1.62782 loss)
I1029 22:59:07.473913 27430 sgd_solver.cpp:105] Iteration 8400, lr = 0.00352933
I1029 22:59:43.034432 27430 solver.cpp:222] Iteration 8440 (1.12487 iter/s, 35.5597s/40 iters), loss = 1.63001
I1029 22:59:43.035043 27430 solver.cpp:241]     Train net output #0: loss = 1.63001 (* 1 = 1.63001 loss)
I1029 22:59:43.035100 27430 sgd_solver.cpp:105] Iteration 8440, lr = 0.00351187
I1029 23:00:14.054302 27430 solver.cpp:222] Iteration 8480 (1.28955 iter/s, 31.0186s/40 iters), loss = 1.36788
I1029 23:00:14.054916 27430 solver.cpp:241]     Train net output #0: loss = 1.36788 (* 1 = 1.36788 loss)
I1029 23:00:14.054988 27430 sgd_solver.cpp:105] Iteration 8480, lr = 0.0034945
I1029 23:00:28.243618 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_8500.caffemodel
I1029 23:00:28.418951 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_8500.solverstate
I1029 23:00:28.548904 27430 solver.cpp:334] Iteration 8500, Testing net (#0)
I1029 23:00:59.557648 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1029 23:00:59.765197 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57532
I1029 23:00:59.765247 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.806599
I1029 23:00:59.765259 27430 solver.cpp:401]     Test net output #2: loss = 1.89845 (* 1 = 1.89845 loss)
I1029 23:01:15.299721 27430 solver.cpp:222] Iteration 8520 (0.653132 iter/s, 61.2434s/40 iters), loss = 1.20805
I1029 23:01:15.300158 27430 solver.cpp:241]     Train net output #0: loss = 1.20805 (* 1 = 1.20805 loss)
I1029 23:01:15.300218 27430 sgd_solver.cpp:105] Iteration 8520, lr = 0.00347721
I1029 23:01:45.642514 27430 solver.cpp:222] Iteration 8560 (1.31832 iter/s, 30.3417s/40 iters), loss = 1.13724
I1029 23:01:45.642982 27430 solver.cpp:241]     Train net output #0: loss = 1.13724 (* 1 = 1.13724 loss)
I1029 23:01:45.643005 27430 sgd_solver.cpp:105] Iteration 8560, lr = 0.00346001
I1029 23:02:15.990938 27430 solver.cpp:222] Iteration 8600 (1.31808 iter/s, 30.3472s/40 iters), loss = 1.35757
I1029 23:02:15.991513 27430 solver.cpp:241]     Train net output #0: loss = 1.35757 (* 1 = 1.35757 loss)
I1029 23:02:15.991575 27430 sgd_solver.cpp:105] Iteration 8600, lr = 0.00344289
I1029 23:02:46.305929 27430 solver.cpp:222] Iteration 8640 (1.31953 iter/s, 30.3137s/40 iters), loss = 1.40778
I1029 23:02:46.306110 27430 solver.cpp:241]     Train net output #0: loss = 1.40778 (* 1 = 1.40778 loss)
I1029 23:02:46.306125 27430 sgd_solver.cpp:105] Iteration 8640, lr = 0.00342586
I1029 23:03:17.226380 27430 solver.cpp:222] Iteration 8680 (1.29368 iter/s, 30.9195s/40 iters), loss = 1.42846
I1029 23:03:17.226562 27430 solver.cpp:241]     Train net output #0: loss = 1.42846 (* 1 = 1.42846 loss)
I1029 23:03:17.226580 27430 sgd_solver.cpp:105] Iteration 8680, lr = 0.00340891
I1029 23:03:49.182413 27430 solver.cpp:222] Iteration 8720 (1.25176 iter/s, 31.9551s/40 iters), loss = 1.47417
I1029 23:03:49.183037 27430 solver.cpp:241]     Train net output #0: loss = 1.47417 (* 1 = 1.47417 loss)
I1029 23:03:49.183082 27430 sgd_solver.cpp:105] Iteration 8720, lr = 0.00339204
I1029 23:04:19.328472 27430 solver.cpp:222] Iteration 8760 (1.32693 iter/s, 30.1447s/40 iters), loss = 1.37666
I1029 23:04:19.329176 27430 solver.cpp:241]     Train net output #0: loss = 1.37666 (* 1 = 1.37666 loss)
I1029 23:04:19.329215 27430 sgd_solver.cpp:105] Iteration 8760, lr = 0.00337526
I1029 23:04:49.475466 27430 solver.cpp:222] Iteration 8800 (1.32689 iter/s, 30.1456s/40 iters), loss = 1.19039
I1029 23:04:49.475638 27430 solver.cpp:241]     Train net output #0: loss = 1.19039 (* 1 = 1.19039 loss)
I1029 23:04:49.475652 27430 sgd_solver.cpp:105] Iteration 8800, lr = 0.00335857
I1029 23:05:19.827632 27430 solver.cpp:222] Iteration 8840 (1.3179 iter/s, 30.3513s/40 iters), loss = 1.82303
I1029 23:05:19.827808 27430 solver.cpp:241]     Train net output #0: loss = 1.82303 (* 1 = 1.82303 loss)
I1029 23:05:19.827823 27430 sgd_solver.cpp:105] Iteration 8840, lr = 0.00334195
I1029 23:05:49.149036 27430 solver.cpp:222] Iteration 8880 (1.36423 iter/s, 29.3205s/40 iters), loss = 1.4075
I1029 23:05:49.149503 27430 solver.cpp:241]     Train net output #0: loss = 1.4075 (* 1 = 1.4075 loss)
I1029 23:05:49.149547 27430 sgd_solver.cpp:105] Iteration 8880, lr = 0.00332542
I1029 23:06:19.193591 27430 solver.cpp:222] Iteration 8920 (1.33141 iter/s, 30.0434s/40 iters), loss = 1.34621
I1029 23:06:19.194197 27430 solver.cpp:241]     Train net output #0: loss = 1.34621 (* 1 = 1.34621 loss)
I1029 23:06:19.194247 27430 sgd_solver.cpp:105] Iteration 8920, lr = 0.00330897
I1029 23:06:48.847815 27430 solver.cpp:222] Iteration 8960 (1.34894 iter/s, 29.653s/40 iters), loss = 1.44153
I1029 23:06:48.848242 27430 solver.cpp:241]     Train net output #0: loss = 1.44153 (* 1 = 1.44153 loss)
I1029 23:06:48.848280 27430 sgd_solver.cpp:105] Iteration 8960, lr = 0.0032926
I1029 23:07:18.762558 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_9000.caffemodel
I1029 23:07:18.933468 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_9000.solverstate
I1029 23:07:19.046303 27430 solver.cpp:334] Iteration 9000, Testing net (#0)
I1029 23:07:50.307404 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58016
I1029 23:07:50.307489 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8038
I1029 23:07:50.307502 27430 solver.cpp:401]     Test net output #2: loss = 1.86789 (* 1 = 1.86789 loss)
I1029 23:07:51.074158 27430 solver.cpp:222] Iteration 9000 (0.642834 iter/s, 62.2245s/40 iters), loss = 1.253
I1029 23:07:51.074204 27430 solver.cpp:241]     Train net output #0: loss = 1.253 (* 1 = 1.253 loss)
I1029 23:07:51.074218 27430 sgd_solver.cpp:105] Iteration 9000, lr = 0.00327631
I1029 23:08:20.474701 27430 solver.cpp:222] Iteration 9040 (1.36055 iter/s, 29.3998s/40 iters), loss = 1.7892
I1029 23:08:20.475270 27430 solver.cpp:241]     Train net output #0: loss = 1.7892 (* 1 = 1.7892 loss)
I1029 23:08:20.475327 27430 sgd_solver.cpp:105] Iteration 9040, lr = 0.0032601
I1029 23:08:50.183176 27430 solver.cpp:222] Iteration 9080 (1.34647 iter/s, 29.7072s/40 iters), loss = 1.41869
I1029 23:08:50.183629 27430 solver.cpp:241]     Train net output #0: loss = 1.41869 (* 1 = 1.41869 loss)
I1029 23:08:50.183681 27430 sgd_solver.cpp:105] Iteration 9080, lr = 0.00324397
I1029 23:09:19.635692 27430 solver.cpp:222] Iteration 9120 (1.35817 iter/s, 29.4514s/40 iters), loss = 1.29293
I1029 23:09:19.636274 27430 solver.cpp:241]     Train net output #0: loss = 1.29293 (* 1 = 1.29293 loss)
I1029 23:09:19.636325 27430 sgd_solver.cpp:105] Iteration 9120, lr = 0.00322792
I1029 23:09:49.209794 27430 solver.cpp:222] Iteration 9160 (1.35259 iter/s, 29.5728s/40 iters), loss = 1.7282
I1029 23:09:49.210278 27430 solver.cpp:241]     Train net output #0: loss = 1.7282 (* 1 = 1.7282 loss)
I1029 23:09:49.210330 27430 sgd_solver.cpp:105] Iteration 9160, lr = 0.00321195
I1029 23:10:50.723779 27430 solver.cpp:222] Iteration 9200 (0.650279 iter/s, 61.5121s/40 iters), loss = 1.77962
I1029 23:10:50.724315 27430 solver.cpp:241]     Train net output #0: loss = 1.77962 (* 1 = 1.77962 loss)
I1029 23:10:50.724359 27430 sgd_solver.cpp:105] Iteration 9200, lr = 0.00319606
I1029 23:11:20.388938 27430 solver.cpp:222] Iteration 9240 (1.34844 iter/s, 29.6639s/40 iters), loss = 1.46135
I1029 23:11:20.389470 27430 solver.cpp:241]     Train net output #0: loss = 1.46135 (* 1 = 1.46135 loss)
I1029 23:11:20.389524 27430 sgd_solver.cpp:105] Iteration 9240, lr = 0.00318025
I1029 23:11:49.997207 27430 solver.cpp:222] Iteration 9280 (1.35103 iter/s, 29.6071s/40 iters), loss = 1.52139
I1029 23:11:49.997865 27430 solver.cpp:241]     Train net output #0: loss = 1.52139 (* 1 = 1.52139 loss)
I1029 23:11:49.997911 27430 sgd_solver.cpp:105] Iteration 9280, lr = 0.00316452
I1029 23:12:19.462628 27430 solver.cpp:222] Iteration 9320 (1.35758 iter/s, 29.4641s/40 iters), loss = 1.41431
I1029 23:12:19.463141 27430 solver.cpp:241]     Train net output #0: loss = 1.41431 (* 1 = 1.41431 loss)
I1029 23:12:19.463196 27430 sgd_solver.cpp:105] Iteration 9320, lr = 0.00314886
I1029 23:12:48.781967 27430 solver.cpp:222] Iteration 9360 (1.36434 iter/s, 29.3182s/40 iters), loss = 1.47014
I1029 23:12:48.782605 27430 solver.cpp:241]     Train net output #0: loss = 1.47014 (* 1 = 1.47014 loss)
I1029 23:12:48.782654 27430 sgd_solver.cpp:105] Iteration 9360, lr = 0.00313329
I1029 23:13:18.008713 27430 solver.cpp:222] Iteration 9400 (1.36867 iter/s, 29.2255s/40 iters), loss = 1.6297
I1029 23:13:18.009167 27430 solver.cpp:241]     Train net output #0: loss = 1.6297 (* 1 = 1.6297 loss)
I1029 23:13:18.009214 27430 sgd_solver.cpp:105] Iteration 9400, lr = 0.00311779
I1029 23:13:47.769655 27430 solver.cpp:222] Iteration 9440 (1.34409 iter/s, 29.7598s/40 iters), loss = 1.44776
I1029 23:13:47.770284 27430 solver.cpp:241]     Train net output #0: loss = 1.44776 (* 1 = 1.44776 loss)
I1029 23:13:47.770321 27430 sgd_solver.cpp:105] Iteration 9440, lr = 0.00310236
I1029 23:14:20.824538 27430 solver.cpp:222] Iteration 9480 (1.21016 iter/s, 33.0535s/40 iters), loss = 1.44602
I1029 23:14:20.825021 27430 solver.cpp:241]     Train net output #0: loss = 1.44602 (* 1 = 1.44602 loss)
I1029 23:14:20.825062 27430 sgd_solver.cpp:105] Iteration 9480, lr = 0.00308701
I1029 23:14:35.776859 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_9500.caffemodel
I1029 23:14:35.924268 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_9500.solverstate
I1029 23:14:36.038651 27430 solver.cpp:334] Iteration 9500, Testing net (#0)
I1029 23:15:07.117259 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1029 23:15:07.329459 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57928
I1029 23:15:07.329509 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.809159
I1029 23:15:07.329520 27430 solver.cpp:401]     Test net output #2: loss = 1.88549 (* 1 = 1.88549 loss)
I1029 23:15:23.355782 27430 solver.cpp:222] Iteration 9520 (0.6397 iter/s, 62.5293s/40 iters), loss = 1.57123
I1029 23:15:23.356210 27430 solver.cpp:241]     Train net output #0: loss = 1.57123 (* 1 = 1.57123 loss)
I1029 23:15:23.356263 27430 sgd_solver.cpp:105] Iteration 9520, lr = 0.00307174
I1029 23:15:53.937767 27430 solver.cpp:222] Iteration 9560 (1.30801 iter/s, 30.5809s/40 iters), loss = 1.78253
I1029 23:15:53.938374 27430 solver.cpp:241]     Train net output #0: loss = 1.78253 (* 1 = 1.78253 loss)
I1029 23:15:53.938421 27430 sgd_solver.cpp:105] Iteration 9560, lr = 0.00305654
I1029 23:16:24.409659 27430 solver.cpp:222] Iteration 9600 (1.31274 iter/s, 30.4706s/40 iters), loss = 1.47163
I1029 23:16:24.409859 27430 solver.cpp:241]     Train net output #0: loss = 1.47163 (* 1 = 1.47163 loss)
I1029 23:16:24.409873 27430 sgd_solver.cpp:105] Iteration 9600, lr = 0.00304142
I1029 23:17:06.854728 27430 solver.cpp:222] Iteration 9640 (0.942421 iter/s, 42.4439s/40 iters), loss = 1.48186
I1029 23:17:06.855319 27430 solver.cpp:241]     Train net output #0: loss = 1.48186 (* 1 = 1.48186 loss)
I1029 23:17:06.855381 27430 sgd_solver.cpp:105] Iteration 9640, lr = 0.00302638
I1029 23:17:36.430822 27430 solver.cpp:222] Iteration 9680 (1.3525 iter/s, 29.5748s/40 iters), loss = 1.25061
I1029 23:17:36.431269 27430 solver.cpp:241]     Train net output #0: loss = 1.25061 (* 1 = 1.25061 loss)
I1029 23:17:36.431320 27430 sgd_solver.cpp:105] Iteration 9680, lr = 0.00301141
I1029 23:18:06.687988 27430 solver.cpp:222] Iteration 9720 (1.32205 iter/s, 30.256s/40 iters), loss = 1.55765
I1029 23:18:06.688629 27430 solver.cpp:241]     Train net output #0: loss = 1.55765 (* 1 = 1.55765 loss)
I1029 23:18:06.688668 27430 sgd_solver.cpp:105] Iteration 9720, lr = 0.00299651
I1029 23:18:36.222443 27430 solver.cpp:222] Iteration 9760 (1.35441 iter/s, 29.5332s/40 iters), loss = 1.70758
I1029 23:18:36.222872 27430 solver.cpp:241]     Train net output #0: loss = 1.70758 (* 1 = 1.70758 loss)
I1029 23:18:36.222944 27430 sgd_solver.cpp:105] Iteration 9760, lr = 0.00298168
I1029 23:19:05.825098 27430 solver.cpp:222] Iteration 9800 (1.35128 iter/s, 29.6016s/40 iters), loss = 1.62594
I1029 23:19:05.825669 27430 solver.cpp:241]     Train net output #0: loss = 1.62594 (* 1 = 1.62594 loss)
I1029 23:19:05.825716 27430 sgd_solver.cpp:105] Iteration 9800, lr = 0.00296693
I1029 23:19:35.408928 27430 solver.cpp:222] Iteration 9840 (1.35215 iter/s, 29.5826s/40 iters), loss = 1.42049
I1029 23:19:35.409368 27430 solver.cpp:241]     Train net output #0: loss = 1.42049 (* 1 = 1.42049 loss)
I1029 23:19:35.409409 27430 sgd_solver.cpp:105] Iteration 9840, lr = 0.00295225
I1029 23:20:05.115288 27430 solver.cpp:222] Iteration 9880 (1.34656 iter/s, 29.7052s/40 iters), loss = 1.54445
I1029 23:20:05.115862 27430 solver.cpp:241]     Train net output #0: loss = 1.54445 (* 1 = 1.54445 loss)
I1029 23:20:05.115911 27430 sgd_solver.cpp:105] Iteration 9880, lr = 0.00293765
I1029 23:20:34.596057 27430 solver.cpp:222] Iteration 9920 (1.35687 iter/s, 29.4795s/40 iters), loss = 1.0105
I1029 23:20:34.596506 27430 solver.cpp:241]     Train net output #0: loss = 1.0105 (* 1 = 1.0105 loss)
I1029 23:20:34.596546 27430 sgd_solver.cpp:105] Iteration 9920, lr = 0.00292312
I1029 23:21:04.811152 27430 solver.cpp:222] Iteration 9960 (1.32389 iter/s, 30.214s/40 iters), loss = 1.37101
I1029 23:21:04.811728 27430 solver.cpp:241]     Train net output #0: loss = 1.37101 (* 1 = 1.37101 loss)
I1029 23:21:04.811769 27430 sgd_solver.cpp:105] Iteration 9960, lr = 0.00290866
I1029 23:21:33.594454 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_10000.caffemodel
I1029 23:21:33.740227 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_10000.solverstate
I1029 23:21:33.856813 27430 solver.cpp:334] Iteration 10000, Testing net (#0)
I1029 23:22:05.111455 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58076
I1029 23:22:05.112013 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8038
I1029 23:22:05.112077 27430 solver.cpp:401]     Test net output #2: loss = 1.86125 (* 1 = 1.86125 loss)
I1029 23:22:05.877884 27430 solver.cpp:222] Iteration 10000 (0.655042 iter/s, 61.0648s/40 iters), loss = 1.41457
I1029 23:22:05.877945 27430 solver.cpp:241]     Train net output #0: loss = 1.41457 (* 1 = 1.41457 loss)
I1029 23:22:05.877959 27430 sgd_solver.cpp:105] Iteration 10000, lr = 0.00289427
I1029 23:22:09.684167 27479 data_layer.cpp:73] Restarting data prefetching from start.
I1029 23:24:56.356178 27430 solver.cpp:222] Iteration 10040 (0.234639 iter/s, 170.474s/40 iters), loss = 1.36258
I1029 23:24:56.356807 27430 solver.cpp:241]     Train net output #0: loss = 1.36258 (* 1 = 1.36258 loss)
I1029 23:24:56.356861 27430 sgd_solver.cpp:105] Iteration 10040, lr = 0.00287995
I1029 23:25:26.386811 27430 solver.cpp:222] Iteration 10080 (1.33203 iter/s, 30.0293s/40 iters), loss = 1.59817
I1029 23:25:26.387363 27430 solver.cpp:241]     Train net output #0: loss = 1.59817 (* 1 = 1.59817 loss)
I1029 23:25:26.387408 27430 sgd_solver.cpp:105] Iteration 10080, lr = 0.0028657
I1029 23:25:56.401638 27430 solver.cpp:222] Iteration 10120 (1.33273 iter/s, 30.0136s/40 iters), loss = 1.47384
I1029 23:25:56.402307 27430 solver.cpp:241]     Train net output #0: loss = 1.47384 (* 1 = 1.47384 loss)
I1029 23:25:56.402372 27430 sgd_solver.cpp:105] Iteration 10120, lr = 0.00285152
I1029 23:26:26.996364 27430 solver.cpp:222] Iteration 10160 (1.30747 iter/s, 30.5934s/40 iters), loss = 1.41414
I1029 23:26:26.996556 27430 solver.cpp:241]     Train net output #0: loss = 1.41414 (* 1 = 1.41414 loss)
I1029 23:26:26.996569 27430 sgd_solver.cpp:105] Iteration 10160, lr = 0.00283742
I1029 23:26:57.741699 27430 solver.cpp:222] Iteration 10200 (1.30105 iter/s, 30.7444s/40 iters), loss = 1.4825
I1029 23:26:57.742321 27430 solver.cpp:241]     Train net output #0: loss = 1.4825 (* 1 = 1.4825 loss)
I1029 23:26:57.747565 27430 sgd_solver.cpp:105] Iteration 10200, lr = 0.00282338
I1029 23:27:28.658421 27430 solver.cpp:222] Iteration 10240 (1.29385 iter/s, 30.9154s/40 iters), loss = 1.54381
I1029 23:27:28.658602 27430 solver.cpp:241]     Train net output #0: loss = 1.54381 (* 1 = 1.54381 loss)
I1029 23:27:28.658617 27430 sgd_solver.cpp:105] Iteration 10240, lr = 0.00280941
I1029 23:27:59.260624 27430 solver.cpp:222] Iteration 10280 (1.30713 iter/s, 30.6013s/40 iters), loss = 1.41801
I1029 23:27:59.260803 27430 solver.cpp:241]     Train net output #0: loss = 1.41801 (* 1 = 1.41801 loss)
I1029 23:27:59.260819 27430 sgd_solver.cpp:105] Iteration 10280, lr = 0.00279551
I1029 23:28:29.275188 27430 solver.cpp:222] Iteration 10320 (1.33273 iter/s, 30.0137s/40 iters), loss = 1.29894
I1029 23:28:29.275755 27430 solver.cpp:241]     Train net output #0: loss = 1.29894 (* 1 = 1.29894 loss)
I1029 23:28:29.275799 27430 sgd_solver.cpp:105] Iteration 10320, lr = 0.00278168
I1029 23:29:00.844225 27430 solver.cpp:222] Iteration 10360 (1.26712 iter/s, 31.5677s/40 iters), loss = 1.60039
I1029 23:29:00.844735 27430 solver.cpp:241]     Train net output #0: loss = 1.60039 (* 1 = 1.60039 loss)
I1029 23:29:00.844770 27430 sgd_solver.cpp:105] Iteration 10360, lr = 0.00276792
I1029 23:29:30.611840 27430 solver.cpp:222] Iteration 10400 (1.3438 iter/s, 29.7664s/40 iters), loss = 1.51611
I1029 23:29:30.612272 27430 solver.cpp:241]     Train net output #0: loss = 1.51611 (* 1 = 1.51611 loss)
I1029 23:29:30.612316 27430 sgd_solver.cpp:105] Iteration 10400, lr = 0.00275423
I1029 23:30:00.241891 27430 solver.cpp:222] Iteration 10440 (1.35003 iter/s, 29.6289s/40 iters), loss = 1.46212
I1029 23:30:00.242457 27430 solver.cpp:241]     Train net output #0: loss = 1.46212 (* 1 = 1.46212 loss)
I1029 23:30:00.242509 27430 sgd_solver.cpp:105] Iteration 10440, lr = 0.0027406
I1029 23:30:30.418311 27430 solver.cpp:222] Iteration 10480 (1.32559 iter/s, 30.1752s/40 iters), loss = 1.54713
I1029 23:30:30.418536 27430 solver.cpp:241]     Train net output #0: loss = 1.54713 (* 1 = 1.54713 loss)
I1029 23:30:30.418555 27430 sgd_solver.cpp:105] Iteration 10480, lr = 0.00272704
I1029 23:30:46.093613 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_10500.caffemodel
I1029 23:30:46.236541 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_10500.solverstate
I1029 23:30:46.354476 27430 solver.cpp:334] Iteration 10500, Testing net (#0)
I1029 23:31:17.557916 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1029 23:31:17.753556 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.579
I1029 23:31:17.753602 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8084
I1029 23:31:17.753613 27430 solver.cpp:401]     Test net output #2: loss = 1.87246 (* 1 = 1.87246 loss)
I1029 23:31:33.448163 27430 solver.cpp:222] Iteration 10520 (0.634637 iter/s, 63.0281s/40 iters), loss = 1.273
I1029 23:31:33.448221 27430 solver.cpp:241]     Train net output #0: loss = 1.273 (* 1 = 1.273 loss)
I1029 23:31:33.448235 27430 sgd_solver.cpp:105] Iteration 10520, lr = 0.00271355
I1029 23:32:02.809482 27430 solver.cpp:222] Iteration 10560 (1.36237 iter/s, 29.3605s/40 iters), loss = 1.21269
I1029 23:32:02.810282 27430 solver.cpp:241]     Train net output #0: loss = 1.21269 (* 1 = 1.21269 loss)
I1029 23:32:02.810353 27430 sgd_solver.cpp:105] Iteration 10560, lr = 0.00270013
I1029 23:32:33.261950 27430 solver.cpp:222] Iteration 10600 (1.31359 iter/s, 30.451s/40 iters), loss = 1.27487
I1029 23:32:33.262430 27430 solver.cpp:241]     Train net output #0: loss = 1.27487 (* 1 = 1.27487 loss)
I1029 23:32:33.262471 27430 sgd_solver.cpp:105] Iteration 10600, lr = 0.00268677
I1029 23:33:03.467017 27430 solver.cpp:222] Iteration 10640 (1.32433 iter/s, 30.2039s/40 iters), loss = 1.62869
I1029 23:33:03.467651 27430 solver.cpp:241]     Train net output #0: loss = 1.62869 (* 1 = 1.62869 loss)
I1029 23:33:03.467702 27430 sgd_solver.cpp:105] Iteration 10640, lr = 0.00267348
I1029 23:33:33.079246 27430 solver.cpp:222] Iteration 10680 (1.35085 iter/s, 29.6109s/40 iters), loss = 1.38823
I1029 23:33:33.079704 27430 solver.cpp:241]     Train net output #0: loss = 1.38823 (* 1 = 1.38823 loss)
I1029 23:33:33.079754 27430 sgd_solver.cpp:105] Iteration 10680, lr = 0.00266025
I1029 23:34:02.745105 27430 solver.cpp:222] Iteration 10720 (1.3484 iter/s, 29.6647s/40 iters), loss = 1.38013
I1029 23:34:02.745720 27430 solver.cpp:241]     Train net output #0: loss = 1.38013 (* 1 = 1.38013 loss)
I1029 23:34:02.745765 27430 sgd_solver.cpp:105] Iteration 10720, lr = 0.00264709
I1029 23:34:32.732189 27430 solver.cpp:222] Iteration 10760 (1.33396 iter/s, 29.9858s/40 iters), loss = 1.68994
I1029 23:34:32.732630 27430 solver.cpp:241]     Train net output #0: loss = 1.68994 (* 1 = 1.68994 loss)
I1029 23:34:32.732676 27430 sgd_solver.cpp:105] Iteration 10760, lr = 0.002634
I1029 23:35:02.581981 27430 solver.cpp:222] Iteration 10800 (1.34009 iter/s, 29.8487s/40 iters), loss = 1.20824
I1029 23:35:02.582553 27430 solver.cpp:241]     Train net output #0: loss = 1.20824 (* 1 = 1.20824 loss)
I1029 23:35:02.582604 27430 sgd_solver.cpp:105] Iteration 10800, lr = 0.00262097
I1029 23:35:32.077060 27430 solver.cpp:222] Iteration 10840 (1.35622 iter/s, 29.4938s/40 iters), loss = 1.38717
I1029 23:35:32.077517 27430 solver.cpp:241]     Train net output #0: loss = 1.38717 (* 1 = 1.38717 loss)
I1029 23:35:32.077566 27430 sgd_solver.cpp:105] Iteration 10840, lr = 0.002608
I1029 23:36:01.597280 27430 solver.cpp:222] Iteration 10880 (1.35506 iter/s, 29.5191s/40 iters), loss = 1.28137
I1029 23:36:01.597805 27430 solver.cpp:241]     Train net output #0: loss = 1.28137 (* 1 = 1.28137 loss)
I1029 23:36:01.597852 27430 sgd_solver.cpp:105] Iteration 10880, lr = 0.0025951
I1029 23:36:31.089043 27430 solver.cpp:222] Iteration 10920 (1.35637 iter/s, 29.4906s/40 iters), loss = 1.44455
I1029 23:36:31.089464 27430 solver.cpp:241]     Train net output #0: loss = 1.44455 (* 1 = 1.44455 loss)
I1029 23:36:31.089510 27430 sgd_solver.cpp:105] Iteration 10920, lr = 0.00258226
I1029 23:37:00.513819 27430 solver.cpp:222] Iteration 10960 (1.35945 iter/s, 29.4237s/40 iters), loss = 1.26751
I1029 23:37:00.514408 27430 solver.cpp:241]     Train net output #0: loss = 1.26751 (* 1 = 1.26751 loss)
I1029 23:37:00.514459 27430 sgd_solver.cpp:105] Iteration 10960, lr = 0.00256949
I1029 23:37:29.340509 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_11000.caffemodel
I1029 23:37:29.474539 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_11000.solverstate
I1029 23:37:29.605648 27430 solver.cpp:334] Iteration 11000, Testing net (#0)
I1029 23:38:01.050581 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58188
I1029 23:38:01.050767 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.805239
I1029 23:38:01.050781 27430 solver.cpp:401]     Test net output #2: loss = 1.86842 (* 1 = 1.86842 loss)
I1029 23:38:01.804512 27430 solver.cpp:222] Iteration 11000 (0.652649 iter/s, 61.2887s/40 iters), loss = 1.41092
I1029 23:38:01.804561 27430 solver.cpp:241]     Train net output #0: loss = 1.41092 (* 1 = 1.41092 loss)
I1029 23:38:01.804574 27430 sgd_solver.cpp:105] Iteration 11000, lr = 0.00255677
I1029 23:38:31.395896 27430 solver.cpp:222] Iteration 11040 (1.35178 iter/s, 29.5906s/40 iters), loss = 1.1722
I1029 23:38:31.396476 27430 solver.cpp:241]     Train net output #0: loss = 1.1722 (* 1 = 1.1722 loss)
I1029 23:38:31.396519 27430 sgd_solver.cpp:105] Iteration 11040, lr = 0.00254413
I1029 23:39:01.463451 27430 solver.cpp:222] Iteration 11080 (1.33039 iter/s, 30.0663s/40 iters), loss = 1.35094
I1029 23:39:01.463971 27430 solver.cpp:241]     Train net output #0: loss = 1.35094 (* 1 = 1.35094 loss)
I1029 23:39:01.464016 27430 sgd_solver.cpp:105] Iteration 11080, lr = 0.00253154
I1029 23:39:31.680649 27430 solver.cpp:222] Iteration 11120 (1.3238 iter/s, 30.216s/40 iters), loss = 1.67838
I1029 23:39:31.681053 27430 solver.cpp:241]     Train net output #0: loss = 1.67838 (* 1 = 1.67838 loss)
I1029 23:39:31.681069 27430 sgd_solver.cpp:105] Iteration 11120, lr = 0.00251902
I1029 23:40:01.110851 27430 solver.cpp:222] Iteration 11160 (1.3592 iter/s, 29.4291s/40 iters), loss = 1.35298
I1029 23:40:01.111335 27430 solver.cpp:241]     Train net output #0: loss = 1.35298 (* 1 = 1.35298 loss)
I1029 23:40:01.111400 27430 sgd_solver.cpp:105] Iteration 11160, lr = 0.00250655
I1029 23:40:30.740556 27430 solver.cpp:222] Iteration 11200 (1.35005 iter/s, 29.6285s/40 iters), loss = 1.58783
I1029 23:40:30.741209 27430 solver.cpp:241]     Train net output #0: loss = 1.58783 (* 1 = 1.58783 loss)
I1029 23:40:30.741256 27430 sgd_solver.cpp:105] Iteration 11200, lr = 0.00249415
I1029 23:41:00.610360 27430 solver.cpp:222] Iteration 11240 (1.3392 iter/s, 29.8685s/40 iters), loss = 1.33363
I1029 23:41:00.610772 27430 solver.cpp:241]     Train net output #0: loss = 1.33363 (* 1 = 1.33363 loss)
I1029 23:41:00.610831 27430 sgd_solver.cpp:105] Iteration 11240, lr = 0.00248181
I1029 23:41:30.084332 27430 solver.cpp:222] Iteration 11280 (1.35718 iter/s, 29.4729s/40 iters), loss = 1.49786
I1029 23:41:30.084826 27430 solver.cpp:241]     Train net output #0: loss = 1.49786 (* 1 = 1.49786 loss)
I1029 23:41:30.084861 27430 sgd_solver.cpp:105] Iteration 11280, lr = 0.00246954
I1029 23:42:00.099442 27430 solver.cpp:222] Iteration 11320 (1.33271 iter/s, 30.0139s/40 iters), loss = 1.543
I1029 23:42:00.100016 27430 solver.cpp:241]     Train net output #0: loss = 1.543 (* 1 = 1.543 loss)
I1029 23:42:00.100060 27430 sgd_solver.cpp:105] Iteration 11320, lr = 0.00245732
I1029 23:42:30.538682 27430 solver.cpp:222] Iteration 11360 (1.31415 iter/s, 30.438s/40 iters), loss = 1.52071
I1029 23:42:30.539140 27430 solver.cpp:241]     Train net output #0: loss = 1.52071 (* 1 = 1.52071 loss)
I1029 23:42:30.539156 27430 sgd_solver.cpp:105] Iteration 11360, lr = 0.00244516
I1029 23:43:00.146494 27430 solver.cpp:222] Iteration 11400 (1.35105 iter/s, 29.6067s/40 iters), loss = 1.28416
I1029 23:43:00.146953 27430 solver.cpp:241]     Train net output #0: loss = 1.28416 (* 1 = 1.28416 loss)
I1029 23:43:00.147001 27430 sgd_solver.cpp:105] Iteration 11400, lr = 0.00243307
I1029 23:43:34.705575 27430 solver.cpp:222] Iteration 11440 (1.15748 iter/s, 34.5578s/40 iters), loss = 2.02319
I1029 23:43:34.706166 27430 solver.cpp:241]     Train net output #0: loss = 2.02319 (* 1 = 2.02319 loss)
I1029 23:43:34.706214 27430 sgd_solver.cpp:105] Iteration 11440, lr = 0.00242103
I1029 23:44:05.440343 27430 solver.cpp:222] Iteration 11480 (1.30151 iter/s, 30.7335s/40 iters), loss = 1.22186
I1029 23:44:05.440887 27430 solver.cpp:241]     Train net output #0: loss = 1.22186 (* 1 = 1.22186 loss)
I1029 23:44:05.440917 27430 sgd_solver.cpp:105] Iteration 11480, lr = 0.00240905
I1029 23:44:20.045060 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_11500.caffemodel
I1029 23:44:20.186825 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_11500.solverstate
I1029 23:44:20.327004 27430 solver.cpp:334] Iteration 11500, Testing net (#0)
I1029 23:44:51.439762 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1029 23:44:51.650297 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57872
I1029 23:44:51.650348 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80868
I1029 23:44:51.650377 27430 solver.cpp:401]     Test net output #2: loss = 1.86565 (* 1 = 1.86565 loss)
I1029 23:45:08.394088 27430 solver.cpp:222] Iteration 11520 (0.635408 iter/s, 62.9517s/40 iters), loss = 1.49116
I1029 23:45:08.394426 27430 solver.cpp:241]     Train net output #0: loss = 1.49116 (* 1 = 1.49116 loss)
I1029 23:45:08.394443 27430 sgd_solver.cpp:105] Iteration 11520, lr = 0.00239713
I1029 23:45:39.151911 27430 solver.cpp:222] Iteration 11560 (1.30053 iter/s, 30.7567s/40 iters), loss = 1.4446
I1029 23:45:39.152144 27430 solver.cpp:241]     Train net output #0: loss = 1.4446 (* 1 = 1.4446 loss)
I1029 23:45:39.152159 27430 sgd_solver.cpp:105] Iteration 11560, lr = 0.00238528
I1029 23:46:09.445636 27430 solver.cpp:222] Iteration 11600 (1.32045 iter/s, 30.2927s/40 iters), loss = 1.62511
I1029 23:46:09.445824 27430 solver.cpp:241]     Train net output #0: loss = 1.62511 (* 1 = 1.62511 loss)
I1029 23:46:09.445842 27430 sgd_solver.cpp:105] Iteration 11600, lr = 0.00237347
I1029 23:46:39.482306 27430 solver.cpp:222] Iteration 11640 (1.33175 iter/s, 30.0358s/40 iters), loss = 1.49071
I1029 23:46:39.482882 27430 solver.cpp:241]     Train net output #0: loss = 1.49071 (* 1 = 1.49071 loss)
I1029 23:46:39.482969 27430 sgd_solver.cpp:105] Iteration 11640, lr = 0.00236173
I1029 23:47:09.473101 27430 solver.cpp:222] Iteration 11680 (1.3338 iter/s, 29.9895s/40 iters), loss = 1.49316
I1029 23:47:09.473584 27430 solver.cpp:241]     Train net output #0: loss = 1.49316 (* 1 = 1.49316 loss)
I1029 23:47:09.473639 27430 sgd_solver.cpp:105] Iteration 11680, lr = 0.00235005
I1029 23:47:39.733508 27430 solver.cpp:222] Iteration 11720 (1.32191 iter/s, 30.2592s/40 iters), loss = 1.50166
I1029 23:47:39.733700 27430 solver.cpp:241]     Train net output #0: loss = 1.50166 (* 1 = 1.50166 loss)
I1029 23:47:39.733713 27430 sgd_solver.cpp:105] Iteration 11720, lr = 0.00233842
I1029 23:48:09.912695 27430 solver.cpp:222] Iteration 11760 (1.32546 iter/s, 30.1783s/40 iters), loss = 1.4056
I1029 23:48:09.912864 27430 solver.cpp:241]     Train net output #0: loss = 1.4056 (* 1 = 1.4056 loss)
I1029 23:48:09.912879 27430 sgd_solver.cpp:105] Iteration 11760, lr = 0.00232685
I1029 23:48:39.586416 27430 solver.cpp:222] Iteration 11800 (1.34803 iter/s, 29.6728s/40 iters), loss = 1.58466
I1029 23:48:39.586969 27430 solver.cpp:241]     Train net output #0: loss = 1.58466 (* 1 = 1.58466 loss)
I1029 23:48:39.587024 27430 sgd_solver.cpp:105] Iteration 11800, lr = 0.00231534
I1029 23:49:09.539475 27430 solver.cpp:222] Iteration 11840 (1.33548 iter/s, 29.9519s/40 iters), loss = 1.52951
I1029 23:49:09.540115 27430 solver.cpp:241]     Train net output #0: loss = 1.52951 (* 1 = 1.52951 loss)
I1029 23:49:09.540163 27430 sgd_solver.cpp:105] Iteration 11840, lr = 0.00230389
I1029 23:49:39.664741 27430 solver.cpp:222] Iteration 11880 (1.32785 iter/s, 30.1239s/40 iters), loss = 1.82338
I1029 23:49:39.664911 27430 solver.cpp:241]     Train net output #0: loss = 1.82338 (* 1 = 1.82338 loss)
I1029 23:49:39.664929 27430 sgd_solver.cpp:105] Iteration 11880, lr = 0.00229249
I1029 23:50:09.760071 27430 solver.cpp:222] Iteration 11920 (1.32915 iter/s, 30.0944s/40 iters), loss = 1.38966
I1029 23:50:09.760244 27430 solver.cpp:241]     Train net output #0: loss = 1.38966 (* 1 = 1.38966 loss)
I1029 23:50:09.760258 27430 sgd_solver.cpp:105] Iteration 11920, lr = 0.00228115
I1029 23:50:39.718961 27430 solver.cpp:222] Iteration 11960 (1.3352 iter/s, 29.958s/40 iters), loss = 1.55162
I1029 23:50:39.719444 27430 solver.cpp:241]     Train net output #0: loss = 1.55162 (* 1 = 1.55162 loss)
I1029 23:50:39.719491 27430 sgd_solver.cpp:105] Iteration 11960, lr = 0.00226987
I1029 23:51:08.360934 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_12000.caffemodel
I1029 23:51:08.500833 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_12000.solverstate
I1029 23:51:08.611963 27430 solver.cpp:334] Iteration 12000, Testing net (#0)
I1029 23:51:39.956377 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58276
I1029 23:51:39.956583 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80596
I1029 23:51:39.956598 27430 solver.cpp:401]     Test net output #2: loss = 1.85477 (* 1 = 1.85477 loss)
I1029 23:51:40.707239 27430 solver.cpp:222] Iteration 12000 (0.655884 iter/s, 60.9864s/40 iters), loss = 1.79652
I1029 23:51:40.707301 27430 solver.cpp:241]     Train net output #0: loss = 1.79652 (* 1 = 1.79652 loss)
I1029 23:51:40.707314 27430 sgd_solver.cpp:105] Iteration 12000, lr = 0.00225864
I1029 23:52:09.991273 27430 solver.cpp:222] Iteration 12040 (1.36597 iter/s, 29.2833s/40 iters), loss = 1.51419
I1029 23:52:09.991772 27430 solver.cpp:241]     Train net output #0: loss = 1.51419 (* 1 = 1.51419 loss)
I1029 23:52:09.991822 27430 sgd_solver.cpp:105] Iteration 12040, lr = 0.00224746
I1029 23:52:39.736776 27430 solver.cpp:222] Iteration 12080 (1.34479 iter/s, 29.7443s/40 iters), loss = 1.55443
I1029 23:52:39.737288 27430 solver.cpp:241]     Train net output #0: loss = 1.55443 (* 1 = 1.55443 loss)
I1029 23:52:39.737334 27430 sgd_solver.cpp:105] Iteration 12080, lr = 0.00223634
I1029 23:53:27.014994 27430 solver.cpp:222] Iteration 12120 (0.846084 iter/s, 47.2766s/40 iters), loss = 1.7104
I1029 23:53:27.015558 27430 solver.cpp:241]     Train net output #0: loss = 1.7104 (* 1 = 1.7104 loss)
I1029 23:53:27.015609 27430 sgd_solver.cpp:105] Iteration 12120, lr = 0.00222528
I1029 23:53:57.414697 27430 solver.cpp:222] Iteration 12160 (1.31586 iter/s, 30.3985s/40 iters), loss = 1.65837
I1029 23:53:57.415355 27430 solver.cpp:241]     Train net output #0: loss = 1.65837 (* 1 = 1.65837 loss)
I1029 23:53:57.415403 27430 sgd_solver.cpp:105] Iteration 12160, lr = 0.00221427
I1029 23:54:27.621217 27430 solver.cpp:222] Iteration 12200 (1.32428 iter/s, 30.2052s/40 iters), loss = 1.25141
I1029 23:54:27.621795 27430 solver.cpp:241]     Train net output #0: loss = 1.25141 (* 1 = 1.25141 loss)
I1029 23:54:27.621835 27430 sgd_solver.cpp:105] Iteration 12200, lr = 0.00220332
I1029 23:54:58.843544 27430 solver.cpp:222] Iteration 12240 (1.28119 iter/s, 31.2211s/40 iters), loss = 1.59068
I1029 23:54:58.844099 27430 solver.cpp:241]     Train net output #0: loss = 1.59068 (* 1 = 1.59068 loss)
I1029 23:54:58.844147 27430 sgd_solver.cpp:105] Iteration 12240, lr = 0.00219242
I1029 23:55:29.739354 27430 solver.cpp:222] Iteration 12280 (1.29473 iter/s, 30.8946s/40 iters), loss = 1.9827
I1029 23:55:29.739909 27430 solver.cpp:241]     Train net output #0: loss = 1.9827 (* 1 = 1.9827 loss)
I1029 23:55:29.739964 27430 sgd_solver.cpp:105] Iteration 12280, lr = 0.00218157
I1029 23:55:59.301944 27430 solver.cpp:222] Iteration 12320 (1.35312 iter/s, 29.5613s/40 iters), loss = 1.34701
I1029 23:55:59.302350 27430 solver.cpp:241]     Train net output #0: loss = 1.34701 (* 1 = 1.34701 loss)
I1029 23:55:59.302397 27430 sgd_solver.cpp:105] Iteration 12320, lr = 0.00217078
I1029 23:56:29.442066 27430 solver.cpp:222] Iteration 12360 (1.32718 iter/s, 30.139s/40 iters), loss = 0.898519
I1029 23:56:29.442661 27430 solver.cpp:241]     Train net output #0: loss = 0.898519 (* 1 = 0.898519 loss)
I1029 23:56:29.442706 27430 sgd_solver.cpp:105] Iteration 12360, lr = 0.00216004
I1029 23:56:59.482319 27430 solver.cpp:222] Iteration 12400 (1.3316 iter/s, 30.039s/40 iters), loss = 1.32435
I1029 23:56:59.482889 27430 solver.cpp:241]     Train net output #0: loss = 1.32435 (* 1 = 1.32435 loss)
I1029 23:56:59.482957 27430 sgd_solver.cpp:105] Iteration 12400, lr = 0.00214935
I1029 23:57:29.421283 27430 solver.cpp:222] Iteration 12440 (1.33611 iter/s, 29.9377s/40 iters), loss = 1.5596
I1029 23:57:29.421743 27430 solver.cpp:241]     Train net output #0: loss = 1.5596 (* 1 = 1.5596 loss)
I1029 23:57:29.421789 27430 sgd_solver.cpp:105] Iteration 12440, lr = 0.00213872
I1029 23:57:59.447906 27430 solver.cpp:222] Iteration 12480 (1.3322 iter/s, 30.0255s/40 iters), loss = 1.30393
I1029 23:57:59.448426 27430 solver.cpp:241]     Train net output #0: loss = 1.30393 (* 1 = 1.30393 loss)
I1029 23:57:59.448472 27430 sgd_solver.cpp:105] Iteration 12480, lr = 0.00212814
I1029 23:58:13.818550 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_12500.caffemodel
I1029 23:58:15.454144 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_12500.solverstate
I1029 23:58:20.544131 27430 solver.cpp:334] Iteration 12500, Testing net (#0)
I1029 23:58:51.592358 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1029 23:58:51.802363 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57952
I1029 23:58:51.802410 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81
I1029 23:58:51.802423 27430 solver.cpp:401]     Test net output #2: loss = 1.85384 (* 1 = 1.85384 loss)
I1029 23:58:58.124228 27479 data_layer.cpp:73] Restarting data prefetching from start.
I1029 23:59:07.516762 27430 solver.cpp:222] Iteration 12520 (0.587658 iter/s, 68.0668s/40 iters), loss = 1.39361
I1029 23:59:07.516815 27430 solver.cpp:241]     Train net output #0: loss = 1.39361 (* 1 = 1.39361 loss)
I1029 23:59:07.516829 27430 sgd_solver.cpp:105] Iteration 12520, lr = 0.00211761
I1029 23:59:37.311204 27430 solver.cpp:222] Iteration 12560 (1.34257 iter/s, 29.7937s/40 iters), loss = 1.72429
I1029 23:59:37.311837 27430 solver.cpp:241]     Train net output #0: loss = 1.72429 (* 1 = 1.72429 loss)
I1029 23:59:37.311884 27430 sgd_solver.cpp:105] Iteration 12560, lr = 0.00210713
I1030 00:00:07.605304 27430 solver.cpp:222] Iteration 12600 (1.32045 iter/s, 30.2928s/40 iters), loss = 1.42186
I1030 00:00:07.605471 27430 solver.cpp:241]     Train net output #0: loss = 1.42186 (* 1 = 1.42186 loss)
I1030 00:00:07.605485 27430 sgd_solver.cpp:105] Iteration 12600, lr = 0.00209671
I1030 00:00:36.854060 27430 solver.cpp:222] Iteration 12640 (1.36762 iter/s, 29.2479s/40 iters), loss = 1.40948
I1030 00:00:36.854547 27430 solver.cpp:241]     Train net output #0: loss = 1.40948 (* 1 = 1.40948 loss)
I1030 00:00:36.854599 27430 sgd_solver.cpp:105] Iteration 12640, lr = 0.00208634
I1030 00:01:06.341733 27430 solver.cpp:222] Iteration 12680 (1.35655 iter/s, 29.4865s/40 iters), loss = 1.20884
I1030 00:01:06.342267 27430 solver.cpp:241]     Train net output #0: loss = 1.20884 (* 1 = 1.20884 loss)
I1030 00:01:06.342314 27430 sgd_solver.cpp:105] Iteration 12680, lr = 0.00207602
I1030 00:01:35.788321 27430 solver.cpp:222] Iteration 12720 (1.35845 iter/s, 29.4454s/40 iters), loss = 1.47837
I1030 00:01:35.788900 27430 solver.cpp:241]     Train net output #0: loss = 1.47837 (* 1 = 1.47837 loss)
I1030 00:01:35.789000 27430 sgd_solver.cpp:105] Iteration 12720, lr = 0.00206575
I1030 00:02:05.984699 27430 solver.cpp:222] Iteration 12760 (1.32472 iter/s, 30.1951s/40 iters), loss = 1.22438
I1030 00:02:05.985316 27430 solver.cpp:241]     Train net output #0: loss = 1.22438 (* 1 = 1.22438 loss)
I1030 00:02:05.985369 27430 sgd_solver.cpp:105] Iteration 12760, lr = 0.00205553
I1030 00:02:36.578531 27430 solver.cpp:222] Iteration 12800 (1.30751 iter/s, 30.5925s/40 iters), loss = 1.52913
I1030 00:02:36.578702 27430 solver.cpp:241]     Train net output #0: loss = 1.52913 (* 1 = 1.52913 loss)
I1030 00:02:36.578717 27430 sgd_solver.cpp:105] Iteration 12800, lr = 0.00204536
I1030 00:03:06.446507 27430 solver.cpp:222] Iteration 12840 (1.33927 iter/s, 29.8671s/40 iters), loss = 1.44178
I1030 00:03:06.447026 27430 solver.cpp:241]     Train net output #0: loss = 1.44178 (* 1 = 1.44178 loss)
I1030 00:03:06.447074 27430 sgd_solver.cpp:105] Iteration 12840, lr = 0.00203524
I1030 00:03:37.491551 27430 solver.cpp:222] Iteration 12880 (1.2885 iter/s, 31.0438s/40 iters), loss = 1.51799
I1030 00:03:37.492166 27430 solver.cpp:241]     Train net output #0: loss = 1.51799 (* 1 = 1.51799 loss)
I1030 00:03:37.492202 27430 sgd_solver.cpp:105] Iteration 12880, lr = 0.00202517
I1030 00:04:09.210019 27430 solver.cpp:222] Iteration 12920 (1.26115 iter/s, 31.7171s/40 iters), loss = 1.08217
I1030 00:04:09.210723 27430 solver.cpp:241]     Train net output #0: loss = 1.08217 (* 1 = 1.08217 loss)
I1030 00:04:09.210767 27430 sgd_solver.cpp:105] Iteration 12920, lr = 0.00201515
I1030 00:04:38.848695 27430 solver.cpp:222] Iteration 12960 (1.34965 iter/s, 29.6373s/40 iters), loss = 1.93612
I1030 00:04:38.849167 27430 solver.cpp:241]     Train net output #0: loss = 1.93612 (* 1 = 1.93612 loss)
I1030 00:04:38.849220 27430 sgd_solver.cpp:105] Iteration 12960, lr = 0.00200518
I1030 00:05:07.873785 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_13000.caffemodel
I1030 00:05:08.028908 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_13000.solverstate
I1030 00:05:08.147188 27430 solver.cpp:334] Iteration 13000, Testing net (#0)
I1030 00:05:39.306349 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.581
I1030 00:05:39.306433 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80688
I1030 00:05:39.306445 27430 solver.cpp:401]     Test net output #2: loss = 1.84904 (* 1 = 1.84904 loss)
I1030 00:05:40.071630 27430 solver.cpp:222] Iteration 13000 (0.65337 iter/s, 61.2211s/40 iters), loss = 1.08445
I1030 00:05:40.071671 27430 solver.cpp:241]     Train net output #0: loss = 1.08445 (* 1 = 1.08445 loss)
I1030 00:05:40.071686 27430 sgd_solver.cpp:105] Iteration 13000, lr = 0.00199526
I1030 00:06:09.964354 27430 solver.cpp:222] Iteration 13040 (1.33815 iter/s, 29.892s/40 iters), loss = 1.52229
I1030 00:06:09.964850 27430 solver.cpp:241]     Train net output #0: loss = 1.52229 (* 1 = 1.52229 loss)
I1030 00:06:09.964908 27430 sgd_solver.cpp:105] Iteration 13040, lr = 0.00198539
I1030 00:06:39.595286 27430 solver.cpp:222] Iteration 13080 (1.34999 iter/s, 29.6297s/40 iters), loss = 1.27418
I1030 00:06:39.595726 27430 solver.cpp:241]     Train net output #0: loss = 1.27418 (* 1 = 1.27418 loss)
I1030 00:06:39.595768 27430 sgd_solver.cpp:105] Iteration 13080, lr = 0.00197557
I1030 00:07:09.034162 27430 solver.cpp:222] Iteration 13120 (1.3588 iter/s, 29.4378s/40 iters), loss = 1.29061
I1030 00:07:09.034754 27430 solver.cpp:241]     Train net output #0: loss = 1.29061 (* 1 = 1.29061 loss)
I1030 00:07:09.034801 27430 sgd_solver.cpp:105] Iteration 13120, lr = 0.0019658
I1030 00:07:39.298813 27430 solver.cpp:222] Iteration 13160 (1.32173 iter/s, 30.2634s/40 iters), loss = 1.44925
I1030 00:07:39.299428 27430 solver.cpp:241]     Train net output #0: loss = 1.44925 (* 1 = 1.44925 loss)
I1030 00:07:39.299470 27430 sgd_solver.cpp:105] Iteration 13160, lr = 0.00195607
I1030 00:08:08.850646 27430 solver.cpp:222] Iteration 13200 (1.35361 iter/s, 29.5505s/40 iters), loss = 1.27749
I1030 00:08:08.851141 27430 solver.cpp:241]     Train net output #0: loss = 1.27749 (* 1 = 1.27749 loss)
I1030 00:08:08.851192 27430 sgd_solver.cpp:105] Iteration 13200, lr = 0.00194639
I1030 00:08:38.606215 27430 solver.cpp:222] Iteration 13240 (1.34434 iter/s, 29.7544s/40 iters), loss = 1.56761
I1030 00:08:38.606793 27430 solver.cpp:241]     Train net output #0: loss = 1.56761 (* 1 = 1.56761 loss)
I1030 00:08:38.606844 27430 sgd_solver.cpp:105] Iteration 13240, lr = 0.00193677
I1030 00:09:08.305245 27430 solver.cpp:222] Iteration 13280 (1.3469 iter/s, 29.6978s/40 iters), loss = 1.51265
I1030 00:09:08.305760 27430 solver.cpp:241]     Train net output #0: loss = 1.51265 (* 1 = 1.51265 loss)
I1030 00:09:08.305812 27430 sgd_solver.cpp:105] Iteration 13280, lr = 0.00192718
I1030 00:09:38.327061 27430 solver.cpp:222] Iteration 13320 (1.33242 iter/s, 30.0206s/40 iters), loss = 1.40641
I1030 00:09:38.327652 27430 solver.cpp:241]     Train net output #0: loss = 1.40641 (* 1 = 1.40641 loss)
I1030 00:09:38.327698 27430 sgd_solver.cpp:105] Iteration 13320, lr = 0.00191765
I1030 00:10:09.069579 27430 solver.cpp:222] Iteration 13360 (1.30118 iter/s, 30.7412s/40 iters), loss = 1.26985
I1030 00:10:09.070128 27430 solver.cpp:241]     Train net output #0: loss = 1.26985 (* 1 = 1.26985 loss)
I1030 00:10:09.070176 27430 sgd_solver.cpp:105] Iteration 13360, lr = 0.00190816
I1030 00:10:39.091094 27430 solver.cpp:222] Iteration 13400 (1.33243 iter/s, 30.0203s/40 iters), loss = 1.19314
I1030 00:10:39.091667 27430 solver.cpp:241]     Train net output #0: loss = 1.19314 (* 1 = 1.19314 loss)
I1030 00:10:39.091717 27430 sgd_solver.cpp:105] Iteration 13400, lr = 0.00189872
I1030 00:11:08.587949 27430 solver.cpp:222] Iteration 13440 (1.35613 iter/s, 29.4956s/40 iters), loss = 1.56555
I1030 00:11:08.588415 27430 solver.cpp:241]     Train net output #0: loss = 1.56555 (* 1 = 1.56555 loss)
I1030 00:11:08.588461 27430 sgd_solver.cpp:105] Iteration 13440, lr = 0.00188933
I1030 00:11:38.055006 27430 solver.cpp:222] Iteration 13480 (1.3575 iter/s, 29.4659s/40 iters), loss = 1.30562
I1030 00:11:38.055588 27430 solver.cpp:241]     Train net output #0: loss = 1.30562 (* 1 = 1.30562 loss)
I1030 00:11:38.055634 27430 sgd_solver.cpp:105] Iteration 13480, lr = 0.00187998
I1030 00:11:52.288553 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_13500.caffemodel
I1030 00:11:52.438223 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_13500.solverstate
I1030 00:11:52.563482 27430 solver.cpp:334] Iteration 13500, Testing net (#0)
I1030 00:12:23.692417 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1030 00:12:23.903317 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5818
I1030 00:12:23.903368 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.810759
I1030 00:12:23.903378 27430 solver.cpp:401]     Test net output #2: loss = 1.87492 (* 1 = 1.87492 loss)
I1030 00:12:39.768921 27430 solver.cpp:222] Iteration 13520 (0.648173 iter/s, 61.7119s/40 iters), loss = 1.46593
I1030 00:12:39.769379 27430 solver.cpp:241]     Train net output #0: loss = 1.46593 (* 1 = 1.46593 loss)
I1030 00:12:39.769430 27430 sgd_solver.cpp:105] Iteration 13520, lr = 0.00187068
I1030 00:13:10.113018 27430 solver.cpp:222] Iteration 13560 (1.31826 iter/s, 30.3429s/40 iters), loss = 1.09517
I1030 00:13:10.113584 27430 solver.cpp:241]     Train net output #0: loss = 1.09517 (* 1 = 1.09517 loss)
I1030 00:13:10.113629 27430 sgd_solver.cpp:105] Iteration 13560, lr = 0.00186143
I1030 00:13:40.985158 27430 solver.cpp:222] Iteration 13600 (1.29572 iter/s, 30.8708s/40 iters), loss = 1.91522
I1030 00:13:40.985793 27430 solver.cpp:241]     Train net output #0: loss = 1.91522 (* 1 = 1.91522 loss)
I1030 00:13:40.985846 27430 sgd_solver.cpp:105] Iteration 13600, lr = 0.00185222
I1030 00:14:10.946063 27430 solver.cpp:222] Iteration 13640 (1.33513 iter/s, 29.9596s/40 iters), loss = 1.49898
I1030 00:14:10.946532 27430 solver.cpp:241]     Train net output #0: loss = 1.49898 (* 1 = 1.49898 loss)
I1030 00:14:10.946573 27430 sgd_solver.cpp:105] Iteration 13640, lr = 0.00184306
I1030 00:14:41.178892 27430 solver.cpp:222] Iteration 13680 (1.32312 iter/s, 30.2317s/40 iters), loss = 1.26928
I1030 00:14:41.179592 27430 solver.cpp:241]     Train net output #0: loss = 1.26928 (* 1 = 1.26928 loss)
I1030 00:14:41.179661 27430 sgd_solver.cpp:105] Iteration 13680, lr = 0.00183394
I1030 00:15:48.894408 27430 solver.cpp:222] Iteration 13720 (0.590726 iter/s, 67.7133s/40 iters), loss = 1.38436
I1030 00:15:48.894990 27430 solver.cpp:241]     Train net output #0: loss = 1.38436 (* 1 = 1.38436 loss)
I1030 00:15:48.895036 27430 sgd_solver.cpp:105] Iteration 13720, lr = 0.00182487
I1030 00:16:55.267761 27430 solver.cpp:222] Iteration 13760 (0.60267 iter/s, 66.3713s/40 iters), loss = 1.70921
I1030 00:16:55.268369 27430 solver.cpp:241]     Train net output #0: loss = 1.70921 (* 1 = 1.70921 loss)
I1030 00:16:55.268414 27430 sgd_solver.cpp:105] Iteration 13760, lr = 0.00181584
I1030 00:17:55.273630 27430 solver.cpp:222] Iteration 13800 (0.666623 iter/s, 60.0039s/40 iters), loss = 1.36902
I1030 00:17:55.274188 27430 solver.cpp:241]     Train net output #0: loss = 1.36902 (* 1 = 1.36902 loss)
I1030 00:17:55.274207 27430 sgd_solver.cpp:105] Iteration 13800, lr = 0.00180685
I1030 00:18:25.570101 27430 solver.cpp:222] Iteration 13840 (1.32034 iter/s, 30.2952s/40 iters), loss = 1.35512
I1030 00:18:25.570302 27430 solver.cpp:241]     Train net output #0: loss = 1.35512 (* 1 = 1.35512 loss)
I1030 00:18:25.570323 27430 sgd_solver.cpp:105] Iteration 13840, lr = 0.00179792
I1030 00:18:56.297359 27430 solver.cpp:222] Iteration 13880 (1.30181 iter/s, 30.7263s/40 iters), loss = 1.5365
I1030 00:18:56.297569 27430 solver.cpp:241]     Train net output #0: loss = 1.5365 (* 1 = 1.5365 loss)
I1030 00:18:56.297583 27430 sgd_solver.cpp:105] Iteration 13880, lr = 0.00178902
I1030 00:19:26.075438 27430 solver.cpp:222] Iteration 13920 (1.34331 iter/s, 29.7772s/40 iters), loss = 1.55019
I1030 00:19:26.075904 27430 solver.cpp:241]     Train net output #0: loss = 1.55019 (* 1 = 1.55019 loss)
I1030 00:19:26.076009 27430 sgd_solver.cpp:105] Iteration 13920, lr = 0.00178017
I1030 00:19:56.528841 27430 solver.cpp:222] Iteration 13960 (1.31353 iter/s, 30.4523s/40 iters), loss = 1.80692
I1030 00:19:56.529328 27430 solver.cpp:241]     Train net output #0: loss = 1.80692 (* 1 = 1.80692 loss)
I1030 00:19:56.529345 27430 sgd_solver.cpp:105] Iteration 13960, lr = 0.00177136
I1030 00:20:25.349278 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_14000.caffemodel
I1030 00:20:25.489962 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_14000.solverstate
I1030 00:20:25.600069 27430 solver.cpp:334] Iteration 14000, Testing net (#0)
I1030 00:20:56.861819 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58256
I1030 00:20:56.862350 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80608
I1030 00:20:56.862371 27430 solver.cpp:401]     Test net output #2: loss = 1.85168 (* 1 = 1.85168 loss)
I1030 00:20:57.622031 27430 solver.cpp:222] Iteration 14000 (0.654758 iter/s, 61.0913s/40 iters), loss = 1.47446
I1030 00:20:57.622092 27430 solver.cpp:241]     Train net output #0: loss = 1.47446 (* 1 = 1.47446 loss)
I1030 00:20:57.622105 27430 sgd_solver.cpp:105] Iteration 14000, lr = 0.0017626
I1030 00:21:27.127630 27430 solver.cpp:222] Iteration 14040 (1.35571 iter/s, 29.5048s/40 iters), loss = 1.36413
I1030 00:21:27.127789 27430 solver.cpp:241]     Train net output #0: loss = 1.36413 (* 1 = 1.36413 loss)
I1030 00:21:27.127802 27430 sgd_solver.cpp:105] Iteration 14040, lr = 0.00175388
I1030 00:21:56.580826 27430 solver.cpp:222] Iteration 14080 (1.35813 iter/s, 29.4523s/40 iters), loss = 1.42899
I1030 00:21:56.581259 27430 solver.cpp:241]     Train net output #0: loss = 1.42899 (* 1 = 1.42899 loss)
I1030 00:21:56.581305 27430 sgd_solver.cpp:105] Iteration 14080, lr = 0.0017452
I1030 00:22:26.180614 27430 solver.cpp:222] Iteration 14120 (1.35141 iter/s, 29.5987s/40 iters), loss = 1.27107
I1030 00:22:26.181192 27430 solver.cpp:241]     Train net output #0: loss = 1.27107 (* 1 = 1.27107 loss)
I1030 00:22:26.181244 27430 sgd_solver.cpp:105] Iteration 14120, lr = 0.00173657
I1030 00:22:55.770792 27430 solver.cpp:222] Iteration 14160 (1.35186 iter/s, 29.5889s/40 iters), loss = 1.63454
I1030 00:22:55.771265 27430 solver.cpp:241]     Train net output #0: loss = 1.63454 (* 1 = 1.63454 loss)
I1030 00:22:55.771317 27430 sgd_solver.cpp:105] Iteration 14160, lr = 0.00172798
I1030 00:23:25.586241 27430 solver.cpp:222] Iteration 14200 (1.34164 iter/s, 29.8143s/40 iters), loss = 1.82167
I1030 00:23:25.586840 27430 solver.cpp:241]     Train net output #0: loss = 1.82167 (* 1 = 1.82167 loss)
I1030 00:23:25.586886 27430 sgd_solver.cpp:105] Iteration 14200, lr = 0.00171943
I1030 00:23:55.011044 27430 solver.cpp:222] Iteration 14240 (1.35946 iter/s, 29.4235s/40 iters), loss = 1.69635
I1030 00:23:55.011504 27430 solver.cpp:241]     Train net output #0: loss = 1.69635 (* 1 = 1.69635 loss)
I1030 00:23:55.011553 27430 sgd_solver.cpp:105] Iteration 14240, lr = 0.00171092
I1030 00:24:24.396342 27430 solver.cpp:222] Iteration 14280 (1.36128 iter/s, 29.3842s/40 iters), loss = 1.42877
I1030 00:24:24.396888 27430 solver.cpp:241]     Train net output #0: loss = 1.42877 (* 1 = 1.42877 loss)
I1030 00:24:24.396991 27430 sgd_solver.cpp:105] Iteration 14280, lr = 0.00170246
I1030 00:24:53.887670 27430 solver.cpp:222] Iteration 14320 (1.35639 iter/s, 29.4901s/40 iters), loss = 1.39493
I1030 00:24:53.888170 27430 solver.cpp:241]     Train net output #0: loss = 1.39493 (* 1 = 1.39493 loss)
I1030 00:24:53.888216 27430 sgd_solver.cpp:105] Iteration 14320, lr = 0.00169404
I1030 00:25:23.429396 27430 solver.cpp:222] Iteration 14360 (1.35407 iter/s, 29.5405s/40 iters), loss = 1.44886
I1030 00:25:23.430089 27430 solver.cpp:241]     Train net output #0: loss = 1.44886 (* 1 = 1.44886 loss)
I1030 00:25:23.430136 27430 sgd_solver.cpp:105] Iteration 14360, lr = 0.00168566
I1030 00:25:52.923194 27430 solver.cpp:222] Iteration 14400 (1.35628 iter/s, 29.4924s/40 iters), loss = 1.26107
I1030 00:25:52.923669 27430 solver.cpp:241]     Train net output #0: loss = 1.26107 (* 1 = 1.26107 loss)
I1030 00:25:52.923717 27430 sgd_solver.cpp:105] Iteration 14400, lr = 0.00167732
I1030 00:26:22.657001 27430 solver.cpp:222] Iteration 14440 (1.34532 iter/s, 29.7327s/40 iters), loss = 1.69205
I1030 00:26:22.657589 27430 solver.cpp:241]     Train net output #0: loss = 1.69205 (* 1 = 1.69205 loss)
I1030 00:26:22.657635 27430 sgd_solver.cpp:105] Iteration 14440, lr = 0.00166902
I1030 00:26:53.624600 27430 solver.cpp:222] Iteration 14480 (1.29173 iter/s, 30.9663s/40 iters), loss = 1.43314
I1030 00:26:53.624773 27430 solver.cpp:241]     Train net output #0: loss = 1.43314 (* 1 = 1.43314 loss)
I1030 00:26:53.624786 27430 sgd_solver.cpp:105] Iteration 14480, lr = 0.00166076
I1030 00:27:08.195639 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_14500.caffemodel
I1030 00:27:08.339877 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_14500.solverstate
I1030 00:27:08.462314 27430 solver.cpp:334] Iteration 14500, Testing net (#0)
I1030 00:27:39.400900 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1030 00:27:39.614316 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58012
I1030 00:27:39.614367 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.810639
I1030 00:27:39.614377 27430 solver.cpp:401]     Test net output #2: loss = 1.85713 (* 1 = 1.85713 loss)
I1030 00:27:55.168463 27430 solver.cpp:222] Iteration 14520 (0.64996 iter/s, 61.5422s/40 iters), loss = 1.32748
I1030 00:27:55.168898 27430 solver.cpp:241]     Train net output #0: loss = 1.32748 (* 1 = 1.32748 loss)
I1030 00:27:55.168967 27430 sgd_solver.cpp:105] Iteration 14520, lr = 0.00165255
I1030 00:28:24.820706 27430 solver.cpp:222] Iteration 14560 (1.34902 iter/s, 29.6511s/40 iters), loss = 1.57297
I1030 00:28:24.821315 27430 solver.cpp:241]     Train net output #0: loss = 1.57297 (* 1 = 1.57297 loss)
I1030 00:28:24.821360 27430 sgd_solver.cpp:105] Iteration 14560, lr = 0.00164437
I1030 00:28:54.159543 27430 solver.cpp:222] Iteration 14600 (1.36344 iter/s, 29.3375s/40 iters), loss = 1.22972
I1030 00:28:54.160048 27430 solver.cpp:241]     Train net output #0: loss = 1.22972 (* 1 = 1.22972 loss)
I1030 00:28:54.160100 27430 sgd_solver.cpp:105] Iteration 14600, lr = 0.00163624
I1030 00:29:23.481554 27430 solver.cpp:222] Iteration 14640 (1.36422 iter/s, 29.3208s/40 iters), loss = 1.13109
I1030 00:29:23.482174 27430 solver.cpp:241]     Train net output #0: loss = 1.13109 (* 1 = 1.13109 loss)
I1030 00:29:23.482223 27430 sgd_solver.cpp:105] Iteration 14640, lr = 0.00162814
I1030 00:29:52.808092 27430 solver.cpp:222] Iteration 14680 (1.36401 iter/s, 29.3252s/40 iters), loss = 1.59568
I1030 00:29:52.808506 27430 solver.cpp:241]     Train net output #0: loss = 1.59568 (* 1 = 1.59568 loss)
I1030 00:29:52.808540 27430 sgd_solver.cpp:105] Iteration 14680, lr = 0.00162009
I1030 00:30:22.417488 27430 solver.cpp:222] Iteration 14720 (1.35097 iter/s, 29.6083s/40 iters), loss = 1.46163
I1030 00:30:22.418087 27430 solver.cpp:241]     Train net output #0: loss = 1.46163 (* 1 = 1.46163 loss)
I1030 00:30:22.418123 27430 sgd_solver.cpp:105] Iteration 14720, lr = 0.00161207
I1030 00:30:51.746317 27430 solver.cpp:222] Iteration 14760 (1.36391 iter/s, 29.3276s/40 iters), loss = 1.58848
I1030 00:30:51.746748 27430 solver.cpp:241]     Train net output #0: loss = 1.58848 (* 1 = 1.58848 loss)
I1030 00:30:51.746785 27430 sgd_solver.cpp:105] Iteration 14760, lr = 0.0016041
I1030 00:31:21.726853 27430 solver.cpp:222] Iteration 14800 (1.33425 iter/s, 29.9794s/40 iters), loss = 1.45984
I1030 00:31:21.727538 27430 solver.cpp:241]     Train net output #0: loss = 1.45984 (* 1 = 1.45984 loss)
I1030 00:31:21.727592 27430 sgd_solver.cpp:105] Iteration 14800, lr = 0.00159616
I1030 00:31:51.269845 27430 solver.cpp:222] Iteration 14840 (1.35402 iter/s, 29.5416s/40 iters), loss = 1.77984
I1030 00:31:51.270241 27430 solver.cpp:241]     Train net output #0: loss = 1.77984 (* 1 = 1.77984 loss)
I1030 00:31:51.270275 27430 sgd_solver.cpp:105] Iteration 14840, lr = 0.00158827
I1030 00:32:20.786545 27430 solver.cpp:222] Iteration 14880 (1.35521 iter/s, 29.5156s/40 iters), loss = 1.60209
I1030 00:32:20.787130 27430 solver.cpp:241]     Train net output #0: loss = 1.60209 (* 1 = 1.60209 loss)
I1030 00:32:20.787168 27430 sgd_solver.cpp:105] Iteration 14880, lr = 0.00158041
I1030 00:32:50.473433 27430 solver.cpp:222] Iteration 14920 (1.34745 iter/s, 29.6856s/40 iters), loss = 1.10176
I1030 00:32:50.473855 27430 solver.cpp:241]     Train net output #0: loss = 1.10176 (* 1 = 1.10176 loss)
I1030 00:32:50.473892 27430 sgd_solver.cpp:105] Iteration 14920, lr = 0.00157259
I1030 00:33:33.336419 27430 solver.cpp:222] Iteration 14960 (0.933237 iter/s, 42.8616s/40 iters), loss = 1.12793
I1030 00:33:33.337033 27430 solver.cpp:241]     Train net output #0: loss = 1.12793 (* 1 = 1.12793 loss)
I1030 00:33:33.337072 27430 sgd_solver.cpp:105] Iteration 14960, lr = 0.00156481
I1030 00:34:26.310761 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_15000.caffemodel
I1030 00:34:26.467728 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_15000.solverstate
I1030 00:34:26.578014 27430 solver.cpp:334] Iteration 15000, Testing net (#0)
I1030 00:34:57.874943 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58444
I1030 00:34:57.875099 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80584
I1030 00:34:57.875116 27430 solver.cpp:401]     Test net output #2: loss = 1.85312 (* 1 = 1.85312 loss)
I1030 00:34:58.635032 27430 solver.cpp:222] Iteration 15000 (0.468955 iter/s, 85.2961s/40 iters), loss = 1.2882
I1030 00:34:58.635092 27430 solver.cpp:241]     Train net output #0: loss = 1.2882 (* 1 = 1.2882 loss)
I1030 00:34:58.635108 27430 sgd_solver.cpp:105] Iteration 15000, lr = 0.00155707
I1030 00:35:05.382043 27479 data_layer.cpp:73] Restarting data prefetching from start.
I1030 00:35:31.052719 27430 solver.cpp:222] Iteration 15040 (1.23393 iter/s, 32.4169s/40 iters), loss = 1.20992
I1030 00:35:31.053241 27430 solver.cpp:241]     Train net output #0: loss = 1.20992 (* 1 = 1.20992 loss)
I1030 00:35:31.053261 27430 sgd_solver.cpp:105] Iteration 15040, lr = 0.00154937
I1030 00:36:04.820868 27430 solver.cpp:222] Iteration 15080 (1.18459 iter/s, 33.7668s/40 iters), loss = 1.33263
I1030 00:36:04.821482 27430 solver.cpp:241]     Train net output #0: loss = 1.33263 (* 1 = 1.33263 loss)
I1030 00:36:04.821542 27430 sgd_solver.cpp:105] Iteration 15080, lr = 0.0015417
I1030 00:36:34.465062 27430 solver.cpp:222] Iteration 15120 (1.3494 iter/s, 29.6429s/40 iters), loss = 1.29824
I1030 00:36:34.465503 27430 solver.cpp:241]     Train net output #0: loss = 1.29824 (* 1 = 1.29824 loss)
I1030 00:36:34.465545 27430 sgd_solver.cpp:105] Iteration 15120, lr = 0.00153407
I1030 00:37:04.933640 27430 solver.cpp:222] Iteration 15160 (1.31288 iter/s, 30.4674s/40 iters), loss = 1.39454
I1030 00:37:04.934223 27430 solver.cpp:241]     Train net output #0: loss = 1.39454 (* 1 = 1.39454 loss)
I1030 00:37:04.934270 27430 sgd_solver.cpp:105] Iteration 15160, lr = 0.00152648
I1030 00:37:41.735718 27430 solver.cpp:222] Iteration 15200 (1.08694 iter/s, 36.8007s/40 iters), loss = 1.43074
I1030 00:37:41.736356 27430 solver.cpp:241]     Train net output #0: loss = 1.43074 (* 1 = 1.43074 loss)
I1030 00:37:41.736389 27430 sgd_solver.cpp:105] Iteration 15200, lr = 0.00151893
I1030 00:38:11.983326 27430 solver.cpp:222] Iteration 15240 (1.32248 iter/s, 30.2463s/40 iters), loss = 1.34527
I1030 00:38:11.983515 27430 solver.cpp:241]     Train net output #0: loss = 1.34527 (* 1 = 1.34527 loss)
I1030 00:38:11.983528 27430 sgd_solver.cpp:105] Iteration 15240, lr = 0.00151142
I1030 00:38:41.526196 27430 solver.cpp:222] Iteration 15280 (1.354 iter/s, 29.542s/40 iters), loss = 1.7405
I1030 00:38:41.526651 27430 solver.cpp:241]     Train net output #0: loss = 1.7405 (* 1 = 1.7405 loss)
I1030 00:38:41.526702 27430 sgd_solver.cpp:105] Iteration 15280, lr = 0.00150394
I1030 00:39:11.087085 27430 solver.cpp:222] Iteration 15320 (1.35319 iter/s, 29.5598s/40 iters), loss = 1.48567
I1030 00:39:11.087694 27430 solver.cpp:241]     Train net output #0: loss = 1.48567 (* 1 = 1.48567 loss)
I1030 00:39:11.087740 27430 sgd_solver.cpp:105] Iteration 15320, lr = 0.0014965
I1030 00:39:55.022565 27430 solver.cpp:222] Iteration 15360 (0.910459 iter/s, 43.9339s/40 iters), loss = 1.47125
I1030 00:39:55.023169 27430 solver.cpp:241]     Train net output #0: loss = 1.47125 (* 1 = 1.47125 loss)
I1030 00:39:55.023226 27430 sgd_solver.cpp:105] Iteration 15360, lr = 0.0014891
I1030 00:40:44.823465 27430 solver.cpp:222] Iteration 15400 (0.803226 iter/s, 49.7992s/40 iters), loss = 1.26425
I1030 00:40:44.824082 27430 solver.cpp:241]     Train net output #0: loss = 1.26425 (* 1 = 1.26425 loss)
I1030 00:40:44.824133 27430 sgd_solver.cpp:105] Iteration 15400, lr = 0.00148173
I1030 00:41:15.128651 27430 solver.cpp:222] Iteration 15440 (1.31996 iter/s, 30.3039s/40 iters), loss = 1.26381
I1030 00:41:15.128846 27430 solver.cpp:241]     Train net output #0: loss = 1.26381 (* 1 = 1.26381 loss)
I1030 00:41:15.128868 27430 sgd_solver.cpp:105] Iteration 15440, lr = 0.0014744
I1030 00:41:46.288183 27430 solver.cpp:222] Iteration 15480 (1.28375 iter/s, 31.1586s/40 iters), loss = 1.37414
I1030 00:41:46.288698 27430 solver.cpp:241]     Train net output #0: loss = 1.37414 (* 1 = 1.37414 loss)
I1030 00:41:46.288722 27430 sgd_solver.cpp:105] Iteration 15480, lr = 0.00146711
I1030 00:42:21.005324 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_15500.caffemodel
I1030 00:42:21.165315 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_15500.solverstate
I1030 00:42:21.280890 27430 solver.cpp:334] Iteration 15500, Testing net (#0)
I1030 00:42:52.327775 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1030 00:42:52.536942 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58232
I1030 00:42:52.536990 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.811839
I1030 00:42:52.537001 27430 solver.cpp:401]     Test net output #2: loss = 1.8526 (* 1 = 1.8526 loss)
I1030 00:43:08.418669 27430 solver.cpp:222] Iteration 15520 (0.487044 iter/s, 82.1281s/40 iters), loss = 1.41116
I1030 00:43:08.419090 27430 solver.cpp:241]     Train net output #0: loss = 1.41116 (* 1 = 1.41116 loss)
I1030 00:43:08.419142 27430 sgd_solver.cpp:105] Iteration 15520, lr = 0.00145985
I1030 00:43:42.109895 27430 solver.cpp:222] Iteration 15560 (1.18729 iter/s, 33.69s/40 iters), loss = 1.45213
I1030 00:43:42.110514 27430 solver.cpp:241]     Train net output #0: loss = 1.45213 (* 1 = 1.45213 loss)
I1030 00:43:42.110568 27430 sgd_solver.cpp:105] Iteration 15560, lr = 0.00145263
I1030 00:44:12.068351 27430 solver.cpp:222] Iteration 15600 (1.33524 iter/s, 29.9572s/40 iters), loss = 1.31377
I1030 00:44:12.068811 27430 solver.cpp:241]     Train net output #0: loss = 1.31377 (* 1 = 1.31377 loss)
I1030 00:44:12.068852 27430 sgd_solver.cpp:105] Iteration 15600, lr = 0.00144544
I1030 00:44:42.765031 27430 solver.cpp:222] Iteration 15640 (1.30312 iter/s, 30.6955s/40 iters), loss = 1.62834
I1030 00:44:42.765705 27430 solver.cpp:241]     Train net output #0: loss = 1.62834 (* 1 = 1.62834 loss)
I1030 00:44:42.765769 27430 sgd_solver.cpp:105] Iteration 15640, lr = 0.00143829
I1030 00:45:12.057000 27430 solver.cpp:222] Iteration 15680 (1.36562 iter/s, 29.2906s/40 iters), loss = 1.4755
I1030 00:45:12.057466 27430 solver.cpp:241]     Train net output #0: loss = 1.4755 (* 1 = 1.4755 loss)
I1030 00:45:12.057514 27430 sgd_solver.cpp:105] Iteration 15680, lr = 0.00143117
I1030 00:45:41.922580 27430 solver.cpp:222] Iteration 15720 (1.33939 iter/s, 29.8644s/40 iters), loss = 1.49265
I1030 00:45:41.923111 27430 solver.cpp:241]     Train net output #0: loss = 1.49265 (* 1 = 1.49265 loss)
I1030 00:45:41.923142 27430 sgd_solver.cpp:105] Iteration 15720, lr = 0.00142409
I1030 00:46:20.555390 27430 solver.cpp:222] Iteration 15760 (1.03543 iter/s, 38.6314s/40 iters), loss = 1.38237
I1030 00:46:20.555943 27430 solver.cpp:241]     Train net output #0: loss = 1.38237 (* 1 = 1.38237 loss)
I1030 00:46:20.555994 27430 sgd_solver.cpp:105] Iteration 15760, lr = 0.00141705
I1030 00:46:57.404871 27430 solver.cpp:222] Iteration 15800 (1.08554 iter/s, 36.8481s/40 iters), loss = 1.53793
I1030 00:46:57.405375 27430 solver.cpp:241]     Train net output #0: loss = 1.53793 (* 1 = 1.53793 loss)
I1030 00:46:57.405395 27430 sgd_solver.cpp:105] Iteration 15800, lr = 0.00141004
I1030 00:47:28.241670 27430 solver.cpp:222] Iteration 15840 (1.2972 iter/s, 30.8356s/40 iters), loss = 1.26126
I1030 00:47:28.241873 27430 solver.cpp:241]     Train net output #0: loss = 1.26126 (* 1 = 1.26126 loss)
I1030 00:47:28.241886 27430 sgd_solver.cpp:105] Iteration 15840, lr = 0.00140306
I1030 00:47:58.364082 27430 solver.cpp:222] Iteration 15880 (1.32796 iter/s, 30.1215s/40 iters), loss = 1.29918
I1030 00:47:58.364627 27430 solver.cpp:241]     Train net output #0: loss = 1.29918 (* 1 = 1.29918 loss)
I1030 00:47:58.364670 27430 sgd_solver.cpp:105] Iteration 15880, lr = 0.00139612
I1030 00:48:28.032660 27430 solver.cpp:222] Iteration 15920 (1.34828 iter/s, 29.6673s/40 iters), loss = 1.62849
I1030 00:48:28.033118 27430 solver.cpp:241]     Train net output #0: loss = 1.62849 (* 1 = 1.62849 loss)
I1030 00:48:28.033167 27430 sgd_solver.cpp:105] Iteration 15920, lr = 0.00138921
I1030 00:48:57.572304 27430 solver.cpp:222] Iteration 15960 (1.35416 iter/s, 29.5385s/40 iters), loss = 1.21442
I1030 00:48:57.573035 27430 solver.cpp:241]     Train net output #0: loss = 1.21442 (* 1 = 1.21442 loss)
I1030 00:48:57.573082 27430 sgd_solver.cpp:105] Iteration 15960, lr = 0.00138234
I1030 00:49:26.398097 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_16000.caffemodel
I1030 00:49:26.540138 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_16000.solverstate
I1030 00:49:26.653065 27430 solver.cpp:334] Iteration 16000, Testing net (#0)
I1030 00:49:57.925802 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58432
I1030 00:49:57.926323 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8068
I1030 00:49:57.926386 27430 solver.cpp:401]     Test net output #2: loss = 1.85793 (* 1 = 1.85793 loss)
I1030 00:49:58.696362 27430 solver.cpp:222] Iteration 16000 (0.65443 iter/s, 61.1219s/40 iters), loss = 1.55855
I1030 00:49:58.696419 27430 solver.cpp:241]     Train net output #0: loss = 1.55855 (* 1 = 1.55855 loss)
I1030 00:49:58.696431 27430 sgd_solver.cpp:105] Iteration 16000, lr = 0.0013755
I1030 00:50:29.158033 27430 solver.cpp:222] Iteration 16040 (1.31316 iter/s, 30.4609s/40 iters), loss = 1.63211
I1030 00:50:29.158232 27430 solver.cpp:241]     Train net output #0: loss = 1.63211 (* 1 = 1.63211 loss)
I1030 00:50:29.158246 27430 sgd_solver.cpp:105] Iteration 16040, lr = 0.0013687
I1030 00:50:58.671233 27430 solver.cpp:222] Iteration 16080 (1.35537 iter/s, 29.5123s/40 iters), loss = 1.44407
I1030 00:50:58.671636 27430 solver.cpp:241]     Train net output #0: loss = 1.44407 (* 1 = 1.44407 loss)
I1030 00:50:58.671684 27430 sgd_solver.cpp:105] Iteration 16080, lr = 0.00136193
I1030 00:51:35.435324 27430 solver.cpp:222] Iteration 16120 (1.08805 iter/s, 36.7629s/40 iters), loss = 1.41975
I1030 00:51:35.435899 27430 solver.cpp:241]     Train net output #0: loss = 1.41975 (* 1 = 1.41975 loss)
I1030 00:51:35.435945 27430 sgd_solver.cpp:105] Iteration 16120, lr = 0.00135519
I1030 00:52:04.813153 27430 solver.cpp:222] Iteration 16160 (1.36163 iter/s, 29.3766s/40 iters), loss = 1.29013
I1030 00:52:04.813591 27430 solver.cpp:241]     Train net output #0: loss = 1.29013 (* 1 = 1.29013 loss)
I1030 00:52:04.813642 27430 sgd_solver.cpp:105] Iteration 16160, lr = 0.00134849
I1030 00:52:34.536010 27430 solver.cpp:222] Iteration 16200 (1.34582 iter/s, 29.7217s/40 iters), loss = 1.34719
I1030 00:52:34.536548 27430 solver.cpp:241]     Train net output #0: loss = 1.34719 (* 1 = 1.34719 loss)
I1030 00:52:34.536588 27430 sgd_solver.cpp:105] Iteration 16200, lr = 0.00134181
I1030 00:53:04.108467 27430 solver.cpp:222] Iteration 16240 (1.35267 iter/s, 29.5712s/40 iters), loss = 1.25562
I1030 00:53:04.108886 27430 solver.cpp:241]     Train net output #0: loss = 1.25562 (* 1 = 1.25562 loss)
I1030 00:53:04.108952 27430 sgd_solver.cpp:105] Iteration 16240, lr = 0.00133518
I1030 00:53:33.751729 27430 solver.cpp:222] Iteration 16280 (1.34943 iter/s, 29.6422s/40 iters), loss = 1.40389
I1030 00:53:33.752326 27430 solver.cpp:241]     Train net output #0: loss = 1.40389 (* 1 = 1.40389 loss)
I1030 00:53:33.752364 27430 sgd_solver.cpp:105] Iteration 16280, lr = 0.00132857
I1030 00:54:03.602620 27430 solver.cpp:222] Iteration 16320 (1.34005 iter/s, 29.8496s/40 iters), loss = 1.41942
I1030 00:54:03.603056 27430 solver.cpp:241]     Train net output #0: loss = 1.41942 (* 1 = 1.41942 loss)
I1030 00:54:03.603108 27430 sgd_solver.cpp:105] Iteration 16320, lr = 0.001322
I1030 00:54:33.077142 27430 solver.cpp:222] Iteration 16360 (1.35715 iter/s, 29.4734s/40 iters), loss = 1.52076
I1030 00:54:33.077654 27430 solver.cpp:241]     Train net output #0: loss = 1.52076 (* 1 = 1.52076 loss)
I1030 00:54:33.077689 27430 sgd_solver.cpp:105] Iteration 16360, lr = 0.00131546
I1030 00:55:03.523632 27430 solver.cpp:222] Iteration 16400 (1.31383 iter/s, 30.4453s/40 iters), loss = 1.42865
I1030 00:55:03.523810 27430 solver.cpp:241]     Train net output #0: loss = 1.42865 (* 1 = 1.42865 loss)
I1030 00:55:03.523824 27430 sgd_solver.cpp:105] Iteration 16400, lr = 0.00130895
I1030 00:55:34.587152 27430 solver.cpp:222] Iteration 16440 (1.28772 iter/s, 31.0626s/40 iters), loss = 1.52135
I1030 00:55:34.587661 27430 solver.cpp:241]     Train net output #0: loss = 1.52135 (* 1 = 1.52135 loss)
I1030 00:55:34.587690 27430 sgd_solver.cpp:105] Iteration 16440, lr = 0.00130247
I1030 00:56:05.335343 27430 solver.cpp:222] Iteration 16480 (1.30094 iter/s, 30.747s/40 iters), loss = 1.41745
I1030 00:56:05.335530 27430 solver.cpp:241]     Train net output #0: loss = 1.41745 (* 1 = 1.41745 loss)
I1030 00:56:05.335543 27430 sgd_solver.cpp:105] Iteration 16480, lr = 0.00129603
I1030 00:56:19.765951 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_16500.caffemodel
I1030 00:56:19.910377 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_16500.solverstate
I1030 00:56:20.591693 27430 solver.cpp:334] Iteration 16500, Testing net (#0)
I1030 00:56:51.727558 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1030 00:56:51.938992 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58424
I1030 00:56:51.939044 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.812199
I1030 00:56:51.939056 27430 solver.cpp:401]     Test net output #2: loss = 1.85055 (* 1 = 1.85055 loss)
I1030 00:57:07.903038 27430 solver.cpp:222] Iteration 16520 (0.639324 iter/s, 62.566s/40 iters), loss = 1.55136
I1030 00:57:07.903466 27430 solver.cpp:241]     Train net output #0: loss = 1.55136 (* 1 = 1.55136 loss)
I1030 00:57:07.903509 27430 sgd_solver.cpp:105] Iteration 16520, lr = 0.00128962
I1030 00:57:37.887763 27430 solver.cpp:222] Iteration 16560 (1.33406 iter/s, 29.9836s/40 iters), loss = 1.30585
I1030 00:57:37.888361 27430 solver.cpp:241]     Train net output #0: loss = 1.30585 (* 1 = 1.30585 loss)
I1030 00:57:37.888417 27430 sgd_solver.cpp:105] Iteration 16560, lr = 0.00128324
I1030 00:58:07.497995 27430 solver.cpp:222] Iteration 16600 (1.35094 iter/s, 29.609s/40 iters), loss = 1.59917
I1030 00:58:07.498397 27430 solver.cpp:241]     Train net output #0: loss = 1.59917 (* 1 = 1.59917 loss)
I1030 00:58:07.498436 27430 sgd_solver.cpp:105] Iteration 16600, lr = 0.00127689
I1030 00:58:37.161521 27430 solver.cpp:222] Iteration 16640 (1.34851 iter/s, 29.6624s/40 iters), loss = 1.49815
I1030 00:58:37.162067 27430 solver.cpp:241]     Train net output #0: loss = 1.49815 (* 1 = 1.49815 loss)
I1030 00:58:37.162112 27430 sgd_solver.cpp:105] Iteration 16640, lr = 0.00127057
I1030 00:59:06.893808 27430 solver.cpp:222] Iteration 16680 (1.34539 iter/s, 29.731s/40 iters), loss = 1.23853
I1030 00:59:06.894259 27430 solver.cpp:241]     Train net output #0: loss = 1.23853 (* 1 = 1.23853 loss)
I1030 00:59:06.894311 27430 sgd_solver.cpp:105] Iteration 16680, lr = 0.00126429
I1030 00:59:37.047415 27430 solver.cpp:222] Iteration 16720 (1.32659 iter/s, 30.1525s/40 iters), loss = 1.6115
I1030 00:59:37.047595 27430 solver.cpp:241]     Train net output #0: loss = 1.6115 (* 1 = 1.6115 loss)
I1030 00:59:37.047608 27430 sgd_solver.cpp:105] Iteration 16720, lr = 0.00125803
I1030 01:00:07.671994 27430 solver.cpp:222] Iteration 16760 (1.30618 iter/s, 30.6237s/40 iters), loss = 1.16742
I1030 01:00:07.672528 27430 solver.cpp:241]     Train net output #0: loss = 1.16742 (* 1 = 1.16742 loss)
I1030 01:00:07.672554 27430 sgd_solver.cpp:105] Iteration 16760, lr = 0.00125181
I1030 01:00:38.053480 27430 solver.cpp:222] Iteration 16800 (1.31665 iter/s, 30.3802s/40 iters), loss = 1.42742
I1030 01:00:38.053649 27430 solver.cpp:241]     Train net output #0: loss = 1.42742 (* 1 = 1.42742 loss)
I1030 01:00:38.053664 27430 sgd_solver.cpp:105] Iteration 16800, lr = 0.00124562
I1030 01:01:07.624714 27430 solver.cpp:222] Iteration 16840 (1.35271 iter/s, 29.5704s/40 iters), loss = 1.42675
I1030 01:01:07.625154 27430 solver.cpp:241]     Train net output #0: loss = 1.42675 (* 1 = 1.42675 loss)
I1030 01:01:07.625205 27430 sgd_solver.cpp:105] Iteration 16840, lr = 0.00123946
I1030 01:01:37.195863 27430 solver.cpp:222] Iteration 16880 (1.35272 iter/s, 29.5701s/40 iters), loss = 1.27997
I1030 01:01:37.196471 27430 solver.cpp:241]     Train net output #0: loss = 1.27997 (* 1 = 1.27997 loss)
I1030 01:01:37.196519 27430 sgd_solver.cpp:105] Iteration 16880, lr = 0.00123332
I1030 01:02:07.286994 27430 solver.cpp:222] Iteration 16920 (1.32935 iter/s, 30.0899s/40 iters), loss = 1.47501
I1030 01:02:07.287132 27430 solver.cpp:241]     Train net output #0: loss = 1.47501 (* 1 = 1.47501 loss)
I1030 01:02:07.287147 27430 sgd_solver.cpp:105] Iteration 16920, lr = 0.00122722
I1030 01:02:52.720268 27430 solver.cpp:222] Iteration 16960 (0.880436 iter/s, 45.4321s/40 iters), loss = 1.46067
I1030 01:02:52.720769 27430 solver.cpp:241]     Train net output #0: loss = 1.46067 (* 1 = 1.46067 loss)
I1030 01:02:52.720811 27430 sgd_solver.cpp:105] Iteration 16960, lr = 0.00122115
I1030 01:03:22.782392 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_17000.caffemodel
I1030 01:03:22.932013 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_17000.solverstate
I1030 01:03:23.046427 27430 solver.cpp:334] Iteration 17000, Testing net (#0)
I1030 01:03:54.269199 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58532
I1030 01:03:54.269359 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.806999
I1030 01:03:54.269374 27430 solver.cpp:401]     Test net output #2: loss = 1.84204 (* 1 = 1.84204 loss)
I1030 01:03:55.023591 27430 solver.cpp:222] Iteration 17000 (0.64204 iter/s, 62.3014s/40 iters), loss = 1.49622
I1030 01:03:55.023648 27430 solver.cpp:241]     Train net output #0: loss = 1.49622 (* 1 = 1.49622 loss)
I1030 01:03:55.023660 27430 sgd_solver.cpp:105] Iteration 17000, lr = 0.00121511
I1030 01:04:24.415707 27430 solver.cpp:222] Iteration 17040 (1.36094 iter/s, 29.3914s/40 iters), loss = 1.63515
I1030 01:04:24.416321 27430 solver.cpp:241]     Train net output #0: loss = 1.63515 (* 1 = 1.63515 loss)
I1030 01:04:24.416366 27430 sgd_solver.cpp:105] Iteration 17040, lr = 0.0012091
I1030 01:04:54.128459 27430 solver.cpp:222] Iteration 17080 (1.34628 iter/s, 29.7115s/40 iters), loss = 1.47398
I1030 01:04:54.128942 27430 solver.cpp:241]     Train net output #0: loss = 1.47398 (* 1 = 1.47398 loss)
I1030 01:04:54.128995 27430 sgd_solver.cpp:105] Iteration 17080, lr = 0.00120312
I1030 01:05:24.100183 27430 solver.cpp:222] Iteration 17120 (1.33464 iter/s, 29.9706s/40 iters), loss = 1.48087
I1030 01:05:24.100713 27430 solver.cpp:241]     Train net output #0: loss = 1.48087 (* 1 = 1.48087 loss)
I1030 01:05:24.100745 27430 sgd_solver.cpp:105] Iteration 17120, lr = 0.00119716
I1030 01:05:54.228907 27430 solver.cpp:222] Iteration 17160 (1.32769 iter/s, 30.1275s/40 iters), loss = 1.32098
I1030 01:05:54.229419 27430 solver.cpp:241]     Train net output #0: loss = 1.32098 (* 1 = 1.32098 loss)
I1030 01:05:54.229470 27430 sgd_solver.cpp:105] Iteration 17160, lr = 0.00119124
I1030 01:06:24.212797 27430 solver.cpp:222] Iteration 17200 (1.3341 iter/s, 29.9827s/40 iters), loss = 1.25806
I1030 01:06:24.213249 27430 solver.cpp:241]     Train net output #0: loss = 1.25806 (* 1 = 1.25806 loss)
I1030 01:06:24.213301 27430 sgd_solver.cpp:105] Iteration 17200, lr = 0.00118535
I1030 01:07:05.176966 27430 solver.cpp:222] Iteration 17240 (0.976496 iter/s, 40.9628s/40 iters), loss = 1.57558
I1030 01:07:05.177518 27430 solver.cpp:241]     Train net output #0: loss = 1.57558 (* 1 = 1.57558 loss)
I1030 01:07:05.177567 27430 sgd_solver.cpp:105] Iteration 17240, lr = 0.00117948
I1030 01:07:35.541872 27430 solver.cpp:222] Iteration 17280 (1.31736 iter/s, 30.3637s/40 iters), loss = 1.19264
I1030 01:07:35.542048 27430 solver.cpp:241]     Train net output #0: loss = 1.19264 (* 1 = 1.19264 loss)
I1030 01:07:35.542062 27430 sgd_solver.cpp:105] Iteration 17280, lr = 0.00117365
I1030 01:08:05.510676 27430 solver.cpp:222] Iteration 17320 (1.33476 iter/s, 29.9679s/40 iters), loss = 1.26904
I1030 01:08:05.511093 27430 solver.cpp:241]     Train net output #0: loss = 1.26904 (* 1 = 1.26904 loss)
I1030 01:08:05.511127 27430 sgd_solver.cpp:105] Iteration 17320, lr = 0.00116784
I1030 01:08:36.600015 27430 solver.cpp:222] Iteration 17360 (1.28666 iter/s, 31.0882s/40 iters), loss = 1.30363
I1030 01:08:36.600574 27430 solver.cpp:241]     Train net output #0: loss = 1.30363 (* 1 = 1.30363 loss)
I1030 01:08:36.600597 27430 sgd_solver.cpp:105] Iteration 17360, lr = 0.00116207
I1030 01:09:07.950122 27430 solver.cpp:222] Iteration 17400 (1.27597 iter/s, 31.3488s/40 iters), loss = 1.4739
I1030 01:09:07.950366 27430 solver.cpp:241]     Train net output #0: loss = 1.4739 (* 1 = 1.4739 loss)
I1030 01:09:07.950395 27430 sgd_solver.cpp:105] Iteration 17400, lr = 0.00115632
I1030 01:09:38.439664 27430 solver.cpp:222] Iteration 17440 (1.31197 iter/s, 30.4886s/40 iters), loss = 1.28757
I1030 01:09:38.439873 27430 solver.cpp:241]     Train net output #0: loss = 1.28757 (* 1 = 1.28757 loss)
I1030 01:09:38.439888 27430 sgd_solver.cpp:105] Iteration 17440, lr = 0.0011506
I1030 01:10:07.905400 27430 solver.cpp:222] Iteration 17480 (1.35755 iter/s, 29.4648s/40 iters), loss = 1.59527
I1030 01:10:07.905776 27430 solver.cpp:241]     Train net output #0: loss = 1.59527 (* 1 = 1.59527 loss)
I1030 01:10:07.905823 27430 sgd_solver.cpp:105] Iteration 17480, lr = 0.0011449
I1030 01:10:21.912835 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_17500.caffemodel
I1030 01:10:22.054024 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_17500.solverstate
I1030 01:10:22.173110 27430 solver.cpp:334] Iteration 17500, Testing net (#0)
I1030 01:10:53.205804 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1030 01:10:53.412869 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58448
I1030 01:10:53.412933 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.811479
I1030 01:10:53.412945 27430 solver.cpp:401]     Test net output #2: loss = 1.85338 (* 1 = 1.85338 loss)
I1030 01:11:06.296475 27479 data_layer.cpp:73] Restarting data prefetching from start.
I1030 01:11:10.838698 27430 solver.cpp:222] Iteration 17520 (0.635612 iter/s, 62.9315s/40 iters), loss = 1.39697
I1030 01:11:10.838754 27430 solver.cpp:241]     Train net output #0: loss = 1.39697 (* 1 = 1.39697 loss)
I1030 01:11:10.838768 27430 sgd_solver.cpp:105] Iteration 17520, lr = 0.00113924
I1030 01:11:40.938542 27430 solver.cpp:222] Iteration 17560 (1.32895 iter/s, 30.0991s/40 iters), loss = 1.70609
I1030 01:11:40.939208 27430 solver.cpp:241]     Train net output #0: loss = 1.70609 (* 1 = 1.70609 loss)
I1030 01:11:40.939287 27430 sgd_solver.cpp:105] Iteration 17560, lr = 0.0011336
I1030 01:12:13.512728 27430 solver.cpp:222] Iteration 17600 (1.22802 iter/s, 32.5728s/40 iters), loss = 1.13888
I1030 01:12:13.513301 27430 solver.cpp:241]     Train net output #0: loss = 1.13888 (* 1 = 1.13888 loss)
I1030 01:12:13.513345 27430 sgd_solver.cpp:105] Iteration 17600, lr = 0.001128
I1030 01:12:43.027223 27430 solver.cpp:222] Iteration 17640 (1.35532 iter/s, 29.5132s/40 iters), loss = 1.4587
I1030 01:12:43.027691 27430 solver.cpp:241]     Train net output #0: loss = 1.4587 (* 1 = 1.4587 loss)
I1030 01:12:43.027740 27430 sgd_solver.cpp:105] Iteration 17640, lr = 0.00112242
I1030 01:13:12.933151 27430 solver.cpp:222] Iteration 17680 (1.33758 iter/s, 29.9048s/40 iters), loss = 1.59682
I1030 01:13:12.933765 27430 solver.cpp:241]     Train net output #0: loss = 1.59682 (* 1 = 1.59682 loss)
I1030 01:13:12.933811 27430 sgd_solver.cpp:105] Iteration 17680, lr = 0.00111686
I1030 01:13:42.701030 27430 solver.cpp:222] Iteration 17720 (1.34379 iter/s, 29.7666s/40 iters), loss = 1.31496
I1030 01:13:42.701485 27430 solver.cpp:241]     Train net output #0: loss = 1.31496 (* 1 = 1.31496 loss)
I1030 01:13:42.701531 27430 sgd_solver.cpp:105] Iteration 17720, lr = 0.00111134
I1030 01:14:12.605854 27430 solver.cpp:222] Iteration 17760 (1.33763 iter/s, 29.9037s/40 iters), loss = 1.76249
I1030 01:14:12.606477 27430 solver.cpp:241]     Train net output #0: loss = 1.76249 (* 1 = 1.76249 loss)
I1030 01:14:12.606530 27430 sgd_solver.cpp:105] Iteration 17760, lr = 0.00110584
I1030 01:15:18.749390 27430 solver.cpp:222] Iteration 17800 (0.604765 iter/s, 66.1414s/40 iters), loss = 1.02521
I1030 01:15:18.749996 27430 solver.cpp:241]     Train net output #0: loss = 1.02521 (* 1 = 1.02521 loss)
I1030 01:15:18.750030 27430 sgd_solver.cpp:105] Iteration 17800, lr = 0.00110037
I1030 01:15:49.594794 27430 solver.cpp:222] Iteration 17840 (1.29684 iter/s, 30.8441s/40 iters), loss = 1.37863
I1030 01:15:49.595165 27430 solver.cpp:241]     Train net output #0: loss = 1.37863 (* 1 = 1.37863 loss)
I1030 01:15:49.595180 27430 sgd_solver.cpp:105] Iteration 17840, lr = 0.00109493
I1030 01:16:20.223242 27430 solver.cpp:222] Iteration 17880 (1.30602 iter/s, 30.6274s/40 iters), loss = 1.42374
I1030 01:16:20.223443 27430 solver.cpp:241]     Train net output #0: loss = 1.42374 (* 1 = 1.42374 loss)
I1030 01:16:20.223457 27430 sgd_solver.cpp:105] Iteration 17880, lr = 0.00108951
I1030 01:16:49.966320 27430 solver.cpp:222] Iteration 17920 (1.34489 iter/s, 29.7422s/40 iters), loss = 1.28834
I1030 01:16:49.966773 27430 solver.cpp:241]     Train net output #0: loss = 1.28834 (* 1 = 1.28834 loss)
I1030 01:16:49.966820 27430 sgd_solver.cpp:105] Iteration 17920, lr = 0.00108412
I1030 01:17:19.224756 27430 solver.cpp:222] Iteration 17960 (1.36718 iter/s, 29.2573s/40 iters), loss = 1.64715
I1030 01:17:19.225307 27430 solver.cpp:241]     Train net output #0: loss = 1.64715 (* 1 = 1.64715 loss)
I1030 01:17:19.225363 27430 sgd_solver.cpp:105] Iteration 17960, lr = 0.00107876
I1030 01:17:48.007355 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_18000.caffemodel
I1030 01:17:48.154371 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_18000.solverstate
I1030 01:17:48.270963 27430 solver.cpp:334] Iteration 18000, Testing net (#0)
I1030 01:18:19.440284 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58628
I1030 01:18:19.440850 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.808319
I1030 01:18:19.440884 27430 solver.cpp:401]     Test net output #2: loss = 1.84299 (* 1 = 1.84299 loss)
I1030 01:18:20.210095 27430 solver.cpp:222] Iteration 18000 (0.655916 iter/s, 60.9834s/40 iters), loss = 1.26029
I1030 01:18:20.210150 27430 solver.cpp:241]     Train net output #0: loss = 1.26029 (* 1 = 1.26029 loss)
I1030 01:18:20.210161 27430 sgd_solver.cpp:105] Iteration 18000, lr = 0.00107342
I1030 01:18:50.612047 27430 solver.cpp:222] Iteration 18040 (1.31574 iter/s, 30.4012s/40 iters), loss = 1.19603
I1030 01:18:50.612237 27430 solver.cpp:241]     Train net output #0: loss = 1.19603 (* 1 = 1.19603 loss)
I1030 01:18:50.612252 27430 sgd_solver.cpp:105] Iteration 18040, lr = 0.00106811
I1030 01:19:20.087551 27430 solver.cpp:222] Iteration 18080 (1.3571 iter/s, 29.4746s/40 iters), loss = 1.36645
I1030 01:19:20.088110 27430 solver.cpp:241]     Train net output #0: loss = 1.36645 (* 1 = 1.36645 loss)
I1030 01:19:20.088161 27430 sgd_solver.cpp:105] Iteration 18080, lr = 0.00106282
I1030 01:19:49.734686 27430 solver.cpp:222] Iteration 18120 (1.34926 iter/s, 29.6459s/40 iters), loss = 1.3641
I1030 01:19:49.735205 27430 solver.cpp:241]     Train net output #0: loss = 1.3641 (* 1 = 1.3641 loss)
I1030 01:19:49.735249 27430 sgd_solver.cpp:105] Iteration 18120, lr = 0.00105757
I1030 01:20:58.329285 27430 solver.cpp:222] Iteration 18160 (0.583154 iter/s, 68.5925s/40 iters), loss = 1.47059
I1030 01:20:58.329812 27430 solver.cpp:241]     Train net output #0: loss = 1.47059 (* 1 = 1.47059 loss)
I1030 01:20:58.329864 27430 sgd_solver.cpp:105] Iteration 18160, lr = 0.00105233
I1030 01:21:28.126678 27430 solver.cpp:222] Iteration 18200 (1.34245 iter/s, 29.7962s/40 iters), loss = 1.19697
I1030 01:21:28.127094 27430 solver.cpp:241]     Train net output #0: loss = 1.19697 (* 1 = 1.19697 loss)
I1030 01:21:28.127133 27430 sgd_solver.cpp:105] Iteration 18200, lr = 0.00104713
I1030 01:21:57.746436 27430 solver.cpp:222] Iteration 18240 (1.3505 iter/s, 29.6187s/40 iters), loss = 1.23627
I1030 01:21:57.747045 27430 solver.cpp:241]     Train net output #0: loss = 1.23627 (* 1 = 1.23627 loss)
I1030 01:21:57.747107 27430 sgd_solver.cpp:105] Iteration 18240, lr = 0.00104195
I1030 01:22:28.660770 27430 solver.cpp:222] Iteration 18280 (1.29395 iter/s, 30.913s/40 iters), loss = 1.67454
I1030 01:22:28.660939 27430 solver.cpp:241]     Train net output #0: loss = 1.67454 (* 1 = 1.67454 loss)
I1030 01:22:28.660953 27430 sgd_solver.cpp:105] Iteration 18280, lr = 0.00103679
I1030 01:22:58.475662 27430 solver.cpp:222] Iteration 18320 (1.34165 iter/s, 29.814s/40 iters), loss = 1.33062
I1030 01:22:58.476023 27430 solver.cpp:241]     Train net output #0: loss = 1.33062 (* 1 = 1.33062 loss)
I1030 01:22:58.476056 27430 sgd_solver.cpp:105] Iteration 18320, lr = 0.00103166
I1030 01:23:28.009881 27430 solver.cpp:222] Iteration 18360 (1.35441 iter/s, 29.5332s/40 iters), loss = 1.63935
I1030 01:23:28.010363 27430 solver.cpp:241]     Train net output #0: loss = 1.63935 (* 1 = 1.63935 loss)
I1030 01:23:28.010398 27430 sgd_solver.cpp:105] Iteration 18360, lr = 0.00102656
I1030 01:23:57.572681 27430 solver.cpp:222] Iteration 18400 (1.3531 iter/s, 29.5616s/40 iters), loss = 1.40131
I1030 01:23:57.573125 27430 solver.cpp:241]     Train net output #0: loss = 1.40131 (* 1 = 1.40131 loss)
I1030 01:23:57.573158 27430 sgd_solver.cpp:105] Iteration 18400, lr = 0.00102148
I1030 01:24:26.896155 27430 solver.cpp:222] Iteration 18440 (1.36415 iter/s, 29.3224s/40 iters), loss = 1.20958
I1030 01:24:26.896731 27430 solver.cpp:241]     Train net output #0: loss = 1.20958 (* 1 = 1.20958 loss)
I1030 01:24:26.896769 27430 sgd_solver.cpp:105] Iteration 18440, lr = 0.00101643
I1030 01:24:56.514799 27430 solver.cpp:222] Iteration 18480 (1.35056 iter/s, 29.6174s/40 iters), loss = 1.42962
I1030 01:24:56.515244 27430 solver.cpp:241]     Train net output #0: loss = 1.42962 (* 1 = 1.42962 loss)
I1030 01:24:56.515287 27430 sgd_solver.cpp:105] Iteration 18480, lr = 0.0010114
I1030 01:25:10.621587 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_18500.caffemodel
I1030 01:25:10.802470 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_18500.solverstate
I1030 01:25:10.920402 27430 solver.cpp:334] Iteration 18500, Testing net (#0)
I1030 01:25:42.213976 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1030 01:25:42.338461 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58324
I1030 01:25:42.338542 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.812279
I1030 01:25:42.338562 27430 solver.cpp:401]     Test net output #2: loss = 1.83999 (* 1 = 1.83999 loss)
I1030 01:25:58.177986 27430 solver.cpp:222] Iteration 18520 (0.648705 iter/s, 61.6613s/40 iters), loss = 1.49786
I1030 01:25:58.178436 27430 solver.cpp:241]     Train net output #0: loss = 1.49786 (* 1 = 1.49786 loss)
I1030 01:25:58.178485 27430 sgd_solver.cpp:105] Iteration 18520, lr = 0.0010064
I1030 01:26:27.477120 27430 solver.cpp:222] Iteration 18560 (1.36528 iter/s, 29.298s/40 iters), loss = 1.29231
I1030 01:26:27.477686 27430 solver.cpp:241]     Train net output #0: loss = 1.29231 (* 1 = 1.29231 loss)
I1030 01:26:27.477733 27430 sgd_solver.cpp:105] Iteration 18560, lr = 0.00100142
I1030 01:26:56.959504 27430 solver.cpp:222] Iteration 18600 (1.3568 iter/s, 29.4811s/40 iters), loss = 1.45743
I1030 01:26:56.960147 27430 solver.cpp:241]     Train net output #0: loss = 1.45743 (* 1 = 1.45743 loss)
I1030 01:26:56.960228 27430 sgd_solver.cpp:105] Iteration 18600, lr = 0.000996464
I1030 01:27:26.700498 27430 solver.cpp:222] Iteration 18640 (1.345 iter/s, 29.7397s/40 iters), loss = 1.45941
I1030 01:27:26.701090 27430 solver.cpp:241]     Train net output #0: loss = 1.45941 (* 1 = 1.45941 loss)
I1030 01:27:26.701138 27430 sgd_solver.cpp:105] Iteration 18640, lr = 0.000991534
I1030 01:27:56.224092 27430 solver.cpp:222] Iteration 18680 (1.35491 iter/s, 29.5223s/40 iters), loss = 1.63006
I1030 01:27:56.224550 27430 solver.cpp:241]     Train net output #0: loss = 1.63006 (* 1 = 1.63006 loss)
I1030 01:27:56.224597 27430 sgd_solver.cpp:105] Iteration 18680, lr = 0.000986629
I1030 01:28:32.528319 27430 solver.cpp:222] Iteration 18720 (1.10184 iter/s, 36.3029s/40 iters), loss = 1.70147
I1030 01:28:32.528972 27430 solver.cpp:241]     Train net output #0: loss = 1.70147 (* 1 = 1.70147 loss)
I1030 01:28:32.529045 27430 sgd_solver.cpp:105] Iteration 18720, lr = 0.000981748
I1030 01:29:14.616715 27430 solver.cpp:222] Iteration 18760 (0.950418 iter/s, 42.0868s/40 iters), loss = 1.5602
I1030 01:29:14.617260 27430 solver.cpp:241]     Train net output #0: loss = 1.5602 (* 1 = 1.5602 loss)
I1030 01:29:14.617298 27430 sgd_solver.cpp:105] Iteration 18760, lr = 0.000976891
I1030 01:29:52.438226 27430 solver.cpp:222] Iteration 18800 (1.05764 iter/s, 37.8201s/40 iters), loss = 1.58306
I1030 01:29:52.438797 27430 solver.cpp:241]     Train net output #0: loss = 1.58306 (* 1 = 1.58306 loss)
I1030 01:29:52.438838 27430 sgd_solver.cpp:105] Iteration 18800, lr = 0.000972058
I1030 01:30:22.997696 27430 solver.cpp:222] Iteration 18840 (1.30898 iter/s, 30.5582s/40 iters), loss = 1.30022
I1030 01:30:22.998250 27430 solver.cpp:241]     Train net output #0: loss = 1.30022 (* 1 = 1.30022 loss)
I1030 01:30:22.998293 27430 sgd_solver.cpp:105] Iteration 18840, lr = 0.000967249
I1030 01:30:53.706909 27430 solver.cpp:222] Iteration 18880 (1.30259 iter/s, 30.708s/40 iters), loss = 1.4464
I1030 01:30:53.707422 27430 solver.cpp:241]     Train net output #0: loss = 1.4464 (* 1 = 1.4464 loss)
I1030 01:30:53.707458 27430 sgd_solver.cpp:105] Iteration 18880, lr = 0.000962464
I1030 01:31:24.631122 27430 solver.cpp:222] Iteration 18920 (1.29354 iter/s, 30.923s/40 iters), loss = 1.04898
I1030 01:31:25.052366 27430 solver.cpp:241]     Train net output #0: loss = 1.04898 (* 1 = 1.04898 loss)
I1030 01:31:25.052444 27430 sgd_solver.cpp:105] Iteration 18920, lr = 0.000957703
I1030 01:31:54.726856 27430 solver.cpp:222] Iteration 18960 (1.34799 iter/s, 29.6738s/40 iters), loss = 1.6616
I1030 01:31:54.727331 27430 solver.cpp:241]     Train net output #0: loss = 1.6616 (* 1 = 1.6616 loss)
I1030 01:31:54.727383 27430 sgd_solver.cpp:105] Iteration 18960, lr = 0.000952965
I1030 01:32:23.570945 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_19000.caffemodel
I1030 01:32:23.745040 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_19000.solverstate
I1030 01:32:23.860479 27430 solver.cpp:334] Iteration 19000, Testing net (#0)
I1030 01:32:55.060467 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58728
I1030 01:32:55.060883 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8084
I1030 01:32:55.061206 27430 solver.cpp:401]     Test net output #2: loss = 1.84534 (* 1 = 1.84534 loss)
I1030 01:32:55.812368 27430 solver.cpp:222] Iteration 19000 (0.65484 iter/s, 61.0836s/40 iters), loss = 1.32469
I1030 01:32:55.812430 27430 solver.cpp:241]     Train net output #0: loss = 1.32469 (* 1 = 1.32469 loss)
I1030 01:32:55.812443 27430 sgd_solver.cpp:105] Iteration 19000, lr = 0.000948251
I1030 01:33:25.360147 27430 solver.cpp:222] Iteration 19040 (1.35378 iter/s, 29.547s/40 iters), loss = 1.26635
I1030 01:33:25.360651 27430 solver.cpp:241]     Train net output #0: loss = 1.26635 (* 1 = 1.26635 loss)
I1030 01:33:25.360693 27430 sgd_solver.cpp:105] Iteration 19040, lr = 0.000943559
I1030 01:34:14.735222 27430 solver.cpp:222] Iteration 19080 (0.810152 iter/s, 49.3734s/40 iters), loss = 1.27216
I1030 01:34:14.735816 27430 solver.cpp:241]     Train net output #0: loss = 1.27216 (* 1 = 1.27216 loss)
I1030 01:34:14.735870 27430 sgd_solver.cpp:105] Iteration 19080, lr = 0.000938891
I1030 01:34:49.704422 27430 solver.cpp:222] Iteration 19120 (1.14391 iter/s, 34.9678s/40 iters), loss = 1.36416
I1030 01:34:49.704907 27430 solver.cpp:241]     Train net output #0: loss = 1.36416 (* 1 = 1.36416 loss)
I1030 01:34:49.705214 27430 sgd_solver.cpp:105] Iteration 19120, lr = 0.000934247
I1030 01:35:21.773731 27430 solver.cpp:222] Iteration 19160 (1.24735 iter/s, 32.0681s/40 iters), loss = 1.30373
I1030 01:35:21.774318 27430 solver.cpp:241]     Train net output #0: loss = 1.30373 (* 1 = 1.30373 loss)
I1030 01:35:21.774364 27430 sgd_solver.cpp:105] Iteration 19160, lr = 0.000929625
I1030 01:35:52.371572 27430 solver.cpp:222] Iteration 19200 (1.30734 iter/s, 30.5966s/40 iters), loss = 1.16469
I1030 01:35:52.372114 27430 solver.cpp:241]     Train net output #0: loss = 1.16469 (* 1 = 1.16469 loss)
I1030 01:35:52.372159 27430 sgd_solver.cpp:105] Iteration 19200, lr = 0.000925026
I1030 01:36:21.795734 27430 solver.cpp:222] Iteration 19240 (1.35948 iter/s, 29.423s/40 iters), loss = 1.3805
I1030 01:36:21.796183 27430 solver.cpp:241]     Train net output #0: loss = 1.3805 (* 1 = 1.3805 loss)
I1030 01:36:21.796217 27430 sgd_solver.cpp:105] Iteration 19240, lr = 0.00092045
I1030 01:36:51.180440 27430 solver.cpp:222] Iteration 19280 (1.3613 iter/s, 29.3836s/40 iters), loss = 1.2476
I1030 01:36:51.181040 27430 solver.cpp:241]     Train net output #0: loss = 1.2476 (* 1 = 1.2476 loss)
I1030 01:36:51.181087 27430 sgd_solver.cpp:105] Iteration 19280, lr = 0.000915896
I1030 01:37:20.559139 27430 solver.cpp:222] Iteration 19320 (1.36159 iter/s, 29.3774s/40 iters), loss = 1.61873
I1030 01:37:20.559582 27430 solver.cpp:241]     Train net output #0: loss = 1.61873 (* 1 = 1.61873 loss)
I1030 01:37:20.559640 27430 sgd_solver.cpp:105] Iteration 19320, lr = 0.000911365
I1030 01:37:50.064422 27430 solver.cpp:222] Iteration 19360 (1.35574 iter/s, 29.5042s/40 iters), loss = 1.40735
I1030 01:37:50.065212 27430 solver.cpp:241]     Train net output #0: loss = 1.40735 (* 1 = 1.40735 loss)
I1030 01:37:50.065265 27430 sgd_solver.cpp:105] Iteration 19360, lr = 0.000906856
I1030 01:38:19.833727 27430 solver.cpp:222] Iteration 19400 (1.34373 iter/s, 29.7678s/40 iters), loss = 1.36989
I1030 01:38:19.834192 27430 solver.cpp:241]     Train net output #0: loss = 1.36989 (* 1 = 1.36989 loss)
I1030 01:38:19.834242 27430 sgd_solver.cpp:105] Iteration 19400, lr = 0.00090237
I1030 01:38:49.206513 27430 solver.cpp:222] Iteration 19440 (1.36186 iter/s, 29.3717s/40 iters), loss = 1.72783
I1030 01:38:49.207154 27430 solver.cpp:241]     Train net output #0: loss = 1.72783 (* 1 = 1.72783 loss)
I1030 01:38:49.207198 27430 sgd_solver.cpp:105] Iteration 19440, lr = 0.000897906
I1030 01:39:19.071494 27430 solver.cpp:222] Iteration 19480 (1.33942 iter/s, 29.8637s/40 iters), loss = 1.05076
I1030 01:39:19.071888 27430 solver.cpp:241]     Train net output #0: loss = 1.05076 (* 1 = 1.05076 loss)
I1030 01:39:19.072049 27430 sgd_solver.cpp:105] Iteration 19480, lr = 0.000893464
I1030 01:39:33.406836 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_19500.caffemodel
I1030 01:39:33.552873 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_19500.solverstate
I1030 01:39:33.667847 27430 solver.cpp:334] Iteration 19500, Testing net (#0)
I1030 01:40:04.606539 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1030 01:40:04.814316 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58352
I1030 01:40:04.814366 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813079
I1030 01:40:04.814378 27430 solver.cpp:401]     Test net output #2: loss = 1.84116 (* 1 = 1.84116 loss)
I1030 01:40:20.328194 27430 solver.cpp:222] Iteration 19520 (0.653009 iter/s, 61.2549s/40 iters), loss = 1.57567
I1030 01:40:20.328621 27430 solver.cpp:241]     Train net output #0: loss = 1.57567 (* 1 = 1.57567 loss)
I1030 01:40:20.328668 27430 sgd_solver.cpp:105] Iteration 19520, lr = 0.000889044
I1030 01:40:49.947948 27430 solver.cpp:222] Iteration 19560 (1.3505 iter/s, 29.6187s/40 iters), loss = 1.19759
I1030 01:40:49.948565 27430 solver.cpp:241]     Train net output #0: loss = 1.19759 (* 1 = 1.19759 loss)
I1030 01:40:49.948611 27430 sgd_solver.cpp:105] Iteration 19560, lr = 0.000884645
I1030 01:41:19.715948 27430 solver.cpp:222] Iteration 19600 (1.34378 iter/s, 29.7667s/40 iters), loss = 1.42997
I1030 01:41:19.716385 27430 solver.cpp:241]     Train net output #0: loss = 1.42997 (* 1 = 1.42997 loss)
I1030 01:41:19.716434 27430 sgd_solver.cpp:105] Iteration 19600, lr = 0.000880269
I1030 01:41:49.169515 27430 solver.cpp:222] Iteration 19640 (1.35812 iter/s, 29.4524s/40 iters), loss = 1.52578
I1030 01:41:49.170003 27430 solver.cpp:241]     Train net output #0: loss = 1.52578 (* 1 = 1.52578 loss)
I1030 01:41:49.170038 27430 sgd_solver.cpp:105] Iteration 19640, lr = 0.000875914
I1030 01:42:18.769830 27430 solver.cpp:222] Iteration 19680 (1.35139 iter/s, 29.5991s/40 iters), loss = 1.42476
I1030 01:42:18.770237 27430 solver.cpp:241]     Train net output #0: loss = 1.42476 (* 1 = 1.42476 loss)
I1030 01:42:18.770273 27430 sgd_solver.cpp:105] Iteration 19680, lr = 0.000871581
I1030 01:42:48.075182 27430 solver.cpp:222] Iteration 19720 (1.36499 iter/s, 29.3043s/40 iters), loss = 1.659
I1030 01:42:48.075696 27430 solver.cpp:241]     Train net output #0: loss = 1.659 (* 1 = 1.659 loss)
I1030 01:42:48.075731 27430 sgd_solver.cpp:105] Iteration 19720, lr = 0.000867269
I1030 01:43:18.196517 27430 solver.cpp:222] Iteration 19760 (1.32802 iter/s, 30.1201s/40 iters), loss = 1.24352
I1030 01:43:18.196655 27430 solver.cpp:241]     Train net output #0: loss = 1.24352 (* 1 = 1.24352 loss)
I1030 01:43:18.196668 27430 sgd_solver.cpp:105] Iteration 19760, lr = 0.000862979
I1030 01:43:47.715751 27430 solver.cpp:222] Iteration 19800 (1.35509 iter/s, 29.5184s/40 iters), loss = 1.65859
I1030 01:43:47.716171 27430 solver.cpp:241]     Train net output #0: loss = 1.65859 (* 1 = 1.65859 loss)
I1030 01:43:47.716226 27430 sgd_solver.cpp:105] Iteration 19800, lr = 0.000858709
I1030 01:44:17.075242 27430 solver.cpp:222] Iteration 19840 (1.36247 iter/s, 29.3584s/40 iters), loss = 1.50352
I1030 01:44:17.075887 27430 solver.cpp:241]     Train net output #0: loss = 1.50352 (* 1 = 1.50352 loss)
I1030 01:44:17.076021 27430 sgd_solver.cpp:105] Iteration 19840, lr = 0.000854461
I1030 01:44:46.501925 27430 solver.cpp:222] Iteration 19880 (1.35937 iter/s, 29.4254s/40 iters), loss = 1.50568
I1030 01:44:46.502399 27430 solver.cpp:241]     Train net output #0: loss = 1.50568 (* 1 = 1.50568 loss)
I1030 01:44:46.502450 27430 sgd_solver.cpp:105] Iteration 19880, lr = 0.000850234
I1030 01:45:15.879231 27430 solver.cpp:222] Iteration 19920 (1.36165 iter/s, 29.3762s/40 iters), loss = 1.37074
I1030 01:45:15.879811 27430 solver.cpp:241]     Train net output #0: loss = 1.37074 (* 1 = 1.37074 loss)
I1030 01:45:15.879858 27430 sgd_solver.cpp:105] Iteration 19920, lr = 0.000846028
I1030 01:45:45.450510 27430 solver.cpp:222] Iteration 19960 (1.35272 iter/s, 29.57s/40 iters), loss = 1.53663
I1030 01:45:45.451056 27430 solver.cpp:241]     Train net output #0: loss = 1.53663 (* 1 = 1.53663 loss)
I1030 01:45:45.451105 27430 sgd_solver.cpp:105] Iteration 19960, lr = 0.000841842
I1030 01:46:20.872603 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_20000.caffemodel
I1030 01:46:21.019325 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_20000.solverstate
I1030 01:46:21.144556 27430 solver.cpp:334] Iteration 20000, Testing net (#0)
I1030 01:46:52.415933 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58612
I1030 01:46:52.416082 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80856
I1030 01:46:52.416098 27430 solver.cpp:401]     Test net output #2: loss = 1.84354 (* 1 = 1.84354 loss)
I1030 01:46:53.167284 27430 solver.cpp:222] Iteration 20000 (0.590714 iter/s, 67.7147s/40 iters), loss = 2.05241
I1030 01:46:53.167326 27430 solver.cpp:241]     Train net output #0: loss = 2.05241 (* 1 = 2.05241 loss)
I1030 01:46:53.167342 27430 sgd_solver.cpp:105] Iteration 20000, lr = 0.000837678
I1030 01:47:03.833683 27479 data_layer.cpp:73] Restarting data prefetching from start.
I1030 01:47:23.324049 27430 solver.cpp:222] Iteration 20040 (1.32644 iter/s, 30.156s/40 iters), loss = 1.3658
I1030 01:47:23.324529 27430 solver.cpp:241]     Train net output #0: loss = 1.3658 (* 1 = 1.3658 loss)
I1030 01:47:23.324581 27430 sgd_solver.cpp:105] Iteration 20040, lr = 0.000833534
I1030 01:47:54.065367 27430 solver.cpp:222] Iteration 20080 (1.30123 iter/s, 30.7401s/40 iters), loss = 1.30701
I1030 01:47:54.065536 27430 solver.cpp:241]     Train net output #0: loss = 1.30701 (* 1 = 1.30701 loss)
I1030 01:47:54.065551 27430 sgd_solver.cpp:105] Iteration 20080, lr = 0.00082941
I1030 01:48:23.713531 27430 solver.cpp:222] Iteration 20120 (1.3492 iter/s, 29.6473s/40 iters), loss = 1.46648
I1030 01:48:23.714110 27430 solver.cpp:241]     Train net output #0: loss = 1.46648 (* 1 = 1.46648 loss)
I1030 01:48:23.714164 27430 sgd_solver.cpp:105] Iteration 20120, lr = 0.000825307
I1030 01:48:54.102665 27430 solver.cpp:222] Iteration 20160 (1.31632 iter/s, 30.3879s/40 iters), loss = 1.22985
I1030 01:48:54.103269 27430 solver.cpp:241]     Train net output #0: loss = 1.22985 (* 1 = 1.22985 loss)
I1030 01:48:54.103315 27430 sgd_solver.cpp:105] Iteration 20160, lr = 0.000821224
I1030 01:49:32.495141 27430 solver.cpp:222] Iteration 20200 (1.04191 iter/s, 38.391s/40 iters), loss = 1.38404
I1030 01:49:32.495745 27430 solver.cpp:241]     Train net output #0: loss = 1.38404 (* 1 = 1.38404 loss)
I1030 01:49:32.495785 27430 sgd_solver.cpp:105] Iteration 20200, lr = 0.000817161
I1030 01:50:03.089982 27430 solver.cpp:222] Iteration 20240 (1.30747 iter/s, 30.5935s/40 iters), loss = 1.45342
I1030 01:50:03.090178 27430 solver.cpp:241]     Train net output #0: loss = 1.45342 (* 1 = 1.45342 loss)
I1030 01:50:03.090191 27430 sgd_solver.cpp:105] Iteration 20240, lr = 0.000813119
I1030 01:50:32.784165 27430 solver.cpp:222] Iteration 20280 (1.34711 iter/s, 29.6933s/40 iters), loss = 1.47332
I1030 01:50:32.784688 27430 solver.cpp:241]     Train net output #0: loss = 1.47332 (* 1 = 1.47332 loss)
I1030 01:50:32.784739 27430 sgd_solver.cpp:105] Iteration 20280, lr = 0.000809096
I1030 01:51:02.484004 27430 solver.cpp:222] Iteration 20320 (1.34686 iter/s, 29.6986s/40 iters), loss = 1.35485
I1030 01:51:02.484664 27430 solver.cpp:241]     Train net output #0: loss = 1.35485 (* 1 = 1.35485 loss)
I1030 01:51:02.484710 27430 sgd_solver.cpp:105] Iteration 20320, lr = 0.000805093
I1030 01:51:32.948796 27430 solver.cpp:222] Iteration 20360 (1.31305 iter/s, 30.4634s/40 iters), loss = 1.22674
I1030 01:51:32.949463 27430 solver.cpp:241]     Train net output #0: loss = 1.22674 (* 1 = 1.22674 loss)
I1030 01:51:32.949515 27430 sgd_solver.cpp:105] Iteration 20360, lr = 0.00080111
I1030 01:52:02.614588 27430 solver.cpp:222] Iteration 20400 (1.34842 iter/s, 29.6644s/40 iters), loss = 1.49122
I1030 01:52:02.615061 27430 solver.cpp:241]     Train net output #0: loss = 1.49122 (* 1 = 1.49122 loss)
I1030 01:52:02.615103 27430 sgd_solver.cpp:105] Iteration 20400, lr = 0.000797147
I1030 01:52:32.474073 27430 solver.cpp:222] Iteration 20440 (1.33966 iter/s, 29.8583s/40 iters), loss = 1.11332
I1030 01:52:32.474684 27430 solver.cpp:241]     Train net output #0: loss = 1.11332 (* 1 = 1.11332 loss)
I1030 01:52:32.474733 27430 sgd_solver.cpp:105] Iteration 20440, lr = 0.000793204
I1030 01:53:03.109155 27430 solver.cpp:222] Iteration 20480 (1.30575 iter/s, 30.6338s/40 iters), loss = 1.43087
I1030 01:53:03.109316 27430 solver.cpp:241]     Train net output #0: loss = 1.43087 (* 1 = 1.43087 loss)
I1030 01:53:03.109333 27430 sgd_solver.cpp:105] Iteration 20480, lr = 0.000789279
I1030 01:53:17.473950 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_20500.caffemodel
I1030 01:53:18.974649 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_20500.solverstate
I1030 01:53:19.510344 27430 solver.cpp:334] Iteration 20500, Testing net (#0)
I1030 01:53:50.655180 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1030 01:53:50.865759 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58436
I1030 01:53:50.865800 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.812519
I1030 01:53:50.865810 27430 solver.cpp:401]     Test net output #2: loss = 1.84976 (* 1 = 1.84976 loss)
I1030 01:54:06.574986 27430 solver.cpp:222] Iteration 20520 (0.630277 iter/s, 63.4642s/40 iters), loss = 1.48161
I1030 01:54:06.575392 27430 solver.cpp:241]     Train net output #0: loss = 1.48161 (* 1 = 1.48161 loss)
I1030 01:54:06.575429 27430 sgd_solver.cpp:105] Iteration 20520, lr = 0.000785375
I1030 01:54:36.624738 27430 solver.cpp:222] Iteration 20560 (1.33117 iter/s, 30.0487s/40 iters), loss = 1.06957
I1030 01:54:36.625238 27430 solver.cpp:241]     Train net output #0: loss = 1.06957 (* 1 = 1.06957 loss)
I1030 01:54:36.625278 27430 sgd_solver.cpp:105] Iteration 20560, lr = 0.000781489
I1030 01:55:06.921727 27430 solver.cpp:222] Iteration 20600 (1.32032 iter/s, 30.2958s/40 iters), loss = 1.23873
I1030 01:55:06.922271 27430 solver.cpp:241]     Train net output #0: loss = 1.23873 (* 1 = 1.23873 loss)
I1030 01:55:06.922307 27430 sgd_solver.cpp:105] Iteration 20600, lr = 0.000777623
I1030 01:55:38.119554 27430 solver.cpp:222] Iteration 20640 (1.28219 iter/s, 31.1966s/40 iters), loss = 1.36568
I1030 01:55:38.120110 27430 solver.cpp:241]     Train net output #0: loss = 1.36568 (* 1 = 1.36568 loss)
I1030 01:55:38.120152 27430 sgd_solver.cpp:105] Iteration 20640, lr = 0.000773776
I1030 01:56:08.059736 27430 solver.cpp:222] Iteration 20680 (1.33605 iter/s, 29.9389s/40 iters), loss = 1.74484
I1030 01:56:08.060142 27430 solver.cpp:241]     Train net output #0: loss = 1.74484 (* 1 = 1.74484 loss)
I1030 01:56:08.060179 27430 sgd_solver.cpp:105] Iteration 20680, lr = 0.000769948
I1030 01:56:37.948635 27430 solver.cpp:222] Iteration 20720 (1.33834 iter/s, 29.8878s/40 iters), loss = 0.964575
I1030 01:56:37.949280 27430 solver.cpp:241]     Train net output #0: loss = 0.964575 (* 1 = 0.964575 loss)
I1030 01:56:37.949340 27430 sgd_solver.cpp:105] Iteration 20720, lr = 0.000766139
I1030 01:57:07.602268 27430 solver.cpp:222] Iteration 20760 (1.34897 iter/s, 29.6523s/40 iters), loss = 1.31063
I1030 01:57:07.602687 27430 solver.cpp:241]     Train net output #0: loss = 1.31063 (* 1 = 1.31063 loss)
I1030 01:57:07.602738 27430 sgd_solver.cpp:105] Iteration 20760, lr = 0.000762349
I1030 01:57:38.256819 27430 solver.cpp:222] Iteration 20800 (1.30491 iter/s, 30.6534s/40 iters), loss = 1.43614
I1030 01:57:38.257380 27430 solver.cpp:241]     Train net output #0: loss = 1.43614 (* 1 = 1.43614 loss)
I1030 01:57:38.257417 27430 sgd_solver.cpp:105] Iteration 20800, lr = 0.000758578
I1030 01:58:08.469215 27430 solver.cpp:222] Iteration 20840 (1.32402 iter/s, 30.2111s/40 iters), loss = 1.29015
I1030 01:58:08.469771 27430 solver.cpp:241]     Train net output #0: loss = 1.29015 (* 1 = 1.29015 loss)
I1030 01:58:08.469825 27430 sgd_solver.cpp:105] Iteration 20840, lr = 0.000754825
I1030 01:58:38.865795 27430 solver.cpp:222] Iteration 20880 (1.31599 iter/s, 30.3953s/40 iters), loss = 1.48632
I1030 01:58:38.866464 27430 solver.cpp:241]     Train net output #0: loss = 1.48632 (* 1 = 1.48632 loss)
I1030 01:58:38.866556 27430 sgd_solver.cpp:105] Iteration 20880, lr = 0.000751091
I1030 01:59:15.097594 27430 solver.cpp:222] Iteration 20920 (1.10405 iter/s, 36.2303s/40 iters), loss = 1.26884
I1030 01:59:15.098173 27430 solver.cpp:241]     Train net output #0: loss = 1.26884 (* 1 = 1.26884 loss)
I1030 01:59:15.098222 27430 sgd_solver.cpp:105] Iteration 20920, lr = 0.000747375
I1030 01:59:45.814604 27430 solver.cpp:222] Iteration 20960 (1.30226 iter/s, 30.7157s/40 iters), loss = 1.33917
I1030 01:59:45.815212 27430 solver.cpp:241]     Train net output #0: loss = 1.33917 (* 1 = 1.33917 loss)
I1030 01:59:45.815264 27430 sgd_solver.cpp:105] Iteration 20960, lr = 0.000743677
I1030 02:00:14.682307 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_21000.caffemodel
I1030 02:00:14.826354 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_21000.solverstate
I1030 02:00:14.939729 27430 solver.cpp:334] Iteration 21000, Testing net (#0)
I1030 02:00:46.124755 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58696
I1030 02:00:46.125351 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80868
I1030 02:00:46.125378 27430 solver.cpp:401]     Test net output #2: loss = 1.83463 (* 1 = 1.83463 loss)
I1030 02:00:46.889001 27430 solver.cpp:222] Iteration 21000 (0.65496 iter/s, 61.0724s/40 iters), loss = 1.64434
I1030 02:00:46.889051 27430 solver.cpp:241]     Train net output #0: loss = 1.64434 (* 1 = 1.64434 loss)
I1030 02:00:46.889063 27430 sgd_solver.cpp:105] Iteration 21000, lr = 0.000739998
I1030 02:01:16.928593 27430 solver.cpp:222] Iteration 21040 (1.33161 iter/s, 30.0388s/40 iters), loss = 1.45401
I1030 02:01:16.928771 27430 solver.cpp:241]     Train net output #0: loss = 1.45401 (* 1 = 1.45401 loss)
I1030 02:01:16.928786 27430 sgd_solver.cpp:105] Iteration 21040, lr = 0.000736338
I1030 02:01:46.534618 27430 solver.cpp:222] Iteration 21080 (1.35112 iter/s, 29.6051s/40 iters), loss = 1.61293
I1030 02:01:46.535048 27430 solver.cpp:241]     Train net output #0: loss = 1.61293 (* 1 = 1.61293 loss)
I1030 02:01:46.535092 27430 sgd_solver.cpp:105] Iteration 21080, lr = 0.000732695
I1030 02:02:16.801534 27430 solver.cpp:222] Iteration 21120 (1.32162 iter/s, 30.2658s/40 iters), loss = 1.32929
I1030 02:02:16.802044 27430 solver.cpp:241]     Train net output #0: loss = 1.32929 (* 1 = 1.32929 loss)
I1030 02:02:16.802093 27430 sgd_solver.cpp:105] Iteration 21120, lr = 0.00072907
I1030 02:02:46.720901 27430 solver.cpp:222] Iteration 21160 (1.33698 iter/s, 29.9182s/40 iters), loss = 1.43628
I1030 02:02:46.721318 27430 solver.cpp:241]     Train net output #0: loss = 1.43628 (* 1 = 1.43628 loss)
I1030 02:02:46.721366 27430 sgd_solver.cpp:105] Iteration 21160, lr = 0.000725463
I1030 02:03:16.340035 27430 solver.cpp:222] Iteration 21200 (1.35053 iter/s, 29.618s/40 iters), loss = 1.48578
I1030 02:03:16.340665 27430 solver.cpp:241]     Train net output #0: loss = 1.48578 (* 1 = 1.48578 loss)
I1030 02:03:16.340714 27430 sgd_solver.cpp:105] Iteration 21200, lr = 0.000721874
I1030 02:03:46.688637 27430 solver.cpp:222] Iteration 21240 (1.31808 iter/s, 30.3473s/40 iters), loss = 1.20231
I1030 02:03:46.688823 27430 solver.cpp:241]     Train net output #0: loss = 1.20231 (* 1 = 1.20231 loss)
I1030 02:03:46.688838 27430 sgd_solver.cpp:105] Iteration 21240, lr = 0.000718303
I1030 02:04:15.847652 27430 solver.cpp:222] Iteration 21280 (1.37183 iter/s, 29.1581s/40 iters), loss = 1.54285
I1030 02:04:15.848083 27430 solver.cpp:241]     Train net output #0: loss = 1.54285 (* 1 = 1.54285 loss)
I1030 02:04:15.848125 27430 sgd_solver.cpp:105] Iteration 21280, lr = 0.00071475
I1030 02:04:46.656828 27430 solver.cpp:222] Iteration 21320 (1.29836 iter/s, 30.808s/40 iters), loss = 1.53521
I1030 02:04:46.657404 27430 solver.cpp:241]     Train net output #0: loss = 1.53521 (* 1 = 1.53521 loss)
I1030 02:04:46.657447 27430 sgd_solver.cpp:105] Iteration 21320, lr = 0.000711214
I1030 02:05:16.230538 27430 solver.cpp:222] Iteration 21360 (1.35261 iter/s, 29.5725s/40 iters), loss = 1.49802
I1030 02:05:16.231046 27430 solver.cpp:241]     Train net output #0: loss = 1.49802 (* 1 = 1.49802 loss)
I1030 02:05:16.231093 27430 sgd_solver.cpp:105] Iteration 21360, lr = 0.000707695
I1030 02:05:46.024178 27430 solver.cpp:222] Iteration 21400 (1.34262 iter/s, 29.7925s/40 iters), loss = 1.35973
I1030 02:05:46.024785 27430 solver.cpp:241]     Train net output #0: loss = 1.35973 (* 1 = 1.35973 loss)
I1030 02:05:46.024839 27430 sgd_solver.cpp:105] Iteration 21400, lr = 0.000704194
I1030 02:06:16.454344 27430 solver.cpp:222] Iteration 21440 (1.31454 iter/s, 30.4289s/40 iters), loss = 1.63739
I1030 02:06:16.454880 27430 solver.cpp:241]     Train net output #0: loss = 1.63739 (* 1 = 1.63739 loss)
I1030 02:06:16.454983 27430 sgd_solver.cpp:105] Iteration 21440, lr = 0.00070071
I1030 02:06:47.168881 27430 solver.cpp:222] Iteration 21480 (1.30237 iter/s, 30.7133s/40 iters), loss = 1.49501
I1030 02:06:47.169474 27430 solver.cpp:241]     Train net output #0: loss = 1.49501 (* 1 = 1.49501 loss)
I1030 02:06:47.169515 27430 sgd_solver.cpp:105] Iteration 21480, lr = 0.000697244
I1030 02:07:01.995151 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_21500.caffemodel
I1030 02:07:02.143527 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_21500.solverstate
I1030 02:07:02.264963 27430 solver.cpp:334] Iteration 21500, Testing net (#0)
I1030 02:07:33.287395 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1030 02:07:33.497018 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58436
I1030 02:07:33.497057 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.812479
I1030 02:07:33.497067 27430 solver.cpp:401]     Test net output #2: loss = 1.85039 (* 1 = 1.85039 loss)
I1030 02:07:54.793552 27430 solver.cpp:222] Iteration 21520 (0.591519 iter/s, 67.6225s/40 iters), loss = 1.47921
I1030 02:07:54.794155 27430 solver.cpp:241]     Train net output #0: loss = 1.47921 (* 1 = 1.47921 loss)
I1030 02:07:54.794211 27430 sgd_solver.cpp:105] Iteration 21520, lr = 0.000693794
I1030 02:08:24.922088 27430 solver.cpp:222] Iteration 21560 (1.3277 iter/s, 30.1273s/40 iters), loss = 1.44591
I1030 02:08:24.922282 27430 solver.cpp:241]     Train net output #0: loss = 1.44591 (* 1 = 1.44591 loss)
I1030 02:08:24.922297 27430 sgd_solver.cpp:105] Iteration 21560, lr = 0.000690362
I1030 02:08:54.673027 27430 solver.cpp:222] Iteration 21600 (1.34454 iter/s, 29.75s/40 iters), loss = 1.58989
I1030 02:08:54.673447 27430 solver.cpp:241]     Train net output #0: loss = 1.58989 (* 1 = 1.58989 loss)
I1030 02:08:54.673496 27430 sgd_solver.cpp:105] Iteration 21600, lr = 0.000686947
I1030 02:09:24.880496 27430 solver.cpp:222] Iteration 21640 (1.32422 iter/s, 30.2064s/40 iters), loss = 1.31047
I1030 02:09:24.881093 27430 solver.cpp:241]     Train net output #0: loss = 1.31047 (* 1 = 1.31047 loss)
I1030 02:09:24.881139 27430 sgd_solver.cpp:105] Iteration 21640, lr = 0.000683548
I1030 02:09:57.988116 27430 solver.cpp:222] Iteration 21680 (1.20823 iter/s, 33.1063s/40 iters), loss = 1.26164
I1030 02:09:57.988672 27430 solver.cpp:241]     Train net output #0: loss = 1.26164 (* 1 = 1.26164 loss)
I1030 02:09:57.988698 27430 sgd_solver.cpp:105] Iteration 21680, lr = 0.000680167
I1030 02:10:49.861434 27430 solver.cpp:222] Iteration 21720 (0.771136 iter/s, 51.8716s/40 iters), loss = 1.2791
I1030 02:10:49.862154 27430 solver.cpp:241]     Train net output #0: loss = 1.2791 (* 1 = 1.2791 loss)
I1030 02:10:49.862195 27430 sgd_solver.cpp:105] Iteration 21720, lr = 0.000676802
I1030 02:11:23.029062 27430 solver.cpp:222] Iteration 21760 (1.20605 iter/s, 33.1662s/40 iters), loss = 1.25351
I1030 02:11:23.029588 27430 solver.cpp:241]     Train net output #0: loss = 1.25351 (* 1 = 1.25351 loss)
I1030 02:11:23.029630 27430 sgd_solver.cpp:105] Iteration 21760, lr = 0.000673454
I1030 02:11:53.090598 27430 solver.cpp:222] Iteration 21800 (1.33066 iter/s, 30.0603s/40 iters), loss = 1.42397
I1030 02:11:53.090786 27430 solver.cpp:241]     Train net output #0: loss = 1.42397 (* 1 = 1.42397 loss)
I1030 02:11:53.090801 27430 sgd_solver.cpp:105] Iteration 21800, lr = 0.000670122
I1030 02:12:22.575214 27430 solver.cpp:222] Iteration 21840 (1.35668 iter/s, 29.4837s/40 iters), loss = 1.35774
I1030 02:12:22.575681 27430 solver.cpp:241]     Train net output #0: loss = 1.35774 (* 1 = 1.35774 loss)
I1030 02:12:22.575734 27430 sgd_solver.cpp:105] Iteration 21840, lr = 0.000666807
I1030 02:12:52.344856 27430 solver.cpp:222] Iteration 21880 (1.3437 iter/s, 29.7685s/40 iters), loss = 1.52223
I1030 02:12:52.345384 27430 solver.cpp:241]     Train net output #0: loss = 1.52223 (* 1 = 1.52223 loss)
I1030 02:12:52.345422 27430 sgd_solver.cpp:105] Iteration 21880, lr = 0.000663508
I1030 02:13:22.520202 27430 solver.cpp:222] Iteration 21920 (1.32564 iter/s, 30.1741s/40 iters), loss = 1.38322
I1030 02:13:22.520356 27430 solver.cpp:241]     Train net output #0: loss = 1.38322 (* 1 = 1.38322 loss)
I1030 02:13:22.520370 27430 sgd_solver.cpp:105] Iteration 21920, lr = 0.000660226
I1030 02:13:52.691762 27430 solver.cpp:222] Iteration 21960 (1.32579 iter/s, 30.1707s/40 iters), loss = 1.05381
I1030 02:13:52.691907 27430 solver.cpp:241]     Train net output #0: loss = 1.05381 (* 1 = 1.05381 loss)
I1030 02:13:52.691926 27430 sgd_solver.cpp:105] Iteration 21960, lr = 0.000656959
I1030 02:14:21.445591 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_22000.caffemodel
I1030 02:14:21.586129 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_22000.solverstate
I1030 02:14:21.691480 27430 solver.cpp:334] Iteration 22000, Testing net (#0)
I1030 02:14:52.835222 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5856
I1030 02:14:52.835652 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80836
I1030 02:14:52.835671 27430 solver.cpp:401]     Test net output #2: loss = 1.83957 (* 1 = 1.83957 loss)
I1030 02:14:53.601861 27430 solver.cpp:222] Iteration 22000 (0.656723 iter/s, 60.9085s/40 iters), loss = 1.16795
I1030 02:14:53.601917 27430 solver.cpp:241]     Train net output #0: loss = 1.16795 (* 1 = 1.16795 loss)
I1030 02:14:53.601935 27430 sgd_solver.cpp:105] Iteration 22000, lr = 0.000653709
I1030 02:15:23.365396 27430 solver.cpp:222] Iteration 22040 (1.34396 iter/s, 29.7628s/40 iters), loss = 1.56234
I1030 02:15:23.365545 27430 solver.cpp:241]     Train net output #0: loss = 1.56234 (* 1 = 1.56234 loss)
I1030 02:15:23.365559 27430 sgd_solver.cpp:105] Iteration 22040, lr = 0.000650475
I1030 02:15:53.019351 27430 solver.cpp:222] Iteration 22080 (1.34893 iter/s, 29.6531s/40 iters), loss = 1.66242
I1030 02:15:53.019814 27430 solver.cpp:241]     Train net output #0: loss = 1.66242 (* 1 = 1.66242 loss)
I1030 02:15:53.019870 27430 sgd_solver.cpp:105] Iteration 22080, lr = 0.000647257
I1030 02:16:22.324307 27430 solver.cpp:222] Iteration 22120 (1.36501 iter/s, 29.3038s/40 iters), loss = 1.04665
I1030 02:16:22.324913 27430 solver.cpp:241]     Train net output #0: loss = 1.04665 (* 1 = 1.04665 loss)
I1030 02:16:22.325003 27430 sgd_solver.cpp:105] Iteration 22120, lr = 0.000644055
I1030 02:16:51.853763 27430 solver.cpp:222] Iteration 22160 (1.35464 iter/s, 29.5282s/40 iters), loss = 1.38576
I1030 02:16:51.854193 27430 solver.cpp:241]     Train net output #0: loss = 1.38576 (* 1 = 1.38576 loss)
I1030 02:16:51.854243 27430 sgd_solver.cpp:105] Iteration 22160, lr = 0.000640869
I1030 02:17:21.444284 27430 solver.cpp:222] Iteration 22200 (1.35183 iter/s, 29.5894s/40 iters), loss = 1.32922
I1030 02:17:21.444828 27430 solver.cpp:241]     Train net output #0: loss = 1.32922 (* 1 = 1.32922 loss)
I1030 02:17:21.444880 27430 sgd_solver.cpp:105] Iteration 22200, lr = 0.000637699
I1030 02:17:51.196282 27430 solver.cpp:222] Iteration 22240 (1.3445 iter/s, 29.7508s/40 iters), loss = 1.63548
I1030 02:17:51.196797 27430 solver.cpp:241]     Train net output #0: loss = 1.63548 (* 1 = 1.63548 loss)
I1030 02:17:51.196848 27430 sgd_solver.cpp:105] Iteration 22240, lr = 0.000634544
I1030 02:18:20.839078 27430 solver.cpp:222] Iteration 22280 (1.34945 iter/s, 29.6416s/40 iters), loss = 1.59695
I1030 02:18:20.839635 27430 solver.cpp:241]     Train net output #0: loss = 1.59695 (* 1 = 1.59695 loss)
I1030 02:18:20.839666 27430 sgd_solver.cpp:105] Iteration 22280, lr = 0.000631405
I1030 02:18:50.568719 27430 solver.cpp:222] Iteration 22320 (1.34551 iter/s, 29.7284s/40 iters), loss = 1.46337
I1030 02:18:50.569140 27430 solver.cpp:241]     Train net output #0: loss = 1.46337 (* 1 = 1.46337 loss)
I1030 02:18:50.569180 27430 sgd_solver.cpp:105] Iteration 22320, lr = 0.000628281
I1030 02:19:20.618751 27430 solver.cpp:222] Iteration 22360 (1.33116 iter/s, 30.0489s/40 iters), loss = 1.56808
I1030 02:19:20.619340 27430 solver.cpp:241]     Train net output #0: loss = 1.56808 (* 1 = 1.56808 loss)
I1030 02:19:20.619388 27430 sgd_solver.cpp:105] Iteration 22360, lr = 0.000625173
I1030 02:19:49.938130 27430 solver.cpp:222] Iteration 22400 (1.36434 iter/s, 29.3181s/40 iters), loss = 1.87307
I1030 02:19:49.938575 27430 solver.cpp:241]     Train net output #0: loss = 1.87307 (* 1 = 1.87307 loss)
I1030 02:19:49.938625 27430 sgd_solver.cpp:105] Iteration 22400, lr = 0.00062208
I1030 02:21:11.571754 27430 solver.cpp:222] Iteration 22440 (0.490008 iter/s, 81.6313s/40 iters), loss = 1.36025
I1030 02:21:11.573070 27430 solver.cpp:241]     Train net output #0: loss = 1.36025 (* 1 = 1.36025 loss)
I1030 02:21:11.577831 27430 sgd_solver.cpp:105] Iteration 22440, lr = 0.000619002
I1030 02:21:42.262806 27430 solver.cpp:222] Iteration 22480 (1.3034 iter/s, 30.6891s/40 iters), loss = 1.44239
I1030 02:21:42.263067 27430 solver.cpp:241]     Train net output #0: loss = 1.44239 (* 1 = 1.44239 loss)
I1030 02:21:42.263082 27430 sgd_solver.cpp:105] Iteration 22480, lr = 0.00061594
I1030 02:21:56.678486 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_22500.caffemodel
I1030 02:21:56.819573 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_22500.solverstate
I1030 02:21:56.965059 27430 solver.cpp:334] Iteration 22500, Testing net (#0)
I1030 02:22:28.040895 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1030 02:22:28.253707 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5858
I1030 02:22:28.253748 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81308
I1030 02:22:28.253759 27430 solver.cpp:401]     Test net output #2: loss = 1.84518 (* 1 = 1.84518 loss)
I1030 02:22:40.858518 27479 data_layer.cpp:73] Restarting data prefetching from start.
I1030 02:22:43.720518 27430 solver.cpp:222] Iteration 22520 (0.650872 iter/s, 61.456s/40 iters), loss = 1.46091
I1030 02:22:43.720579 27430 solver.cpp:241]     Train net output #0: loss = 1.46091 (* 1 = 1.46091 loss)
I1030 02:22:43.720599 27430 sgd_solver.cpp:105] Iteration 22520, lr = 0.000612893
I1030 02:23:13.157158 27430 solver.cpp:222] Iteration 22560 (1.35889 iter/s, 29.4359s/40 iters), loss = 1.19416
I1030 02:23:13.157727 27430 solver.cpp:241]     Train net output #0: loss = 1.19416 (* 1 = 1.19416 loss)
I1030 02:23:13.157763 27430 sgd_solver.cpp:105] Iteration 22560, lr = 0.000609861
I1030 02:23:42.521713 27430 solver.cpp:222] Iteration 22600 (1.36224 iter/s, 29.3633s/40 iters), loss = 1.52298
I1030 02:23:42.522169 27430 solver.cpp:241]     Train net output #0: loss = 1.52298 (* 1 = 1.52298 loss)
I1030 02:23:42.522222 27430 sgd_solver.cpp:105] Iteration 22600, lr = 0.000606844
I1030 02:24:12.095080 27430 solver.cpp:222] Iteration 22640 (1.35262 iter/s, 29.5722s/40 iters), loss = 1.21262
I1030 02:24:12.095634 27430 solver.cpp:241]     Train net output #0: loss = 1.21262 (* 1 = 1.21262 loss)
I1030 02:24:12.095674 27430 sgd_solver.cpp:105] Iteration 22640, lr = 0.000603842
I1030 02:24:41.733742 27430 solver.cpp:222] Iteration 22680 (1.34964 iter/s, 29.6374s/40 iters), loss = 1.18097
I1030 02:24:41.734160 27430 solver.cpp:241]     Train net output #0: loss = 1.18097 (* 1 = 1.18097 loss)
I1030 02:24:41.734211 27430 sgd_solver.cpp:105] Iteration 22680, lr = 0.000600854
I1030 02:25:11.257160 27430 solver.cpp:222] Iteration 22720 (1.35491 iter/s, 29.5223s/40 iters), loss = 1.12516
I1030 02:25:11.257752 27430 solver.cpp:241]     Train net output #0: loss = 1.12516 (* 1 = 1.12516 loss)
I1030 02:25:11.257797 27430 sgd_solver.cpp:105] Iteration 22720, lr = 0.000597882
I1030 02:25:40.735579 27430 solver.cpp:222] Iteration 22760 (1.35698 iter/s, 29.4772s/40 iters), loss = 1.07821
I1030 02:25:40.736079 27430 solver.cpp:241]     Train net output #0: loss = 1.07821 (* 1 = 1.07821 loss)
I1030 02:25:40.736129 27430 sgd_solver.cpp:105] Iteration 22760, lr = 0.000594924
I1030 02:26:11.218061 27430 solver.cpp:222] Iteration 22800 (1.31228 iter/s, 30.4813s/40 iters), loss = 1.36886
I1030 02:26:11.218700 27430 solver.cpp:241]     Train net output #0: loss = 1.36886 (* 1 = 1.36886 loss)
I1030 02:26:11.218734 27430 sgd_solver.cpp:105] Iteration 22800, lr = 0.000591981
I1030 02:26:41.264192 27430 solver.cpp:222] Iteration 22840 (1.33135 iter/s, 30.0448s/40 iters), loss = 1.24228
I1030 02:26:41.264713 27430 solver.cpp:241]     Train net output #0: loss = 1.24228 (* 1 = 1.24228 loss)
I1030 02:26:41.264753 27430 sgd_solver.cpp:105] Iteration 22840, lr = 0.000589052
I1030 02:27:11.128937 27430 solver.cpp:222] Iteration 22880 (1.33943 iter/s, 29.8635s/40 iters), loss = 1.4964
I1030 02:27:11.129359 27430 solver.cpp:241]     Train net output #0: loss = 1.4964 (* 1 = 1.4964 loss)
I1030 02:27:11.129408 27430 sgd_solver.cpp:105] Iteration 22880, lr = 0.000586138
I1030 02:27:41.556816 27430 solver.cpp:222] Iteration 22920 (1.31463 iter/s, 30.4268s/40 iters), loss = 1.16401
I1030 02:27:41.557015 27430 solver.cpp:241]     Train net output #0: loss = 1.16401 (* 1 = 1.16401 loss)
I1030 02:27:41.557029 27430 sgd_solver.cpp:105] Iteration 22920, lr = 0.000583238
I1030 02:28:11.293339 27430 solver.cpp:222] Iteration 22960 (1.34519 iter/s, 29.7356s/40 iters), loss = 1.36645
I1030 02:28:11.293807 27430 solver.cpp:241]     Train net output #0: loss = 1.36645 (* 1 = 1.36645 loss)
I1030 02:28:11.293859 27430 sgd_solver.cpp:105] Iteration 22960, lr = 0.000580353
I1030 02:28:40.292157 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_23000.caffemodel
I1030 02:28:40.433369 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_23000.solverstate
I1030 02:28:40.543684 27430 solver.cpp:334] Iteration 23000, Testing net (#0)
I1030 02:29:11.723889 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58624
I1030 02:29:11.723984 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.807959
I1030 02:29:11.723996 27430 solver.cpp:401]     Test net output #2: loss = 1.84608 (* 1 = 1.84608 loss)
I1030 02:29:12.487797 27430 solver.cpp:222] Iteration 23000 (0.653674 iter/s, 61.1926s/40 iters), loss = 1.29209
I1030 02:29:12.487870 27430 solver.cpp:241]     Train net output #0: loss = 1.29209 (* 1 = 1.29209 loss)
I1030 02:29:12.487884 27430 sgd_solver.cpp:105] Iteration 23000, lr = 0.000577482
I1030 02:29:42.199937 27430 solver.cpp:222] Iteration 23040 (1.34629 iter/s, 29.7113s/40 iters), loss = 1.30472
I1030 02:29:42.200539 27430 solver.cpp:241]     Train net output #0: loss = 1.30472 (* 1 = 1.30472 loss)
I1030 02:29:42.200587 27430 sgd_solver.cpp:105] Iteration 23040, lr = 0.000574625
I1030 02:30:11.761114 27430 solver.cpp:222] Iteration 23080 (1.35319 iter/s, 29.5599s/40 iters), loss = 1.42474
I1030 02:30:11.761546 27430 solver.cpp:241]     Train net output #0: loss = 1.42474 (* 1 = 1.42474 loss)
I1030 02:30:11.761596 27430 sgd_solver.cpp:105] Iteration 23080, lr = 0.000571782
I1030 02:30:41.003285 27430 solver.cpp:222] Iteration 23120 (1.36794 iter/s, 29.2411s/40 iters), loss = 1.10284
I1030 02:30:41.003897 27430 solver.cpp:241]     Train net output #0: loss = 1.10284 (* 1 = 1.10284 loss)
I1030 02:30:41.004170 27430 sgd_solver.cpp:105] Iteration 23120, lr = 0.000568954
I1030 02:31:10.353554 27430 solver.cpp:222] Iteration 23160 (1.36291 iter/s, 29.349s/40 iters), loss = 1.28769
I1030 02:31:10.354045 27430 solver.cpp:241]     Train net output #0: loss = 1.28769 (* 1 = 1.28769 loss)
I1030 02:31:10.354096 27430 sgd_solver.cpp:105] Iteration 23160, lr = 0.000566139
I1030 02:31:40.951186 27430 solver.cpp:222] Iteration 23200 (1.30734 iter/s, 30.5964s/40 iters), loss = 1.17378
I1030 02:31:40.951786 27430 solver.cpp:241]     Train net output #0: loss = 1.17378 (* 1 = 1.17378 loss)
I1030 02:31:40.951838 27430 sgd_solver.cpp:105] Iteration 23200, lr = 0.000563338
I1030 02:32:10.351615 27430 solver.cpp:222] Iteration 23240 (1.36058 iter/s, 29.3992s/40 iters), loss = 1.26613
I1030 02:32:10.352078 27430 solver.cpp:241]     Train net output #0: loss = 1.26613 (* 1 = 1.26613 loss)
I1030 02:32:10.352123 27430 sgd_solver.cpp:105] Iteration 23240, lr = 0.000560551
I1030 02:32:39.993479 27430 solver.cpp:222] Iteration 23280 (1.3495 iter/s, 29.6407s/40 iters), loss = 1.41298
I1030 02:32:39.994093 27430 solver.cpp:241]     Train net output #0: loss = 1.41298 (* 1 = 1.41298 loss)
I1030 02:32:39.994144 27430 sgd_solver.cpp:105] Iteration 23280, lr = 0.000557778
I1030 02:33:09.403918 27430 solver.cpp:222] Iteration 23320 (1.36012 iter/s, 29.4092s/40 iters), loss = 1.29784
I1030 02:33:09.404417 27430 solver.cpp:241]     Train net output #0: loss = 1.29784 (* 1 = 1.29784 loss)
I1030 02:33:09.404462 27430 sgd_solver.cpp:105] Iteration 23320, lr = 0.000555019
I1030 02:33:39.050513 27430 solver.cpp:222] Iteration 23360 (1.34928 iter/s, 29.6454s/40 iters), loss = 1.28879
I1030 02:33:39.051065 27430 solver.cpp:241]     Train net output #0: loss = 1.28879 (* 1 = 1.28879 loss)
I1030 02:33:39.051110 27430 sgd_solver.cpp:105] Iteration 23360, lr = 0.000552273
I1030 02:34:08.383922 27430 solver.cpp:222] Iteration 23400 (1.36369 iter/s, 29.3322s/40 iters), loss = 1.34111
I1030 02:34:08.384383 27430 solver.cpp:241]     Train net output #0: loss = 1.34111 (* 1 = 1.34111 loss)
I1030 02:34:08.384420 27430 sgd_solver.cpp:105] Iteration 23400, lr = 0.000549541
I1030 02:34:37.684324 27430 solver.cpp:222] Iteration 23440 (1.36522 iter/s, 29.2993s/40 iters), loss = 1.94733
I1030 02:34:37.684854 27430 solver.cpp:241]     Train net output #0: loss = 1.94733 (* 1 = 1.94733 loss)
I1030 02:34:37.684898 27430 sgd_solver.cpp:105] Iteration 23440, lr = 0.000546822
I1030 02:35:06.972986 27430 solver.cpp:222] Iteration 23480 (1.36577 iter/s, 29.2875s/40 iters), loss = 1.16057
I1030 02:35:06.973409 27430 solver.cpp:241]     Train net output #0: loss = 1.16057 (* 1 = 1.16057 loss)
I1030 02:35:06.973459 27430 sgd_solver.cpp:105] Iteration 23480, lr = 0.000544117
I1030 02:35:20.877750 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_23500.caffemodel
I1030 02:35:21.021541 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_23500.solverstate
I1030 02:35:21.129465 27430 solver.cpp:334] Iteration 23500, Testing net (#0)
I1030 02:35:52.117355 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1030 02:35:52.325630 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58408
I1030 02:35:52.325681 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8134
I1030 02:35:52.325692 27430 solver.cpp:401]     Test net output #2: loss = 1.8376 (* 1 = 1.8376 loss)
I1030 02:36:07.874482 27430 solver.cpp:222] Iteration 23520 (0.656818 iter/s, 60.8997s/40 iters), loss = 1.16078
I1030 02:36:07.874539 27430 solver.cpp:241]     Train net output #0: loss = 1.16078 (* 1 = 1.16078 loss)
I1030 02:36:07.874553 27430 sgd_solver.cpp:105] Iteration 23520, lr = 0.000541425
I1030 02:36:37.112298 27430 solver.cpp:222] Iteration 23560 (1.36813 iter/s, 29.2371s/40 iters), loss = 1.47389
I1030 02:36:37.112766 27430 solver.cpp:241]     Train net output #0: loss = 1.47389 (* 1 = 1.47389 loss)
I1030 02:36:37.112812 27430 sgd_solver.cpp:105] Iteration 23560, lr = 0.000538747
I1030 02:37:06.666656 27430 solver.cpp:222] Iteration 23600 (1.35349 iter/s, 29.5532s/40 iters), loss = 1.63651
I1030 02:37:06.667078 27430 solver.cpp:241]     Train net output #0: loss = 1.63651 (* 1 = 1.63651 loss)
I1030 02:37:06.667124 27430 sgd_solver.cpp:105] Iteration 23600, lr = 0.000536081
I1030 02:37:36.234045 27430 solver.cpp:222] Iteration 23640 (1.35289 iter/s, 29.5663s/40 iters), loss = 1.28533
I1030 02:37:36.234506 27430 solver.cpp:241]     Train net output #0: loss = 1.28533 (* 1 = 1.28533 loss)
I1030 02:37:36.234540 27430 sgd_solver.cpp:105] Iteration 23640, lr = 0.000533429
I1030 02:38:06.691316 27430 solver.cpp:222] Iteration 23680 (1.31337 iter/s, 30.4561s/40 iters), loss = 1.5662
I1030 02:38:06.691454 27430 solver.cpp:241]     Train net output #0: loss = 1.5662 (* 1 = 1.5662 loss)
I1030 02:38:06.691468 27430 sgd_solver.cpp:105] Iteration 23680, lr = 0.00053079
I1030 02:38:36.790556 27430 solver.cpp:222] Iteration 23720 (1.32897 iter/s, 30.0984s/40 iters), loss = 1.45668
I1030 02:38:36.790736 27430 solver.cpp:241]     Train net output #0: loss = 1.45668 (* 1 = 1.45668 loss)
I1030 02:38:36.790751 27430 sgd_solver.cpp:105] Iteration 23720, lr = 0.000528165
I1030 02:39:06.399155 27430 solver.cpp:222] Iteration 23760 (1.351 iter/s, 29.6077s/40 iters), loss = 1.30084
I1030 02:39:06.399224 27430 solver.cpp:241]     Train net output #0: loss = 1.30084 (* 1 = 1.30084 loss)
I1030 02:39:06.399235 27430 sgd_solver.cpp:105] Iteration 23760, lr = 0.000525552
I1030 02:40:07.448496 27430 solver.cpp:222] Iteration 23800 (0.655224 iter/s, 61.0478s/40 iters), loss = 1.36314
I1030 02:40:07.449128 27430 solver.cpp:241]     Train net output #0: loss = 1.36314 (* 1 = 1.36314 loss)
I1030 02:40:07.449894 27430 sgd_solver.cpp:105] Iteration 23800, lr = 0.000522952
I1030 02:40:50.289579 27430 solver.cpp:222] Iteration 23840 (0.933718 iter/s, 42.8395s/40 iters), loss = 1.62663
I1030 02:40:50.290129 27430 solver.cpp:241]     Train net output #0: loss = 1.62663 (* 1 = 1.62663 loss)
I1030 02:40:50.290163 27430 sgd_solver.cpp:105] Iteration 23840, lr = 0.000520365
I1030 02:41:57.001111 27430 solver.cpp:222] Iteration 23880 (0.599615 iter/s, 66.7095s/40 iters), loss = 1.20952
I1030 02:41:57.001718 27430 solver.cpp:241]     Train net output #0: loss = 1.20952 (* 1 = 1.20952 loss)
I1030 02:41:57.001765 27430 sgd_solver.cpp:105] Iteration 23880, lr = 0.00051779
I1030 02:42:26.975383 27430 solver.cpp:222] Iteration 23920 (1.33453 iter/s, 29.973s/40 iters), loss = 1.29645
I1030 02:42:26.975832 27430 solver.cpp:241]     Train net output #0: loss = 1.29645 (* 1 = 1.29645 loss)
I1030 02:42:26.975885 27430 sgd_solver.cpp:105] Iteration 23920, lr = 0.000515229
I1030 02:42:57.372334 27430 solver.cpp:222] Iteration 23960 (1.31597 iter/s, 30.3958s/40 iters), loss = 1.18542
I1030 02:42:57.373039 27430 solver.cpp:241]     Train net output #0: loss = 1.18542 (* 1 = 1.18542 loss)
I1030 02:42:57.373077 27430 sgd_solver.cpp:105] Iteration 23960, lr = 0.00051268
I1030 02:43:27.184891 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_24000.caffemodel
I1030 02:43:27.346140 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_24000.solverstate
I1030 02:43:27.467869 27430 solver.cpp:334] Iteration 24000, Testing net (#0)
I1030 02:43:58.577497 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58804
I1030 02:43:58.577947 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.808919
I1030 02:43:58.577967 27430 solver.cpp:401]     Test net output #2: loss = 1.84196 (* 1 = 1.84196 loss)
I1030 02:43:59.343909 27430 solver.cpp:222] Iteration 24000 (0.645478 iter/s, 61.9696s/40 iters), loss = 1.79461
I1030 02:43:59.343984 27430 solver.cpp:241]     Train net output #0: loss = 1.79461 (* 1 = 1.79461 loss)
I1030 02:43:59.344002 27430 sgd_solver.cpp:105] Iteration 24000, lr = 0.000510143
I1030 02:44:28.624959 27430 solver.cpp:222] Iteration 24040 (1.36611 iter/s, 29.2803s/40 iters), loss = 1.4752
I1030 02:44:28.625591 27430 solver.cpp:241]     Train net output #0: loss = 1.4752 (* 1 = 1.4752 loss)
I1030 02:44:28.625641 27430 sgd_solver.cpp:105] Iteration 24040, lr = 0.00050762
I1030 02:44:58.203871 27430 solver.cpp:222] Iteration 24080 (1.35237 iter/s, 29.5776s/40 iters), loss = 1.65002
I1030 02:44:58.204329 27430 solver.cpp:241]     Train net output #0: loss = 1.65002 (* 1 = 1.65002 loss)
I1030 02:44:58.204378 27430 sgd_solver.cpp:105] Iteration 24080, lr = 0.000505108
I1030 02:47:31.609237 27430 solver.cpp:222] Iteration 24120 (0.260754 iter/s, 153.401s/40 iters), loss = 1.42189
I1030 02:47:31.609827 27430 solver.cpp:241]     Train net output #0: loss = 1.42189 (* 1 = 1.42189 loss)
I1030 02:47:31.609877 27430 sgd_solver.cpp:105] Iteration 24120, lr = 0.00050261
I1030 02:48:01.654058 27430 solver.cpp:222] Iteration 24160 (1.3314 iter/s, 30.0436s/40 iters), loss = 1.15499
I1030 02:48:01.654549 27430 solver.cpp:241]     Train net output #0: loss = 1.15499 (* 1 = 1.15499 loss)
I1030 02:48:01.654594 27430 sgd_solver.cpp:105] Iteration 24160, lr = 0.000500123
I1030 02:48:31.580181 27430 solver.cpp:222] Iteration 24200 (1.33668 iter/s, 29.925s/40 iters), loss = 1.37758
I1030 02:48:31.580672 27430 solver.cpp:241]     Train net output #0: loss = 1.37758 (* 1 = 1.37758 loss)
I1030 02:48:31.580723 27430 sgd_solver.cpp:105] Iteration 24200, lr = 0.000497649
I1030 02:49:07.644031 27430 solver.cpp:222] Iteration 24240 (1.10918 iter/s, 36.0625s/40 iters), loss = 1.56652
I1030 02:49:07.644554 27430 solver.cpp:241]     Train net output #0: loss = 1.56652 (* 1 = 1.56652 loss)
I1030 02:49:07.644596 27430 sgd_solver.cpp:105] Iteration 24240, lr = 0.000495187
I1030 02:49:38.555222 27430 solver.cpp:222] Iteration 24280 (1.29408 iter/s, 30.91s/40 iters), loss = 1.56189
I1030 02:49:38.555316 27430 solver.cpp:241]     Train net output #0: loss = 1.56189 (* 1 = 1.56189 loss)
I1030 02:49:38.555330 27430 sgd_solver.cpp:105] Iteration 24280, lr = 0.000492737
I1030 02:50:07.922621 27430 solver.cpp:222] Iteration 24320 (1.36209 iter/s, 29.3666s/40 iters), loss = 1.48774
I1030 02:50:07.923122 27430 solver.cpp:241]     Train net output #0: loss = 1.48774 (* 1 = 1.48774 loss)
I1030 02:50:07.923172 27430 sgd_solver.cpp:105] Iteration 24320, lr = 0.0004903
I1030 02:50:37.195011 27430 solver.cpp:222] Iteration 24360 (1.36653 iter/s, 29.2712s/40 iters), loss = 1.51627
I1030 02:50:37.195587 27430 solver.cpp:241]     Train net output #0: loss = 1.51627 (* 1 = 1.51627 loss)
I1030 02:50:37.195636 27430 sgd_solver.cpp:105] Iteration 24360, lr = 0.000487874
I1030 02:51:06.501107 27430 solver.cpp:222] Iteration 24400 (1.36496 iter/s, 29.3048s/40 iters), loss = 1.37259
I1030 02:51:06.501493 27430 solver.cpp:241]     Train net output #0: loss = 1.37259 (* 1 = 1.37259 loss)
I1030 02:51:06.501529 27430 sgd_solver.cpp:105] Iteration 24400, lr = 0.00048546
I1030 02:51:36.041818 27430 solver.cpp:222] Iteration 24440 (1.35411 iter/s, 29.5396s/40 iters), loss = 1.72125
I1030 02:51:36.042400 27430 solver.cpp:241]     Train net output #0: loss = 1.72125 (* 1 = 1.72125 loss)
I1030 02:51:36.042445 27430 sgd_solver.cpp:105] Iteration 24440, lr = 0.000483059
I1030 02:52:05.584650 27430 solver.cpp:222] Iteration 24480 (1.35402 iter/s, 29.5416s/40 iters), loss = 1.48546
I1030 02:52:05.585134 27430 solver.cpp:241]     Train net output #0: loss = 1.48546 (* 1 = 1.48546 loss)
I1030 02:52:05.585186 27430 sgd_solver.cpp:105] Iteration 24480, lr = 0.000480669
I1030 02:52:19.600502 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_24500.caffemodel
I1030 02:52:19.741945 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_24500.solverstate
I1030 02:52:19.858638 27430 solver.cpp:334] Iteration 24500, Testing net (#0)
I1030 02:52:51.663064 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1030 02:52:51.843775 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58604
I1030 02:52:51.843838 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81456
I1030 02:52:51.843854 27430 solver.cpp:401]     Test net output #2: loss = 1.84098 (* 1 = 1.84098 loss)
I1030 02:53:07.615712 27430 solver.cpp:222] Iteration 24520 (0.644858 iter/s, 62.0291s/40 iters), loss = 1.75393
I1030 02:53:07.616233 27430 solver.cpp:241]     Train net output #0: loss = 1.75393 (* 1 = 1.75393 loss)
I1030 02:53:07.616286 27430 sgd_solver.cpp:105] Iteration 24520, lr = 0.000478291
I1030 02:53:36.927212 27430 solver.cpp:222] Iteration 24560 (1.36471 iter/s, 29.3103s/40 iters), loss = 1.37249
I1030 02:53:36.927778 27430 solver.cpp:241]     Train net output #0: loss = 1.37249 (* 1 = 1.37249 loss)
I1030 02:53:36.927825 27430 sgd_solver.cpp:105] Iteration 24560, lr = 0.000475925
I1030 02:54:06.881449 27430 solver.cpp:222] Iteration 24600 (1.33543 iter/s, 29.953s/40 iters), loss = 1.48446
I1030 02:54:06.881882 27430 solver.cpp:241]     Train net output #0: loss = 1.48446 (* 1 = 1.48446 loss)
I1030 02:54:06.881976 27430 sgd_solver.cpp:105] Iteration 24600, lr = 0.000473571
I1030 02:54:36.252872 27430 solver.cpp:222] Iteration 24640 (1.36192 iter/s, 29.3703s/40 iters), loss = 1.58506
I1030 02:54:36.253489 27430 solver.cpp:241]     Train net output #0: loss = 1.58506 (* 1 = 1.58506 loss)
I1030 02:54:36.253541 27430 sgd_solver.cpp:105] Iteration 24640, lr = 0.000471228
I1030 02:55:05.653843 27430 solver.cpp:222] Iteration 24680 (1.36056 iter/s, 29.3997s/40 iters), loss = 1.27802
I1030 02:55:05.654333 27430 solver.cpp:241]     Train net output #0: loss = 1.27802 (* 1 = 1.27802 loss)
I1030 02:55:05.654387 27430 sgd_solver.cpp:105] Iteration 24680, lr = 0.000468896
I1030 02:55:35.029150 27430 solver.cpp:222] Iteration 24720 (1.36174 iter/s, 29.3741s/40 iters), loss = 1.51213
I1030 02:55:35.029714 27430 solver.cpp:241]     Train net output #0: loss = 1.51213 (* 1 = 1.51213 loss)
I1030 02:55:35.029765 27430 sgd_solver.cpp:105] Iteration 24720, lr = 0.000466577
I1030 02:56:04.694574 27430 solver.cpp:222] Iteration 24760 (1.34843 iter/s, 29.6642s/40 iters), loss = 1.39574
I1030 02:56:04.695034 27430 solver.cpp:241]     Train net output #0: loss = 1.39574 (* 1 = 1.39574 loss)
I1030 02:56:04.695083 27430 sgd_solver.cpp:105] Iteration 24760, lr = 0.000464269
I1030 02:56:49.076143 27430 solver.cpp:222] Iteration 24800 (0.901305 iter/s, 44.3801s/40 iters), loss = 1.71753
I1030 02:56:49.076753 27430 solver.cpp:241]     Train net output #0: loss = 1.71753 (* 1 = 1.71753 loss)
I1030 02:56:49.076820 27430 sgd_solver.cpp:105] Iteration 24800, lr = 0.000461972
I1030 02:57:21.393117 27430 solver.cpp:222] Iteration 24840 (1.23779 iter/s, 32.3156s/40 iters), loss = 1.31206
I1030 02:57:21.393649 27430 solver.cpp:241]     Train net output #0: loss = 1.31206 (* 1 = 1.31206 loss)
I1030 02:57:21.393679 27430 sgd_solver.cpp:105] Iteration 24840, lr = 0.000459686
I1030 02:57:51.227442 27430 solver.cpp:222] Iteration 24880 (1.34079 iter/s, 29.8331s/40 iters), loss = 1.6155
I1030 02:57:51.227859 27430 solver.cpp:241]     Train net output #0: loss = 1.6155 (* 1 = 1.6155 loss)
I1030 02:57:51.227901 27430 sgd_solver.cpp:105] Iteration 24880, lr = 0.000457412
I1030 02:58:24.094169 27430 solver.cpp:222] Iteration 24920 (1.21708 iter/s, 32.8655s/40 iters), loss = 1.33777
I1030 02:58:24.094827 27430 solver.cpp:241]     Train net output #0: loss = 1.33777 (* 1 = 1.33777 loss)
I1030 02:58:24.094877 27430 sgd_solver.cpp:105] Iteration 24920, lr = 0.000455149
I1030 02:58:53.966142 27430 solver.cpp:222] Iteration 24960 (1.33911 iter/s, 29.8706s/40 iters), loss = 1.41062
I1030 02:58:53.966593 27430 solver.cpp:241]     Train net output #0: loss = 1.41062 (* 1 = 1.41062 loss)
I1030 02:58:53.966641 27430 sgd_solver.cpp:105] Iteration 24960, lr = 0.000452898
I1030 02:59:23.877734 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_25000.caffemodel
I1030 02:59:24.018204 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_25000.solverstate
I1030 02:59:24.132513 27430 solver.cpp:334] Iteration 25000, Testing net (#0)
I1030 02:59:55.355698 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58532
I1030 02:59:55.355844 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80788
I1030 02:59:55.355859 27430 solver.cpp:401]     Test net output #2: loss = 1.84343 (* 1 = 1.84343 loss)
I1030 02:59:56.110085 27430 solver.cpp:222] Iteration 25000 (0.643686 iter/s, 62.1421s/40 iters), loss = 1.4774
I1030 02:59:56.110142 27430 solver.cpp:241]     Train net output #0: loss = 1.4774 (* 1 = 1.4774 loss)
I1030 02:59:56.110154 27430 sgd_solver.cpp:105] Iteration 25000, lr = 0.000450657
I1030 03:00:10.156404 27479 data_layer.cpp:73] Restarting data prefetching from start.
I1030 03:00:27.262591 27430 solver.cpp:222] Iteration 25040 (1.28404 iter/s, 31.1517s/40 iters), loss = 1.49945
I1030 03:00:27.263149 27430 solver.cpp:241]     Train net output #0: loss = 1.49945 (* 1 = 1.49945 loss)
I1030 03:00:27.263172 27430 sgd_solver.cpp:105] Iteration 25040, lr = 0.000448428
I1030 03:00:57.408668 27430 solver.cpp:222] Iteration 25080 (1.32693 iter/s, 30.1448s/40 iters), loss = 1.42961
I1030 03:00:57.409270 27430 solver.cpp:241]     Train net output #0: loss = 1.42961 (* 1 = 1.42961 loss)
I1030 03:00:57.409315 27430 sgd_solver.cpp:105] Iteration 25080, lr = 0.000446209
I1030 03:01:26.974241 27430 solver.cpp:222] Iteration 25120 (1.35298 iter/s, 29.5643s/40 iters), loss = 1.03264
I1030 03:01:26.974714 27430 solver.cpp:241]     Train net output #0: loss = 1.03264 (* 1 = 1.03264 loss)
I1030 03:01:26.974757 27430 sgd_solver.cpp:105] Iteration 25120, lr = 0.000444002
I1030 03:01:58.017845 27430 solver.cpp:222] Iteration 25160 (1.28856 iter/s, 31.0424s/40 iters), loss = 1.29241
I1030 03:01:58.018501 27430 solver.cpp:241]     Train net output #0: loss = 1.29241 (* 1 = 1.29241 loss)
I1030 03:01:58.018548 27430 sgd_solver.cpp:105] Iteration 25160, lr = 0.000441805
I1030 03:02:27.934157 27430 solver.cpp:222] Iteration 25200 (1.33712 iter/s, 29.915s/40 iters), loss = 1.37596
I1030 03:02:27.934623 27430 solver.cpp:241]     Train net output #0: loss = 1.37596 (* 1 = 1.37596 loss)
I1030 03:02:27.934672 27430 sgd_solver.cpp:105] Iteration 25200, lr = 0.000439619
I1030 03:02:57.313611 27430 solver.cpp:222] Iteration 25240 (1.36155 iter/s, 29.3783s/40 iters), loss = 1.46461
I1030 03:02:57.314216 27430 solver.cpp:241]     Train net output #0: loss = 1.46461 (* 1 = 1.46461 loss)
I1030 03:02:57.314265 27430 sgd_solver.cpp:105] Iteration 25240, lr = 0.000437445
I1030 03:03:26.786156 27430 solver.cpp:222] Iteration 25280 (1.35725 iter/s, 29.4713s/40 iters), loss = 1.19359
I1030 03:03:26.786613 27430 solver.cpp:241]     Train net output #0: loss = 1.19359 (* 1 = 1.19359 loss)
I1030 03:03:26.786661 27430 sgd_solver.cpp:105] Iteration 25280, lr = 0.000435281
I1030 03:03:56.331240 27430 solver.cpp:222] Iteration 25320 (1.35391 iter/s, 29.544s/40 iters), loss = 1.37895
I1030 03:03:56.331809 27430 solver.cpp:241]     Train net output #0: loss = 1.37895 (* 1 = 1.37895 loss)
I1030 03:03:56.331845 27430 sgd_solver.cpp:105] Iteration 25320, lr = 0.000433127
I1030 03:04:25.892724 27430 solver.cpp:222] Iteration 25360 (1.35317 iter/s, 29.5602s/40 iters), loss = 1.44701
I1030 03:04:25.893167 27430 solver.cpp:241]     Train net output #0: loss = 1.44701 (* 1 = 1.44701 loss)
I1030 03:04:25.893213 27430 sgd_solver.cpp:105] Iteration 25360, lr = 0.000430984
I1030 03:04:55.622916 27430 solver.cpp:222] Iteration 25400 (1.34548 iter/s, 29.7291s/40 iters), loss = 1.2686
I1030 03:04:55.623538 27430 solver.cpp:241]     Train net output #0: loss = 1.2686 (* 1 = 1.2686 loss)
I1030 03:04:55.623589 27430 sgd_solver.cpp:105] Iteration 25400, lr = 0.000428852
I1030 03:05:25.189153 27430 solver.cpp:222] Iteration 25440 (1.35295 iter/s, 29.565s/40 iters), loss = 1.22561
I1030 03:05:25.189607 27430 solver.cpp:241]     Train net output #0: loss = 1.22561 (* 1 = 1.22561 loss)
I1030 03:05:25.189654 27430 sgd_solver.cpp:105] Iteration 25440, lr = 0.000426731
I1030 03:05:54.569655 27430 solver.cpp:222] Iteration 25480 (1.3615 iter/s, 29.3794s/40 iters), loss = 1.34254
I1030 03:05:54.570158 27430 solver.cpp:241]     Train net output #0: loss = 1.34254 (* 1 = 1.34254 loss)
I1030 03:05:54.570200 27430 sgd_solver.cpp:105] Iteration 25480, lr = 0.00042462
I1030 03:06:08.644835 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_25500.caffemodel
I1030 03:06:08.779806 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_25500.solverstate
I1030 03:06:08.899806 27430 solver.cpp:334] Iteration 25500, Testing net (#0)
I1030 03:06:39.924772 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1030 03:06:40.134989 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.586
I1030 03:06:40.135033 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8134
I1030 03:06:40.135046 27430 solver.cpp:401]     Test net output #2: loss = 1.84299 (* 1 = 1.84299 loss)
I1030 03:06:55.513290 27430 solver.cpp:222] Iteration 25520 (0.656365 iter/s, 60.9417s/40 iters), loss = 1.70027
I1030 03:06:55.513754 27430 solver.cpp:241]     Train net output #0: loss = 1.70027 (* 1 = 1.70027 loss)
I1030 03:06:55.513801 27430 sgd_solver.cpp:105] Iteration 25520, lr = 0.000422519
I1030 03:07:24.889922 27430 solver.cpp:222] Iteration 25560 (1.36168 iter/s, 29.3755s/40 iters), loss = 1.13208
I1030 03:07:24.890432 27430 solver.cpp:241]     Train net output #0: loss = 1.13208 (* 1 = 1.13208 loss)
I1030 03:07:24.890470 27430 sgd_solver.cpp:105] Iteration 25560, lr = 0.000420429
I1030 03:07:54.213276 27430 solver.cpp:222] Iteration 25600 (1.36416 iter/s, 29.3222s/40 iters), loss = 1.51001
I1030 03:07:54.213732 27430 solver.cpp:241]     Train net output #0: loss = 1.51001 (* 1 = 1.51001 loss)
I1030 03:07:54.213780 27430 sgd_solver.cpp:105] Iteration 25600, lr = 0.000418349
I1030 03:08:23.522910 27430 solver.cpp:222] Iteration 25640 (1.36479 iter/s, 29.3085s/40 iters), loss = 1.48111
I1030 03:08:23.523468 27430 solver.cpp:241]     Train net output #0: loss = 1.48111 (* 1 = 1.48111 loss)
I1030 03:08:23.523514 27430 sgd_solver.cpp:105] Iteration 25640, lr = 0.000416279
I1030 03:08:53.154028 27430 solver.cpp:222] Iteration 25680 (1.34999 iter/s, 29.6299s/40 iters), loss = 1.34306
I1030 03:08:53.154506 27430 solver.cpp:241]     Train net output #0: loss = 1.34306 (* 1 = 1.34306 loss)
I1030 03:08:53.154554 27430 sgd_solver.cpp:105] Iteration 25680, lr = 0.00041422
I1030 03:09:23.748150 27430 solver.cpp:222] Iteration 25720 (1.30749 iter/s, 30.5929s/40 iters), loss = 1.47649
I1030 03:09:23.748643 27430 solver.cpp:241]     Train net output #0: loss = 1.47649 (* 1 = 1.47649 loss)
I1030 03:09:23.748705 27430 sgd_solver.cpp:105] Iteration 25720, lr = 0.000412171
I1030 03:09:53.178231 27430 solver.cpp:222] Iteration 25760 (1.35921 iter/s, 29.4289s/40 iters), loss = 1.47794
I1030 03:09:53.178666 27430 solver.cpp:241]     Train net output #0: loss = 1.47794 (* 1 = 1.47794 loss)
I1030 03:09:53.178699 27430 sgd_solver.cpp:105] Iteration 25760, lr = 0.000410131
I1030 03:10:22.460675 27430 solver.cpp:222] Iteration 25800 (1.36606 iter/s, 29.2813s/40 iters), loss = 1.20625
I1030 03:10:22.461289 27430 solver.cpp:241]     Train net output #0: loss = 1.20625 (* 1 = 1.20625 loss)
I1030 03:10:22.461339 27430 sgd_solver.cpp:105] Iteration 25800, lr = 0.000408103
I1030 03:10:51.939508 27430 solver.cpp:222] Iteration 25840 (1.35697 iter/s, 29.4775s/40 iters), loss = 1.24385
I1030 03:10:51.939981 27430 solver.cpp:241]     Train net output #0: loss = 1.24385 (* 1 = 1.24385 loss)
I1030 03:10:51.940018 27430 sgd_solver.cpp:105] Iteration 25840, lr = 0.000406084
I1030 03:11:21.093641 27430 solver.cpp:222] Iteration 25880 (1.37207 iter/s, 29.153s/40 iters), loss = 1.40703
I1030 03:11:21.094211 27430 solver.cpp:241]     Train net output #0: loss = 1.40703 (* 1 = 1.40703 loss)
I1030 03:11:21.094267 27430 sgd_solver.cpp:105] Iteration 25880, lr = 0.000404075
I1030 03:11:50.409126 27430 solver.cpp:222] Iteration 25920 (1.36452 iter/s, 29.3142s/40 iters), loss = 1.44951
I1030 03:11:50.409597 27430 solver.cpp:241]     Train net output #0: loss = 1.44951 (* 1 = 1.44951 loss)
I1030 03:11:50.409637 27430 sgd_solver.cpp:105] Iteration 25920, lr = 0.000402076
I1030 03:12:19.694463 27430 solver.cpp:222] Iteration 25960 (1.36592 iter/s, 29.2842s/40 iters), loss = 1.44256
I1030 03:12:19.695108 27430 solver.cpp:241]     Train net output #0: loss = 1.44256 (* 1 = 1.44256 loss)
I1030 03:12:19.695161 27430 sgd_solver.cpp:105] Iteration 25960, lr = 0.000400086
I1030 03:12:55.464711 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_26000.caffemodel
I1030 03:12:55.614012 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_26000.solverstate
I1030 03:12:55.735271 27430 solver.cpp:334] Iteration 26000, Testing net (#0)
I1030 03:13:26.959540 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.587
I1030 03:13:26.959674 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8096
I1030 03:13:26.959687 27430 solver.cpp:401]     Test net output #2: loss = 1.83838 (* 1 = 1.83838 loss)
I1030 03:13:27.731560 27430 solver.cpp:222] Iteration 26000 (0.587934 iter/s, 68.0349s/40 iters), loss = 1.59599
I1030 03:13:27.731614 27430 solver.cpp:241]     Train net output #0: loss = 1.59599 (* 1 = 1.59599 loss)
I1030 03:13:27.731626 27430 sgd_solver.cpp:105] Iteration 26000, lr = 0.000398107
I1030 03:14:48.769078 27430 solver.cpp:222] Iteration 26040 (0.49361 iter/s, 81.0356s/40 iters), loss = 1.40809
I1030 03:14:48.769701 27430 solver.cpp:241]     Train net output #0: loss = 1.40809 (* 1 = 1.40809 loss)
I1030 03:14:48.769757 27430 sgd_solver.cpp:105] Iteration 26040, lr = 0.000396138
I1030 03:15:24.966264 27430 solver.cpp:222] Iteration 26080 (1.1051 iter/s, 36.1958s/40 iters), loss = 1.63728
I1030 03:15:24.966814 27430 solver.cpp:241]     Train net output #0: loss = 1.63728 (* 1 = 1.63728 loss)
I1030 03:15:24.966866 27430 sgd_solver.cpp:105] Iteration 26080, lr = 0.000394178
I1030 03:15:55.430057 27430 solver.cpp:222] Iteration 26120 (1.31309 iter/s, 30.4626s/40 iters), loss = 1.62874
I1030 03:15:55.430246 27430 solver.cpp:241]     Train net output #0: loss = 1.62874 (* 1 = 1.62874 loss)
I1030 03:15:55.430261 27430 sgd_solver.cpp:105] Iteration 26120, lr = 0.000392228
I1030 03:16:25.797531 27430 solver.cpp:222] Iteration 26160 (1.31724 iter/s, 30.3666s/40 iters), loss = 1.45393
I1030 03:16:25.797674 27430 solver.cpp:241]     Train net output #0: loss = 1.45393 (* 1 = 1.45393 loss)
I1030 03:16:25.797689 27430 sgd_solver.cpp:105] Iteration 26160, lr = 0.000390288
I1030 03:16:55.948490 27430 solver.cpp:222] Iteration 26200 (1.32669 iter/s, 30.1501s/40 iters), loss = 1.62573
I1030 03:16:55.949115 27430 solver.cpp:241]     Train net output #0: loss = 1.62573 (* 1 = 1.62573 loss)
I1030 03:16:55.949162 27430 sgd_solver.cpp:105] Iteration 26200, lr = 0.000388357
I1030 03:17:26.317981 27430 solver.cpp:222] Iteration 26240 (1.31717 iter/s, 30.3682s/40 iters), loss = 1.4031
I1030 03:17:26.318228 27430 solver.cpp:241]     Train net output #0: loss = 1.4031 (* 1 = 1.4031 loss)
I1030 03:17:26.318266 27430 sgd_solver.cpp:105] Iteration 26240, lr = 0.000386435
I1030 03:17:55.946421 27430 solver.cpp:222] Iteration 26280 (1.3501 iter/s, 29.6275s/40 iters), loss = 1.39034
I1030 03:17:55.946837 27430 solver.cpp:241]     Train net output #0: loss = 1.39034 (* 1 = 1.39034 loss)
I1030 03:17:55.946874 27430 sgd_solver.cpp:105] Iteration 26280, lr = 0.000384524
I1030 03:18:25.930785 27430 solver.cpp:222] Iteration 26320 (1.33408 iter/s, 29.9833s/40 iters), loss = 1.20326
I1030 03:18:25.931324 27430 solver.cpp:241]     Train net output #0: loss = 1.20326 (* 1 = 1.20326 loss)
I1030 03:18:25.931375 27430 sgd_solver.cpp:105] Iteration 26320, lr = 0.000382621
I1030 03:18:55.323910 27430 solver.cpp:222] Iteration 26360 (1.36092 iter/s, 29.3919s/40 iters), loss = 1.48778
I1030 03:18:55.324359 27430 solver.cpp:241]     Train net output #0: loss = 1.48778 (* 1 = 1.48778 loss)
I1030 03:18:55.324398 27430 sgd_solver.cpp:105] Iteration 26360, lr = 0.000380729
I1030 03:19:25.699626 27430 solver.cpp:222] Iteration 26400 (1.31689 iter/s, 30.3746s/40 iters), loss = 1.34562
I1030 03:19:25.700167 27430 solver.cpp:241]     Train net output #0: loss = 1.34562 (* 1 = 1.34562 loss)
I1030 03:19:25.700199 27430 sgd_solver.cpp:105] Iteration 26400, lr = 0.000378845
I1030 03:19:56.252514 27430 solver.cpp:222] Iteration 26440 (1.30926 iter/s, 30.5516s/40 iters), loss = 1.30286
I1030 03:19:56.252713 27430 solver.cpp:241]     Train net output #0: loss = 1.30286 (* 1 = 1.30286 loss)
I1030 03:19:56.252729 27430 sgd_solver.cpp:105] Iteration 26440, lr = 0.000376971
I1030 03:20:26.426946 27430 solver.cpp:222] Iteration 26480 (1.32567 iter/s, 30.1735s/40 iters), loss = 1.7147
I1030 03:20:26.427114 27430 solver.cpp:241]     Train net output #0: loss = 1.7147 (* 1 = 1.7147 loss)
I1030 03:20:26.427129 27430 sgd_solver.cpp:105] Iteration 26480, lr = 0.000375106
I1030 03:20:40.828981 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_26500.caffemodel
I1030 03:20:40.977123 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_26500.solverstate
I1030 03:20:41.113054 27430 solver.cpp:334] Iteration 26500, Testing net (#0)
I1030 03:21:12.131484 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1030 03:21:12.342538 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58544
I1030 03:21:12.342581 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.812599
I1030 03:21:12.342592 27430 solver.cpp:401]     Test net output #2: loss = 1.84229 (* 1 = 1.84229 loss)
I1030 03:21:28.346384 27430 solver.cpp:222] Iteration 26520 (0.646018 iter/s, 61.9178s/40 iters), loss = 1.42266
I1030 03:21:28.346468 27430 solver.cpp:241]     Train net output #0: loss = 1.42266 (* 1 = 1.42266 loss)
I1030 03:21:28.346489 27430 sgd_solver.cpp:105] Iteration 26520, lr = 0.00037325
I1030 03:21:59.947134 27430 solver.cpp:222] Iteration 26560 (1.26583 iter/s, 31.5999s/40 iters), loss = 1.2993
I1030 03:21:59.947731 27430 solver.cpp:241]     Train net output #0: loss = 1.2993 (* 1 = 1.2993 loss)
I1030 03:21:59.947779 27430 sgd_solver.cpp:105] Iteration 26560, lr = 0.000371404
I1030 03:22:30.361552 27430 solver.cpp:222] Iteration 26600 (1.31522 iter/s, 30.4131s/40 iters), loss = 1.70963
I1030 03:22:30.362107 27430 solver.cpp:241]     Train net output #0: loss = 1.70963 (* 1 = 1.70963 loss)
I1030 03:22:30.362143 27430 sgd_solver.cpp:105] Iteration 26600, lr = 0.000369566
I1030 03:23:00.491258 27430 solver.cpp:222] Iteration 26640 (1.32765 iter/s, 30.1285s/40 iters), loss = 1.24101
I1030 03:23:00.491433 27430 solver.cpp:241]     Train net output #0: loss = 1.24101 (* 1 = 1.24101 loss)
I1030 03:23:00.491449 27430 sgd_solver.cpp:105] Iteration 26640, lr = 0.000367738
I1030 03:23:30.271484 27430 solver.cpp:222] Iteration 26680 (1.34321 iter/s, 29.7793s/40 iters), loss = 1.52677
I1030 03:23:30.271550 27430 solver.cpp:241]     Train net output #0: loss = 1.52677 (* 1 = 1.52677 loss)
I1030 03:23:30.271562 27430 sgd_solver.cpp:105] Iteration 26680, lr = 0.000365919
I1030 03:24:00.628689 27430 solver.cpp:222] Iteration 26720 (1.31768 iter/s, 30.3564s/40 iters), loss = 1.48544
I1030 03:24:00.629005 27430 solver.cpp:241]     Train net output #0: loss = 1.48544 (* 1 = 1.48544 loss)
I1030 03:24:00.629037 27430 sgd_solver.cpp:105] Iteration 26720, lr = 0.000364109
I1030 03:24:30.001039 27430 solver.cpp:222] Iteration 26760 (1.36187 iter/s, 29.3714s/40 iters), loss = 1.19584
I1030 03:24:30.001446 27430 solver.cpp:241]     Train net output #0: loss = 1.19584 (* 1 = 1.19584 loss)
I1030 03:24:30.001490 27430 sgd_solver.cpp:105] Iteration 26760, lr = 0.000362307
I1030 03:24:59.725380 27430 solver.cpp:222] Iteration 26800 (1.34575 iter/s, 29.7233s/40 iters), loss = 1.49783
I1030 03:24:59.726228 27430 solver.cpp:241]     Train net output #0: loss = 1.49783 (* 1 = 1.49783 loss)
I1030 03:24:59.726282 27430 sgd_solver.cpp:105] Iteration 26800, lr = 0.000360515
I1030 03:25:29.224376 27430 solver.cpp:222] Iteration 26840 (1.35605 iter/s, 29.4975s/40 iters), loss = 1.39019
I1030 03:25:29.224839 27430 solver.cpp:241]     Train net output #0: loss = 1.39019 (* 1 = 1.39019 loss)
I1030 03:25:29.224895 27430 sgd_solver.cpp:105] Iteration 26840, lr = 0.000358731
I1030 03:25:58.679350 27430 solver.cpp:222] Iteration 26880 (1.35806 iter/s, 29.4539s/40 iters), loss = 1.37528
I1030 03:25:58.679890 27430 solver.cpp:241]     Train net output #0: loss = 1.37528 (* 1 = 1.37528 loss)
I1030 03:25:58.680039 27430 sgd_solver.cpp:105] Iteration 26880, lr = 0.000356957
I1030 03:26:28.231925 27430 solver.cpp:222] Iteration 26920 (1.35358 iter/s, 29.5514s/40 iters), loss = 1.16124
I1030 03:26:28.232362 27430 solver.cpp:241]     Train net output #0: loss = 1.16124 (* 1 = 1.16124 loss)
I1030 03:26:28.232405 27430 sgd_solver.cpp:105] Iteration 26920, lr = 0.000355191
I1030 03:26:57.924582 27430 solver.cpp:222] Iteration 26960 (1.34718 iter/s, 29.6916s/40 iters), loss = 1.44956
I1030 03:26:57.925130 27430 solver.cpp:241]     Train net output #0: loss = 1.44956 (* 1 = 1.44956 loss)
I1030 03:26:57.925179 27430 sgd_solver.cpp:105] Iteration 26960, lr = 0.000353434
I1030 03:27:27.267235 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_27000.caffemodel
I1030 03:27:27.411447 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_27000.solverstate
I1030 03:27:27.525676 27430 solver.cpp:334] Iteration 27000, Testing net (#0)
I1030 03:27:58.895694 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58744
I1030 03:27:58.895864 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80908
I1030 03:27:58.895879 27430 solver.cpp:401]     Test net output #2: loss = 1.83766 (* 1 = 1.83766 loss)
I1030 03:27:59.663627 27430 solver.cpp:222] Iteration 27000 (0.647909 iter/s, 61.7371s/40 iters), loss = 1.41392
I1030 03:27:59.663671 27430 solver.cpp:241]     Train net output #0: loss = 1.41392 (* 1 = 1.41392 loss)
I1030 03:27:59.663689 27430 sgd_solver.cpp:105] Iteration 27000, lr = 0.000351685
I1030 03:28:31.029979 27430 solver.cpp:222] Iteration 27040 (1.27528 iter/s, 31.3656s/40 iters), loss = 1.63404
I1030 03:28:31.030473 27430 solver.cpp:241]     Train net output #0: loss = 1.63404 (* 1 = 1.63404 loss)
I1030 03:28:31.030489 27430 sgd_solver.cpp:105] Iteration 27040, lr = 0.000349945
I1030 03:29:01.210041 27430 solver.cpp:222] Iteration 27080 (1.32543 iter/s, 30.1789s/40 iters), loss = 1.54682
I1030 03:29:01.210664 27430 solver.cpp:241]     Train net output #0: loss = 1.54682 (* 1 = 1.54682 loss)
I1030 03:29:01.210716 27430 sgd_solver.cpp:105] Iteration 27080, lr = 0.000348214
I1030 03:29:31.568050 27430 solver.cpp:222] Iteration 27120 (1.31767 iter/s, 30.3567s/40 iters), loss = 1.04043
I1030 03:29:31.568665 27430 solver.cpp:241]     Train net output #0: loss = 1.04043 (* 1 = 1.04043 loss)
I1030 03:29:31.568713 27430 sgd_solver.cpp:105] Iteration 27120, lr = 0.000346491
I1030 03:30:02.168851 27430 solver.cpp:222] Iteration 27160 (1.30721 iter/s, 30.5995s/40 iters), loss = 1.2065
I1030 03:30:02.169399 27430 solver.cpp:241]     Train net output #0: loss = 1.2065 (* 1 = 1.2065 loss)
I1030 03:30:02.169436 27430 sgd_solver.cpp:105] Iteration 27160, lr = 0.000344777
I1030 03:30:32.758401 27430 solver.cpp:222] Iteration 27200 (1.30769 iter/s, 30.5883s/40 iters), loss = 1.68836
I1030 03:30:32.758558 27430 solver.cpp:241]     Train net output #0: loss = 1.68836 (* 1 = 1.68836 loss)
I1030 03:30:32.758572 27430 sgd_solver.cpp:105] Iteration 27200, lr = 0.000343072
I1030 03:31:03.344734 27430 solver.cpp:222] Iteration 27240 (1.30781 iter/s, 30.5854s/40 iters), loss = 1.53903
I1030 03:31:03.345301 27430 solver.cpp:241]     Train net output #0: loss = 1.53903 (* 1 = 1.53903 loss)
I1030 03:31:03.345348 27430 sgd_solver.cpp:105] Iteration 27240, lr = 0.000341374
I1030 03:31:32.938302 27430 solver.cpp:222] Iteration 27280 (1.3517 iter/s, 29.5923s/40 iters), loss = 1.27881
I1030 03:31:32.938669 27430 solver.cpp:241]     Train net output #0: loss = 1.27881 (* 1 = 1.27881 loss)
I1030 03:31:32.938704 27430 sgd_solver.cpp:105] Iteration 27280, lr = 0.000339685
I1030 03:32:04.171093 27430 solver.cpp:222] Iteration 27320 (1.28075 iter/s, 31.2317s/40 iters), loss = 1.31194
I1030 03:32:04.171577 27430 solver.cpp:241]     Train net output #0: loss = 1.31194 (* 1 = 1.31194 loss)
I1030 03:32:04.171609 27430 sgd_solver.cpp:105] Iteration 27320, lr = 0.000338005
I1030 03:32:34.518805 27430 solver.cpp:222] Iteration 27360 (1.31811 iter/s, 30.3465s/40 iters), loss = 1.46605
I1030 03:32:34.519004 27430 solver.cpp:241]     Train net output #0: loss = 1.46605 (* 1 = 1.46605 loss)
I1030 03:32:34.519018 27430 sgd_solver.cpp:105] Iteration 27360, lr = 0.000336333
I1030 03:33:04.876731 27430 solver.cpp:222] Iteration 27400 (1.31765 iter/s, 30.357s/40 iters), loss = 1.34018
I1030 03:33:04.876850 27430 solver.cpp:241]     Train net output #0: loss = 1.34018 (* 1 = 1.34018 loss)
I1030 03:33:04.876865 27430 sgd_solver.cpp:105] Iteration 27400, lr = 0.000334669
I1030 03:33:34.733654 27430 solver.cpp:222] Iteration 27440 (1.33976 iter/s, 29.8561s/40 iters), loss = 1.52087
I1030 03:33:34.734102 27430 solver.cpp:241]     Train net output #0: loss = 1.52087 (* 1 = 1.52087 loss)
I1030 03:33:34.734151 27430 sgd_solver.cpp:105] Iteration 27440, lr = 0.000333013
I1030 03:34:05.145289 27430 solver.cpp:222] Iteration 27480 (1.31534 iter/s, 30.4105s/40 iters), loss = 1.40578
I1030 03:34:05.145807 27430 solver.cpp:241]     Train net output #0: loss = 1.40578 (* 1 = 1.40578 loss)
I1030 03:34:05.145830 27430 sgd_solver.cpp:105] Iteration 27480, lr = 0.000331366
I1030 03:34:19.217666 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_27500.caffemodel
I1030 03:34:19.368489 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_27500.solverstate
I1030 03:34:19.487645 27430 solver.cpp:334] Iteration 27500, Testing net (#0)
I1030 03:34:50.448729 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1030 03:34:50.658686 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58636
I1030 03:34:50.658735 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81328
I1030 03:34:50.658747 27430 solver.cpp:401]     Test net output #2: loss = 1.83907 (* 1 = 1.83907 loss)
I1030 03:35:06.695721 27430 solver.cpp:222] Iteration 27520 (0.649894 iter/s, 61.5485s/40 iters), loss = 1.36384
I1030 03:35:06.696175 27430 solver.cpp:241]     Train net output #0: loss = 1.36384 (* 1 = 1.36384 loss)
I1030 03:35:06.696220 27430 sgd_solver.cpp:105] Iteration 27520, lr = 0.000329727
I1030 03:35:07.497051 27479 data_layer.cpp:73] Restarting data prefetching from start.
I1030 03:35:36.516294 27430 solver.cpp:222] Iteration 27560 (1.34141 iter/s, 29.8194s/40 iters), loss = 1.32911
I1030 03:35:36.516908 27430 solver.cpp:241]     Train net output #0: loss = 1.32911 (* 1 = 1.32911 loss)
I1030 03:35:36.517194 27430 sgd_solver.cpp:105] Iteration 27560, lr = 0.000328095
I1030 03:36:06.006052 27430 solver.cpp:222] Iteration 27600 (1.35646 iter/s, 29.4885s/40 iters), loss = 1.49873
I1030 03:36:06.006537 27430 solver.cpp:241]     Train net output #0: loss = 1.49873 (* 1 = 1.49873 loss)
I1030 03:36:06.006603 27430 sgd_solver.cpp:105] Iteration 27600, lr = 0.000326472
I1030 03:36:35.789959 27430 solver.cpp:222] Iteration 27640 (1.34306 iter/s, 29.7827s/40 iters), loss = 1.3137
I1030 03:36:35.790544 27430 solver.cpp:241]     Train net output #0: loss = 1.3137 (* 1 = 1.3137 loss)
I1030 03:36:35.790588 27430 sgd_solver.cpp:105] Iteration 27640, lr = 0.000324857
I1030 03:37:05.546352 27430 solver.cpp:222] Iteration 27680 (1.34431 iter/s, 29.7551s/40 iters), loss = 1.37074
I1030 03:37:05.547133 27430 solver.cpp:241]     Train net output #0: loss = 1.37074 (* 1 = 1.37074 loss)
I1030 03:37:05.547188 27430 sgd_solver.cpp:105] Iteration 27680, lr = 0.00032325
I1030 03:37:35.324738 27430 solver.cpp:222] Iteration 27720 (1.34332 iter/s, 29.7769s/40 iters), loss = 1.16039
I1030 03:37:35.325248 27430 solver.cpp:241]     Train net output #0: loss = 1.16039 (* 1 = 1.16039 loss)
I1030 03:37:35.325275 27430 sgd_solver.cpp:105] Iteration 27720, lr = 0.000321651
I1030 03:38:04.924629 27430 solver.cpp:222] Iteration 27760 (1.35141 iter/s, 29.5987s/40 iters), loss = 1.22445
I1030 03:38:04.925091 27430 solver.cpp:241]     Train net output #0: loss = 1.22445 (* 1 = 1.22445 loss)
I1030 03:38:04.925140 27430 sgd_solver.cpp:105] Iteration 27760, lr = 0.00032006
I1030 03:38:35.090546 27430 solver.cpp:222] Iteration 27800 (1.32605 iter/s, 30.1648s/40 iters), loss = 1.37969
I1030 03:38:35.090734 27430 solver.cpp:241]     Train net output #0: loss = 1.37969 (* 1 = 1.37969 loss)
I1030 03:38:35.090749 27430 sgd_solver.cpp:105] Iteration 27800, lr = 0.000318476
I1030 03:39:22.575387 27430 solver.cpp:222] Iteration 27840 (0.842397 iter/s, 47.4835s/40 iters), loss = 1.51043
I1030 03:39:22.575878 27430 solver.cpp:241]     Train net output #0: loss = 1.51043 (* 1 = 1.51043 loss)
I1030 03:39:22.576011 27430 sgd_solver.cpp:105] Iteration 27840, lr = 0.000316901
I1030 03:39:52.311518 27430 solver.cpp:222] Iteration 27880 (1.34522 iter/s, 29.735s/40 iters), loss = 1.55478
I1030 03:39:52.311910 27430 solver.cpp:241]     Train net output #0: loss = 1.55478 (* 1 = 1.55478 loss)
I1030 03:39:52.312180 27430 sgd_solver.cpp:105] Iteration 27880, lr = 0.000315333
I1030 03:40:33.149030 27430 solver.cpp:222] Iteration 27920 (0.979523 iter/s, 40.8362s/40 iters), loss = 1.71849
I1030 03:40:33.149652 27430 solver.cpp:241]     Train net output #0: loss = 1.71849 (* 1 = 1.71849 loss)
I1030 03:40:33.149700 27430 sgd_solver.cpp:105] Iteration 27920, lr = 0.000313773
I1030 03:41:02.651587 27430 solver.cpp:222] Iteration 27960 (1.35587 iter/s, 29.5013s/40 iters), loss = 1.2696
I1030 03:41:02.652202 27430 solver.cpp:241]     Train net output #0: loss = 1.2696 (* 1 = 1.2696 loss)
I1030 03:41:02.652243 27430 sgd_solver.cpp:105] Iteration 27960, lr = 0.000312221
I1030 03:41:31.392699 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_28000.caffemodel
I1030 03:41:31.537082 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_28000.solverstate
I1030 03:41:31.661406 27430 solver.cpp:334] Iteration 28000, Testing net (#0)
I1030 03:42:02.857522 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58832
I1030 03:42:02.857599 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.809599
I1030 03:42:02.857610 27430 solver.cpp:401]     Test net output #2: loss = 1.83667 (* 1 = 1.83667 loss)
I1030 03:42:03.606503 27430 solver.cpp:222] Iteration 28000 (0.656244 iter/s, 60.9529s/40 iters), loss = 0.963463
I1030 03:42:03.606561 27430 solver.cpp:241]     Train net output #0: loss = 0.963463 (* 1 = 0.963463 loss)
I1030 03:42:03.606575 27430 sgd_solver.cpp:105] Iteration 28000, lr = 0.000310676
I1030 03:42:33.327312 27430 solver.cpp:222] Iteration 28040 (1.34589 iter/s, 29.72s/40 iters), loss = 1.07964
I1030 03:42:33.327863 27430 solver.cpp:241]     Train net output #0: loss = 1.07964 (* 1 = 1.07964 loss)
I1030 03:42:33.328006 27430 sgd_solver.cpp:105] Iteration 28040, lr = 0.000309139
I1030 03:43:03.010042 27430 solver.cpp:222] Iteration 28080 (1.34764 iter/s, 29.6815s/40 iters), loss = 1.29049
I1030 03:43:03.010515 27430 solver.cpp:241]     Train net output #0: loss = 1.29049 (* 1 = 1.29049 loss)
I1030 03:43:03.010572 27430 sgd_solver.cpp:105] Iteration 28080, lr = 0.00030761
I1030 03:43:33.073339 27430 solver.cpp:222] Iteration 28120 (1.33058 iter/s, 30.0622s/40 iters), loss = 1.17564
I1030 03:43:33.073526 27430 solver.cpp:241]     Train net output #0: loss = 1.17564 (* 1 = 1.17564 loss)
I1030 03:43:33.073540 27430 sgd_solver.cpp:105] Iteration 28120, lr = 0.000306088
I1030 03:44:17.216270 27430 solver.cpp:222] Iteration 28160 (0.906172 iter/s, 44.1417s/40 iters), loss = 1.34498
I1030 03:44:17.216820 27430 solver.cpp:241]     Train net output #0: loss = 1.34498 (* 1 = 1.34498 loss)
I1030 03:44:17.216866 27430 sgd_solver.cpp:105] Iteration 28160, lr = 0.000304574
I1030 03:44:47.566435 27430 solver.cpp:222] Iteration 28200 (1.318 iter/s, 30.3489s/40 iters), loss = 0.984708
I1030 03:44:47.567205 27430 solver.cpp:241]     Train net output #0: loss = 0.984708 (* 1 = 0.984708 loss)
I1030 03:44:47.567246 27430 sgd_solver.cpp:105] Iteration 28200, lr = 0.000303067
I1030 03:45:25.003218 27430 solver.cpp:222] Iteration 28240 (1.06851 iter/s, 37.4351s/40 iters), loss = 1.21351
I1030 03:45:25.003847 27430 solver.cpp:241]     Train net output #0: loss = 1.21351 (* 1 = 1.21351 loss)
I1030 03:45:25.003895 27430 sgd_solver.cpp:105] Iteration 28240, lr = 0.000301568
I1030 03:46:41.338125 27430 solver.cpp:222] Iteration 28280 (0.524023 iter/s, 76.3326s/40 iters), loss = 1.46663
I1030 03:46:41.338703 27430 solver.cpp:241]     Train net output #0: loss = 1.46663 (* 1 = 1.46663 loss)
I1030 03:46:41.338755 27430 sgd_solver.cpp:105] Iteration 28280, lr = 0.000300076
I1030 03:47:11.905573 27430 solver.cpp:222] Iteration 28320 (1.30864 iter/s, 30.5662s/40 iters), loss = 1.38417
I1030 03:47:11.905762 27430 solver.cpp:241]     Train net output #0: loss = 1.38417 (* 1 = 1.38417 loss)
I1030 03:47:11.905776 27430 sgd_solver.cpp:105] Iteration 28320, lr = 0.000298591
I1030 03:47:41.857373 27430 solver.cpp:222] Iteration 28360 (1.33552 iter/s, 29.9509s/40 iters), loss = 1.51244
I1030 03:47:41.857766 27430 solver.cpp:241]     Train net output #0: loss = 1.51244 (* 1 = 1.51244 loss)
I1030 03:47:41.857792 27430 sgd_solver.cpp:105] Iteration 28360, lr = 0.000297114
I1030 03:48:56.895095 27430 solver.cpp:222] Iteration 28400 (0.53308 iter/s, 75.0356s/40 iters), loss = 1.47621
I1030 03:48:56.895700 27430 solver.cpp:241]     Train net output #0: loss = 1.47621 (* 1 = 1.47621 loss)
I1030 03:48:56.895750 27430 sgd_solver.cpp:105] Iteration 28400, lr = 0.000295644
I1030 03:49:26.484874 27430 solver.cpp:222] Iteration 28440 (1.35188 iter/s, 29.5885s/40 iters), loss = 1.28423
I1030 03:49:26.485347 27430 solver.cpp:241]     Train net output #0: loss = 1.28423 (* 1 = 1.28423 loss)
I1030 03:49:26.485401 27430 sgd_solver.cpp:105] Iteration 28440, lr = 0.000294182
I1030 03:49:55.949271 27430 solver.cpp:222] Iteration 28480 (1.35762 iter/s, 29.4633s/40 iters), loss = 1.32127
I1030 03:49:55.949796 27430 solver.cpp:241]     Train net output #0: loss = 1.32127 (* 1 = 1.32127 loss)
I1030 03:49:55.949837 27430 sgd_solver.cpp:105] Iteration 28480, lr = 0.000292726
I1030 03:50:33.189266 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_28500.caffemodel
I1030 03:50:33.812185 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_28500.solverstate
I1030 03:50:33.947434 27430 solver.cpp:334] Iteration 28500, Testing net (#0)
I1030 03:51:04.898486 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1030 03:51:05.108114 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58552
I1030 03:51:05.108151 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813799
I1030 03:51:05.108162 27430 solver.cpp:401]     Test net output #2: loss = 1.8418 (* 1 = 1.8418 loss)
I1030 03:51:22.095027 27430 solver.cpp:222] Iteration 28520 (0.464343 iter/s, 86.1433s/40 iters), loss = 1.58869
I1030 03:51:22.095494 27430 solver.cpp:241]     Train net output #0: loss = 1.58869 (* 1 = 1.58869 loss)
I1030 03:51:22.095548 27430 sgd_solver.cpp:105] Iteration 28520, lr = 0.000291278
I1030 03:51:51.720532 27430 solver.cpp:222] Iteration 28560 (1.35024 iter/s, 29.6244s/40 iters), loss = 1.25921
I1030 03:51:51.721155 27430 solver.cpp:241]     Train net output #0: loss = 1.25921 (* 1 = 1.25921 loss)
I1030 03:51:51.721205 27430 sgd_solver.cpp:105] Iteration 28560, lr = 0.000289837
I1030 03:52:20.863910 27430 solver.cpp:222] Iteration 28600 (1.37259 iter/s, 29.1421s/40 iters), loss = 1.72759
I1030 03:52:20.864312 27430 solver.cpp:241]     Train net output #0: loss = 1.72759 (* 1 = 1.72759 loss)
I1030 03:52:20.864351 27430 sgd_solver.cpp:105] Iteration 28600, lr = 0.000288403
I1030 03:52:50.141070 27430 solver.cpp:222] Iteration 28640 (1.3663 iter/s, 29.2761s/40 iters), loss = 1.66027
I1030 03:52:50.141679 27430 solver.cpp:241]     Train net output #0: loss = 1.66027 (* 1 = 1.66027 loss)
I1030 03:52:50.141729 27430 sgd_solver.cpp:105] Iteration 28640, lr = 0.000286976
I1030 03:53:19.536375 27430 solver.cpp:222] Iteration 28680 (1.36082 iter/s, 29.394s/40 iters), loss = 1.14272
I1030 03:53:19.536839 27430 solver.cpp:241]     Train net output #0: loss = 1.14272 (* 1 = 1.14272 loss)
I1030 03:53:19.536890 27430 sgd_solver.cpp:105] Iteration 28680, lr = 0.000285557
I1030 03:54:11.030750 27430 solver.cpp:222] Iteration 28720 (0.776809 iter/s, 51.4927s/40 iters), loss = 1.53307
I1030 03:54:11.031366 27430 solver.cpp:241]     Train net output #0: loss = 1.53307 (* 1 = 1.53307 loss)
I1030 03:54:11.031433 27430 sgd_solver.cpp:105] Iteration 28720, lr = 0.000284144
I1030 03:54:49.638514 27430 solver.cpp:222] Iteration 28760 (1.0361 iter/s, 38.6063s/40 iters), loss = 1.23794
I1030 03:54:49.639145 27430 solver.cpp:241]     Train net output #0: loss = 1.23794 (* 1 = 1.23794 loss)
I1030 03:54:49.639189 27430 sgd_solver.cpp:105] Iteration 28760, lr = 0.000282738
I1030 03:55:22.055373 27430 solver.cpp:222] Iteration 28800 (1.23398 iter/s, 32.4155s/40 iters), loss = 1.64554
I1030 03:55:22.056020 27430 solver.cpp:241]     Train net output #0: loss = 1.64554 (* 1 = 1.64554 loss)
I1030 03:55:22.056072 27430 sgd_solver.cpp:105] Iteration 28800, lr = 0.00028134
I1030 03:55:58.311426 27430 solver.cpp:222] Iteration 28840 (1.10331 iter/s, 36.2546s/40 iters), loss = 1.41586
I1030 03:55:58.311888 27430 solver.cpp:241]     Train net output #0: loss = 1.41586 (* 1 = 1.41586 loss)
I1030 03:55:58.312211 27430 sgd_solver.cpp:105] Iteration 28840, lr = 0.000279948
I1030 03:56:28.562698 27430 solver.cpp:222] Iteration 28880 (1.32231 iter/s, 30.2501s/40 iters), loss = 1.09364
I1030 03:56:28.562901 27430 solver.cpp:241]     Train net output #0: loss = 1.09364 (* 1 = 1.09364 loss)
I1030 03:56:28.562916 27430 sgd_solver.cpp:105] Iteration 28880, lr = 0.000278563
I1030 03:56:58.293718 27430 solver.cpp:222] Iteration 28920 (1.34544 iter/s, 29.7301s/40 iters), loss = 1.59484
I1030 03:56:58.294168 27430 solver.cpp:241]     Train net output #0: loss = 1.59484 (* 1 = 1.59484 loss)
I1030 03:56:58.294219 27430 sgd_solver.cpp:105] Iteration 28920, lr = 0.000277185
I1030 03:57:27.690985 27430 solver.cpp:222] Iteration 28960 (1.36072 iter/s, 29.3961s/40 iters), loss = 1.56796
I1030 03:57:27.691558 27430 solver.cpp:241]     Train net output #0: loss = 1.56796 (* 1 = 1.56796 loss)
I1030 03:57:27.691608 27430 sgd_solver.cpp:105] Iteration 28960, lr = 0.000275813
I1030 03:57:56.558787 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_29000.caffemodel
I1030 03:57:56.708652 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_29000.solverstate
I1030 03:57:56.833863 27430 solver.cpp:334] Iteration 29000, Testing net (#0)
I1030 03:58:28.134176 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58848
I1030 03:58:28.134452 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80884
I1030 03:58:28.134483 27430 solver.cpp:401]     Test net output #2: loss = 1.83666 (* 1 = 1.83666 loss)
I1030 03:58:28.882403 27430 solver.cpp:222] Iteration 29000 (0.653707 iter/s, 61.1895s/40 iters), loss = 1.49767
I1030 03:58:28.882441 27430 solver.cpp:241]     Train net output #0: loss = 1.49767 (* 1 = 1.49767 loss)
I1030 03:58:28.882452 27430 sgd_solver.cpp:105] Iteration 29000, lr = 0.000274449
I1030 03:58:58.063910 27430 solver.cpp:222] Iteration 29040 (1.37077 iter/s, 29.1808s/40 iters), loss = 1.50587
I1030 03:58:58.064362 27430 solver.cpp:241]     Train net output #0: loss = 1.50587 (* 1 = 1.50587 loss)
I1030 03:58:58.064407 27430 sgd_solver.cpp:105] Iteration 29040, lr = 0.000273091
I1030 03:59:27.521939 27430 solver.cpp:222] Iteration 29080 (1.35792 iter/s, 29.4569s/40 iters), loss = 1.39548
I1030 03:59:27.522482 27430 solver.cpp:241]     Train net output #0: loss = 1.39548 (* 1 = 1.39548 loss)
I1030 03:59:27.522517 27430 sgd_solver.cpp:105] Iteration 29080, lr = 0.00027174
I1030 03:59:57.288897 27430 solver.cpp:222] Iteration 29120 (1.34383 iter/s, 29.7657s/40 iters), loss = 1.20827
I1030 03:59:57.289322 27430 solver.cpp:241]     Train net output #0: loss = 1.20827 (* 1 = 1.20827 loss)
I1030 03:59:57.289357 27430 sgd_solver.cpp:105] Iteration 29120, lr = 0.000270396
I1030 04:00:27.520167 27430 solver.cpp:222] Iteration 29160 (1.32318 iter/s, 30.2301s/40 iters), loss = 1.35863
I1030 04:00:27.520359 27430 solver.cpp:241]     Train net output #0: loss = 1.35863 (* 1 = 1.35863 loss)
I1030 04:00:27.520373 27430 sgd_solver.cpp:105] Iteration 29160, lr = 0.000269058
I1030 04:00:57.740458 27430 solver.cpp:222] Iteration 29200 (1.32365 iter/s, 30.2194s/40 iters), loss = 1.14144
I1030 04:00:57.740623 27430 solver.cpp:241]     Train net output #0: loss = 1.14144 (* 1 = 1.14144 loss)
I1030 04:00:57.740638 27430 sgd_solver.cpp:105] Iteration 29200, lr = 0.000267727
I1030 04:01:27.625789 27430 solver.cpp:222] Iteration 29240 (1.33849 iter/s, 29.8845s/40 iters), loss = 1.42991
I1030 04:01:27.626237 27430 solver.cpp:241]     Train net output #0: loss = 1.42991 (* 1 = 1.42991 loss)
I1030 04:01:27.626273 27430 sgd_solver.cpp:105] Iteration 29240, lr = 0.000266403
I1030 04:01:57.139619 27430 solver.cpp:222] Iteration 29280 (1.35535 iter/s, 29.5127s/40 iters), loss = 1.55437
I1030 04:01:57.140197 27430 solver.cpp:241]     Train net output #0: loss = 1.55437 (* 1 = 1.55437 loss)
I1030 04:01:57.140231 27430 sgd_solver.cpp:105] Iteration 29280, lr = 0.000265085
I1030 04:02:26.870086 27430 solver.cpp:222] Iteration 29320 (1.34548 iter/s, 29.7292s/40 iters), loss = 1.26232
I1030 04:02:26.870508 27430 solver.cpp:241]     Train net output #0: loss = 1.26232 (* 1 = 1.26232 loss)
I1030 04:02:26.870551 27430 sgd_solver.cpp:105] Iteration 29320, lr = 0.000263773
I1030 04:02:56.139596 27430 solver.cpp:222] Iteration 29360 (1.36666 iter/s, 29.2684s/40 iters), loss = 1.16556
I1030 04:02:56.140163 27430 solver.cpp:241]     Train net output #0: loss = 1.16556 (* 1 = 1.16556 loss)
I1030 04:02:56.140213 27430 sgd_solver.cpp:105] Iteration 29360, lr = 0.000262468
I1030 04:03:25.621709 27430 solver.cpp:222] Iteration 29400 (1.35681 iter/s, 29.4809s/40 iters), loss = 1.62467
I1030 04:03:25.622174 27430 solver.cpp:241]     Train net output #0: loss = 1.62467 (* 1 = 1.62467 loss)
I1030 04:03:25.622223 27430 sgd_solver.cpp:105] Iteration 29400, lr = 0.00026117
I1030 04:03:55.099793 27430 solver.cpp:222] Iteration 29440 (1.35699 iter/s, 29.477s/40 iters), loss = 1.45068
I1030 04:03:55.100255 27430 solver.cpp:241]     Train net output #0: loss = 1.45068 (* 1 = 1.45068 loss)
I1030 04:03:55.100288 27430 sgd_solver.cpp:105] Iteration 29440, lr = 0.000259878
I1030 04:04:24.652380 27430 solver.cpp:222] Iteration 29480 (1.35357 iter/s, 29.5514s/40 iters), loss = 1.50121
I1030 04:04:24.652842 27430 solver.cpp:241]     Train net output #0: loss = 1.50121 (* 1 = 1.50121 loss)
I1030 04:04:24.652887 27430 sgd_solver.cpp:105] Iteration 29480, lr = 0.000258592
I1030 04:04:38.709846 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_29500.caffemodel
I1030 04:04:38.863765 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_29500.solverstate
I1030 04:04:38.980664 27430 solver.cpp:334] Iteration 29500, Testing net (#0)
I1030 04:05:10.001451 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1030 04:05:10.211117 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5858
I1030 04:05:10.211170 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.814119
I1030 04:05:10.211184 27430 solver.cpp:401]     Test net output #2: loss = 1.83819 (* 1 = 1.83819 loss)
I1030 04:05:25.594193 27430 solver.cpp:222] Iteration 29520 (0.656384 iter/s, 60.9399s/40 iters), loss = 1.26083
I1030 04:05:25.594655 27430 solver.cpp:241]     Train net output #0: loss = 1.26083 (* 1 = 1.26083 loss)
I1030 04:05:25.594707 27430 sgd_solver.cpp:105] Iteration 29520, lr = 0.000257313
I1030 04:05:55.110671 27430 solver.cpp:222] Iteration 29560 (1.35523 iter/s, 29.5153s/40 iters), loss = 1.63577
I1030 04:05:55.111188 27430 solver.cpp:241]     Train net output #0: loss = 1.63577 (* 1 = 1.63577 loss)
I1030 04:05:55.111234 27430 sgd_solver.cpp:105] Iteration 29560, lr = 0.00025604
I1030 04:06:24.719832 27430 solver.cpp:222] Iteration 29600 (1.35099 iter/s, 29.608s/40 iters), loss = 1.33913
I1030 04:06:24.720293 27430 solver.cpp:241]     Train net output #0: loss = 1.33913 (* 1 = 1.33913 loss)
I1030 04:06:24.720342 27430 sgd_solver.cpp:105] Iteration 29600, lr = 0.000254773
I1030 04:06:54.471310 27430 solver.cpp:222] Iteration 29640 (1.34452 iter/s, 29.7503s/40 iters), loss = 1.37146
I1030 04:06:54.471890 27430 solver.cpp:241]     Train net output #0: loss = 1.37146 (* 1 = 1.37146 loss)
I1030 04:06:54.472168 27430 sgd_solver.cpp:105] Iteration 29640, lr = 0.000253513
I1030 04:07:24.459535 27430 solver.cpp:222] Iteration 29680 (1.33391 iter/s, 29.987s/40 iters), loss = 1.22479
I1030 04:07:24.460055 27430 solver.cpp:241]     Train net output #0: loss = 1.22479 (* 1 = 1.22479 loss)
I1030 04:07:24.460099 27430 sgd_solver.cpp:105] Iteration 29680, lr = 0.000252259
I1030 04:07:54.416858 27430 solver.cpp:222] Iteration 29720 (1.33528 iter/s, 29.9562s/40 iters), loss = 1.41366
I1030 04:07:54.417368 27430 solver.cpp:241]     Train net output #0: loss = 1.41366 (* 1 = 1.41366 loss)
I1030 04:07:54.417412 27430 sgd_solver.cpp:105] Iteration 29720, lr = 0.000251011
I1030 04:08:24.094344 27430 solver.cpp:222] Iteration 29760 (1.34788 iter/s, 29.6763s/40 iters), loss = 1.44717
I1030 04:08:24.094769 27430 solver.cpp:241]     Train net output #0: loss = 1.44717 (* 1 = 1.44717 loss)
I1030 04:08:24.094821 27430 sgd_solver.cpp:105] Iteration 29760, lr = 0.000249769
I1030 04:08:53.963811 27430 solver.cpp:222] Iteration 29800 (1.33921 iter/s, 29.8684s/40 iters), loss = 1.74762
I1030 04:08:53.964350 27430 solver.cpp:241]     Train net output #0: loss = 1.74762 (* 1 = 1.74762 loss)
I1030 04:08:53.964387 27430 sgd_solver.cpp:105] Iteration 29800, lr = 0.000248533
I1030 04:09:23.698828 27430 solver.cpp:222] Iteration 29840 (1.34527 iter/s, 29.7338s/40 iters), loss = 1.33872
I1030 04:09:23.699282 27430 solver.cpp:241]     Train net output #0: loss = 1.33872 (* 1 = 1.33872 loss)
I1030 04:09:23.699335 27430 sgd_solver.cpp:105] Iteration 29840, lr = 0.000247304
I1030 04:09:53.297040 27430 solver.cpp:222] Iteration 29880 (1.35149 iter/s, 29.5971s/40 iters), loss = 1.41031
I1030 04:09:53.297508 27430 solver.cpp:241]     Train net output #0: loss = 1.41031 (* 1 = 1.41031 loss)
I1030 04:09:53.297533 27430 sgd_solver.cpp:105] Iteration 29880, lr = 0.00024608
I1030 04:10:23.331864 27430 solver.cpp:222] Iteration 29920 (1.33184 iter/s, 30.0337s/40 iters), loss = 1.26153
I1030 04:10:23.332461 27430 solver.cpp:241]     Train net output #0: loss = 1.26153 (* 1 = 1.26153 loss)
I1030 04:10:23.332515 27430 sgd_solver.cpp:105] Iteration 29920, lr = 0.000244863
I1030 04:10:52.579552 27430 solver.cpp:222] Iteration 29960 (1.36769 iter/s, 29.2464s/40 iters), loss = 1.28037
I1030 04:10:52.580152 27430 solver.cpp:241]     Train net output #0: loss = 1.28037 (* 1 = 1.28037 loss)
I1030 04:10:52.580204 27430 sgd_solver.cpp:105] Iteration 29960, lr = 0.000243652
I1030 04:11:22.454991 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_30000.caffemodel
I1030 04:11:22.599432 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_30000.solverstate
I1030 04:11:22.718408 27430 solver.cpp:334] Iteration 30000, Testing net (#0)
I1030 04:11:55.090629 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5868
I1030 04:11:55.090762 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80892
I1030 04:11:55.090776 27430 solver.cpp:401]     Test net output #2: loss = 1.83466 (* 1 = 1.83466 loss)
I1030 04:11:55.841953 27430 solver.cpp:222] Iteration 30000 (0.632308 iter/s, 63.2603s/40 iters), loss = 1.33294
I1030 04:11:55.842419 27430 solver.cpp:241]     Train net output #0: loss = 1.33294 (* 1 = 1.33294 loss)
I1030 04:11:55.842469 27430 sgd_solver.cpp:105] Iteration 30000, lr = 0.000242446
I1030 04:12:15.970829 27479 data_layer.cpp:73] Restarting data prefetching from start.
I1030 04:12:42.010962 27430 solver.cpp:222] Iteration 30040 (0.866411 iter/s, 46.1675s/40 iters), loss = 1.29203
I1030 04:12:42.011575 27430 solver.cpp:241]     Train net output #0: loss = 1.29203 (* 1 = 1.29203 loss)
I1030 04:12:42.011634 27430 sgd_solver.cpp:105] Iteration 30040, lr = 0.000241247
I1030 04:13:12.343163 27430 solver.cpp:222] Iteration 30080 (1.31879 iter/s, 30.3309s/40 iters), loss = 1.42921
I1030 04:13:12.343343 27430 solver.cpp:241]     Train net output #0: loss = 1.42921 (* 1 = 1.42921 loss)
I1030 04:13:12.343363 27430 sgd_solver.cpp:105] Iteration 30080, lr = 0.000240053
I1030 04:13:41.754518 27430 solver.cpp:222] Iteration 30120 (1.36006 iter/s, 29.4105s/40 iters), loss = 1.16689
I1030 04:13:41.754971 27430 solver.cpp:241]     Train net output #0: loss = 1.16689 (* 1 = 1.16689 loss)
I1030 04:13:41.755005 27430 sgd_solver.cpp:105] Iteration 30120, lr = 0.000238866
I1030 04:14:12.053221 27430 solver.cpp:222] Iteration 30160 (1.32024 iter/s, 30.2976s/40 iters), loss = 1.24279
I1030 04:14:12.053789 27430 solver.cpp:241]     Train net output #0: loss = 1.24279 (* 1 = 1.24279 loss)
I1030 04:14:12.053824 27430 sgd_solver.cpp:105] Iteration 30160, lr = 0.000237684
I1030 04:14:42.182157 27430 solver.cpp:222] Iteration 30200 (1.32768 iter/s, 30.1277s/40 iters), loss = 1.58393
I1030 04:14:42.182339 27430 solver.cpp:241]     Train net output #0: loss = 1.58393 (* 1 = 1.58393 loss)
I1030 04:14:42.182353 27430 sgd_solver.cpp:105] Iteration 30200, lr = 0.000236508
I1030 04:15:11.719179 27430 solver.cpp:222] Iteration 30240 (1.35427 iter/s, 29.5361s/40 iters), loss = 1.35567
I1030 04:15:11.719624 27430 solver.cpp:241]     Train net output #0: loss = 1.35567 (* 1 = 1.35567 loss)
I1030 04:15:11.719676 27430 sgd_solver.cpp:105] Iteration 30240, lr = 0.000235338
I1030 04:15:41.477268 27430 solver.cpp:222] Iteration 30280 (1.34422 iter/s, 29.757s/40 iters), loss = 1.34815
I1030 04:15:41.477910 27430 solver.cpp:241]     Train net output #0: loss = 1.34815 (* 1 = 1.34815 loss)
I1030 04:15:41.478157 27430 sgd_solver.cpp:105] Iteration 30280, lr = 0.000234174
I1030 04:16:11.224467 27430 solver.cpp:222] Iteration 30320 (1.34472 iter/s, 29.7459s/40 iters), loss = 1.44113
I1030 04:16:11.225167 27430 solver.cpp:241]     Train net output #0: loss = 1.44113 (* 1 = 1.44113 loss)
I1030 04:16:11.225219 27430 sgd_solver.cpp:105] Iteration 30320, lr = 0.000233015
I1030 04:16:40.648054 27430 solver.cpp:222] Iteration 30360 (1.35951 iter/s, 29.4225s/40 iters), loss = 1.46695
I1030 04:16:40.648582 27430 solver.cpp:241]     Train net output #0: loss = 1.46695 (* 1 = 1.46695 loss)
I1030 04:16:40.648618 27430 sgd_solver.cpp:105] Iteration 30360, lr = 0.000231863
I1030 04:17:10.170140 27430 solver.cpp:222] Iteration 30400 (1.35497 iter/s, 29.5209s/40 iters), loss = 1.29836
I1030 04:17:10.170616 27430 solver.cpp:241]     Train net output #0: loss = 1.29836 (* 1 = 1.29836 loss)
I1030 04:17:10.170663 27430 sgd_solver.cpp:105] Iteration 30400, lr = 0.000230716
I1030 04:17:39.523852 27430 solver.cpp:222] Iteration 30440 (1.36274 iter/s, 29.3526s/40 iters), loss = 1.56149
I1030 04:17:39.524497 27430 solver.cpp:241]     Train net output #0: loss = 1.56149 (* 1 = 1.56149 loss)
I1030 04:17:39.524549 27430 sgd_solver.cpp:105] Iteration 30440, lr = 0.000229574
I1030 04:18:08.858705 27430 solver.cpp:222] Iteration 30480 (1.36363 iter/s, 29.3335s/40 iters), loss = 1.38582
I1030 04:18:08.859174 27430 solver.cpp:241]     Train net output #0: loss = 1.38582 (* 1 = 1.38582 loss)
I1030 04:18:08.859227 27430 sgd_solver.cpp:105] Iteration 30480, lr = 0.000228438
I1030 04:18:23.079746 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_30500.caffemodel
I1030 04:18:23.237799 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_30500.solverstate
I1030 04:18:23.362607 27430 solver.cpp:334] Iteration 30500, Testing net (#0)
I1030 04:18:54.486826 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1030 04:18:54.700573 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5862
I1030 04:18:54.700624 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81404
I1030 04:18:54.700634 27430 solver.cpp:401]     Test net output #2: loss = 1.83922 (* 1 = 1.83922 loss)
I1030 04:19:10.034322 27430 solver.cpp:222] Iteration 30520 (0.653875 iter/s, 61.1738s/40 iters), loss = 1.23847
I1030 04:19:10.034721 27430 solver.cpp:241]     Train net output #0: loss = 1.23847 (* 1 = 1.23847 loss)
I1030 04:19:10.034757 27430 sgd_solver.cpp:105] Iteration 30520, lr = 0.000227308
I1030 04:19:39.285506 27430 solver.cpp:222] Iteration 30560 (1.36752 iter/s, 29.2501s/40 iters), loss = 1.28032
I1030 04:19:39.286056 27430 solver.cpp:241]     Train net output #0: loss = 1.28032 (* 1 = 1.28032 loss)
I1030 04:19:39.286101 27430 sgd_solver.cpp:105] Iteration 30560, lr = 0.000226184
I1030 04:20:08.613907 27430 solver.cpp:222] Iteration 30600 (1.36392 iter/s, 29.3272s/40 iters), loss = 1.45301
I1030 04:20:08.614327 27430 solver.cpp:241]     Train net output #0: loss = 1.45301 (* 1 = 1.45301 loss)
I1030 04:20:08.614362 27430 sgd_solver.cpp:105] Iteration 30600, lr = 0.000225065
I1030 04:20:37.844337 27430 solver.cpp:222] Iteration 30640 (1.36849 iter/s, 29.2293s/40 iters), loss = 1.6965
I1030 04:20:37.844890 27430 solver.cpp:241]     Train net output #0: loss = 1.6965 (* 1 = 1.6965 loss)
I1030 04:20:37.844974 27430 sgd_solver.cpp:105] Iteration 30640, lr = 0.000223951
I1030 04:21:07.210680 27430 solver.cpp:222] Iteration 30680 (1.36216 iter/s, 29.3651s/40 iters), loss = 1.29825
I1030 04:21:07.211133 27430 solver.cpp:241]     Train net output #0: loss = 1.29825 (* 1 = 1.29825 loss)
I1030 04:21:07.211184 27430 sgd_solver.cpp:105] Iteration 30680, lr = 0.000222844
I1030 04:21:36.645143 27430 solver.cpp:222] Iteration 30720 (1.359 iter/s, 29.4333s/40 iters), loss = 1.31151
I1030 04:21:36.645701 27430 solver.cpp:241]     Train net output #0: loss = 1.31151 (* 1 = 1.31151 loss)
I1030 04:21:36.645753 27430 sgd_solver.cpp:105] Iteration 30720, lr = 0.000221741
I1030 04:22:06.525436 27430 solver.cpp:222] Iteration 30760 (1.33873 iter/s, 29.879s/40 iters), loss = 1.35118
I1030 04:22:06.525849 27430 solver.cpp:241]     Train net output #0: loss = 1.35118 (* 1 = 1.35118 loss)
I1030 04:22:06.525884 27430 sgd_solver.cpp:105] Iteration 30760, lr = 0.000220644
I1030 04:22:36.087903 27430 solver.cpp:222] Iteration 30800 (1.35312 iter/s, 29.5614s/40 iters), loss = 1.39381
I1030 04:22:36.088682 27430 solver.cpp:241]     Train net output #0: loss = 1.39381 (* 1 = 1.39381 loss)
I1030 04:22:36.088716 27430 sgd_solver.cpp:105] Iteration 30800, lr = 0.000219553
I1030 04:23:05.671903 27430 solver.cpp:222] Iteration 30840 (1.35215 iter/s, 29.5825s/40 iters), loss = 1.31443
I1030 04:23:05.672379 27430 solver.cpp:241]     Train net output #0: loss = 1.31443 (* 1 = 1.31443 loss)
I1030 04:23:05.672441 27430 sgd_solver.cpp:105] Iteration 30840, lr = 0.000218466
I1030 04:23:35.149634 27430 solver.cpp:222] Iteration 30880 (1.35701 iter/s, 29.4766s/40 iters), loss = 1.31151
I1030 04:23:35.150213 27430 solver.cpp:241]     Train net output #0: loss = 1.31151 (* 1 = 1.31151 loss)
I1030 04:23:35.150255 27430 sgd_solver.cpp:105] Iteration 30880, lr = 0.000217386
I1030 04:24:04.706948 27430 solver.cpp:222] Iteration 30920 (1.35336 iter/s, 29.556s/40 iters), loss = 1.61041
I1030 04:24:04.707362 27430 solver.cpp:241]     Train net output #0: loss = 1.61041 (* 1 = 1.61041 loss)
I1030 04:24:04.707401 27430 sgd_solver.cpp:105] Iteration 30920, lr = 0.00021631
I1030 04:24:34.231509 27430 solver.cpp:222] Iteration 30960 (1.35485 iter/s, 29.5235s/40 iters), loss = 1.21016
I1030 04:24:34.232056 27430 solver.cpp:241]     Train net output #0: loss = 1.21016 (* 1 = 1.21016 loss)
I1030 04:24:34.232095 27430 sgd_solver.cpp:105] Iteration 30960, lr = 0.00021524
I1030 04:25:02.914373 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_31000.caffemodel
I1030 04:25:03.058461 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_31000.solverstate
I1030 04:25:03.178844 27430 solver.cpp:334] Iteration 31000, Testing net (#0)
I1030 04:25:34.382148 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5866
I1030 04:25:34.382602 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.809479
I1030 04:25:34.382643 27430 solver.cpp:401]     Test net output #2: loss = 1.83579 (* 1 = 1.83579 loss)
I1030 04:25:35.156126 27430 solver.cpp:222] Iteration 31000 (0.65657 iter/s, 60.9227s/40 iters), loss = 0.969054
I1030 04:25:35.156170 27430 solver.cpp:241]     Train net output #0: loss = 0.969054 (* 1 = 0.969054 loss)
I1030 04:25:35.156183 27430 sgd_solver.cpp:105] Iteration 31000, lr = 0.000214175
I1030 04:26:04.972136 27430 solver.cpp:222] Iteration 31040 (1.3416 iter/s, 29.8152s/40 iters), loss = 1.23484
I1030 04:26:04.972309 27430 solver.cpp:241]     Train net output #0: loss = 1.23484 (* 1 = 1.23484 loss)
I1030 04:26:04.972323 27430 sgd_solver.cpp:105] Iteration 31040, lr = 0.000213116
I1030 04:26:55.328013 27430 solver.cpp:222] Iteration 31080 (0.794368 iter/s, 50.3545s/40 iters), loss = 1.13509
I1030 04:26:55.328621 27430 solver.cpp:241]     Train net output #0: loss = 1.13509 (* 1 = 1.13509 loss)
I1030 04:26:55.328676 27430 sgd_solver.cpp:105] Iteration 31080, lr = 0.000212061
I1030 04:27:43.321703 27430 solver.cpp:222] Iteration 31120 (0.833472 iter/s, 47.992s/40 iters), loss = 1.29912
I1030 04:27:43.322283 27430 solver.cpp:241]     Train net output #0: loss = 1.29912 (* 1 = 1.29912 loss)
I1030 04:27:43.322332 27430 sgd_solver.cpp:105] Iteration 31120, lr = 0.000211012
I1030 04:28:13.939180 27430 solver.cpp:222] Iteration 31160 (1.3065 iter/s, 30.6162s/40 iters), loss = 1.43795
I1030 04:28:13.939831 27430 solver.cpp:241]     Train net output #0: loss = 1.43795 (* 1 = 1.43795 loss)
I1030 04:28:13.939896 27430 sgd_solver.cpp:105] Iteration 31160, lr = 0.000209968
I1030 04:28:16.269974 27482 blocking_queue.cpp:49] Waiting for data
I1030 04:28:44.920521 27430 solver.cpp:222] Iteration 31200 (1.29116 iter/s, 30.98s/40 iters), loss = 1.54789
I1030 04:28:44.921057 27430 solver.cpp:241]     Train net output #0: loss = 1.54789 (* 1 = 1.54789 loss)
I1030 04:28:44.921108 27430 sgd_solver.cpp:105] Iteration 31200, lr = 0.00020893
I1030 04:29:14.182029 27430 solver.cpp:222] Iteration 31240 (1.36704 iter/s, 29.2603s/40 iters), loss = 1.32952
I1030 04:29:14.182488 27430 solver.cpp:241]     Train net output #0: loss = 1.32952 (* 1 = 1.32952 loss)
I1030 04:29:14.182528 27430 sgd_solver.cpp:105] Iteration 31240, lr = 0.000207896
I1030 04:29:43.506804 27430 solver.cpp:222] Iteration 31280 (1.36409 iter/s, 29.3237s/40 iters), loss = 1.2211
I1030 04:29:43.507381 27430 solver.cpp:241]     Train net output #0: loss = 1.2211 (* 1 = 1.2211 loss)
I1030 04:29:43.507426 27430 sgd_solver.cpp:105] Iteration 31280, lr = 0.000206868
I1030 04:30:12.875099 27430 solver.cpp:222] Iteration 31320 (1.36207 iter/s, 29.3671s/40 iters), loss = 1.21812
I1030 04:30:12.875564 27430 solver.cpp:241]     Train net output #0: loss = 1.21812 (* 1 = 1.21812 loss)
I1030 04:30:12.875615 27430 sgd_solver.cpp:105] Iteration 31320, lr = 0.000205844
I1030 04:30:43.343466 27430 solver.cpp:222] Iteration 31360 (1.31289 iter/s, 30.4672s/40 iters), loss = 1.34264
I1030 04:30:43.343713 27430 solver.cpp:241]     Train net output #0: loss = 1.34264 (* 1 = 1.34264 loss)
I1030 04:30:43.343729 27430 sgd_solver.cpp:105] Iteration 31360, lr = 0.000204826
I1030 04:31:13.067106 27430 solver.cpp:222] Iteration 31400 (1.34577 iter/s, 29.7227s/40 iters), loss = 1.54328
I1030 04:31:13.067541 27430 solver.cpp:241]     Train net output #0: loss = 1.54328 (* 1 = 1.54328 loss)
I1030 04:31:13.067589 27430 sgd_solver.cpp:105] Iteration 31400, lr = 0.000203812
I1030 04:31:43.621769 27430 solver.cpp:222] Iteration 31440 (1.30918 iter/s, 30.5535s/40 iters), loss = 1.32366
I1030 04:31:43.622721 27430 solver.cpp:241]     Train net output #0: loss = 1.32366 (* 1 = 1.32366 loss)
I1030 04:31:43.622762 27430 sgd_solver.cpp:105] Iteration 31440, lr = 0.000202804
I1030 04:32:14.470274 27430 solver.cpp:222] Iteration 31480 (1.29673 iter/s, 30.8468s/40 iters), loss = 1.62172
I1030 04:32:14.470785 27430 solver.cpp:241]     Train net output #0: loss = 1.62172 (* 1 = 1.62172 loss)
I1030 04:32:14.470811 27430 sgd_solver.cpp:105] Iteration 31480, lr = 0.000201801
I1030 04:32:28.926067 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_31500.caffemodel
I1030 04:32:29.079250 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_31500.solverstate
I1030 04:32:29.195963 27430 solver.cpp:334] Iteration 31500, Testing net (#0)
I1030 04:33:00.216364 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1030 04:33:00.428066 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58556
I1030 04:33:00.428109 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.814079
I1030 04:33:00.428120 27430 solver.cpp:401]     Test net output #2: loss = 1.83834 (* 1 = 1.83834 loss)
I1030 04:33:16.377147 27430 solver.cpp:222] Iteration 31520 (0.646152 iter/s, 61.9049s/40 iters), loss = 1.2541
I1030 04:33:16.377683 27430 solver.cpp:241]     Train net output #0: loss = 1.2541 (* 1 = 1.2541 loss)
I1030 04:33:16.377719 27430 sgd_solver.cpp:105] Iteration 31520, lr = 0.000200803
I1030 04:33:47.288405 27430 solver.cpp:222] Iteration 31560 (1.29408 iter/s, 30.91s/40 iters), loss = 1.63896
I1030 04:33:47.289012 27430 solver.cpp:241]     Train net output #0: loss = 1.63896 (* 1 = 1.63896 loss)
I1030 04:33:47.289052 27430 sgd_solver.cpp:105] Iteration 31560, lr = 0.000199809
I1030 04:34:17.559880 27430 solver.cpp:222] Iteration 31600 (1.32143 iter/s, 30.2702s/40 iters), loss = 1.28955
I1030 04:34:17.560096 27430 solver.cpp:241]     Train net output #0: loss = 1.28955 (* 1 = 1.28955 loss)
I1030 04:34:17.560111 27430 sgd_solver.cpp:105] Iteration 31600, lr = 0.000198821
I1030 04:34:47.388296 27430 solver.cpp:222] Iteration 31640 (1.34105 iter/s, 29.8275s/40 iters), loss = 1.11102
I1030 04:34:47.388752 27430 solver.cpp:241]     Train net output #0: loss = 1.11102 (* 1 = 1.11102 loss)
I1030 04:34:47.388808 27430 sgd_solver.cpp:105] Iteration 31640, lr = 0.000197837
I1030 04:35:17.197193 27430 solver.cpp:222] Iteration 31680 (1.34193 iter/s, 29.8078s/40 iters), loss = 1.48081
I1030 04:35:17.197748 27430 solver.cpp:241]     Train net output #0: loss = 1.48081 (* 1 = 1.48081 loss)
I1030 04:35:17.197800 27430 sgd_solver.cpp:105] Iteration 31680, lr = 0.000196858
I1030 04:35:47.706035 27430 solver.cpp:222] Iteration 31720 (1.31115 iter/s, 30.5076s/40 iters), loss = 1.22427
I1030 04:35:47.706214 27430 solver.cpp:241]     Train net output #0: loss = 1.22427 (* 1 = 1.22427 loss)
I1030 04:35:47.706228 27430 sgd_solver.cpp:105] Iteration 31720, lr = 0.000195884
I1030 04:36:17.301300 27430 solver.cpp:222] Iteration 31760 (1.35161 iter/s, 29.5944s/40 iters), loss = 1.41539
I1030 04:36:17.301767 27430 solver.cpp:241]     Train net output #0: loss = 1.41539 (* 1 = 1.41539 loss)
I1030 04:36:17.301818 27430 sgd_solver.cpp:105] Iteration 31760, lr = 0.000194915
I1030 04:36:46.757709 27430 solver.cpp:222] Iteration 31800 (1.35799 iter/s, 29.4553s/40 iters), loss = 1.33811
I1030 04:36:46.758337 27430 solver.cpp:241]     Train net output #0: loss = 1.33811 (* 1 = 1.33811 loss)
I1030 04:36:46.758384 27430 sgd_solver.cpp:105] Iteration 31800, lr = 0.000193951
I1030 04:37:16.574275 27430 solver.cpp:222] Iteration 31840 (1.34159 iter/s, 29.8153s/40 iters), loss = 1.22535
I1030 04:37:16.575083 27430 solver.cpp:241]     Train net output #0: loss = 1.22535 (* 1 = 1.22535 loss)
I1030 04:37:16.575124 27430 sgd_solver.cpp:105] Iteration 31840, lr = 0.000192992
I1030 04:37:46.764222 27430 solver.cpp:222] Iteration 31880 (1.32501 iter/s, 30.1885s/40 iters), loss = 1.45967
I1030 04:37:46.765110 27430 solver.cpp:241]     Train net output #0: loss = 1.45967 (* 1 = 1.45967 loss)
I1030 04:37:46.765156 27430 sgd_solver.cpp:105] Iteration 31880, lr = 0.000192037
I1030 04:38:17.052565 27430 solver.cpp:222] Iteration 31920 (1.32071 iter/s, 30.2868s/40 iters), loss = 1.32052
I1030 04:38:17.053117 27430 solver.cpp:241]     Train net output #0: loss = 1.32052 (* 1 = 1.32052 loss)
I1030 04:38:17.053148 27430 sgd_solver.cpp:105] Iteration 31920, lr = 0.000191087
I1030 04:38:47.409252 27430 solver.cpp:222] Iteration 31960 (1.31772 iter/s, 30.3554s/40 iters), loss = 1.38551
I1030 04:38:47.409780 27430 solver.cpp:241]     Train net output #0: loss = 1.38551 (* 1 = 1.38551 loss)
I1030 04:38:47.409817 27430 sgd_solver.cpp:105] Iteration 31960, lr = 0.000190142
I1030 04:39:17.145588 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_32000.caffemodel
I1030 04:39:17.287937 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_32000.solverstate
I1030 04:39:17.401897 27430 solver.cpp:334] Iteration 32000, Testing net (#0)
I1030 04:39:48.757179 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58784
I1030 04:39:48.757642 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.809359
I1030 04:39:48.757694 27430 solver.cpp:401]     Test net output #2: loss = 1.83268 (* 1 = 1.83268 loss)
I1030 04:39:49.523473 27430 solver.cpp:222] Iteration 32000 (0.643995 iter/s, 62.1122s/40 iters), loss = 1.37378
I1030 04:39:49.523530 27430 solver.cpp:241]     Train net output #0: loss = 1.37378 (* 1 = 1.37378 loss)
I1030 04:39:49.523545 27430 sgd_solver.cpp:105] Iteration 32000, lr = 0.000189201
I1030 04:40:20.355521 27430 solver.cpp:222] Iteration 32040 (1.29739 iter/s, 30.8312s/40 iters), loss = 1.60258
I1030 04:40:20.355741 27430 solver.cpp:241]     Train net output #0: loss = 1.60258 (* 1 = 1.60258 loss)
I1030 04:40:20.355756 27430 sgd_solver.cpp:105] Iteration 32040, lr = 0.000188265
I1030 04:40:50.485159 27430 solver.cpp:222] Iteration 32080 (1.32764 iter/s, 30.1287s/40 iters), loss = 1.28623
I1030 04:40:50.485766 27430 solver.cpp:241]     Train net output #0: loss = 1.28623 (* 1 = 1.28623 loss)
I1030 04:40:50.485818 27430 sgd_solver.cpp:105] Iteration 32080, lr = 0.000187333
I1030 04:41:20.916985 27430 solver.cpp:222] Iteration 32120 (1.31447 iter/s, 30.4305s/40 iters), loss = 1.56667
I1030 04:41:20.917899 27430 solver.cpp:241]     Train net output #0: loss = 1.56667 (* 1 = 1.56667 loss)
I1030 04:41:20.918180 27430 sgd_solver.cpp:105] Iteration 32120, lr = 0.000186407
I1030 04:41:51.581086 27430 solver.cpp:222] Iteration 32160 (1.30453 iter/s, 30.6625s/40 iters), loss = 1.27902
I1030 04:41:51.581261 27430 solver.cpp:241]     Train net output #0: loss = 1.27902 (* 1 = 1.27902 loss)
I1030 04:41:51.581276 27430 sgd_solver.cpp:105] Iteration 32160, lr = 0.000185485
I1030 04:42:22.651329 27430 solver.cpp:222] Iteration 32200 (1.28744 iter/s, 31.0693s/40 iters), loss = 1.32288
I1030 04:42:22.651973 27430 solver.cpp:241]     Train net output #0: loss = 1.32288 (* 1 = 1.32288 loss)
I1030 04:42:22.652029 27430 sgd_solver.cpp:105] Iteration 32200, lr = 0.000184567
I1030 04:42:53.402130 27430 solver.cpp:222] Iteration 32240 (1.30083 iter/s, 30.7495s/40 iters), loss = 1.29493
I1030 04:42:53.402573 27430 solver.cpp:241]     Train net output #0: loss = 1.29493 (* 1 = 1.29493 loss)
I1030 04:42:53.402600 27430 sgd_solver.cpp:105] Iteration 32240, lr = 0.000183654
I1030 04:43:23.162657 27430 solver.cpp:222] Iteration 32280 (1.34411 iter/s, 29.7594s/40 iters), loss = 1.73203
I1030 04:43:23.163072 27430 solver.cpp:241]     Train net output #0: loss = 1.73203 (* 1 = 1.73203 loss)
I1030 04:43:23.163113 27430 sgd_solver.cpp:105] Iteration 32280, lr = 0.000182745
I1030 04:43:52.860765 27430 solver.cpp:222] Iteration 32320 (1.34694 iter/s, 29.697s/40 iters), loss = 1.47104
I1030 04:43:52.861357 27430 solver.cpp:241]     Train net output #0: loss = 1.47104 (* 1 = 1.47104 loss)
I1030 04:43:52.861412 27430 sgd_solver.cpp:105] Iteration 32320, lr = 0.000181841
I1030 04:44:39.036376 27430 solver.cpp:222] Iteration 32360 (0.866289 iter/s, 46.174s/40 iters), loss = 1.61369
I1030 04:44:39.036905 27430 solver.cpp:241]     Train net output #0: loss = 1.61369 (* 1 = 1.61369 loss)
I1030 04:44:39.042428 27430 sgd_solver.cpp:105] Iteration 32360, lr = 0.000180942
I1030 04:45:09.391890 27430 solver.cpp:222] Iteration 32400 (1.31777 iter/s, 30.3543s/40 iters), loss = 1.30552
I1030 04:45:09.392444 27430 solver.cpp:241]     Train net output #0: loss = 1.30552 (* 1 = 1.30552 loss)
I1030 04:45:09.392479 27430 sgd_solver.cpp:105] Iteration 32400, lr = 0.000180046
I1030 04:45:39.860632 27430 solver.cpp:222] Iteration 32440 (1.31288 iter/s, 30.4675s/40 iters), loss = 1.53378
I1030 04:45:39.861094 27430 solver.cpp:241]     Train net output #0: loss = 1.53378 (* 1 = 1.53378 loss)
I1030 04:45:39.861121 27430 sgd_solver.cpp:105] Iteration 32440, lr = 0.000179156
I1030 04:46:10.140863 27430 solver.cpp:222] Iteration 32480 (1.32104 iter/s, 30.2791s/40 iters), loss = 1.31958
I1030 04:46:10.141443 27430 solver.cpp:241]     Train net output #0: loss = 1.31958 (* 1 = 1.31958 loss)
I1030 04:46:10.141476 27430 sgd_solver.cpp:105] Iteration 32480, lr = 0.000178269
I1030 04:46:24.380393 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_32500.caffemodel
I1030 04:46:24.523524 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_32500.solverstate
I1030 04:46:24.651000 27430 solver.cpp:334] Iteration 32500, Testing net (#0)
I1030 04:46:55.594724 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1030 04:46:55.802842 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58704
I1030 04:46:55.802887 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8132
I1030 04:46:55.802899 27430 solver.cpp:401]     Test net output #2: loss = 1.8359 (* 1 = 1.8359 loss)
I1030 04:47:11.618171 27430 solver.cpp:222] Iteration 32520 (0.650668 iter/s, 61.4753s/40 iters), loss = 1.3053
I1030 04:47:11.618613 27430 solver.cpp:241]     Train net output #0: loss = 1.3053 (* 1 = 1.3053 loss)
I1030 04:47:11.618649 27430 sgd_solver.cpp:105] Iteration 32520, lr = 0.000177388
I1030 04:47:15.850111 27479 data_layer.cpp:73] Restarting data prefetching from start.
I1030 04:47:41.791327 27430 solver.cpp:222] Iteration 32560 (1.32573 iter/s, 30.172s/40 iters), loss = 1.31932
I1030 04:47:41.792155 27430 solver.cpp:241]     Train net output #0: loss = 1.31932 (* 1 = 1.31932 loss)
I1030 04:47:41.792208 27430 sgd_solver.cpp:105] Iteration 32560, lr = 0.00017651
I1030 04:48:11.393589 27430 solver.cpp:222] Iteration 32600 (1.35132 iter/s, 29.6008s/40 iters), loss = 1.39505
I1030 04:48:11.394044 27430 solver.cpp:241]     Train net output #0: loss = 1.39505 (* 1 = 1.39505 loss)
I1030 04:48:11.394078 27430 sgd_solver.cpp:105] Iteration 32600, lr = 0.000175637
I1030 04:48:40.922417 27430 solver.cpp:222] Iteration 32640 (1.35466 iter/s, 29.5277s/40 iters), loss = 1.29759
I1030 04:48:40.923074 27430 solver.cpp:241]     Train net output #0: loss = 1.29759 (* 1 = 1.29759 loss)
I1030 04:48:40.923130 27430 sgd_solver.cpp:105] Iteration 32640, lr = 0.000174768
I1030 04:49:10.594153 27430 solver.cpp:222] Iteration 32680 (1.34814 iter/s, 29.6704s/40 iters), loss = 1.27361
I1030 04:49:10.594627 27430 solver.cpp:241]     Train net output #0: loss = 1.27361 (* 1 = 1.27361 loss)
I1030 04:49:10.594672 27430 sgd_solver.cpp:105] Iteration 32680, lr = 0.000173903
I1030 04:49:41.373450 27430 solver.cpp:222] Iteration 32720 (1.29962 iter/s, 30.7781s/40 iters), loss = 1.28878
I1030 04:49:41.374203 27430 solver.cpp:241]     Train net output #0: loss = 1.28878 (* 1 = 1.28878 loss)
I1030 04:49:41.374248 27430 sgd_solver.cpp:105] Iteration 32720, lr = 0.000173043
I1030 04:50:11.722575 27430 solver.cpp:222] Iteration 32760 (1.31806 iter/s, 30.3477s/40 iters), loss = 1.55012
I1030 04:50:11.723137 27430 solver.cpp:241]     Train net output #0: loss = 1.55012 (* 1 = 1.55012 loss)
I1030 04:50:11.723189 27430 sgd_solver.cpp:105] Iteration 32760, lr = 0.000172187
I1030 04:50:41.904448 27430 solver.cpp:222] Iteration 32800 (1.32535 iter/s, 30.1806s/40 iters), loss = 0.867326
I1030 04:50:41.905048 27430 solver.cpp:241]     Train net output #0: loss = 0.867326 (* 1 = 0.867326 loss)
I1030 04:50:41.905100 27430 sgd_solver.cpp:105] Iteration 32800, lr = 0.000171335
I1030 04:51:11.843351 27430 solver.cpp:222] Iteration 32840 (1.33611 iter/s, 29.9376s/40 iters), loss = 1.68025
I1030 04:51:11.843746 27430 solver.cpp:241]     Train net output #0: loss = 1.68025 (* 1 = 1.68025 loss)
I1030 04:51:11.843783 27430 sgd_solver.cpp:105] Iteration 32840, lr = 0.000170487
I1030 04:51:42.407191 27430 solver.cpp:222] Iteration 32880 (1.30878 iter/s, 30.5627s/40 iters), loss = 1.46791
I1030 04:51:42.408164 27430 solver.cpp:241]     Train net output #0: loss = 1.46791 (* 1 = 1.46791 loss)
I1030 04:51:42.408208 27430 sgd_solver.cpp:105] Iteration 32880, lr = 0.000169644
I1030 04:52:12.192317 27430 solver.cpp:222] Iteration 32920 (1.34303 iter/s, 29.7835s/40 iters), loss = 1.41612
I1030 04:52:12.192750 27430 solver.cpp:241]     Train net output #0: loss = 1.41612 (* 1 = 1.41612 loss)
I1030 04:52:12.192801 27430 sgd_solver.cpp:105] Iteration 32920, lr = 0.000168805
I1030 04:52:42.173359 27430 solver.cpp:222] Iteration 32960 (1.33423 iter/s, 29.9799s/40 iters), loss = 1.65559
I1030 04:52:42.173905 27430 solver.cpp:241]     Train net output #0: loss = 1.65559 (* 1 = 1.65559 loss)
I1030 04:52:42.174139 27430 sgd_solver.cpp:105] Iteration 32960, lr = 0.00016797
I1030 04:53:11.669464 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_33000.caffemodel
I1030 04:53:13.521739 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_33000.solverstate
I1030 04:53:13.638124 27430 solver.cpp:334] Iteration 33000, Testing net (#0)
I1030 04:53:44.829135 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58756
I1030 04:53:44.829562 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.809879
I1030 04:53:44.829578 27430 solver.cpp:401]     Test net output #2: loss = 1.83376 (* 1 = 1.83376 loss)
I1030 04:53:45.614584 27430 solver.cpp:222] Iteration 33000 (0.630525 iter/s, 63.4392s/40 iters), loss = 1.32461
I1030 04:53:45.614642 27430 solver.cpp:241]     Train net output #0: loss = 1.32461 (* 1 = 1.32461 loss)
I1030 04:53:45.614657 27430 sgd_solver.cpp:105] Iteration 33000, lr = 0.000167139
I1030 04:54:15.378818 27430 solver.cpp:222] Iteration 33040 (1.34393 iter/s, 29.7635s/40 iters), loss = 1.27048
I1030 04:54:15.379374 27430 solver.cpp:241]     Train net output #0: loss = 1.27048 (* 1 = 1.27048 loss)
I1030 04:54:15.379413 27430 sgd_solver.cpp:105] Iteration 33040, lr = 0.000166312
I1030 04:54:45.627701 27430 solver.cpp:222] Iteration 33080 (1.32242 iter/s, 30.2476s/40 iters), loss = 1.52254
I1030 04:54:45.628260 27430 solver.cpp:241]     Train net output #0: loss = 1.52254 (* 1 = 1.52254 loss)
I1030 04:54:45.628310 27430 sgd_solver.cpp:105] Iteration 33080, lr = 0.000165489
I1030 04:55:16.544338 27430 solver.cpp:222] Iteration 33120 (1.29386 iter/s, 30.9154s/40 iters), loss = 1.51446
I1030 04:55:16.544853 27430 solver.cpp:241]     Train net output #0: loss = 1.51446 (* 1 = 1.51446 loss)
I1030 04:55:16.544890 27430 sgd_solver.cpp:105] Iteration 33120, lr = 0.00016467
I1030 04:55:47.004873 27430 solver.cpp:222] Iteration 33160 (1.31323 iter/s, 30.4593s/40 iters), loss = 1.36169
I1030 04:55:47.005410 27430 solver.cpp:241]     Train net output #0: loss = 1.36169 (* 1 = 1.36169 loss)
I1030 04:55:47.005456 27430 sgd_solver.cpp:105] Iteration 33160, lr = 0.000163856
I1030 04:56:16.731376 27430 solver.cpp:222] Iteration 33200 (1.34566 iter/s, 29.7253s/40 iters), loss = 1.63186
I1030 04:56:16.731775 27430 solver.cpp:241]     Train net output #0: loss = 1.63186 (* 1 = 1.63186 loss)
I1030 04:56:16.731822 27430 sgd_solver.cpp:105] Iteration 33200, lr = 0.000163045
I1030 04:56:46.346721 27430 solver.cpp:222] Iteration 33240 (1.3507 iter/s, 29.6143s/40 iters), loss = 1.76126
I1030 04:56:46.347252 27430 solver.cpp:241]     Train net output #0: loss = 1.76126 (* 1 = 1.76126 loss)
I1030 04:56:46.347287 27430 sgd_solver.cpp:105] Iteration 33240, lr = 0.000162238
I1030 04:57:16.899044 27430 solver.cpp:222] Iteration 33280 (1.30928 iter/s, 30.5511s/40 iters), loss = 1.55902
I1030 04:57:16.899554 27430 solver.cpp:241]     Train net output #0: loss = 1.55902 (* 1 = 1.55902 loss)
I1030 04:57:16.899600 27430 sgd_solver.cpp:105] Iteration 33280, lr = 0.000161436
I1030 04:57:47.648102 27430 solver.cpp:222] Iteration 33320 (1.3009 iter/s, 30.7478s/40 iters), loss = 1.39438
I1030 04:57:47.648566 27430 solver.cpp:241]     Train net output #0: loss = 1.39438 (* 1 = 1.39438 loss)
I1030 04:57:47.648584 27430 sgd_solver.cpp:105] Iteration 33320, lr = 0.000160637
I1030 04:58:17.958305 27430 solver.cpp:222] Iteration 33360 (1.31974 iter/s, 30.309s/40 iters), loss = 1.21784
I1030 04:58:17.958782 27430 solver.cpp:241]     Train net output #0: loss = 1.21784 (* 1 = 1.21784 loss)
I1030 04:58:17.958818 27430 sgd_solver.cpp:105] Iteration 33360, lr = 0.000159843
I1030 04:58:48.624946 27430 solver.cpp:222] Iteration 33400 (1.3044 iter/s, 30.6655s/40 iters), loss = 1.40616
I1030 04:58:48.625476 27430 solver.cpp:241]     Train net output #0: loss = 1.40616 (* 1 = 1.40616 loss)
I1030 04:58:48.625525 27430 sgd_solver.cpp:105] Iteration 33400, lr = 0.000159052
I1030 04:59:19.291597 27430 solver.cpp:222] Iteration 33440 (1.3044 iter/s, 30.6654s/40 iters), loss = 1.18421
I1030 04:59:19.292173 27430 solver.cpp:241]     Train net output #0: loss = 1.18421 (* 1 = 1.18421 loss)
I1030 04:59:19.292208 27430 sgd_solver.cpp:105] Iteration 33440, lr = 0.000158265
I1030 04:59:50.233791 27430 solver.cpp:222] Iteration 33480 (1.29279 iter/s, 30.9409s/40 iters), loss = 1.57158
I1030 04:59:50.234545 27430 solver.cpp:241]     Train net output #0: loss = 1.57158 (* 1 = 1.57158 loss)
I1030 04:59:50.234591 27430 sgd_solver.cpp:105] Iteration 33480, lr = 0.000157482
I1030 05:00:04.629138 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_33500.caffemodel
I1030 05:00:04.783149 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_33500.solverstate
I1030 05:00:04.908110 27430 solver.cpp:334] Iteration 33500, Testing net (#0)
I1030 05:00:35.989099 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1030 05:00:36.199724 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58616
I1030 05:00:36.199775 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.814239
I1030 05:00:36.199785 27430 solver.cpp:401]     Test net output #2: loss = 1.83714 (* 1 = 1.83714 loss)
I1030 05:00:52.128497 27430 solver.cpp:222] Iteration 33520 (0.646281 iter/s, 61.8925s/40 iters), loss = 1.24265
I1030 05:00:52.129190 27430 solver.cpp:241]     Train net output #0: loss = 1.24265 (* 1 = 1.24265 loss)
I1030 05:00:52.129240 27430 sgd_solver.cpp:105] Iteration 33520, lr = 0.000156703
I1030 05:01:21.977643 27430 solver.cpp:222] Iteration 33560 (1.34013 iter/s, 29.8478s/40 iters), loss = 1.69076
I1030 05:01:21.978209 27430 solver.cpp:241]     Train net output #0: loss = 1.69076 (* 1 = 1.69076 loss)
I1030 05:01:21.978260 27430 sgd_solver.cpp:105] Iteration 33560, lr = 0.000155928
I1030 05:01:51.244025 27430 solver.cpp:222] Iteration 33600 (1.36681 iter/s, 29.2652s/40 iters), loss = 1.75569
I1030 05:01:51.244468 27430 solver.cpp:241]     Train net output #0: loss = 1.75569 (* 1 = 1.75569 loss)
I1030 05:01:51.244519 27430 sgd_solver.cpp:105] Iteration 33600, lr = 0.000155156
I1030 05:02:20.713496 27430 solver.cpp:222] Iteration 33640 (1.35739 iter/s, 29.4684s/40 iters), loss = 1.34502
I1030 05:02:20.714054 27430 solver.cpp:241]     Train net output #0: loss = 1.34502 (* 1 = 1.34502 loss)
I1030 05:02:20.714102 27430 sgd_solver.cpp:105] Iteration 33640, lr = 0.000154389
I1030 05:02:49.943749 27430 solver.cpp:222] Iteration 33680 (1.3685 iter/s, 29.229s/40 iters), loss = 1.48974
I1030 05:02:49.944190 27430 solver.cpp:241]     Train net output #0: loss = 1.48974 (* 1 = 1.48974 loss)
I1030 05:02:49.944237 27430 sgd_solver.cpp:105] Iteration 33680, lr = 0.000153625
I1030 05:03:23.741564 27430 solver.cpp:222] Iteration 33720 (1.18355 iter/s, 33.7966s/40 iters), loss = 1.4562
I1030 05:03:23.742142 27430 solver.cpp:241]     Train net output #0: loss = 1.4562 (* 1 = 1.4562 loss)
I1030 05:03:23.742195 27430 sgd_solver.cpp:105] Iteration 33720, lr = 0.000152865
I1030 05:03:54.554208 27430 solver.cpp:222] Iteration 33760 (1.29822 iter/s, 30.8114s/40 iters), loss = 1.16378
I1030 05:03:54.554411 27430 solver.cpp:241]     Train net output #0: loss = 1.16378 (* 1 = 1.16378 loss)
I1030 05:03:54.554427 27430 sgd_solver.cpp:105] Iteration 33760, lr = 0.000152109
I1030 05:04:25.801898 27430 solver.cpp:222] Iteration 33800 (1.28013 iter/s, 31.2467s/40 iters), loss = 1.55565
I1030 05:04:25.802091 27430 solver.cpp:241]     Train net output #0: loss = 1.55565 (* 1 = 1.55565 loss)
I1030 05:04:25.802111 27430 sgd_solver.cpp:105] Iteration 33800, lr = 0.000151356
I1030 05:04:59.039938 27430 solver.cpp:222] Iteration 33840 (1.20348 iter/s, 33.2371s/40 iters), loss = 1.57079
I1030 05:04:59.040139 27430 solver.cpp:241]     Train net output #0: loss = 1.57079 (* 1 = 1.57079 loss)
I1030 05:04:59.040153 27430 sgd_solver.cpp:105] Iteration 33840, lr = 0.000150607
I1030 05:05:29.365895 27430 solver.cpp:222] Iteration 33880 (1.31904 iter/s, 30.325s/40 iters), loss = 1.53651
I1030 05:05:29.366088 27430 solver.cpp:241]     Train net output #0: loss = 1.53651 (* 1 = 1.53651 loss)
I1030 05:05:29.366102 27430 sgd_solver.cpp:105] Iteration 33880, lr = 0.000149862
I1030 05:05:59.424865 27430 solver.cpp:222] Iteration 33920 (1.33076 iter/s, 30.0581s/40 iters), loss = 1.61008
I1030 05:05:59.425058 27430 solver.cpp:241]     Train net output #0: loss = 1.61008 (* 1 = 1.61008 loss)
I1030 05:05:59.425076 27430 sgd_solver.cpp:105] Iteration 33920, lr = 0.000149121
I1030 05:06:42.771322 27430 solver.cpp:222] Iteration 33960 (0.922823 iter/s, 43.3453s/40 iters), loss = 1.75456
I1030 05:06:42.771479 27430 solver.cpp:241]     Train net output #0: loss = 1.75456 (* 1 = 1.75456 loss)
I1030 05:06:42.771500 27430 sgd_solver.cpp:105] Iteration 33960, lr = 0.000148383
I1030 05:07:15.770474 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_34000.caffemodel
I1030 05:07:15.905609 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_34000.solverstate
I1030 05:07:16.012101 27430 solver.cpp:334] Iteration 34000, Testing net (#0)
I1030 05:07:47.234601 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58876
I1030 05:07:47.234776 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.809879
I1030 05:07:47.234788 27430 solver.cpp:401]     Test net output #2: loss = 1.83358 (* 1 = 1.83358 loss)
I1030 05:07:47.970906 27430 solver.cpp:222] Iteration 34000 (0.613517 iter/s, 65.1979s/40 iters), loss = 1.45671
I1030 05:07:47.970963 27430 solver.cpp:241]     Train net output #0: loss = 1.45671 (* 1 = 1.45671 loss)
I1030 05:07:47.970980 27430 sgd_solver.cpp:105] Iteration 34000, lr = 0.000147649
I1030 05:08:21.105219 27430 solver.cpp:222] Iteration 34040 (1.20724 iter/s, 33.1335s/40 iters), loss = 1.44215
I1030 05:08:21.105448 27430 solver.cpp:241]     Train net output #0: loss = 1.44215 (* 1 = 1.44215 loss)
I1030 05:08:21.105463 27430 sgd_solver.cpp:105] Iteration 34040, lr = 0.000146919
I1030 05:08:54.076891 27430 solver.cpp:222] Iteration 34080 (1.2132 iter/s, 32.9707s/40 iters), loss = 1.3769
I1030 05:08:54.077093 27430 solver.cpp:241]     Train net output #0: loss = 1.3769 (* 1 = 1.3769 loss)
I1030 05:08:54.077108 27430 sgd_solver.cpp:105] Iteration 34080, lr = 0.000146192
I1030 05:09:29.011711 27430 solver.cpp:222] Iteration 34120 (1.14502 iter/s, 34.9338s/40 iters), loss = 1.40886
I1030 05:09:29.011910 27430 solver.cpp:241]     Train net output #0: loss = 1.40886 (* 1 = 1.40886 loss)
I1030 05:09:29.011929 27430 sgd_solver.cpp:105] Iteration 34120, lr = 0.000145469
I1030 05:09:59.903796 27430 solver.cpp:222] Iteration 34160 (1.29487 iter/s, 30.8911s/40 iters), loss = 1.60642
I1030 05:09:59.904247 27430 solver.cpp:241]     Train net output #0: loss = 1.60642 (* 1 = 1.60642 loss)
I1030 05:09:59.904261 27430 sgd_solver.cpp:105] Iteration 34160, lr = 0.000144749
I1030 05:10:31.192750 27430 solver.cpp:222] Iteration 34200 (1.27846 iter/s, 31.2878s/40 iters), loss = 1.36852
I1030 05:10:31.192934 27430 solver.cpp:241]     Train net output #0: loss = 1.36852 (* 1 = 1.36852 loss)
I1030 05:10:31.192950 27430 sgd_solver.cpp:105] Iteration 34200, lr = 0.000144033
I1030 05:11:01.210690 27430 solver.cpp:222] Iteration 34240 (1.33258 iter/s, 30.017s/40 iters), loss = 1.62867
I1030 05:11:01.210868 27430 solver.cpp:241]     Train net output #0: loss = 1.62867 (* 1 = 1.62867 loss)
I1030 05:11:01.210882 27430 sgd_solver.cpp:105] Iteration 34240, lr = 0.00014332
I1030 05:11:30.644038 27430 solver.cpp:222] Iteration 34280 (1.35904 iter/s, 29.4325s/40 iters), loss = 1.47106
I1030 05:11:30.644099 27430 solver.cpp:241]     Train net output #0: loss = 1.47106 (* 1 = 1.47106 loss)
I1030 05:11:30.644111 27430 sgd_solver.cpp:105] Iteration 34280, lr = 0.000142611
I1030 05:11:59.922909 27430 solver.cpp:222] Iteration 34320 (1.36621 iter/s, 29.2781s/40 iters), loss = 1.60444
I1030 05:11:59.923084 27430 solver.cpp:241]     Train net output #0: loss = 1.60444 (* 1 = 1.60444 loss)
I1030 05:11:59.923099 27430 sgd_solver.cpp:105] Iteration 34320, lr = 0.000141906
I1030 05:12:29.270134 27430 solver.cpp:222] Iteration 34360 (1.36303 iter/s, 29.3464s/40 iters), loss = 1.18114
I1030 05:12:29.270201 27430 solver.cpp:241]     Train net output #0: loss = 1.18114 (* 1 = 1.18114 loss)
I1030 05:12:29.270215 27430 sgd_solver.cpp:105] Iteration 34360, lr = 0.000141204
I1030 05:12:58.623414 27430 solver.cpp:222] Iteration 34400 (1.36275 iter/s, 29.3525s/40 iters), loss = 1.65803
I1030 05:12:58.623579 27430 solver.cpp:241]     Train net output #0: loss = 1.65803 (* 1 = 1.65803 loss)
I1030 05:12:58.623591 27430 sgd_solver.cpp:105] Iteration 34400, lr = 0.000140505
I1030 05:13:28.007346 27430 solver.cpp:222] Iteration 34440 (1.36133 iter/s, 29.3831s/40 iters), loss = 1.38055
I1030 05:13:28.007405 27430 solver.cpp:241]     Train net output #0: loss = 1.38055 (* 1 = 1.38055 loss)
I1030 05:13:28.007418 27430 sgd_solver.cpp:105] Iteration 34440, lr = 0.00013981
I1030 05:13:57.556558 27430 solver.cpp:222] Iteration 34480 (1.35371 iter/s, 29.5485s/40 iters), loss = 1.31814
I1030 05:13:57.556954 27430 solver.cpp:241]     Train net output #0: loss = 1.31814 (* 1 = 1.31814 loss)
I1030 05:13:57.556968 27430 sgd_solver.cpp:105] Iteration 34480, lr = 0.000139118
I1030 05:14:11.552642 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_34500.caffemodel
I1030 05:14:11.699609 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_34500.solverstate
I1030 05:14:11.817513 27430 solver.cpp:334] Iteration 34500, Testing net (#0)
I1030 05:14:42.779734 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1030 05:14:42.989434 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5866
I1030 05:14:42.989478 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81392
I1030 05:14:42.989490 27430 solver.cpp:401]     Test net output #2: loss = 1.83643 (* 1 = 1.83643 loss)
I1030 05:14:59.002357 27430 solver.cpp:222] Iteration 34520 (0.651 iter/s, 61.444s/40 iters), loss = 1.37508
I1030 05:14:59.002415 27430 solver.cpp:241]     Train net output #0: loss = 1.37508 (* 1 = 1.37508 loss)
I1030 05:14:59.002429 27430 sgd_solver.cpp:105] Iteration 34520, lr = 0.00013843
I1030 05:15:28.310271 27430 solver.cpp:222] Iteration 34560 (1.36485 iter/s, 29.3071s/40 iters), loss = 1.42909
I1030 05:15:28.310428 27430 solver.cpp:241]     Train net output #0: loss = 1.42909 (* 1 = 1.42909 loss)
I1030 05:15:28.310441 27430 sgd_solver.cpp:105] Iteration 34560, lr = 0.000137745
I1030 05:15:57.626922 27430 solver.cpp:222] Iteration 34600 (1.36445 iter/s, 29.3158s/40 iters), loss = 1.36467
I1030 05:15:57.626979 27430 solver.cpp:241]     Train net output #0: loss = 1.36467 (* 1 = 1.36467 loss)
I1030 05:15:57.626992 27430 sgd_solver.cpp:105] Iteration 34600, lr = 0.000137064
I1030 05:16:27.069888 27430 solver.cpp:222] Iteration 34640 (1.35859 iter/s, 29.4422s/40 iters), loss = 1.34417
I1030 05:16:27.070097 27430 solver.cpp:241]     Train net output #0: loss = 1.34417 (* 1 = 1.34417 loss)
I1030 05:16:27.070111 27430 sgd_solver.cpp:105] Iteration 34640, lr = 0.000136386
I1030 05:16:56.467680 27430 solver.cpp:222] Iteration 34680 (1.36069 iter/s, 29.3969s/40 iters), loss = 1.55735
I1030 05:16:56.467738 27430 solver.cpp:241]     Train net output #0: loss = 1.55735 (* 1 = 1.55735 loss)
I1030 05:16:56.467751 27430 sgd_solver.cpp:105] Iteration 34680, lr = 0.000135711
I1030 05:17:25.925750 27430 solver.cpp:222] Iteration 34720 (1.3579 iter/s, 29.4573s/40 iters), loss = 1.53688
I1030 05:17:25.925899 27430 solver.cpp:241]     Train net output #0: loss = 1.53688 (* 1 = 1.53688 loss)
I1030 05:17:25.925912 27430 sgd_solver.cpp:105] Iteration 34720, lr = 0.00013504
I1030 05:17:56.064688 27430 solver.cpp:222] Iteration 34760 (1.32723 iter/s, 30.1381s/40 iters), loss = 1.31565
I1030 05:17:56.064828 27430 solver.cpp:241]     Train net output #0: loss = 1.31565 (* 1 = 1.31565 loss)
I1030 05:17:56.064842 27430 sgd_solver.cpp:105] Iteration 34760, lr = 0.000134372
I1030 05:18:42.399736 27430 solver.cpp:222] Iteration 34800 (0.863301 iter/s, 46.3338s/40 iters), loss = 1.14314
I1030 05:18:42.399930 27430 solver.cpp:241]     Train net output #0: loss = 1.14314 (* 1 = 1.14314 loss)
I1030 05:18:42.399946 27430 sgd_solver.cpp:105] Iteration 34800, lr = 0.000133707
I1030 05:19:12.995942 27430 solver.cpp:222] Iteration 34840 (1.30739 iter/s, 30.5953s/40 iters), loss = 1.60106
I1030 05:19:12.996139 27430 solver.cpp:241]     Train net output #0: loss = 1.60106 (* 1 = 1.60106 loss)
I1030 05:19:12.996152 27430 sgd_solver.cpp:105] Iteration 34840, lr = 0.000133045
I1030 05:19:42.280541 27430 solver.cpp:222] Iteration 34880 (1.36595 iter/s, 29.2837s/40 iters), loss = 1.23147
I1030 05:19:42.280599 27430 solver.cpp:241]     Train net output #0: loss = 1.23147 (* 1 = 1.23147 loss)
I1030 05:19:42.280612 27430 sgd_solver.cpp:105] Iteration 34880, lr = 0.000132387
I1030 05:20:11.528465 27430 solver.cpp:222] Iteration 34920 (1.36765 iter/s, 29.2472s/40 iters), loss = 1.24264
I1030 05:20:11.528684 27430 solver.cpp:241]     Train net output #0: loss = 1.24264 (* 1 = 1.24264 loss)
I1030 05:20:11.528698 27430 sgd_solver.cpp:105] Iteration 34920, lr = 0.000131732
I1030 05:20:40.898880 27430 solver.cpp:222] Iteration 34960 (1.36196 iter/s, 29.3695s/40 iters), loss = 1.38626
I1030 05:20:40.898934 27430 solver.cpp:241]     Train net output #0: loss = 1.38626 (* 1 = 1.38626 loss)
I1030 05:20:40.898947 27430 sgd_solver.cpp:105] Iteration 34960, lr = 0.000131081
I1030 05:21:09.822072 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_35000.caffemodel
I1030 05:21:09.958780 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_35000.solverstate
I1030 05:21:10.074651 27430 solver.cpp:334] Iteration 35000, Testing net (#0)
I1030 05:21:41.313859 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58756
I1030 05:21:41.314003 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80976
I1030 05:21:41.314018 27430 solver.cpp:401]     Test net output #2: loss = 1.83314 (* 1 = 1.83314 loss)
I1030 05:21:42.067991 27430 solver.cpp:222] Iteration 35000 (0.653941 iter/s, 61.1676s/40 iters), loss = 1.33951
I1030 05:21:42.068029 27430 solver.cpp:241]     Train net output #0: loss = 1.33951 (* 1 = 1.33951 loss)
I1030 05:21:42.068042 27430 sgd_solver.cpp:105] Iteration 35000, lr = 0.000130432
I1030 05:22:02.420815 27479 data_layer.cpp:73] Restarting data prefetching from start.
I1030 05:22:11.954186 27430 solver.cpp:222] Iteration 35040 (1.33844 iter/s, 29.8854s/40 iters), loss = 1.35442
I1030 05:22:11.954371 27430 solver.cpp:241]     Train net output #0: loss = 1.35442 (* 1 = 1.35442 loss)
I1030 05:22:11.954385 27430 sgd_solver.cpp:105] Iteration 35040, lr = 0.000129787
I1030 05:22:47.680027 27430 solver.cpp:222] Iteration 35080 (1.11967 iter/s, 35.7248s/40 iters), loss = 0.952552
I1030 05:22:47.680173 27430 solver.cpp:241]     Train net output #0: loss = 0.952552 (* 1 = 0.952552 loss)
I1030 05:22:47.680187 27430 sgd_solver.cpp:105] Iteration 35080, lr = 0.000129145
I1030 05:26:22.107192 27430 solver.cpp:222] Iteration 35120 (0.186548 iter/s, 214.422s/40 iters), loss = 1.11913
I1030 05:26:22.107383 27430 solver.cpp:241]     Train net output #0: loss = 1.11913 (* 1 = 1.11913 loss)
I1030 05:26:22.107398 27430 sgd_solver.cpp:105] Iteration 35120, lr = 0.000128506
I1030 05:26:52.244779 27430 solver.cpp:222] Iteration 35160 (1.32728 iter/s, 30.1367s/40 iters), loss = 1.29248
I1030 05:26:52.244936 27430 solver.cpp:241]     Train net output #0: loss = 1.29248 (* 1 = 1.29248 loss)
I1030 05:26:52.244951 27430 sgd_solver.cpp:105] Iteration 35160, lr = 0.00012787
I1030 05:27:22.309500 27430 solver.cpp:222] Iteration 35200 (1.3305 iter/s, 30.0639s/40 iters), loss = 1.39727
I1030 05:27:22.309655 27430 solver.cpp:241]     Train net output #0: loss = 1.39727 (* 1 = 1.39727 loss)
I1030 05:27:22.309670 27430 sgd_solver.cpp:105] Iteration 35200, lr = 0.000127238
I1030 05:27:52.572212 27430 solver.cpp:222] Iteration 35240 (1.3218 iter/s, 30.2618s/40 iters), loss = 1.38178
I1030 05:27:52.572402 27430 solver.cpp:241]     Train net output #0: loss = 1.38178 (* 1 = 1.38178 loss)
I1030 05:27:52.572415 27430 sgd_solver.cpp:105] Iteration 35240, lr = 0.000126608
I1030 05:28:22.844849 27430 solver.cpp:222] Iteration 35280 (1.32136 iter/s, 30.2717s/40 iters), loss = 1.48345
I1030 05:28:22.845043 27430 solver.cpp:241]     Train net output #0: loss = 1.48345 (* 1 = 1.48345 loss)
I1030 05:28:22.845068 27430 sgd_solver.cpp:105] Iteration 35280, lr = 0.000125982
I1030 05:28:53.090199 27430 solver.cpp:222] Iteration 35320 (1.32256 iter/s, 30.2444s/40 iters), loss = 1.14203
I1030 05:28:53.090369 27430 solver.cpp:241]     Train net output #0: loss = 1.14203 (* 1 = 1.14203 loss)
I1030 05:28:53.090384 27430 sgd_solver.cpp:105] Iteration 35320, lr = 0.000125359
I1030 05:29:23.247036 27430 solver.cpp:222] Iteration 35360 (1.32644 iter/s, 30.156s/40 iters), loss = 1.25592
I1030 05:29:23.247186 27430 solver.cpp:241]     Train net output #0: loss = 1.25592 (* 1 = 1.25592 loss)
I1030 05:29:23.247201 27430 sgd_solver.cpp:105] Iteration 35360, lr = 0.000124738
I1030 05:29:52.854421 27430 solver.cpp:222] Iteration 35400 (1.35105 iter/s, 29.6065s/40 iters), loss = 1.49301
I1030 05:29:52.854482 27430 solver.cpp:241]     Train net output #0: loss = 1.49301 (* 1 = 1.49301 loss)
I1030 05:29:52.854496 27430 sgd_solver.cpp:105] Iteration 35400, lr = 0.000124121
I1030 05:30:22.663290 27430 solver.cpp:222] Iteration 35440 (1.34192 iter/s, 29.8081s/40 iters), loss = 1.57138
I1030 05:30:22.663542 27430 solver.cpp:241]     Train net output #0: loss = 1.57138 (* 1 = 1.57138 loss)
I1030 05:30:22.663563 27430 sgd_solver.cpp:105] Iteration 35440, lr = 0.000123507
I1030 05:30:52.344693 27430 solver.cpp:222] Iteration 35480 (1.34769 iter/s, 29.6804s/40 iters), loss = 1.17593
I1030 05:30:52.344763 27430 solver.cpp:241]     Train net output #0: loss = 1.17593 (* 1 = 1.17593 loss)
I1030 05:30:52.344780 27430 sgd_solver.cpp:105] Iteration 35480, lr = 0.000122896
I1030 05:31:07.070436 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_35500.caffemodel
I1030 05:31:07.212191 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_35500.solverstate
I1030 05:31:07.320127 27430 solver.cpp:334] Iteration 35500, Testing net (#0)
I1030 05:31:38.304476 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1030 05:31:38.517624 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5866
I1030 05:31:38.517675 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81388
I1030 05:31:38.517685 27430 solver.cpp:401]     Test net output #2: loss = 1.83791 (* 1 = 1.83791 loss)
I1030 05:31:54.725874 27430 solver.cpp:222] Iteration 35520 (0.641235 iter/s, 62.3797s/40 iters), loss = 1.48629
I1030 05:31:54.725937 27430 solver.cpp:241]     Train net output #0: loss = 1.48629 (* 1 = 1.48629 loss)
I1030 05:31:54.725950 27430 sgd_solver.cpp:105] Iteration 35520, lr = 0.000122288
I1030 05:32:24.904373 27430 solver.cpp:222] Iteration 35560 (1.32548 iter/s, 30.1777s/40 iters), loss = 1.19017
I1030 05:32:24.904568 27430 solver.cpp:241]     Train net output #0: loss = 1.19017 (* 1 = 1.19017 loss)
I1030 05:32:24.904582 27430 sgd_solver.cpp:105] Iteration 35560, lr = 0.000121683
I1030 05:32:54.847456 27430 solver.cpp:222] Iteration 35600 (1.33591 iter/s, 29.9422s/40 iters), loss = 1.45422
I1030 05:32:54.847513 27430 solver.cpp:241]     Train net output #0: loss = 1.45422 (* 1 = 1.45422 loss)
I1030 05:32:54.847527 27430 sgd_solver.cpp:105] Iteration 35600, lr = 0.000121081
I1030 05:33:24.329282 27430 solver.cpp:222] Iteration 35640 (1.3568 iter/s, 29.4811s/40 iters), loss = 1.53141
I1030 05:33:24.329488 27430 solver.cpp:241]     Train net output #0: loss = 1.53141 (* 1 = 1.53141 loss)
I1030 05:33:24.329501 27430 sgd_solver.cpp:105] Iteration 35640, lr = 0.000120482
I1030 05:33:53.676807 27430 solver.cpp:222] Iteration 35680 (1.36302 iter/s, 29.3466s/40 iters), loss = 1.20542
I1030 05:33:53.676863 27430 solver.cpp:241]     Train net output #0: loss = 1.20542 (* 1 = 1.20542 loss)
I1030 05:33:53.676877 27430 sgd_solver.cpp:105] Iteration 35680, lr = 0.000119886
I1030 05:34:23.048101 27430 solver.cpp:222] Iteration 35720 (1.36191 iter/s, 29.3705s/40 iters), loss = 1.40477
I1030 05:34:23.048297 27430 solver.cpp:241]     Train net output #0: loss = 1.40477 (* 1 = 1.40477 loss)
I1030 05:34:23.048311 27430 sgd_solver.cpp:105] Iteration 35720, lr = 0.000119293
I1030 05:34:52.464596 27430 solver.cpp:222] Iteration 35760 (1.35982 iter/s, 29.4156s/40 iters), loss = 1.2106
I1030 05:34:52.464650 27430 solver.cpp:241]     Train net output #0: loss = 1.2106 (* 1 = 1.2106 loss)
I1030 05:34:52.464663 27430 sgd_solver.cpp:105] Iteration 35760, lr = 0.000118703
I1030 05:35:21.924173 27430 solver.cpp:222] Iteration 35800 (1.35783 iter/s, 29.4588s/40 iters), loss = 1.155
I1030 05:35:21.924371 27430 solver.cpp:241]     Train net output #0: loss = 1.155 (* 1 = 1.155 loss)
I1030 05:35:21.924386 27430 sgd_solver.cpp:105] Iteration 35800, lr = 0.000118116
I1030 05:35:51.436278 27430 solver.cpp:222] Iteration 35840 (1.35542 iter/s, 29.5112s/40 iters), loss = 1.56369
I1030 05:35:51.436342 27430 solver.cpp:241]     Train net output #0: loss = 1.56369 (* 1 = 1.56369 loss)
I1030 05:35:51.436354 27430 sgd_solver.cpp:105] Iteration 35840, lr = 0.000117531
I1030 05:36:20.879500 27430 solver.cpp:222] Iteration 35880 (1.35858 iter/s, 29.4425s/40 iters), loss = 1.24878
I1030 05:36:20.879647 27430 solver.cpp:241]     Train net output #0: loss = 1.24878 (* 1 = 1.24878 loss)
I1030 05:36:20.879662 27430 sgd_solver.cpp:105] Iteration 35880, lr = 0.00011695
I1030 05:36:50.334046 27430 solver.cpp:222] Iteration 35920 (1.35806 iter/s, 29.4537s/40 iters), loss = 1.28347
I1030 05:36:50.334106 27430 solver.cpp:241]     Train net output #0: loss = 1.28347 (* 1 = 1.28347 loss)
I1030 05:36:50.334120 27430 sgd_solver.cpp:105] Iteration 35920, lr = 0.000116371
I1030 05:37:19.756006 27430 solver.cpp:222] Iteration 35960 (1.35956 iter/s, 29.4212s/40 iters), loss = 1.35676
I1030 05:37:19.756228 27430 solver.cpp:241]     Train net output #0: loss = 1.35676 (* 1 = 1.35676 loss)
I1030 05:37:19.756243 27430 sgd_solver.cpp:105] Iteration 35960, lr = 0.000115796
I1030 05:37:48.467134 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_36000.caffemodel
I1030 05:37:48.608278 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_36000.solverstate
I1030 05:37:48.720273 27430 solver.cpp:334] Iteration 36000, Testing net (#0)
I1030 05:38:19.864989 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58724
I1030 05:38:19.865067 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.809879
I1030 05:38:19.865078 27430 solver.cpp:401]     Test net output #2: loss = 1.83214 (* 1 = 1.83214 loss)
I1030 05:38:20.619438 27430 solver.cpp:222] Iteration 36000 (0.657227 iter/s, 60.8618s/40 iters), loss = 1.58999
I1030 05:38:20.619500 27430 solver.cpp:241]     Train net output #0: loss = 1.58999 (* 1 = 1.58999 loss)
I1030 05:38:20.619513 27430 sgd_solver.cpp:105] Iteration 36000, lr = 0.000115223
I1030 05:38:50.206828 27430 solver.cpp:222] Iteration 36040 (1.35196 iter/s, 29.5866s/40 iters), loss = 1.30995
I1030 05:38:50.207000 27430 solver.cpp:241]     Train net output #0: loss = 1.30995 (* 1 = 1.30995 loss)
I1030 05:38:50.207026 27430 sgd_solver.cpp:105] Iteration 36040, lr = 0.000114653
I1030 05:39:20.388891 27430 solver.cpp:222] Iteration 36080 (1.32533 iter/s, 30.1812s/40 iters), loss = 1.54654
I1030 05:39:20.389039 27430 solver.cpp:241]     Train net output #0: loss = 1.54654 (* 1 = 1.54654 loss)
I1030 05:39:20.389052 27430 sgd_solver.cpp:105] Iteration 36080, lr = 0.000114086
I1030 05:39:50.975256 27430 solver.cpp:222] Iteration 36120 (1.30781 iter/s, 30.5855s/40 iters), loss = 1.23761
I1030 05:39:50.975425 27430 solver.cpp:241]     Train net output #0: loss = 1.23761 (* 1 = 1.23761 loss)
I1030 05:39:50.975440 27430 sgd_solver.cpp:105] Iteration 36120, lr = 0.000113521
I1030 05:40:21.451069 27430 solver.cpp:222] Iteration 36160 (1.31256 iter/s, 30.4749s/40 iters), loss = 1.34937
I1030 05:40:21.451282 27430 solver.cpp:241]     Train net output #0: loss = 1.34937 (* 1 = 1.34937 loss)
I1030 05:40:21.451297 27430 sgd_solver.cpp:105] Iteration 36160, lr = 0.00011296
I1030 05:40:51.972059 27430 solver.cpp:222] Iteration 36200 (1.31061 iter/s, 30.52s/40 iters), loss = 1.25707
I1030 05:40:51.972206 27430 solver.cpp:241]     Train net output #0: loss = 1.25707 (* 1 = 1.25707 loss)
I1030 05:40:51.972220 27430 sgd_solver.cpp:105] Iteration 36200, lr = 0.000112401
I1030 05:41:21.660401 27430 solver.cpp:222] Iteration 36240 (1.34737 iter/s, 29.6875s/40 iters), loss = 1.35139
I1030 05:41:21.660466 27430 solver.cpp:241]     Train net output #0: loss = 1.35139 (* 1 = 1.35139 loss)
I1030 05:41:21.660478 27430 sgd_solver.cpp:105] Iteration 36240, lr = 0.000111845
I1030 05:41:51.200234 27430 solver.cpp:222] Iteration 36280 (1.35414 iter/s, 29.539s/40 iters), loss = 1.34118
I1030 05:41:51.200398 27430 solver.cpp:241]     Train net output #0: loss = 1.34118 (* 1 = 1.34118 loss)
I1030 05:41:51.200412 27430 sgd_solver.cpp:105] Iteration 36280, lr = 0.000111291
I1030 05:42:20.936565 27430 solver.cpp:222] Iteration 36320 (1.3452 iter/s, 29.7355s/40 iters), loss = 1.33912
I1030 05:42:20.936627 27430 solver.cpp:241]     Train net output #0: loss = 1.33912 (* 1 = 1.33912 loss)
I1030 05:42:20.936640 27430 sgd_solver.cpp:105] Iteration 36320, lr = 0.000110741
I1030 05:42:50.862030 27430 solver.cpp:222] Iteration 36360 (1.33669 iter/s, 29.9247s/40 iters), loss = 1.36876
I1030 05:42:50.862262 27430 solver.cpp:241]     Train net output #0: loss = 1.36876 (* 1 = 1.36876 loss)
I1030 05:42:50.862277 27430 sgd_solver.cpp:105] Iteration 36360, lr = 0.000110193
I1030 05:43:20.694468 27430 solver.cpp:222] Iteration 36400 (1.34086 iter/s, 29.8315s/40 iters), loss = 1.44347
I1030 05:43:20.694525 27430 solver.cpp:241]     Train net output #0: loss = 1.44347 (* 1 = 1.44347 loss)
I1030 05:43:20.694537 27430 sgd_solver.cpp:105] Iteration 36400, lr = 0.000109648
I1030 05:43:51.029862 27430 solver.cpp:222] Iteration 36440 (1.31863 iter/s, 30.3346s/40 iters), loss = 1.32668
I1030 05:43:51.030028 27430 solver.cpp:241]     Train net output #0: loss = 1.32668 (* 1 = 1.32668 loss)
I1030 05:43:51.030043 27430 sgd_solver.cpp:105] Iteration 36440, lr = 0.000109105
I1030 05:44:21.513152 27430 solver.cpp:222] Iteration 36480 (1.31223 iter/s, 30.4824s/40 iters), loss = 1.52399
I1030 05:44:21.513289 27430 solver.cpp:241]     Train net output #0: loss = 1.52399 (* 1 = 1.52399 loss)
I1030 05:44:21.513303 27430 sgd_solver.cpp:105] Iteration 36480, lr = 0.000108566
I1030 05:44:35.828172 27430 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_36500.caffemodel
I1030 05:44:35.975790 27430 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_36500.solverstate
I1030 05:44:36.094468 27430 solver.cpp:334] Iteration 36500, Testing net (#0)
I1030 05:45:07.206671 27480 data_layer.cpp:73] Restarting data prefetching from start.
I1030 05:45:07.414901 27430 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58612
I1030 05:45:07.414954 27430 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8138
I1030 05:45:07.414965 27430 solver.cpp:401]     Test net output #2: loss = 1.83625 (* 1 = 1.83625 loss)
I1030 05:45:23.390414 27430 solver.cpp:222] Iteration 36520 (0.646458 iter/s, 61.8757s/40 iters), loss = 1.48011
I1030 05:45:23.390468 27430 solver.cpp:241]     Train net output #0: loss = 1.48011 (* 1 = 1.48011 loss)
I1030 05:45:23.390480 27430 sgd_solver.cpp:105] Iteration 36520, lr = 0.000108029
I1030 05:45:53.883569 27430 solver.cpp:222] Iteration 36560 (1.3118 iter/s, 30.4924s/40 iters), loss = 1.50615
I1030 05:45:53.883749 27430 solver.cpp:241]     Train net output #0: loss = 1.50615 (* 1 = 1.50615 loss)
I1030 05:45:53.883766 27430 sgd_solver.cpp:105] Iteration 36560, lr = 0.000107494
I1030 05:46:24.079964 27430 solver.cpp:222] Iteration 36600 (1.3247 iter/s, 30.1955s/40 iters), loss = 1.47557
I1030 05:46:24.080173 27430 solver.cpp:241]     Train net output #0: loss = 1.47557 (* 1 = 1.47557 loss)
I1030 05:46:24.080188 27430 sgd_solver.cpp:105] Iteration 36600, lr = 0.000106962
I1030 05:46:53.869081 27430 solver.cpp:222] Iteration 36640 (1.34281 iter/s, 29.7882s/40 iters), loss = 1.21274
I1030 05:46:53.869146 27430 solver.cpp:241]     Train net output #0: loss = 1.21274 (* 1 = 1.21274 loss)
I1030 05:46:53.869159 27430 sgd_solver.cpp:105] Iteration 36640, lr = 0.000106433
I1030 05:47:23.748157 27430 solver.cpp:222] Iteration 36680 (1.33876 iter/s, 29.8783s/40 iters), loss = 1.44941
I1030 05:47:23.748306 27430 solver.cpp:241]     Train net output #0: loss = 1.44941 (* 1 = 1.44941 loss)
I1030 05:47:23.748319 27430 sgd_solver.cpp:105] Iteration 36680, lr = 0.000105907
I1030 05:47:55.092622 27430 solver.cpp:222] Iteration 36720 (1.27618 iter/s, 31.3436s/40 iters), loss = 1.57714
I1030 05:47:55.092806 27430 solver.cpp:241]     Train net output #0: loss = 1.57714 (* 1 = 1.57714 loss)
I1030 05:47:55.092821 27430 sgd_solver.cpp:105] Iteration 36720, lr = 0.000105383
I1030 05:48:25.852604 27430 solver.cpp:222] Iteration 36760 (1.30043 iter/s, 30.7591s/40 iters), loss = 1.5461
I1030 05:48:25.852804 27430 solver.cpp:241]     Train net output #0: loss = 1.5461 (* 1 = 1.5461 loss)
I1030 05:48:25.852826 27430 sgd_solver.cpp:105] Iteration 36760, lr = 0.000104861
I1030 05:48:55.841536 27430 solver.cpp:222] Iteration 36800 (1.33387 iter/s, 29.988s/40 iters), loss = 1.657
I1030 05:48:55.841593 27430 solver.cpp:241]     Train net output #0: loss = 1.657 (* 1 = 1.657 loss)
I1030 05:48:55.841610 27430 sgd_solver.cpp:105] Iteration 36800, lr = 0.000104343
I1030 05:49:26.306303 27430 solver.cpp:222] Iteration 36840 (1.31303 iter/s, 30.464s/40 iters), loss = 1.74238
I1030 05:49:26.306550 27430 solver.cpp:241]     Train net output #0: loss = 1.74238 (* 1 = 1.74238 loss)
I1030 05:49:26.306565 27430 sgd_solver.cpp:105] Iteration 36840, lr = 0.000103826
I1030 05:49:55.690958 27430 solver.cpp:222] Iteration 36880 (1.3613 iter/s, 29.3837s/40 iters), loss = 1.2998
I1030 05:49:55.691016 27430 solver.cpp:241]     Train net output #0: loss = 1.2998 (* 1 = 1.2998 loss)
I1030 05:49:55.691030 27430 sgd_solver.cpp:105] Iteration 36880, lr = 0.000103313
I1030 05:50:25.564275 27430 solver.cpp:222] Iteration 36920 (1.33902 iter/s, 29.8725s/40 iters), loss = 1.6752
I1030 05:50:25.564469 27430 solver.cpp:241]     Train net output #0: loss = 1.6752 (* 1 = 1.6752 loss)
I1030 05:50:25.564483 27430 sgd_solver.cpp:105] Iteration 36920, lr = 0.000102802
