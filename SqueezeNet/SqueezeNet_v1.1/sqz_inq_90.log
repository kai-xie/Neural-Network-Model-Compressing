nohup: ignoring input
I1030 05:31:12.073113  1046 caffe.cpp:218] Using GPUs 0, 1, 2, 3
I1030 05:31:12.074291  1046 caffe.cpp:223] GPU 0: Tesla P40
I1030 05:31:12.074718  1046 caffe.cpp:223] GPU 1: Tesla P40
I1030 05:31:12.075112  1046 caffe.cpp:223] GPU 2: Tesla P40
I1030 05:31:12.075501  1046 caffe.cpp:223] GPU 3: Tesla P40
I1030 05:31:12.719141  1046 solver.cpp:44] Initializing solver from parameters: 
test_iter: 500
test_interval: 500
base_lr: 0.01
display: 40
max_iter: 50000
lr_policy: "exp"
gamma: 0.999876
momentum: 0.9
weight_decay: 0.0002
snapshot: 500
snapshot_prefix: "SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90"
solver_mode: GPU
device_id: 0
random_seed: 42
net: "SqueezeNet/SqueezeNet_v1.1/train_val_inq_80-90.prototxt"
train_state {
  level: 0
  stage: ""
}
I1030 05:31:12.719543  1046 solver.cpp:87] Creating training net from net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_80-90.prototxt
I1030 05:31:12.721472  1046 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1030 05:31:12.721530  1046 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top1
I1030 05:31:12.721539  1046 net.cpp:301] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top5
I1030 05:31:12.722215  1046 net.cpp:51] Initializing net from parameters: 
name: "SqueezeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/data/caffe-imagenet/ilsvrc12_train_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "INQConvolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "fire3/concat"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire4/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool3"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "fire5/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire4/concat"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "fire5/concat"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire6/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool5"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "fire9/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire8/concat"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "INQConvolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "pool10"
  bottom: "label"
  top: "loss"
}
I1030 05:31:12.722625  1046 layer_factory.hpp:77] Creating layer data
I1030 05:31:12.723148  1046 db_lmdb.cpp:35] Opened lmdb /home/data/caffe-imagenet/ilsvrc12_train_lmdb
I1030 05:31:12.723201  1046 net.cpp:84] Creating Layer data
I1030 05:31:12.723213  1046 net.cpp:387] data -> data
I1030 05:31:12.723248  1046 net.cpp:387] data -> label
I1030 05:31:12.725025  1046 data_layer.cpp:45] output data size: 128,3,227,227
I1030 05:31:12.938027  1046 net.cpp:127] Setting up data
I1030 05:31:12.938100  1046 net.cpp:136] Top shape: 128 3 227 227 (19787136)
I1030 05:31:12.938109  1046 net.cpp:136] Top shape: 128 (128)
I1030 05:31:12.938115  1046 net.cpp:144] Memory required for data: 79149056
I1030 05:31:12.938134  1046 layer_factory.hpp:77] Creating layer conv1
I1030 05:31:12.938163  1046 net.cpp:84] Creating Layer conv1
I1030 05:31:12.938175  1046 net.cpp:413] conv1 <- data
I1030 05:31:12.938196  1046 net.cpp:387] conv1 -> conv1
I1030 05:31:12.941555  1046 net.cpp:127] Setting up conv1
I1030 05:31:12.941577  1046 net.cpp:136] Top shape: 128 64 113 113 (104603648)
I1030 05:31:12.941583  1046 net.cpp:144] Memory required for data: 497563648
I1030 05:31:12.941606  1046 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1030 05:31:12.941620  1046 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1030 05:31:12.941632  1046 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1030 05:31:12.941640  1046 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:1
I1030 05:31:12.941645  1046 layer_factory.hpp:77] Creating layer relu_conv1
I1030 05:31:12.941663  1046 net.cpp:84] Creating Layer relu_conv1
I1030 05:31:12.941668  1046 net.cpp:413] relu_conv1 <- conv1
I1030 05:31:12.941676  1046 net.cpp:374] relu_conv1 -> conv1 (in-place)
I1030 05:31:13.310590  1046 net.cpp:127] Setting up relu_conv1
I1030 05:31:13.310642  1046 net.cpp:136] Top shape: 128 64 113 113 (104603648)
I1030 05:31:13.310649  1046 net.cpp:144] Memory required for data: 915978240
I1030 05:31:13.310660  1046 layer_factory.hpp:77] Creating layer pool1
I1030 05:31:13.310683  1046 net.cpp:84] Creating Layer pool1
I1030 05:31:13.310690  1046 net.cpp:413] pool1 <- conv1
I1030 05:31:13.310703  1046 net.cpp:387] pool1 -> pool1
I1030 05:31:13.310812  1046 net.cpp:127] Setting up pool1
I1030 05:31:13.310858  1046 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1030 05:31:13.310864  1046 net.cpp:144] Memory required for data: 1018738688
I1030 05:31:13.310869  1046 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I1030 05:31:13.310887  1046 net.cpp:84] Creating Layer fire2/squeeze1x1
I1030 05:31:13.310894  1046 net.cpp:413] fire2/squeeze1x1 <- pool1
I1030 05:31:13.310901  1046 net.cpp:387] fire2/squeeze1x1 -> fire2/squeeze1x1
I1030 05:31:13.312747  1046 net.cpp:127] Setting up fire2/squeeze1x1
I1030 05:31:13.312768  1046 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1030 05:31:13.312774  1046 net.cpp:144] Memory required for data: 1044428800
I1030 05:31:13.312786  1046 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1030 05:31:13.312796  1046 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1030 05:31:13.312803  1046 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1030 05:31:13.312809  1046 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:4
I1030 05:31:13.312814  1046 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I1030 05:31:13.312824  1046 net.cpp:84] Creating Layer fire2/relu_squeeze1x1
I1030 05:31:13.312830  1046 net.cpp:413] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I1030 05:31:13.312837  1046 net.cpp:374] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I1030 05:31:13.314172  1046 net.cpp:127] Setting up fire2/relu_squeeze1x1
I1030 05:31:13.314191  1046 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1030 05:31:13.314198  1046 net.cpp:144] Memory required for data: 1070118912
I1030 05:31:13.314203  1046 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1030 05:31:13.314215  1046 net.cpp:84] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1030 05:31:13.314221  1046 net.cpp:413] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I1030 05:31:13.314229  1046 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1030 05:31:13.314239  1046 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1030 05:31:13.314287  1046 net.cpp:127] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1030 05:31:13.314303  1046 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1030 05:31:13.314311  1046 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1030 05:31:13.314316  1046 net.cpp:144] Memory required for data: 1121499136
I1030 05:31:13.314321  1046 layer_factory.hpp:77] Creating layer fire2/expand1x1
I1030 05:31:13.314330  1046 net.cpp:84] Creating Layer fire2/expand1x1
I1030 05:31:13.314337  1046 net.cpp:413] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1030 05:31:13.314345  1046 net.cpp:387] fire2/expand1x1 -> fire2/expand1x1
I1030 05:31:13.314663  1046 net.cpp:127] Setting up fire2/expand1x1
I1030 05:31:13.314676  1046 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1030 05:31:13.314682  1046 net.cpp:144] Memory required for data: 1224259584
I1030 05:31:13.314690  1046 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1030 05:31:13.314702  1046 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1030 05:31:13.314709  1046 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1030 05:31:13.314714  1046 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:7
I1030 05:31:13.314719  1046 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I1030 05:31:13.314728  1046 net.cpp:84] Creating Layer fire2/relu_expand1x1
I1030 05:31:13.314734  1046 net.cpp:413] fire2/relu_expand1x1 <- fire2/expand1x1
I1030 05:31:13.314741  1046 net.cpp:374] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I1030 05:31:13.314930  1046 net.cpp:127] Setting up fire2/relu_expand1x1
I1030 05:31:13.314941  1046 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1030 05:31:13.314956  1046 net.cpp:144] Memory required for data: 1327020032
I1030 05:31:13.314975  1046 layer_factory.hpp:77] Creating layer fire2/expand3x3
I1030 05:31:13.314985  1046 net.cpp:84] Creating Layer fire2/expand3x3
I1030 05:31:13.314990  1046 net.cpp:413] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1030 05:31:13.314998  1046 net.cpp:387] fire2/expand3x3 -> fire2/expand3x3
I1030 05:31:13.315402  1046 net.cpp:127] Setting up fire2/expand3x3
I1030 05:31:13.315415  1046 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1030 05:31:13.315421  1046 net.cpp:144] Memory required for data: 1429780480
I1030 05:31:13.315429  1046 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1030 05:31:13.315436  1046 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1030 05:31:13.315443  1046 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1030 05:31:13.315449  1046 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:9
I1030 05:31:13.315454  1046 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I1030 05:31:13.315461  1046 net.cpp:84] Creating Layer fire2/relu_expand3x3
I1030 05:31:13.315467  1046 net.cpp:413] fire2/relu_expand3x3 <- fire2/expand3x3
I1030 05:31:13.315474  1046 net.cpp:374] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I1030 05:31:13.315666  1046 net.cpp:127] Setting up fire2/relu_expand3x3
I1030 05:31:13.315677  1046 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1030 05:31:13.315683  1046 net.cpp:144] Memory required for data: 1532540928
I1030 05:31:13.315688  1046 layer_factory.hpp:77] Creating layer fire2/concat
I1030 05:31:13.315699  1046 net.cpp:84] Creating Layer fire2/concat
I1030 05:31:13.315707  1046 net.cpp:413] fire2/concat <- fire2/expand1x1
I1030 05:31:13.315713  1046 net.cpp:413] fire2/concat <- fire2/expand3x3
I1030 05:31:13.315719  1046 net.cpp:387] fire2/concat -> fire2/concat
I1030 05:31:13.315752  1046 net.cpp:127] Setting up fire2/concat
I1030 05:31:13.315760  1046 net.cpp:136] Top shape: 128 128 56 56 (51380224)
I1030 05:31:13.315765  1046 net.cpp:144] Memory required for data: 1738061824
I1030 05:31:13.315770  1046 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I1030 05:31:13.315780  1046 net.cpp:84] Creating Layer fire3/squeeze1x1
I1030 05:31:13.315788  1046 net.cpp:413] fire3/squeeze1x1 <- fire2/concat
I1030 05:31:13.315795  1046 net.cpp:387] fire3/squeeze1x1 -> fire3/squeeze1x1
I1030 05:31:13.316107  1046 net.cpp:127] Setting up fire3/squeeze1x1
I1030 05:31:13.316118  1046 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1030 05:31:13.316123  1046 net.cpp:144] Memory required for data: 1763751936
I1030 05:31:13.316131  1046 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1030 05:31:13.316140  1046 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1030 05:31:13.316149  1046 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1030 05:31:13.316155  1046 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:12
I1030 05:31:13.316160  1046 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I1030 05:31:13.316167  1046 net.cpp:84] Creating Layer fire3/relu_squeeze1x1
I1030 05:31:13.316174  1046 net.cpp:413] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I1030 05:31:13.316181  1046 net.cpp:374] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I1030 05:31:13.317522  1046 net.cpp:127] Setting up fire3/relu_squeeze1x1
I1030 05:31:13.317540  1046 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1030 05:31:13.317546  1046 net.cpp:144] Memory required for data: 1789442048
I1030 05:31:13.317553  1046 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1030 05:31:13.317569  1046 net.cpp:84] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1030 05:31:13.317574  1046 net.cpp:413] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I1030 05:31:13.317589  1046 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1030 05:31:13.317612  1046 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1030 05:31:13.317661  1046 net.cpp:127] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1030 05:31:13.317670  1046 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1030 05:31:13.317677  1046 net.cpp:136] Top shape: 128 16 56 56 (6422528)
I1030 05:31:13.317682  1046 net.cpp:144] Memory required for data: 1840822272
I1030 05:31:13.317687  1046 layer_factory.hpp:77] Creating layer fire3/expand1x1
I1030 05:31:13.317695  1046 net.cpp:84] Creating Layer fire3/expand1x1
I1030 05:31:13.317700  1046 net.cpp:413] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1030 05:31:13.317708  1046 net.cpp:387] fire3/expand1x1 -> fire3/expand1x1
I1030 05:31:13.318012  1046 net.cpp:127] Setting up fire3/expand1x1
I1030 05:31:13.318023  1046 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1030 05:31:13.318028  1046 net.cpp:144] Memory required for data: 1943582720
I1030 05:31:13.318037  1046 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1030 05:31:13.318044  1046 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1030 05:31:13.318050  1046 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1030 05:31:13.318055  1046 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:15
I1030 05:31:13.318060  1046 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I1030 05:31:13.318070  1046 net.cpp:84] Creating Layer fire3/relu_expand1x1
I1030 05:31:13.318078  1046 net.cpp:413] fire3/relu_expand1x1 <- fire3/expand1x1
I1030 05:31:13.318084  1046 net.cpp:374] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I1030 05:31:13.318271  1046 net.cpp:127] Setting up fire3/relu_expand1x1
I1030 05:31:13.318284  1046 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1030 05:31:13.318289  1046 net.cpp:144] Memory required for data: 2046343168
I1030 05:31:13.318295  1046 layer_factory.hpp:77] Creating layer fire3/expand3x3
I1030 05:31:13.318311  1046 net.cpp:84] Creating Layer fire3/expand3x3
I1030 05:31:13.318317  1046 net.cpp:413] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1030 05:31:13.318325  1046 net.cpp:387] fire3/expand3x3 -> fire3/expand3x3
I1030 05:31:13.318706  1046 net.cpp:127] Setting up fire3/expand3x3
I1030 05:31:13.318717  1046 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1030 05:31:13.318722  1046 net.cpp:144] Memory required for data: 2149103616
I1030 05:31:13.318728  1046 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1030 05:31:13.318735  1046 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1030 05:31:13.318740  1046 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1030 05:31:13.318747  1046 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:17
I1030 05:31:13.318752  1046 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I1030 05:31:13.318759  1046 net.cpp:84] Creating Layer fire3/relu_expand3x3
I1030 05:31:13.318764  1046 net.cpp:413] fire3/relu_expand3x3 <- fire3/expand3x3
I1030 05:31:13.318771  1046 net.cpp:374] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I1030 05:31:13.318955  1046 net.cpp:127] Setting up fire3/relu_expand3x3
I1030 05:31:13.318967  1046 net.cpp:136] Top shape: 128 64 56 56 (25690112)
I1030 05:31:13.318974  1046 net.cpp:144] Memory required for data: 2251864064
I1030 05:31:13.318979  1046 layer_factory.hpp:77] Creating layer fire3/concat
I1030 05:31:13.318987  1046 net.cpp:84] Creating Layer fire3/concat
I1030 05:31:13.318992  1046 net.cpp:413] fire3/concat <- fire3/expand1x1
I1030 05:31:13.319000  1046 net.cpp:413] fire3/concat <- fire3/expand3x3
I1030 05:31:13.319005  1046 net.cpp:387] fire3/concat -> fire3/concat
I1030 05:31:13.319043  1046 net.cpp:127] Setting up fire3/concat
I1030 05:31:13.319052  1046 net.cpp:136] Top shape: 128 128 56 56 (51380224)
I1030 05:31:13.319068  1046 net.cpp:144] Memory required for data: 2457384960
I1030 05:31:13.319074  1046 layer_factory.hpp:77] Creating layer pool3
I1030 05:31:13.319082  1046 net.cpp:84] Creating Layer pool3
I1030 05:31:13.319087  1046 net.cpp:413] pool3 <- fire3/concat
I1030 05:31:13.319095  1046 net.cpp:387] pool3 -> pool3
I1030 05:31:13.319138  1046 net.cpp:127] Setting up pool3
I1030 05:31:13.319147  1046 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1030 05:31:13.319152  1046 net.cpp:144] Memory required for data: 2508765184
I1030 05:31:13.319157  1046 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I1030 05:31:13.319167  1046 net.cpp:84] Creating Layer fire4/squeeze1x1
I1030 05:31:13.319175  1046 net.cpp:413] fire4/squeeze1x1 <- pool3
I1030 05:31:13.319182  1046 net.cpp:387] fire4/squeeze1x1 -> fire4/squeeze1x1
I1030 05:31:13.319525  1046 net.cpp:127] Setting up fire4/squeeze1x1
I1030 05:31:13.319536  1046 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1030 05:31:13.319541  1046 net.cpp:144] Memory required for data: 2521610240
I1030 05:31:13.319548  1046 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1030 05:31:13.319555  1046 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1030 05:31:13.319561  1046 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1030 05:31:13.319566  1046 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:21
I1030 05:31:13.319571  1046 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I1030 05:31:13.319578  1046 net.cpp:84] Creating Layer fire4/relu_squeeze1x1
I1030 05:31:13.319586  1046 net.cpp:413] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I1030 05:31:13.319592  1046 net.cpp:374] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I1030 05:31:13.319782  1046 net.cpp:127] Setting up fire4/relu_squeeze1x1
I1030 05:31:13.319793  1046 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1030 05:31:13.319798  1046 net.cpp:144] Memory required for data: 2534455296
I1030 05:31:13.319804  1046 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1030 05:31:13.319813  1046 net.cpp:84] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1030 05:31:13.319818  1046 net.cpp:413] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I1030 05:31:13.319824  1046 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1030 05:31:13.319835  1046 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1030 05:31:13.319878  1046 net.cpp:127] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1030 05:31:13.319887  1046 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1030 05:31:13.319893  1046 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1030 05:31:13.319900  1046 net.cpp:144] Memory required for data: 2560145408
I1030 05:31:13.319905  1046 layer_factory.hpp:77] Creating layer fire4/expand1x1
I1030 05:31:13.319914  1046 net.cpp:84] Creating Layer fire4/expand1x1
I1030 05:31:13.319921  1046 net.cpp:413] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1030 05:31:13.319927  1046 net.cpp:387] fire4/expand1x1 -> fire4/expand1x1
I1030 05:31:13.320252  1046 net.cpp:127] Setting up fire4/expand1x1
I1030 05:31:13.320266  1046 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1030 05:31:13.320271  1046 net.cpp:144] Memory required for data: 2611525632
I1030 05:31:13.320279  1046 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1030 05:31:13.320288  1046 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1030 05:31:13.320294  1046 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1030 05:31:13.320307  1046 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:24
I1030 05:31:13.320317  1046 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I1030 05:31:13.320338  1046 net.cpp:84] Creating Layer fire4/relu_expand1x1
I1030 05:31:13.320344  1046 net.cpp:413] fire4/relu_expand1x1 <- fire4/expand1x1
I1030 05:31:13.320350  1046 net.cpp:374] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I1030 05:31:13.321774  1046 net.cpp:127] Setting up fire4/relu_expand1x1
I1030 05:31:13.321794  1046 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1030 05:31:13.321799  1046 net.cpp:144] Memory required for data: 2662905856
I1030 05:31:13.321805  1046 layer_factory.hpp:77] Creating layer fire4/expand3x3
I1030 05:31:13.321817  1046 net.cpp:84] Creating Layer fire4/expand3x3
I1030 05:31:13.321825  1046 net.cpp:413] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1030 05:31:13.321835  1046 net.cpp:387] fire4/expand3x3 -> fire4/expand3x3
I1030 05:31:13.327466  1046 net.cpp:127] Setting up fire4/expand3x3
I1030 05:31:13.327486  1046 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1030 05:31:13.327491  1046 net.cpp:144] Memory required for data: 2714286080
I1030 05:31:13.327498  1046 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1030 05:31:13.327507  1046 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1030 05:31:13.327512  1046 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1030 05:31:13.327517  1046 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:26
I1030 05:31:13.327522  1046 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I1030 05:31:13.327533  1046 net.cpp:84] Creating Layer fire4/relu_expand3x3
I1030 05:31:13.327538  1046 net.cpp:413] fire4/relu_expand3x3 <- fire4/expand3x3
I1030 05:31:13.327545  1046 net.cpp:374] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I1030 05:31:13.327776  1046 net.cpp:127] Setting up fire4/relu_expand3x3
I1030 05:31:13.327790  1046 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1030 05:31:13.327795  1046 net.cpp:144] Memory required for data: 2765666304
I1030 05:31:13.327800  1046 layer_factory.hpp:77] Creating layer fire4/concat
I1030 05:31:13.327807  1046 net.cpp:84] Creating Layer fire4/concat
I1030 05:31:13.327812  1046 net.cpp:413] fire4/concat <- fire4/expand1x1
I1030 05:31:13.327818  1046 net.cpp:413] fire4/concat <- fire4/expand3x3
I1030 05:31:13.327826  1046 net.cpp:387] fire4/concat -> fire4/concat
I1030 05:31:13.327857  1046 net.cpp:127] Setting up fire4/concat
I1030 05:31:13.327865  1046 net.cpp:136] Top shape: 128 256 28 28 (25690112)
I1030 05:31:13.327870  1046 net.cpp:144] Memory required for data: 2868426752
I1030 05:31:13.327874  1046 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I1030 05:31:13.327886  1046 net.cpp:84] Creating Layer fire5/squeeze1x1
I1030 05:31:13.327891  1046 net.cpp:413] fire5/squeeze1x1 <- fire4/concat
I1030 05:31:13.327900  1046 net.cpp:387] fire5/squeeze1x1 -> fire5/squeeze1x1
I1030 05:31:13.328301  1046 net.cpp:127] Setting up fire5/squeeze1x1
I1030 05:31:13.328313  1046 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1030 05:31:13.328318  1046 net.cpp:144] Memory required for data: 2881271808
I1030 05:31:13.328325  1046 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1030 05:31:13.328331  1046 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1030 05:31:13.328337  1046 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1030 05:31:13.328342  1046 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:29
I1030 05:31:13.328347  1046 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I1030 05:31:13.328354  1046 net.cpp:84] Creating Layer fire5/relu_squeeze1x1
I1030 05:31:13.328361  1046 net.cpp:413] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I1030 05:31:13.328368  1046 net.cpp:374] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I1030 05:31:13.328603  1046 net.cpp:127] Setting up fire5/relu_squeeze1x1
I1030 05:31:13.328624  1046 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1030 05:31:13.328649  1046 net.cpp:144] Memory required for data: 2894116864
I1030 05:31:13.328655  1046 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1030 05:31:13.328666  1046 net.cpp:84] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1030 05:31:13.328671  1046 net.cpp:413] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I1030 05:31:13.328678  1046 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1030 05:31:13.328687  1046 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1030 05:31:13.334833  1046 net.cpp:127] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1030 05:31:13.334844  1046 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1030 05:31:13.334851  1046 net.cpp:136] Top shape: 128 32 28 28 (3211264)
I1030 05:31:13.334856  1046 net.cpp:144] Memory required for data: 2919806976
I1030 05:31:13.334861  1046 layer_factory.hpp:77] Creating layer fire5/expand1x1
I1030 05:31:13.334874  1046 net.cpp:84] Creating Layer fire5/expand1x1
I1030 05:31:13.334880  1046 net.cpp:413] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1030 05:31:13.334890  1046 net.cpp:387] fire5/expand1x1 -> fire5/expand1x1
I1030 05:31:13.335237  1046 net.cpp:127] Setting up fire5/expand1x1
I1030 05:31:13.335248  1046 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1030 05:31:13.335254  1046 net.cpp:144] Memory required for data: 2971187200
I1030 05:31:13.335261  1046 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1030 05:31:13.335268  1046 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1030 05:31:13.335273  1046 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1030 05:31:13.335279  1046 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:32
I1030 05:31:13.335283  1046 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I1030 05:31:13.335292  1046 net.cpp:84] Creating Layer fire5/relu_expand1x1
I1030 05:31:13.335304  1046 net.cpp:413] fire5/relu_expand1x1 <- fire5/expand1x1
I1030 05:31:13.335311  1046 net.cpp:374] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I1030 05:31:13.335561  1046 net.cpp:127] Setting up fire5/relu_expand1x1
I1030 05:31:13.335573  1046 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1030 05:31:13.335579  1046 net.cpp:144] Memory required for data: 3022567424
I1030 05:31:13.335584  1046 layer_factory.hpp:77] Creating layer fire5/expand3x3
I1030 05:31:13.335595  1046 net.cpp:84] Creating Layer fire5/expand3x3
I1030 05:31:13.335602  1046 net.cpp:413] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1030 05:31:13.335610  1046 net.cpp:387] fire5/expand3x3 -> fire5/expand3x3
I1030 05:31:13.336220  1046 net.cpp:127] Setting up fire5/expand3x3
I1030 05:31:13.336231  1046 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1030 05:31:13.336236  1046 net.cpp:144] Memory required for data: 3073947648
I1030 05:31:13.336243  1046 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1030 05:31:13.336249  1046 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1030 05:31:13.336256  1046 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1030 05:31:13.336261  1046 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:34
I1030 05:31:13.336266  1046 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I1030 05:31:13.336275  1046 net.cpp:84] Creating Layer fire5/relu_expand3x3
I1030 05:31:13.336280  1046 net.cpp:413] fire5/relu_expand3x3 <- fire5/expand3x3
I1030 05:31:13.336287  1046 net.cpp:374] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I1030 05:31:13.337656  1046 net.cpp:127] Setting up fire5/relu_expand3x3
I1030 05:31:13.337677  1046 net.cpp:136] Top shape: 128 128 28 28 (12845056)
I1030 05:31:13.337689  1046 net.cpp:144] Memory required for data: 3125327872
I1030 05:31:13.337713  1046 layer_factory.hpp:77] Creating layer fire5/concat
I1030 05:31:13.337723  1046 net.cpp:84] Creating Layer fire5/concat
I1030 05:31:13.337730  1046 net.cpp:413] fire5/concat <- fire5/expand1x1
I1030 05:31:13.337738  1046 net.cpp:413] fire5/concat <- fire5/expand3x3
I1030 05:31:13.337744  1046 net.cpp:387] fire5/concat -> fire5/concat
I1030 05:31:13.337782  1046 net.cpp:127] Setting up fire5/concat
I1030 05:31:13.337790  1046 net.cpp:136] Top shape: 128 256 28 28 (25690112)
I1030 05:31:13.337795  1046 net.cpp:144] Memory required for data: 3228088320
I1030 05:31:13.337800  1046 layer_factory.hpp:77] Creating layer pool5
I1030 05:31:13.337810  1046 net.cpp:84] Creating Layer pool5
I1030 05:31:13.337815  1046 net.cpp:413] pool5 <- fire5/concat
I1030 05:31:13.337821  1046 net.cpp:387] pool5 -> pool5
I1030 05:31:13.337867  1046 net.cpp:127] Setting up pool5
I1030 05:31:13.337877  1046 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1030 05:31:13.337882  1046 net.cpp:144] Memory required for data: 3253778432
I1030 05:31:13.337887  1046 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I1030 05:31:13.337898  1046 net.cpp:84] Creating Layer fire6/squeeze1x1
I1030 05:31:13.337903  1046 net.cpp:413] fire6/squeeze1x1 <- pool5
I1030 05:31:13.337911  1046 net.cpp:387] fire6/squeeze1x1 -> fire6/squeeze1x1
I1030 05:31:13.338354  1046 net.cpp:127] Setting up fire6/squeeze1x1
I1030 05:31:13.338368  1046 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1030 05:31:13.338373  1046 net.cpp:144] Memory required for data: 3258595328
I1030 05:31:13.338380  1046 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1030 05:31:13.338387  1046 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1030 05:31:13.338392  1046 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1030 05:31:13.338398  1046 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:38
I1030 05:31:13.338403  1046 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I1030 05:31:13.338412  1046 net.cpp:84] Creating Layer fire6/relu_squeeze1x1
I1030 05:31:13.338416  1046 net.cpp:413] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I1030 05:31:13.338423  1046 net.cpp:374] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I1030 05:31:13.338631  1046 net.cpp:127] Setting up fire6/relu_squeeze1x1
I1030 05:31:13.338646  1046 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1030 05:31:13.338651  1046 net.cpp:144] Memory required for data: 3263412224
I1030 05:31:13.338657  1046 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1030 05:31:13.338665  1046 net.cpp:84] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1030 05:31:13.338670  1046 net.cpp:413] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I1030 05:31:13.338675  1046 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1030 05:31:13.338683  1046 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1030 05:31:13.338738  1046 net.cpp:127] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1030 05:31:13.338747  1046 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1030 05:31:13.338754  1046 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1030 05:31:13.338759  1046 net.cpp:144] Memory required for data: 3273046016
I1030 05:31:13.338763  1046 layer_factory.hpp:77] Creating layer fire6/expand1x1
I1030 05:31:13.338776  1046 net.cpp:84] Creating Layer fire6/expand1x1
I1030 05:31:13.338781  1046 net.cpp:413] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1030 05:31:13.338788  1046 net.cpp:387] fire6/expand1x1 -> fire6/expand1x1
I1030 05:31:13.339191  1046 net.cpp:127] Setting up fire6/expand1x1
I1030 05:31:13.339202  1046 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1030 05:31:13.339212  1046 net.cpp:144] Memory required for data: 3292313600
I1030 05:31:13.339229  1046 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1030 05:31:13.339236  1046 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1030 05:31:13.339243  1046 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1030 05:31:13.339248  1046 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:41
I1030 05:31:13.339253  1046 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I1030 05:31:13.339269  1046 net.cpp:84] Creating Layer fire6/relu_expand1x1
I1030 05:31:13.339275  1046 net.cpp:413] fire6/relu_expand1x1 <- fire6/expand1x1
I1030 05:31:13.339282  1046 net.cpp:374] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I1030 05:31:13.339495  1046 net.cpp:127] Setting up fire6/relu_expand1x1
I1030 05:31:13.339509  1046 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1030 05:31:13.339514  1046 net.cpp:144] Memory required for data: 3311581184
I1030 05:31:13.339519  1046 layer_factory.hpp:77] Creating layer fire6/expand3x3
I1030 05:31:13.339530  1046 net.cpp:84] Creating Layer fire6/expand3x3
I1030 05:31:13.339538  1046 net.cpp:413] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1030 05:31:13.339545  1046 net.cpp:387] fire6/expand3x3 -> fire6/expand3x3
I1030 05:31:13.341956  1046 net.cpp:127] Setting up fire6/expand3x3
I1030 05:31:13.341979  1046 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1030 05:31:13.341984  1046 net.cpp:144] Memory required for data: 3330848768
I1030 05:31:13.341991  1046 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1030 05:31:13.342000  1046 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1030 05:31:13.342005  1046 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1030 05:31:13.342011  1046 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:43
I1030 05:31:13.342015  1046 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I1030 05:31:13.342023  1046 net.cpp:84] Creating Layer fire6/relu_expand3x3
I1030 05:31:13.342030  1046 net.cpp:413] fire6/relu_expand3x3 <- fire6/expand3x3
I1030 05:31:13.342036  1046 net.cpp:374] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I1030 05:31:13.342263  1046 net.cpp:127] Setting up fire6/relu_expand3x3
I1030 05:31:13.342278  1046 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1030 05:31:13.342283  1046 net.cpp:144] Memory required for data: 3350116352
I1030 05:31:13.342289  1046 layer_factory.hpp:77] Creating layer fire6/concat
I1030 05:31:13.342301  1046 net.cpp:84] Creating Layer fire6/concat
I1030 05:31:13.342308  1046 net.cpp:413] fire6/concat <- fire6/expand1x1
I1030 05:31:13.342314  1046 net.cpp:413] fire6/concat <- fire6/expand3x3
I1030 05:31:13.342321  1046 net.cpp:387] fire6/concat -> fire6/concat
I1030 05:31:13.342357  1046 net.cpp:127] Setting up fire6/concat
I1030 05:31:13.342366  1046 net.cpp:136] Top shape: 128 384 14 14 (9633792)
I1030 05:31:13.342370  1046 net.cpp:144] Memory required for data: 3388651520
I1030 05:31:13.342375  1046 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I1030 05:31:13.342386  1046 net.cpp:84] Creating Layer fire7/squeeze1x1
I1030 05:31:13.342391  1046 net.cpp:413] fire7/squeeze1x1 <- fire6/concat
I1030 05:31:13.342401  1046 net.cpp:387] fire7/squeeze1x1 -> fire7/squeeze1x1
I1030 05:31:13.342882  1046 net.cpp:127] Setting up fire7/squeeze1x1
I1030 05:31:13.342895  1046 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1030 05:31:13.342900  1046 net.cpp:144] Memory required for data: 3393468416
I1030 05:31:13.342914  1046 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1030 05:31:13.342926  1046 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1030 05:31:13.342932  1046 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1030 05:31:13.342938  1046 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:46
I1030 05:31:13.342949  1046 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I1030 05:31:13.342969  1046 net.cpp:84] Creating Layer fire7/relu_squeeze1x1
I1030 05:31:13.342975  1046 net.cpp:413] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I1030 05:31:13.342983  1046 net.cpp:374] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I1030 05:31:13.344372  1046 net.cpp:127] Setting up fire7/relu_squeeze1x1
I1030 05:31:13.344391  1046 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1030 05:31:13.344396  1046 net.cpp:144] Memory required for data: 3398285312
I1030 05:31:13.344403  1046 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1030 05:31:13.344410  1046 net.cpp:84] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1030 05:31:13.344418  1046 net.cpp:413] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I1030 05:31:13.344426  1046 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1030 05:31:13.344435  1046 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1030 05:31:13.344487  1046 net.cpp:127] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1030 05:31:13.344499  1046 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1030 05:31:13.344506  1046 net.cpp:136] Top shape: 128 48 14 14 (1204224)
I1030 05:31:13.344521  1046 net.cpp:144] Memory required for data: 3407919104
I1030 05:31:13.344527  1046 layer_factory.hpp:77] Creating layer fire7/expand1x1
I1030 05:31:13.344537  1046 net.cpp:84] Creating Layer fire7/expand1x1
I1030 05:31:13.344544  1046 net.cpp:413] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1030 05:31:13.344552  1046 net.cpp:387] fire7/expand1x1 -> fire7/expand1x1
I1030 05:31:13.344957  1046 net.cpp:127] Setting up fire7/expand1x1
I1030 05:31:13.344969  1046 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1030 05:31:13.344974  1046 net.cpp:144] Memory required for data: 3427186688
I1030 05:31:13.344981  1046 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1030 05:31:13.344988  1046 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1030 05:31:13.344993  1046 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1030 05:31:13.345000  1046 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:49
I1030 05:31:13.345005  1046 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I1030 05:31:13.345011  1046 net.cpp:84] Creating Layer fire7/relu_expand1x1
I1030 05:31:13.345017  1046 net.cpp:413] fire7/relu_expand1x1 <- fire7/expand1x1
I1030 05:31:13.345026  1046 net.cpp:374] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I1030 05:31:13.345244  1046 net.cpp:127] Setting up fire7/relu_expand1x1
I1030 05:31:13.345257  1046 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1030 05:31:13.345262  1046 net.cpp:144] Memory required for data: 3446454272
I1030 05:31:13.345266  1046 layer_factory.hpp:77] Creating layer fire7/expand3x3
I1030 05:31:13.345278  1046 net.cpp:84] Creating Layer fire7/expand3x3
I1030 05:31:13.345283  1046 net.cpp:413] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1030 05:31:13.345294  1046 net.cpp:387] fire7/expand3x3 -> fire7/expand3x3
I1030 05:31:13.346302  1046 net.cpp:127] Setting up fire7/expand3x3
I1030 05:31:13.346316  1046 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1030 05:31:13.346321  1046 net.cpp:144] Memory required for data: 3465721856
I1030 05:31:13.346328  1046 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1030 05:31:13.346335  1046 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1030 05:31:13.346343  1046 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1030 05:31:13.346348  1046 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:51
I1030 05:31:13.346359  1046 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I1030 05:31:13.346379  1046 net.cpp:84] Creating Layer fire7/relu_expand3x3
I1030 05:31:13.346385  1046 net.cpp:413] fire7/relu_expand3x3 <- fire7/expand3x3
I1030 05:31:13.346393  1046 net.cpp:374] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I1030 05:31:13.346603  1046 net.cpp:127] Setting up fire7/relu_expand3x3
I1030 05:31:13.346616  1046 net.cpp:136] Top shape: 128 192 14 14 (4816896)
I1030 05:31:13.346621  1046 net.cpp:144] Memory required for data: 3484989440
I1030 05:31:13.346626  1046 layer_factory.hpp:77] Creating layer fire7/concat
I1030 05:31:13.346633  1046 net.cpp:84] Creating Layer fire7/concat
I1030 05:31:13.346638  1046 net.cpp:413] fire7/concat <- fire7/expand1x1
I1030 05:31:13.346644  1046 net.cpp:413] fire7/concat <- fire7/expand3x3
I1030 05:31:13.346653  1046 net.cpp:387] fire7/concat -> fire7/concat
I1030 05:31:13.346688  1046 net.cpp:127] Setting up fire7/concat
I1030 05:31:13.346695  1046 net.cpp:136] Top shape: 128 384 14 14 (9633792)
I1030 05:31:13.346699  1046 net.cpp:144] Memory required for data: 3523524608
I1030 05:31:13.346704  1046 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I1030 05:31:13.346715  1046 net.cpp:84] Creating Layer fire8/squeeze1x1
I1030 05:31:13.346720  1046 net.cpp:413] fire8/squeeze1x1 <- fire7/concat
I1030 05:31:13.346735  1046 net.cpp:387] fire8/squeeze1x1 -> fire8/squeeze1x1
I1030 05:31:13.347259  1046 net.cpp:127] Setting up fire8/squeeze1x1
I1030 05:31:13.347270  1046 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1030 05:31:13.347275  1046 net.cpp:144] Memory required for data: 3529947136
I1030 05:31:13.347282  1046 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1030 05:31:13.347288  1046 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1030 05:31:13.347295  1046 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1030 05:31:13.347306  1046 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:54
I1030 05:31:13.347311  1046 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I1030 05:31:13.347319  1046 net.cpp:84] Creating Layer fire8/relu_squeeze1x1
I1030 05:31:13.347326  1046 net.cpp:413] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I1030 05:31:13.347332  1046 net.cpp:374] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I1030 05:31:13.348726  1046 net.cpp:127] Setting up fire8/relu_squeeze1x1
I1030 05:31:13.348745  1046 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1030 05:31:13.348752  1046 net.cpp:144] Memory required for data: 3536369664
I1030 05:31:13.348757  1046 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1030 05:31:13.348768  1046 net.cpp:84] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1030 05:31:13.348774  1046 net.cpp:413] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I1030 05:31:13.348781  1046 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1030 05:31:13.348790  1046 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1030 05:31:13.348845  1046 net.cpp:127] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1030 05:31:13.348855  1046 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1030 05:31:13.348861  1046 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1030 05:31:13.348866  1046 net.cpp:144] Memory required for data: 3549214720
I1030 05:31:13.348871  1046 layer_factory.hpp:77] Creating layer fire8/expand1x1
I1030 05:31:13.348883  1046 net.cpp:84] Creating Layer fire8/expand1x1
I1030 05:31:13.348888  1046 net.cpp:413] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1030 05:31:13.348897  1046 net.cpp:387] fire8/expand1x1 -> fire8/expand1x1
I1030 05:31:13.349361  1046 net.cpp:127] Setting up fire8/expand1x1
I1030 05:31:13.349375  1046 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1030 05:31:13.349385  1046 net.cpp:144] Memory required for data: 3574904832
I1030 05:31:13.349406  1046 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1030 05:31:13.349413  1046 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1030 05:31:13.349419  1046 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1030 05:31:13.349424  1046 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:57
I1030 05:31:13.349428  1046 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I1030 05:31:13.349437  1046 net.cpp:84] Creating Layer fire8/relu_expand1x1
I1030 05:31:13.349442  1046 net.cpp:413] fire8/relu_expand1x1 <- fire8/expand1x1
I1030 05:31:13.349450  1046 net.cpp:374] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I1030 05:31:13.349663  1046 net.cpp:127] Setting up fire8/relu_expand1x1
I1030 05:31:13.349674  1046 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1030 05:31:13.349680  1046 net.cpp:144] Memory required for data: 3600594944
I1030 05:31:13.349685  1046 layer_factory.hpp:77] Creating layer fire8/expand3x3
I1030 05:31:13.349697  1046 net.cpp:84] Creating Layer fire8/expand3x3
I1030 05:31:13.349702  1046 net.cpp:413] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1030 05:31:13.349714  1046 net.cpp:387] fire8/expand3x3 -> fire8/expand3x3
I1030 05:31:13.352618  1046 net.cpp:127] Setting up fire8/expand3x3
I1030 05:31:13.352638  1046 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1030 05:31:13.352644  1046 net.cpp:144] Memory required for data: 3626285056
I1030 05:31:13.352651  1046 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1030 05:31:13.352659  1046 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1030 05:31:13.352665  1046 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1030 05:31:13.352671  1046 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:59
I1030 05:31:13.352675  1046 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I1030 05:31:13.352684  1046 net.cpp:84] Creating Layer fire8/relu_expand3x3
I1030 05:31:13.352689  1046 net.cpp:413] fire8/relu_expand3x3 <- fire8/expand3x3
I1030 05:31:13.352699  1046 net.cpp:374] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I1030 05:31:13.352922  1046 net.cpp:127] Setting up fire8/relu_expand3x3
I1030 05:31:13.352936  1046 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1030 05:31:13.352941  1046 net.cpp:144] Memory required for data: 3651975168
I1030 05:31:13.352946  1046 layer_factory.hpp:77] Creating layer fire8/concat
I1030 05:31:13.352954  1046 net.cpp:84] Creating Layer fire8/concat
I1030 05:31:13.352959  1046 net.cpp:413] fire8/concat <- fire8/expand1x1
I1030 05:31:13.352965  1046 net.cpp:413] fire8/concat <- fire8/expand3x3
I1030 05:31:13.352974  1046 net.cpp:387] fire8/concat -> fire8/concat
I1030 05:31:13.353008  1046 net.cpp:127] Setting up fire8/concat
I1030 05:31:13.353018  1046 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1030 05:31:13.353022  1046 net.cpp:144] Memory required for data: 3703355392
I1030 05:31:13.353027  1046 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I1030 05:31:13.353039  1046 net.cpp:84] Creating Layer fire9/squeeze1x1
I1030 05:31:13.353044  1046 net.cpp:413] fire9/squeeze1x1 <- fire8/concat
I1030 05:31:13.353056  1046 net.cpp:387] fire9/squeeze1x1 -> fire9/squeeze1x1
I1030 05:31:13.353651  1046 net.cpp:127] Setting up fire9/squeeze1x1
I1030 05:31:13.353663  1046 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1030 05:31:13.353667  1046 net.cpp:144] Memory required for data: 3709777920
I1030 05:31:13.353674  1046 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1030 05:31:13.353682  1046 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1030 05:31:13.353688  1046 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1030 05:31:13.353694  1046 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:62
I1030 05:31:13.353719  1046 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I1030 05:31:13.353727  1046 net.cpp:84] Creating Layer fire9/relu_squeeze1x1
I1030 05:31:13.353734  1046 net.cpp:413] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I1030 05:31:13.353742  1046 net.cpp:374] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I1030 05:31:13.353958  1046 net.cpp:127] Setting up fire9/relu_squeeze1x1
I1030 05:31:13.353971  1046 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1030 05:31:13.353977  1046 net.cpp:144] Memory required for data: 3716200448
I1030 05:31:13.353982  1046 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1030 05:31:13.353999  1046 net.cpp:84] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1030 05:31:13.354005  1046 net.cpp:413] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I1030 05:31:13.354012  1046 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1030 05:31:13.354020  1046 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1030 05:31:13.354070  1046 net.cpp:127] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1030 05:31:13.354081  1046 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1030 05:31:13.354087  1046 net.cpp:136] Top shape: 128 64 14 14 (1605632)
I1030 05:31:13.354092  1046 net.cpp:144] Memory required for data: 3729045504
I1030 05:31:13.354099  1046 layer_factory.hpp:77] Creating layer fire9/expand1x1
I1030 05:31:13.354106  1046 net.cpp:84] Creating Layer fire9/expand1x1
I1030 05:31:13.354112  1046 net.cpp:413] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1030 05:31:13.354121  1046 net.cpp:387] fire9/expand1x1 -> fire9/expand1x1
I1030 05:31:13.354579  1046 net.cpp:127] Setting up fire9/expand1x1
I1030 05:31:13.354593  1046 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1030 05:31:13.354596  1046 net.cpp:144] Memory required for data: 3754735616
I1030 05:31:13.354604  1046 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1030 05:31:13.354610  1046 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1030 05:31:13.354617  1046 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1030 05:31:13.354622  1046 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:65
I1030 05:31:13.354627  1046 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I1030 05:31:13.354636  1046 net.cpp:84] Creating Layer fire9/relu_expand1x1
I1030 05:31:13.354641  1046 net.cpp:413] fire9/relu_expand1x1 <- fire9/expand1x1
I1030 05:31:13.354650  1046 net.cpp:374] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I1030 05:31:13.356036  1046 net.cpp:127] Setting up fire9/relu_expand1x1
I1030 05:31:13.356055  1046 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1030 05:31:13.356061  1046 net.cpp:144] Memory required for data: 3780425728
I1030 05:31:13.356066  1046 layer_factory.hpp:77] Creating layer fire9/expand3x3
I1030 05:31:13.356081  1046 net.cpp:84] Creating Layer fire9/expand3x3
I1030 05:31:13.356088  1046 net.cpp:413] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1030 05:31:13.356099  1046 net.cpp:387] fire9/expand3x3 -> fire9/expand3x3
I1030 05:31:13.357599  1046 net.cpp:127] Setting up fire9/expand3x3
I1030 05:31:13.357614  1046 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1030 05:31:13.357617  1046 net.cpp:144] Memory required for data: 3806115840
I1030 05:31:13.357625  1046 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1030 05:31:13.357632  1046 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1030 05:31:13.357638  1046 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1030 05:31:13.357645  1046 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:67
I1030 05:31:13.357661  1046 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I1030 05:31:13.357681  1046 net.cpp:84] Creating Layer fire9/relu_expand3x3
I1030 05:31:13.357686  1046 net.cpp:413] fire9/relu_expand3x3 <- fire9/expand3x3
I1030 05:31:13.357694  1046 net.cpp:374] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I1030 05:31:13.357904  1046 net.cpp:127] Setting up fire9/relu_expand3x3
I1030 05:31:13.357916  1046 net.cpp:136] Top shape: 128 256 14 14 (6422528)
I1030 05:31:13.357921  1046 net.cpp:144] Memory required for data: 3831805952
I1030 05:31:13.357928  1046 layer_factory.hpp:77] Creating layer fire9/concat
I1030 05:31:13.357934  1046 net.cpp:84] Creating Layer fire9/concat
I1030 05:31:13.357939  1046 net.cpp:413] fire9/concat <- fire9/expand1x1
I1030 05:31:13.357945  1046 net.cpp:413] fire9/concat <- fire9/expand3x3
I1030 05:31:13.357954  1046 net.cpp:387] fire9/concat -> fire9/concat
I1030 05:31:13.357986  1046 net.cpp:127] Setting up fire9/concat
I1030 05:31:13.357995  1046 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1030 05:31:13.358000  1046 net.cpp:144] Memory required for data: 3883186176
I1030 05:31:13.358006  1046 layer_factory.hpp:77] Creating layer drop9
I1030 05:31:13.358018  1046 net.cpp:84] Creating Layer drop9
I1030 05:31:13.358024  1046 net.cpp:413] drop9 <- fire9/concat
I1030 05:31:13.358032  1046 net.cpp:374] drop9 -> fire9/concat (in-place)
I1030 05:31:13.358067  1046 net.cpp:127] Setting up drop9
I1030 05:31:13.358075  1046 net.cpp:136] Top shape: 128 512 14 14 (12845056)
I1030 05:31:13.358080  1046 net.cpp:144] Memory required for data: 3934566400
I1030 05:31:13.358085  1046 layer_factory.hpp:77] Creating layer conv10
I1030 05:31:13.358098  1046 net.cpp:84] Creating Layer conv10
I1030 05:31:13.358103  1046 net.cpp:413] conv10 <- fire9/concat
I1030 05:31:13.358113  1046 net.cpp:387] conv10 -> conv10
I1030 05:31:13.367784  1046 net.cpp:127] Setting up conv10
I1030 05:31:13.367805  1046 net.cpp:136] Top shape: 128 1000 14 14 (25088000)
I1030 05:31:13.367811  1046 net.cpp:144] Memory required for data: 4034918400
I1030 05:31:13.367818  1046 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1030 05:31:13.367826  1046 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1030 05:31:13.367832  1046 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1030 05:31:13.367838  1046 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:71
I1030 05:31:13.367842  1046 layer_factory.hpp:77] Creating layer relu_conv10
I1030 05:31:13.367852  1046 net.cpp:84] Creating Layer relu_conv10
I1030 05:31:13.367858  1046 net.cpp:413] relu_conv10 <- conv10
I1030 05:31:13.367866  1046 net.cpp:374] relu_conv10 -> conv10 (in-place)
I1030 05:31:13.368101  1046 net.cpp:127] Setting up relu_conv10
I1030 05:31:13.368114  1046 net.cpp:136] Top shape: 128 1000 14 14 (25088000)
I1030 05:31:13.368120  1046 net.cpp:144] Memory required for data: 4135270400
I1030 05:31:13.368126  1046 layer_factory.hpp:77] Creating layer pool10
I1030 05:31:13.368136  1046 net.cpp:84] Creating Layer pool10
I1030 05:31:13.368141  1046 net.cpp:413] pool10 <- conv10
I1030 05:31:13.368149  1046 net.cpp:387] pool10 -> pool10
I1030 05:31:13.368408  1046 net.cpp:127] Setting up pool10
I1030 05:31:13.368422  1046 net.cpp:136] Top shape: 128 1000 1 1 (128000)
I1030 05:31:13.368428  1046 net.cpp:144] Memory required for data: 4135782400
I1030 05:31:13.368434  1046 layer_factory.hpp:77] Creating layer loss
I1030 05:31:13.368444  1046 net.cpp:84] Creating Layer loss
I1030 05:31:13.368449  1046 net.cpp:413] loss <- pool10
I1030 05:31:13.368455  1046 net.cpp:413] loss <- label
I1030 05:31:13.368466  1046 net.cpp:387] loss -> loss
I1030 05:31:13.368480  1046 layer_factory.hpp:77] Creating layer loss
I1030 05:31:13.371493  1046 net.cpp:127] Setting up loss
I1030 05:31:13.371515  1046 net.cpp:136] Top shape: (1)
I1030 05:31:13.371520  1046 net.cpp:139]     with loss weight 1
I1030 05:31:13.371548  1046 net.cpp:144] Memory required for data: 4135782404
I1030 05:31:13.371562  1046 net.cpp:205] loss needs backward computation.
I1030 05:31:13.371582  1046 net.cpp:205] pool10 needs backward computation.
I1030 05:31:13.371587  1046 net.cpp:205] relu_conv10 needs backward computation.
I1030 05:31:13.371592  1046 net.cpp:205] conv10 needs backward computation.
I1030 05:31:13.371596  1046 net.cpp:205] drop9 needs backward computation.
I1030 05:31:13.371600  1046 net.cpp:205] fire9/concat needs backward computation.
I1030 05:31:13.371605  1046 net.cpp:205] fire9/relu_expand3x3 needs backward computation.
I1030 05:31:13.371609  1046 net.cpp:205] fire9/expand3x3 needs backward computation.
I1030 05:31:13.371614  1046 net.cpp:205] fire9/relu_expand1x1 needs backward computation.
I1030 05:31:13.371618  1046 net.cpp:205] fire9/expand1x1 needs backward computation.
I1030 05:31:13.371623  1046 net.cpp:205] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I1030 05:31:13.371628  1046 net.cpp:205] fire9/relu_squeeze1x1 needs backward computation.
I1030 05:31:13.371634  1046 net.cpp:205] fire9/squeeze1x1 needs backward computation.
I1030 05:31:13.371637  1046 net.cpp:205] fire8/concat needs backward computation.
I1030 05:31:13.371642  1046 net.cpp:205] fire8/relu_expand3x3 needs backward computation.
I1030 05:31:13.371647  1046 net.cpp:205] fire8/expand3x3 needs backward computation.
I1030 05:31:13.371651  1046 net.cpp:205] fire8/relu_expand1x1 needs backward computation.
I1030 05:31:13.371655  1046 net.cpp:205] fire8/expand1x1 needs backward computation.
I1030 05:31:13.371660  1046 net.cpp:205] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I1030 05:31:13.371665  1046 net.cpp:205] fire8/relu_squeeze1x1 needs backward computation.
I1030 05:31:13.371670  1046 net.cpp:205] fire8/squeeze1x1 needs backward computation.
I1030 05:31:13.371675  1046 net.cpp:205] fire7/concat needs backward computation.
I1030 05:31:13.371680  1046 net.cpp:205] fire7/relu_expand3x3 needs backward computation.
I1030 05:31:13.371683  1046 net.cpp:205] fire7/expand3x3 needs backward computation.
I1030 05:31:13.371687  1046 net.cpp:205] fire7/relu_expand1x1 needs backward computation.
I1030 05:31:13.371692  1046 net.cpp:205] fire7/expand1x1 needs backward computation.
I1030 05:31:13.371696  1046 net.cpp:205] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I1030 05:31:13.371701  1046 net.cpp:205] fire7/relu_squeeze1x1 needs backward computation.
I1030 05:31:13.371706  1046 net.cpp:205] fire7/squeeze1x1 needs backward computation.
I1030 05:31:13.371709  1046 net.cpp:205] fire6/concat needs backward computation.
I1030 05:31:13.371714  1046 net.cpp:205] fire6/relu_expand3x3 needs backward computation.
I1030 05:31:13.371719  1046 net.cpp:205] fire6/expand3x3 needs backward computation.
I1030 05:31:13.371723  1046 net.cpp:205] fire6/relu_expand1x1 needs backward computation.
I1030 05:31:13.371727  1046 net.cpp:205] fire6/expand1x1 needs backward computation.
I1030 05:31:13.371732  1046 net.cpp:205] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I1030 05:31:13.371737  1046 net.cpp:205] fire6/relu_squeeze1x1 needs backward computation.
I1030 05:31:13.371740  1046 net.cpp:205] fire6/squeeze1x1 needs backward computation.
I1030 05:31:13.371745  1046 net.cpp:205] pool5 needs backward computation.
I1030 05:31:13.371750  1046 net.cpp:205] fire5/concat needs backward computation.
I1030 05:31:13.371754  1046 net.cpp:205] fire5/relu_expand3x3 needs backward computation.
I1030 05:31:13.371759  1046 net.cpp:205] fire5/expand3x3 needs backward computation.
I1030 05:31:13.371763  1046 net.cpp:205] fire5/relu_expand1x1 needs backward computation.
I1030 05:31:13.371767  1046 net.cpp:205] fire5/expand1x1 needs backward computation.
I1030 05:31:13.371773  1046 net.cpp:205] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I1030 05:31:13.371776  1046 net.cpp:205] fire5/relu_squeeze1x1 needs backward computation.
I1030 05:31:13.371781  1046 net.cpp:205] fire5/squeeze1x1 needs backward computation.
I1030 05:31:13.371789  1046 net.cpp:205] fire4/concat needs backward computation.
I1030 05:31:13.371794  1046 net.cpp:205] fire4/relu_expand3x3 needs backward computation.
I1030 05:31:13.371803  1046 net.cpp:205] fire4/expand3x3 needs backward computation.
I1030 05:31:13.371809  1046 net.cpp:205] fire4/relu_expand1x1 needs backward computation.
I1030 05:31:13.371812  1046 net.cpp:205] fire4/expand1x1 needs backward computation.
I1030 05:31:13.371817  1046 net.cpp:205] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I1030 05:31:13.371830  1046 net.cpp:205] fire4/relu_squeeze1x1 needs backward computation.
I1030 05:31:13.371835  1046 net.cpp:205] fire4/squeeze1x1 needs backward computation.
I1030 05:31:13.371840  1046 net.cpp:205] pool3 needs backward computation.
I1030 05:31:13.371845  1046 net.cpp:205] fire3/concat needs backward computation.
I1030 05:31:13.371850  1046 net.cpp:205] fire3/relu_expand3x3 needs backward computation.
I1030 05:31:13.371855  1046 net.cpp:205] fire3/expand3x3 needs backward computation.
I1030 05:31:13.371858  1046 net.cpp:205] fire3/relu_expand1x1 needs backward computation.
I1030 05:31:13.371863  1046 net.cpp:205] fire3/expand1x1 needs backward computation.
I1030 05:31:13.371867  1046 net.cpp:205] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I1030 05:31:13.371872  1046 net.cpp:205] fire3/relu_squeeze1x1 needs backward computation.
I1030 05:31:13.371876  1046 net.cpp:205] fire3/squeeze1x1 needs backward computation.
I1030 05:31:13.371881  1046 net.cpp:205] fire2/concat needs backward computation.
I1030 05:31:13.371886  1046 net.cpp:205] fire2/relu_expand3x3 needs backward computation.
I1030 05:31:13.371891  1046 net.cpp:205] fire2/expand3x3 needs backward computation.
I1030 05:31:13.371896  1046 net.cpp:205] fire2/relu_expand1x1 needs backward computation.
I1030 05:31:13.371899  1046 net.cpp:205] fire2/expand1x1 needs backward computation.
I1030 05:31:13.371903  1046 net.cpp:205] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I1030 05:31:13.371908  1046 net.cpp:205] fire2/relu_squeeze1x1 needs backward computation.
I1030 05:31:13.371912  1046 net.cpp:205] fire2/squeeze1x1 needs backward computation.
I1030 05:31:13.371917  1046 net.cpp:205] pool1 needs backward computation.
I1030 05:31:13.371922  1046 net.cpp:205] relu_conv1 needs backward computation.
I1030 05:31:13.371927  1046 net.cpp:205] conv1 needs backward computation.
I1030 05:31:13.371932  1046 net.cpp:207] data does not need backward computation.
I1030 05:31:13.371937  1046 net.cpp:249] This network produces output loss
I1030 05:31:13.371990  1046 net.cpp:262] Network initialization done.
I1030 05:31:13.373805  1046 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_80-90.prototxt
I1030 05:31:13.373914  1046 net.cpp:301] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1030 05:31:13.374681  1046 net.cpp:51] Initializing net from parameters: 
name: "SqueezeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "/home/data/caffe-imagenet/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "INQConvolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "INQConvolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "INQConvolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "fire3/concat"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire4/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool3"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "INQConvolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "fire5/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire4/concat"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "INQConvolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "fire5/concat"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire6/squeeze1x1"
  type: "INQConvolution"
  bottom: "pool5"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "INQConvolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "INQConvolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "INQConvolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "fire9/squeeze1x1"
  type: "INQConvolution"
  bottom: "fire8/concat"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "INQConvolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "INQConvolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
  inq_convolution_param {
    portion: 0.8
    portion: 0.9
    weight_mask_filler {
      type: "constant"
      value: 1
    }
    bias_mask_filler {
      type: "constant"
      value: 1
    }
    num_quantum_values: 7
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "pool10"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy_top1"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy_top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy_top5"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy_top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I1030 05:31:13.375072  1046 layer_factory.hpp:77] Creating layer data
I1030 05:31:13.375150  1046 db_lmdb.cpp:35] Opened lmdb /home/data/caffe-imagenet/ilsvrc12_val_lmdb
I1030 05:31:13.375172  1046 net.cpp:84] Creating Layer data
I1030 05:31:13.375182  1046 net.cpp:387] data -> data
I1030 05:31:13.375200  1046 net.cpp:387] data -> label
I1030 05:31:13.375627  1046 data_layer.cpp:45] output data size: 50,3,227,227
I1030 05:31:13.466626  1046 net.cpp:127] Setting up data
I1030 05:31:13.466680  1046 net.cpp:136] Top shape: 50 3 227 227 (7729350)
I1030 05:31:13.466688  1046 net.cpp:136] Top shape: 50 (50)
I1030 05:31:13.466694  1046 net.cpp:144] Memory required for data: 30917600
I1030 05:31:13.466704  1046 layer_factory.hpp:77] Creating layer label_data_1_split
I1030 05:31:13.466722  1046 net.cpp:84] Creating Layer label_data_1_split
I1030 05:31:13.466729  1046 net.cpp:413] label_data_1_split <- label
I1030 05:31:13.466740  1046 net.cpp:387] label_data_1_split -> label_data_1_split_0
I1030 05:31:13.466754  1046 net.cpp:387] label_data_1_split -> label_data_1_split_1
I1030 05:31:13.466763  1046 net.cpp:387] label_data_1_split -> label_data_1_split_2
I1030 05:31:13.466895  1046 net.cpp:127] Setting up label_data_1_split
I1030 05:31:13.466907  1046 net.cpp:136] Top shape: 50 (50)
I1030 05:31:13.466913  1046 net.cpp:136] Top shape: 50 (50)
I1030 05:31:13.466919  1046 net.cpp:136] Top shape: 50 (50)
I1030 05:31:13.466924  1046 net.cpp:144] Memory required for data: 30918200
I1030 05:31:13.466929  1046 layer_factory.hpp:77] Creating layer conv1
I1030 05:31:13.466945  1046 net.cpp:84] Creating Layer conv1
I1030 05:31:13.466951  1046 net.cpp:413] conv1 <- data
I1030 05:31:13.466960  1046 net.cpp:387] conv1 -> conv1
I1030 05:31:13.467381  1046 net.cpp:127] Setting up conv1
I1030 05:31:13.467394  1046 net.cpp:136] Top shape: 50 64 113 113 (40860800)
I1030 05:31:13.467399  1046 net.cpp:144] Memory required for data: 194361400
I1030 05:31:13.467411  1046 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1030 05:31:13.467420  1046 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1030 05:31:13.467428  1046 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1030 05:31:13.467437  1046 net.cpp:453] Found INQ layer:conv1, type: INQConvolution, layer id:2
I1030 05:31:13.467442  1046 layer_factory.hpp:77] Creating layer relu_conv1
I1030 05:31:13.467453  1046 net.cpp:84] Creating Layer relu_conv1
I1030 05:31:13.467458  1046 net.cpp:413] relu_conv1 <- conv1
I1030 05:31:13.467465  1046 net.cpp:374] relu_conv1 -> conv1 (in-place)
I1030 05:31:13.467809  1046 net.cpp:127] Setting up relu_conv1
I1030 05:31:13.467823  1046 net.cpp:136] Top shape: 50 64 113 113 (40860800)
I1030 05:31:13.467828  1046 net.cpp:144] Memory required for data: 357804600
I1030 05:31:13.467833  1046 layer_factory.hpp:77] Creating layer pool1
I1030 05:31:13.467846  1046 net.cpp:84] Creating Layer pool1
I1030 05:31:13.467851  1046 net.cpp:413] pool1 <- conv1
I1030 05:31:13.467859  1046 net.cpp:387] pool1 -> pool1
I1030 05:31:13.467916  1046 net.cpp:127] Setting up pool1
I1030 05:31:13.467923  1046 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1030 05:31:13.467928  1046 net.cpp:144] Memory required for data: 397945400
I1030 05:31:13.467933  1046 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I1030 05:31:13.467944  1046 net.cpp:84] Creating Layer fire2/squeeze1x1
I1030 05:31:13.467949  1046 net.cpp:413] fire2/squeeze1x1 <- pool1
I1030 05:31:13.467958  1046 net.cpp:387] fire2/squeeze1x1 -> fire2/squeeze1x1
I1030 05:31:13.470738  1046 net.cpp:127] Setting up fire2/squeeze1x1
I1030 05:31:13.470752  1046 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1030 05:31:13.470757  1046 net.cpp:144] Memory required for data: 407980600
I1030 05:31:13.470764  1046 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1030 05:31:13.470773  1046 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1030 05:31:13.470780  1046 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1030 05:31:13.470787  1046 net.cpp:453] Found INQ layer:fire2/squeeze1x1, type: INQConvolution, layer id:5
I1030 05:31:13.470793  1046 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I1030 05:31:13.470801  1046 net.cpp:84] Creating Layer fire2/relu_squeeze1x1
I1030 05:31:13.470818  1046 net.cpp:413] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I1030 05:31:13.470850  1046 net.cpp:374] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I1030 05:31:13.471078  1046 net.cpp:127] Setting up fire2/relu_squeeze1x1
I1030 05:31:13.471091  1046 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1030 05:31:13.471096  1046 net.cpp:144] Memory required for data: 418015800
I1030 05:31:13.471101  1046 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1030 05:31:13.471109  1046 net.cpp:84] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1030 05:31:13.471114  1046 net.cpp:413] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I1030 05:31:13.471122  1046 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1030 05:31:13.471132  1046 net.cpp:387] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1030 05:31:13.471184  1046 net.cpp:127] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I1030 05:31:13.471194  1046 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1030 05:31:13.471199  1046 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1030 05:31:13.471205  1046 net.cpp:144] Memory required for data: 438086200
I1030 05:31:13.471210  1046 layer_factory.hpp:77] Creating layer fire2/expand1x1
I1030 05:31:13.471222  1046 net.cpp:84] Creating Layer fire2/expand1x1
I1030 05:31:13.471228  1046 net.cpp:413] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I1030 05:31:13.471236  1046 net.cpp:387] fire2/expand1x1 -> fire2/expand1x1
I1030 05:31:13.473871  1046 net.cpp:127] Setting up fire2/expand1x1
I1030 05:31:13.473886  1046 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1030 05:31:13.473891  1046 net.cpp:144] Memory required for data: 478227000
I1030 05:31:13.473902  1046 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1030 05:31:13.473912  1046 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1030 05:31:13.473919  1046 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1030 05:31:13.473925  1046 net.cpp:453] Found INQ layer:fire2/expand1x1, type: INQConvolution, layer id:8
I1030 05:31:13.473932  1046 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I1030 05:31:13.473949  1046 net.cpp:84] Creating Layer fire2/relu_expand1x1
I1030 05:31:13.473956  1046 net.cpp:413] fire2/relu_expand1x1 <- fire2/expand1x1
I1030 05:31:13.473963  1046 net.cpp:374] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I1030 05:31:13.475474  1046 net.cpp:127] Setting up fire2/relu_expand1x1
I1030 05:31:13.475495  1046 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1030 05:31:13.475500  1046 net.cpp:144] Memory required for data: 518367800
I1030 05:31:13.475507  1046 layer_factory.hpp:77] Creating layer fire2/expand3x3
I1030 05:31:13.475520  1046 net.cpp:84] Creating Layer fire2/expand3x3
I1030 05:31:13.475527  1046 net.cpp:413] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I1030 05:31:13.475535  1046 net.cpp:387] fire2/expand3x3 -> fire2/expand3x3
I1030 05:31:13.475996  1046 net.cpp:127] Setting up fire2/expand3x3
I1030 05:31:13.476007  1046 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1030 05:31:13.476011  1046 net.cpp:144] Memory required for data: 558508600
I1030 05:31:13.476018  1046 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1030 05:31:13.476025  1046 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1030 05:31:13.476032  1046 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1030 05:31:13.476037  1046 net.cpp:453] Found INQ layer:fire2/expand3x3, type: INQConvolution, layer id:10
I1030 05:31:13.476043  1046 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I1030 05:31:13.476052  1046 net.cpp:84] Creating Layer fire2/relu_expand3x3
I1030 05:31:13.476058  1046 net.cpp:413] fire2/relu_expand3x3 <- fire2/expand3x3
I1030 05:31:13.476071  1046 net.cpp:374] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I1030 05:31:13.476307  1046 net.cpp:127] Setting up fire2/relu_expand3x3
I1030 05:31:13.476325  1046 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1030 05:31:13.476333  1046 net.cpp:144] Memory required for data: 598649400
I1030 05:31:13.476338  1046 layer_factory.hpp:77] Creating layer fire2/concat
I1030 05:31:13.476348  1046 net.cpp:84] Creating Layer fire2/concat
I1030 05:31:13.476354  1046 net.cpp:413] fire2/concat <- fire2/expand1x1
I1030 05:31:13.476361  1046 net.cpp:413] fire2/concat <- fire2/expand3x3
I1030 05:31:13.476369  1046 net.cpp:387] fire2/concat -> fire2/concat
I1030 05:31:13.476403  1046 net.cpp:127] Setting up fire2/concat
I1030 05:31:13.476411  1046 net.cpp:136] Top shape: 50 128 56 56 (20070400)
I1030 05:31:13.476416  1046 net.cpp:144] Memory required for data: 678931000
I1030 05:31:13.476421  1046 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I1030 05:31:13.476433  1046 net.cpp:84] Creating Layer fire3/squeeze1x1
I1030 05:31:13.476439  1046 net.cpp:413] fire3/squeeze1x1 <- fire2/concat
I1030 05:31:13.476449  1046 net.cpp:387] fire3/squeeze1x1 -> fire3/squeeze1x1
I1030 05:31:13.476825  1046 net.cpp:127] Setting up fire3/squeeze1x1
I1030 05:31:13.476836  1046 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1030 05:31:13.476840  1046 net.cpp:144] Memory required for data: 688966200
I1030 05:31:13.476850  1046 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1030 05:31:13.476861  1046 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1030 05:31:13.476868  1046 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1030 05:31:13.476874  1046 net.cpp:453] Found INQ layer:fire3/squeeze1x1, type: INQConvolution, layer id:13
I1030 05:31:13.476879  1046 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I1030 05:31:13.476887  1046 net.cpp:84] Creating Layer fire3/relu_squeeze1x1
I1030 05:31:13.476892  1046 net.cpp:413] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I1030 05:31:13.476899  1046 net.cpp:374] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I1030 05:31:13.477109  1046 net.cpp:127] Setting up fire3/relu_squeeze1x1
I1030 05:31:13.477120  1046 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1030 05:31:13.477126  1046 net.cpp:144] Memory required for data: 699001400
I1030 05:31:13.477131  1046 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1030 05:31:13.477141  1046 net.cpp:84] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1030 05:31:13.477146  1046 net.cpp:413] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I1030 05:31:13.477154  1046 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1030 05:31:13.477164  1046 net.cpp:387] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1030 05:31:13.477213  1046 net.cpp:127] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I1030 05:31:13.477222  1046 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1030 05:31:13.477229  1046 net.cpp:136] Top shape: 50 16 56 56 (2508800)
I1030 05:31:13.477233  1046 net.cpp:144] Memory required for data: 719071800
I1030 05:31:13.477239  1046 layer_factory.hpp:77] Creating layer fire3/expand1x1
I1030 05:31:13.477253  1046 net.cpp:84] Creating Layer fire3/expand1x1
I1030 05:31:13.477259  1046 net.cpp:413] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I1030 05:31:13.477269  1046 net.cpp:387] fire3/expand1x1 -> fire3/expand1x1
I1030 05:31:13.477643  1046 net.cpp:127] Setting up fire3/expand1x1
I1030 05:31:13.477658  1046 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1030 05:31:13.477663  1046 net.cpp:144] Memory required for data: 759212600
I1030 05:31:13.477670  1046 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1030 05:31:13.477676  1046 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1030 05:31:13.477689  1046 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1030 05:31:13.477705  1046 net.cpp:453] Found INQ layer:fire3/expand1x1, type: INQConvolution, layer id:16
I1030 05:31:13.477710  1046 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I1030 05:31:13.477717  1046 net.cpp:84] Creating Layer fire3/relu_expand1x1
I1030 05:31:13.477723  1046 net.cpp:413] fire3/relu_expand1x1 <- fire3/expand1x1
I1030 05:31:13.477730  1046 net.cpp:374] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I1030 05:31:13.477948  1046 net.cpp:127] Setting up fire3/relu_expand1x1
I1030 05:31:13.477962  1046 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1030 05:31:13.477967  1046 net.cpp:144] Memory required for data: 799353400
I1030 05:31:13.477972  1046 layer_factory.hpp:77] Creating layer fire3/expand3x3
I1030 05:31:13.477982  1046 net.cpp:84] Creating Layer fire3/expand3x3
I1030 05:31:13.477988  1046 net.cpp:413] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I1030 05:31:13.477998  1046 net.cpp:387] fire3/expand3x3 -> fire3/expand3x3
I1030 05:31:13.478446  1046 net.cpp:127] Setting up fire3/expand3x3
I1030 05:31:13.478459  1046 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1030 05:31:13.478463  1046 net.cpp:144] Memory required for data: 839494200
I1030 05:31:13.478471  1046 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1030 05:31:13.478477  1046 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1030 05:31:13.478482  1046 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1030 05:31:13.478487  1046 net.cpp:453] Found INQ layer:fire3/expand3x3, type: INQConvolution, layer id:18
I1030 05:31:13.478492  1046 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I1030 05:31:13.478502  1046 net.cpp:84] Creating Layer fire3/relu_expand3x3
I1030 05:31:13.478507  1046 net.cpp:413] fire3/relu_expand3x3 <- fire3/expand3x3
I1030 05:31:13.478514  1046 net.cpp:374] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I1030 05:31:13.479945  1046 net.cpp:127] Setting up fire3/relu_expand3x3
I1030 05:31:13.479965  1046 net.cpp:136] Top shape: 50 64 56 56 (10035200)
I1030 05:31:13.479971  1046 net.cpp:144] Memory required for data: 879635000
I1030 05:31:13.479979  1046 layer_factory.hpp:77] Creating layer fire3/concat
I1030 05:31:13.479988  1046 net.cpp:84] Creating Layer fire3/concat
I1030 05:31:13.479995  1046 net.cpp:413] fire3/concat <- fire3/expand1x1
I1030 05:31:13.480002  1046 net.cpp:413] fire3/concat <- fire3/expand3x3
I1030 05:31:13.480011  1046 net.cpp:387] fire3/concat -> fire3/concat
I1030 05:31:13.480051  1046 net.cpp:127] Setting up fire3/concat
I1030 05:31:13.480058  1046 net.cpp:136] Top shape: 50 128 56 56 (20070400)
I1030 05:31:13.480063  1046 net.cpp:144] Memory required for data: 959916600
I1030 05:31:13.480067  1046 layer_factory.hpp:77] Creating layer pool3
I1030 05:31:13.480077  1046 net.cpp:84] Creating Layer pool3
I1030 05:31:13.480082  1046 net.cpp:413] pool3 <- fire3/concat
I1030 05:31:13.480090  1046 net.cpp:387] pool3 -> pool3
I1030 05:31:13.480139  1046 net.cpp:127] Setting up pool3
I1030 05:31:13.480157  1046 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1030 05:31:13.480161  1046 net.cpp:144] Memory required for data: 979987000
I1030 05:31:13.480166  1046 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I1030 05:31:13.480180  1046 net.cpp:84] Creating Layer fire4/squeeze1x1
I1030 05:31:13.480186  1046 net.cpp:413] fire4/squeeze1x1 <- pool3
I1030 05:31:13.480193  1046 net.cpp:387] fire4/squeeze1x1 -> fire4/squeeze1x1
I1030 05:31:13.480604  1046 net.cpp:127] Setting up fire4/squeeze1x1
I1030 05:31:13.480618  1046 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1030 05:31:13.480623  1046 net.cpp:144] Memory required for data: 985004600
I1030 05:31:13.480629  1046 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1030 05:31:13.480636  1046 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1030 05:31:13.480648  1046 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1030 05:31:13.480667  1046 net.cpp:453] Found INQ layer:fire4/squeeze1x1, type: INQConvolution, layer id:22
I1030 05:31:13.480672  1046 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I1030 05:31:13.480681  1046 net.cpp:84] Creating Layer fire4/relu_squeeze1x1
I1030 05:31:13.480686  1046 net.cpp:413] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I1030 05:31:13.480695  1046 net.cpp:374] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I1030 05:31:13.480911  1046 net.cpp:127] Setting up fire4/relu_squeeze1x1
I1030 05:31:13.480923  1046 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1030 05:31:13.480929  1046 net.cpp:144] Memory required for data: 990022200
I1030 05:31:13.480936  1046 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1030 05:31:13.480942  1046 net.cpp:84] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1030 05:31:13.480947  1046 net.cpp:413] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I1030 05:31:13.480957  1046 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1030 05:31:13.480967  1046 net.cpp:387] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1030 05:31:13.481019  1046 net.cpp:127] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I1030 05:31:13.481029  1046 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1030 05:31:13.481035  1046 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1030 05:31:13.481040  1046 net.cpp:144] Memory required for data: 1000057400
I1030 05:31:13.481045  1046 layer_factory.hpp:77] Creating layer fire4/expand1x1
I1030 05:31:13.481057  1046 net.cpp:84] Creating Layer fire4/expand1x1
I1030 05:31:13.481062  1046 net.cpp:413] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I1030 05:31:13.481072  1046 net.cpp:387] fire4/expand1x1 -> fire4/expand1x1
I1030 05:31:13.481454  1046 net.cpp:127] Setting up fire4/expand1x1
I1030 05:31:13.481474  1046 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1030 05:31:13.481479  1046 net.cpp:144] Memory required for data: 1020127800
I1030 05:31:13.481492  1046 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1030 05:31:13.481501  1046 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1030 05:31:13.481508  1046 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1030 05:31:13.481513  1046 net.cpp:453] Found INQ layer:fire4/expand1x1, type: INQConvolution, layer id:25
I1030 05:31:13.481518  1046 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I1030 05:31:13.481528  1046 net.cpp:84] Creating Layer fire4/relu_expand1x1
I1030 05:31:13.481534  1046 net.cpp:413] fire4/relu_expand1x1 <- fire4/expand1x1
I1030 05:31:13.481540  1046 net.cpp:374] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I1030 05:31:13.481760  1046 net.cpp:127] Setting up fire4/relu_expand1x1
I1030 05:31:13.481772  1046 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1030 05:31:13.481778  1046 net.cpp:144] Memory required for data: 1040198200
I1030 05:31:13.481784  1046 layer_factory.hpp:77] Creating layer fire4/expand3x3
I1030 05:31:13.481797  1046 net.cpp:84] Creating Layer fire4/expand3x3
I1030 05:31:13.481803  1046 net.cpp:413] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I1030 05:31:13.481813  1046 net.cpp:387] fire4/expand3x3 -> fire4/expand3x3
I1030 05:31:13.482489  1046 net.cpp:127] Setting up fire4/expand3x3
I1030 05:31:13.482501  1046 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1030 05:31:13.482506  1046 net.cpp:144] Memory required for data: 1060268600
I1030 05:31:13.482513  1046 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1030 05:31:13.482519  1046 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1030 05:31:13.482530  1046 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1030 05:31:13.482547  1046 net.cpp:453] Found INQ layer:fire4/expand3x3, type: INQConvolution, layer id:27
I1030 05:31:13.482553  1046 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I1030 05:31:13.482561  1046 net.cpp:84] Creating Layer fire4/relu_expand3x3
I1030 05:31:13.482566  1046 net.cpp:413] fire4/relu_expand3x3 <- fire4/expand3x3
I1030 05:31:13.482575  1046 net.cpp:374] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I1030 05:31:13.482790  1046 net.cpp:127] Setting up fire4/relu_expand3x3
I1030 05:31:13.482802  1046 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1030 05:31:13.482807  1046 net.cpp:144] Memory required for data: 1080339000
I1030 05:31:13.482812  1046 layer_factory.hpp:77] Creating layer fire4/concat
I1030 05:31:13.482821  1046 net.cpp:84] Creating Layer fire4/concat
I1030 05:31:13.482827  1046 net.cpp:413] fire4/concat <- fire4/expand1x1
I1030 05:31:13.482833  1046 net.cpp:413] fire4/concat <- fire4/expand3x3
I1030 05:31:13.482839  1046 net.cpp:387] fire4/concat -> fire4/concat
I1030 05:31:13.482875  1046 net.cpp:127] Setting up fire4/concat
I1030 05:31:13.482884  1046 net.cpp:136] Top shape: 50 256 28 28 (10035200)
I1030 05:31:13.482889  1046 net.cpp:144] Memory required for data: 1120479800
I1030 05:31:13.482894  1046 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I1030 05:31:13.482906  1046 net.cpp:84] Creating Layer fire5/squeeze1x1
I1030 05:31:13.482913  1046 net.cpp:413] fire5/squeeze1x1 <- fire4/concat
I1030 05:31:13.482921  1046 net.cpp:387] fire5/squeeze1x1 -> fire5/squeeze1x1
I1030 05:31:13.483356  1046 net.cpp:127] Setting up fire5/squeeze1x1
I1030 05:31:13.483368  1046 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1030 05:31:13.483373  1046 net.cpp:144] Memory required for data: 1125497400
I1030 05:31:13.483379  1046 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1030 05:31:13.483386  1046 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1030 05:31:13.483392  1046 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1030 05:31:13.483397  1046 net.cpp:453] Found INQ layer:fire5/squeeze1x1, type: INQConvolution, layer id:30
I1030 05:31:13.483404  1046 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I1030 05:31:13.483412  1046 net.cpp:84] Creating Layer fire5/relu_squeeze1x1
I1030 05:31:13.483418  1046 net.cpp:413] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I1030 05:31:13.483424  1046 net.cpp:374] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I1030 05:31:13.484840  1046 net.cpp:127] Setting up fire5/relu_squeeze1x1
I1030 05:31:13.484859  1046 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1030 05:31:13.484865  1046 net.cpp:144] Memory required for data: 1130515000
I1030 05:31:13.484870  1046 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1030 05:31:13.484884  1046 net.cpp:84] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1030 05:31:13.484892  1046 net.cpp:413] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I1030 05:31:13.484901  1046 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1030 05:31:13.484910  1046 net.cpp:387] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1030 05:31:13.484967  1046 net.cpp:127] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I1030 05:31:13.484975  1046 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1030 05:31:13.484982  1046 net.cpp:136] Top shape: 50 32 28 28 (1254400)
I1030 05:31:13.484987  1046 net.cpp:144] Memory required for data: 1140550200
I1030 05:31:13.484990  1046 layer_factory.hpp:77] Creating layer fire5/expand1x1
I1030 05:31:13.485003  1046 net.cpp:84] Creating Layer fire5/expand1x1
I1030 05:31:13.485009  1046 net.cpp:413] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I1030 05:31:13.485016  1046 net.cpp:387] fire5/expand1x1 -> fire5/expand1x1
I1030 05:31:13.485424  1046 net.cpp:127] Setting up fire5/expand1x1
I1030 05:31:13.485450  1046 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1030 05:31:13.485456  1046 net.cpp:144] Memory required for data: 1160620600
I1030 05:31:13.485463  1046 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1030 05:31:13.485471  1046 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1030 05:31:13.485476  1046 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1030 05:31:13.485481  1046 net.cpp:453] Found INQ layer:fire5/expand1x1, type: INQConvolution, layer id:33
I1030 05:31:13.485486  1046 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I1030 05:31:13.485497  1046 net.cpp:84] Creating Layer fire5/relu_expand1x1
I1030 05:31:13.485503  1046 net.cpp:413] fire5/relu_expand1x1 <- fire5/expand1x1
I1030 05:31:13.485512  1046 net.cpp:374] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I1030 05:31:13.485733  1046 net.cpp:127] Setting up fire5/relu_expand1x1
I1030 05:31:13.485746  1046 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1030 05:31:13.485752  1046 net.cpp:144] Memory required for data: 1180691000
I1030 05:31:13.485759  1046 layer_factory.hpp:77] Creating layer fire5/expand3x3
I1030 05:31:13.485769  1046 net.cpp:84] Creating Layer fire5/expand3x3
I1030 05:31:13.485775  1046 net.cpp:413] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I1030 05:31:13.485785  1046 net.cpp:387] fire5/expand3x3 -> fire5/expand3x3
I1030 05:31:13.486457  1046 net.cpp:127] Setting up fire5/expand3x3
I1030 05:31:13.486470  1046 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1030 05:31:13.486475  1046 net.cpp:144] Memory required for data: 1200761400
I1030 05:31:13.486482  1046 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1030 05:31:13.486488  1046 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1030 05:31:13.486495  1046 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1030 05:31:13.486500  1046 net.cpp:453] Found INQ layer:fire5/expand3x3, type: INQConvolution, layer id:35
I1030 05:31:13.486505  1046 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I1030 05:31:13.486512  1046 net.cpp:84] Creating Layer fire5/relu_expand3x3
I1030 05:31:13.486518  1046 net.cpp:413] fire5/relu_expand3x3 <- fire5/expand3x3
I1030 05:31:13.486527  1046 net.cpp:374] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I1030 05:31:13.486740  1046 net.cpp:127] Setting up fire5/relu_expand3x3
I1030 05:31:13.486752  1046 net.cpp:136] Top shape: 50 128 28 28 (5017600)
I1030 05:31:13.486757  1046 net.cpp:144] Memory required for data: 1220831800
I1030 05:31:13.486763  1046 layer_factory.hpp:77] Creating layer fire5/concat
I1030 05:31:13.486771  1046 net.cpp:84] Creating Layer fire5/concat
I1030 05:31:13.486776  1046 net.cpp:413] fire5/concat <- fire5/expand1x1
I1030 05:31:13.486783  1046 net.cpp:413] fire5/concat <- fire5/expand3x3
I1030 05:31:13.486791  1046 net.cpp:387] fire5/concat -> fire5/concat
I1030 05:31:13.486825  1046 net.cpp:127] Setting up fire5/concat
I1030 05:31:13.486834  1046 net.cpp:136] Top shape: 50 256 28 28 (10035200)
I1030 05:31:13.486837  1046 net.cpp:144] Memory required for data: 1260972600
I1030 05:31:13.486843  1046 layer_factory.hpp:77] Creating layer pool5
I1030 05:31:13.486850  1046 net.cpp:84] Creating Layer pool5
I1030 05:31:13.486855  1046 net.cpp:413] pool5 <- fire5/concat
I1030 05:31:13.486863  1046 net.cpp:387] pool5 -> pool5
I1030 05:31:13.486913  1046 net.cpp:127] Setting up pool5
I1030 05:31:13.486925  1046 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1030 05:31:13.486930  1046 net.cpp:144] Memory required for data: 1271007800
I1030 05:31:13.486934  1046 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I1030 05:31:13.486945  1046 net.cpp:84] Creating Layer fire6/squeeze1x1
I1030 05:31:13.486950  1046 net.cpp:413] fire6/squeeze1x1 <- pool5
I1030 05:31:13.486963  1046 net.cpp:387] fire6/squeeze1x1 -> fire6/squeeze1x1
I1030 05:31:13.487445  1046 net.cpp:127] Setting up fire6/squeeze1x1
I1030 05:31:13.487469  1046 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1030 05:31:13.487474  1046 net.cpp:144] Memory required for data: 1272889400
I1030 05:31:13.487480  1046 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1030 05:31:13.487488  1046 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1030 05:31:13.487493  1046 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1030 05:31:13.487498  1046 net.cpp:453] Found INQ layer:fire6/squeeze1x1, type: INQConvolution, layer id:39
I1030 05:31:13.487504  1046 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I1030 05:31:13.487514  1046 net.cpp:84] Creating Layer fire6/relu_squeeze1x1
I1030 05:31:13.487520  1046 net.cpp:413] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I1030 05:31:13.487527  1046 net.cpp:374] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I1030 05:31:13.487740  1046 net.cpp:127] Setting up fire6/relu_squeeze1x1
I1030 05:31:13.487751  1046 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1030 05:31:13.487756  1046 net.cpp:144] Memory required for data: 1274771000
I1030 05:31:13.487761  1046 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1030 05:31:13.487772  1046 net.cpp:84] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1030 05:31:13.487777  1046 net.cpp:413] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I1030 05:31:13.487784  1046 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1030 05:31:13.487794  1046 net.cpp:387] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1030 05:31:13.487869  1046 net.cpp:127] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I1030 05:31:13.487879  1046 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1030 05:31:13.487886  1046 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1030 05:31:13.487890  1046 net.cpp:144] Memory required for data: 1278534200
I1030 05:31:13.487896  1046 layer_factory.hpp:77] Creating layer fire6/expand1x1
I1030 05:31:13.487907  1046 net.cpp:84] Creating Layer fire6/expand1x1
I1030 05:31:13.487913  1046 net.cpp:413] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I1030 05:31:13.487922  1046 net.cpp:387] fire6/expand1x1 -> fire6/expand1x1
I1030 05:31:13.488354  1046 net.cpp:127] Setting up fire6/expand1x1
I1030 05:31:13.488366  1046 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1030 05:31:13.488370  1046 net.cpp:144] Memory required for data: 1286060600
I1030 05:31:13.488378  1046 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1030 05:31:13.488384  1046 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1030 05:31:13.488389  1046 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1030 05:31:13.488395  1046 net.cpp:453] Found INQ layer:fire6/expand1x1, type: INQConvolution, layer id:42
I1030 05:31:13.488399  1046 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I1030 05:31:13.488407  1046 net.cpp:84] Creating Layer fire6/relu_expand1x1
I1030 05:31:13.488414  1046 net.cpp:413] fire6/relu_expand1x1 <- fire6/expand1x1
I1030 05:31:13.488421  1046 net.cpp:374] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I1030 05:31:13.489830  1046 net.cpp:127] Setting up fire6/relu_expand1x1
I1030 05:31:13.489850  1046 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1030 05:31:13.489856  1046 net.cpp:144] Memory required for data: 1293587000
I1030 05:31:13.489861  1046 layer_factory.hpp:77] Creating layer fire6/expand3x3
I1030 05:31:13.489873  1046 net.cpp:84] Creating Layer fire6/expand3x3
I1030 05:31:13.489881  1046 net.cpp:413] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I1030 05:31:13.489892  1046 net.cpp:387] fire6/expand3x3 -> fire6/expand3x3
I1030 05:31:13.490975  1046 net.cpp:127] Setting up fire6/expand3x3
I1030 05:31:13.490989  1046 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1030 05:31:13.491009  1046 net.cpp:144] Memory required for data: 1301113400
I1030 05:31:13.491017  1046 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1030 05:31:13.491024  1046 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1030 05:31:13.491030  1046 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1030 05:31:13.491036  1046 net.cpp:453] Found INQ layer:fire6/expand3x3, type: INQConvolution, layer id:44
I1030 05:31:13.491042  1046 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I1030 05:31:13.491051  1046 net.cpp:84] Creating Layer fire6/relu_expand3x3
I1030 05:31:13.491056  1046 net.cpp:413] fire6/relu_expand3x3 <- fire6/expand3x3
I1030 05:31:13.491063  1046 net.cpp:374] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I1030 05:31:13.491282  1046 net.cpp:127] Setting up fire6/relu_expand3x3
I1030 05:31:13.491295  1046 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1030 05:31:13.491307  1046 net.cpp:144] Memory required for data: 1308639800
I1030 05:31:13.491314  1046 layer_factory.hpp:77] Creating layer fire6/concat
I1030 05:31:13.491322  1046 net.cpp:84] Creating Layer fire6/concat
I1030 05:31:13.491328  1046 net.cpp:413] fire6/concat <- fire6/expand1x1
I1030 05:31:13.491333  1046 net.cpp:413] fire6/concat <- fire6/expand3x3
I1030 05:31:13.491340  1046 net.cpp:387] fire6/concat -> fire6/concat
I1030 05:31:13.491377  1046 net.cpp:127] Setting up fire6/concat
I1030 05:31:13.491386  1046 net.cpp:136] Top shape: 50 384 14 14 (3763200)
I1030 05:31:13.491390  1046 net.cpp:144] Memory required for data: 1323692600
I1030 05:31:13.491394  1046 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I1030 05:31:13.491406  1046 net.cpp:84] Creating Layer fire7/squeeze1x1
I1030 05:31:13.491412  1046 net.cpp:413] fire7/squeeze1x1 <- fire6/concat
I1030 05:31:13.491421  1046 net.cpp:387] fire7/squeeze1x1 -> fire7/squeeze1x1
I1030 05:31:13.491940  1046 net.cpp:127] Setting up fire7/squeeze1x1
I1030 05:31:13.491950  1046 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1030 05:31:13.491955  1046 net.cpp:144] Memory required for data: 1325574200
I1030 05:31:13.491969  1046 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1030 05:31:13.491984  1046 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1030 05:31:13.491991  1046 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1030 05:31:13.491997  1046 net.cpp:453] Found INQ layer:fire7/squeeze1x1, type: INQConvolution, layer id:47
I1030 05:31:13.492002  1046 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I1030 05:31:13.492009  1046 net.cpp:84] Creating Layer fire7/relu_squeeze1x1
I1030 05:31:13.492014  1046 net.cpp:413] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I1030 05:31:13.492022  1046 net.cpp:374] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I1030 05:31:13.492238  1046 net.cpp:127] Setting up fire7/relu_squeeze1x1
I1030 05:31:13.492250  1046 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1030 05:31:13.492255  1046 net.cpp:144] Memory required for data: 1327455800
I1030 05:31:13.492261  1046 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1030 05:31:13.492270  1046 net.cpp:84] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1030 05:31:13.492276  1046 net.cpp:413] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I1030 05:31:13.492282  1046 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1030 05:31:13.492291  1046 net.cpp:387] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1030 05:31:13.492348  1046 net.cpp:127] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I1030 05:31:13.492360  1046 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1030 05:31:13.492372  1046 net.cpp:136] Top shape: 50 48 14 14 (470400)
I1030 05:31:13.492388  1046 net.cpp:144] Memory required for data: 1331219000
I1030 05:31:13.492393  1046 layer_factory.hpp:77] Creating layer fire7/expand1x1
I1030 05:31:13.492403  1046 net.cpp:84] Creating Layer fire7/expand1x1
I1030 05:31:13.492408  1046 net.cpp:413] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I1030 05:31:13.492419  1046 net.cpp:387] fire7/expand1x1 -> fire7/expand1x1
I1030 05:31:13.492846  1046 net.cpp:127] Setting up fire7/expand1x1
I1030 05:31:13.492859  1046 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1030 05:31:13.492864  1046 net.cpp:144] Memory required for data: 1338745400
I1030 05:31:13.492871  1046 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1030 05:31:13.492878  1046 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1030 05:31:13.492883  1046 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1030 05:31:13.492889  1046 net.cpp:453] Found INQ layer:fire7/expand1x1, type: INQConvolution, layer id:50
I1030 05:31:13.492893  1046 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I1030 05:31:13.492900  1046 net.cpp:84] Creating Layer fire7/relu_expand1x1
I1030 05:31:13.492905  1046 net.cpp:413] fire7/relu_expand1x1 <- fire7/expand1x1
I1030 05:31:13.492913  1046 net.cpp:374] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I1030 05:31:13.494326  1046 net.cpp:127] Setting up fire7/relu_expand1x1
I1030 05:31:13.494346  1046 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1030 05:31:13.494352  1046 net.cpp:144] Memory required for data: 1346271800
I1030 05:31:13.494360  1046 layer_factory.hpp:77] Creating layer fire7/expand3x3
I1030 05:31:13.494374  1046 net.cpp:84] Creating Layer fire7/expand3x3
I1030 05:31:13.494380  1046 net.cpp:413] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I1030 05:31:13.494390  1046 net.cpp:387] fire7/expand3x3 -> fire7/expand3x3
I1030 05:31:13.495476  1046 net.cpp:127] Setting up fire7/expand3x3
I1030 05:31:13.495491  1046 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1030 05:31:13.495496  1046 net.cpp:144] Memory required for data: 1353798200
I1030 05:31:13.495502  1046 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1030 05:31:13.495509  1046 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1030 05:31:13.495517  1046 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1030 05:31:13.495522  1046 net.cpp:453] Found INQ layer:fire7/expand3x3, type: INQConvolution, layer id:52
I1030 05:31:13.495525  1046 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I1030 05:31:13.495533  1046 net.cpp:84] Creating Layer fire7/relu_expand3x3
I1030 05:31:13.495538  1046 net.cpp:413] fire7/relu_expand3x3 <- fire7/expand3x3
I1030 05:31:13.495549  1046 net.cpp:374] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I1030 05:31:13.495766  1046 net.cpp:127] Setting up fire7/relu_expand3x3
I1030 05:31:13.495779  1046 net.cpp:136] Top shape: 50 192 14 14 (1881600)
I1030 05:31:13.495784  1046 net.cpp:144] Memory required for data: 1361324600
I1030 05:31:13.495788  1046 layer_factory.hpp:77] Creating layer fire7/concat
I1030 05:31:13.495798  1046 net.cpp:84] Creating Layer fire7/concat
I1030 05:31:13.495805  1046 net.cpp:413] fire7/concat <- fire7/expand1x1
I1030 05:31:13.495810  1046 net.cpp:413] fire7/concat <- fire7/expand3x3
I1030 05:31:13.495816  1046 net.cpp:387] fire7/concat -> fire7/concat
I1030 05:31:13.495851  1046 net.cpp:127] Setting up fire7/concat
I1030 05:31:13.495862  1046 net.cpp:136] Top shape: 50 384 14 14 (3763200)
I1030 05:31:13.495867  1046 net.cpp:144] Memory required for data: 1376377400
I1030 05:31:13.495872  1046 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I1030 05:31:13.495882  1046 net.cpp:84] Creating Layer fire8/squeeze1x1
I1030 05:31:13.495888  1046 net.cpp:413] fire8/squeeze1x1 <- fire7/concat
I1030 05:31:13.495898  1046 net.cpp:387] fire8/squeeze1x1 -> fire8/squeeze1x1
I1030 05:31:13.497915  1046 net.cpp:127] Setting up fire8/squeeze1x1
I1030 05:31:13.497946  1046 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1030 05:31:13.497952  1046 net.cpp:144] Memory required for data: 1378886200
I1030 05:31:13.497961  1046 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1030 05:31:13.497967  1046 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1030 05:31:13.497974  1046 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1030 05:31:13.497979  1046 net.cpp:453] Found INQ layer:fire8/squeeze1x1, type: INQConvolution, layer id:55
I1030 05:31:13.497984  1046 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I1030 05:31:13.497994  1046 net.cpp:84] Creating Layer fire8/relu_squeeze1x1
I1030 05:31:13.497999  1046 net.cpp:413] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I1030 05:31:13.498009  1046 net.cpp:374] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I1030 05:31:13.498241  1046 net.cpp:127] Setting up fire8/relu_squeeze1x1
I1030 05:31:13.498255  1046 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1030 05:31:13.498260  1046 net.cpp:144] Memory required for data: 1381395000
I1030 05:31:13.498265  1046 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1030 05:31:13.498273  1046 net.cpp:84] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1030 05:31:13.498278  1046 net.cpp:413] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I1030 05:31:13.498287  1046 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1030 05:31:13.498302  1046 net.cpp:387] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1030 05:31:13.498358  1046 net.cpp:127] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I1030 05:31:13.498370  1046 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1030 05:31:13.498376  1046 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1030 05:31:13.498381  1046 net.cpp:144] Memory required for data: 1386412600
I1030 05:31:13.498386  1046 layer_factory.hpp:77] Creating layer fire8/expand1x1
I1030 05:31:13.498396  1046 net.cpp:84] Creating Layer fire8/expand1x1
I1030 05:31:13.498402  1046 net.cpp:413] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I1030 05:31:13.498412  1046 net.cpp:387] fire8/expand1x1 -> fire8/expand1x1
I1030 05:31:13.498904  1046 net.cpp:127] Setting up fire8/expand1x1
I1030 05:31:13.498915  1046 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1030 05:31:13.498920  1046 net.cpp:144] Memory required for data: 1396447800
I1030 05:31:13.498927  1046 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1030 05:31:13.498934  1046 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1030 05:31:13.498939  1046 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1030 05:31:13.498945  1046 net.cpp:453] Found INQ layer:fire8/expand1x1, type: INQConvolution, layer id:58
I1030 05:31:13.498950  1046 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I1030 05:31:13.498957  1046 net.cpp:84] Creating Layer fire8/relu_expand1x1
I1030 05:31:13.498963  1046 net.cpp:413] fire8/relu_expand1x1 <- fire8/expand1x1
I1030 05:31:13.498971  1046 net.cpp:374] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I1030 05:31:13.499192  1046 net.cpp:127] Setting up fire8/relu_expand1x1
I1030 05:31:13.499204  1046 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1030 05:31:13.499209  1046 net.cpp:144] Memory required for data: 1406483000
I1030 05:31:13.499214  1046 layer_factory.hpp:77] Creating layer fire8/expand3x3
I1030 05:31:13.499228  1046 net.cpp:84] Creating Layer fire8/expand3x3
I1030 05:31:13.499233  1046 net.cpp:413] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I1030 05:31:13.499243  1046 net.cpp:387] fire8/expand3x3 -> fire8/expand3x3
I1030 05:31:13.502176  1046 net.cpp:127] Setting up fire8/expand3x3
I1030 05:31:13.502199  1046 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1030 05:31:13.502221  1046 net.cpp:144] Memory required for data: 1416518200
I1030 05:31:13.502230  1046 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1030 05:31:13.502238  1046 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1030 05:31:13.502243  1046 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1030 05:31:13.502249  1046 net.cpp:453] Found INQ layer:fire8/expand3x3, type: INQConvolution, layer id:60
I1030 05:31:13.502254  1046 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I1030 05:31:13.502264  1046 net.cpp:84] Creating Layer fire8/relu_expand3x3
I1030 05:31:13.502270  1046 net.cpp:413] fire8/relu_expand3x3 <- fire8/expand3x3
I1030 05:31:13.502277  1046 net.cpp:374] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I1030 05:31:13.503706  1046 net.cpp:127] Setting up fire8/relu_expand3x3
I1030 05:31:13.503726  1046 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1030 05:31:13.503733  1046 net.cpp:144] Memory required for data: 1426553400
I1030 05:31:13.503739  1046 layer_factory.hpp:77] Creating layer fire8/concat
I1030 05:31:13.503749  1046 net.cpp:84] Creating Layer fire8/concat
I1030 05:31:13.503756  1046 net.cpp:413] fire8/concat <- fire8/expand1x1
I1030 05:31:13.503762  1046 net.cpp:413] fire8/concat <- fire8/expand3x3
I1030 05:31:13.503769  1046 net.cpp:387] fire8/concat -> fire8/concat
I1030 05:31:13.503810  1046 net.cpp:127] Setting up fire8/concat
I1030 05:31:13.503820  1046 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1030 05:31:13.503825  1046 net.cpp:144] Memory required for data: 1446623800
I1030 05:31:13.503830  1046 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I1030 05:31:13.503844  1046 net.cpp:84] Creating Layer fire9/squeeze1x1
I1030 05:31:13.503849  1046 net.cpp:413] fire9/squeeze1x1 <- fire8/concat
I1030 05:31:13.503859  1046 net.cpp:387] fire9/squeeze1x1 -> fire9/squeeze1x1
I1030 05:31:13.504495  1046 net.cpp:127] Setting up fire9/squeeze1x1
I1030 05:31:13.504508  1046 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1030 05:31:13.504513  1046 net.cpp:144] Memory required for data: 1449132600
I1030 05:31:13.504520  1046 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1030 05:31:13.504528  1046 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1030 05:31:13.504534  1046 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1030 05:31:13.504539  1046 net.cpp:453] Found INQ layer:fire9/squeeze1x1, type: INQConvolution, layer id:63
I1030 05:31:13.504544  1046 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I1030 05:31:13.504559  1046 net.cpp:84] Creating Layer fire9/relu_squeeze1x1
I1030 05:31:13.504565  1046 net.cpp:413] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I1030 05:31:13.504571  1046 net.cpp:374] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I1030 05:31:13.504789  1046 net.cpp:127] Setting up fire9/relu_squeeze1x1
I1030 05:31:13.504801  1046 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1030 05:31:13.504806  1046 net.cpp:144] Memory required for data: 1451641400
I1030 05:31:13.504812  1046 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1030 05:31:13.504822  1046 net.cpp:84] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1030 05:31:13.504827  1046 net.cpp:413] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I1030 05:31:13.504833  1046 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1030 05:31:13.504842  1046 net.cpp:387] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1030 05:31:13.504895  1046 net.cpp:127] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I1030 05:31:13.504905  1046 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1030 05:31:13.504912  1046 net.cpp:136] Top shape: 50 64 14 14 (627200)
I1030 05:31:13.504923  1046 net.cpp:144] Memory required for data: 1456659000
I1030 05:31:13.504940  1046 layer_factory.hpp:77] Creating layer fire9/expand1x1
I1030 05:31:13.504951  1046 net.cpp:84] Creating Layer fire9/expand1x1
I1030 05:31:13.504956  1046 net.cpp:413] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I1030 05:31:13.504966  1046 net.cpp:387] fire9/expand1x1 -> fire9/expand1x1
I1030 05:31:13.505461  1046 net.cpp:127] Setting up fire9/expand1x1
I1030 05:31:13.505475  1046 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1030 05:31:13.505479  1046 net.cpp:144] Memory required for data: 1466694200
I1030 05:31:13.505486  1046 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1030 05:31:13.505492  1046 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1030 05:31:13.505499  1046 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1030 05:31:13.505504  1046 net.cpp:453] Found INQ layer:fire9/expand1x1, type: INQConvolution, layer id:66
I1030 05:31:13.505508  1046 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I1030 05:31:13.505517  1046 net.cpp:84] Creating Layer fire9/relu_expand1x1
I1030 05:31:13.505522  1046 net.cpp:413] fire9/relu_expand1x1 <- fire9/expand1x1
I1030 05:31:13.505530  1046 net.cpp:374] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I1030 05:31:13.505753  1046 net.cpp:127] Setting up fire9/relu_expand1x1
I1030 05:31:13.505765  1046 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1030 05:31:13.505770  1046 net.cpp:144] Memory required for data: 1476729400
I1030 05:31:13.505775  1046 layer_factory.hpp:77] Creating layer fire9/expand3x3
I1030 05:31:13.505787  1046 net.cpp:84] Creating Layer fire9/expand3x3
I1030 05:31:13.505792  1046 net.cpp:413] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I1030 05:31:13.505802  1046 net.cpp:387] fire9/expand3x3 -> fire9/expand3x3
I1030 05:31:13.508749  1046 net.cpp:127] Setting up fire9/expand3x3
I1030 05:31:13.508770  1046 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1030 05:31:13.508776  1046 net.cpp:144] Memory required for data: 1486764600
I1030 05:31:13.508783  1046 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1030 05:31:13.508791  1046 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1030 05:31:13.508798  1046 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1030 05:31:13.508803  1046 net.cpp:453] Found INQ layer:fire9/expand3x3, type: INQConvolution, layer id:68
I1030 05:31:13.508808  1046 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I1030 05:31:13.508816  1046 net.cpp:84] Creating Layer fire9/relu_expand3x3
I1030 05:31:13.508822  1046 net.cpp:413] fire9/relu_expand3x3 <- fire9/expand3x3
I1030 05:31:13.508831  1046 net.cpp:374] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I1030 05:31:13.509061  1046 net.cpp:127] Setting up fire9/relu_expand3x3
I1030 05:31:13.509075  1046 net.cpp:136] Top shape: 50 256 14 14 (2508800)
I1030 05:31:13.509080  1046 net.cpp:144] Memory required for data: 1496799800
I1030 05:31:13.509085  1046 layer_factory.hpp:77] Creating layer fire9/concat
I1030 05:31:13.509093  1046 net.cpp:84] Creating Layer fire9/concat
I1030 05:31:13.509099  1046 net.cpp:413] fire9/concat <- fire9/expand1x1
I1030 05:31:13.509104  1046 net.cpp:413] fire9/concat <- fire9/expand3x3
I1030 05:31:13.509114  1046 net.cpp:387] fire9/concat -> fire9/concat
I1030 05:31:13.509160  1046 net.cpp:127] Setting up fire9/concat
I1030 05:31:13.509169  1046 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1030 05:31:13.509174  1046 net.cpp:144] Memory required for data: 1516870200
I1030 05:31:13.509179  1046 layer_factory.hpp:77] Creating layer drop9
I1030 05:31:13.509192  1046 net.cpp:84] Creating Layer drop9
I1030 05:31:13.509197  1046 net.cpp:413] drop9 <- fire9/concat
I1030 05:31:13.509203  1046 net.cpp:374] drop9 -> fire9/concat (in-place)
I1030 05:31:13.509243  1046 net.cpp:127] Setting up drop9
I1030 05:31:13.509253  1046 net.cpp:136] Top shape: 50 512 14 14 (5017600)
I1030 05:31:13.509270  1046 net.cpp:144] Memory required for data: 1536940600
I1030 05:31:13.509275  1046 layer_factory.hpp:77] Creating layer conv10
I1030 05:31:13.509286  1046 net.cpp:84] Creating Layer conv10
I1030 05:31:13.509292  1046 net.cpp:413] conv10 <- fire9/concat
I1030 05:31:13.509310  1046 net.cpp:387] conv10 -> conv10
I1030 05:31:13.519031  1046 net.cpp:127] Setting up conv10
I1030 05:31:13.519057  1046 net.cpp:136] Top shape: 50 1000 14 14 (9800000)
I1030 05:31:13.519062  1046 net.cpp:144] Memory required for data: 1576140600
I1030 05:31:13.519071  1046 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1030 05:31:13.519078  1046 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1030 05:31:13.519084  1046 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1030 05:31:13.519089  1046 net.cpp:453] Found INQ layer:conv10, type: INQConvolution, layer id:72
I1030 05:31:13.519093  1046 layer_factory.hpp:77] Creating layer relu_conv10
I1030 05:31:13.519103  1046 net.cpp:84] Creating Layer relu_conv10
I1030 05:31:13.519109  1046 net.cpp:413] relu_conv10 <- conv10
I1030 05:31:13.519117  1046 net.cpp:374] relu_conv10 -> conv10 (in-place)
I1030 05:31:13.520611  1046 net.cpp:127] Setting up relu_conv10
I1030 05:31:13.520630  1046 net.cpp:136] Top shape: 50 1000 14 14 (9800000)
I1030 05:31:13.520637  1046 net.cpp:144] Memory required for data: 1615340600
I1030 05:31:13.520642  1046 layer_factory.hpp:77] Creating layer pool10
I1030 05:31:13.520653  1046 net.cpp:84] Creating Layer pool10
I1030 05:31:13.520660  1046 net.cpp:413] pool10 <- conv10
I1030 05:31:13.520668  1046 net.cpp:387] pool10 -> pool10
I1030 05:31:13.520917  1046 net.cpp:127] Setting up pool10
I1030 05:31:13.520931  1046 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1030 05:31:13.520936  1046 net.cpp:144] Memory required for data: 1615540600
I1030 05:31:13.520941  1046 layer_factory.hpp:77] Creating layer pool10_pool10_0_split
I1030 05:31:13.520951  1046 net.cpp:84] Creating Layer pool10_pool10_0_split
I1030 05:31:13.520956  1046 net.cpp:413] pool10_pool10_0_split <- pool10
I1030 05:31:13.520963  1046 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_0
I1030 05:31:13.520973  1046 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_1
I1030 05:31:13.520982  1046 net.cpp:387] pool10_pool10_0_split -> pool10_pool10_0_split_2
I1030 05:31:13.521047  1046 net.cpp:127] Setting up pool10_pool10_0_split
I1030 05:31:13.521056  1046 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1030 05:31:13.521064  1046 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1030 05:31:13.521070  1046 net.cpp:136] Top shape: 50 1000 1 1 (50000)
I1030 05:31:13.521073  1046 net.cpp:144] Memory required for data: 1616140600
I1030 05:31:13.521078  1046 layer_factory.hpp:77] Creating layer loss
I1030 05:31:13.521086  1046 net.cpp:84] Creating Layer loss
I1030 05:31:13.521092  1046 net.cpp:413] loss <- pool10_pool10_0_split_0
I1030 05:31:13.521098  1046 net.cpp:413] loss <- label_data_1_split_0
I1030 05:31:13.521106  1046 net.cpp:387] loss -> loss
I1030 05:31:13.521116  1046 layer_factory.hpp:77] Creating layer loss
I1030 05:31:13.521503  1046 net.cpp:127] Setting up loss
I1030 05:31:13.521518  1046 net.cpp:136] Top shape: (1)
I1030 05:31:13.521522  1046 net.cpp:139]     with loss weight 1
I1030 05:31:13.521535  1046 net.cpp:144] Memory required for data: 1616140604
I1030 05:31:13.521541  1046 layer_factory.hpp:77] Creating layer accuracy_top1
I1030 05:31:13.521555  1046 net.cpp:84] Creating Layer accuracy_top1
I1030 05:31:13.521562  1046 net.cpp:413] accuracy_top1 <- pool10_pool10_0_split_1
I1030 05:31:13.521569  1046 net.cpp:413] accuracy_top1 <- label_data_1_split_1
I1030 05:31:13.521579  1046 net.cpp:387] accuracy_top1 -> accuracy_top1
I1030 05:31:13.521591  1046 net.cpp:127] Setting up accuracy_top1
I1030 05:31:13.521598  1046 net.cpp:136] Top shape: (1)
I1030 05:31:13.521602  1046 net.cpp:144] Memory required for data: 1616140608
I1030 05:31:13.521613  1046 layer_factory.hpp:77] Creating layer accuracy_top5
I1030 05:31:13.521638  1046 net.cpp:84] Creating Layer accuracy_top5
I1030 05:31:13.521644  1046 net.cpp:413] accuracy_top5 <- pool10_pool10_0_split_2
I1030 05:31:13.521651  1046 net.cpp:413] accuracy_top5 <- label_data_1_split_2
I1030 05:31:13.521659  1046 net.cpp:387] accuracy_top5 -> accuracy_top5
I1030 05:31:13.521679  1046 net.cpp:127] Setting up accuracy_top5
I1030 05:31:13.521687  1046 net.cpp:136] Top shape: (1)
I1030 05:31:13.521692  1046 net.cpp:144] Memory required for data: 1616140612
I1030 05:31:13.521697  1046 net.cpp:207] accuracy_top5 does not need backward computation.
I1030 05:31:13.521701  1046 net.cpp:207] accuracy_top1 does not need backward computation.
I1030 05:31:13.521708  1046 net.cpp:205] loss needs backward computation.
I1030 05:31:13.521713  1046 net.cpp:205] pool10_pool10_0_split needs backward computation.
I1030 05:31:13.521718  1046 net.cpp:205] pool10 needs backward computation.
I1030 05:31:13.521723  1046 net.cpp:205] relu_conv10 needs backward computation.
I1030 05:31:13.521726  1046 net.cpp:205] conv10 needs backward computation.
I1030 05:31:13.521731  1046 net.cpp:205] drop9 needs backward computation.
I1030 05:31:13.521736  1046 net.cpp:205] fire9/concat needs backward computation.
I1030 05:31:13.521741  1046 net.cpp:205] fire9/relu_expand3x3 needs backward computation.
I1030 05:31:13.521745  1046 net.cpp:205] fire9/expand3x3 needs backward computation.
I1030 05:31:13.521750  1046 net.cpp:205] fire9/relu_expand1x1 needs backward computation.
I1030 05:31:13.521755  1046 net.cpp:205] fire9/expand1x1 needs backward computation.
I1030 05:31:13.521765  1046 net.cpp:205] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I1030 05:31:13.521770  1046 net.cpp:205] fire9/relu_squeeze1x1 needs backward computation.
I1030 05:31:13.521775  1046 net.cpp:205] fire9/squeeze1x1 needs backward computation.
I1030 05:31:13.521780  1046 net.cpp:205] fire8/concat needs backward computation.
I1030 05:31:13.521785  1046 net.cpp:205] fire8/relu_expand3x3 needs backward computation.
I1030 05:31:13.521790  1046 net.cpp:205] fire8/expand3x3 needs backward computation.
I1030 05:31:13.521795  1046 net.cpp:205] fire8/relu_expand1x1 needs backward computation.
I1030 05:31:13.521798  1046 net.cpp:205] fire8/expand1x1 needs backward computation.
I1030 05:31:13.521803  1046 net.cpp:205] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I1030 05:31:13.521808  1046 net.cpp:205] fire8/relu_squeeze1x1 needs backward computation.
I1030 05:31:13.521812  1046 net.cpp:205] fire8/squeeze1x1 needs backward computation.
I1030 05:31:13.521817  1046 net.cpp:205] fire7/concat needs backward computation.
I1030 05:31:13.521822  1046 net.cpp:205] fire7/relu_expand3x3 needs backward computation.
I1030 05:31:13.521827  1046 net.cpp:205] fire7/expand3x3 needs backward computation.
I1030 05:31:13.521832  1046 net.cpp:205] fire7/relu_expand1x1 needs backward computation.
I1030 05:31:13.521836  1046 net.cpp:205] fire7/expand1x1 needs backward computation.
I1030 05:31:13.521842  1046 net.cpp:205] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I1030 05:31:13.521845  1046 net.cpp:205] fire7/relu_squeeze1x1 needs backward computation.
I1030 05:31:13.521850  1046 net.cpp:205] fire7/squeeze1x1 needs backward computation.
I1030 05:31:13.521855  1046 net.cpp:205] fire6/concat needs backward computation.
I1030 05:31:13.521860  1046 net.cpp:205] fire6/relu_expand3x3 needs backward computation.
I1030 05:31:13.521865  1046 net.cpp:205] fire6/expand3x3 needs backward computation.
I1030 05:31:13.521870  1046 net.cpp:205] fire6/relu_expand1x1 needs backward computation.
I1030 05:31:13.521874  1046 net.cpp:205] fire6/expand1x1 needs backward computation.
I1030 05:31:13.521879  1046 net.cpp:205] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I1030 05:31:13.521883  1046 net.cpp:205] fire6/relu_squeeze1x1 needs backward computation.
I1030 05:31:13.521893  1046 net.cpp:205] fire6/squeeze1x1 needs backward computation.
I1030 05:31:13.521904  1046 net.cpp:205] pool5 needs backward computation.
I1030 05:31:13.521909  1046 net.cpp:205] fire5/concat needs backward computation.
I1030 05:31:13.521914  1046 net.cpp:205] fire5/relu_expand3x3 needs backward computation.
I1030 05:31:13.521919  1046 net.cpp:205] fire5/expand3x3 needs backward computation.
I1030 05:31:13.521924  1046 net.cpp:205] fire5/relu_expand1x1 needs backward computation.
I1030 05:31:13.521929  1046 net.cpp:205] fire5/expand1x1 needs backward computation.
I1030 05:31:13.521934  1046 net.cpp:205] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I1030 05:31:13.521940  1046 net.cpp:205] fire5/relu_squeeze1x1 needs backward computation.
I1030 05:31:13.521944  1046 net.cpp:205] fire5/squeeze1x1 needs backward computation.
I1030 05:31:13.521950  1046 net.cpp:205] fire4/concat needs backward computation.
I1030 05:31:13.521955  1046 net.cpp:205] fire4/relu_expand3x3 needs backward computation.
I1030 05:31:13.521960  1046 net.cpp:205] fire4/expand3x3 needs backward computation.
I1030 05:31:13.521965  1046 net.cpp:205] fire4/relu_expand1x1 needs backward computation.
I1030 05:31:13.521968  1046 net.cpp:205] fire4/expand1x1 needs backward computation.
I1030 05:31:13.521973  1046 net.cpp:205] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I1030 05:31:13.521978  1046 net.cpp:205] fire4/relu_squeeze1x1 needs backward computation.
I1030 05:31:13.521982  1046 net.cpp:205] fire4/squeeze1x1 needs backward computation.
I1030 05:31:13.521988  1046 net.cpp:205] pool3 needs backward computation.
I1030 05:31:13.521993  1046 net.cpp:205] fire3/concat needs backward computation.
I1030 05:31:13.521998  1046 net.cpp:205] fire3/relu_expand3x3 needs backward computation.
I1030 05:31:13.522002  1046 net.cpp:205] fire3/expand3x3 needs backward computation.
I1030 05:31:13.522007  1046 net.cpp:205] fire3/relu_expand1x1 needs backward computation.
I1030 05:31:13.522011  1046 net.cpp:205] fire3/expand1x1 needs backward computation.
I1030 05:31:13.522017  1046 net.cpp:205] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I1030 05:31:13.522022  1046 net.cpp:205] fire3/relu_squeeze1x1 needs backward computation.
I1030 05:31:13.522025  1046 net.cpp:205] fire3/squeeze1x1 needs backward computation.
I1030 05:31:13.522030  1046 net.cpp:205] fire2/concat needs backward computation.
I1030 05:31:13.522035  1046 net.cpp:205] fire2/relu_expand3x3 needs backward computation.
I1030 05:31:13.522040  1046 net.cpp:205] fire2/expand3x3 needs backward computation.
I1030 05:31:13.522045  1046 net.cpp:205] fire2/relu_expand1x1 needs backward computation.
I1030 05:31:13.522049  1046 net.cpp:205] fire2/expand1x1 needs backward computation.
I1030 05:31:13.522054  1046 net.cpp:205] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I1030 05:31:13.522059  1046 net.cpp:205] fire2/relu_squeeze1x1 needs backward computation.
I1030 05:31:13.522063  1046 net.cpp:205] fire2/squeeze1x1 needs backward computation.
I1030 05:31:13.522068  1046 net.cpp:205] pool1 needs backward computation.
I1030 05:31:13.522073  1046 net.cpp:205] relu_conv1 needs backward computation.
I1030 05:31:13.522078  1046 net.cpp:205] conv1 needs backward computation.
I1030 05:31:13.522084  1046 net.cpp:207] label_data_1_split does not need backward computation.
I1030 05:31:13.522089  1046 net.cpp:207] data does not need backward computation.
I1030 05:31:13.522094  1046 net.cpp:249] This network produces output accuracy_top1
I1030 05:31:13.522099  1046 net.cpp:249] This network produces output accuracy_top5
I1030 05:31:13.522104  1046 net.cpp:249] This network produces output loss
I1030 05:31:13.522159  1046 net.cpp:262] Network initialization done.
I1030 05:31:13.522500  1046 solver.cpp:56] Solver scaffolding done.
I1030 05:31:13.529752  1046 caffe.cpp:155] Finetuning from SqueezeNet/SqueezeNet_v1.1/sqznet_inq_80_iter_35000.caffemodel
I1030 05:31:13.549876  1046 caffe.cpp:248] Starting Optimization
I1030 05:31:17.410594  1098 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_80-90.prototxt
I1030 05:31:17.415125  1099 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_80-90.prototxt
I1030 05:31:17.416127  1100 solver.cpp:172] Creating test net (#0) specified by net file: SqueezeNet/SqueezeNet_v1.1/train_val_inq_80-90.prototxt
I1030 05:31:18.194391  1046 solver.cpp:276] Solving SqueezeNet
I1030 05:31:18.194468  1046 solver.cpp:277] Learning Rate Policy: exp
I1030 05:31:18.194934  1046 solver.cpp:334] Iteration 0, Testing net (#0)
I1030 05:31:49.475639  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58756
I1030 05:31:49.475790  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80976
I1030 05:31:49.475807  1046 solver.cpp:401]     Test net output #2: loss = 1.83314 (* 1 = 1.83314 loss)
I1030 05:31:49.475924  1046 inq_conv_layer.cu:52] conv1 (INQConvolution):  Shaping the weights...
I1030 05:31:49.475980  1046 inq_conv_layer.cpp:263] Max_power = 0
I1030 05:31:49.475988  1046 inq_conv_layer.cpp:264] Min_power = -6
I1030 05:31:49.476008  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9769% -> 89.9884%)
I1030 05:31:49.476025  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 1730/1728
I1030 05:31:49.476030  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 173/173/346
I1030 05:31:49.476096  1046 inq_conv_layer.cu:62] conv1 (INQConvolution):  Shaping the bias...
I1030 05:31:49.476127  1046 inq_conv_layer.cpp:263] Max_power = -2
I1030 05:31:49.476135  1046 inq_conv_layer.cpp:264] Min_power = -8
I1030 05:31:49.476145  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.6875% -> 89.0625%)
I1030 05:31:49.476153  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 65/64
I1030 05:31:49.476158  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 6/7/13
I1030 05:31:49.488849  1046 inq_conv_layer.cu:52] fire2/squeeze1x1 (INQConvolution):  Shaping the weights...
I1030 05:31:49.506372  1046 inq_conv_layer.cpp:263] Max_power = 0
I1030 05:31:49.506384  1046 inq_conv_layer.cpp:264] Min_power = -6
I1030 05:31:49.506402  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9805% -> 89.9414%)
I1030 05:31:49.506413  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 1025/1024
I1030 05:31:49.506419  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 102/103/205
I1030 05:31:49.506456  1046 inq_conv_layer.cu:62] fire2/squeeze1x1 (INQConvolution):  Shaping the bias...
I1030 05:31:49.506486  1046 inq_conv_layer.cpp:263] Max_power = -2
I1030 05:31:49.506494  1046 inq_conv_layer.cpp:264] Min_power = -8
I1030 05:31:49.506500  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 75% -> 87.5%)
I1030 05:31:49.506508  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 20/16
I1030 05:31:49.506513  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 2/2/4
I1030 05:31:49.509961  1046 inq_conv_layer.cu:52] fire2/expand1x1 (INQConvolution):  Shaping the weights...
I1030 05:31:49.510196  1046 inq_conv_layer.cpp:263] Max_power = 0
I1030 05:31:49.510207  1046 inq_conv_layer.cpp:264] Min_power = -6
I1030 05:31:49.510223  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9805% -> 89.9414%)
I1030 05:31:49.510237  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 1025/1024
I1030 05:31:49.510242  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 102/103/205
I1030 05:31:49.510280  1046 inq_conv_layer.cu:62] fire2/expand1x1 (INQConvolution):  Shaping the bias...
I1030 05:31:49.510315  1046 inq_conv_layer.cpp:263] Max_power = -3
I1030 05:31:49.510324  1046 inq_conv_layer.cpp:264] Min_power = -9
I1030 05:31:49.510332  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.6875% -> 89.0625%)
I1030 05:31:49.510341  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 65/64
I1030 05:31:49.510346  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 6/7/13
I1030 05:31:49.514447  1046 inq_conv_layer.cu:52] fire2/expand3x3 (INQConvolution):  Shaping the weights...
I1030 05:31:49.515560  1046 inq_conv_layer.cpp:263] Max_power = -1
I1030 05:31:49.515570  1046 inq_conv_layer.cpp:264] Min_power = -7
I1030 05:31:49.515625  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9913% -> 89.9957%)
I1030 05:31:49.515640  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 9220/9216
I1030 05:31:49.515645  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 922/922/1844
I1030 05:31:49.515945  1046 inq_conv_layer.cu:62] fire2/expand3x3 (INQConvolution):  Shaping the bias...
I1030 05:31:49.515980  1046 inq_conv_layer.cpp:263] Max_power = -4
I1030 05:31:49.516002  1046 inq_conv_layer.cpp:264] Min_power = -10
I1030 05:31:49.516010  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.6875% -> 89.0625%)
I1030 05:31:49.516021  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 65/64
I1030 05:31:49.516024  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 6/7/13
I1030 05:31:49.525231  1046 inq_conv_layer.cu:52] fire3/squeeze1x1 (INQConvolution):  Shaping the weights...
I1030 05:31:49.528802  1046 inq_conv_layer.cpp:263] Max_power = 0
I1030 05:31:49.528812  1046 inq_conv_layer.cpp:264] Min_power = -6
I1030 05:31:49.528834  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9805% -> 89.9902%)
I1030 05:31:49.528846  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 2050/2048
I1030 05:31:49.528851  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 205/205/410
I1030 05:31:49.528920  1046 inq_conv_layer.cu:62] fire3/squeeze1x1 (INQConvolution):  Shaping the bias...
I1030 05:31:49.528955  1046 inq_conv_layer.cpp:263] Max_power = -2
I1030 05:31:49.528964  1046 inq_conv_layer.cpp:264] Min_power = -8
I1030 05:31:49.528970  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 75% -> 87.5%)
I1030 05:31:49.528978  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 20/16
I1030 05:31:49.528982  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 2/2/4
I1030 05:31:49.532433  1046 inq_conv_layer.cu:52] fire3/expand1x1 (INQConvolution):  Shaping the weights...
I1030 05:31:49.533124  1046 inq_conv_layer.cpp:263] Max_power = 0
I1030 05:31:49.533133  1046 inq_conv_layer.cpp:264] Min_power = -6
I1030 05:31:49.533149  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9805% -> 89.9414%)
I1030 05:31:49.533160  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 1025/1024
I1030 05:31:49.533164  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 102/103/205
I1030 05:31:49.533202  1046 inq_conv_layer.cu:62] fire3/expand1x1 (INQConvolution):  Shaping the bias...
I1030 05:31:49.533231  1046 inq_conv_layer.cpp:263] Max_power = -2
I1030 05:31:49.533236  1046 inq_conv_layer.cpp:264] Min_power = -8
I1030 05:31:49.533242  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.6875% -> 89.0625%)
I1030 05:31:49.533252  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 65/64
I1030 05:31:49.533255  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 6/7/13
I1030 05:31:49.537320  1046 inq_conv_layer.cu:52] fire3/expand3x3 (INQConvolution):  Shaping the weights...
I1030 05:31:49.538444  1046 inq_conv_layer.cpp:263] Max_power = 0
I1030 05:31:49.538455  1046 inq_conv_layer.cpp:264] Min_power = -6
I1030 05:31:49.538509  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9913% -> 89.9957%)
I1030 05:31:49.538524  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 9220/9216
I1030 05:31:49.538529  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 922/922/1844
I1030 05:31:49.538808  1046 inq_conv_layer.cu:62] fire3/expand3x3 (INQConvolution):  Shaping the bias...
I1030 05:31:49.538841  1046 inq_conv_layer.cpp:263] Max_power = -3
I1030 05:31:49.538848  1046 inq_conv_layer.cpp:264] Min_power = -9
I1030 05:31:49.538856  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.6875% -> 89.0625%)
I1030 05:31:49.538872  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 65/64
I1030 05:31:49.538877  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 6/7/13
I1030 05:31:49.551221  1046 inq_conv_layer.cu:52] fire4/squeeze1x1 (INQConvolution):  Shaping the weights...
I1030 05:31:49.553459  1046 inq_conv_layer.cpp:263] Max_power = 0
I1030 05:31:49.553470  1046 inq_conv_layer.cpp:264] Min_power = -6
I1030 05:31:49.553500  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9805% -> 89.9902%)
I1030 05:31:49.553514  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 4100/4096
I1030 05:31:49.553519  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 410/410/820
I1030 05:31:49.553666  1046 inq_conv_layer.cu:62] fire4/squeeze1x1 (INQConvolution):  Shaping the bias...
I1030 05:31:49.553700  1046 inq_conv_layer.cpp:263] Max_power = -3
I1030 05:31:49.553707  1046 inq_conv_layer.cpp:264] Min_power = -9
I1030 05:31:49.553714  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 78.125% -> 87.5%)
I1030 05:31:49.553724  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 35/32
I1030 05:31:49.553727  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 3/4/7
I1030 05:31:49.557232  1046 inq_conv_layer.cu:52] fire4/expand1x1 (INQConvolution):  Shaping the weights...
I1030 05:31:49.558334  1046 inq_conv_layer.cpp:263] Max_power = -1
I1030 05:31:49.558346  1046 inq_conv_layer.cpp:264] Min_power = -7
I1030 05:31:49.558375  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9805% -> 89.9902%)
I1030 05:31:49.558388  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 4100/4096
I1030 05:31:49.558394  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 410/410/820
I1030 05:31:49.558526  1046 inq_conv_layer.cu:62] fire4/expand1x1 (INQConvolution):  Shaping the bias...
I1030 05:31:49.558557  1046 inq_conv_layer.cpp:263] Max_power = -4
I1030 05:31:49.558564  1046 inq_conv_layer.cpp:264] Min_power = -10
I1030 05:31:49.558571  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.6875% -> 89.8438%)
I1030 05:31:49.558581  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 130/128
I1030 05:31:49.558585  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 13/13/26
I1030 05:31:49.562386  1046 inq_conv_layer.cu:52] fire4/expand3x3 (INQConvolution):  Shaping the weights...
I1030 05:31:49.563230  1046 inq_conv_layer.cpp:263] Max_power = -1
I1030 05:31:49.563241  1046 inq_conv_layer.cpp:264] Min_power = -7
I1030 05:31:49.563421  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9995% -> 89.9984%)
I1030 05:31:49.563441  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 36865/36864
I1030 05:31:49.563446  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 3686/3687/7373
I1030 05:31:49.564702  1046 inq_conv_layer.cu:62] fire4/expand3x3 (INQConvolution):  Shaping the bias...
I1030 05:31:49.564739  1046 inq_conv_layer.cpp:263] Max_power = -4
I1030 05:31:49.564746  1046 inq_conv_layer.cpp:264] Min_power = -10
I1030 05:31:49.564754  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.6875% -> 89.8438%)
I1030 05:31:49.564765  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 130/128
I1030 05:31:49.564769  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 13/13/26
I1030 05:31:49.571300  1046 inq_conv_layer.cu:52] fire5/squeeze1x1 (INQConvolution):  Shaping the weights...
I1030 05:31:49.573468  1046 inq_conv_layer.cpp:263] Max_power = -1
I1030 05:31:49.573479  1046 inq_conv_layer.cpp:264] Min_power = -7
I1030 05:31:49.573521  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9927% -> 89.9902%)
I1030 05:31:49.573536  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 8195/8192
I1030 05:31:49.573541  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 819/820/1639
I1030 05:31:49.573809  1046 inq_conv_layer.cu:62] fire5/squeeze1x1 (INQConvolution):  Shaping the bias...
I1030 05:31:49.573848  1046 inq_conv_layer.cpp:263] Max_power = -2
I1030 05:31:49.573855  1046 inq_conv_layer.cpp:264] Min_power = -8
I1030 05:31:49.573863  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 78.125% -> 87.5%)
I1030 05:31:49.573871  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 35/32
I1030 05:31:49.573875  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 3/4/7
I1030 05:31:49.578961  1046 inq_conv_layer.cu:52] fire5/expand1x1 (INQConvolution):  Shaping the weights...
I1030 05:31:49.580819  1046 inq_conv_layer.cpp:263] Max_power = -1
I1030 05:31:49.580831  1046 inq_conv_layer.cpp:264] Min_power = -7
I1030 05:31:49.580857  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9805% -> 89.9902%)
I1030 05:31:49.580885  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 4100/4096
I1030 05:31:49.580890  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 410/410/820
I1030 05:31:49.581022  1046 inq_conv_layer.cu:62] fire5/expand1x1 (INQConvolution):  Shaping the bias...
I1030 05:31:49.581055  1046 inq_conv_layer.cpp:263] Max_power = -3
I1030 05:31:49.581068  1046 inq_conv_layer.cpp:264] Min_power = -9
I1030 05:31:49.581079  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.6875% -> 89.8438%)
I1030 05:31:49.581089  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 130/128
I1030 05:31:49.581092  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 13/13/26
I1030 05:31:49.584894  1046 inq_conv_layer.cu:52] fire5/expand3x3 (INQConvolution):  Shaping the weights...
I1030 05:31:49.585733  1046 inq_conv_layer.cpp:263] Max_power = 0
I1030 05:31:49.585746  1046 inq_conv_layer.cpp:264] Min_power = -6
I1030 05:31:49.585917  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9995% -> 89.9984%)
I1030 05:31:49.585934  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 36865/36864
I1030 05:31:49.585942  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 3686/3687/7373
I1030 05:31:49.587054  1046 inq_conv_layer.cu:62] fire5/expand3x3 (INQConvolution):  Shaping the bias...
I1030 05:31:49.587090  1046 inq_conv_layer.cpp:263] Max_power = -5
I1030 05:31:49.587097  1046 inq_conv_layer.cpp:264] Min_power = -11
I1030 05:31:49.587105  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.6875% -> 89.8438%)
I1030 05:31:49.587121  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 130/128
I1030 05:31:49.587126  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 13/13/26
I1030 05:31:49.596978  1046 inq_conv_layer.cu:52] fire6/squeeze1x1 (INQConvolution):  Shaping the weights...
I1030 05:31:49.597957  1046 inq_conv_layer.cpp:263] Max_power = -1
I1030 05:31:49.597968  1046 inq_conv_layer.cpp:264] Min_power = -7
I1030 05:31:49.598031  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9967% -> 89.9984%)
I1030 05:31:49.598045  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 12290/12288
I1030 05:31:49.598052  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 1229/1229/2458
I1030 05:31:49.598459  1046 inq_conv_layer.cu:62] fire6/squeeze1x1 (INQConvolution):  Shaping the bias...
I1030 05:31:49.598490  1046 inq_conv_layer.cpp:263] Max_power = -3
I1030 05:31:49.598497  1046 inq_conv_layer.cpp:264] Min_power = -9
I1030 05:31:49.598503  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.1667% -> 89.5833%)
I1030 05:31:49.598512  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 50/48
I1030 05:31:49.598518  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 5/5/10
I1030 05:31:49.602208  1046 inq_conv_layer.cu:52] fire6/expand1x1 (INQConvolution):  Shaping the weights...
I1030 05:31:49.604498  1046 inq_conv_layer.cpp:263] Max_power = -1
I1030 05:31:49.604509  1046 inq_conv_layer.cpp:264] Min_power = -7
I1030 05:31:49.604557  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9913% -> 89.9957%)
I1030 05:31:49.604573  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 9220/9216
I1030 05:31:49.604583  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 922/922/1844
I1030 05:31:49.604881  1046 inq_conv_layer.cu:62] fire6/expand1x1 (INQConvolution):  Shaping the bias...
I1030 05:31:49.604914  1046 inq_conv_layer.cpp:263] Max_power = -5
I1030 05:31:49.604920  1046 inq_conv_layer.cpp:264] Min_power = -11
I1030 05:31:49.604928  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.6875% -> 89.5833%)
I1030 05:31:49.604940  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 195/192
I1030 05:31:49.604946  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 19/20/39
I1030 05:31:49.608569  1046 inq_conv_layer.cu:52] fire6/expand3x3 (INQConvolution):  Shaping the weights...
I1030 05:31:49.609452  1046 inq_conv_layer.cpp:263] Max_power = -1
I1030 05:31:49.609467  1046 inq_conv_layer.cpp:264] Min_power = -7
I1030 05:31:49.609858  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9998% -> 89.9993%)
I1030 05:31:49.609874  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 82945/82944
I1030 05:31:49.609879  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 8294/8295/16589
I1030 05:31:49.612785  1046 inq_conv_layer.cu:62] fire6/expand3x3 (INQConvolution):  Shaping the bias...
I1030 05:31:49.612824  1046 inq_conv_layer.cpp:263] Max_power = -5
I1030 05:31:49.612830  1046 inq_conv_layer.cpp:264] Min_power = -11
I1030 05:31:49.612838  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.6875% -> 89.5833%)
I1030 05:31:49.612850  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 195/192
I1030 05:31:49.612855  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 19/20/39
I1030 05:31:49.619201  1046 inq_conv_layer.cu:52] fire7/squeeze1x1 (INQConvolution):  Shaping the weights...
I1030 05:31:49.621204  1046 inq_conv_layer.cpp:263] Max_power = -1
I1030 05:31:49.621215  1046 inq_conv_layer.cpp:264] Min_power = -7
I1030 05:31:49.621305  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9967% -> 89.9957%)
I1030 05:31:49.621321  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 18435/18432
I1030 05:31:49.621326  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 1843/1844/3687
I1030 05:31:49.621937  1046 inq_conv_layer.cu:62] fire7/squeeze1x1 (INQConvolution):  Shaping the bias...
I1030 05:31:49.621969  1046 inq_conv_layer.cpp:263] Max_power = -2
I1030 05:31:49.621975  1046 inq_conv_layer.cpp:264] Min_power = -8
I1030 05:31:49.621981  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.1667% -> 89.5833%)
I1030 05:31:49.621992  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 50/48
I1030 05:31:49.621997  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 5/5/10
I1030 05:31:49.625563  1046 inq_conv_layer.cu:52] fire7/expand1x1 (INQConvolution):  Shaping the weights...
I1030 05:31:49.629088  1046 inq_conv_layer.cpp:263] Max_power = -1
I1030 05:31:49.629098  1046 inq_conv_layer.cpp:264] Min_power = -7
I1030 05:31:49.629148  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9913% -> 89.9957%)
I1030 05:31:49.629163  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 9220/9216
I1030 05:31:49.629168  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 922/922/1844
I1030 05:31:49.629470  1046 inq_conv_layer.cu:62] fire7/expand1x1 (INQConvolution):  Shaping the bias...
I1030 05:31:49.629503  1046 inq_conv_layer.cpp:263] Max_power = -2
I1030 05:31:49.629510  1046 inq_conv_layer.cpp:264] Min_power = -8
I1030 05:31:49.629519  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.6875% -> 89.5833%)
I1030 05:31:49.629528  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 195/192
I1030 05:31:49.629534  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 19/20/39
I1030 05:31:49.633092  1046 inq_conv_layer.cu:52] fire7/expand3x3 (INQConvolution):  Shaping the weights...
I1030 05:31:49.634008  1046 inq_conv_layer.cpp:263] Max_power = -1
I1030 05:31:49.634021  1046 inq_conv_layer.cpp:264] Min_power = -7
I1030 05:31:49.634383  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9998% -> 89.9993%)
I1030 05:31:49.634399  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 82945/82944
I1030 05:31:49.634404  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 8294/8295/16589
I1030 05:31:49.637305  1046 inq_conv_layer.cu:62] fire7/expand3x3 (INQConvolution):  Shaping the bias...
I1030 05:31:49.637343  1046 inq_conv_layer.cpp:263] Max_power = -4
I1030 05:31:49.637351  1046 inq_conv_layer.cpp:264] Min_power = -10
I1030 05:31:49.637358  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.6875% -> 89.5833%)
I1030 05:31:49.637383  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 195/192
I1030 05:31:49.637388  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 19/20/39
I1030 05:31:49.643710  1046 inq_conv_layer.cu:52] fire8/squeeze1x1 (INQConvolution):  Shaping the weights...
I1030 05:31:49.645771  1046 inq_conv_layer.cpp:263] Max_power = -1
I1030 05:31:49.645781  1046 inq_conv_layer.cpp:264] Min_power = -7
I1030 05:31:49.645892  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9967% -> 89.9984%)
I1030 05:31:49.645908  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 24580/24576
I1030 05:31:49.645913  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 2458/2458/4916
I1030 05:31:49.646744  1046 inq_conv_layer.cu:62] fire8/squeeze1x1 (INQConvolution):  Shaping the bias...
I1030 05:31:49.646777  1046 inq_conv_layer.cpp:263] Max_power = 3
I1030 05:31:49.646785  1046 inq_conv_layer.cpp:264] Min_power = -3
I1030 05:31:49.646791  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.6875% -> 89.0625%)
I1030 05:31:49.646802  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 65/64
I1030 05:31:49.646808  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 6/7/13
I1030 05:31:49.650393  1046 inq_conv_layer.cu:52] fire8/expand1x1 (INQConvolution):  Shaping the weights...
I1030 05:31:49.654028  1046 inq_conv_layer.cpp:263] Max_power = -1
I1030 05:31:49.654039  1046 inq_conv_layer.cpp:264] Min_power = -7
I1030 05:31:49.654114  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9988% -> 89.9963%)
I1030 05:31:49.654134  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 16385/16384
I1030 05:31:49.654139  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 1638/1639/3277
I1030 05:31:49.654686  1046 inq_conv_layer.cu:62] fire8/expand1x1 (INQConvolution):  Shaping the bias...
I1030 05:31:49.654721  1046 inq_conv_layer.cpp:263] Max_power = -1
I1030 05:31:49.654727  1046 inq_conv_layer.cpp:264] Min_power = -7
I1030 05:31:49.654736  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.6875% -> 89.8438%)
I1030 05:31:49.654748  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 260/256
I1030 05:31:49.654752  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 26/26/52
I1030 05:31:49.658378  1046 inq_conv_layer.cu:52] fire8/expand3x3 (INQConvolution):  Shaping the weights...
I1030 05:31:49.659895  1046 inq_conv_layer.cpp:263] Max_power = -1
I1030 05:31:49.659909  1046 inq_conv_layer.cpp:264] Min_power = -7
I1030 05:31:49.660553  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9995% -> 89.9997%)
I1030 05:31:49.660570  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 147460/147456
I1030 05:31:49.660575  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 14746/14746/29492
I1030 05:31:49.665747  1046 inq_conv_layer.cu:62] fire8/expand3x3 (INQConvolution):  Shaping the bias...
I1030 05:31:49.665786  1046 inq_conv_layer.cpp:263] Max_power = -1
I1030 05:31:49.665791  1046 inq_conv_layer.cpp:264] Min_power = -7
I1030 05:31:49.665802  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.6875% -> 89.8438%)
I1030 05:31:49.665815  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 260/256
I1030 05:31:49.665827  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 26/26/52
I1030 05:31:49.672829  1046 inq_conv_layer.cu:52] fire9/squeeze1x1 (INQConvolution):  Shaping the weights...
I1030 05:31:49.676465  1046 inq_conv_layer.cpp:263] Max_power = -1
I1030 05:31:49.676476  1046 inq_conv_layer.cpp:264] Min_power = -7
I1030 05:31:49.676620  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9988% -> 89.9994%)
I1030 05:31:49.676635  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 32770/32768
I1030 05:31:49.676641  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 3277/3277/6554
I1030 05:31:49.677757  1046 inq_conv_layer.cu:62] fire9/squeeze1x1 (INQConvolution):  Shaping the bias...
I1030 05:31:49.677805  1046 inq_conv_layer.cpp:263] Max_power = 0
I1030 05:31:49.677811  1046 inq_conv_layer.cpp:264] Min_power = -6
I1030 05:31:49.677819  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.6875% -> 89.0625%)
I1030 05:31:49.677832  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 65/64
I1030 05:31:49.677836  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 6/7/13
I1030 05:31:49.681433  1046 inq_conv_layer.cu:52] fire9/expand1x1 (INQConvolution):  Shaping the weights...
I1030 05:31:49.686316  1046 inq_conv_layer.cpp:263] Max_power = -1
I1030 05:31:49.686327  1046 inq_conv_layer.cpp:264] Min_power = -7
I1030 05:31:49.686403  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9988% -> 89.9963%)
I1030 05:31:49.686424  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 16385/16384
I1030 05:31:49.686427  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 1638/1639/3277
I1030 05:31:49.686970  1046 inq_conv_layer.cu:62] fire9/expand1x1 (INQConvolution):  Shaping the bias...
I1030 05:31:49.687006  1046 inq_conv_layer.cpp:263] Max_power = -4
I1030 05:31:49.687012  1046 inq_conv_layer.cpp:264] Min_power = -10
I1030 05:31:49.687021  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.6875% -> 89.8438%)
I1030 05:31:49.687031  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 260/256
I1030 05:31:49.687036  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 26/26/52
I1030 05:31:49.690665  1046 inq_conv_layer.cu:52] fire9/expand3x3 (INQConvolution):  Shaping the weights...
I1030 05:31:49.692162  1046 inq_conv_layer.cpp:263] Max_power = -1
I1030 05:31:49.692174  1046 inq_conv_layer.cpp:264] Min_power = -7
I1030 05:31:49.692803  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.9995% -> 89.9997%)
I1030 05:31:49.692821  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 147460/147456
I1030 05:31:49.692826  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 14746/14746/29492
I1030 05:31:49.697991  1046 inq_conv_layer.cu:62] fire9/expand3x3 (INQConvolution):  Shaping the bias...
I1030 05:31:49.698027  1046 inq_conv_layer.cpp:263] Max_power = -5
I1030 05:31:49.698035  1046 inq_conv_layer.cpp:264] Min_power = -11
I1030 05:31:49.698043  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 79.6875% -> 89.8438%)
I1030 05:31:49.698056  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 260/256
I1030 05:31:49.698061  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 26/26/52
I1030 05:31:49.712111  1046 inq_conv_layer.cu:52] conv10 (INQConvolution):  Shaping the weights...
I1030 05:31:49.715819  1046 inq_conv_layer.cpp:263] Max_power = -2
I1030 05:31:49.715833  1046 inq_conv_layer.cpp:264] Min_power = -8
I1030 05:31:49.718101  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 80% -> 90%)
I1030 05:31:49.718116  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 512000/512000
I1030 05:31:49.718122  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 51200/51200/102400
I1030 05:31:49.737429  1046 inq_conv_layer.cu:62] conv10 (INQConvolution):  Shaping the bias...
I1030 05:31:49.737475  1046 inq_conv_layer.cpp:263] Max_power = -2
I1030 05:31:49.737494  1046 inq_conv_layer.cpp:264] Min_power = -8
I1030 05:31:49.737509  1046 inq_conv_layer.cpp:307] portions: 80% -> 90% (total: 80% -> 90%)
I1030 05:31:49.737527  1046 inq_conv_layer.cpp:313] init_not_quantized/total: 1000/1000
I1030 05:31:49.737531  1046 inq_conv_layer.cpp:316] to_update/not_tobe_quantized/not_yet_quantized: 100/100/200
I1030 05:31:50.624480  1046 solver.cpp:222] Iteration 0 (-1.02783e-33 iter/s, 32.4278s/40 iters), loss = 1.64529
I1030 05:31:50.624534  1046 solver.cpp:241]     Train net output #0: loss = 1.64529 (* 1 = 1.64529 loss)
I1030 05:31:50.624567  1046 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I1030 05:32:21.300313  1046 solver.cpp:222] Iteration 40 (1.30401 iter/s, 30.6746s/40 iters), loss = 1.91645
I1030 05:32:21.300575  1046 solver.cpp:241]     Train net output #0: loss = 1.91645 (* 1 = 1.91645 loss)
I1030 05:32:21.300602  1046 sgd_solver.cpp:105] Iteration 40, lr = 0.00995053
I1030 05:32:52.213187  1046 solver.cpp:222] Iteration 80 (1.29402 iter/s, 30.9115s/40 iters), loss = 1.56586
I1030 05:32:52.213415  1046 solver.cpp:241]     Train net output #0: loss = 1.56586 (* 1 = 1.56586 loss)
I1030 05:32:52.213433  1046 sgd_solver.cpp:105] Iteration 80, lr = 0.0099013
I1030 05:33:22.897027  1046 solver.cpp:222] Iteration 120 (1.30368 iter/s, 30.6825s/40 iters), loss = 1.53876
I1030 05:33:22.897213  1046 solver.cpp:241]     Train net output #0: loss = 1.53876 (* 1 = 1.53876 loss)
I1030 05:33:22.897229  1046 sgd_solver.cpp:105] Iteration 120, lr = 0.00985232
I1030 05:33:53.378252  1046 solver.cpp:222] Iteration 160 (1.31234 iter/s, 30.4799s/40 iters), loss = 1.3584
I1030 05:33:53.378434  1046 solver.cpp:241]     Train net output #0: loss = 1.3584 (* 1 = 1.3584 loss)
I1030 05:33:53.378451  1046 sgd_solver.cpp:105] Iteration 160, lr = 0.00980358
I1030 05:34:24.079025  1046 solver.cpp:222] Iteration 200 (1.30296 iter/s, 30.6994s/40 iters), loss = 1.46881
I1030 05:34:24.079188  1046 solver.cpp:241]     Train net output #0: loss = 1.46881 (* 1 = 1.46881 loss)
I1030 05:34:24.079205  1046 sgd_solver.cpp:105] Iteration 200, lr = 0.00975508
I1030 05:34:54.738816  1046 solver.cpp:222] Iteration 240 (1.3047 iter/s, 30.6585s/40 iters), loss = 1.36476
I1030 05:34:54.738973  1046 solver.cpp:241]     Train net output #0: loss = 1.36476 (* 1 = 1.36476 loss)
I1030 05:34:54.738991  1046 sgd_solver.cpp:105] Iteration 240, lr = 0.00970682
I1030 05:35:25.339843  1046 solver.cpp:222] Iteration 280 (1.3072 iter/s, 30.5997s/40 iters), loss = 1.22302
I1030 05:35:25.340008  1046 solver.cpp:241]     Train net output #0: loss = 1.22302 (* 1 = 1.22302 loss)
I1030 05:35:25.340029  1046 sgd_solver.cpp:105] Iteration 280, lr = 0.0096588
I1030 05:35:55.942508  1046 solver.cpp:222] Iteration 320 (1.30713 iter/s, 30.6013s/40 iters), loss = 1.52482
I1030 05:35:55.942679  1046 solver.cpp:241]     Train net output #0: loss = 1.52482 (* 1 = 1.52482 loss)
I1030 05:35:55.942697  1046 sgd_solver.cpp:105] Iteration 320, lr = 0.00961101
I1030 05:36:26.524432  1046 solver.cpp:222] Iteration 360 (1.30802 iter/s, 30.5806s/40 iters), loss = 1.36902
I1030 05:36:26.524585  1046 solver.cpp:241]     Train net output #0: loss = 1.36902 (* 1 = 1.36902 loss)
I1030 05:36:26.524605  1046 sgd_solver.cpp:105] Iteration 360, lr = 0.00956347
I1030 05:36:57.048517  1046 solver.cpp:222] Iteration 400 (1.3105 iter/s, 30.5228s/40 iters), loss = 1.57638
I1030 05:36:57.048698  1046 solver.cpp:241]     Train net output #0: loss = 1.57638 (* 1 = 1.57638 loss)
I1030 05:36:57.048715  1046 sgd_solver.cpp:105] Iteration 400, lr = 0.00951616
I1030 05:37:27.464871  1046 solver.cpp:222] Iteration 440 (1.31514 iter/s, 30.415s/40 iters), loss = 1.42742
I1030 05:37:27.465037  1046 solver.cpp:241]     Train net output #0: loss = 1.42742 (* 1 = 1.42742 loss)
I1030 05:37:27.465054  1046 sgd_solver.cpp:105] Iteration 440, lr = 0.00946908
I1030 05:37:57.895318  1046 solver.cpp:222] Iteration 480 (1.31453 iter/s, 30.4291s/40 iters), loss = 1.24929
I1030 05:37:57.895511  1046 solver.cpp:241]     Train net output #0: loss = 1.24929 (* 1 = 1.24929 loss)
I1030 05:37:57.895539  1046 sgd_solver.cpp:105] Iteration 480, lr = 0.00942223
I1030 05:38:12.387111  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_500.caffemodel
I1030 05:38:12.465014  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_500.solverstate
I1030 05:38:12.482138  1046 solver.cpp:334] Iteration 500, Testing net (#0)
I1030 05:38:43.356587  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 05:38:43.564574  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57336
I1030 05:38:43.564635  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80616
I1030 05:38:43.564651  1046 solver.cpp:401]     Test net output #2: loss = 1.91268 (* 1 = 1.91268 loss)
I1030 05:38:59.675698  1046 solver.cpp:222] Iteration 520 (0.647481 iter/s, 61.7779s/40 iters), loss = 1.38084
I1030 05:38:59.675763  1046 solver.cpp:241]     Train net output #0: loss = 1.38084 (* 1 = 1.38084 loss)
I1030 05:38:59.675781  1046 sgd_solver.cpp:105] Iteration 520, lr = 0.00937562
I1030 05:39:30.489969  1046 solver.cpp:222] Iteration 560 (1.29815 iter/s, 30.813s/40 iters), loss = 1.61171
I1030 05:39:30.490197  1046 solver.cpp:241]     Train net output #0: loss = 1.61171 (* 1 = 1.61171 loss)
I1030 05:39:30.490214  1046 sgd_solver.cpp:105] Iteration 560, lr = 0.00932924
I1030 05:40:01.125429  1046 solver.cpp:222] Iteration 600 (1.30574 iter/s, 30.6341s/40 iters), loss = 1.33168
I1030 05:40:01.125635  1046 solver.cpp:241]     Train net output #0: loss = 1.33168 (* 1 = 1.33168 loss)
I1030 05:40:01.125655  1046 sgd_solver.cpp:105] Iteration 600, lr = 0.00928308
I1030 05:40:31.539997  1046 solver.cpp:222] Iteration 640 (1.31522 iter/s, 30.4132s/40 iters), loss = 1.21974
I1030 05:40:31.541028  1046 solver.cpp:241]     Train net output #0: loss = 1.21974 (* 1 = 1.21974 loss)
I1030 05:40:31.541045  1046 sgd_solver.cpp:105] Iteration 640, lr = 0.00923716
I1030 05:41:02.040586  1046 solver.cpp:222] Iteration 680 (1.31154 iter/s, 30.4984s/40 iters), loss = 1.31526
I1030 05:41:02.040776  1046 solver.cpp:241]     Train net output #0: loss = 1.31526 (* 1 = 1.31526 loss)
I1030 05:41:02.040792  1046 sgd_solver.cpp:105] Iteration 680, lr = 0.00919146
I1030 05:41:32.386029  1046 solver.cpp:222] Iteration 720 (1.31821 iter/s, 30.3441s/40 iters), loss = 1.44886
I1030 05:41:32.386216  1046 solver.cpp:241]     Train net output #0: loss = 1.44886 (* 1 = 1.44886 loss)
I1030 05:41:32.386235  1046 sgd_solver.cpp:105] Iteration 720, lr = 0.00914599
I1030 05:42:02.726666  1046 solver.cpp:222] Iteration 760 (1.31842 iter/s, 30.3393s/40 iters), loss = 1.56095
I1030 05:42:02.726840  1046 solver.cpp:241]     Train net output #0: loss = 1.56095 (* 1 = 1.56095 loss)
I1030 05:42:02.726861  1046 sgd_solver.cpp:105] Iteration 760, lr = 0.00910074
I1030 05:42:32.922045  1046 solver.cpp:222] Iteration 800 (1.32476 iter/s, 30.1941s/40 iters), loss = 1.3948
I1030 05:42:32.922222  1046 solver.cpp:241]     Train net output #0: loss = 1.3948 (* 1 = 1.3948 loss)
I1030 05:42:32.922242  1046 sgd_solver.cpp:105] Iteration 800, lr = 0.00905572
I1030 05:43:03.054643  1046 solver.cpp:222] Iteration 840 (1.32752 iter/s, 30.1313s/40 iters), loss = 1.56272
I1030 05:43:03.054833  1046 solver.cpp:241]     Train net output #0: loss = 1.56272 (* 1 = 1.56272 loss)
I1030 05:43:03.054855  1046 sgd_solver.cpp:105] Iteration 840, lr = 0.00901092
I1030 05:43:33.602799  1046 solver.cpp:222] Iteration 880 (1.30947 iter/s, 30.5468s/40 iters), loss = 1.7431
I1030 05:43:33.602993  1046 solver.cpp:241]     Train net output #0: loss = 1.7431 (* 1 = 1.7431 loss)
I1030 05:43:33.603011  1046 sgd_solver.cpp:105] Iteration 880, lr = 0.00896634
I1030 05:44:04.140173  1046 solver.cpp:222] Iteration 920 (1.30993 iter/s, 30.536s/40 iters), loss = 1.09558
I1030 05:44:04.140406  1046 solver.cpp:241]     Train net output #0: loss = 1.09558 (* 1 = 1.09558 loss)
I1030 05:44:04.140424  1046 sgd_solver.cpp:105] Iteration 920, lr = 0.00892199
I1030 05:44:34.572633  1046 solver.cpp:222] Iteration 960 (1.31445 iter/s, 30.4311s/40 iters), loss = 1.44328
I1030 05:44:34.572842  1046 solver.cpp:241]     Train net output #0: loss = 1.44328 (* 1 = 1.44328 loss)
I1030 05:44:34.572862  1046 sgd_solver.cpp:105] Iteration 960, lr = 0.00887785
I1030 05:45:04.331861  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_1000.caffemodel
I1030 05:45:04.366240  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_1000.solverstate
I1030 05:45:04.384083  1046 solver.cpp:334] Iteration 1000, Testing net (#0)
I1030 05:45:35.532335  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57184
I1030 05:45:35.532505  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.801559
I1030 05:45:35.532522  1046 solver.cpp:401]     Test net output #2: loss = 1.9021 (* 1 = 1.9021 loss)
I1030 05:45:36.306651  1046 solver.cpp:222] Iteration 1000 (0.647967 iter/s, 61.7315s/40 iters), loss = 0.886875
I1030 05:45:36.306715  1046 solver.cpp:241]     Train net output #0: loss = 0.886875 (* 1 = 0.886875 loss)
I1030 05:45:36.306736  1046 sgd_solver.cpp:105] Iteration 1000, lr = 0.00883393
I1030 05:46:07.092471  1046 solver.cpp:222] Iteration 1040 (1.29935 iter/s, 30.7846s/40 iters), loss = 1.72047
I1030 05:46:07.092653  1046 solver.cpp:241]     Train net output #0: loss = 1.72047 (* 1 = 1.72047 loss)
I1030 05:46:07.092671  1046 sgd_solver.cpp:105] Iteration 1040, lr = 0.00879022
I1030 05:46:37.511019  1046 solver.cpp:222] Iteration 1080 (1.31504 iter/s, 30.4172s/40 iters), loss = 1.68852
I1030 05:46:37.511203  1046 solver.cpp:241]     Train net output #0: loss = 1.68852 (* 1 = 1.68852 loss)
I1030 05:46:37.511224  1046 sgd_solver.cpp:105] Iteration 1080, lr = 0.00874674
I1030 05:47:08.004922  1046 solver.cpp:222] Iteration 1120 (1.3118 iter/s, 30.4926s/40 iters), loss = 1.29049
I1030 05:47:08.005105  1046 solver.cpp:241]     Train net output #0: loss = 1.29049 (* 1 = 1.29049 loss)
I1030 05:47:08.005127  1046 sgd_solver.cpp:105] Iteration 1120, lr = 0.00870347
I1030 05:47:38.551270  1046 solver.cpp:222] Iteration 1160 (1.30954 iter/s, 30.545s/40 iters), loss = 1.42796
I1030 05:47:38.551457  1046 solver.cpp:241]     Train net output #0: loss = 1.42796 (* 1 = 1.42796 loss)
I1030 05:47:38.551477  1046 sgd_solver.cpp:105] Iteration 1160, lr = 0.00866041
I1030 05:48:08.947831  1046 solver.cpp:222] Iteration 1200 (1.316 iter/s, 30.3952s/40 iters), loss = 1.22914
I1030 05:48:08.948024  1046 solver.cpp:241]     Train net output #0: loss = 1.22914 (* 1 = 1.22914 loss)
I1030 05:48:08.948040  1046 sgd_solver.cpp:105] Iteration 1200, lr = 0.00861757
I1030 05:48:39.326839  1046 solver.cpp:222] Iteration 1240 (1.31676 iter/s, 30.3777s/40 iters), loss = 1.34605
I1030 05:48:39.327019  1046 solver.cpp:241]     Train net output #0: loss = 1.34605 (* 1 = 1.34605 loss)
I1030 05:48:39.327039  1046 sgd_solver.cpp:105] Iteration 1240, lr = 0.00857493
I1030 05:49:09.606515  1046 solver.cpp:222] Iteration 1280 (1.32108 iter/s, 30.2784s/40 iters), loss = 1.33218
I1030 05:49:09.606676  1046 solver.cpp:241]     Train net output #0: loss = 1.33218 (* 1 = 1.33218 loss)
I1030 05:49:09.606693  1046 sgd_solver.cpp:105] Iteration 1280, lr = 0.00853251
I1030 05:49:39.483785  1046 solver.cpp:222] Iteration 1320 (1.33887 iter/s, 29.876s/40 iters), loss = 1.53244
I1030 05:49:39.483847  1046 solver.cpp:241]     Train net output #0: loss = 1.53244 (* 1 = 1.53244 loss)
I1030 05:49:39.483862  1046 sgd_solver.cpp:105] Iteration 1320, lr = 0.0084903
I1030 05:50:10.295042  1046 solver.cpp:222] Iteration 1360 (1.29828 iter/s, 30.81s/40 iters), loss = 1.36096
I1030 05:50:10.295244  1046 solver.cpp:241]     Train net output #0: loss = 1.36096 (* 1 = 1.36096 loss)
I1030 05:50:10.295264  1046 sgd_solver.cpp:105] Iteration 1360, lr = 0.0084483
I1030 05:50:40.241338  1046 solver.cpp:222] Iteration 1400 (1.33578 iter/s, 29.945s/40 iters), loss = 1.36959
I1030 05:50:40.241405  1046 solver.cpp:241]     Train net output #0: loss = 1.36959 (* 1 = 1.36959 loss)
I1030 05:50:40.241446  1046 sgd_solver.cpp:105] Iteration 1400, lr = 0.0084065
I1030 05:51:10.737030  1046 solver.cpp:222] Iteration 1440 (1.31171 iter/s, 30.4945s/40 iters), loss = 1.51023
I1030 05:51:10.737287  1046 solver.cpp:241]     Train net output #0: loss = 1.51023 (* 1 = 1.51023 loss)
I1030 05:51:10.737313  1046 sgd_solver.cpp:105] Iteration 1440, lr = 0.00836491
I1030 05:51:40.915207  1046 solver.cpp:222] Iteration 1480 (1.32552 iter/s, 30.1768s/40 iters), loss = 1.53621
I1030 05:51:40.915401  1046 solver.cpp:241]     Train net output #0: loss = 1.53621 (* 1 = 1.53621 loss)
I1030 05:51:40.915421  1046 sgd_solver.cpp:105] Iteration 1480, lr = 0.00832353
I1030 05:51:55.289273  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_1500.caffemodel
I1030 05:51:55.330255  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_1500.solverstate
I1030 05:51:55.348843  1046 solver.cpp:334] Iteration 1500, Testing net (#0)
I1030 05:52:26.339107  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 05:52:26.548605  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57424
I1030 05:52:26.548656  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80528
I1030 05:52:26.548671  1046 solver.cpp:401]     Test net output #2: loss = 1.90951 (* 1 = 1.90951 loss)
I1030 05:52:42.522608  1046 solver.cpp:222] Iteration 1520 (0.649299 iter/s, 61.6049s/40 iters), loss = 1.60764
I1030 05:52:42.522678  1046 solver.cpp:241]     Train net output #0: loss = 1.60764 (* 1 = 1.60764 loss)
I1030 05:52:42.522696  1046 sgd_solver.cpp:105] Iteration 1520, lr = 0.00828236
I1030 05:53:13.117835  1046 solver.cpp:222] Iteration 1560 (1.30745 iter/s, 30.594s/40 iters), loss = 1.55623
I1030 05:53:13.118012  1046 solver.cpp:241]     Train net output #0: loss = 1.55623 (* 1 = 1.55623 loss)
I1030 05:53:13.118031  1046 sgd_solver.cpp:105] Iteration 1560, lr = 0.00824138
I1030 05:53:43.730957  1046 solver.cpp:222] Iteration 1600 (1.30669 iter/s, 30.6118s/40 iters), loss = 1.52979
I1030 05:53:43.731122  1046 solver.cpp:241]     Train net output #0: loss = 1.52979 (* 1 = 1.52979 loss)
I1030 05:53:43.731142  1046 sgd_solver.cpp:105] Iteration 1600, lr = 0.00820061
I1030 05:54:14.427325  1046 solver.cpp:222] Iteration 1640 (1.30314 iter/s, 30.695s/40 iters), loss = 1.47753
I1030 05:54:14.427508  1046 solver.cpp:241]     Train net output #0: loss = 1.47753 (* 1 = 1.47753 loss)
I1030 05:54:14.427528  1046 sgd_solver.cpp:105] Iteration 1640, lr = 0.00816004
I1030 05:54:44.890516  1046 solver.cpp:222] Iteration 1680 (1.31312 iter/s, 30.4619s/40 iters), loss = 1.42961
I1030 05:54:44.890693  1046 solver.cpp:241]     Train net output #0: loss = 1.42961 (* 1 = 1.42961 loss)
I1030 05:54:44.890712  1046 sgd_solver.cpp:105] Iteration 1680, lr = 0.00811967
I1030 05:55:15.425745  1046 solver.cpp:222] Iteration 1720 (1.31002 iter/s, 30.5339s/40 iters), loss = 1.17308
I1030 05:55:15.425946  1046 solver.cpp:241]     Train net output #0: loss = 1.17308 (* 1 = 1.17308 loss)
I1030 05:55:15.425966  1046 sgd_solver.cpp:105] Iteration 1720, lr = 0.0080795
I1030 05:55:45.720567  1046 solver.cpp:222] Iteration 1760 (1.32042 iter/s, 30.2935s/40 iters), loss = 1.47158
I1030 05:55:45.720769  1046 solver.cpp:241]     Train net output #0: loss = 1.47158 (* 1 = 1.47158 loss)
I1030 05:55:45.720799  1046 sgd_solver.cpp:105] Iteration 1760, lr = 0.00803953
I1030 05:56:15.895892  1046 solver.cpp:222] Iteration 1800 (1.32565 iter/s, 30.174s/40 iters), loss = 1.83543
I1030 05:56:15.896092  1046 solver.cpp:241]     Train net output #0: loss = 1.83543 (* 1 = 1.83543 loss)
I1030 05:56:15.896112  1046 sgd_solver.cpp:105] Iteration 1800, lr = 0.00799976
I1030 05:56:46.238246  1046 solver.cpp:222] Iteration 1840 (1.31835 iter/s, 30.341s/40 iters), loss = 1.41132
I1030 05:56:46.238448  1046 solver.cpp:241]     Train net output #0: loss = 1.41132 (* 1 = 1.41132 loss)
I1030 05:56:46.238467  1046 sgd_solver.cpp:105] Iteration 1840, lr = 0.00796018
I1030 05:57:16.079820  1046 solver.cpp:222] Iteration 1880 (1.34047 iter/s, 29.8402s/40 iters), loss = 1.46119
I1030 05:57:16.079897  1046 solver.cpp:241]     Train net output #0: loss = 1.46119 (* 1 = 1.46119 loss)
I1030 05:57:16.079916  1046 sgd_solver.cpp:105] Iteration 1880, lr = 0.0079208
I1030 05:57:46.364720  1046 solver.cpp:222] Iteration 1920 (1.32084 iter/s, 30.2837s/40 iters), loss = 1.4903
I1030 05:57:46.364956  1046 solver.cpp:241]     Train net output #0: loss = 1.4903 (* 1 = 1.4903 loss)
I1030 05:57:46.364984  1046 sgd_solver.cpp:105] Iteration 1920, lr = 0.00788162
I1030 05:58:16.726083  1046 solver.cpp:222] Iteration 1960 (1.31752 iter/s, 30.36s/40 iters), loss = 1.31993
I1030 05:58:16.726302  1046 solver.cpp:241]     Train net output #0: loss = 1.31993 (* 1 = 1.31993 loss)
I1030 05:58:16.726320  1046 sgd_solver.cpp:105] Iteration 1960, lr = 0.00784263
I1030 05:58:46.157728  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_2000.caffemodel
I1030 05:58:46.192031  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_2000.solverstate
I1030 05:58:46.209949  1046 solver.cpp:334] Iteration 2000, Testing net (#0)
I1030 05:59:17.449816  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57856
I1030 05:59:17.450009  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8032
I1030 05:59:17.450024  1046 solver.cpp:401]     Test net output #2: loss = 1.88398 (* 1 = 1.88398 loss)
I1030 05:59:18.218956  1046 solver.cpp:222] Iteration 2000 (0.650509 iter/s, 61.4904s/40 iters), loss = 1.30483
I1030 05:59:18.219008  1046 solver.cpp:241]     Train net output #0: loss = 1.30483 (* 1 = 1.30483 loss)
I1030 05:59:18.219023  1046 sgd_solver.cpp:105] Iteration 2000, lr = 0.00780383
I1030 05:59:48.712761  1046 solver.cpp:222] Iteration 2040 (1.31179 iter/s, 30.4926s/40 iters), loss = 1.6221
I1030 05:59:48.712946  1046 solver.cpp:241]     Train net output #0: loss = 1.6221 (* 1 = 1.6221 loss)
I1030 05:59:48.712965  1046 sgd_solver.cpp:105] Iteration 2040, lr = 0.00776522
I1030 06:00:19.778194  1046 solver.cpp:222] Iteration 2080 (1.28766 iter/s, 31.0641s/40 iters), loss = 1.74775
I1030 06:00:19.778420  1046 solver.cpp:241]     Train net output #0: loss = 1.74775 (* 1 = 1.74775 loss)
I1030 06:00:19.778437  1046 sgd_solver.cpp:105] Iteration 2080, lr = 0.00772681
I1030 06:00:50.596410  1046 solver.cpp:222] Iteration 2120 (1.29799 iter/s, 30.8168s/40 iters), loss = 1.23267
I1030 06:00:50.596595  1046 solver.cpp:241]     Train net output #0: loss = 1.23267 (* 1 = 1.23267 loss)
I1030 06:00:50.596611  1046 sgd_solver.cpp:105] Iteration 2120, lr = 0.00768858
I1030 06:01:22.811054  1046 solver.cpp:222] Iteration 2160 (1.24173 iter/s, 32.2132s/40 iters), loss = 1.33167
I1030 06:01:22.811328  1046 solver.cpp:241]     Train net output #0: loss = 1.33167 (* 1 = 1.33167 loss)
I1030 06:01:22.811357  1046 sgd_solver.cpp:105] Iteration 2160, lr = 0.00765054
I1030 06:01:54.783972  1046 solver.cpp:222] Iteration 2200 (1.25112 iter/s, 31.9714s/40 iters), loss = 1.59643
I1030 06:01:54.784211  1046 solver.cpp:241]     Train net output #0: loss = 1.59643 (* 1 = 1.59643 loss)
I1030 06:01:54.784242  1046 sgd_solver.cpp:105] Iteration 2200, lr = 0.0076127
I1030 06:02:13.927909  1099 blocking_queue.cpp:49] Waiting for data
I1030 06:02:51.663306  1046 solver.cpp:222] Iteration 2240 (0.703272 iter/s, 56.877s/40 iters), loss = 1.52518
I1030 06:02:51.663552  1046 solver.cpp:241]     Train net output #0: loss = 1.52518 (* 1 = 1.52518 loss)
I1030 06:02:51.663573  1046 sgd_solver.cpp:105] Iteration 2240, lr = 0.00757503
I1030 06:03:25.242384  1046 solver.cpp:222] Iteration 2280 (1.19127 iter/s, 33.5776s/40 iters), loss = 1.20917
I1030 06:03:25.242650  1046 solver.cpp:241]     Train net output #0: loss = 1.20917 (* 1 = 1.20917 loss)
I1030 06:03:25.242683  1046 sgd_solver.cpp:105] Iteration 2280, lr = 0.00753756
I1030 06:03:56.621512  1046 solver.cpp:222] Iteration 2320 (1.27479 iter/s, 31.3777s/40 iters), loss = 1.49929
I1030 06:03:56.621752  1046 solver.cpp:241]     Train net output #0: loss = 1.49929 (* 1 = 1.49929 loss)
I1030 06:03:56.621784  1046 sgd_solver.cpp:105] Iteration 2320, lr = 0.00750027
I1030 06:04:38.015218  1046 solver.cpp:222] Iteration 2360 (0.966372 iter/s, 41.3919s/40 iters), loss = 1.24931
I1030 06:04:38.015457  1046 solver.cpp:241]     Train net output #0: loss = 1.24931 (* 1 = 1.24931 loss)
I1030 06:04:38.015476  1046 sgd_solver.cpp:105] Iteration 2360, lr = 0.00746317
I1030 06:05:08.964434  1046 solver.cpp:222] Iteration 2400 (1.2925 iter/s, 30.9478s/40 iters), loss = 1.25558
I1030 06:05:08.964654  1046 solver.cpp:241]     Train net output #0: loss = 1.25558 (* 1 = 1.25558 loss)
I1030 06:05:08.964684  1046 sgd_solver.cpp:105] Iteration 2400, lr = 0.00742624
I1030 06:05:40.400627  1046 solver.cpp:222] Iteration 2440 (1.27248 iter/s, 31.4348s/40 iters), loss = 1.75116
I1030 06:05:40.400812  1046 solver.cpp:241]     Train net output #0: loss = 1.75116 (* 1 = 1.75116 loss)
I1030 06:05:40.400830  1046 sgd_solver.cpp:105] Iteration 2440, lr = 0.00738951
I1030 06:06:11.353668  1046 solver.cpp:222] Iteration 2480 (1.29234 iter/s, 30.9517s/40 iters), loss = 1.51505
I1030 06:06:11.353863  1046 solver.cpp:241]     Train net output #0: loss = 1.51505 (* 1 = 1.51505 loss)
I1030 06:06:11.353878  1046 sgd_solver.cpp:105] Iteration 2480, lr = 0.00735295
I1030 06:06:25.332944  1096 data_layer.cpp:73] Restarting data prefetching from start.
I1030 06:06:25.977079  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_2500.caffemodel
I1030 06:06:26.010416  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_2500.solverstate
I1030 06:06:26.028466  1046 solver.cpp:334] Iteration 2500, Testing net (#0)
I1030 06:06:56.775264  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 06:06:56.981881  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57376
I1030 06:06:56.981935  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80528
I1030 06:06:56.981948  1046 solver.cpp:401]     Test net output #2: loss = 1.87552 (* 1 = 1.87552 loss)
I1030 06:07:12.934882  1046 solver.cpp:222] Iteration 2520 (0.649575 iter/s, 61.5787s/40 iters), loss = 1.64474
I1030 06:07:12.934948  1046 solver.cpp:241]     Train net output #0: loss = 1.64474 (* 1 = 1.64474 loss)
I1030 06:07:12.934967  1046 sgd_solver.cpp:105] Iteration 2520, lr = 0.00731657
I1030 06:07:43.301798  1046 solver.cpp:222] Iteration 2560 (1.31728 iter/s, 30.3657s/40 iters), loss = 1.25779
I1030 06:07:43.301981  1046 solver.cpp:241]     Train net output #0: loss = 1.25779 (* 1 = 1.25779 loss)
I1030 06:07:43.302000  1046 sgd_solver.cpp:105] Iteration 2560, lr = 0.00728038
I1030 06:08:13.724405  1046 solver.cpp:222] Iteration 2600 (1.31487 iter/s, 30.4213s/40 iters), loss = 1.51922
I1030 06:08:13.724584  1046 solver.cpp:241]     Train net output #0: loss = 1.51922 (* 1 = 1.51922 loss)
I1030 06:08:13.724601  1046 sgd_solver.cpp:105] Iteration 2600, lr = 0.00724436
I1030 06:08:44.163503  1046 solver.cpp:222] Iteration 2640 (1.31416 iter/s, 30.4378s/40 iters), loss = 1.58922
I1030 06:08:44.163672  1046 solver.cpp:241]     Train net output #0: loss = 1.58922 (* 1 = 1.58922 loss)
I1030 06:08:44.163770  1046 sgd_solver.cpp:105] Iteration 2640, lr = 0.00720852
I1030 06:09:14.596047  1046 solver.cpp:222] Iteration 2680 (1.31444 iter/s, 30.4312s/40 iters), loss = 1.19083
I1030 06:09:14.596212  1046 solver.cpp:241]     Train net output #0: loss = 1.19083 (* 1 = 1.19083 loss)
I1030 06:09:14.596232  1046 sgd_solver.cpp:105] Iteration 2680, lr = 0.00717286
I1030 06:09:45.060755  1046 solver.cpp:222] Iteration 2720 (1.31305 iter/s, 30.4634s/40 iters), loss = 1.27635
I1030 06:09:45.060925  1046 solver.cpp:241]     Train net output #0: loss = 1.27635 (* 1 = 1.27635 loss)
I1030 06:09:45.060946  1046 sgd_solver.cpp:105] Iteration 2720, lr = 0.00713737
I1030 06:10:15.534919  1046 solver.cpp:222] Iteration 2760 (1.31264 iter/s, 30.4728s/40 iters), loss = 1.64503
I1030 06:10:15.535162  1046 solver.cpp:241]     Train net output #0: loss = 1.64503 (* 1 = 1.64503 loss)
I1030 06:10:15.535198  1046 sgd_solver.cpp:105] Iteration 2760, lr = 0.00710206
I1030 06:10:46.030377  1046 solver.cpp:222] Iteration 2800 (1.31173 iter/s, 30.4941s/40 iters), loss = 1.27572
I1030 06:10:46.030581  1046 solver.cpp:241]     Train net output #0: loss = 1.27572 (* 1 = 1.27572 loss)
I1030 06:10:46.030598  1046 sgd_solver.cpp:105] Iteration 2800, lr = 0.00706693
I1030 06:11:16.464746  1046 solver.cpp:222] Iteration 2840 (1.31436 iter/s, 30.433s/40 iters), loss = 1.35174
I1030 06:11:16.464934  1046 solver.cpp:241]     Train net output #0: loss = 1.35174 (* 1 = 1.35174 loss)
I1030 06:11:16.464951  1046 sgd_solver.cpp:105] Iteration 2840, lr = 0.00703197
I1030 06:11:47.268592  1046 solver.cpp:222] Iteration 2880 (1.2986 iter/s, 30.8025s/40 iters), loss = 1.36376
I1030 06:11:47.268795  1046 solver.cpp:241]     Train net output #0: loss = 1.36376 (* 1 = 1.36376 loss)
I1030 06:11:47.268813  1046 sgd_solver.cpp:105] Iteration 2880, lr = 0.00699718
I1030 06:12:19.062934  1046 solver.cpp:222] Iteration 2920 (1.25814 iter/s, 31.7929s/40 iters), loss = 1.31611
I1030 06:12:19.063103  1046 solver.cpp:241]     Train net output #0: loss = 1.31611 (* 1 = 1.31611 loss)
I1030 06:12:19.063120  1046 sgd_solver.cpp:105] Iteration 2920, lr = 0.00696256
I1030 06:12:49.739115  1046 solver.cpp:222] Iteration 2960 (1.304 iter/s, 30.6749s/40 iters), loss = 1.4692
I1030 06:12:49.739284  1046 solver.cpp:241]     Train net output #0: loss = 1.4692 (* 1 = 1.4692 loss)
I1030 06:12:49.739306  1046 sgd_solver.cpp:105] Iteration 2960, lr = 0.00692812
I1030 06:13:19.901212  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_3000.caffemodel
I1030 06:13:19.956598  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_3000.solverstate
I1030 06:13:19.991492  1046 solver.cpp:334] Iteration 3000, Testing net (#0)
I1030 06:13:51.237017  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57744
I1030 06:13:51.237174  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80236
I1030 06:13:51.237190  1046 solver.cpp:401]     Test net output #2: loss = 1.89382 (* 1 = 1.89382 loss)
I1030 06:13:51.998769  1046 solver.cpp:222] Iteration 3000 (0.642496 iter/s, 62.2572s/40 iters), loss = 1.91617
I1030 06:13:51.998827  1046 solver.cpp:241]     Train net output #0: loss = 1.91617 (* 1 = 1.91617 loss)
I1030 06:13:51.998843  1046 sgd_solver.cpp:105] Iteration 3000, lr = 0.00689385
I1030 06:14:22.890650  1046 solver.cpp:222] Iteration 3040 (1.29489 iter/s, 30.8907s/40 iters), loss = 1.50937
I1030 06:14:22.890842  1046 solver.cpp:241]     Train net output #0: loss = 1.50937 (* 1 = 1.50937 loss)
I1030 06:14:22.890861  1046 sgd_solver.cpp:105] Iteration 3040, lr = 0.00685974
I1030 06:14:53.204471  1046 solver.cpp:222] Iteration 3080 (1.31959 iter/s, 30.3125s/40 iters), loss = 1.29458
I1030 06:14:53.204663  1046 solver.cpp:241]     Train net output #0: loss = 1.29458 (* 1 = 1.29458 loss)
I1030 06:14:53.204680  1046 sgd_solver.cpp:105] Iteration 3080, lr = 0.0068258
I1030 06:15:23.612782  1046 solver.cpp:222] Iteration 3120 (1.31549 iter/s, 30.407s/40 iters), loss = 1.43508
I1030 06:15:23.612936  1046 solver.cpp:241]     Train net output #0: loss = 1.43508 (* 1 = 1.43508 loss)
I1030 06:15:23.612952  1046 sgd_solver.cpp:105] Iteration 3120, lr = 0.00679204
I1030 06:15:53.999202  1046 solver.cpp:222] Iteration 3160 (1.31643 iter/s, 30.3851s/40 iters), loss = 1.53515
I1030 06:15:53.999385  1046 solver.cpp:241]     Train net output #0: loss = 1.53515 (* 1 = 1.53515 loss)
I1030 06:15:53.999408  1046 sgd_solver.cpp:105] Iteration 3160, lr = 0.00675844
I1030 06:16:24.298362  1046 solver.cpp:222] Iteration 3200 (1.32023 iter/s, 30.2978s/40 iters), loss = 1.5802
I1030 06:16:24.298516  1046 solver.cpp:241]     Train net output #0: loss = 1.5802 (* 1 = 1.5802 loss)
I1030 06:16:24.298532  1046 sgd_solver.cpp:105] Iteration 3200, lr = 0.006725
I1030 06:16:54.619063  1046 solver.cpp:222] Iteration 3240 (1.31929 iter/s, 30.3193s/40 iters), loss = 1.76015
I1030 06:16:54.619334  1046 solver.cpp:241]     Train net output #0: loss = 1.76015 (* 1 = 1.76015 loss)
I1030 06:16:54.619354  1046 sgd_solver.cpp:105] Iteration 3240, lr = 0.00669173
I1030 06:17:25.402572  1046 solver.cpp:222] Iteration 3280 (1.29946 iter/s, 30.7821s/40 iters), loss = 1.7067
I1030 06:17:25.402775  1046 solver.cpp:241]     Train net output #0: loss = 1.7067 (* 1 = 1.7067 loss)
I1030 06:17:25.402791  1046 sgd_solver.cpp:105] Iteration 3280, lr = 0.00665863
I1030 06:17:56.620038  1046 solver.cpp:222] Iteration 3320 (1.28139 iter/s, 31.2161s/40 iters), loss = 1.47828
I1030 06:17:56.620249  1046 solver.cpp:241]     Train net output #0: loss = 1.47828 (* 1 = 1.47828 loss)
I1030 06:17:56.620265  1046 sgd_solver.cpp:105] Iteration 3320, lr = 0.00662568
I1030 06:18:27.038516  1046 solver.cpp:222] Iteration 3360 (1.31505 iter/s, 30.4171s/40 iters), loss = 1.50075
I1030 06:18:27.038692  1046 solver.cpp:241]     Train net output #0: loss = 1.50075 (* 1 = 1.50075 loss)
I1030 06:18:27.038710  1046 sgd_solver.cpp:105] Iteration 3360, lr = 0.00659291
I1030 06:18:57.696107  1046 solver.cpp:222] Iteration 3400 (1.30479 iter/s, 30.6563s/40 iters), loss = 1.48888
I1030 06:18:57.696342  1046 solver.cpp:241]     Train net output #0: loss = 1.48888 (* 1 = 1.48888 loss)
I1030 06:18:57.696373  1046 sgd_solver.cpp:105] Iteration 3400, lr = 0.00656029
I1030 06:19:28.876132  1046 solver.cpp:222] Iteration 3440 (1.28293 iter/s, 31.1786s/40 iters), loss = 1.42216
I1030 06:19:28.876317  1046 solver.cpp:241]     Train net output #0: loss = 1.42216 (* 1 = 1.42216 loss)
I1030 06:19:28.876333  1046 sgd_solver.cpp:105] Iteration 3440, lr = 0.00652784
I1030 06:20:00.069588  1046 solver.cpp:222] Iteration 3480 (1.28238 iter/s, 31.1921s/40 iters), loss = 1.29606
I1030 06:20:00.069774  1046 solver.cpp:241]     Train net output #0: loss = 1.29606 (* 1 = 1.29606 loss)
I1030 06:20:00.069792  1046 sgd_solver.cpp:105] Iteration 3480, lr = 0.00649554
I1030 06:20:14.661059  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_3500.caffemodel
I1030 06:20:14.706955  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_3500.solverstate
I1030 06:20:14.729912  1046 solver.cpp:334] Iteration 3500, Testing net (#0)
I1030 06:20:45.559586  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 06:20:45.766652  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57704
I1030 06:20:45.766710  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80856
I1030 06:20:45.766724  1046 solver.cpp:401]     Test net output #2: loss = 1.87583 (* 1 = 1.87583 loss)
I1030 06:21:02.140681  1046 solver.cpp:222] Iteration 3520 (0.644448 iter/s, 62.0686s/40 iters), loss = 1.43205
I1030 06:21:02.140746  1046 solver.cpp:241]     Train net output #0: loss = 1.43205 (* 1 = 1.43205 loss)
I1030 06:21:02.140761  1046 sgd_solver.cpp:105] Iteration 3520, lr = 0.00646341
I1030 06:21:32.585067  1046 solver.cpp:222] Iteration 3560 (1.31392 iter/s, 30.4432s/40 iters), loss = 1.45586
I1030 06:21:32.585263  1046 solver.cpp:241]     Train net output #0: loss = 1.45586 (* 1 = 1.45586 loss)
I1030 06:21:32.585279  1046 sgd_solver.cpp:105] Iteration 3560, lr = 0.00643143
I1030 06:22:03.520282  1046 solver.cpp:222] Iteration 3600 (1.29308 iter/s, 30.9339s/40 iters), loss = 1.81637
I1030 06:22:03.520473  1046 solver.cpp:241]     Train net output #0: loss = 1.81637 (* 1 = 1.81637 loss)
I1030 06:22:03.520493  1046 sgd_solver.cpp:105] Iteration 3600, lr = 0.00639961
I1030 06:22:34.266975  1046 solver.cpp:222] Iteration 3640 (1.30101 iter/s, 30.7453s/40 iters), loss = 1.52571
I1030 06:22:34.267156  1046 solver.cpp:241]     Train net output #0: loss = 1.52571 (* 1 = 1.52571 loss)
I1030 06:22:34.267180  1046 sgd_solver.cpp:105] Iteration 3640, lr = 0.00636796
I1030 06:23:04.904175  1046 solver.cpp:222] Iteration 3680 (1.30566 iter/s, 30.6359s/40 iters), loss = 1.09891
I1030 06:23:04.904419  1046 solver.cpp:241]     Train net output #0: loss = 1.09891 (* 1 = 1.09891 loss)
I1030 06:23:04.904453  1046 sgd_solver.cpp:105] Iteration 3680, lr = 0.00633645
I1030 06:23:35.513433  1046 solver.cpp:222] Iteration 3720 (1.30685 iter/s, 30.6079s/40 iters), loss = 1.58548
I1030 06:23:35.513594  1046 solver.cpp:241]     Train net output #0: loss = 1.58548 (* 1 = 1.58548 loss)
I1030 06:23:35.513612  1046 sgd_solver.cpp:105] Iteration 3720, lr = 0.0063051
I1030 06:24:06.121079  1046 solver.cpp:222] Iteration 3760 (1.30692 iter/s, 30.6063s/40 iters), loss = 1.22321
I1030 06:24:06.121235  1046 solver.cpp:241]     Train net output #0: loss = 1.22321 (* 1 = 1.22321 loss)
I1030 06:24:06.121256  1046 sgd_solver.cpp:105] Iteration 3760, lr = 0.00627391
I1030 06:24:36.751024  1046 solver.cpp:222] Iteration 3800 (1.30597 iter/s, 30.6286s/40 iters), loss = 1.26405
I1030 06:24:36.751236  1046 solver.cpp:241]     Train net output #0: loss = 1.26405 (* 1 = 1.26405 loss)
I1030 06:24:36.751252  1046 sgd_solver.cpp:105] Iteration 3800, lr = 0.00624287
I1030 06:25:07.452870  1046 solver.cpp:222] Iteration 3840 (1.30291 iter/s, 30.7005s/40 iters), loss = 1.16116
I1030 06:25:07.453030  1046 solver.cpp:241]     Train net output #0: loss = 1.16116 (* 1 = 1.16116 loss)
I1030 06:25:07.453048  1046 sgd_solver.cpp:105] Iteration 3840, lr = 0.00621199
I1030 06:25:38.279187  1046 solver.cpp:222] Iteration 3880 (1.29765 iter/s, 30.825s/40 iters), loss = 1.64211
I1030 06:25:38.279364  1046 solver.cpp:241]     Train net output #0: loss = 1.64211 (* 1 = 1.64211 loss)
I1030 06:25:38.279381  1046 sgd_solver.cpp:105] Iteration 3880, lr = 0.00618126
I1030 06:26:08.960808  1046 solver.cpp:222] Iteration 3920 (1.30377 iter/s, 30.6803s/40 iters), loss = 1.30069
I1030 06:26:08.960965  1046 solver.cpp:241]     Train net output #0: loss = 1.30069 (* 1 = 1.30069 loss)
I1030 06:26:08.960981  1046 sgd_solver.cpp:105] Iteration 3920, lr = 0.00615068
I1030 06:26:39.499058  1046 solver.cpp:222] Iteration 3960 (1.30989 iter/s, 30.5369s/40 iters), loss = 1.35059
I1030 06:26:39.499243  1046 solver.cpp:241]     Train net output #0: loss = 1.35059 (* 1 = 1.35059 loss)
I1030 06:26:39.499260  1046 sgd_solver.cpp:105] Iteration 3960, lr = 0.00612025
I1030 06:27:09.545761  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_4000.caffemodel
I1030 06:27:09.583840  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_4000.solverstate
I1030 06:27:09.606982  1046 solver.cpp:334] Iteration 4000, Testing net (#0)
I1030 06:27:40.559870  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57952
I1030 06:27:40.560045  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80436
I1030 06:27:40.560061  1046 solver.cpp:401]     Test net output #2: loss = 1.8702 (* 1 = 1.8702 loss)
I1030 06:27:41.323499  1046 solver.cpp:222] Iteration 4000 (0.647019 iter/s, 61.822s/40 iters), loss = 1.14795
I1030 06:27:41.323560  1046 solver.cpp:241]     Train net output #0: loss = 1.14795 (* 1 = 1.14795 loss)
I1030 06:27:41.323577  1046 sgd_solver.cpp:105] Iteration 4000, lr = 0.00608997
I1030 06:28:11.713186  1046 solver.cpp:222] Iteration 4040 (1.31629 iter/s, 30.3885s/40 iters), loss = 1.54908
I1030 06:28:11.713409  1046 solver.cpp:241]     Train net output #0: loss = 1.54908 (* 1 = 1.54908 loss)
I1030 06:28:11.713433  1046 sgd_solver.cpp:105] Iteration 4040, lr = 0.00605985
I1030 06:28:41.990314  1046 solver.cpp:222] Iteration 4080 (1.32119 iter/s, 30.2758s/40 iters), loss = 1.48658
I1030 06:28:41.990484  1046 solver.cpp:241]     Train net output #0: loss = 1.48658 (* 1 = 1.48658 loss)
I1030 06:28:41.990501  1046 sgd_solver.cpp:105] Iteration 4080, lr = 0.00602987
I1030 06:29:12.733400  1046 solver.cpp:222] Iteration 4120 (1.30116 iter/s, 30.7417s/40 iters), loss = 1.54622
I1030 06:29:12.733626  1046 solver.cpp:241]     Train net output #0: loss = 1.54622 (* 1 = 1.54622 loss)
I1030 06:29:12.733656  1046 sgd_solver.cpp:105] Iteration 4120, lr = 0.00600004
I1030 06:29:57.796783  1046 solver.cpp:222] Iteration 4160 (0.887676 iter/s, 45.0615s/40 iters), loss = 1.45136
I1030 06:29:57.797036  1046 solver.cpp:241]     Train net output #0: loss = 1.45136 (* 1 = 1.45136 loss)
I1030 06:29:57.797055  1046 sgd_solver.cpp:105] Iteration 4160, lr = 0.00597035
I1030 06:30:30.370685  1046 solver.cpp:222] Iteration 4200 (1.22803 iter/s, 32.5724s/40 iters), loss = 1.2267
I1030 06:30:30.370905  1046 solver.cpp:241]     Train net output #0: loss = 1.2267 (* 1 = 1.2267 loss)
I1030 06:30:30.370924  1046 sgd_solver.cpp:105] Iteration 4200, lr = 0.00594082
I1030 06:31:15.673553  1046 solver.cpp:222] Iteration 4240 (0.882984 iter/s, 45.3009s/40 iters), loss = 1.39925
I1030 06:31:15.673816  1046 solver.cpp:241]     Train net output #0: loss = 1.39925 (* 1 = 1.39925 loss)
I1030 06:31:15.673846  1046 sgd_solver.cpp:105] Iteration 4240, lr = 0.00591143
I1030 06:31:46.644654  1046 solver.cpp:222] Iteration 4280 (1.29159 iter/s, 30.9697s/40 iters), loss = 1.25675
I1030 06:31:46.644858  1046 solver.cpp:241]     Train net output #0: loss = 1.25675 (* 1 = 1.25675 loss)
I1030 06:31:46.644876  1046 sgd_solver.cpp:105] Iteration 4280, lr = 0.00588218
I1030 06:32:18.063232  1046 solver.cpp:222] Iteration 4320 (1.27319 iter/s, 31.4172s/40 iters), loss = 1.3668
I1030 06:32:18.063503  1046 solver.cpp:241]     Train net output #0: loss = 1.3668 (* 1 = 1.3668 loss)
I1030 06:32:18.063530  1046 sgd_solver.cpp:105] Iteration 4320, lr = 0.00585308
I1030 06:32:50.168076  1046 solver.cpp:222] Iteration 4360 (1.24598 iter/s, 32.1034s/40 iters), loss = 1.43694
I1030 06:32:50.168268  1046 solver.cpp:241]     Train net output #0: loss = 1.43694 (* 1 = 1.43694 loss)
I1030 06:32:50.168285  1046 sgd_solver.cpp:105] Iteration 4360, lr = 0.00582413
I1030 06:33:21.683346  1046 solver.cpp:222] Iteration 4400 (1.26928 iter/s, 31.5139s/40 iters), loss = 1.53023
I1030 06:33:21.683578  1046 solver.cpp:241]     Train net output #0: loss = 1.53023 (* 1 = 1.53023 loss)
I1030 06:33:21.683598  1046 sgd_solver.cpp:105] Iteration 4400, lr = 0.00579531
I1030 06:33:52.807703  1046 solver.cpp:222] Iteration 4440 (1.28523 iter/s, 31.1229s/40 iters), loss = 1.3255
I1030 06:33:52.807893  1046 solver.cpp:241]     Train net output #0: loss = 1.3255 (* 1 = 1.3255 loss)
I1030 06:33:52.807910  1046 sgd_solver.cpp:105] Iteration 4440, lr = 0.00576664
I1030 06:34:23.447523  1046 solver.cpp:222] Iteration 4480 (1.30555 iter/s, 30.6385s/40 iters), loss = 1.12679
I1030 06:34:23.447727  1046 solver.cpp:241]     Train net output #0: loss = 1.12679 (* 1 = 1.12679 loss)
I1030 06:34:23.447743  1046 sgd_solver.cpp:105] Iteration 4480, lr = 0.00573811
I1030 06:34:38.146877  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_4500.caffemodel
I1030 06:34:38.178174  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_4500.solverstate
I1030 06:34:38.200318  1046 solver.cpp:334] Iteration 4500, Testing net (#0)
I1030 06:35:09.006191  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 06:35:09.212608  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57808
I1030 06:35:09.212669  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.808919
I1030 06:35:09.212683  1046 solver.cpp:401]     Test net output #2: loss = 1.89078 (* 1 = 1.89078 loss)
I1030 06:35:25.278108  1046 solver.cpp:222] Iteration 4520 (0.646955 iter/s, 61.8281s/40 iters), loss = 1.39905
I1030 06:35:25.278182  1046 solver.cpp:241]     Train net output #0: loss = 1.39905 (* 1 = 1.39905 loss)
I1030 06:35:25.278199  1046 sgd_solver.cpp:105] Iteration 4520, lr = 0.00570973
I1030 06:35:56.164117  1046 solver.cpp:222] Iteration 4560 (1.29514 iter/s, 30.8848s/40 iters), loss = 1.38048
I1030 06:35:56.164314  1046 solver.cpp:241]     Train net output #0: loss = 1.38048 (* 1 = 1.38048 loss)
I1030 06:35:56.164332  1046 sgd_solver.cpp:105] Iteration 4560, lr = 0.00568148
I1030 06:36:27.092286  1046 solver.cpp:222] Iteration 4600 (1.29338 iter/s, 30.9268s/40 iters), loss = 1.51772
I1030 06:36:27.092541  1046 solver.cpp:241]     Train net output #0: loss = 1.51772 (* 1 = 1.51772 loss)
I1030 06:36:27.092561  1046 sgd_solver.cpp:105] Iteration 4600, lr = 0.00565337
I1030 06:36:58.151876  1046 solver.cpp:222] Iteration 4640 (1.28791 iter/s, 31.0581s/40 iters), loss = 1.79335
I1030 06:36:58.152062  1046 solver.cpp:241]     Train net output #0: loss = 1.79335 (* 1 = 1.79335 loss)
I1030 06:36:58.152082  1046 sgd_solver.cpp:105] Iteration 4640, lr = 0.00562541
I1030 06:37:29.003043  1046 solver.cpp:222] Iteration 4680 (1.2966 iter/s, 30.8498s/40 iters), loss = 1.51939
I1030 06:37:29.003228  1046 solver.cpp:241]     Train net output #0: loss = 1.51939 (* 1 = 1.51939 loss)
I1030 06:37:29.003247  1046 sgd_solver.cpp:105] Iteration 4680, lr = 0.00559758
I1030 06:38:00.010627  1046 solver.cpp:222] Iteration 4720 (1.29006 iter/s, 31.0062s/40 iters), loss = 1.41274
I1030 06:38:00.010819  1046 solver.cpp:241]     Train net output #0: loss = 1.41274 (* 1 = 1.41274 loss)
I1030 06:38:00.010836  1046 sgd_solver.cpp:105] Iteration 4720, lr = 0.00556988
I1030 06:38:30.960351  1046 solver.cpp:222] Iteration 4760 (1.29248 iter/s, 30.9484s/40 iters), loss = 1.25618
I1030 06:38:30.960558  1046 solver.cpp:241]     Train net output #0: loss = 1.25618 (* 1 = 1.25618 loss)
I1030 06:38:30.960580  1046 sgd_solver.cpp:105] Iteration 4760, lr = 0.00554233
I1030 06:39:01.744770  1046 solver.cpp:222] Iteration 4800 (1.29942 iter/s, 30.783s/40 iters), loss = 1.5661
I1030 06:39:01.744976  1046 solver.cpp:241]     Train net output #0: loss = 1.5661 (* 1 = 1.5661 loss)
I1030 06:39:01.744992  1046 sgd_solver.cpp:105] Iteration 4800, lr = 0.00551491
I1030 06:39:32.444785  1046 solver.cpp:222] Iteration 4840 (1.30299 iter/s, 30.6987s/40 iters), loss = 1.38349
I1030 06:39:32.444972  1046 solver.cpp:241]     Train net output #0: loss = 1.38349 (* 1 = 1.38349 loss)
I1030 06:39:32.444989  1046 sgd_solver.cpp:105] Iteration 4840, lr = 0.00548763
I1030 06:40:03.099733  1046 solver.cpp:222] Iteration 4880 (1.3049 iter/s, 30.6536s/40 iters), loss = 1.83472
I1030 06:40:03.099925  1046 solver.cpp:241]     Train net output #0: loss = 1.83472 (* 1 = 1.83472 loss)
I1030 06:40:03.099942  1046 sgd_solver.cpp:105] Iteration 4880, lr = 0.00546048
I1030 06:40:33.513007  1046 solver.cpp:222] Iteration 4920 (1.31527 iter/s, 30.4119s/40 iters), loss = 1.16074
I1030 06:40:33.513180  1046 solver.cpp:241]     Train net output #0: loss = 1.16074 (* 1 = 1.16074 loss)
I1030 06:40:33.513196  1046 sgd_solver.cpp:105] Iteration 4920, lr = 0.00543347
I1030 06:41:04.246229  1046 solver.cpp:222] Iteration 4960 (1.30158 iter/s, 30.7319s/40 iters), loss = 1.39563
I1030 06:41:04.246419  1046 solver.cpp:241]     Train net output #0: loss = 1.39563 (* 1 = 1.39563 loss)
I1030 06:41:04.246436  1046 sgd_solver.cpp:105] Iteration 4960, lr = 0.00540659
I1030 06:41:33.966246  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_5000.caffemodel
I1030 06:41:34.000921  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_5000.solverstate
I1030 06:41:34.027555  1046 solver.cpp:334] Iteration 5000, Testing net (#0)
I1030 06:42:05.021432  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58108
I1030 06:42:05.021630  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80432
I1030 06:42:05.021646  1046 solver.cpp:401]     Test net output #2: loss = 1.84746 (* 1 = 1.84746 loss)
I1030 06:42:05.792606  1046 solver.cpp:222] Iteration 5000 (0.649943 iter/s, 61.5439s/40 iters), loss = 1.74584
I1030 06:42:05.792670  1046 solver.cpp:241]     Train net output #0: loss = 1.74584 (* 1 = 1.74584 loss)
I1030 06:42:05.792687  1046 sgd_solver.cpp:105] Iteration 5000, lr = 0.00537984
I1030 06:42:05.878406  1096 data_layer.cpp:73] Restarting data prefetching from start.
I1030 06:42:36.256464  1046 solver.cpp:222] Iteration 5040 (1.31308 iter/s, 30.4626s/40 iters), loss = 1.40087
I1030 06:42:36.256770  1046 solver.cpp:241]     Train net output #0: loss = 1.40087 (* 1 = 1.40087 loss)
I1030 06:42:36.256829  1046 sgd_solver.cpp:105] Iteration 5040, lr = 0.00535322
I1030 06:43:06.827253  1046 solver.cpp:222] Iteration 5080 (1.3085 iter/s, 30.5693s/40 iters), loss = 1.495
I1030 06:43:06.827450  1046 solver.cpp:241]     Train net output #0: loss = 1.495 (* 1 = 1.495 loss)
I1030 06:43:06.827471  1046 sgd_solver.cpp:105] Iteration 5080, lr = 0.00532674
I1030 06:43:37.155366  1046 solver.cpp:222] Iteration 5120 (1.31897 iter/s, 30.3268s/40 iters), loss = 1.50055
I1030 06:43:37.155566  1046 solver.cpp:241]     Train net output #0: loss = 1.50055 (* 1 = 1.50055 loss)
I1030 06:43:37.155583  1046 sgd_solver.cpp:105] Iteration 5120, lr = 0.00530039
I1030 06:44:07.588008  1046 solver.cpp:222] Iteration 5160 (1.31444 iter/s, 30.4313s/40 iters), loss = 1.72344
I1030 06:44:07.588212  1046 solver.cpp:241]     Train net output #0: loss = 1.72344 (* 1 = 1.72344 loss)
I1030 06:44:07.588229  1046 sgd_solver.cpp:105] Iteration 5160, lr = 0.00527417
I1030 06:44:38.618101  1046 solver.cpp:222] Iteration 5200 (1.28913 iter/s, 31.0287s/40 iters), loss = 1.57827
I1030 06:44:38.618295  1046 solver.cpp:241]     Train net output #0: loss = 1.57827 (* 1 = 1.57827 loss)
I1030 06:44:38.618319  1046 sgd_solver.cpp:105] Iteration 5200, lr = 0.00524807
I1030 06:45:09.407138  1046 solver.cpp:222] Iteration 5240 (1.29922 iter/s, 30.7877s/40 iters), loss = 1.24781
I1030 06:45:09.407363  1046 solver.cpp:241]     Train net output #0: loss = 1.24781 (* 1 = 1.24781 loss)
I1030 06:45:09.407444  1046 sgd_solver.cpp:105] Iteration 5240, lr = 0.00522211
I1030 06:45:40.295403  1046 solver.cpp:222] Iteration 5280 (1.29505 iter/s, 30.8869s/40 iters), loss = 1.68769
I1030 06:45:40.295617  1046 solver.cpp:241]     Train net output #0: loss = 1.68769 (* 1 = 1.68769 loss)
I1030 06:45:40.295634  1046 sgd_solver.cpp:105] Iteration 5280, lr = 0.00519628
I1030 06:46:11.382683  1046 solver.cpp:222] Iteration 5320 (1.28676 iter/s, 31.0859s/40 iters), loss = 1.3107
I1030 06:46:11.382881  1046 solver.cpp:241]     Train net output #0: loss = 1.3107 (* 1 = 1.3107 loss)
I1030 06:46:11.382899  1046 sgd_solver.cpp:105] Iteration 5320, lr = 0.00517057
I1030 06:46:42.551668  1046 solver.cpp:222] Iteration 5360 (1.28338 iter/s, 31.1676s/40 iters), loss = 1.68549
I1030 06:46:42.551874  1046 solver.cpp:241]     Train net output #0: loss = 1.68549 (* 1 = 1.68549 loss)
I1030 06:46:42.551892  1046 sgd_solver.cpp:105] Iteration 5360, lr = 0.00514499
I1030 06:47:13.548868  1046 solver.cpp:222] Iteration 5400 (1.2905 iter/s, 30.9958s/40 iters), loss = 1.69561
I1030 06:47:13.549093  1046 solver.cpp:241]     Train net output #0: loss = 1.69561 (* 1 = 1.69561 loss)
I1030 06:47:13.549113  1046 sgd_solver.cpp:105] Iteration 5400, lr = 0.00511954
I1030 06:47:44.622001  1046 solver.cpp:222] Iteration 5440 (1.28734 iter/s, 31.0717s/40 iters), loss = 1.49429
I1030 06:47:44.622197  1046 solver.cpp:241]     Train net output #0: loss = 1.49429 (* 1 = 1.49429 loss)
I1030 06:47:44.622215  1046 sgd_solver.cpp:105] Iteration 5440, lr = 0.00509421
I1030 06:48:15.549782  1046 solver.cpp:222] Iteration 5480 (1.29339 iter/s, 30.9264s/40 iters), loss = 1.24146
I1030 06:48:15.549962  1046 solver.cpp:241]     Train net output #0: loss = 1.24146 (* 1 = 1.24146 loss)
I1030 06:48:15.549980  1046 sgd_solver.cpp:105] Iteration 5480, lr = 0.00506901
I1030 06:48:30.492182  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_5500.caffemodel
I1030 06:48:30.523636  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_5500.solverstate
I1030 06:48:30.540590  1046 solver.cpp:334] Iteration 5500, Testing net (#0)
I1030 06:49:01.260321  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 06:49:01.467675  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.57852
I1030 06:49:01.467734  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80824
I1030 06:49:01.467748  1046 solver.cpp:401]     Test net output #2: loss = 1.8842 (* 1 = 1.8842 loss)
I1030 06:49:17.719332  1046 solver.cpp:222] Iteration 5520 (0.643428 iter/s, 62.167s/40 iters), loss = 1.20043
I1030 06:49:17.719413  1046 solver.cpp:241]     Train net output #0: loss = 1.20043 (* 1 = 1.20043 loss)
I1030 06:49:17.719429  1046 sgd_solver.cpp:105] Iteration 5520, lr = 0.00504393
I1030 06:49:48.827198  1046 solver.cpp:222] Iteration 5560 (1.2859 iter/s, 31.1066s/40 iters), loss = 1.32144
I1030 06:49:48.827497  1046 solver.cpp:241]     Train net output #0: loss = 1.32144 (* 1 = 1.32144 loss)
I1030 06:49:48.827535  1046 sgd_solver.cpp:105] Iteration 5560, lr = 0.00501898
I1030 06:50:19.150171  1046 solver.cpp:222] Iteration 5600 (1.31919 iter/s, 30.3215s/40 iters), loss = 1.27492
I1030 06:50:19.150519  1046 solver.cpp:241]     Train net output #0: loss = 1.27492 (* 1 = 1.27492 loss)
I1030 06:50:19.150537  1046 sgd_solver.cpp:105] Iteration 5600, lr = 0.00499415
I1030 06:50:49.700400  1046 solver.cpp:222] Iteration 5640 (1.30938 iter/s, 30.5487s/40 iters), loss = 1.42129
I1030 06:50:49.700587  1046 solver.cpp:241]     Train net output #0: loss = 1.42129 (* 1 = 1.42129 loss)
I1030 06:50:49.700603  1046 sgd_solver.cpp:105] Iteration 5640, lr = 0.00496944
I1030 06:51:20.425503  1046 solver.cpp:222] Iteration 5680 (1.30192 iter/s, 30.7238s/40 iters), loss = 1.57872
I1030 06:51:20.425700  1046 solver.cpp:241]     Train net output #0: loss = 1.57872 (* 1 = 1.57872 loss)
I1030 06:51:20.425717  1046 sgd_solver.cpp:105] Iteration 5680, lr = 0.00494486
I1030 06:51:51.008648  1046 solver.cpp:222] Iteration 5720 (1.30797 iter/s, 30.5818s/40 iters), loss = 1.28444
I1030 06:51:51.008838  1046 solver.cpp:241]     Train net output #0: loss = 1.28444 (* 1 = 1.28444 loss)
I1030 06:51:51.008857  1046 sgd_solver.cpp:105] Iteration 5720, lr = 0.0049204
I1030 06:52:21.697206  1046 solver.cpp:222] Iteration 5760 (1.30347 iter/s, 30.6872s/40 iters), loss = 1.31102
I1030 06:52:21.697393  1046 solver.cpp:241]     Train net output #0: loss = 1.31102 (* 1 = 1.31102 loss)
I1030 06:52:21.697412  1046 sgd_solver.cpp:105] Iteration 5760, lr = 0.00489605
I1030 06:52:52.225925  1046 solver.cpp:222] Iteration 5800 (1.3103 iter/s, 30.5274s/40 iters), loss = 1.34924
I1030 06:52:52.226109  1046 solver.cpp:241]     Train net output #0: loss = 1.34924 (* 1 = 1.34924 loss)
I1030 06:52:52.226125  1046 sgd_solver.cpp:105] Iteration 5800, lr = 0.00487183
I1030 06:53:23.110659  1046 solver.cpp:222] Iteration 5840 (1.29519 iter/s, 30.8834s/40 iters), loss = 1.5558
I1030 06:53:23.110851  1046 solver.cpp:241]     Train net output #0: loss = 1.5558 (* 1 = 1.5558 loss)
I1030 06:53:23.110868  1046 sgd_solver.cpp:105] Iteration 5840, lr = 0.00484773
I1030 06:53:53.812414  1046 solver.cpp:222] Iteration 5880 (1.30291 iter/s, 30.7004s/40 iters), loss = 1.6023
I1030 06:53:53.812594  1046 solver.cpp:241]     Train net output #0: loss = 1.6023 (* 1 = 1.6023 loss)
I1030 06:53:53.812613  1046 sgd_solver.cpp:105] Iteration 5880, lr = 0.00482375
I1030 06:54:24.342520  1046 solver.cpp:222] Iteration 5920 (1.31024 iter/s, 30.5288s/40 iters), loss = 1.32946
I1030 06:54:24.342736  1046 solver.cpp:241]     Train net output #0: loss = 1.32946 (* 1 = 1.32946 loss)
I1030 06:54:24.342833  1046 sgd_solver.cpp:105] Iteration 5920, lr = 0.00479988
I1030 06:54:55.510877  1046 solver.cpp:222] Iteration 5960 (1.28341 iter/s, 31.167s/40 iters), loss = 1.44894
I1030 06:54:55.511085  1046 solver.cpp:241]     Train net output #0: loss = 1.44894 (* 1 = 1.44894 loss)
I1030 06:54:55.511102  1046 sgd_solver.cpp:105] Iteration 5960, lr = 0.00477614
I1030 06:55:25.564980  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_6000.caffemodel
I1030 06:55:25.596400  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_6000.solverstate
I1030 06:55:25.612994  1046 solver.cpp:334] Iteration 6000, Testing net (#0)
I1030 06:55:56.488816  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5806
I1030 06:55:56.489066  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80484
I1030 06:55:56.489092  1046 solver.cpp:401]     Test net output #2: loss = 1.86609 (* 1 = 1.86609 loss)
I1030 06:55:57.239970  1046 solver.cpp:222] Iteration 6000 (0.648019 iter/s, 61.7266s/40 iters), loss = 1.59258
I1030 06:55:57.240031  1046 solver.cpp:241]     Train net output #0: loss = 1.59258 (* 1 = 1.59258 loss)
I1030 06:55:57.240048  1046 sgd_solver.cpp:105] Iteration 6000, lr = 0.00475251
I1030 06:56:28.295922  1046 solver.cpp:222] Iteration 6040 (1.28805 iter/s, 31.0547s/40 iters), loss = 1.40072
I1030 06:56:28.296118  1046 solver.cpp:241]     Train net output #0: loss = 1.40072 (* 1 = 1.40072 loss)
I1030 06:56:28.296134  1046 sgd_solver.cpp:105] Iteration 6040, lr = 0.004729
I1030 06:56:58.945451  1046 solver.cpp:222] Iteration 6080 (1.30514 iter/s, 30.6481s/40 iters), loss = 0.893826
I1030 06:56:58.945657  1046 solver.cpp:241]     Train net output #0: loss = 0.893826 (* 1 = 0.893826 loss)
I1030 06:56:58.945674  1046 sgd_solver.cpp:105] Iteration 6080, lr = 0.0047056
I1030 06:57:30.509950  1046 solver.cpp:222] Iteration 6120 (1.2673 iter/s, 31.5631s/40 iters), loss = 1.32374
I1030 06:57:30.510138  1046 solver.cpp:241]     Train net output #0: loss = 1.32374 (* 1 = 1.32374 loss)
I1030 06:57:30.510162  1046 sgd_solver.cpp:105] Iteration 6120, lr = 0.00468232
I1030 06:58:01.223773  1046 solver.cpp:222] Iteration 6160 (1.3024 iter/s, 30.7125s/40 iters), loss = 1.42635
I1030 06:58:01.223955  1046 solver.cpp:241]     Train net output #0: loss = 1.42635 (* 1 = 1.42635 loss)
I1030 06:58:01.223973  1046 sgd_solver.cpp:105] Iteration 6160, lr = 0.00465916
I1030 06:58:34.519899  1046 solver.cpp:222] Iteration 6200 (1.20139 iter/s, 33.2947s/40 iters), loss = 1.45588
I1030 06:58:34.520121  1046 solver.cpp:241]     Train net output #0: loss = 1.45588 (* 1 = 1.45588 loss)
I1030 06:58:34.520145  1046 sgd_solver.cpp:105] Iteration 6200, lr = 0.00463611
I1030 06:59:10.061882  1046 solver.cpp:222] Iteration 6240 (1.12548 iter/s, 35.5404s/40 iters), loss = 1.23245
I1030 06:59:10.062090  1046 solver.cpp:241]     Train net output #0: loss = 1.23245 (* 1 = 1.23245 loss)
I1030 06:59:10.062108  1046 sgd_solver.cpp:105] Iteration 6240, lr = 0.00461318
I1030 06:59:41.187796  1046 solver.cpp:222] Iteration 6280 (1.28516 iter/s, 31.1245s/40 iters), loss = 1.44179
I1030 06:59:41.187996  1046 solver.cpp:241]     Train net output #0: loss = 1.44179 (* 1 = 1.44179 loss)
I1030 06:59:41.188015  1046 sgd_solver.cpp:105] Iteration 6280, lr = 0.00459035
I1030 07:00:11.691614  1046 solver.cpp:222] Iteration 6320 (1.31137 iter/s, 30.5025s/40 iters), loss = 1.31138
I1030 07:00:11.691907  1046 solver.cpp:241]     Train net output #0: loss = 1.31138 (* 1 = 1.31138 loss)
I1030 07:00:11.691931  1046 sgd_solver.cpp:105] Iteration 6320, lr = 0.00456764
I1030 07:00:42.630596  1046 solver.cpp:222] Iteration 6360 (1.29293 iter/s, 30.9375s/40 iters), loss = 1.31585
I1030 07:00:42.630779  1046 solver.cpp:241]     Train net output #0: loss = 1.31585 (* 1 = 1.31585 loss)
I1030 07:00:42.630798  1046 sgd_solver.cpp:105] Iteration 6360, lr = 0.00454505
I1030 07:01:13.051827  1046 solver.cpp:222] Iteration 6400 (1.31493 iter/s, 30.4199s/40 iters), loss = 1.42414
I1030 07:01:13.052009  1046 solver.cpp:241]     Train net output #0: loss = 1.42414 (* 1 = 1.42414 loss)
I1030 07:01:13.052026  1046 sgd_solver.cpp:105] Iteration 6400, lr = 0.00452256
I1030 07:01:43.223398  1046 solver.cpp:222] Iteration 6440 (1.32581 iter/s, 30.1703s/40 iters), loss = 1.50191
I1030 07:01:43.223577  1046 solver.cpp:241]     Train net output #0: loss = 1.50191 (* 1 = 1.50191 loss)
I1030 07:01:43.223594  1046 sgd_solver.cpp:105] Iteration 6440, lr = 0.00450019
I1030 07:02:14.601343  1046 solver.cpp:222] Iteration 6480 (1.27484 iter/s, 31.3766s/40 iters), loss = 1.28912
I1030 07:02:14.601538  1046 solver.cpp:241]     Train net output #0: loss = 1.28912 (* 1 = 1.28912 loss)
I1030 07:02:14.601567  1046 sgd_solver.cpp:105] Iteration 6480, lr = 0.00447793
I1030 07:02:29.800284  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_6500.caffemodel
I1030 07:02:29.842288  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_6500.solverstate
I1030 07:02:29.864420  1046 solver.cpp:334] Iteration 6500, Testing net (#0)
I1030 07:03:00.592864  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 07:03:00.799309  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58028
I1030 07:03:00.799373  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81052
I1030 07:03:00.799387  1046 solver.cpp:401]     Test net output #2: loss = 1.8641 (* 1 = 1.8641 loss)
I1030 07:03:17.369441  1046 solver.cpp:222] Iteration 6520 (0.637292 iter/s, 62.7656s/40 iters), loss = 1.63592
I1030 07:03:17.369515  1046 solver.cpp:241]     Train net output #0: loss = 1.63592 (* 1 = 1.63592 loss)
I1030 07:03:17.369531  1046 sgd_solver.cpp:105] Iteration 6520, lr = 0.00445577
I1030 07:03:48.286890  1046 solver.cpp:222] Iteration 6560 (1.29382 iter/s, 30.9162s/40 iters), loss = 1.5721
I1030 07:03:48.287106  1046 solver.cpp:241]     Train net output #0: loss = 1.5721 (* 1 = 1.5721 loss)
I1030 07:03:48.287123  1046 sgd_solver.cpp:105] Iteration 6560, lr = 0.00443373
I1030 07:04:22.508236  1046 solver.cpp:222] Iteration 6600 (1.16891 iter/s, 34.2198s/40 iters), loss = 1.62588
I1030 07:04:22.508441  1046 solver.cpp:241]     Train net output #0: loss = 1.62588 (* 1 = 1.62588 loss)
I1030 07:04:22.508464  1046 sgd_solver.cpp:105] Iteration 6600, lr = 0.0044118
I1030 07:04:53.296957  1046 solver.cpp:222] Iteration 6640 (1.29923 iter/s, 30.7874s/40 iters), loss = 1.39468
I1030 07:04:53.297161  1046 solver.cpp:241]     Train net output #0: loss = 1.39468 (* 1 = 1.39468 loss)
I1030 07:04:53.297179  1046 sgd_solver.cpp:105] Iteration 6640, lr = 0.00438997
I1030 07:05:24.119925  1046 solver.cpp:222] Iteration 6680 (1.29779 iter/s, 30.8216s/40 iters), loss = 1.44108
I1030 07:05:24.120115  1046 solver.cpp:241]     Train net output #0: loss = 1.44108 (* 1 = 1.44108 loss)
I1030 07:05:24.120132  1046 sgd_solver.cpp:105] Iteration 6680, lr = 0.00436825
I1030 07:05:54.987253  1046 solver.cpp:222] Iteration 6720 (1.29593 iter/s, 30.866s/40 iters), loss = 1.36005
I1030 07:05:54.987474  1046 solver.cpp:241]     Train net output #0: loss = 1.36005 (* 1 = 1.36005 loss)
I1030 07:05:54.987493  1046 sgd_solver.cpp:105] Iteration 6720, lr = 0.00434664
I1030 07:06:25.937772  1046 solver.cpp:222] Iteration 6760 (1.29244 iter/s, 30.9491s/40 iters), loss = 1.47934
I1030 07:06:25.937970  1046 solver.cpp:241]     Train net output #0: loss = 1.47934 (* 1 = 1.47934 loss)
I1030 07:06:25.937988  1046 sgd_solver.cpp:105] Iteration 6760, lr = 0.00432514
I1030 07:06:56.922366  1046 solver.cpp:222] Iteration 6800 (1.29102 iter/s, 30.9832s/40 iters), loss = 1.41981
I1030 07:06:56.922572  1046 solver.cpp:241]     Train net output #0: loss = 1.41981 (* 1 = 1.41981 loss)
I1030 07:06:56.922590  1046 sgd_solver.cpp:105] Iteration 6800, lr = 0.00430374
I1030 07:07:27.880849  1046 solver.cpp:222] Iteration 6840 (1.29211 iter/s, 30.9571s/40 iters), loss = 1.3517
I1030 07:07:27.881045  1046 solver.cpp:241]     Train net output #0: loss = 1.3517 (* 1 = 1.3517 loss)
I1030 07:07:27.881062  1046 sgd_solver.cpp:105] Iteration 6840, lr = 0.00428245
I1030 07:07:58.965870  1046 solver.cpp:222] Iteration 6880 (1.28685 iter/s, 31.0837s/40 iters), loss = 1.49904
I1030 07:07:58.966050  1046 solver.cpp:241]     Train net output #0: loss = 1.49904 (* 1 = 1.49904 loss)
I1030 07:07:58.966068  1046 sgd_solver.cpp:105] Iteration 6880, lr = 0.00426126
I1030 07:08:29.869526  1046 solver.cpp:222] Iteration 6920 (1.2944 iter/s, 30.9023s/40 iters), loss = 1.20761
I1030 07:08:29.869730  1046 solver.cpp:241]     Train net output #0: loss = 1.20761 (* 1 = 1.20761 loss)
I1030 07:08:29.869747  1046 sgd_solver.cpp:105] Iteration 6920, lr = 0.00424018
I1030 07:09:01.286764  1046 solver.cpp:222] Iteration 6960 (1.27324 iter/s, 31.4159s/40 iters), loss = 1.17239
I1030 07:09:01.286962  1046 solver.cpp:241]     Train net output #0: loss = 1.17239 (* 1 = 1.17239 loss)
I1030 07:09:01.286978  1046 sgd_solver.cpp:105] Iteration 6960, lr = 0.00421921
I1030 07:09:31.212361  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_7000.caffemodel
I1030 07:09:31.244767  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_7000.solverstate
I1030 07:09:31.261778  1046 solver.cpp:334] Iteration 7000, Testing net (#0)
I1030 07:10:02.288188  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58332
I1030 07:10:02.288615  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80676
I1030 07:10:02.288631  1046 solver.cpp:401]     Test net output #2: loss = 1.86513 (* 1 = 1.86513 loss)
I1030 07:10:03.058794  1046 solver.cpp:222] Iteration 7000 (0.647568 iter/s, 61.7695s/40 iters), loss = 1.43178
I1030 07:10:03.058857  1046 solver.cpp:241]     Train net output #0: loss = 1.43178 (* 1 = 1.43178 loss)
I1030 07:10:03.058872  1046 sgd_solver.cpp:105] Iteration 7000, lr = 0.00419833
I1030 07:10:33.277379  1046 solver.cpp:222] Iteration 7040 (1.32374 iter/s, 30.2174s/40 iters), loss = 1.68102
I1030 07:10:33.277575  1046 solver.cpp:241]     Train net output #0: loss = 1.68102 (* 1 = 1.68102 loss)
I1030 07:10:33.277595  1046 sgd_solver.cpp:105] Iteration 7040, lr = 0.00417756
I1030 07:11:03.676762  1046 solver.cpp:222] Iteration 7080 (1.31587 iter/s, 30.398s/40 iters), loss = 1.23297
I1030 07:11:03.676954  1046 solver.cpp:241]     Train net output #0: loss = 1.23297 (* 1 = 1.23297 loss)
I1030 07:11:03.676970  1046 sgd_solver.cpp:105] Iteration 7080, lr = 0.0041569
I1030 07:11:34.625542  1046 solver.cpp:222] Iteration 7120 (1.29251 iter/s, 30.9474s/40 iters), loss = 1.54831
I1030 07:11:34.625784  1046 solver.cpp:241]     Train net output #0: loss = 1.54831 (* 1 = 1.54831 loss)
I1030 07:11:34.625815  1046 sgd_solver.cpp:105] Iteration 7120, lr = 0.00413633
I1030 07:12:05.679811  1046 solver.cpp:222] Iteration 7160 (1.28813 iter/s, 31.0529s/40 iters), loss = 1.67316
I1030 07:12:05.679983  1046 solver.cpp:241]     Train net output #0: loss = 1.67316 (* 1 = 1.67316 loss)
I1030 07:12:05.680003  1046 sgd_solver.cpp:105] Iteration 7160, lr = 0.00411587
I1030 07:12:36.230450  1046 solver.cpp:222] Iteration 7200 (1.30936 iter/s, 30.5493s/40 iters), loss = 1.63314
I1030 07:12:36.230645  1046 solver.cpp:241]     Train net output #0: loss = 1.63314 (* 1 = 1.63314 loss)
I1030 07:12:36.230661  1046 sgd_solver.cpp:105] Iteration 7200, lr = 0.00409551
I1030 07:13:06.979771  1046 solver.cpp:222] Iteration 7240 (1.3009 iter/s, 30.748s/40 iters), loss = 1.27034
I1030 07:13:06.979967  1046 solver.cpp:241]     Train net output #0: loss = 1.27034 (* 1 = 1.27034 loss)
I1030 07:13:06.979985  1046 sgd_solver.cpp:105] Iteration 7240, lr = 0.00407525
I1030 07:13:37.851523  1046 solver.cpp:222] Iteration 7280 (1.29574 iter/s, 30.8704s/40 iters), loss = 1.56381
I1030 07:13:37.851709  1046 solver.cpp:241]     Train net output #0: loss = 1.56381 (* 1 = 1.56381 loss)
I1030 07:13:37.851728  1046 sgd_solver.cpp:105] Iteration 7280, lr = 0.00405509
I1030 07:14:10.429932  1046 solver.cpp:222] Iteration 7320 (1.22786 iter/s, 32.577s/40 iters), loss = 1.39295
I1030 07:14:10.430243  1046 solver.cpp:241]     Train net output #0: loss = 1.39295 (* 1 = 1.39295 loss)
I1030 07:14:10.430289  1046 sgd_solver.cpp:105] Iteration 7320, lr = 0.00403502
I1030 07:14:43.223789  1046 solver.cpp:222] Iteration 7360 (1.2198 iter/s, 32.7923s/40 iters), loss = 1.35763
I1030 07:14:43.223994  1046 solver.cpp:241]     Train net output #0: loss = 1.35763 (* 1 = 1.35763 loss)
I1030 07:14:43.224012  1046 sgd_solver.cpp:105] Iteration 7360, lr = 0.00401506
I1030 07:15:13.501677  1046 solver.cpp:222] Iteration 7400 (1.32115 iter/s, 30.2765s/40 iters), loss = 1.71581
I1030 07:15:13.501848  1046 solver.cpp:241]     Train net output #0: loss = 1.71581 (* 1 = 1.71581 loss)
I1030 07:15:13.501865  1046 sgd_solver.cpp:105] Iteration 7400, lr = 0.0039952
I1030 07:15:44.129664  1046 solver.cpp:222] Iteration 7440 (1.30605 iter/s, 30.6267s/40 iters), loss = 1.58583
I1030 07:15:44.129875  1046 solver.cpp:241]     Train net output #0: loss = 1.58583 (* 1 = 1.58583 loss)
I1030 07:15:44.129902  1046 sgd_solver.cpp:105] Iteration 7440, lr = 0.00397543
I1030 07:16:36.598058  1046 solver.cpp:222] Iteration 7480 (0.762396 iter/s, 52.4662s/40 iters), loss = 1.51868
I1030 07:16:36.598286  1046 solver.cpp:241]     Train net output #0: loss = 1.51868 (* 1 = 1.51868 loss)
I1030 07:16:36.598311  1046 sgd_solver.cpp:105] Iteration 7480, lr = 0.00395577
I1030 07:16:51.214975  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_7500.caffemodel
I1030 07:16:51.245908  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_7500.solverstate
I1030 07:16:51.262457  1046 solver.cpp:334] Iteration 7500, Testing net (#0)
I1030 07:17:22.101784  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 07:17:22.308300  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58092
I1030 07:17:22.308351  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.808879
I1030 07:17:22.308367  1046 solver.cpp:401]     Test net output #2: loss = 1.84813 (* 1 = 1.84813 loss)
I1030 07:17:24.965598  1096 data_layer.cpp:73] Restarting data prefetching from start.
I1030 07:17:38.410837  1046 solver.cpp:222] Iteration 7520 (0.647142 iter/s, 61.8102s/40 iters), loss = 1.40127
I1030 07:17:38.410907  1046 solver.cpp:241]     Train net output #0: loss = 1.40127 (* 1 = 1.40127 loss)
I1030 07:17:38.410923  1046 sgd_solver.cpp:105] Iteration 7520, lr = 0.0039362
I1030 07:18:09.430475  1046 solver.cpp:222] Iteration 7560 (1.28956 iter/s, 31.0184s/40 iters), loss = 1.49174
I1030 07:18:09.430676  1046 solver.cpp:241]     Train net output #0: loss = 1.49174 (* 1 = 1.49174 loss)
I1030 07:18:09.430693  1046 sgd_solver.cpp:105] Iteration 7560, lr = 0.00391673
I1030 07:18:39.540514  1046 solver.cpp:222] Iteration 7600 (1.32852 iter/s, 30.1087s/40 iters), loss = 1.48664
I1030 07:18:39.541179  1046 solver.cpp:241]     Train net output #0: loss = 1.48664 (* 1 = 1.48664 loss)
I1030 07:18:39.541198  1046 sgd_solver.cpp:105] Iteration 7600, lr = 0.00389735
I1030 07:19:09.688809  1046 solver.cpp:222] Iteration 7640 (1.32686 iter/s, 30.1465s/40 iters), loss = 1.26935
I1030 07:19:09.688988  1046 solver.cpp:241]     Train net output #0: loss = 1.26935 (* 1 = 1.26935 loss)
I1030 07:19:09.689007  1046 sgd_solver.cpp:105] Iteration 7640, lr = 0.00387807
I1030 07:19:40.602259  1046 solver.cpp:222] Iteration 7680 (1.29399 iter/s, 30.9121s/40 iters), loss = 1.39756
I1030 07:19:40.602440  1046 solver.cpp:241]     Train net output #0: loss = 1.39756 (* 1 = 1.39756 loss)
I1030 07:19:40.602460  1046 sgd_solver.cpp:105] Iteration 7680, lr = 0.00385888
I1030 07:20:11.370653  1046 solver.cpp:222] Iteration 7720 (1.30009 iter/s, 30.767s/40 iters), loss = 1.44345
I1030 07:20:11.370842  1046 solver.cpp:241]     Train net output #0: loss = 1.44345 (* 1 = 1.44345 loss)
I1030 07:20:11.370860  1046 sgd_solver.cpp:105] Iteration 7720, lr = 0.00383979
I1030 07:20:42.396103  1046 solver.cpp:222] Iteration 7760 (1.28932 iter/s, 31.0241s/40 iters), loss = 1.0922
I1030 07:20:42.396311  1046 solver.cpp:241]     Train net output #0: loss = 1.0922 (* 1 = 1.0922 loss)
I1030 07:20:42.396329  1046 sgd_solver.cpp:105] Iteration 7760, lr = 0.0038208
I1030 07:21:13.352478  1046 solver.cpp:222] Iteration 7800 (1.2922 iter/s, 30.955s/40 iters), loss = 1.4855
I1030 07:21:13.352680  1046 solver.cpp:241]     Train net output #0: loss = 1.4855 (* 1 = 1.4855 loss)
I1030 07:21:13.352699  1046 sgd_solver.cpp:105] Iteration 7800, lr = 0.00380189
I1030 07:21:43.734853  1046 solver.cpp:222] Iteration 7840 (1.31661 iter/s, 30.381s/40 iters), loss = 1.22806
I1030 07:21:43.735038  1046 solver.cpp:241]     Train net output #0: loss = 1.22806 (* 1 = 1.22806 loss)
I1030 07:21:43.735056  1046 sgd_solver.cpp:105] Iteration 7840, lr = 0.00378309
I1030 07:22:14.113612  1046 solver.cpp:222] Iteration 7880 (1.31677 iter/s, 30.3774s/40 iters), loss = 1.44698
I1030 07:22:14.113803  1046 solver.cpp:241]     Train net output #0: loss = 1.44698 (* 1 = 1.44698 loss)
I1030 07:22:14.113833  1046 sgd_solver.cpp:105] Iteration 7880, lr = 0.00376437
I1030 07:22:44.932934  1046 solver.cpp:222] Iteration 7920 (1.29794 iter/s, 30.818s/40 iters), loss = 1.39511
I1030 07:22:44.933137  1046 solver.cpp:241]     Train net output #0: loss = 1.39511 (* 1 = 1.39511 loss)
I1030 07:22:44.933153  1046 sgd_solver.cpp:105] Iteration 7920, lr = 0.00374575
I1030 07:23:15.430976  1046 solver.cpp:222] Iteration 7960 (1.31162 iter/s, 30.4967s/40 iters), loss = 1.46565
I1030 07:23:15.431169  1046 solver.cpp:241]     Train net output #0: loss = 1.46565 (* 1 = 1.46565 loss)
I1030 07:23:15.431186  1046 sgd_solver.cpp:105] Iteration 7960, lr = 0.00372722
I1030 07:23:45.606453  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_8000.caffemodel
I1030 07:23:45.655553  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_8000.solverstate
I1030 07:23:45.678095  1046 solver.cpp:334] Iteration 8000, Testing net (#0)
I1030 07:24:16.624060  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58284
I1030 07:24:16.624249  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.807479
I1030 07:24:16.624266  1046 solver.cpp:401]     Test net output #2: loss = 1.86189 (* 1 = 1.86189 loss)
I1030 07:24:17.388852  1046 solver.cpp:222] Iteration 8000 (0.645626 iter/s, 61.9554s/40 iters), loss = 1.85103
I1030 07:24:17.388911  1046 solver.cpp:241]     Train net output #0: loss = 1.85103 (* 1 = 1.85103 loss)
I1030 07:24:17.388926  1046 sgd_solver.cpp:105] Iteration 8000, lr = 0.00370878
I1030 07:24:48.704097  1046 solver.cpp:222] Iteration 8040 (1.27738 iter/s, 31.314s/40 iters), loss = 1.47729
I1030 07:24:48.704360  1046 solver.cpp:241]     Train net output #0: loss = 1.47729 (* 1 = 1.47729 loss)
I1030 07:24:48.704383  1046 sgd_solver.cpp:105] Iteration 8040, lr = 0.00369043
I1030 07:25:20.497228  1046 solver.cpp:222] Iteration 8080 (1.25819 iter/s, 31.7917s/40 iters), loss = 1.52547
I1030 07:25:20.497438  1046 solver.cpp:241]     Train net output #0: loss = 1.52547 (* 1 = 1.52547 loss)
I1030 07:25:20.497457  1046 sgd_solver.cpp:105] Iteration 8080, lr = 0.00367217
I1030 07:25:51.083364  1046 solver.cpp:222] Iteration 8120 (1.30784 iter/s, 30.5848s/40 iters), loss = 1.32382
I1030 07:25:51.083575  1046 solver.cpp:241]     Train net output #0: loss = 1.32382 (* 1 = 1.32382 loss)
I1030 07:25:51.083592  1046 sgd_solver.cpp:105] Iteration 8120, lr = 0.00365401
I1030 07:26:21.990226  1046 solver.cpp:222] Iteration 8160 (1.29427 iter/s, 30.9055s/40 iters), loss = 1.42628
I1030 07:26:21.990424  1046 solver.cpp:241]     Train net output #0: loss = 1.42628 (* 1 = 1.42628 loss)
I1030 07:26:21.990440  1046 sgd_solver.cpp:105] Iteration 8160, lr = 0.00363593
I1030 07:26:52.790529  1046 solver.cpp:222] Iteration 8200 (1.29875 iter/s, 30.7989s/40 iters), loss = 1.57853
I1030 07:26:52.790704  1046 solver.cpp:241]     Train net output #0: loss = 1.57853 (* 1 = 1.57853 loss)
I1030 07:26:52.790721  1046 sgd_solver.cpp:105] Iteration 8200, lr = 0.00361794
I1030 07:27:23.592401  1046 solver.cpp:222] Iteration 8240 (1.29868 iter/s, 30.8005s/40 iters), loss = 1.25617
I1030 07:27:23.592586  1046 solver.cpp:241]     Train net output #0: loss = 1.25617 (* 1 = 1.25617 loss)
I1030 07:27:23.592602  1046 sgd_solver.cpp:105] Iteration 8240, lr = 0.00360004
I1030 07:27:54.390549  1046 solver.cpp:222] Iteration 8280 (1.29884 iter/s, 30.7968s/40 iters), loss = 1.44131
I1030 07:27:54.390736  1046 solver.cpp:241]     Train net output #0: loss = 1.44131 (* 1 = 1.44131 loss)
I1030 07:27:54.390753  1046 sgd_solver.cpp:105] Iteration 8280, lr = 0.00358223
I1030 07:28:25.261685  1046 solver.cpp:222] Iteration 8320 (1.29577 iter/s, 30.8698s/40 iters), loss = 1.45091
I1030 07:28:25.261865  1046 solver.cpp:241]     Train net output #0: loss = 1.45091 (* 1 = 1.45091 loss)
I1030 07:28:25.261883  1046 sgd_solver.cpp:105] Iteration 8320, lr = 0.00356451
I1030 07:28:56.413275  1046 solver.cpp:222] Iteration 8360 (1.2841 iter/s, 31.1502s/40 iters), loss = 1.49666
I1030 07:28:56.413569  1046 solver.cpp:241]     Train net output #0: loss = 1.49666 (* 1 = 1.49666 loss)
I1030 07:28:56.413595  1046 sgd_solver.cpp:105] Iteration 8360, lr = 0.00354688
I1030 07:29:27.525002  1046 solver.cpp:222] Iteration 8400 (1.28575 iter/s, 31.1103s/40 iters), loss = 1.57891
I1030 07:29:27.525187  1046 solver.cpp:241]     Train net output #0: loss = 1.57891 (* 1 = 1.57891 loss)
I1030 07:29:27.525204  1046 sgd_solver.cpp:105] Iteration 8400, lr = 0.00352933
I1030 07:29:58.416404  1046 solver.cpp:222] Iteration 8440 (1.29492 iter/s, 30.8901s/40 iters), loss = 1.63875
I1030 07:29:58.416615  1046 solver.cpp:241]     Train net output #0: loss = 1.63875 (* 1 = 1.63875 loss)
I1030 07:29:58.416635  1046 sgd_solver.cpp:105] Iteration 8440, lr = 0.00351187
I1030 07:30:29.192731  1046 solver.cpp:222] Iteration 8480 (1.29976 iter/s, 30.775s/40 iters), loss = 1.31169
I1030 07:30:29.192939  1046 solver.cpp:241]     Train net output #0: loss = 1.31169 (* 1 = 1.31169 loss)
I1030 07:30:29.192956  1046 sgd_solver.cpp:105] Iteration 8480, lr = 0.0034945
I1030 07:30:43.989270  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_8500.caffemodel
I1030 07:30:44.020207  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_8500.solverstate
I1030 07:30:44.036811  1046 solver.cpp:334] Iteration 8500, Testing net (#0)
I1030 07:31:14.756748  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 07:31:14.964257  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58144
I1030 07:31:14.964319  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.810279
I1030 07:31:14.964334  1046 solver.cpp:401]     Test net output #2: loss = 1.86206 (* 1 = 1.86206 loss)
I1030 07:31:31.122388  1046 solver.cpp:222] Iteration 8520 (0.645921 iter/s, 61.9271s/40 iters), loss = 1.18326
I1030 07:31:31.122457  1046 solver.cpp:241]     Train net output #0: loss = 1.18326 (* 1 = 1.18326 loss)
I1030 07:31:31.122473  1046 sgd_solver.cpp:105] Iteration 8520, lr = 0.00347721
I1030 07:32:02.463238  1046 solver.cpp:222] Iteration 8560 (1.27634 iter/s, 31.3396s/40 iters), loss = 1.09749
I1030 07:32:02.463431  1046 solver.cpp:241]     Train net output #0: loss = 1.09749 (* 1 = 1.09749 loss)
I1030 07:32:02.463449  1046 sgd_solver.cpp:105] Iteration 8560, lr = 0.00346001
I1030 07:32:39.658151  1046 solver.cpp:222] Iteration 8600 (1.07546 iter/s, 37.1933s/40 iters), loss = 1.34025
I1030 07:32:39.658505  1046 solver.cpp:241]     Train net output #0: loss = 1.34025 (* 1 = 1.34025 loss)
I1030 07:32:39.658522  1046 sgd_solver.cpp:105] Iteration 8600, lr = 0.00344289
I1030 07:33:10.837126  1046 solver.cpp:222] Iteration 8640 (1.28298 iter/s, 31.1774s/40 iters), loss = 1.38561
I1030 07:33:10.837312  1046 solver.cpp:241]     Train net output #0: loss = 1.38561 (* 1 = 1.38561 loss)
I1030 07:33:10.837330  1046 sgd_solver.cpp:105] Iteration 8640, lr = 0.00342586
I1030 07:33:41.632905  1046 solver.cpp:222] Iteration 8680 (1.29894 iter/s, 30.7944s/40 iters), loss = 1.39236
I1030 07:33:41.633072  1046 solver.cpp:241]     Train net output #0: loss = 1.39236 (* 1 = 1.39236 loss)
I1030 07:33:41.633091  1046 sgd_solver.cpp:105] Iteration 8680, lr = 0.00340891
I1030 07:34:12.473973  1046 solver.cpp:222] Iteration 8720 (1.29703 iter/s, 30.8397s/40 iters), loss = 1.46877
I1030 07:34:12.474141  1046 solver.cpp:241]     Train net output #0: loss = 1.46877 (* 1 = 1.46877 loss)
I1030 07:34:12.474159  1046 sgd_solver.cpp:105] Iteration 8720, lr = 0.00339204
I1030 07:34:43.232988  1046 solver.cpp:222] Iteration 8760 (1.30049 iter/s, 30.7577s/40 iters), loss = 1.33046
I1030 07:34:43.233150  1046 solver.cpp:241]     Train net output #0: loss = 1.33046 (* 1 = 1.33046 loss)
I1030 07:34:43.233166  1046 sgd_solver.cpp:105] Iteration 8760, lr = 0.00337526
I1030 07:35:13.872676  1046 solver.cpp:222] Iteration 8800 (1.30555 iter/s, 30.6384s/40 iters), loss = 1.15371
I1030 07:35:13.872892  1046 solver.cpp:241]     Train net output #0: loss = 1.15371 (* 1 = 1.15371 loss)
I1030 07:35:13.872918  1046 sgd_solver.cpp:105] Iteration 8800, lr = 0.00335857
I1030 07:35:44.492628  1046 solver.cpp:222] Iteration 8840 (1.3064 iter/s, 30.6186s/40 iters), loss = 1.76619
I1030 07:35:44.492847  1046 solver.cpp:241]     Train net output #0: loss = 1.76619 (* 1 = 1.76619 loss)
I1030 07:35:44.492866  1046 sgd_solver.cpp:105] Iteration 8840, lr = 0.00334195
I1030 07:36:15.145102  1046 solver.cpp:222] Iteration 8880 (1.30501 iter/s, 30.6511s/40 iters), loss = 1.36889
I1030 07:36:15.145277  1046 solver.cpp:241]     Train net output #0: loss = 1.36889 (* 1 = 1.36889 loss)
I1030 07:36:15.145294  1046 sgd_solver.cpp:105] Iteration 8880, lr = 0.00332542
I1030 07:36:45.577666  1046 solver.cpp:222] Iteration 8920 (1.31444 iter/s, 30.4313s/40 iters), loss = 1.31366
I1030 07:36:45.577831  1046 solver.cpp:241]     Train net output #0: loss = 1.31366 (* 1 = 1.31366 loss)
I1030 07:36:45.577847  1046 sgd_solver.cpp:105] Iteration 8920, lr = 0.00330897
I1030 07:37:16.124939  1046 solver.cpp:222] Iteration 8960 (1.3095 iter/s, 30.546s/40 iters), loss = 1.43876
I1030 07:37:16.125141  1046 solver.cpp:241]     Train net output #0: loss = 1.43876 (* 1 = 1.43876 loss)
I1030 07:37:16.125159  1046 sgd_solver.cpp:105] Iteration 8960, lr = 0.0032926
I1030 07:37:46.790494  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_9000.caffemodel
I1030 07:37:46.821491  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_9000.solverstate
I1030 07:37:46.838157  1046 solver.cpp:334] Iteration 9000, Testing net (#0)
I1030 07:38:17.728463  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58368
I1030 07:38:17.728651  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8068
I1030 07:38:17.728667  1046 solver.cpp:401]     Test net output #2: loss = 1.85537 (* 1 = 1.85537 loss)
I1030 07:38:18.494387  1046 solver.cpp:222] Iteration 9000 (0.641366 iter/s, 62.3669s/40 iters), loss = 1.26902
I1030 07:38:18.494429  1046 solver.cpp:241]     Train net output #0: loss = 1.26902 (* 1 = 1.26902 loss)
I1030 07:38:18.494446  1046 sgd_solver.cpp:105] Iteration 9000, lr = 0.00327631
I1030 07:38:49.555586  1046 solver.cpp:222] Iteration 9040 (1.28783 iter/s, 31.06s/40 iters), loss = 1.68142
I1030 07:38:49.555750  1046 solver.cpp:241]     Train net output #0: loss = 1.68142 (* 1 = 1.68142 loss)
I1030 07:38:49.555768  1046 sgd_solver.cpp:105] Iteration 9040, lr = 0.0032601
I1030 07:39:20.399466  1046 solver.cpp:222] Iteration 9080 (1.29691 iter/s, 30.8426s/40 iters), loss = 1.38588
I1030 07:39:20.399665  1046 solver.cpp:241]     Train net output #0: loss = 1.38588 (* 1 = 1.38588 loss)
I1030 07:39:20.399682  1046 sgd_solver.cpp:105] Iteration 9080, lr = 0.00324397
I1030 07:39:51.090173  1046 solver.cpp:222] Iteration 9120 (1.30338 iter/s, 30.6894s/40 iters), loss = 1.25997
I1030 07:39:51.090399  1046 solver.cpp:241]     Train net output #0: loss = 1.25997 (* 1 = 1.25997 loss)
I1030 07:39:51.090416  1046 sgd_solver.cpp:105] Iteration 9120, lr = 0.00322792
I1030 07:40:21.695745  1046 solver.cpp:222] Iteration 9160 (1.30701 iter/s, 30.6042s/40 iters), loss = 1.6727
I1030 07:40:21.695952  1046 solver.cpp:241]     Train net output #0: loss = 1.6727 (* 1 = 1.6727 loss)
I1030 07:40:21.695971  1046 sgd_solver.cpp:105] Iteration 9160, lr = 0.00321195
I1030 07:40:52.337615  1046 solver.cpp:222] Iteration 9200 (1.30546 iter/s, 30.6405s/40 iters), loss = 1.75
I1030 07:40:52.337801  1046 solver.cpp:241]     Train net output #0: loss = 1.75 (* 1 = 1.75 loss)
I1030 07:40:52.337819  1046 sgd_solver.cpp:105] Iteration 9200, lr = 0.00319606
I1030 07:41:22.951825  1046 solver.cpp:222] Iteration 9240 (1.30664 iter/s, 30.6129s/40 iters), loss = 1.43706
I1030 07:41:22.952020  1046 solver.cpp:241]     Train net output #0: loss = 1.43706 (* 1 = 1.43706 loss)
I1030 07:41:22.952039  1046 sgd_solver.cpp:105] Iteration 9240, lr = 0.00318025
I1030 07:41:53.694000  1046 solver.cpp:222] Iteration 9280 (1.3012 iter/s, 30.7408s/40 iters), loss = 1.4916
I1030 07:41:53.694253  1046 solver.cpp:241]     Train net output #0: loss = 1.4916 (* 1 = 1.4916 loss)
I1030 07:41:53.694272  1046 sgd_solver.cpp:105] Iteration 9280, lr = 0.00316452
I1030 07:42:24.428905  1046 solver.cpp:222] Iteration 9320 (1.30151 iter/s, 30.7335s/40 iters), loss = 1.37336
I1030 07:42:24.429093  1046 solver.cpp:241]     Train net output #0: loss = 1.37336 (* 1 = 1.37336 loss)
I1030 07:42:24.429111  1046 sgd_solver.cpp:105] Iteration 9320, lr = 0.00314886
I1030 07:42:55.454231  1046 solver.cpp:222] Iteration 9360 (1.28933 iter/s, 31.024s/40 iters), loss = 1.44578
I1030 07:42:55.454418  1046 solver.cpp:241]     Train net output #0: loss = 1.44578 (* 1 = 1.44578 loss)
I1030 07:42:55.454435  1046 sgd_solver.cpp:105] Iteration 9360, lr = 0.00313329
I1030 07:43:26.638506  1046 solver.cpp:222] Iteration 9400 (1.28275 iter/s, 31.1829s/40 iters), loss = 1.60212
I1030 07:43:26.638707  1046 solver.cpp:241]     Train net output #0: loss = 1.60212 (* 1 = 1.60212 loss)
I1030 07:43:26.638725  1046 sgd_solver.cpp:105] Iteration 9400, lr = 0.00311779
I1030 07:43:57.570533  1046 solver.cpp:222] Iteration 9440 (1.29322 iter/s, 30.9307s/40 iters), loss = 1.42558
I1030 07:43:57.570718  1046 solver.cpp:241]     Train net output #0: loss = 1.42558 (* 1 = 1.42558 loss)
I1030 07:43:57.570734  1046 sgd_solver.cpp:105] Iteration 9440, lr = 0.00310236
I1030 07:44:28.092244  1046 solver.cpp:222] Iteration 9480 (1.3106 iter/s, 30.5204s/40 iters), loss = 1.39862
I1030 07:44:28.092422  1046 solver.cpp:241]     Train net output #0: loss = 1.39862 (* 1 = 1.39862 loss)
I1030 07:44:28.092438  1046 sgd_solver.cpp:105] Iteration 9480, lr = 0.00308701
I1030 07:44:42.530778  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_9500.caffemodel
I1030 07:44:42.562556  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_9500.solverstate
I1030 07:44:42.579031  1046 solver.cpp:334] Iteration 9500, Testing net (#0)
I1030 07:45:13.342224  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 07:45:13.548002  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58252
I1030 07:45:13.548063  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.810319
I1030 07:45:13.548075  1046 solver.cpp:401]     Test net output #2: loss = 1.85474 (* 1 = 1.85474 loss)
I1030 07:45:29.923228  1046 solver.cpp:222] Iteration 9520 (0.646951 iter/s, 61.8285s/40 iters), loss = 1.56576
I1030 07:45:29.923316  1046 solver.cpp:241]     Train net output #0: loss = 1.56576 (* 1 = 1.56576 loss)
I1030 07:45:29.923337  1046 sgd_solver.cpp:105] Iteration 9520, lr = 0.00307174
I1030 07:46:00.836616  1046 solver.cpp:222] Iteration 9560 (1.29399 iter/s, 30.9121s/40 iters), loss = 1.77033
I1030 07:46:00.836846  1046 solver.cpp:241]     Train net output #0: loss = 1.77033 (* 1 = 1.77033 loss)
I1030 07:46:00.836869  1046 sgd_solver.cpp:105] Iteration 9560, lr = 0.00305654
I1030 07:46:31.494292  1046 solver.cpp:222] Iteration 9600 (1.30479 iter/s, 30.6563s/40 iters), loss = 1.42873
I1030 07:46:31.494515  1046 solver.cpp:241]     Train net output #0: loss = 1.42873 (* 1 = 1.42873 loss)
I1030 07:46:31.494541  1046 sgd_solver.cpp:105] Iteration 9600, lr = 0.00304142
I1030 07:47:02.561985  1046 solver.cpp:222] Iteration 9640 (1.28757 iter/s, 31.0663s/40 iters), loss = 1.42688
I1030 07:47:02.562163  1046 solver.cpp:241]     Train net output #0: loss = 1.42688 (* 1 = 1.42688 loss)
I1030 07:47:02.562180  1046 sgd_solver.cpp:105] Iteration 9640, lr = 0.00302638
I1030 07:47:33.243070  1046 solver.cpp:222] Iteration 9680 (1.30379 iter/s, 30.6798s/40 iters), loss = 1.25038
I1030 07:47:33.243250  1046 solver.cpp:241]     Train net output #0: loss = 1.25038 (* 1 = 1.25038 loss)
I1030 07:47:33.243268  1046 sgd_solver.cpp:105] Iteration 9680, lr = 0.00301141
I1030 07:48:04.050415  1046 solver.cpp:222] Iteration 9720 (1.29845 iter/s, 30.806s/40 iters), loss = 1.49434
I1030 07:48:04.050658  1046 solver.cpp:241]     Train net output #0: loss = 1.49434 (* 1 = 1.49434 loss)
I1030 07:48:04.050678  1046 sgd_solver.cpp:105] Iteration 9720, lr = 0.00299651
I1030 07:48:34.692878  1046 solver.cpp:222] Iteration 9760 (1.30544 iter/s, 30.6411s/40 iters), loss = 1.69856
I1030 07:48:34.693063  1046 solver.cpp:241]     Train net output #0: loss = 1.69856 (* 1 = 1.69856 loss)
I1030 07:48:34.693083  1046 sgd_solver.cpp:105] Iteration 9760, lr = 0.00298168
I1030 07:49:05.286571  1046 solver.cpp:222] Iteration 9800 (1.30752 iter/s, 30.5924s/40 iters), loss = 1.59602
I1030 07:49:05.286784  1046 solver.cpp:241]     Train net output #0: loss = 1.59602 (* 1 = 1.59602 loss)
I1030 07:49:05.286803  1046 sgd_solver.cpp:105] Iteration 9800, lr = 0.00296693
I1030 07:49:35.773377  1046 solver.cpp:222] Iteration 9840 (1.3121 iter/s, 30.4854s/40 iters), loss = 1.37623
I1030 07:49:35.773555  1046 solver.cpp:241]     Train net output #0: loss = 1.37623 (* 1 = 1.37623 loss)
I1030 07:49:35.773572  1046 sgd_solver.cpp:105] Iteration 9840, lr = 0.00295225
I1030 07:50:06.490852  1046 solver.cpp:222] Iteration 9880 (1.30225 iter/s, 30.7161s/40 iters), loss = 1.55616
I1030 07:50:06.491080  1046 solver.cpp:241]     Train net output #0: loss = 1.55616 (* 1 = 1.55616 loss)
I1030 07:50:06.491099  1046 sgd_solver.cpp:105] Iteration 9880, lr = 0.00293765
I1030 07:50:41.098688  1046 solver.cpp:222] Iteration 9920 (1.15586 iter/s, 34.6063s/40 iters), loss = 0.967258
I1030 07:50:41.098915  1046 solver.cpp:241]     Train net output #0: loss = 0.967258 (* 1 = 0.967258 loss)
I1030 07:50:41.098940  1046 sgd_solver.cpp:105] Iteration 9920, lr = 0.00292312
I1030 07:51:12.543845  1046 solver.cpp:222] Iteration 9960 (1.27211 iter/s, 31.4437s/40 iters), loss = 1.33634
I1030 07:51:12.544113  1046 solver.cpp:241]     Train net output #0: loss = 1.33634 (* 1 = 1.33634 loss)
I1030 07:51:12.544143  1046 sgd_solver.cpp:105] Iteration 9960, lr = 0.00290866
I1030 07:51:42.183594  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_10000.caffemodel
I1030 07:51:42.220757  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_10000.solverstate
I1030 07:51:42.244617  1046 solver.cpp:334] Iteration 10000, Testing net (#0)
I1030 07:52:13.206934  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58468
I1030 07:52:13.207145  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.806799
I1030 07:52:13.207161  1046 solver.cpp:401]     Test net output #2: loss = 1.84637 (* 1 = 1.84637 loss)
I1030 07:52:13.970496  1046 solver.cpp:222] Iteration 10000 (0.65121 iter/s, 61.4241s/40 iters), loss = 1.3891
I1030 07:52:13.970566  1046 solver.cpp:241]     Train net output #0: loss = 1.3891 (* 1 = 1.3891 loss)
I1030 07:52:13.970582  1046 sgd_solver.cpp:105] Iteration 10000, lr = 0.00289427
I1030 07:52:17.794020  1096 data_layer.cpp:73] Restarting data prefetching from start.
I1030 07:52:44.290246  1046 solver.cpp:222] Iteration 10040 (1.31933 iter/s, 30.3185s/40 iters), loss = 1.34381
I1030 07:52:44.290447  1046 solver.cpp:241]     Train net output #0: loss = 1.34381 (* 1 = 1.34381 loss)
I1030 07:52:44.290465  1046 sgd_solver.cpp:105] Iteration 10040, lr = 0.00287995
I1030 07:53:14.699671  1046 solver.cpp:222] Iteration 10080 (1.31544 iter/s, 30.4081s/40 iters), loss = 1.56466
I1030 07:53:14.699864  1046 solver.cpp:241]     Train net output #0: loss = 1.56466 (* 1 = 1.56466 loss)
I1030 07:53:14.699882  1046 sgd_solver.cpp:105] Iteration 10080, lr = 0.0028657
I1030 07:53:45.580080  1046 solver.cpp:222] Iteration 10120 (1.29538 iter/s, 30.8791s/40 iters), loss = 1.45652
I1030 07:53:45.580271  1046 solver.cpp:241]     Train net output #0: loss = 1.45652 (* 1 = 1.45652 loss)
I1030 07:53:45.580286  1046 sgd_solver.cpp:105] Iteration 10120, lr = 0.00285152
I1030 07:54:16.548825  1046 solver.cpp:222] Iteration 10160 (1.29168 iter/s, 30.9674s/40 iters), loss = 1.36476
I1030 07:54:16.549078  1046 solver.cpp:241]     Train net output #0: loss = 1.36476 (* 1 = 1.36476 loss)
I1030 07:54:16.549105  1046 sgd_solver.cpp:105] Iteration 10160, lr = 0.00283742
I1030 07:54:47.010318  1046 solver.cpp:222] Iteration 10200 (1.31319 iter/s, 30.4601s/40 iters), loss = 1.44555
I1030 07:54:47.010512  1046 solver.cpp:241]     Train net output #0: loss = 1.44555 (* 1 = 1.44555 loss)
I1030 07:54:47.010532  1046 sgd_solver.cpp:105] Iteration 10200, lr = 0.00282338
I1030 07:55:18.132391  1046 solver.cpp:222] Iteration 10240 (1.28532 iter/s, 31.1207s/40 iters), loss = 1.51685
I1030 07:55:18.132582  1046 solver.cpp:241]     Train net output #0: loss = 1.51685 (* 1 = 1.51685 loss)
I1030 07:55:18.132599  1046 sgd_solver.cpp:105] Iteration 10240, lr = 0.00280941
I1030 07:55:49.145526  1046 solver.cpp:222] Iteration 10280 (1.28983 iter/s, 31.0118s/40 iters), loss = 1.39646
I1030 07:55:49.145740  1046 solver.cpp:241]     Train net output #0: loss = 1.39646 (* 1 = 1.39646 loss)
I1030 07:55:49.145759  1046 sgd_solver.cpp:105] Iteration 10280, lr = 0.00279551
I1030 07:56:20.037964  1046 solver.cpp:222] Iteration 10320 (1.29487 iter/s, 30.891s/40 iters), loss = 1.28354
I1030 07:56:20.038172  1046 solver.cpp:241]     Train net output #0: loss = 1.28354 (* 1 = 1.28354 loss)
I1030 07:56:20.038189  1046 sgd_solver.cpp:105] Iteration 10320, lr = 0.00278168
I1030 07:56:50.912120  1046 solver.cpp:222] Iteration 10360 (1.29564 iter/s, 30.8728s/40 iters), loss = 1.57048
I1030 07:56:50.912379  1046 solver.cpp:241]     Train net output #0: loss = 1.57048 (* 1 = 1.57048 loss)
I1030 07:56:50.912408  1046 sgd_solver.cpp:105] Iteration 10360, lr = 0.00276792
I1030 07:57:22.164026  1046 solver.cpp:222] Iteration 10400 (1.27998 iter/s, 31.2505s/40 iters), loss = 1.52208
I1030 07:57:22.164201  1046 solver.cpp:241]     Train net output #0: loss = 1.52208 (* 1 = 1.52208 loss)
I1030 07:57:22.164216  1046 sgd_solver.cpp:105] Iteration 10400, lr = 0.00275423
I1030 07:57:52.888885  1046 solver.cpp:222] Iteration 10440 (1.30193 iter/s, 30.7235s/40 iters), loss = 1.43641
I1030 07:57:52.889083  1046 solver.cpp:241]     Train net output #0: loss = 1.43641 (* 1 = 1.43641 loss)
I1030 07:57:52.889099  1046 sgd_solver.cpp:105] Iteration 10440, lr = 0.0027406
I1030 07:58:23.699852  1046 solver.cpp:222] Iteration 10480 (1.2983 iter/s, 30.8096s/40 iters), loss = 1.51451
I1030 07:58:23.700021  1046 solver.cpp:241]     Train net output #0: loss = 1.51451 (* 1 = 1.51451 loss)
I1030 07:58:23.700037  1046 sgd_solver.cpp:105] Iteration 10480, lr = 0.00272704
I1030 07:58:38.462071  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_10500.caffemodel
I1030 07:58:38.499780  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_10500.solverstate
I1030 07:58:38.523316  1046 solver.cpp:334] Iteration 10500, Testing net (#0)
I1030 07:59:09.292912  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 07:59:09.498894  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58256
I1030 07:59:09.498955  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81032
I1030 07:59:09.498970  1046 solver.cpp:401]     Test net output #2: loss = 1.85621 (* 1 = 1.85621 loss)
I1030 07:59:25.871266  1046 solver.cpp:222] Iteration 10520 (0.643408 iter/s, 62.1689s/40 iters), loss = 1.26798
I1030 07:59:25.871340  1046 solver.cpp:241]     Train net output #0: loss = 1.26798 (* 1 = 1.26798 loss)
I1030 07:59:25.871356  1046 sgd_solver.cpp:105] Iteration 10520, lr = 0.00271355
I1030 07:59:56.717005  1046 solver.cpp:222] Iteration 10560 (1.29683 iter/s, 30.8445s/40 iters), loss = 1.20923
I1030 07:59:56.717180  1046 solver.cpp:241]     Train net output #0: loss = 1.20923 (* 1 = 1.20923 loss)
I1030 07:59:56.717196  1046 sgd_solver.cpp:105] Iteration 10560, lr = 0.00270013
I1030 08:00:27.487293  1046 solver.cpp:222] Iteration 10600 (1.30001 iter/s, 30.7689s/40 iters), loss = 1.26136
I1030 08:00:27.487556  1046 solver.cpp:241]     Train net output #0: loss = 1.26136 (* 1 = 1.26136 loss)
I1030 08:00:27.487581  1046 sgd_solver.cpp:105] Iteration 10600, lr = 0.00268677
I1030 08:01:02.316668  1046 solver.cpp:222] Iteration 10640 (1.14851 iter/s, 34.8278s/40 iters), loss = 1.60274
I1030 08:01:02.317162  1046 solver.cpp:241]     Train net output #0: loss = 1.60274 (* 1 = 1.60274 loss)
I1030 08:01:02.317234  1046 sgd_solver.cpp:105] Iteration 10640, lr = 0.00267348
I1030 08:01:33.347931  1046 solver.cpp:222] Iteration 10680 (1.28909 iter/s, 31.0296s/40 iters), loss = 1.32723
I1030 08:01:33.348127  1046 solver.cpp:241]     Train net output #0: loss = 1.32723 (* 1 = 1.32723 loss)
I1030 08:01:33.348145  1046 sgd_solver.cpp:105] Iteration 10680, lr = 0.00266025
I1030 08:02:04.760619  1046 solver.cpp:222] Iteration 10720 (1.27343 iter/s, 31.4113s/40 iters), loss = 1.35301
I1030 08:02:04.760818  1046 solver.cpp:241]     Train net output #0: loss = 1.35301 (* 1 = 1.35301 loss)
I1030 08:02:04.760838  1046 sgd_solver.cpp:105] Iteration 10720, lr = 0.00264709
I1030 08:02:35.867247  1046 solver.cpp:222] Iteration 10760 (1.28596 iter/s, 31.1053s/40 iters), loss = 1.62359
I1030 08:02:35.867435  1046 solver.cpp:241]     Train net output #0: loss = 1.62359 (* 1 = 1.62359 loss)
I1030 08:02:35.867451  1046 sgd_solver.cpp:105] Iteration 10760, lr = 0.002634
I1030 08:03:06.877960  1046 solver.cpp:222] Iteration 10800 (1.28993 iter/s, 31.0094s/40 iters), loss = 1.23287
I1030 08:03:06.878150  1046 solver.cpp:241]     Train net output #0: loss = 1.23287 (* 1 = 1.23287 loss)
I1030 08:03:06.878167  1046 sgd_solver.cpp:105] Iteration 10800, lr = 0.00262097
I1030 08:03:38.074924  1046 solver.cpp:222] Iteration 10840 (1.28223 iter/s, 31.1956s/40 iters), loss = 1.33403
I1030 08:03:38.075090  1046 solver.cpp:241]     Train net output #0: loss = 1.33403 (* 1 = 1.33403 loss)
I1030 08:03:38.075107  1046 sgd_solver.cpp:105] Iteration 10840, lr = 0.002608
I1030 08:04:11.941093  1046 solver.cpp:222] Iteration 10880 (1.18117 iter/s, 33.8647s/40 iters), loss = 1.27904
I1030 08:04:11.941270  1046 solver.cpp:241]     Train net output #0: loss = 1.27904 (* 1 = 1.27904 loss)
I1030 08:04:11.941288  1046 sgd_solver.cpp:105] Iteration 10880, lr = 0.0025951
I1030 08:04:42.887861  1046 solver.cpp:222] Iteration 10920 (1.2926 iter/s, 30.9454s/40 iters), loss = 1.43047
I1030 08:04:42.888059  1046 solver.cpp:241]     Train net output #0: loss = 1.43047 (* 1 = 1.43047 loss)
I1030 08:04:42.888077  1046 sgd_solver.cpp:105] Iteration 10920, lr = 0.00258226
I1030 08:05:13.596027  1046 solver.cpp:222] Iteration 10960 (1.30264 iter/s, 30.7068s/40 iters), loss = 1.20697
I1030 08:05:13.596295  1046 solver.cpp:241]     Train net output #0: loss = 1.20697 (* 1 = 1.20697 loss)
I1030 08:05:13.596330  1046 sgd_solver.cpp:105] Iteration 10960, lr = 0.00256949
I1030 08:05:43.821096  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_11000.caffemodel
I1030 08:05:43.863490  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_11000.solverstate
I1030 08:05:43.882853  1046 solver.cpp:334] Iteration 11000, Testing net (#0)
I1030 08:06:14.854737  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58528
I1030 08:06:14.854915  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.807639
I1030 08:06:14.854931  1046 solver.cpp:401]     Test net output #2: loss = 1.86051 (* 1 = 1.86051 loss)
I1030 08:06:15.626369  1046 solver.cpp:222] Iteration 11000 (0.644873 iter/s, 62.0278s/40 iters), loss = 1.38307
I1030 08:06:15.626430  1046 solver.cpp:241]     Train net output #0: loss = 1.38307 (* 1 = 1.38307 loss)
I1030 08:06:15.626447  1046 sgd_solver.cpp:105] Iteration 11000, lr = 0.00255677
I1030 08:06:46.158826  1046 solver.cpp:222] Iteration 11040 (1.31013 iter/s, 30.5312s/40 iters), loss = 1.13557
I1030 08:06:46.159011  1046 solver.cpp:241]     Train net output #0: loss = 1.13557 (* 1 = 1.13557 loss)
I1030 08:06:46.159029  1046 sgd_solver.cpp:105] Iteration 11040, lr = 0.00254413
I1030 08:07:16.901856  1046 solver.cpp:222] Iteration 11080 (1.30117 iter/s, 30.7417s/40 iters), loss = 1.31965
I1030 08:07:16.902106  1046 solver.cpp:241]     Train net output #0: loss = 1.31965 (* 1 = 1.31965 loss)
I1030 08:07:16.902137  1046 sgd_solver.cpp:105] Iteration 11080, lr = 0.00253154
I1030 08:07:47.785475  1046 solver.cpp:222] Iteration 11120 (1.29524 iter/s, 30.8822s/40 iters), loss = 1.65949
I1030 08:07:47.785681  1046 solver.cpp:241]     Train net output #0: loss = 1.65949 (* 1 = 1.65949 loss)
I1030 08:07:47.785698  1046 sgd_solver.cpp:105] Iteration 11120, lr = 0.00251902
I1030 08:08:18.549564  1046 solver.cpp:222] Iteration 11160 (1.30028 iter/s, 30.7627s/40 iters), loss = 1.36403
I1030 08:08:18.549757  1046 solver.cpp:241]     Train net output #0: loss = 1.36403 (* 1 = 1.36403 loss)
I1030 08:08:18.549773  1046 sgd_solver.cpp:105] Iteration 11160, lr = 0.00250655
I1030 08:08:49.175045  1046 solver.cpp:222] Iteration 11200 (1.30616 iter/s, 30.6241s/40 iters), loss = 1.57199
I1030 08:08:49.175238  1046 solver.cpp:241]     Train net output #0: loss = 1.57199 (* 1 = 1.57199 loss)
I1030 08:08:49.175254  1046 sgd_solver.cpp:105] Iteration 11200, lr = 0.00249415
I1030 08:09:20.196282  1046 solver.cpp:222] Iteration 11240 (1.2895 iter/s, 31.0199s/40 iters), loss = 1.31709
I1030 08:09:20.196478  1046 solver.cpp:241]     Train net output #0: loss = 1.31709 (* 1 = 1.31709 loss)
I1030 08:09:20.196496  1046 sgd_solver.cpp:105] Iteration 11240, lr = 0.00248181
I1030 08:09:51.274601  1046 solver.cpp:222] Iteration 11280 (1.28713 iter/s, 31.077s/40 iters), loss = 1.48959
I1030 08:09:51.274816  1046 solver.cpp:241]     Train net output #0: loss = 1.48959 (* 1 = 1.48959 loss)
I1030 08:09:51.274832  1046 sgd_solver.cpp:105] Iteration 11280, lr = 0.00246954
I1030 08:10:22.208544  1046 solver.cpp:222] Iteration 11320 (1.29314 iter/s, 30.9326s/40 iters), loss = 1.47369
I1030 08:10:22.208758  1046 solver.cpp:241]     Train net output #0: loss = 1.47369 (* 1 = 1.47369 loss)
I1030 08:10:22.208776  1046 sgd_solver.cpp:105] Iteration 11320, lr = 0.00245732
I1030 08:10:52.994693  1046 solver.cpp:222] Iteration 11360 (1.29934 iter/s, 30.7848s/40 iters), loss = 1.50624
I1030 08:10:52.994879  1046 solver.cpp:241]     Train net output #0: loss = 1.50624 (* 1 = 1.50624 loss)
I1030 08:10:52.994896  1046 sgd_solver.cpp:105] Iteration 11360, lr = 0.00244516
I1030 08:11:24.052072  1046 solver.cpp:222] Iteration 11400 (1.28799 iter/s, 31.056s/40 iters), loss = 1.27954
I1030 08:11:24.052278  1046 solver.cpp:241]     Train net output #0: loss = 1.27954 (* 1 = 1.27954 loss)
I1030 08:11:24.052295  1046 sgd_solver.cpp:105] Iteration 11400, lr = 0.00243307
I1030 08:12:00.214342  1046 solver.cpp:222] Iteration 11440 (1.10617 iter/s, 36.1607s/40 iters), loss = 1.97056
I1030 08:12:00.214632  1046 solver.cpp:241]     Train net output #0: loss = 1.97056 (* 1 = 1.97056 loss)
I1030 08:12:00.214661  1046 sgd_solver.cpp:105] Iteration 11440, lr = 0.00242103
I1030 08:12:31.203191  1046 solver.cpp:222] Iteration 11480 (1.29085 iter/s, 30.9874s/40 iters), loss = 1.17818
I1030 08:12:31.203640  1046 solver.cpp:241]     Train net output #0: loss = 1.17818 (* 1 = 1.17818 loss)
I1030 08:12:31.203657  1046 sgd_solver.cpp:105] Iteration 11480, lr = 0.00240905
I1030 08:12:45.884966  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_11500.caffemodel
I1030 08:12:45.917990  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_11500.solverstate
I1030 08:12:45.960752  1046 solver.cpp:334] Iteration 11500, Testing net (#0)
I1030 08:13:18.661269  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 08:13:18.866842  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58412
I1030 08:13:18.866900  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8096
I1030 08:13:18.866914  1046 solver.cpp:401]     Test net output #2: loss = 1.84991 (* 1 = 1.84991 loss)
I1030 08:13:35.345577  1046 solver.cpp:222] Iteration 11520 (0.62364 iter/s, 64.1395s/40 iters), loss = 1.49908
I1030 08:13:35.345657  1046 solver.cpp:241]     Train net output #0: loss = 1.49908 (* 1 = 1.49908 loss)
I1030 08:13:35.345690  1046 sgd_solver.cpp:105] Iteration 11520, lr = 0.00239713
I1030 08:14:06.289085  1046 solver.cpp:222] Iteration 11560 (1.29273 iter/s, 30.9422s/40 iters), loss = 1.43692
I1030 08:14:06.289674  1046 solver.cpp:241]     Train net output #0: loss = 1.43692 (* 1 = 1.43692 loss)
I1030 08:14:06.289702  1046 sgd_solver.cpp:105] Iteration 11560, lr = 0.00238528
I1030 08:14:38.706933  1046 solver.cpp:222] Iteration 11600 (1.23396 iter/s, 32.416s/40 iters), loss = 1.59233
I1030 08:14:38.707136  1046 solver.cpp:241]     Train net output #0: loss = 1.59233 (* 1 = 1.59233 loss)
I1030 08:14:38.707152  1046 sgd_solver.cpp:105] Iteration 11600, lr = 0.00237347
I1030 08:15:09.797425  1046 solver.cpp:222] Iteration 11640 (1.28662 iter/s, 31.0891s/40 iters), loss = 1.46041
I1030 08:15:09.797628  1046 solver.cpp:241]     Train net output #0: loss = 1.46041 (* 1 = 1.46041 loss)
I1030 08:15:09.797646  1046 sgd_solver.cpp:105] Iteration 11640, lr = 0.00236173
I1030 08:15:40.464069  1046 solver.cpp:222] Iteration 11680 (1.30441 iter/s, 30.6653s/40 iters), loss = 1.47303
I1030 08:15:40.464246  1046 solver.cpp:241]     Train net output #0: loss = 1.47303 (* 1 = 1.47303 loss)
I1030 08:15:40.464262  1046 sgd_solver.cpp:105] Iteration 11680, lr = 0.00235005
I1030 08:16:10.945267  1046 solver.cpp:222] Iteration 11720 (1.31234 iter/s, 30.4799s/40 iters), loss = 1.50013
I1030 08:16:10.945466  1046 solver.cpp:241]     Train net output #0: loss = 1.50013 (* 1 = 1.50013 loss)
I1030 08:16:10.945483  1046 sgd_solver.cpp:105] Iteration 11720, lr = 0.00233842
I1030 08:16:41.291800  1046 solver.cpp:222] Iteration 11760 (1.31817 iter/s, 30.3452s/40 iters), loss = 1.38474
I1030 08:16:41.291990  1046 solver.cpp:241]     Train net output #0: loss = 1.38474 (* 1 = 1.38474 loss)
I1030 08:16:41.292008  1046 sgd_solver.cpp:105] Iteration 11760, lr = 0.00232685
I1030 08:17:11.798252  1046 solver.cpp:222] Iteration 11800 (1.31126 iter/s, 30.5051s/40 iters), loss = 1.55721
I1030 08:17:11.798430  1046 solver.cpp:241]     Train net output #0: loss = 1.55721 (* 1 = 1.55721 loss)
I1030 08:17:11.798447  1046 sgd_solver.cpp:105] Iteration 11800, lr = 0.00231534
I1030 08:17:42.220207  1046 solver.cpp:222] Iteration 11840 (1.3149 iter/s, 30.4206s/40 iters), loss = 1.48937
I1030 08:17:42.220376  1046 solver.cpp:241]     Train net output #0: loss = 1.48937 (* 1 = 1.48937 loss)
I1030 08:17:42.220392  1046 sgd_solver.cpp:105] Iteration 11840, lr = 0.00230389
I1030 08:18:12.873479  1046 solver.cpp:222] Iteration 11880 (1.30497 iter/s, 30.6519s/40 iters), loss = 1.76221
I1030 08:18:12.873670  1046 solver.cpp:241]     Train net output #0: loss = 1.76221 (* 1 = 1.76221 loss)
I1030 08:18:12.873687  1046 sgd_solver.cpp:105] Iteration 11880, lr = 0.00229249
I1030 08:18:43.408911  1046 solver.cpp:222] Iteration 11920 (1.31001 iter/s, 30.5341s/40 iters), loss = 1.34087
I1030 08:18:43.409086  1046 solver.cpp:241]     Train net output #0: loss = 1.34087 (* 1 = 1.34087 loss)
I1030 08:18:43.409103  1046 sgd_solver.cpp:105] Iteration 11920, lr = 0.00228115
I1030 08:19:13.939229  1046 solver.cpp:222] Iteration 11960 (1.31023 iter/s, 30.529s/40 iters), loss = 1.51242
I1030 08:19:13.939424  1046 solver.cpp:241]     Train net output #0: loss = 1.51242 (* 1 = 1.51242 loss)
I1030 08:19:13.939440  1046 sgd_solver.cpp:105] Iteration 11960, lr = 0.00226987
I1030 08:19:43.665308  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_12000.caffemodel
I1030 08:19:43.697970  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_12000.solverstate
I1030 08:19:43.716506  1046 solver.cpp:334] Iteration 12000, Testing net (#0)
I1030 08:20:14.627147  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58408
I1030 08:20:14.627602  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80748
I1030 08:20:14.627619  1046 solver.cpp:401]     Test net output #2: loss = 1.84683 (* 1 = 1.84683 loss)
I1030 08:20:15.390790  1046 solver.cpp:222] Iteration 12000 (0.650946 iter/s, 61.4491s/40 iters), loss = 1.80216
I1030 08:20:15.390873  1046 solver.cpp:241]     Train net output #0: loss = 1.80216 (* 1 = 1.80216 loss)
I1030 08:20:15.390888  1046 sgd_solver.cpp:105] Iteration 12000, lr = 0.00225864
I1030 08:20:46.197553  1046 solver.cpp:222] Iteration 12040 (1.29847 iter/s, 30.8055s/40 iters), loss = 1.50943
I1030 08:20:46.197798  1046 solver.cpp:241]     Train net output #0: loss = 1.50943 (* 1 = 1.50943 loss)
I1030 08:20:46.197816  1046 sgd_solver.cpp:105] Iteration 12040, lr = 0.00224746
I1030 08:21:16.973402  1046 solver.cpp:222] Iteration 12080 (1.29978 iter/s, 30.7744s/40 iters), loss = 1.50524
I1030 08:21:16.973594  1046 solver.cpp:241]     Train net output #0: loss = 1.50524 (* 1 = 1.50524 loss)
I1030 08:21:16.973611  1046 sgd_solver.cpp:105] Iteration 12080, lr = 0.00223634
I1030 08:21:47.518472  1046 solver.cpp:222] Iteration 12120 (1.3096 iter/s, 30.5437s/40 iters), loss = 1.66923
I1030 08:21:47.518651  1046 solver.cpp:241]     Train net output #0: loss = 1.66923 (* 1 = 1.66923 loss)
I1030 08:21:47.518667  1046 sgd_solver.cpp:105] Iteration 12120, lr = 0.00222528
I1030 08:22:18.091779  1046 solver.cpp:222] Iteration 12160 (1.30839 iter/s, 30.572s/40 iters), loss = 1.61542
I1030 08:22:18.091948  1046 solver.cpp:241]     Train net output #0: loss = 1.61542 (* 1 = 1.61542 loss)
I1030 08:22:18.091965  1046 sgd_solver.cpp:105] Iteration 12160, lr = 0.00221427
I1030 08:22:48.875876  1046 solver.cpp:222] Iteration 12200 (1.29943 iter/s, 30.7828s/40 iters), loss = 1.26674
I1030 08:22:48.876061  1046 solver.cpp:241]     Train net output #0: loss = 1.26674 (* 1 = 1.26674 loss)
I1030 08:22:48.876078  1046 sgd_solver.cpp:105] Iteration 12200, lr = 0.00220332
I1030 08:23:20.253919  1046 solver.cpp:222] Iteration 12240 (1.27483 iter/s, 31.3767s/40 iters), loss = 1.56699
I1030 08:23:20.254132  1046 solver.cpp:241]     Train net output #0: loss = 1.56699 (* 1 = 1.56699 loss)
I1030 08:23:20.254148  1046 sgd_solver.cpp:105] Iteration 12240, lr = 0.00219242
I1030 08:23:51.098829  1046 solver.cpp:222] Iteration 12280 (1.29687 iter/s, 30.8435s/40 iters), loss = 1.93306
I1030 08:23:51.099032  1046 solver.cpp:241]     Train net output #0: loss = 1.93306 (* 1 = 1.93306 loss)
I1030 08:23:51.099050  1046 sgd_solver.cpp:105] Iteration 12280, lr = 0.00218157
I1030 08:24:21.977802  1046 solver.cpp:222] Iteration 12320 (1.29544 iter/s, 30.8776s/40 iters), loss = 1.30998
I1030 08:24:21.977993  1046 solver.cpp:241]     Train net output #0: loss = 1.30998 (* 1 = 1.30998 loss)
I1030 08:24:21.978009  1046 sgd_solver.cpp:105] Iteration 12320, lr = 0.00217078
I1030 08:24:52.807893  1046 solver.cpp:222] Iteration 12360 (1.29749 iter/s, 30.8287s/40 iters), loss = 0.878945
I1030 08:24:52.808109  1046 solver.cpp:241]     Train net output #0: loss = 0.878945 (* 1 = 0.878945 loss)
I1030 08:24:52.808127  1046 sgd_solver.cpp:105] Iteration 12360, lr = 0.00216004
I1030 08:25:24.439393  1046 solver.cpp:222] Iteration 12400 (1.26462 iter/s, 31.6301s/40 iters), loss = 1.34141
I1030 08:25:24.439640  1046 solver.cpp:241]     Train net output #0: loss = 1.34141 (* 1 = 1.34141 loss)
I1030 08:25:24.439666  1046 sgd_solver.cpp:105] Iteration 12400, lr = 0.00214935
I1030 08:25:55.809523  1046 solver.cpp:222] Iteration 12440 (1.27516 iter/s, 31.3687s/40 iters), loss = 1.54399
I1030 08:25:55.809697  1046 solver.cpp:241]     Train net output #0: loss = 1.54399 (* 1 = 1.54399 loss)
I1030 08:25:55.809713  1046 sgd_solver.cpp:105] Iteration 12440, lr = 0.00213872
I1030 08:26:26.470415  1046 solver.cpp:222] Iteration 12480 (1.30465 iter/s, 30.6595s/40 iters), loss = 1.32791
I1030 08:26:26.470654  1046 solver.cpp:241]     Train net output #0: loss = 1.32791 (* 1 = 1.32791 loss)
I1030 08:26:26.470679  1046 sgd_solver.cpp:105] Iteration 12480, lr = 0.00212814
I1030 08:26:41.623641  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_12500.caffemodel
I1030 08:26:41.655180  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_12500.solverstate
I1030 08:26:41.672237  1046 solver.cpp:334] Iteration 12500, Testing net (#0)
I1030 08:27:12.543826  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 08:27:12.751202  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5838
I1030 08:27:12.751266  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81108
I1030 08:27:12.751283  1046 solver.cpp:401]     Test net output #2: loss = 1.84944 (* 1 = 1.84944 loss)
I1030 08:27:20.413724  1096 data_layer.cpp:73] Restarting data prefetching from start.
I1030 08:27:29.624176  1046 solver.cpp:222] Iteration 12520 (0.633401 iter/s, 63.1511s/40 iters), loss = 1.37194
I1030 08:27:29.624279  1046 solver.cpp:241]     Train net output #0: loss = 1.37194 (* 1 = 1.37194 loss)
I1030 08:27:29.624310  1046 sgd_solver.cpp:105] Iteration 12520, lr = 0.00211761
I1030 08:28:00.306021  1046 solver.cpp:222] Iteration 12560 (1.30376 iter/s, 30.6806s/40 iters), loss = 1.72159
I1030 08:28:00.306243  1046 solver.cpp:241]     Train net output #0: loss = 1.72159 (* 1 = 1.72159 loss)
I1030 08:28:00.306262  1046 sgd_solver.cpp:105] Iteration 12560, lr = 0.00210713
I1030 08:28:31.105520  1046 solver.cpp:222] Iteration 12600 (1.29878 iter/s, 30.7981s/40 iters), loss = 1.40061
I1030 08:28:31.105690  1046 solver.cpp:241]     Train net output #0: loss = 1.40061 (* 1 = 1.40061 loss)
I1030 08:28:31.105708  1046 sgd_solver.cpp:105] Iteration 12600, lr = 0.00209671
I1030 08:29:01.733227  1046 solver.cpp:222] Iteration 12640 (1.30606 iter/s, 30.6264s/40 iters), loss = 1.39857
I1030 08:29:01.733394  1046 solver.cpp:241]     Train net output #0: loss = 1.39857 (* 1 = 1.39857 loss)
I1030 08:29:01.733412  1046 sgd_solver.cpp:105] Iteration 12640, lr = 0.00208634
I1030 08:29:32.633555  1046 solver.cpp:222] Iteration 12680 (1.29454 iter/s, 30.899s/40 iters), loss = 1.17319
I1030 08:29:32.633750  1046 solver.cpp:241]     Train net output #0: loss = 1.17319 (* 1 = 1.17319 loss)
I1030 08:29:32.633769  1046 sgd_solver.cpp:105] Iteration 12680, lr = 0.00207602
I1030 08:30:03.163381  1046 solver.cpp:222] Iteration 12720 (1.31025 iter/s, 30.5285s/40 iters), loss = 1.46223
I1030 08:30:03.163560  1046 solver.cpp:241]     Train net output #0: loss = 1.46223 (* 1 = 1.46223 loss)
I1030 08:30:03.163583  1046 sgd_solver.cpp:105] Iteration 12720, lr = 0.00206575
I1030 08:30:33.532012  1046 solver.cpp:222] Iteration 12760 (1.31721 iter/s, 30.3673s/40 iters), loss = 1.2211
I1030 08:30:33.532207  1046 solver.cpp:241]     Train net output #0: loss = 1.2211 (* 1 = 1.2211 loss)
I1030 08:30:33.532224  1046 sgd_solver.cpp:105] Iteration 12760, lr = 0.00205553
I1030 08:31:04.249505  1046 solver.cpp:222] Iteration 12800 (1.30225 iter/s, 30.7161s/40 iters), loss = 1.51404
I1030 08:31:04.249724  1046 solver.cpp:241]     Train net output #0: loss = 1.51404 (* 1 = 1.51404 loss)
I1030 08:31:04.249742  1046 sgd_solver.cpp:105] Iteration 12800, lr = 0.00204536
I1030 08:31:35.151573  1046 solver.cpp:222] Iteration 12840 (1.29447 iter/s, 30.9007s/40 iters), loss = 1.4507
I1030 08:31:35.151790  1046 solver.cpp:241]     Train net output #0: loss = 1.4507 (* 1 = 1.4507 loss)
I1030 08:31:35.151808  1046 sgd_solver.cpp:105] Iteration 12840, lr = 0.00203524
I1030 08:32:06.326020  1046 solver.cpp:222] Iteration 12880 (1.28316 iter/s, 31.1731s/40 iters), loss = 1.49767
I1030 08:32:06.326220  1046 solver.cpp:241]     Train net output #0: loss = 1.49767 (* 1 = 1.49767 loss)
I1030 08:32:06.326237  1046 sgd_solver.cpp:105] Iteration 12880, lr = 0.00202517
I1030 08:32:37.237490  1046 solver.cpp:222] Iteration 12920 (1.29408 iter/s, 30.9101s/40 iters), loss = 1.08592
I1030 08:32:37.237691  1046 solver.cpp:241]     Train net output #0: loss = 1.08592 (* 1 = 1.08592 loss)
I1030 08:32:37.237709  1046 sgd_solver.cpp:105] Iteration 12920, lr = 0.00201515
I1030 08:33:08.167100  1046 solver.cpp:222] Iteration 12960 (1.29332 iter/s, 30.9282s/40 iters), loss = 1.89791
I1030 08:33:08.167353  1046 solver.cpp:241]     Train net output #0: loss = 1.89791 (* 1 = 1.89791 loss)
I1030 08:33:08.167382  1046 sgd_solver.cpp:105] Iteration 12960, lr = 0.00200518
I1030 08:33:49.400990  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_13000.caffemodel
I1030 08:33:49.434240  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_13000.solverstate
I1030 08:33:49.452498  1046 solver.cpp:334] Iteration 13000, Testing net (#0)
I1030 08:34:20.340615  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58396
I1030 08:34:20.340790  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.808759
I1030 08:34:20.340806  1046 solver.cpp:401]     Test net output #2: loss = 1.84067 (* 1 = 1.84067 loss)
I1030 08:34:21.091368  1046 solver.cpp:222] Iteration 13000 (0.548537 iter/s, 72.9213s/40 iters), loss = 1.07051
I1030 08:34:21.091428  1046 solver.cpp:241]     Train net output #0: loss = 1.07051 (* 1 = 1.07051 loss)
I1030 08:34:21.091444  1046 sgd_solver.cpp:105] Iteration 13000, lr = 0.00199526
I1030 08:34:57.392771  1046 solver.cpp:222] Iteration 13040 (1.10193 iter/s, 36.3s/40 iters), loss = 1.49924
I1030 08:34:57.392982  1046 solver.cpp:241]     Train net output #0: loss = 1.49924 (* 1 = 1.49924 loss)
I1030 08:34:57.393000  1046 sgd_solver.cpp:105] Iteration 13040, lr = 0.00198539
I1030 08:35:28.246026  1046 solver.cpp:222] Iteration 13080 (1.29652 iter/s, 30.8519s/40 iters), loss = 1.23581
I1030 08:35:28.246246  1046 solver.cpp:241]     Train net output #0: loss = 1.23581 (* 1 = 1.23581 loss)
I1030 08:35:28.246268  1046 sgd_solver.cpp:105] Iteration 13080, lr = 0.00197557
I1030 08:35:58.931542  1046 solver.cpp:222] Iteration 13120 (1.3036 iter/s, 30.6841s/40 iters), loss = 1.2421
I1030 08:35:58.931759  1046 solver.cpp:241]     Train net output #0: loss = 1.2421 (* 1 = 1.2421 loss)
I1030 08:35:58.931777  1046 sgd_solver.cpp:105] Iteration 13120, lr = 0.0019658
I1030 08:36:29.485549  1046 solver.cpp:222] Iteration 13160 (1.30922 iter/s, 30.5526s/40 iters), loss = 1.4315
I1030 08:36:29.485785  1046 solver.cpp:241]     Train net output #0: loss = 1.4315 (* 1 = 1.4315 loss)
I1030 08:36:29.485812  1046 sgd_solver.cpp:105] Iteration 13160, lr = 0.00195607
I1030 08:37:00.612057  1046 solver.cpp:222] Iteration 13200 (1.28514 iter/s, 31.1251s/40 iters), loss = 1.26033
I1030 08:37:00.612272  1046 solver.cpp:241]     Train net output #0: loss = 1.26033 (* 1 = 1.26033 loss)
I1030 08:37:00.612289  1046 sgd_solver.cpp:105] Iteration 13200, lr = 0.00194639
I1030 08:37:31.582448  1046 solver.cpp:222] Iteration 13240 (1.29161 iter/s, 30.969s/40 iters), loss = 1.55025
I1030 08:37:31.582659  1046 solver.cpp:241]     Train net output #0: loss = 1.55025 (* 1 = 1.55025 loss)
I1030 08:37:31.582675  1046 sgd_solver.cpp:105] Iteration 13240, lr = 0.00193677
I1030 08:38:02.161592  1046 solver.cpp:222] Iteration 13280 (1.30814 iter/s, 30.5778s/40 iters), loss = 1.50883
I1030 08:38:02.161794  1046 solver.cpp:241]     Train net output #0: loss = 1.50883 (* 1 = 1.50883 loss)
I1030 08:38:02.161814  1046 sgd_solver.cpp:105] Iteration 13280, lr = 0.00192718
I1030 08:38:32.806164  1046 solver.cpp:222] Iteration 13320 (1.30535 iter/s, 30.6432s/40 iters), loss = 1.4169
I1030 08:38:32.806380  1046 solver.cpp:241]     Train net output #0: loss = 1.4169 (* 1 = 1.4169 loss)
I1030 08:38:32.806398  1046 sgd_solver.cpp:105] Iteration 13320, lr = 0.00191765
I1030 08:39:03.548924  1046 solver.cpp:222] Iteration 13360 (1.30118 iter/s, 30.7414s/40 iters), loss = 1.25564
I1030 08:39:03.549118  1046 solver.cpp:241]     Train net output #0: loss = 1.25564 (* 1 = 1.25564 loss)
I1030 08:39:03.549137  1046 sgd_solver.cpp:105] Iteration 13360, lr = 0.00190816
I1030 08:39:34.143523  1046 solver.cpp:222] Iteration 13400 (1.30748 iter/s, 30.5933s/40 iters), loss = 1.15892
I1030 08:39:34.143707  1046 solver.cpp:241]     Train net output #0: loss = 1.15892 (* 1 = 1.15892 loss)
I1030 08:39:34.143726  1046 sgd_solver.cpp:105] Iteration 13400, lr = 0.00189872
I1030 08:40:04.729692  1046 solver.cpp:222] Iteration 13440 (1.30784 iter/s, 30.5848s/40 iters), loss = 1.51945
I1030 08:40:04.729954  1046 solver.cpp:241]     Train net output #0: loss = 1.51945 (* 1 = 1.51945 loss)
I1030 08:40:04.729990  1046 sgd_solver.cpp:105] Iteration 13440, lr = 0.00188933
I1030 08:40:35.801611  1046 solver.cpp:222] Iteration 13480 (1.2874 iter/s, 31.0705s/40 iters), loss = 1.28584
I1030 08:40:35.801825  1046 solver.cpp:241]     Train net output #0: loss = 1.28584 (* 1 = 1.28584 loss)
I1030 08:40:35.801842  1046 sgd_solver.cpp:105] Iteration 13480, lr = 0.00187998
I1030 08:40:50.373451  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_13500.caffemodel
I1030 08:40:50.405189  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_13500.solverstate
I1030 08:40:50.423894  1046 solver.cpp:334] Iteration 13500, Testing net (#0)
I1030 08:41:21.199971  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 08:41:21.406376  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58324
I1030 08:41:21.406437  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.812559
I1030 08:41:21.406451  1046 solver.cpp:401]     Test net output #2: loss = 1.85475 (* 1 = 1.85475 loss)
I1030 08:41:37.448719  1046 solver.cpp:222] Iteration 13520 (0.648881 iter/s, 61.6446s/40 iters), loss = 1.41772
I1030 08:41:37.448838  1046 solver.cpp:241]     Train net output #0: loss = 1.41772 (* 1 = 1.41772 loss)
I1030 08:41:37.448861  1046 sgd_solver.cpp:105] Iteration 13520, lr = 0.00187068
I1030 08:42:19.089630  1046 solver.cpp:222] Iteration 13560 (0.960633 iter/s, 41.6392s/40 iters), loss = 1.06684
I1030 08:42:19.089846  1046 solver.cpp:241]     Train net output #0: loss = 1.06684 (* 1 = 1.06684 loss)
I1030 08:42:19.089864  1046 sgd_solver.cpp:105] Iteration 13560, lr = 0.00186143
I1030 08:42:49.995815  1046 solver.cpp:222] Iteration 13600 (1.2943 iter/s, 30.9048s/40 iters), loss = 1.89548
I1030 08:42:49.995986  1046 solver.cpp:241]     Train net output #0: loss = 1.89548 (* 1 = 1.89548 loss)
I1030 08:42:49.996004  1046 sgd_solver.cpp:105] Iteration 13600, lr = 0.00185222
I1030 08:43:20.771620  1046 solver.cpp:222] Iteration 13640 (1.29978 iter/s, 30.7745s/40 iters), loss = 1.46414
I1030 08:43:20.771823  1046 solver.cpp:241]     Train net output #0: loss = 1.46414 (* 1 = 1.46414 loss)
I1030 08:43:20.771842  1046 sgd_solver.cpp:105] Iteration 13640, lr = 0.00184306
I1030 08:43:51.839529  1046 solver.cpp:222] Iteration 13680 (1.28756 iter/s, 31.0665s/40 iters), loss = 1.26147
I1030 08:43:51.839743  1046 solver.cpp:241]     Train net output #0: loss = 1.26147 (* 1 = 1.26147 loss)
I1030 08:43:51.839761  1046 sgd_solver.cpp:105] Iteration 13680, lr = 0.00183394
I1030 08:44:22.535606  1046 solver.cpp:222] Iteration 13720 (1.30316 iter/s, 30.6947s/40 iters), loss = 1.36629
I1030 08:44:22.535804  1046 solver.cpp:241]     Train net output #0: loss = 1.36629 (* 1 = 1.36629 loss)
I1030 08:44:22.535821  1046 sgd_solver.cpp:105] Iteration 13720, lr = 0.00182487
I1030 08:44:53.030581  1046 solver.cpp:222] Iteration 13760 (1.31175 iter/s, 30.4936s/40 iters), loss = 1.68287
I1030 08:44:53.030761  1046 solver.cpp:241]     Train net output #0: loss = 1.68287 (* 1 = 1.68287 loss)
I1030 08:44:53.030776  1046 sgd_solver.cpp:105] Iteration 13760, lr = 0.00181584
I1030 08:45:23.495124  1046 solver.cpp:222] Iteration 13800 (1.31306 iter/s, 30.4632s/40 iters), loss = 1.33047
I1030 08:45:23.495316  1046 solver.cpp:241]     Train net output #0: loss = 1.33047 (* 1 = 1.33047 loss)
I1030 08:45:23.495335  1046 sgd_solver.cpp:105] Iteration 13800, lr = 0.00180685
I1030 08:45:54.451097  1046 solver.cpp:222] Iteration 13840 (1.29221 iter/s, 30.9546s/40 iters), loss = 1.32204
I1030 08:45:54.451285  1046 solver.cpp:241]     Train net output #0: loss = 1.32204 (* 1 = 1.32204 loss)
I1030 08:45:54.451308  1046 sgd_solver.cpp:105] Iteration 13840, lr = 0.00179792
I1030 08:46:25.413997  1046 solver.cpp:222] Iteration 13880 (1.29193 iter/s, 30.9615s/40 iters), loss = 1.52764
I1030 08:46:25.414232  1046 solver.cpp:241]     Train net output #0: loss = 1.52764 (* 1 = 1.52764 loss)
I1030 08:46:25.414263  1046 sgd_solver.cpp:105] Iteration 13880, lr = 0.00178902
I1030 08:46:55.879510  1046 solver.cpp:222] Iteration 13920 (1.31302 iter/s, 30.4641s/40 iters), loss = 1.52716
I1030 08:46:55.879678  1046 solver.cpp:241]     Train net output #0: loss = 1.52716 (* 1 = 1.52716 loss)
I1030 08:46:55.879693  1046 sgd_solver.cpp:105] Iteration 13920, lr = 0.00178017
I1030 08:47:26.219410  1046 solver.cpp:222] Iteration 13960 (1.31845 iter/s, 30.3386s/40 iters), loss = 1.78324
I1030 08:47:26.219569  1046 solver.cpp:241]     Train net output #0: loss = 1.78324 (* 1 = 1.78324 loss)
I1030 08:47:26.219593  1046 sgd_solver.cpp:105] Iteration 13960, lr = 0.00177136
I1030 08:47:56.026970  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_14000.caffemodel
I1030 08:47:56.059684  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_14000.solverstate
I1030 08:47:56.076972  1046 solver.cpp:334] Iteration 14000, Testing net (#0)
I1030 08:48:26.992416  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58612
I1030 08:48:26.992607  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.808439
I1030 08:48:26.992624  1046 solver.cpp:401]     Test net output #2: loss = 1.84348 (* 1 = 1.84348 loss)
I1030 08:48:27.768471  1046 solver.cpp:222] Iteration 14000 (0.649914 iter/s, 61.5466s/40 iters), loss = 1.46944
I1030 08:48:27.768534  1046 solver.cpp:241]     Train net output #0: loss = 1.46944 (* 1 = 1.46944 loss)
I1030 08:48:27.768549  1046 sgd_solver.cpp:105] Iteration 14000, lr = 0.0017626
I1030 08:48:58.341212  1046 solver.cpp:222] Iteration 14040 (1.30841 iter/s, 30.5715s/40 iters), loss = 1.36094
I1030 08:48:58.341413  1046 solver.cpp:241]     Train net output #0: loss = 1.36094 (* 1 = 1.36094 loss)
I1030 08:48:58.341431  1046 sgd_solver.cpp:105] Iteration 14040, lr = 0.00175388
I1030 08:49:28.953609  1046 solver.cpp:222] Iteration 14080 (1.30672 iter/s, 30.611s/40 iters), loss = 1.41629
I1030 08:49:28.953809  1046 solver.cpp:241]     Train net output #0: loss = 1.41629 (* 1 = 1.41629 loss)
I1030 08:49:28.953827  1046 sgd_solver.cpp:105] Iteration 14080, lr = 0.0017452
I1030 08:49:59.774693  1046 solver.cpp:222] Iteration 14120 (1.29787 iter/s, 30.8197s/40 iters), loss = 1.23449
I1030 08:49:59.774895  1046 solver.cpp:241]     Train net output #0: loss = 1.23449 (* 1 = 1.23449 loss)
I1030 08:49:59.774916  1046 sgd_solver.cpp:105] Iteration 14120, lr = 0.00173657
I1030 08:50:30.115872  1046 solver.cpp:222] Iteration 14160 (1.3184 iter/s, 30.3398s/40 iters), loss = 1.63329
I1030 08:50:30.116084  1046 solver.cpp:241]     Train net output #0: loss = 1.63329 (* 1 = 1.63329 loss)
I1030 08:50:30.116106  1046 sgd_solver.cpp:105] Iteration 14160, lr = 0.00172798
I1030 08:51:00.364449  1046 solver.cpp:222] Iteration 14200 (1.32244 iter/s, 30.2472s/40 iters), loss = 1.77414
I1030 08:51:00.364610  1046 solver.cpp:241]     Train net output #0: loss = 1.77414 (* 1 = 1.77414 loss)
I1030 08:51:00.364627  1046 sgd_solver.cpp:105] Iteration 14200, lr = 0.00171943
I1030 08:51:30.523828  1046 solver.cpp:222] Iteration 14240 (1.32634 iter/s, 30.1581s/40 iters), loss = 1.65039
I1030 08:51:30.524027  1046 solver.cpp:241]     Train net output #0: loss = 1.65039 (* 1 = 1.65039 loss)
I1030 08:51:30.524045  1046 sgd_solver.cpp:105] Iteration 14240, lr = 0.00171092
I1030 08:52:01.224776  1046 solver.cpp:222] Iteration 14280 (1.30295 iter/s, 30.6996s/40 iters), loss = 1.40351
I1030 08:52:01.224987  1046 solver.cpp:241]     Train net output #0: loss = 1.40351 (* 1 = 1.40351 loss)
I1030 08:52:01.225005  1046 sgd_solver.cpp:105] Iteration 14280, lr = 0.00170246
I1030 08:52:31.595083  1046 solver.cpp:222] Iteration 14320 (1.31713 iter/s, 30.369s/40 iters), loss = 1.39307
I1030 08:52:31.595259  1046 solver.cpp:241]     Train net output #0: loss = 1.39307 (* 1 = 1.39307 loss)
I1030 08:52:31.595276  1046 sgd_solver.cpp:105] Iteration 14320, lr = 0.00169404
I1030 08:53:02.368559  1046 solver.cpp:222] Iteration 14360 (1.29988 iter/s, 30.7721s/40 iters), loss = 1.43914
I1030 08:53:02.368820  1046 solver.cpp:241]     Train net output #0: loss = 1.43914 (* 1 = 1.43914 loss)
I1030 08:53:02.368839  1046 sgd_solver.cpp:105] Iteration 14360, lr = 0.00168566
I1030 08:53:32.980741  1046 solver.cpp:222] Iteration 14400 (1.30673 iter/s, 30.6108s/40 iters), loss = 1.22401
I1030 08:53:32.980922  1046 solver.cpp:241]     Train net output #0: loss = 1.22401 (* 1 = 1.22401 loss)
I1030 08:53:32.980940  1046 sgd_solver.cpp:105] Iteration 14400, lr = 0.00167732
I1030 08:54:03.529670  1046 solver.cpp:222] Iteration 14440 (1.30943 iter/s, 30.5476s/40 iters), loss = 1.67062
I1030 08:54:03.529880  1046 solver.cpp:241]     Train net output #0: loss = 1.67062 (* 1 = 1.67062 loss)
I1030 08:54:03.529896  1046 sgd_solver.cpp:105] Iteration 14440, lr = 0.00166902
I1030 08:54:33.899294  1046 solver.cpp:222] Iteration 14480 (1.31716 iter/s, 30.3683s/40 iters), loss = 1.40925
I1030 08:54:33.899467  1046 solver.cpp:241]     Train net output #0: loss = 1.40925 (* 1 = 1.40925 loss)
I1030 08:54:33.899484  1046 sgd_solver.cpp:105] Iteration 14480, lr = 0.00166076
I1030 08:54:48.355742  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_14500.caffemodel
I1030 08:54:48.387787  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_14500.solverstate
I1030 08:54:48.404631  1046 solver.cpp:334] Iteration 14500, Testing net (#0)
I1030 08:55:19.125128  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 08:55:19.332947  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58428
I1030 08:55:19.333006  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.812319
I1030 08:55:19.333020  1046 solver.cpp:401]     Test net output #2: loss = 1.84127 (* 1 = 1.84127 loss)
I1030 08:55:35.531888  1046 solver.cpp:222] Iteration 14520 (0.649033 iter/s, 61.6301s/40 iters), loss = 1.29055
I1030 08:55:35.531955  1046 solver.cpp:241]     Train net output #0: loss = 1.29055 (* 1 = 1.29055 loss)
I1030 08:55:35.531971  1046 sgd_solver.cpp:105] Iteration 14520, lr = 0.00165255
I1030 08:56:06.907914  1046 solver.cpp:222] Iteration 14560 (1.27491 iter/s, 31.3748s/40 iters), loss = 1.55831
I1030 08:56:06.908164  1046 solver.cpp:241]     Train net output #0: loss = 1.55831 (* 1 = 1.55831 loss)
I1030 08:56:06.908190  1046 sgd_solver.cpp:105] Iteration 14560, lr = 0.00164437
I1030 08:56:39.434164  1046 solver.cpp:222] Iteration 14600 (1.22983 iter/s, 32.5248s/40 iters), loss = 1.20815
I1030 08:56:39.434376  1046 solver.cpp:241]     Train net output #0: loss = 1.20815 (* 1 = 1.20815 loss)
I1030 08:56:39.434401  1046 sgd_solver.cpp:105] Iteration 14600, lr = 0.00163624
I1030 08:57:11.918310  1046 solver.cpp:222] Iteration 14640 (1.23142 iter/s, 32.4827s/40 iters), loss = 1.10147
I1030 08:57:11.918506  1046 solver.cpp:241]     Train net output #0: loss = 1.10147 (* 1 = 1.10147 loss)
I1030 08:57:11.918529  1046 sgd_solver.cpp:105] Iteration 14640, lr = 0.00162814
I1030 08:57:54.833065  1046 solver.cpp:222] Iteration 14680 (0.93212 iter/s, 42.9129s/40 iters), loss = 1.58365
I1030 08:57:54.833246  1046 solver.cpp:241]     Train net output #0: loss = 1.58365 (* 1 = 1.58365 loss)
I1030 08:57:54.833263  1046 sgd_solver.cpp:105] Iteration 14680, lr = 0.00162009
I1030 08:58:25.646203  1046 solver.cpp:222] Iteration 14720 (1.2982 iter/s, 30.8118s/40 iters), loss = 1.42301
I1030 08:58:25.646373  1046 solver.cpp:241]     Train net output #0: loss = 1.42301 (* 1 = 1.42301 loss)
I1030 08:58:25.646391  1046 sgd_solver.cpp:105] Iteration 14720, lr = 0.00161207
I1030 08:58:56.505987  1046 solver.cpp:222] Iteration 14760 (1.29624 iter/s, 30.8584s/40 iters), loss = 1.56327
I1030 08:58:56.506171  1046 solver.cpp:241]     Train net output #0: loss = 1.56327 (* 1 = 1.56327 loss)
I1030 08:58:56.506188  1046 sgd_solver.cpp:105] Iteration 14760, lr = 0.0016041
I1030 08:59:27.376788  1046 solver.cpp:222] Iteration 14800 (1.29578 iter/s, 30.8695s/40 iters), loss = 1.44006
I1030 08:59:27.377012  1046 solver.cpp:241]     Train net output #0: loss = 1.44006 (* 1 = 1.44006 loss)
I1030 08:59:27.377029  1046 sgd_solver.cpp:105] Iteration 14800, lr = 0.00159616
I1030 08:59:58.640782  1046 solver.cpp:222] Iteration 14840 (1.27948 iter/s, 31.2626s/40 iters), loss = 1.77019
I1030 08:59:58.641014  1046 solver.cpp:241]     Train net output #0: loss = 1.77019 (* 1 = 1.77019 loss)
I1030 08:59:58.641037  1046 sgd_solver.cpp:105] Iteration 14840, lr = 0.00158827
I1030 09:00:30.064239  1046 solver.cpp:222] Iteration 14880 (1.27299 iter/s, 31.422s/40 iters), loss = 1.57764
I1030 09:00:30.064435  1046 solver.cpp:241]     Train net output #0: loss = 1.57764 (* 1 = 1.57764 loss)
I1030 09:00:30.064453  1046 sgd_solver.cpp:105] Iteration 14880, lr = 0.00158041
I1030 09:01:01.278218  1046 solver.cpp:222] Iteration 14920 (1.28153 iter/s, 31.2126s/40 iters), loss = 1.0594
I1030 09:01:01.278388  1046 solver.cpp:241]     Train net output #0: loss = 1.0594 (* 1 = 1.0594 loss)
I1030 09:01:01.278405  1046 sgd_solver.cpp:105] Iteration 14920, lr = 0.00157259
I1030 09:01:32.401679  1046 solver.cpp:222] Iteration 14960 (1.28526 iter/s, 31.1221s/40 iters), loss = 1.11214
I1030 09:01:32.401870  1046 solver.cpp:241]     Train net output #0: loss = 1.11214 (* 1 = 1.11214 loss)
I1030 09:01:32.401887  1046 sgd_solver.cpp:105] Iteration 14960, lr = 0.00156481
I1030 09:02:02.272372  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_15000.caffemodel
I1030 09:02:02.313989  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_15000.solverstate
I1030 09:02:02.331113  1046 solver.cpp:334] Iteration 15000, Testing net (#0)
I1030 09:02:33.302429  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58532
I1030 09:02:33.302649  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8084
I1030 09:02:33.302664  1046 solver.cpp:401]     Test net output #2: loss = 1.84437 (* 1 = 1.84437 loss)
I1030 09:02:34.073631  1046 solver.cpp:222] Iteration 15000 (0.648619 iter/s, 61.6695s/40 iters), loss = 1.28253
I1030 09:02:34.073691  1046 solver.cpp:241]     Train net output #0: loss = 1.28253 (* 1 = 1.28253 loss)
I1030 09:02:34.073706  1046 sgd_solver.cpp:105] Iteration 15000, lr = 0.00155707
I1030 09:02:41.036041  1096 data_layer.cpp:73] Restarting data prefetching from start.
I1030 09:03:04.605785  1046 solver.cpp:222] Iteration 15040 (1.31015 iter/s, 30.5309s/40 iters), loss = 1.1961
I1030 09:03:04.605940  1046 solver.cpp:241]     Train net output #0: loss = 1.1961 (* 1 = 1.1961 loss)
I1030 09:03:04.605957  1046 sgd_solver.cpp:105] Iteration 15040, lr = 0.00154937
I1030 09:03:35.153852  1046 solver.cpp:222] Iteration 15080 (1.30947 iter/s, 30.5468s/40 iters), loss = 1.31625
I1030 09:03:35.154031  1046 solver.cpp:241]     Train net output #0: loss = 1.31625 (* 1 = 1.31625 loss)
I1030 09:03:35.154050  1046 sgd_solver.cpp:105] Iteration 15080, lr = 0.0015417
I1030 09:04:05.800482  1046 solver.cpp:222] Iteration 15120 (1.30526 iter/s, 30.6453s/40 iters), loss = 1.26882
I1030 09:04:05.800657  1046 solver.cpp:241]     Train net output #0: loss = 1.26882 (* 1 = 1.26882 loss)
I1030 09:04:05.800676  1046 sgd_solver.cpp:105] Iteration 15120, lr = 0.00153407
I1030 09:04:36.492827  1046 solver.cpp:222] Iteration 15160 (1.30331 iter/s, 30.691s/40 iters), loss = 1.38512
I1030 09:04:36.493017  1046 solver.cpp:241]     Train net output #0: loss = 1.38512 (* 1 = 1.38512 loss)
I1030 09:04:36.493036  1046 sgd_solver.cpp:105] Iteration 15160, lr = 0.00152648
I1030 09:05:07.182673  1046 solver.cpp:222] Iteration 15200 (1.30342 iter/s, 30.6885s/40 iters), loss = 1.40898
I1030 09:05:07.182868  1046 solver.cpp:241]     Train net output #0: loss = 1.40898 (* 1 = 1.40898 loss)
I1030 09:05:07.182884  1046 sgd_solver.cpp:105] Iteration 15200, lr = 0.00151893
I1030 09:05:38.341080  1046 solver.cpp:222] Iteration 15240 (1.28382 iter/s, 31.157s/40 iters), loss = 1.318
I1030 09:05:38.341329  1046 solver.cpp:241]     Train net output #0: loss = 1.318 (* 1 = 1.318 loss)
I1030 09:05:38.341361  1046 sgd_solver.cpp:105] Iteration 15240, lr = 0.00151142
I1030 09:06:09.093328  1046 solver.cpp:222] Iteration 15280 (1.30078 iter/s, 30.7508s/40 iters), loss = 1.73084
I1030 09:06:09.093526  1046 solver.cpp:241]     Train net output #0: loss = 1.73084 (* 1 = 1.73084 loss)
I1030 09:06:09.093545  1046 sgd_solver.cpp:105] Iteration 15280, lr = 0.00150394
I1030 09:06:40.047088  1046 solver.cpp:222] Iteration 15320 (1.29231 iter/s, 30.9524s/40 iters), loss = 1.4821
I1030 09:06:40.047288  1046 solver.cpp:241]     Train net output #0: loss = 1.4821 (* 1 = 1.4821 loss)
I1030 09:06:40.047309  1046 sgd_solver.cpp:105] Iteration 15320, lr = 0.0014965
I1030 09:07:11.039594  1046 solver.cpp:222] Iteration 15360 (1.29069 iter/s, 30.9911s/40 iters), loss = 1.45479
I1030 09:07:11.039851  1046 solver.cpp:241]     Train net output #0: loss = 1.45479 (* 1 = 1.45479 loss)
I1030 09:07:11.039878  1046 sgd_solver.cpp:105] Iteration 15360, lr = 0.0014891
I1030 09:07:43.038090  1046 solver.cpp:222] Iteration 15400 (1.25012 iter/s, 31.997s/40 iters), loss = 1.24259
I1030 09:07:43.038359  1046 solver.cpp:241]     Train net output #0: loss = 1.24259 (* 1 = 1.24259 loss)
I1030 09:07:43.038386  1046 sgd_solver.cpp:105] Iteration 15400, lr = 0.00148173
I1030 09:08:15.046887  1046 solver.cpp:222] Iteration 15440 (1.24971 iter/s, 32.0073s/40 iters), loss = 1.25837
I1030 09:08:15.047099  1046 solver.cpp:241]     Train net output #0: loss = 1.25837 (* 1 = 1.25837 loss)
I1030 09:08:15.047116  1046 sgd_solver.cpp:105] Iteration 15440, lr = 0.0014744
I1030 09:08:45.917114  1046 solver.cpp:222] Iteration 15480 (1.2958 iter/s, 30.8689s/40 iters), loss = 1.36902
I1030 09:08:45.917306  1046 solver.cpp:241]     Train net output #0: loss = 1.36902 (* 1 = 1.36902 loss)
I1030 09:08:45.917325  1046 sgd_solver.cpp:105] Iteration 15480, lr = 0.00146711
I1030 09:09:00.595552  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_15500.caffemodel
I1030 09:09:00.631192  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_15500.solverstate
I1030 09:09:00.654819  1046 solver.cpp:334] Iteration 15500, Testing net (#0)
I1030 09:09:31.505264  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 09:09:31.714182  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5854
I1030 09:09:31.714241  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81212
I1030 09:09:31.714254  1046 solver.cpp:401]     Test net output #2: loss = 1.84578 (* 1 = 1.84578 loss)
I1030 09:09:47.863822  1046 solver.cpp:222] Iteration 15520 (0.645742 iter/s, 61.9442s/40 iters), loss = 1.3925
I1030 09:09:47.863890  1046 solver.cpp:241]     Train net output #0: loss = 1.3925 (* 1 = 1.3925 loss)
I1030 09:09:47.863906  1046 sgd_solver.cpp:105] Iteration 15520, lr = 0.00145985
I1030 09:10:19.004024  1046 solver.cpp:222] Iteration 15560 (1.28456 iter/s, 31.139s/40 iters), loss = 1.44863
I1030 09:10:19.004243  1046 solver.cpp:241]     Train net output #0: loss = 1.44863 (* 1 = 1.44863 loss)
I1030 09:10:19.004263  1046 sgd_solver.cpp:105] Iteration 15560, lr = 0.00145263
I1030 09:10:50.046224  1046 solver.cpp:222] Iteration 15600 (1.28863 iter/s, 31.0408s/40 iters), loss = 1.29096
I1030 09:10:50.046447  1046 solver.cpp:241]     Train net output #0: loss = 1.29096 (* 1 = 1.29096 loss)
I1030 09:10:50.046463  1046 sgd_solver.cpp:105] Iteration 15600, lr = 0.00144544
I1030 09:11:21.174480  1046 solver.cpp:222] Iteration 15640 (1.28506 iter/s, 31.1269s/40 iters), loss = 1.61857
I1030 09:11:21.174685  1046 solver.cpp:241]     Train net output #0: loss = 1.61857 (* 1 = 1.61857 loss)
I1030 09:11:21.174703  1046 sgd_solver.cpp:105] Iteration 15640, lr = 0.00143829
I1030 09:11:52.265934  1046 solver.cpp:222] Iteration 15680 (1.28658 iter/s, 31.0901s/40 iters), loss = 1.45834
I1030 09:11:52.266166  1046 solver.cpp:241]     Train net output #0: loss = 1.45834 (* 1 = 1.45834 loss)
I1030 09:11:52.266183  1046 sgd_solver.cpp:105] Iteration 15680, lr = 0.00143117
I1030 09:12:22.748471  1046 solver.cpp:222] Iteration 15720 (1.31229 iter/s, 30.4812s/40 iters), loss = 1.47015
I1030 09:12:22.748646  1046 solver.cpp:241]     Train net output #0: loss = 1.47015 (* 1 = 1.47015 loss)
I1030 09:12:22.748663  1046 sgd_solver.cpp:105] Iteration 15720, lr = 0.00142409
I1030 09:12:53.700973  1046 solver.cpp:222] Iteration 15760 (1.29236 iter/s, 30.9512s/40 iters), loss = 1.36442
I1030 09:12:53.701205  1046 solver.cpp:241]     Train net output #0: loss = 1.36442 (* 1 = 1.36442 loss)
I1030 09:12:53.701231  1046 sgd_solver.cpp:105] Iteration 15760, lr = 0.00141705
I1030 09:13:24.525274  1046 solver.cpp:222] Iteration 15800 (1.29774 iter/s, 30.8229s/40 iters), loss = 1.53547
I1030 09:13:24.525452  1046 solver.cpp:241]     Train net output #0: loss = 1.53547 (* 1 = 1.53547 loss)
I1030 09:13:24.525470  1046 sgd_solver.cpp:105] Iteration 15800, lr = 0.00141004
I1030 09:13:54.360572  1046 solver.cpp:222] Iteration 15840 (1.34075 iter/s, 29.834s/40 iters), loss = 1.25115
I1030 09:13:54.360638  1046 solver.cpp:241]     Train net output #0: loss = 1.25115 (* 1 = 1.25115 loss)
I1030 09:13:54.360653  1046 sgd_solver.cpp:105] Iteration 15840, lr = 0.00140306
I1030 09:14:24.206205  1046 solver.cpp:222] Iteration 15880 (1.34028 iter/s, 29.8444s/40 iters), loss = 1.27905
I1030 09:14:24.206418  1046 solver.cpp:241]     Train net output #0: loss = 1.27905 (* 1 = 1.27905 loss)
I1030 09:14:24.206436  1046 sgd_solver.cpp:105] Iteration 15880, lr = 0.00139612
I1030 09:14:54.928787  1046 solver.cpp:222] Iteration 15920 (1.30203 iter/s, 30.7212s/40 iters), loss = 1.59777
I1030 09:14:54.928948  1046 solver.cpp:241]     Train net output #0: loss = 1.59777 (* 1 = 1.59777 loss)
I1030 09:14:54.928966  1046 sgd_solver.cpp:105] Iteration 15920, lr = 0.00138921
I1030 09:15:25.450906  1046 solver.cpp:222] Iteration 15960 (1.31058 iter/s, 30.5208s/40 iters), loss = 1.16977
I1030 09:15:25.451112  1046 solver.cpp:241]     Train net output #0: loss = 1.16977 (* 1 = 1.16977 loss)
I1030 09:15:25.451133  1046 sgd_solver.cpp:105] Iteration 15960, lr = 0.00138234
I1030 09:15:55.233712  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_16000.caffemodel
I1030 09:15:55.265410  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_16000.solverstate
I1030 09:15:55.283885  1046 solver.cpp:334] Iteration 16000, Testing net (#0)
I1030 09:16:26.237279  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58584
I1030 09:16:26.237469  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80936
I1030 09:16:26.237485  1046 solver.cpp:401]     Test net output #2: loss = 1.8408 (* 1 = 1.8408 loss)
I1030 09:16:27.013818  1046 solver.cpp:222] Iteration 16000 (0.649768 iter/s, 61.5604s/40 iters), loss = 1.5396
I1030 09:16:27.013877  1046 solver.cpp:241]     Train net output #0: loss = 1.5396 (* 1 = 1.5396 loss)
I1030 09:16:27.013895  1046 sgd_solver.cpp:105] Iteration 16000, lr = 0.0013755
I1030 09:16:57.446264  1046 solver.cpp:222] Iteration 16040 (1.31444 iter/s, 30.4312s/40 iters), loss = 1.61546
I1030 09:16:57.446440  1046 solver.cpp:241]     Train net output #0: loss = 1.61546 (* 1 = 1.61546 loss)
I1030 09:16:57.446457  1046 sgd_solver.cpp:105] Iteration 16040, lr = 0.0013687
I1030 09:17:27.813603  1046 solver.cpp:222] Iteration 16080 (1.31726 iter/s, 30.366s/40 iters), loss = 1.41642
I1030 09:17:27.813767  1046 solver.cpp:241]     Train net output #0: loss = 1.41642 (* 1 = 1.41642 loss)
I1030 09:17:27.813784  1046 sgd_solver.cpp:105] Iteration 16080, lr = 0.00136193
I1030 09:17:58.322480  1046 solver.cpp:222] Iteration 16120 (1.31115 iter/s, 30.5076s/40 iters), loss = 1.41653
I1030 09:17:58.322643  1046 solver.cpp:241]     Train net output #0: loss = 1.41653 (* 1 = 1.41653 loss)
I1030 09:17:58.322659  1046 sgd_solver.cpp:105] Iteration 16120, lr = 0.00135519
I1030 09:18:28.789867  1046 solver.cpp:222] Iteration 16160 (1.31294 iter/s, 30.4661s/40 iters), loss = 1.2516
I1030 09:18:28.790055  1046 solver.cpp:241]     Train net output #0: loss = 1.2516 (* 1 = 1.2516 loss)
I1030 09:18:28.790086  1046 sgd_solver.cpp:105] Iteration 16160, lr = 0.00134849
I1030 09:18:59.196965  1046 solver.cpp:222] Iteration 16200 (1.31554 iter/s, 30.4058s/40 iters), loss = 1.32527
I1030 09:18:59.197154  1046 solver.cpp:241]     Train net output #0: loss = 1.32527 (* 1 = 1.32527 loss)
I1030 09:18:59.197172  1046 sgd_solver.cpp:105] Iteration 16200, lr = 0.00134181
I1030 09:19:29.503423  1046 solver.cpp:222] Iteration 16240 (1.31991 iter/s, 30.3051s/40 iters), loss = 1.24262
I1030 09:19:29.503576  1046 solver.cpp:241]     Train net output #0: loss = 1.24262 (* 1 = 1.24262 loss)
I1030 09:19:29.503592  1046 sgd_solver.cpp:105] Iteration 16240, lr = 0.00133518
I1030 09:19:59.823923  1046 solver.cpp:222] Iteration 16280 (1.3193 iter/s, 30.3192s/40 iters), loss = 1.39999
I1030 09:19:59.824101  1046 solver.cpp:241]     Train net output #0: loss = 1.39999 (* 1 = 1.39999 loss)
I1030 09:19:59.824117  1046 sgd_solver.cpp:105] Iteration 16280, lr = 0.00132857
I1030 09:20:30.532311  1046 solver.cpp:222] Iteration 16320 (1.30263 iter/s, 30.7071s/40 iters), loss = 1.39712
I1030 09:20:30.532541  1046 solver.cpp:241]     Train net output #0: loss = 1.39712 (* 1 = 1.39712 loss)
I1030 09:20:30.532557  1046 sgd_solver.cpp:105] Iteration 16320, lr = 0.001322
I1030 09:21:01.294073  1046 solver.cpp:222] Iteration 16360 (1.30037 iter/s, 30.7604s/40 iters), loss = 1.49256
I1030 09:21:01.294286  1046 solver.cpp:241]     Train net output #0: loss = 1.49256 (* 1 = 1.49256 loss)
I1030 09:21:01.294317  1046 sgd_solver.cpp:105] Iteration 16360, lr = 0.00131546
I1030 09:21:31.784667  1046 solver.cpp:222] Iteration 16400 (1.31194 iter/s, 30.4892s/40 iters), loss = 1.43039
I1030 09:21:31.784873  1046 solver.cpp:241]     Train net output #0: loss = 1.43039 (* 1 = 1.43039 loss)
I1030 09:21:31.784896  1046 sgd_solver.cpp:105] Iteration 16400, lr = 0.00130895
I1030 09:22:02.621001  1046 solver.cpp:222] Iteration 16440 (1.29723 iter/s, 30.835s/40 iters), loss = 1.49941
I1030 09:22:02.621203  1046 solver.cpp:241]     Train net output #0: loss = 1.49941 (* 1 = 1.49941 loss)
I1030 09:22:02.621222  1046 sgd_solver.cpp:105] Iteration 16440, lr = 0.00130247
I1030 09:22:34.144536  1046 solver.cpp:222] Iteration 16480 (1.26895 iter/s, 31.5221s/40 iters), loss = 1.42285
I1030 09:22:34.144740  1046 solver.cpp:241]     Train net output #0: loss = 1.42285 (* 1 = 1.42285 loss)
I1030 09:22:34.144757  1046 sgd_solver.cpp:105] Iteration 16480, lr = 0.00129603
I1030 09:22:48.685994  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_16500.caffemodel
I1030 09:22:48.718928  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_16500.solverstate
I1030 09:22:48.740245  1046 solver.cpp:334] Iteration 16500, Testing net (#0)
I1030 09:23:19.554181  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 09:23:19.760629  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58544
I1030 09:23:19.760690  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.812039
I1030 09:23:19.760704  1046 solver.cpp:401]     Test net output #2: loss = 1.85001 (* 1 = 1.85001 loss)
I1030 09:23:35.823691  1046 solver.cpp:222] Iteration 16520 (0.648544 iter/s, 61.6766s/40 iters), loss = 1.53981
I1030 09:23:35.823765  1046 solver.cpp:241]     Train net output #0: loss = 1.53981 (* 1 = 1.53981 loss)
I1030 09:23:35.823781  1046 sgd_solver.cpp:105] Iteration 16520, lr = 0.00128962
I1030 09:24:06.608305  1046 solver.cpp:222] Iteration 16560 (1.2994 iter/s, 30.7834s/40 iters), loss = 1.26921
I1030 09:24:06.608593  1046 solver.cpp:241]     Train net output #0: loss = 1.26921 (* 1 = 1.26921 loss)
I1030 09:24:06.608621  1046 sgd_solver.cpp:105] Iteration 16560, lr = 0.00128324
I1030 09:24:37.046059  1046 solver.cpp:222] Iteration 16600 (1.31422 iter/s, 30.4363s/40 iters), loss = 1.5881
I1030 09:24:37.046264  1046 solver.cpp:241]     Train net output #0: loss = 1.5881 (* 1 = 1.5881 loss)
I1030 09:24:37.046301  1046 sgd_solver.cpp:105] Iteration 16600, lr = 0.00127689
I1030 09:25:07.967252  1046 solver.cpp:222] Iteration 16640 (1.29367 iter/s, 30.9198s/40 iters), loss = 1.46089
I1030 09:25:07.967456  1046 solver.cpp:241]     Train net output #0: loss = 1.46089 (* 1 = 1.46089 loss)
I1030 09:25:07.967473  1046 sgd_solver.cpp:105] Iteration 16640, lr = 0.00127057
I1030 09:25:39.056224  1046 solver.cpp:222] Iteration 16680 (1.28669 iter/s, 31.0876s/40 iters), loss = 1.21999
I1030 09:25:39.056462  1046 solver.cpp:241]     Train net output #0: loss = 1.21999 (* 1 = 1.21999 loss)
I1030 09:25:39.056480  1046 sgd_solver.cpp:105] Iteration 16680, lr = 0.00126429
I1030 09:26:09.786121  1046 solver.cpp:222] Iteration 16720 (1.30172 iter/s, 30.7285s/40 iters), loss = 1.58602
I1030 09:26:09.786335  1046 solver.cpp:241]     Train net output #0: loss = 1.58602 (* 1 = 1.58602 loss)
I1030 09:26:09.786355  1046 sgd_solver.cpp:105] Iteration 16720, lr = 0.00125803
I1030 09:26:41.020929  1046 solver.cpp:222] Iteration 16760 (1.28068 iter/s, 31.2334s/40 iters), loss = 1.1459
I1030 09:26:41.021140  1046 solver.cpp:241]     Train net output #0: loss = 1.1459 (* 1 = 1.1459 loss)
I1030 09:26:41.021157  1046 sgd_solver.cpp:105] Iteration 16760, lr = 0.00125181
I1030 09:27:11.689368  1046 solver.cpp:222] Iteration 16800 (1.30433 iter/s, 30.6671s/40 iters), loss = 1.41033
I1030 09:27:11.689563  1046 solver.cpp:241]     Train net output #0: loss = 1.41033 (* 1 = 1.41033 loss)
I1030 09:27:11.689581  1046 sgd_solver.cpp:105] Iteration 16800, lr = 0.00124562
I1030 09:27:48.326817  1046 solver.cpp:222] Iteration 16840 (1.09183 iter/s, 36.6359s/40 iters), loss = 1.41714
I1030 09:27:48.327002  1046 solver.cpp:241]     Train net output #0: loss = 1.41714 (* 1 = 1.41714 loss)
I1030 09:27:48.327018  1046 sgd_solver.cpp:105] Iteration 16840, lr = 0.00123946
I1030 09:28:19.452267  1046 solver.cpp:222] Iteration 16880 (1.28518 iter/s, 31.1241s/40 iters), loss = 1.25357
I1030 09:28:19.452466  1046 solver.cpp:241]     Train net output #0: loss = 1.25357 (* 1 = 1.25357 loss)
I1030 09:28:19.452482  1046 sgd_solver.cpp:105] Iteration 16880, lr = 0.00123332
I1030 09:28:50.655879  1046 solver.cpp:222] Iteration 16920 (1.28196 iter/s, 31.2022s/40 iters), loss = 1.44556
I1030 09:28:50.656069  1046 solver.cpp:241]     Train net output #0: loss = 1.44556 (* 1 = 1.44556 loss)
I1030 09:28:50.656085  1046 sgd_solver.cpp:105] Iteration 16920, lr = 0.00122722
I1030 09:29:21.934531  1046 solver.cpp:222] Iteration 16960 (1.27888 iter/s, 31.2773s/40 iters), loss = 1.42999
I1030 09:29:21.934725  1046 solver.cpp:241]     Train net output #0: loss = 1.42999 (* 1 = 1.42999 loss)
I1030 09:29:21.934741  1046 sgd_solver.cpp:105] Iteration 16960, lr = 0.00122115
I1030 09:29:52.096376  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_17000.caffemodel
I1030 09:29:52.127663  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_17000.solverstate
I1030 09:29:52.144596  1046 solver.cpp:334] Iteration 17000, Testing net (#0)
I1030 09:30:23.037688  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58632
I1030 09:30:23.037891  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80908
I1030 09:30:23.037909  1046 solver.cpp:401]     Test net output #2: loss = 1.83676 (* 1 = 1.83676 loss)
I1030 09:30:23.807241  1046 solver.cpp:222] Iteration 17000 (0.646515 iter/s, 61.8702s/40 iters), loss = 1.47875
I1030 09:30:23.807307  1046 solver.cpp:241]     Train net output #0: loss = 1.47875 (* 1 = 1.47875 loss)
I1030 09:30:23.807323  1046 sgd_solver.cpp:105] Iteration 17000, lr = 0.00121511
I1030 09:30:54.658877  1046 solver.cpp:222] Iteration 17040 (1.29658 iter/s, 30.8504s/40 iters), loss = 1.63389
I1030 09:30:54.659068  1046 solver.cpp:241]     Train net output #0: loss = 1.63389 (* 1 = 1.63389 loss)
I1030 09:30:54.659085  1046 sgd_solver.cpp:105] Iteration 17040, lr = 0.0012091
I1030 09:31:25.402191  1046 solver.cpp:222] Iteration 17080 (1.30115 iter/s, 30.742s/40 iters), loss = 1.46055
I1030 09:31:25.402508  1046 solver.cpp:241]     Train net output #0: loss = 1.46055 (* 1 = 1.46055 loss)
I1030 09:31:25.402541  1046 sgd_solver.cpp:105] Iteration 17080, lr = 0.00120312
I1030 09:31:56.068478  1046 solver.cpp:222] Iteration 17120 (1.30443 iter/s, 30.6648s/40 iters), loss = 1.46725
I1030 09:31:56.068666  1046 solver.cpp:241]     Train net output #0: loss = 1.46725 (* 1 = 1.46725 loss)
I1030 09:31:56.068683  1046 sgd_solver.cpp:105] Iteration 17120, lr = 0.00119716
I1030 09:32:26.615310  1046 solver.cpp:222] Iteration 17160 (1.30952 iter/s, 30.5455s/40 iters), loss = 1.32525
I1030 09:32:26.615479  1046 solver.cpp:241]     Train net output #0: loss = 1.32525 (* 1 = 1.32525 loss)
I1030 09:32:26.615497  1046 sgd_solver.cpp:105] Iteration 17160, lr = 0.00119124
I1030 09:32:57.182711  1046 solver.cpp:222] Iteration 17200 (1.30864 iter/s, 30.5661s/40 iters), loss = 1.23741
I1030 09:32:57.182907  1046 solver.cpp:241]     Train net output #0: loss = 1.23741 (* 1 = 1.23741 loss)
I1030 09:32:57.182924  1046 sgd_solver.cpp:105] Iteration 17200, lr = 0.00118535
I1030 09:33:27.792609  1046 solver.cpp:222] Iteration 17240 (1.30682 iter/s, 30.6085s/40 iters), loss = 1.55496
I1030 09:33:27.792768  1046 solver.cpp:241]     Train net output #0: loss = 1.55496 (* 1 = 1.55496 loss)
I1030 09:33:27.792783  1046 sgd_solver.cpp:105] Iteration 17240, lr = 0.00117948
I1030 09:33:58.509312  1046 solver.cpp:222] Iteration 17280 (1.30228 iter/s, 30.7154s/40 iters), loss = 1.18778
I1030 09:33:58.509506  1046 solver.cpp:241]     Train net output #0: loss = 1.18778 (* 1 = 1.18778 loss)
I1030 09:33:58.509523  1046 sgd_solver.cpp:105] Iteration 17280, lr = 0.00117365
I1030 09:34:29.754643  1046 solver.cpp:222] Iteration 17320 (1.28025 iter/s, 31.2439s/40 iters), loss = 1.2679
I1030 09:34:29.754891  1046 solver.cpp:241]     Train net output #0: loss = 1.2679 (* 1 = 1.2679 loss)
I1030 09:34:29.754920  1046 sgd_solver.cpp:105] Iteration 17320, lr = 0.00116784
I1030 09:35:02.453614  1046 solver.cpp:222] Iteration 17360 (1.22334 iter/s, 32.6975s/40 iters), loss = 1.31866
I1030 09:35:02.453860  1046 solver.cpp:241]     Train net output #0: loss = 1.31866 (* 1 = 1.31866 loss)
I1030 09:35:02.453886  1046 sgd_solver.cpp:105] Iteration 17360, lr = 0.00116207
I1030 09:35:36.463009  1046 solver.cpp:222] Iteration 17400 (1.1762 iter/s, 34.0079s/40 iters), loss = 1.45451
I1030 09:35:36.463204  1046 solver.cpp:241]     Train net output #0: loss = 1.45451 (* 1 = 1.45451 loss)
I1030 09:35:36.463220  1046 sgd_solver.cpp:105] Iteration 17400, lr = 0.00115632
I1030 09:36:06.943256  1046 solver.cpp:222] Iteration 17440 (1.31238 iter/s, 30.4789s/40 iters), loss = 1.24644
I1030 09:36:06.943483  1046 solver.cpp:241]     Train net output #0: loss = 1.24644 (* 1 = 1.24644 loss)
I1030 09:36:06.943506  1046 sgd_solver.cpp:105] Iteration 17440, lr = 0.0011506
I1030 09:36:38.980414  1046 solver.cpp:222] Iteration 17480 (1.24861 iter/s, 32.0357s/40 iters), loss = 1.56996
I1030 09:36:38.980585  1046 solver.cpp:241]     Train net output #0: loss = 1.56996 (* 1 = 1.56996 loss)
I1030 09:36:38.980604  1046 sgd_solver.cpp:105] Iteration 17480, lr = 0.0011449
I1030 09:36:53.731779  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_17500.caffemodel
I1030 09:36:53.763339  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_17500.solverstate
I1030 09:36:53.781083  1046 solver.cpp:334] Iteration 17500, Testing net (#0)
I1030 09:37:27.617827  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 09:37:27.825969  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58604
I1030 09:37:27.826031  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.812559
I1030 09:37:27.826045  1046 solver.cpp:401]     Test net output #2: loss = 1.8475 (* 1 = 1.8475 loss)
I1030 09:37:37.708174  1096 data_layer.cpp:73] Restarting data prefetching from start.
I1030 09:37:43.838835  1046 solver.cpp:222] Iteration 17520 (0.616753 iter/s, 64.8558s/40 iters), loss = 1.39078
I1030 09:37:43.838912  1046 solver.cpp:241]     Train net output #0: loss = 1.39078 (* 1 = 1.39078 loss)
I1030 09:37:43.838928  1046 sgd_solver.cpp:105] Iteration 17520, lr = 0.00113924
I1030 09:38:15.822944  1046 solver.cpp:222] Iteration 17560 (1.25067 iter/s, 31.9828s/40 iters), loss = 1.66886
I1030 09:38:15.823199  1046 solver.cpp:241]     Train net output #0: loss = 1.66886 (* 1 = 1.66886 loss)
I1030 09:38:15.823216  1046 sgd_solver.cpp:105] Iteration 17560, lr = 0.0011336
I1030 09:38:47.697019  1046 solver.cpp:222] Iteration 17600 (1.255 iter/s, 31.8726s/40 iters), loss = 1.14823
I1030 09:38:47.697273  1046 solver.cpp:241]     Train net output #0: loss = 1.14823 (* 1 = 1.14823 loss)
I1030 09:38:47.697302  1046 sgd_solver.cpp:105] Iteration 17600, lr = 0.001128
I1030 09:39:19.211431  1046 solver.cpp:222] Iteration 17640 (1.26932 iter/s, 31.513s/40 iters), loss = 1.45212
I1030 09:39:19.211659  1046 solver.cpp:241]     Train net output #0: loss = 1.45212 (* 1 = 1.45212 loss)
I1030 09:39:19.211678  1046 sgd_solver.cpp:105] Iteration 17640, lr = 0.00112242
I1030 09:39:50.167887  1046 solver.cpp:222] Iteration 17680 (1.2922 iter/s, 30.9551s/40 iters), loss = 1.5728
I1030 09:39:50.168100  1046 solver.cpp:241]     Train net output #0: loss = 1.5728 (* 1 = 1.5728 loss)
I1030 09:39:50.168121  1046 sgd_solver.cpp:105] Iteration 17680, lr = 0.00111686
I1030 09:40:21.237694  1046 solver.cpp:222] Iteration 17720 (1.28748 iter/s, 31.0684s/40 iters), loss = 1.30336
I1030 09:40:21.237910  1046 solver.cpp:241]     Train net output #0: loss = 1.30336 (* 1 = 1.30336 loss)
I1030 09:40:21.237927  1046 sgd_solver.cpp:105] Iteration 17720, lr = 0.00111134
I1030 09:40:52.105231  1046 solver.cpp:222] Iteration 17760 (1.29592 iter/s, 30.8662s/40 iters), loss = 1.74239
I1030 09:40:52.105428  1046 solver.cpp:241]     Train net output #0: loss = 1.74239 (* 1 = 1.74239 loss)
I1030 09:40:52.105445  1046 sgd_solver.cpp:105] Iteration 17760, lr = 0.00110584
I1030 09:41:22.943924  1046 solver.cpp:222] Iteration 17800 (1.29713 iter/s, 30.8373s/40 iters), loss = 0.997162
I1030 09:41:22.944120  1046 solver.cpp:241]     Train net output #0: loss = 0.997162 (* 1 = 0.997162 loss)
I1030 09:41:22.944139  1046 sgd_solver.cpp:105] Iteration 17800, lr = 0.00110037
I1030 09:41:53.826253  1046 solver.cpp:222] Iteration 17840 (1.2953 iter/s, 30.881s/40 iters), loss = 1.36518
I1030 09:41:53.826448  1046 solver.cpp:241]     Train net output #0: loss = 1.36518 (* 1 = 1.36518 loss)
I1030 09:41:53.826465  1046 sgd_solver.cpp:105] Iteration 17840, lr = 0.00109493
I1030 09:42:24.065414  1046 solver.cpp:222] Iteration 17880 (1.32285 iter/s, 30.2378s/40 iters), loss = 1.41696
I1030 09:42:24.065578  1046 solver.cpp:241]     Train net output #0: loss = 1.41696 (* 1 = 1.41696 loss)
I1030 09:42:24.065594  1046 sgd_solver.cpp:105] Iteration 17880, lr = 0.00108951
I1030 09:42:54.887820  1046 solver.cpp:222] Iteration 17920 (1.29781 iter/s, 30.8211s/40 iters), loss = 1.28659
I1030 09:42:54.888000  1046 solver.cpp:241]     Train net output #0: loss = 1.28659 (* 1 = 1.28659 loss)
I1030 09:42:54.888020  1046 sgd_solver.cpp:105] Iteration 17920, lr = 0.00108412
I1030 09:43:25.696969  1046 solver.cpp:222] Iteration 17960 (1.29837 iter/s, 30.8078s/40 iters), loss = 1.62454
I1030 09:43:25.697154  1046 solver.cpp:241]     Train net output #0: loss = 1.62454 (* 1 = 1.62454 loss)
I1030 09:43:25.697170  1046 sgd_solver.cpp:105] Iteration 17960, lr = 0.00107876
I1030 09:43:55.547505  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_18000.caffemodel
I1030 09:43:55.589088  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_18000.solverstate
I1030 09:43:55.605990  1046 solver.cpp:334] Iteration 18000, Testing net (#0)
I1030 09:44:26.686714  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58672
I1030 09:44:26.686944  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.808799
I1030 09:44:26.686980  1046 solver.cpp:401]     Test net output #2: loss = 1.84446 (* 1 = 1.84446 loss)
I1030 09:44:27.456302  1046 solver.cpp:222] Iteration 18000 (0.647702 iter/s, 61.7568s/40 iters), loss = 1.24434
I1030 09:44:27.456368  1046 solver.cpp:241]     Train net output #0: loss = 1.24434 (* 1 = 1.24434 loss)
I1030 09:44:27.456383  1046 sgd_solver.cpp:105] Iteration 18000, lr = 0.00107342
I1030 09:44:58.425817  1046 solver.cpp:222] Iteration 18040 (1.29164 iter/s, 30.9683s/40 iters), loss = 1.19109
I1030 09:44:58.426049  1046 solver.cpp:241]     Train net output #0: loss = 1.19109 (* 1 = 1.19109 loss)
I1030 09:44:58.426074  1046 sgd_solver.cpp:105] Iteration 18040, lr = 0.00106811
I1030 09:45:29.514781  1046 solver.cpp:222] Iteration 18080 (1.28669 iter/s, 31.0876s/40 iters), loss = 1.3602
I1030 09:45:29.514976  1046 solver.cpp:241]     Train net output #0: loss = 1.3602 (* 1 = 1.3602 loss)
I1030 09:45:29.514993  1046 sgd_solver.cpp:105] Iteration 18080, lr = 0.00106282
I1030 09:45:59.977113  1046 solver.cpp:222] Iteration 18120 (1.31316 iter/s, 30.461s/40 iters), loss = 1.36744
I1030 09:45:59.977267  1046 solver.cpp:241]     Train net output #0: loss = 1.36744 (* 1 = 1.36744 loss)
I1030 09:45:59.977284  1046 sgd_solver.cpp:105] Iteration 18120, lr = 0.00105757
I1030 09:46:30.452950  1046 solver.cpp:222] Iteration 18160 (1.31257 iter/s, 30.4745s/40 iters), loss = 1.4596
I1030 09:46:30.453125  1046 solver.cpp:241]     Train net output #0: loss = 1.4596 (* 1 = 1.4596 loss)
I1030 09:46:30.453145  1046 sgd_solver.cpp:105] Iteration 18160, lr = 0.00105233
I1030 09:47:01.155881  1046 solver.cpp:222] Iteration 18200 (1.30286 iter/s, 30.7016s/40 iters), loss = 1.18835
I1030 09:47:01.156085  1046 solver.cpp:241]     Train net output #0: loss = 1.18835 (* 1 = 1.18835 loss)
I1030 09:47:01.156101  1046 sgd_solver.cpp:105] Iteration 18200, lr = 0.00104713
I1030 09:47:32.255704  1046 solver.cpp:222] Iteration 18240 (1.28624 iter/s, 31.0984s/40 iters), loss = 1.22808
I1030 09:47:32.255918  1046 solver.cpp:241]     Train net output #0: loss = 1.22808 (* 1 = 1.22808 loss)
I1030 09:47:32.255934  1046 sgd_solver.cpp:105] Iteration 18240, lr = 0.00104195
I1030 09:48:02.702693  1046 solver.cpp:222] Iteration 18280 (1.31382 iter/s, 30.4456s/40 iters), loss = 1.62174
I1030 09:48:02.702879  1046 solver.cpp:241]     Train net output #0: loss = 1.62174 (* 1 = 1.62174 loss)
I1030 09:48:02.702896  1046 sgd_solver.cpp:105] Iteration 18280, lr = 0.00103679
I1030 09:48:33.125005  1046 solver.cpp:222] Iteration 18320 (1.31488 iter/s, 30.421s/40 iters), loss = 1.30713
I1030 09:48:33.125195  1046 solver.cpp:241]     Train net output #0: loss = 1.30713 (* 1 = 1.30713 loss)
I1030 09:48:33.125216  1046 sgd_solver.cpp:105] Iteration 18320, lr = 0.00103166
I1030 09:49:03.802513  1046 solver.cpp:222] Iteration 18360 (1.30394 iter/s, 30.6762s/40 iters), loss = 1.6244
I1030 09:49:03.802716  1046 solver.cpp:241]     Train net output #0: loss = 1.6244 (* 1 = 1.6244 loss)
I1030 09:49:03.802734  1046 sgd_solver.cpp:105] Iteration 18360, lr = 0.00102656
I1030 09:49:34.266883  1046 solver.cpp:222] Iteration 18400 (1.31307 iter/s, 30.463s/40 iters), loss = 1.39571
I1030 09:49:34.267050  1046 solver.cpp:241]     Train net output #0: loss = 1.39571 (* 1 = 1.39571 loss)
I1030 09:49:34.267069  1046 sgd_solver.cpp:105] Iteration 18400, lr = 0.00102148
I1030 09:50:05.126067  1046 solver.cpp:222] Iteration 18440 (1.29627 iter/s, 30.8579s/40 iters), loss = 1.20797
I1030 09:50:05.126260  1046 solver.cpp:241]     Train net output #0: loss = 1.20797 (* 1 = 1.20797 loss)
I1030 09:50:05.126277  1046 sgd_solver.cpp:105] Iteration 18440, lr = 0.00101643
I1030 09:50:36.165978  1046 solver.cpp:222] Iteration 18480 (1.28872 iter/s, 31.0385s/40 iters), loss = 1.42303
I1030 09:50:36.166177  1046 solver.cpp:241]     Train net output #0: loss = 1.42303 (* 1 = 1.42303 loss)
I1030 09:50:36.166193  1046 sgd_solver.cpp:105] Iteration 18480, lr = 0.0010114
I1030 09:50:50.587855  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_18500.caffemodel
I1030 09:50:50.619141  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_18500.solverstate
I1030 09:50:50.635684  1046 solver.cpp:334] Iteration 18500, Testing net (#0)
I1030 09:51:21.351388  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 09:51:21.558478  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58476
I1030 09:51:21.558542  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.812319
I1030 09:51:21.558557  1046 solver.cpp:401]     Test net output #2: loss = 1.83809 (* 1 = 1.83809 loss)
I1030 09:51:38.345239  1046 solver.cpp:222] Iteration 18520 (0.643327 iter/s, 62.1767s/40 iters), loss = 1.47745
I1030 09:51:38.345312  1046 solver.cpp:241]     Train net output #0: loss = 1.47745 (* 1 = 1.47745 loss)
I1030 09:51:38.345329  1046 sgd_solver.cpp:105] Iteration 18520, lr = 0.0010064
I1030 09:52:08.693081  1046 solver.cpp:222] Iteration 18560 (1.3181 iter/s, 30.3466s/40 iters), loss = 1.28642
I1030 09:52:08.693289  1046 solver.cpp:241]     Train net output #0: loss = 1.28642 (* 1 = 1.28642 loss)
I1030 09:52:08.693310  1046 sgd_solver.cpp:105] Iteration 18560, lr = 0.00100142
I1030 09:52:39.206338  1046 solver.cpp:222] Iteration 18600 (1.31096 iter/s, 30.5119s/40 iters), loss = 1.46753
I1030 09:52:39.206562  1046 solver.cpp:241]     Train net output #0: loss = 1.46753 (* 1 = 1.46753 loss)
I1030 09:52:39.206586  1046 sgd_solver.cpp:105] Iteration 18600, lr = 0.000996464
I1030 09:53:12.268549  1046 solver.cpp:222] Iteration 18640 (1.20989 iter/s, 33.0607s/40 iters), loss = 1.4396
I1030 09:53:12.268736  1046 solver.cpp:241]     Train net output #0: loss = 1.4396 (* 1 = 1.4396 loss)
I1030 09:53:12.268752  1046 sgd_solver.cpp:105] Iteration 18640, lr = 0.000991534
I1030 09:53:43.004458  1046 solver.cpp:222] Iteration 18680 (1.30147 iter/s, 30.7346s/40 iters), loss = 1.61804
I1030 09:53:43.004659  1046 solver.cpp:241]     Train net output #0: loss = 1.61804 (* 1 = 1.61804 loss)
I1030 09:53:43.004676  1046 sgd_solver.cpp:105] Iteration 18680, lr = 0.000986629
I1030 09:54:13.806335  1046 solver.cpp:222] Iteration 18720 (1.29868 iter/s, 30.8005s/40 iters), loss = 1.70288
I1030 09:54:13.806517  1046 solver.cpp:241]     Train net output #0: loss = 1.70288 (* 1 = 1.70288 loss)
I1030 09:54:13.806536  1046 sgd_solver.cpp:105] Iteration 18720, lr = 0.000981748
I1030 09:54:44.200789  1046 solver.cpp:222] Iteration 18760 (1.31609 iter/s, 30.3931s/40 iters), loss = 1.53559
I1030 09:54:44.200968  1046 solver.cpp:241]     Train net output #0: loss = 1.53559 (* 1 = 1.53559 loss)
I1030 09:54:44.200984  1046 sgd_solver.cpp:105] Iteration 18760, lr = 0.000976891
I1030 09:55:14.794549  1046 solver.cpp:222] Iteration 18800 (1.30751 iter/s, 30.5924s/40 iters), loss = 1.58014
I1030 09:55:14.794734  1046 solver.cpp:241]     Train net output #0: loss = 1.58014 (* 1 = 1.58014 loss)
I1030 09:55:14.794749  1046 sgd_solver.cpp:105] Iteration 18800, lr = 0.000972058
I1030 09:55:45.679872  1046 solver.cpp:222] Iteration 18840 (1.29517 iter/s, 30.884s/40 iters), loss = 1.2783
I1030 09:55:45.680038  1046 solver.cpp:241]     Train net output #0: loss = 1.2783 (* 1 = 1.2783 loss)
I1030 09:55:45.680058  1046 sgd_solver.cpp:105] Iteration 18840, lr = 0.000967249
I1030 09:56:16.774768  1046 solver.cpp:222] Iteration 18880 (1.28644 iter/s, 31.0936s/40 iters), loss = 1.44056
I1030 09:56:16.774942  1046 solver.cpp:241]     Train net output #0: loss = 1.44056 (* 1 = 1.44056 loss)
I1030 09:56:16.774960  1046 sgd_solver.cpp:105] Iteration 18880, lr = 0.000962464
I1030 09:56:48.497972  1046 solver.cpp:222] Iteration 18920 (1.26096 iter/s, 31.7218s/40 iters), loss = 1.02848
I1030 09:56:48.498183  1046 solver.cpp:241]     Train net output #0: loss = 1.02848 (* 1 = 1.02848 loss)
I1030 09:56:48.498203  1046 sgd_solver.cpp:105] Iteration 18920, lr = 0.000957703
I1030 09:57:19.278669  1046 solver.cpp:222] Iteration 18960 (1.29957 iter/s, 30.7793s/40 iters), loss = 1.65541
I1030 09:57:19.278892  1046 solver.cpp:241]     Train net output #0: loss = 1.65541 (* 1 = 1.65541 loss)
I1030 09:57:19.278921  1046 sgd_solver.cpp:105] Iteration 18960, lr = 0.000952965
I1030 09:57:49.181917  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_19000.caffemodel
I1030 09:57:49.218914  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_19000.solverstate
I1030 09:57:49.241699  1046 solver.cpp:334] Iteration 19000, Testing net (#0)
I1030 09:58:20.286885  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58844
I1030 09:58:20.287058  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.809199
I1030 09:58:20.287075  1046 solver.cpp:401]     Test net output #2: loss = 1.84257 (* 1 = 1.84257 loss)
I1030 09:58:21.048564  1046 solver.cpp:222] Iteration 19000 (0.647591 iter/s, 61.7674s/40 iters), loss = 1.32277
I1030 09:58:21.048631  1046 solver.cpp:241]     Train net output #0: loss = 1.32277 (* 1 = 1.32277 loss)
I1030 09:58:21.048648  1046 sgd_solver.cpp:105] Iteration 19000, lr = 0.000948251
I1030 09:58:51.665091  1046 solver.cpp:222] Iteration 19040 (1.30654 iter/s, 30.6153s/40 iters), loss = 1.26627
I1030 09:58:51.665302  1046 solver.cpp:241]     Train net output #0: loss = 1.26627 (* 1 = 1.26627 loss)
I1030 09:58:51.665323  1046 sgd_solver.cpp:105] Iteration 19040, lr = 0.000943559
I1030 09:59:22.340595  1046 solver.cpp:222] Iteration 19080 (1.30403 iter/s, 30.6741s/40 iters), loss = 1.26313
I1030 09:59:22.340754  1046 solver.cpp:241]     Train net output #0: loss = 1.26313 (* 1 = 1.26313 loss)
I1030 09:59:22.340772  1046 sgd_solver.cpp:105] Iteration 19080, lr = 0.000938891
I1030 09:59:53.057222  1046 solver.cpp:222] Iteration 19120 (1.30228 iter/s, 30.7153s/40 iters), loss = 1.35106
I1030 09:59:53.057404  1046 solver.cpp:241]     Train net output #0: loss = 1.35106 (* 1 = 1.35106 loss)
I1030 09:59:53.057420  1046 sgd_solver.cpp:105] Iteration 19120, lr = 0.000934247
I1030 10:00:24.052232  1046 solver.cpp:222] Iteration 19160 (1.29059 iter/s, 30.9937s/40 iters), loss = 1.27441
I1030 10:00:24.052446  1046 solver.cpp:241]     Train net output #0: loss = 1.27441 (* 1 = 1.27441 loss)
I1030 10:00:24.052464  1046 sgd_solver.cpp:105] Iteration 19160, lr = 0.000929625
I1030 10:00:54.851079  1046 solver.cpp:222] Iteration 19200 (1.29881 iter/s, 30.7975s/40 iters), loss = 1.15653
I1030 10:00:54.851269  1046 solver.cpp:241]     Train net output #0: loss = 1.15653 (* 1 = 1.15653 loss)
I1030 10:00:54.851285  1046 sgd_solver.cpp:105] Iteration 19200, lr = 0.000925026
I1030 10:01:25.779124  1046 solver.cpp:222] Iteration 19240 (1.29338 iter/s, 30.9267s/40 iters), loss = 1.38147
I1030 10:01:25.779325  1046 solver.cpp:241]     Train net output #0: loss = 1.38147 (* 1 = 1.38147 loss)
I1030 10:01:25.779345  1046 sgd_solver.cpp:105] Iteration 19240, lr = 0.00092045
I1030 10:01:57.189647  1046 solver.cpp:222] Iteration 19280 (1.27352 iter/s, 31.4091s/40 iters), loss = 1.20813
I1030 10:01:57.189878  1046 solver.cpp:241]     Train net output #0: loss = 1.20813 (* 1 = 1.20813 loss)
I1030 10:01:57.189908  1046 sgd_solver.cpp:105] Iteration 19280, lr = 0.000915896
I1030 10:02:27.928778  1046 solver.cpp:222] Iteration 19320 (1.30133 iter/s, 30.7377s/40 iters), loss = 1.60745
I1030 10:02:27.929023  1046 solver.cpp:241]     Train net output #0: loss = 1.60745 (* 1 = 1.60745 loss)
I1030 10:02:27.929047  1046 sgd_solver.cpp:105] Iteration 19320, lr = 0.000911365
I1030 10:03:00.387140  1046 solver.cpp:222] Iteration 19360 (1.2324 iter/s, 32.4569s/40 iters), loss = 1.40394
I1030 10:03:00.387336  1046 solver.cpp:241]     Train net output #0: loss = 1.40394 (* 1 = 1.40394 loss)
I1030 10:03:00.387353  1046 sgd_solver.cpp:105] Iteration 19360, lr = 0.000906856
I1030 10:03:31.222165  1046 solver.cpp:222] Iteration 19400 (1.29728 iter/s, 30.8337s/40 iters), loss = 1.37838
I1030 10:03:31.222343  1046 solver.cpp:241]     Train net output #0: loss = 1.37838 (* 1 = 1.37838 loss)
I1030 10:03:31.222360  1046 sgd_solver.cpp:105] Iteration 19400, lr = 0.00090237
I1030 10:04:02.118981  1046 solver.cpp:222] Iteration 19440 (1.29469 iter/s, 30.8955s/40 iters), loss = 1.70205
I1030 10:04:02.119230  1046 solver.cpp:241]     Train net output #0: loss = 1.70205 (* 1 = 1.70205 loss)
I1030 10:04:02.119251  1046 sgd_solver.cpp:105] Iteration 19440, lr = 0.000897906
I1030 10:04:32.724162  1046 solver.cpp:222] Iteration 19480 (1.30703 iter/s, 30.6038s/40 iters), loss = 1.05219
I1030 10:04:32.724405  1046 solver.cpp:241]     Train net output #0: loss = 1.05219 (* 1 = 1.05219 loss)
I1030 10:04:32.724427  1046 sgd_solver.cpp:105] Iteration 19480, lr = 0.000893464
I1030 10:04:48.056121  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_19500.caffemodel
I1030 10:04:48.097461  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_19500.solverstate
I1030 10:04:48.213943  1046 solver.cpp:334] Iteration 19500, Testing net (#0)
I1030 10:05:18.979547  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 10:05:19.189371  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58572
I1030 10:05:19.189433  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81272
I1030 10:05:19.189446  1046 solver.cpp:401]     Test net output #2: loss = 1.83963 (* 1 = 1.83963 loss)
I1030 10:05:35.286484  1046 solver.cpp:222] Iteration 19520 (0.639389 iter/s, 62.5598s/40 iters), loss = 1.56259
I1030 10:05:35.286558  1046 solver.cpp:241]     Train net output #0: loss = 1.56259 (* 1 = 1.56259 loss)
I1030 10:05:35.286576  1046 sgd_solver.cpp:105] Iteration 19520, lr = 0.000889044
I1030 10:06:06.066720  1046 solver.cpp:222] Iteration 19560 (1.29959 iter/s, 30.779s/40 iters), loss = 1.19315
I1030 10:06:06.066995  1046 solver.cpp:241]     Train net output #0: loss = 1.19315 (* 1 = 1.19315 loss)
I1030 10:06:06.067023  1046 sgd_solver.cpp:105] Iteration 19560, lr = 0.000884645
I1030 10:06:36.644810  1046 solver.cpp:222] Iteration 19600 (1.30819 iter/s, 30.5767s/40 iters), loss = 1.40926
I1030 10:06:36.644984  1046 solver.cpp:241]     Train net output #0: loss = 1.40926 (* 1 = 1.40926 loss)
I1030 10:06:36.645000  1046 sgd_solver.cpp:105] Iteration 19600, lr = 0.000880269
I1030 10:07:07.263175  1046 solver.cpp:222] Iteration 19640 (1.30646 iter/s, 30.617s/40 iters), loss = 1.51075
I1030 10:07:07.263411  1046 solver.cpp:241]     Train net output #0: loss = 1.51075 (* 1 = 1.51075 loss)
I1030 10:07:07.263434  1046 sgd_solver.cpp:105] Iteration 19640, lr = 0.000875914
I1030 10:07:38.180847  1046 solver.cpp:222] Iteration 19680 (1.29382 iter/s, 30.9163s/40 iters), loss = 1.40614
I1030 10:07:38.181056  1046 solver.cpp:241]     Train net output #0: loss = 1.40614 (* 1 = 1.40614 loss)
I1030 10:07:38.181074  1046 sgd_solver.cpp:105] Iteration 19680, lr = 0.000871581
I1030 10:08:09.392421  1046 solver.cpp:222] Iteration 19720 (1.28163 iter/s, 31.2102s/40 iters), loss = 1.63454
I1030 10:08:09.392634  1046 solver.cpp:241]     Train net output #0: loss = 1.63454 (* 1 = 1.63454 loss)
I1030 10:08:09.392652  1046 sgd_solver.cpp:105] Iteration 19720, lr = 0.000867269
I1030 10:08:39.923996  1046 solver.cpp:222] Iteration 19760 (1.31018 iter/s, 30.5302s/40 iters), loss = 1.23987
I1030 10:08:39.924192  1046 solver.cpp:241]     Train net output #0: loss = 1.23987 (* 1 = 1.23987 loss)
I1030 10:08:39.924211  1046 sgd_solver.cpp:105] Iteration 19760, lr = 0.000862979
I1030 10:09:10.930647  1046 solver.cpp:222] Iteration 19800 (1.2901 iter/s, 31.0053s/40 iters), loss = 1.65681
I1030 10:09:10.930824  1046 solver.cpp:241]     Train net output #0: loss = 1.65681 (* 1 = 1.65681 loss)
I1030 10:09:10.930840  1046 sgd_solver.cpp:105] Iteration 19800, lr = 0.000858709
I1030 10:09:42.388171  1046 solver.cpp:222] Iteration 19840 (1.27161 iter/s, 31.4562s/40 iters), loss = 1.48099
I1030 10:09:42.388357  1046 solver.cpp:241]     Train net output #0: loss = 1.48099 (* 1 = 1.48099 loss)
I1030 10:09:42.388375  1046 sgd_solver.cpp:105] Iteration 19840, lr = 0.000854461
I1030 10:10:13.900885  1046 solver.cpp:222] Iteration 19880 (1.26938 iter/s, 31.5113s/40 iters), loss = 1.51131
I1030 10:10:13.901178  1046 solver.cpp:241]     Train net output #0: loss = 1.51131 (* 1 = 1.51131 loss)
I1030 10:10:13.901201  1046 sgd_solver.cpp:105] Iteration 19880, lr = 0.000850234
I1030 10:10:45.120749  1046 solver.cpp:222] Iteration 19920 (1.2813 iter/s, 31.2184s/40 iters), loss = 1.34872
I1030 10:10:45.120952  1046 solver.cpp:241]     Train net output #0: loss = 1.34872 (* 1 = 1.34872 loss)
I1030 10:10:45.120970  1046 sgd_solver.cpp:105] Iteration 19920, lr = 0.000846028
I1030 10:11:16.122680  1046 solver.cpp:222] Iteration 19960 (1.2903 iter/s, 31.0006s/40 iters), loss = 1.51424
I1030 10:11:16.122870  1046 solver.cpp:241]     Train net output #0: loss = 1.51424 (* 1 = 1.51424 loss)
I1030 10:11:16.122886  1046 sgd_solver.cpp:105] Iteration 19960, lr = 0.000841842
I1030 10:11:46.057343  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_20000.caffemodel
I1030 10:11:46.090111  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_20000.solverstate
I1030 10:11:46.107656  1046 solver.cpp:334] Iteration 20000, Testing net (#0)
I1030 10:12:16.989995  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58632
I1030 10:12:16.990190  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8098
I1030 10:12:16.990206  1046 solver.cpp:401]     Test net output #2: loss = 1.84025 (* 1 = 1.84025 loss)
I1030 10:12:17.757305  1046 solver.cpp:222] Iteration 20000 (0.649012 iter/s, 61.6321s/40 iters), loss = 2.03709
I1030 10:12:17.757366  1046 solver.cpp:241]     Train net output #0: loss = 2.03709 (* 1 = 2.03709 loss)
I1030 10:12:17.757381  1046 sgd_solver.cpp:105] Iteration 20000, lr = 0.000837678
I1030 10:12:28.435431  1096 data_layer.cpp:73] Restarting data prefetching from start.
I1030 10:12:48.119992  1046 solver.cpp:222] Iteration 20040 (1.31746 iter/s, 30.3615s/40 iters), loss = 1.34346
I1030 10:12:48.120131  1046 solver.cpp:241]     Train net output #0: loss = 1.34346 (* 1 = 1.34346 loss)
I1030 10:12:48.120147  1046 sgd_solver.cpp:105] Iteration 20040, lr = 0.000833534
I1030 10:13:18.987435  1046 solver.cpp:222] Iteration 20080 (1.29592 iter/s, 30.8661s/40 iters), loss = 1.29755
I1030 10:13:18.987622  1046 solver.cpp:241]     Train net output #0: loss = 1.29755 (* 1 = 1.29755 loss)
I1030 10:13:18.987642  1046 sgd_solver.cpp:105] Iteration 20080, lr = 0.00082941
I1030 10:13:49.595058  1046 solver.cpp:222] Iteration 20120 (1.30692 iter/s, 30.6063s/40 iters), loss = 1.46497
I1030 10:13:49.595263  1046 solver.cpp:241]     Train net output #0: loss = 1.46497 (* 1 = 1.46497 loss)
I1030 10:13:49.595279  1046 sgd_solver.cpp:105] Iteration 20120, lr = 0.000825307
I1030 10:14:19.854501  1046 solver.cpp:222] Iteration 20160 (1.32196 iter/s, 30.2581s/40 iters), loss = 1.21698
I1030 10:14:19.854683  1046 solver.cpp:241]     Train net output #0: loss = 1.21698 (* 1 = 1.21698 loss)
I1030 10:14:19.854702  1046 sgd_solver.cpp:105] Iteration 20160, lr = 0.000821224
I1030 10:14:50.188890  1046 solver.cpp:222] Iteration 20200 (1.31869 iter/s, 30.3331s/40 iters), loss = 1.37464
I1030 10:14:50.189079  1046 solver.cpp:241]     Train net output #0: loss = 1.37464 (* 1 = 1.37464 loss)
I1030 10:14:50.189096  1046 sgd_solver.cpp:105] Iteration 20200, lr = 0.000817161
I1030 10:15:20.470739  1046 solver.cpp:222] Iteration 20240 (1.32098 iter/s, 30.2805s/40 iters), loss = 1.44278
I1030 10:15:20.470929  1046 solver.cpp:241]     Train net output #0: loss = 1.44278 (* 1 = 1.44278 loss)
I1030 10:15:20.470947  1046 sgd_solver.cpp:105] Iteration 20240, lr = 0.000813119
I1030 10:15:50.976068  1046 solver.cpp:222] Iteration 20280 (1.3113 iter/s, 30.504s/40 iters), loss = 1.45745
I1030 10:15:50.976261  1046 solver.cpp:241]     Train net output #0: loss = 1.45745 (* 1 = 1.45745 loss)
I1030 10:15:50.976281  1046 sgd_solver.cpp:105] Iteration 20280, lr = 0.000809096
I1030 10:16:21.462589  1046 solver.cpp:222] Iteration 20320 (1.31211 iter/s, 30.4852s/40 iters), loss = 1.34278
I1030 10:16:21.462836  1046 solver.cpp:241]     Train net output #0: loss = 1.34278 (* 1 = 1.34278 loss)
I1030 10:16:21.462867  1046 sgd_solver.cpp:105] Iteration 20320, lr = 0.000805093
I1030 10:16:51.762944  1046 solver.cpp:222] Iteration 20360 (1.32018 iter/s, 30.299s/40 iters), loss = 1.21773
I1030 10:16:51.763113  1046 solver.cpp:241]     Train net output #0: loss = 1.21773 (* 1 = 1.21773 loss)
I1030 10:16:51.763129  1046 sgd_solver.cpp:105] Iteration 20360, lr = 0.00080111
I1030 10:17:22.165307  1046 solver.cpp:222] Iteration 20400 (1.31574 iter/s, 30.401s/40 iters), loss = 1.47321
I1030 10:17:22.165472  1046 solver.cpp:241]     Train net output #0: loss = 1.47321 (* 1 = 1.47321 loss)
I1030 10:17:22.165488  1046 sgd_solver.cpp:105] Iteration 20400, lr = 0.000797147
I1030 10:17:53.466756  1046 solver.cpp:222] Iteration 20440 (1.27795 iter/s, 31.3001s/40 iters), loss = 1.09747
I1030 10:17:53.466936  1046 solver.cpp:241]     Train net output #0: loss = 1.09747 (* 1 = 1.09747 loss)
I1030 10:17:53.466954  1046 sgd_solver.cpp:105] Iteration 20440, lr = 0.000793204
I1030 10:18:24.779289  1046 solver.cpp:222] Iteration 20480 (1.2775 iter/s, 31.3112s/40 iters), loss = 1.4159
I1030 10:18:24.779458  1046 solver.cpp:241]     Train net output #0: loss = 1.4159 (* 1 = 1.4159 loss)
I1030 10:18:24.779477  1046 sgd_solver.cpp:105] Iteration 20480, lr = 0.000789279
I1030 10:18:39.301594  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_20500.caffemodel
I1030 10:18:39.333173  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_20500.solverstate
I1030 10:18:39.350097  1046 solver.cpp:334] Iteration 20500, Testing net (#0)
I1030 10:19:10.128130  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 10:19:10.335043  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58588
I1030 10:19:10.335103  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81208
I1030 10:19:10.335116  1046 solver.cpp:401]     Test net output #2: loss = 1.84502 (* 1 = 1.84502 loss)
I1030 10:19:26.423430  1046 solver.cpp:222] Iteration 20520 (0.648912 iter/s, 61.6417s/40 iters), loss = 1.47444
I1030 10:19:26.423499  1046 solver.cpp:241]     Train net output #0: loss = 1.47444 (* 1 = 1.47444 loss)
I1030 10:19:26.423516  1046 sgd_solver.cpp:105] Iteration 20520, lr = 0.000785375
I1030 10:19:57.712236  1046 solver.cpp:222] Iteration 20560 (1.27846 iter/s, 31.2875s/40 iters), loss = 1.06984
I1030 10:19:57.712453  1046 solver.cpp:241]     Train net output #0: loss = 1.06984 (* 1 = 1.06984 loss)
I1030 10:19:57.712481  1046 sgd_solver.cpp:105] Iteration 20560, lr = 0.000781489
I1030 10:20:29.140774  1046 solver.cpp:222] Iteration 20600 (1.27279 iter/s, 31.4271s/40 iters), loss = 1.23265
I1030 10:20:29.140952  1046 solver.cpp:241]     Train net output #0: loss = 1.23265 (* 1 = 1.23265 loss)
I1030 10:20:29.140969  1046 sgd_solver.cpp:105] Iteration 20600, lr = 0.000777623
I1030 10:21:00.132696  1046 solver.cpp:222] Iteration 20640 (1.29071 iter/s, 30.9906s/40 iters), loss = 1.35393
I1030 10:21:00.132895  1046 solver.cpp:241]     Train net output #0: loss = 1.35393 (* 1 = 1.35393 loss)
I1030 10:21:00.132912  1046 sgd_solver.cpp:105] Iteration 20640, lr = 0.000773776
I1030 10:21:31.182071  1046 solver.cpp:222] Iteration 20680 (1.28833 iter/s, 31.048s/40 iters), loss = 1.73033
I1030 10:21:31.182271  1046 solver.cpp:241]     Train net output #0: loss = 1.73033 (* 1 = 1.73033 loss)
I1030 10:21:31.182286  1046 sgd_solver.cpp:105] Iteration 20680, lr = 0.000769948
I1030 10:22:01.997004  1046 solver.cpp:222] Iteration 20720 (1.29813 iter/s, 30.8136s/40 iters), loss = 0.972775
I1030 10:22:01.997200  1046 solver.cpp:241]     Train net output #0: loss = 0.972775 (* 1 = 0.972775 loss)
I1030 10:22:01.997217  1046 sgd_solver.cpp:105] Iteration 20720, lr = 0.000766139
I1030 10:22:32.883018  1046 solver.cpp:222] Iteration 20760 (1.29514 iter/s, 30.8847s/40 iters), loss = 1.30488
I1030 10:22:32.883329  1046 solver.cpp:241]     Train net output #0: loss = 1.30488 (* 1 = 1.30488 loss)
I1030 10:22:32.883391  1046 sgd_solver.cpp:105] Iteration 20760, lr = 0.000762349
I1030 10:23:03.603690  1046 solver.cpp:222] Iteration 20800 (1.30212 iter/s, 30.7192s/40 iters), loss = 1.43715
I1030 10:23:03.603912  1046 solver.cpp:241]     Train net output #0: loss = 1.43715 (* 1 = 1.43715 loss)
I1030 10:23:03.603929  1046 sgd_solver.cpp:105] Iteration 20800, lr = 0.000758578
I1030 10:23:34.028925  1046 solver.cpp:222] Iteration 20840 (1.31476 iter/s, 30.4239s/40 iters), loss = 1.28492
I1030 10:23:34.029105  1046 solver.cpp:241]     Train net output #0: loss = 1.28492 (* 1 = 1.28492 loss)
I1030 10:23:34.029124  1046 sgd_solver.cpp:105] Iteration 20840, lr = 0.000754825
I1030 10:24:04.953294  1046 solver.cpp:222] Iteration 20880 (1.29353 iter/s, 30.923s/40 iters), loss = 1.48045
I1030 10:24:04.953503  1046 solver.cpp:241]     Train net output #0: loss = 1.48045 (* 1 = 1.48045 loss)
I1030 10:24:04.953531  1046 sgd_solver.cpp:105] Iteration 20880, lr = 0.000751091
I1030 10:24:36.878726  1046 solver.cpp:222] Iteration 20920 (1.25297 iter/s, 31.924s/40 iters), loss = 1.26649
I1030 10:24:36.878962  1046 solver.cpp:241]     Train net output #0: loss = 1.26649 (* 1 = 1.26649 loss)
I1030 10:24:36.878978  1046 sgd_solver.cpp:105] Iteration 20920, lr = 0.000747375
I1030 10:25:07.447273  1046 solver.cpp:222] Iteration 20960 (1.30859 iter/s, 30.5672s/40 iters), loss = 1.31474
I1030 10:25:07.447481  1046 solver.cpp:241]     Train net output #0: loss = 1.31474 (* 1 = 1.31474 loss)
I1030 10:25:07.447499  1046 sgd_solver.cpp:105] Iteration 20960, lr = 0.000743677
I1030 10:25:37.868175  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_21000.caffemodel
I1030 10:25:37.905469  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_21000.solverstate
I1030 10:25:37.923818  1046 solver.cpp:334] Iteration 21000, Testing net (#0)
I1030 10:26:08.893904  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5862
I1030 10:26:08.894067  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80976
I1030 10:26:08.894083  1046 solver.cpp:401]     Test net output #2: loss = 1.83481 (* 1 = 1.83481 loss)
I1030 10:26:09.658833  1046 solver.cpp:222] Iteration 21000 (0.642993 iter/s, 62.209s/40 iters), loss = 1.65604
I1030 10:26:09.658895  1046 solver.cpp:241]     Train net output #0: loss = 1.65604 (* 1 = 1.65604 loss)
I1030 10:26:09.658913  1046 sgd_solver.cpp:105] Iteration 21000, lr = 0.000739998
I1030 10:26:40.567164  1046 solver.cpp:222] Iteration 21040 (1.2942 iter/s, 30.9071s/40 iters), loss = 1.4491
I1030 10:26:40.567570  1046 solver.cpp:241]     Train net output #0: loss = 1.4491 (* 1 = 1.4491 loss)
I1030 10:26:40.567587  1046 sgd_solver.cpp:105] Iteration 21040, lr = 0.000736338
I1030 10:27:11.414114  1046 solver.cpp:222] Iteration 21080 (1.29679 iter/s, 30.8454s/40 iters), loss = 1.59442
I1030 10:27:11.414312  1046 solver.cpp:241]     Train net output #0: loss = 1.59442 (* 1 = 1.59442 loss)
I1030 10:27:11.414332  1046 sgd_solver.cpp:105] Iteration 21080, lr = 0.000732695
I1030 10:27:42.786533  1046 solver.cpp:222] Iteration 21120 (1.27506 iter/s, 31.371s/40 iters), loss = 1.31292
I1030 10:27:42.786761  1046 solver.cpp:241]     Train net output #0: loss = 1.31292 (* 1 = 1.31292 loss)
I1030 10:27:42.786778  1046 sgd_solver.cpp:105] Iteration 21120, lr = 0.00072907
I1030 10:28:14.686777  1046 solver.cpp:222] Iteration 21160 (1.25396 iter/s, 31.8988s/40 iters), loss = 1.43374
I1030 10:28:14.686954  1046 solver.cpp:241]     Train net output #0: loss = 1.43374 (* 1 = 1.43374 loss)
I1030 10:28:14.686971  1046 sgd_solver.cpp:105] Iteration 21160, lr = 0.000725463
I1030 10:28:45.423790  1046 solver.cpp:222] Iteration 21200 (1.30142 iter/s, 30.7357s/40 iters), loss = 1.47462
I1030 10:28:45.423993  1046 solver.cpp:241]     Train net output #0: loss = 1.47462 (* 1 = 1.47462 loss)
I1030 10:28:45.424013  1046 sgd_solver.cpp:105] Iteration 21200, lr = 0.000721874
I1030 10:29:16.130825  1046 solver.cpp:222] Iteration 21240 (1.30269 iter/s, 30.7057s/40 iters), loss = 1.19133
I1030 10:29:16.131069  1046 solver.cpp:241]     Train net output #0: loss = 1.19133 (* 1 = 1.19133 loss)
I1030 10:29:16.131089  1046 sgd_solver.cpp:105] Iteration 21240, lr = 0.000718303
I1030 10:29:47.255565  1046 solver.cpp:222] Iteration 21280 (1.28521 iter/s, 31.1233s/40 iters), loss = 1.5298
I1030 10:29:47.255735  1046 solver.cpp:241]     Train net output #0: loss = 1.5298 (* 1 = 1.5298 loss)
I1030 10:29:47.255751  1046 sgd_solver.cpp:105] Iteration 21280, lr = 0.00071475
I1030 10:30:18.330312  1046 solver.cpp:222] Iteration 21320 (1.28727 iter/s, 31.0734s/40 iters), loss = 1.52769
I1030 10:30:18.330538  1046 solver.cpp:241]     Train net output #0: loss = 1.52769 (* 1 = 1.52769 loss)
I1030 10:30:18.330559  1046 sgd_solver.cpp:105] Iteration 21320, lr = 0.000711214
I1030 10:30:49.309144  1046 solver.cpp:222] Iteration 21360 (1.29126 iter/s, 30.9774s/40 iters), loss = 1.49832
I1030 10:30:49.309371  1046 solver.cpp:241]     Train net output #0: loss = 1.49832 (* 1 = 1.49832 loss)
I1030 10:30:49.309397  1046 sgd_solver.cpp:105] Iteration 21360, lr = 0.000707695
I1030 10:31:20.323792  1046 solver.cpp:222] Iteration 21400 (1.28977 iter/s, 31.0133s/40 iters), loss = 1.36567
I1030 10:31:20.323997  1046 solver.cpp:241]     Train net output #0: loss = 1.36567 (* 1 = 1.36567 loss)
I1030 10:31:20.324013  1046 sgd_solver.cpp:105] Iteration 21400, lr = 0.000704194
I1030 10:31:50.922785  1046 solver.cpp:222] Iteration 21440 (1.30729 iter/s, 30.5976s/40 iters), loss = 1.62523
I1030 10:31:50.922966  1046 solver.cpp:241]     Train net output #0: loss = 1.62523 (* 1 = 1.62523 loss)
I1030 10:31:50.922983  1046 sgd_solver.cpp:105] Iteration 21440, lr = 0.00070071
I1030 10:32:22.245700  1046 solver.cpp:222] Iteration 21480 (1.27708 iter/s, 31.3215s/40 iters), loss = 1.48165
I1030 10:32:22.245890  1046 solver.cpp:241]     Train net output #0: loss = 1.48165 (* 1 = 1.48165 loss)
I1030 10:32:22.245914  1046 sgd_solver.cpp:105] Iteration 21480, lr = 0.000697244
I1030 10:32:36.686792  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_21500.caffemodel
I1030 10:32:36.719722  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_21500.solverstate
I1030 10:32:36.736481  1046 solver.cpp:334] Iteration 21500, Testing net (#0)
I1030 10:33:07.478879  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 10:33:07.684901  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58508
I1030 10:33:07.684960  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813039
I1030 10:33:07.684973  1046 solver.cpp:401]     Test net output #2: loss = 1.84552 (* 1 = 1.84552 loss)
I1030 10:33:23.868911  1046 solver.cpp:222] Iteration 21520 (0.649133 iter/s, 61.6207s/40 iters), loss = 1.46605
I1030 10:33:23.868999  1046 solver.cpp:241]     Train net output #0: loss = 1.46605 (* 1 = 1.46605 loss)
I1030 10:33:23.869017  1046 sgd_solver.cpp:105] Iteration 21520, lr = 0.000693794
I1030 10:33:54.561293  1046 solver.cpp:222] Iteration 21560 (1.30331 iter/s, 30.6911s/40 iters), loss = 1.44219
I1030 10:33:54.561496  1046 solver.cpp:241]     Train net output #0: loss = 1.44219 (* 1 = 1.44219 loss)
I1030 10:33:54.561516  1046 sgd_solver.cpp:105] Iteration 21560, lr = 0.000690362
I1030 10:34:25.636811  1046 solver.cpp:222] Iteration 21600 (1.28724 iter/s, 31.0741s/40 iters), loss = 1.59165
I1030 10:34:25.636993  1046 solver.cpp:241]     Train net output #0: loss = 1.59165 (* 1 = 1.59165 loss)
I1030 10:34:25.637012  1046 sgd_solver.cpp:105] Iteration 21600, lr = 0.000686947
I1030 10:34:56.966238  1046 solver.cpp:222] Iteration 21640 (1.27681 iter/s, 31.3281s/40 iters), loss = 1.30593
I1030 10:34:56.966433  1046 solver.cpp:241]     Train net output #0: loss = 1.30593 (* 1 = 1.30593 loss)
I1030 10:34:56.966449  1046 sgd_solver.cpp:105] Iteration 21640, lr = 0.000683548
I1030 10:35:27.592852  1046 solver.cpp:222] Iteration 21680 (1.30611 iter/s, 30.6253s/40 iters), loss = 1.24607
I1030 10:35:27.593147  1046 solver.cpp:241]     Train net output #0: loss = 1.24607 (* 1 = 1.24607 loss)
I1030 10:35:27.593199  1046 sgd_solver.cpp:105] Iteration 21680, lr = 0.000680167
I1030 10:35:58.509613  1046 solver.cpp:222] Iteration 21720 (1.29386 iter/s, 30.9153s/40 iters), loss = 1.28021
I1030 10:35:58.509788  1046 solver.cpp:241]     Train net output #0: loss = 1.28021 (* 1 = 1.28021 loss)
I1030 10:35:58.509807  1046 sgd_solver.cpp:105] Iteration 21720, lr = 0.000676802
I1030 10:36:29.217115  1046 solver.cpp:222] Iteration 21760 (1.30267 iter/s, 30.7062s/40 iters), loss = 1.24443
I1030 10:36:29.217306  1046 solver.cpp:241]     Train net output #0: loss = 1.24443 (* 1 = 1.24443 loss)
I1030 10:36:29.217326  1046 sgd_solver.cpp:105] Iteration 21760, lr = 0.000673454
I1030 10:36:59.982111  1046 solver.cpp:222] Iteration 21800 (1.30024 iter/s, 30.7636s/40 iters), loss = 1.41003
I1030 10:36:59.982316  1046 solver.cpp:241]     Train net output #0: loss = 1.41003 (* 1 = 1.41003 loss)
I1030 10:36:59.982336  1046 sgd_solver.cpp:105] Iteration 21800, lr = 0.000670122
I1030 10:37:30.790225  1046 solver.cpp:222] Iteration 21840 (1.29842 iter/s, 30.8068s/40 iters), loss = 1.35086
I1030 10:37:30.790418  1046 solver.cpp:241]     Train net output #0: loss = 1.35086 (* 1 = 1.35086 loss)
I1030 10:37:30.790436  1046 sgd_solver.cpp:105] Iteration 21840, lr = 0.000666807
I1030 10:38:01.417026  1046 solver.cpp:222] Iteration 21880 (1.3061 iter/s, 30.6254s/40 iters), loss = 1.51582
I1030 10:38:01.417274  1046 solver.cpp:241]     Train net output #0: loss = 1.51582 (* 1 = 1.51582 loss)
I1030 10:38:01.417309  1046 sgd_solver.cpp:105] Iteration 21880, lr = 0.000663508
I1030 10:38:32.444818  1046 solver.cpp:222] Iteration 21920 (1.28923 iter/s, 31.0264s/40 iters), loss = 1.36501
I1030 10:38:32.445022  1046 solver.cpp:241]     Train net output #0: loss = 1.36501 (* 1 = 1.36501 loss)
I1030 10:38:32.445039  1046 sgd_solver.cpp:105] Iteration 21920, lr = 0.000660226
I1030 10:39:03.454355  1046 solver.cpp:222] Iteration 21960 (1.28998 iter/s, 31.0082s/40 iters), loss = 1.0527
I1030 10:39:03.454560  1046 solver.cpp:241]     Train net output #0: loss = 1.0527 (* 1 = 1.0527 loss)
I1030 10:39:03.454576  1046 sgd_solver.cpp:105] Iteration 21960, lr = 0.000656959
I1030 10:39:34.345525  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_22000.caffemodel
I1030 10:39:34.386582  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_22000.solverstate
I1030 10:39:34.408428  1046 solver.cpp:334] Iteration 22000, Testing net (#0)
I1030 10:40:05.482874  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58736
I1030 10:40:05.483073  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8094
I1030 10:40:05.483088  1046 solver.cpp:401]     Test net output #2: loss = 1.83552 (* 1 = 1.83552 loss)
I1030 10:40:06.249568  1046 solver.cpp:222] Iteration 22000 (0.637017 iter/s, 62.7927s/40 iters), loss = 1.15757
I1030 10:40:06.249627  1046 solver.cpp:241]     Train net output #0: loss = 1.15757 (* 1 = 1.15757 loss)
I1030 10:40:06.249642  1046 sgd_solver.cpp:105] Iteration 22000, lr = 0.000653709
I1030 10:40:37.550356  1046 solver.cpp:222] Iteration 22040 (1.27797 iter/s, 31.2995s/40 iters), loss = 1.55665
I1030 10:40:37.550564  1046 solver.cpp:241]     Train net output #0: loss = 1.55665 (* 1 = 1.55665 loss)
I1030 10:40:37.550580  1046 sgd_solver.cpp:105] Iteration 22040, lr = 0.000650475
I1030 10:41:08.310817  1046 solver.cpp:222] Iteration 22080 (1.30043 iter/s, 30.7591s/40 iters), loss = 1.64701
I1030 10:41:08.310999  1046 solver.cpp:241]     Train net output #0: loss = 1.64701 (* 1 = 1.64701 loss)
I1030 10:41:08.311020  1046 sgd_solver.cpp:105] Iteration 22080, lr = 0.000647257
I1030 10:41:38.979921  1046 solver.cpp:222] Iteration 22120 (1.3043 iter/s, 30.6678s/40 iters), loss = 1.04968
I1030 10:41:38.980120  1046 solver.cpp:241]     Train net output #0: loss = 1.04968 (* 1 = 1.04968 loss)
I1030 10:41:38.980139  1046 sgd_solver.cpp:105] Iteration 22120, lr = 0.000644055
I1030 10:42:09.539254  1046 solver.cpp:222] Iteration 22160 (1.30899 iter/s, 30.558s/40 iters), loss = 1.38843
I1030 10:42:09.539460  1046 solver.cpp:241]     Train net output #0: loss = 1.38843 (* 1 = 1.38843 loss)
I1030 10:42:09.539480  1046 sgd_solver.cpp:105] Iteration 22160, lr = 0.000640869
I1030 10:42:40.131321  1046 solver.cpp:222] Iteration 22200 (1.30759 iter/s, 30.5907s/40 iters), loss = 1.33225
I1030 10:42:40.131538  1046 solver.cpp:241]     Train net output #0: loss = 1.33225 (* 1 = 1.33225 loss)
I1030 10:42:40.131557  1046 sgd_solver.cpp:105] Iteration 22200, lr = 0.000637699
I1030 10:43:10.845531  1046 solver.cpp:222] Iteration 22240 (1.30239 iter/s, 30.7128s/40 iters), loss = 1.62345
I1030 10:43:10.845739  1046 solver.cpp:241]     Train net output #0: loss = 1.62345 (* 1 = 1.62345 loss)
I1030 10:43:10.845758  1046 sgd_solver.cpp:105] Iteration 22240, lr = 0.000634544
I1030 10:43:42.200207  1046 solver.cpp:222] Iteration 22280 (1.27578 iter/s, 31.3533s/40 iters), loss = 1.59153
I1030 10:43:42.200394  1046 solver.cpp:241]     Train net output #0: loss = 1.59153 (* 1 = 1.59153 loss)
I1030 10:43:42.200414  1046 sgd_solver.cpp:105] Iteration 22280, lr = 0.000631405
I1030 10:44:13.051371  1046 solver.cpp:222] Iteration 22320 (1.2966 iter/s, 30.8498s/40 iters), loss = 1.44622
I1030 10:44:13.051538  1046 solver.cpp:241]     Train net output #0: loss = 1.44622 (* 1 = 1.44622 loss)
I1030 10:44:13.051555  1046 sgd_solver.cpp:105] Iteration 22320, lr = 0.000628281
I1030 10:44:43.943162  1046 solver.cpp:222] Iteration 22360 (1.2949 iter/s, 30.8905s/40 iters), loss = 1.54953
I1030 10:44:43.943394  1046 solver.cpp:241]     Train net output #0: loss = 1.54953 (* 1 = 1.54953 loss)
I1030 10:44:43.943411  1046 sgd_solver.cpp:105] Iteration 22360, lr = 0.000625173
I1030 10:45:14.241204  1046 solver.cpp:222] Iteration 22400 (1.32028 iter/s, 30.2967s/40 iters), loss = 1.8753
I1030 10:45:14.241369  1046 solver.cpp:241]     Train net output #0: loss = 1.8753 (* 1 = 1.8753 loss)
I1030 10:45:14.241386  1046 sgd_solver.cpp:105] Iteration 22400, lr = 0.00062208
I1030 10:45:44.928911  1046 solver.cpp:222] Iteration 22440 (1.30351 iter/s, 30.6864s/40 iters), loss = 1.33566
I1030 10:45:44.929137  1046 solver.cpp:241]     Train net output #0: loss = 1.33566 (* 1 = 1.33566 loss)
I1030 10:45:44.929159  1046 sgd_solver.cpp:105] Iteration 22440, lr = 0.000619002
I1030 10:46:15.663801  1046 solver.cpp:222] Iteration 22480 (1.30151 iter/s, 30.7335s/40 iters), loss = 1.44409
I1030 10:46:15.664005  1046 solver.cpp:241]     Train net output #0: loss = 1.44409 (* 1 = 1.44409 loss)
I1030 10:46:15.664021  1046 sgd_solver.cpp:105] Iteration 22480, lr = 0.00061594
I1030 10:46:30.161996  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_22500.caffemodel
I1030 10:46:30.193315  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_22500.solverstate
I1030 10:46:30.210261  1046 solver.cpp:334] Iteration 22500, Testing net (#0)
I1030 10:47:00.980176  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 10:47:01.186764  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5854
I1030 10:47:01.186826  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813199
I1030 10:47:01.186841  1046 solver.cpp:401]     Test net output #2: loss = 1.84112 (* 1 = 1.84112 loss)
I1030 10:47:14.365286  1096 data_layer.cpp:73] Restarting data prefetching from start.
I1030 10:47:17.339830  1046 solver.cpp:222] Iteration 22520 (0.648577 iter/s, 61.6735s/40 iters), loss = 1.44271
I1030 10:47:17.339896  1046 solver.cpp:241]     Train net output #0: loss = 1.44271 (* 1 = 1.44271 loss)
I1030 10:47:17.339911  1046 sgd_solver.cpp:105] Iteration 22520, lr = 0.000612893
I1030 10:47:48.154067  1046 solver.cpp:222] Iteration 22560 (1.29815 iter/s, 30.813s/40 iters), loss = 1.19205
I1030 10:47:48.154284  1046 solver.cpp:241]     Train net output #0: loss = 1.19205 (* 1 = 1.19205 loss)
I1030 10:47:48.154304  1046 sgd_solver.cpp:105] Iteration 22560, lr = 0.000609861
I1030 10:48:18.754076  1046 solver.cpp:222] Iteration 22600 (1.30725 iter/s, 30.5986s/40 iters), loss = 1.53513
I1030 10:48:18.754309  1046 solver.cpp:241]     Train net output #0: loss = 1.53513 (* 1 = 1.53513 loss)
I1030 10:48:18.754328  1046 sgd_solver.cpp:105] Iteration 22600, lr = 0.000606844
I1030 10:48:50.074856  1046 solver.cpp:222] Iteration 22640 (1.27717 iter/s, 31.3194s/40 iters), loss = 1.19248
I1030 10:48:50.075047  1046 solver.cpp:241]     Train net output #0: loss = 1.19248 (* 1 = 1.19248 loss)
I1030 10:48:50.075064  1046 sgd_solver.cpp:105] Iteration 22640, lr = 0.000603842
I1030 10:49:21.174337  1046 solver.cpp:222] Iteration 22680 (1.28625 iter/s, 31.0981s/40 iters), loss = 1.18047
I1030 10:49:21.174515  1046 solver.cpp:241]     Train net output #0: loss = 1.18047 (* 1 = 1.18047 loss)
I1030 10:49:21.174532  1046 sgd_solver.cpp:105] Iteration 22680, lr = 0.000600854
I1030 10:49:51.838325  1046 solver.cpp:222] Iteration 22720 (1.30452 iter/s, 30.6626s/40 iters), loss = 1.11262
I1030 10:49:51.838569  1046 solver.cpp:241]     Train net output #0: loss = 1.11262 (* 1 = 1.11262 loss)
I1030 10:49:51.838594  1046 sgd_solver.cpp:105] Iteration 22720, lr = 0.000597882
I1030 10:50:26.468183  1046 solver.cpp:222] Iteration 22760 (1.15512 iter/s, 34.6283s/40 iters), loss = 1.07381
I1030 10:50:26.468456  1046 solver.cpp:241]     Train net output #0: loss = 1.07381 (* 1 = 1.07381 loss)
I1030 10:50:26.468480  1046 sgd_solver.cpp:105] Iteration 22760, lr = 0.000594924
I1030 10:50:57.977066  1046 solver.cpp:222] Iteration 22800 (1.26954 iter/s, 31.5074s/40 iters), loss = 1.36906
I1030 10:50:57.977241  1046 solver.cpp:241]     Train net output #0: loss = 1.36906 (* 1 = 1.36906 loss)
I1030 10:50:57.977257  1046 sgd_solver.cpp:105] Iteration 22800, lr = 0.000591981
I1030 10:51:28.928043  1046 solver.cpp:222] Iteration 22840 (1.29242 iter/s, 30.9496s/40 iters), loss = 1.22076
I1030 10:51:28.928258  1046 solver.cpp:241]     Train net output #0: loss = 1.22076 (* 1 = 1.22076 loss)
I1030 10:51:28.928275  1046 sgd_solver.cpp:105] Iteration 22840, lr = 0.000589052
I1030 10:51:59.430366  1046 solver.cpp:222] Iteration 22880 (1.31143 iter/s, 30.501s/40 iters), loss = 1.48711
I1030 10:51:59.430562  1046 solver.cpp:241]     Train net output #0: loss = 1.48711 (* 1 = 1.48711 loss)
I1030 10:51:59.430577  1046 sgd_solver.cpp:105] Iteration 22880, lr = 0.000586138
I1030 10:52:29.825152  1046 solver.cpp:222] Iteration 22920 (1.31607 iter/s, 30.3934s/40 iters), loss = 1.1436
I1030 10:52:29.825331  1046 solver.cpp:241]     Train net output #0: loss = 1.1436 (* 1 = 1.1436 loss)
I1030 10:52:29.825351  1046 sgd_solver.cpp:105] Iteration 22920, lr = 0.000583238
I1030 10:53:00.561163  1046 solver.cpp:222] Iteration 22960 (1.30146 iter/s, 30.7347s/40 iters), loss = 1.35562
I1030 10:53:00.561393  1046 solver.cpp:241]     Train net output #0: loss = 1.35562 (* 1 = 1.35562 loss)
I1030 10:53:00.561409  1046 sgd_solver.cpp:105] Iteration 22960, lr = 0.000580353
I1030 10:53:30.202415  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_23000.caffemodel
I1030 10:53:30.234235  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_23000.solverstate
I1030 10:53:30.257386  1046 solver.cpp:334] Iteration 23000, Testing net (#0)
I1030 10:54:01.214213  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.586
I1030 10:54:01.214404  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.809
I1030 10:54:01.214421  1046 solver.cpp:401]     Test net output #2: loss = 1.83833 (* 1 = 1.83833 loss)
I1030 10:54:01.979249  1046 solver.cpp:222] Iteration 23000 (0.651301 iter/s, 61.4156s/40 iters), loss = 1.28887
I1030 10:54:01.979317  1046 solver.cpp:241]     Train net output #0: loss = 1.28887 (* 1 = 1.28887 loss)
I1030 10:54:01.979333  1046 sgd_solver.cpp:105] Iteration 23000, lr = 0.000577482
I1030 10:54:32.924726  1046 solver.cpp:222] Iteration 23040 (1.29265 iter/s, 30.9442s/40 iters), loss = 1.30373
I1030 10:54:32.925137  1046 solver.cpp:241]     Train net output #0: loss = 1.30373 (* 1 = 1.30373 loss)
I1030 10:54:32.925209  1046 sgd_solver.cpp:105] Iteration 23040, lr = 0.000574625
I1030 10:55:09.986750  1046 solver.cpp:222] Iteration 23080 (1.07932 iter/s, 37.0602s/40 iters), loss = 1.41331
I1030 10:55:09.986987  1046 solver.cpp:241]     Train net output #0: loss = 1.41331 (* 1 = 1.41331 loss)
I1030 10:55:09.987006  1046 sgd_solver.cpp:105] Iteration 23080, lr = 0.000571782
I1030 10:55:41.540834  1046 solver.cpp:222] Iteration 23120 (1.26772 iter/s, 31.5527s/40 iters), loss = 1.09289
I1030 10:55:41.541173  1046 solver.cpp:241]     Train net output #0: loss = 1.09289 (* 1 = 1.09289 loss)
I1030 10:55:41.541191  1046 sgd_solver.cpp:105] Iteration 23120, lr = 0.000568954
I1030 10:56:12.112004  1046 solver.cpp:222] Iteration 23160 (1.30849 iter/s, 30.5697s/40 iters), loss = 1.28865
I1030 10:56:12.112182  1046 solver.cpp:241]     Train net output #0: loss = 1.28865 (* 1 = 1.28865 loss)
I1030 10:56:12.112201  1046 sgd_solver.cpp:105] Iteration 23160, lr = 0.000566139
I1030 10:56:43.418507  1046 solver.cpp:222] Iteration 23200 (1.27775 iter/s, 31.3051s/40 iters), loss = 1.1713
I1030 10:56:43.418695  1046 solver.cpp:241]     Train net output #0: loss = 1.1713 (* 1 = 1.1713 loss)
I1030 10:56:43.418711  1046 sgd_solver.cpp:105] Iteration 23200, lr = 0.000563338
I1030 10:57:14.507762  1046 solver.cpp:222] Iteration 23240 (1.28667 iter/s, 31.0879s/40 iters), loss = 1.27371
I1030 10:57:14.507935  1046 solver.cpp:241]     Train net output #0: loss = 1.27371 (* 1 = 1.27371 loss)
I1030 10:57:14.507952  1046 sgd_solver.cpp:105] Iteration 23240, lr = 0.000560551
I1030 10:57:45.282646  1046 solver.cpp:222] Iteration 23280 (1.29982 iter/s, 30.7736s/40 iters), loss = 1.41165
I1030 10:57:45.282858  1046 solver.cpp:241]     Train net output #0: loss = 1.41165 (* 1 = 1.41165 loss)
I1030 10:57:45.282876  1046 sgd_solver.cpp:105] Iteration 23280, lr = 0.000557778
I1030 10:58:16.302320  1046 solver.cpp:222] Iteration 23320 (1.28956 iter/s, 31.0183s/40 iters), loss = 1.28395
I1030 10:58:16.302542  1046 solver.cpp:241]     Train net output #0: loss = 1.28395 (* 1 = 1.28395 loss)
I1030 10:58:16.302561  1046 sgd_solver.cpp:105] Iteration 23320, lr = 0.000555019
I1030 10:58:47.148644  1046 solver.cpp:222] Iteration 23360 (1.29681 iter/s, 30.8449s/40 iters), loss = 1.27882
I1030 10:58:47.148839  1046 solver.cpp:241]     Train net output #0: loss = 1.27882 (* 1 = 1.27882 loss)
I1030 10:58:47.148856  1046 sgd_solver.cpp:105] Iteration 23360, lr = 0.000552273
I1030 10:59:17.873775  1046 solver.cpp:222] Iteration 23400 (1.30192 iter/s, 30.7238s/40 iters), loss = 1.34523
I1030 10:59:17.873991  1046 solver.cpp:241]     Train net output #0: loss = 1.34523 (* 1 = 1.34523 loss)
I1030 10:59:17.874008  1046 sgd_solver.cpp:105] Iteration 23400, lr = 0.000549541
I1030 10:59:48.276037  1046 solver.cpp:222] Iteration 23440 (1.31575 iter/s, 30.4009s/40 iters), loss = 1.92256
I1030 10:59:48.276255  1046 solver.cpp:241]     Train net output #0: loss = 1.92256 (* 1 = 1.92256 loss)
I1030 10:59:48.276273  1046 sgd_solver.cpp:105] Iteration 23440, lr = 0.000546822
I1030 11:00:18.680948  1046 solver.cpp:222] Iteration 23480 (1.31564 iter/s, 30.4035s/40 iters), loss = 1.15219
I1030 11:00:18.681154  1046 solver.cpp:241]     Train net output #0: loss = 1.15219 (* 1 = 1.15219 loss)
I1030 11:00:18.681170  1046 sgd_solver.cpp:105] Iteration 23480, lr = 0.000544117
I1030 11:00:33.181723  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_23500.caffemodel
I1030 11:00:33.222978  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_23500.solverstate
I1030 11:00:33.239709  1046 solver.cpp:334] Iteration 23500, Testing net (#0)
I1030 11:01:03.957387  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 11:01:04.165164  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58572
I1030 11:01:04.165228  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81352
I1030 11:01:04.165256  1046 solver.cpp:401]     Test net output #2: loss = 1.83801 (* 1 = 1.83801 loss)
I1030 11:01:21.942011  1046 solver.cpp:222] Iteration 23520 (0.632326 iter/s, 63.2585s/40 iters), loss = 1.14598
I1030 11:01:21.942090  1046 solver.cpp:241]     Train net output #0: loss = 1.14598 (* 1 = 1.14598 loss)
I1030 11:01:21.942109  1046 sgd_solver.cpp:105] Iteration 23520, lr = 0.000541425
I1030 11:01:54.227164  1046 solver.cpp:222] Iteration 23560 (1.23901 iter/s, 32.2839s/40 iters), loss = 1.46965
I1030 11:01:54.227417  1046 solver.cpp:241]     Train net output #0: loss = 1.46965 (* 1 = 1.46965 loss)
I1030 11:01:54.227438  1046 sgd_solver.cpp:105] Iteration 23560, lr = 0.000538747
I1030 11:02:24.727638  1046 solver.cpp:222] Iteration 23600 (1.31151 iter/s, 30.4991s/40 iters), loss = 1.62375
I1030 11:02:24.727844  1046 solver.cpp:241]     Train net output #0: loss = 1.62375 (* 1 = 1.62375 loss)
I1030 11:02:24.727861  1046 sgd_solver.cpp:105] Iteration 23600, lr = 0.000536081
I1030 11:02:55.756153  1046 solver.cpp:222] Iteration 23640 (1.28919 iter/s, 31.0271s/40 iters), loss = 1.28604
I1030 11:02:55.756405  1046 solver.cpp:241]     Train net output #0: loss = 1.28604 (* 1 = 1.28604 loss)
I1030 11:02:55.756423  1046 sgd_solver.cpp:105] Iteration 23640, lr = 0.000533429
I1030 11:03:30.808503  1046 solver.cpp:222] Iteration 23680 (1.1412 iter/s, 35.0508s/40 iters), loss = 1.55299
I1030 11:03:30.808688  1046 solver.cpp:241]     Train net output #0: loss = 1.55299 (* 1 = 1.55299 loss)
I1030 11:03:30.808710  1046 sgd_solver.cpp:105] Iteration 23680, lr = 0.00053079
I1030 11:04:02.423247  1046 solver.cpp:222] Iteration 23720 (1.26529 iter/s, 31.6134s/40 iters), loss = 1.45832
I1030 11:04:02.423430  1046 solver.cpp:241]     Train net output #0: loss = 1.45832 (* 1 = 1.45832 loss)
I1030 11:04:02.423449  1046 sgd_solver.cpp:105] Iteration 23720, lr = 0.000528165
I1030 11:04:33.229456  1046 solver.cpp:222] Iteration 23760 (1.2985 iter/s, 30.8049s/40 iters), loss = 1.2849
I1030 11:04:33.229666  1046 solver.cpp:241]     Train net output #0: loss = 1.2849 (* 1 = 1.2849 loss)
I1030 11:04:33.229683  1046 sgd_solver.cpp:105] Iteration 23760, lr = 0.000525552
I1030 11:05:04.194468  1046 solver.cpp:222] Iteration 23800 (1.29184 iter/s, 30.9636s/40 iters), loss = 1.3683
I1030 11:05:04.194667  1046 solver.cpp:241]     Train net output #0: loss = 1.3683 (* 1 = 1.3683 loss)
I1030 11:05:04.194684  1046 sgd_solver.cpp:105] Iteration 23800, lr = 0.000522952
I1030 11:05:35.531185  1046 solver.cpp:222] Iteration 23840 (1.27651 iter/s, 31.3353s/40 iters), loss = 1.61069
I1030 11:05:35.531380  1046 solver.cpp:241]     Train net output #0: loss = 1.61069 (* 1 = 1.61069 loss)
I1030 11:05:35.531397  1046 sgd_solver.cpp:105] Iteration 23840, lr = 0.000520365
I1030 11:06:06.592277  1046 solver.cpp:222] Iteration 23880 (1.28784 iter/s, 31.0597s/40 iters), loss = 1.20255
I1030 11:06:06.592478  1046 solver.cpp:241]     Train net output #0: loss = 1.20255 (* 1 = 1.20255 loss)
I1030 11:06:06.592496  1046 sgd_solver.cpp:105] Iteration 23880, lr = 0.00051779
I1030 11:06:37.531042  1046 solver.cpp:222] Iteration 23920 (1.29293 iter/s, 30.9374s/40 iters), loss = 1.28988
I1030 11:06:37.531230  1046 solver.cpp:241]     Train net output #0: loss = 1.28988 (* 1 = 1.28988 loss)
I1030 11:06:37.531249  1046 sgd_solver.cpp:105] Iteration 23920, lr = 0.000515229
I1030 11:07:08.061669  1046 solver.cpp:222] Iteration 23960 (1.31022 iter/s, 30.5293s/40 iters), loss = 1.17822
I1030 11:07:08.061872  1046 solver.cpp:241]     Train net output #0: loss = 1.17822 (* 1 = 1.17822 loss)
I1030 11:07:08.061888  1046 sgd_solver.cpp:105] Iteration 23960, lr = 0.00051268
I1030 11:07:38.017376  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_24000.caffemodel
I1030 11:07:38.050397  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_24000.solverstate
I1030 11:07:38.072350  1046 solver.cpp:334] Iteration 24000, Testing net (#0)
I1030 11:08:09.056984  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.589
I1030 11:08:09.057189  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.809719
I1030 11:08:09.057205  1046 solver.cpp:401]     Test net output #2: loss = 1.83626 (* 1 = 1.83626 loss)
I1030 11:08:09.815248  1046 solver.cpp:222] Iteration 24000 (0.647762 iter/s, 61.7511s/40 iters), loss = 1.78863
I1030 11:08:09.815320  1046 solver.cpp:241]     Train net output #0: loss = 1.78863 (* 1 = 1.78863 loss)
I1030 11:08:09.815336  1046 sgd_solver.cpp:105] Iteration 24000, lr = 0.000510143
I1030 11:08:40.320847  1046 solver.cpp:222] Iteration 24040 (1.31129 iter/s, 30.5044s/40 iters), loss = 1.47302
I1030 11:08:40.321050  1046 solver.cpp:241]     Train net output #0: loss = 1.47302 (* 1 = 1.47302 loss)
I1030 11:08:40.321069  1046 sgd_solver.cpp:105] Iteration 24040, lr = 0.00050762
I1030 11:09:10.809547  1046 solver.cpp:222] Iteration 24080 (1.31202 iter/s, 30.4874s/40 iters), loss = 1.64764
I1030 11:09:10.809731  1046 solver.cpp:241]     Train net output #0: loss = 1.64764 (* 1 = 1.64764 loss)
I1030 11:09:10.809748  1046 sgd_solver.cpp:105] Iteration 24080, lr = 0.000505108
I1030 11:09:41.688498  1046 solver.cpp:222] Iteration 24120 (1.29544 iter/s, 30.8776s/40 iters), loss = 1.41342
I1030 11:09:41.688686  1046 solver.cpp:241]     Train net output #0: loss = 1.41342 (* 1 = 1.41342 loss)
I1030 11:09:41.688704  1046 sgd_solver.cpp:105] Iteration 24120, lr = 0.00050261
I1030 11:10:12.806978  1046 solver.cpp:222] Iteration 24160 (1.28547 iter/s, 31.1171s/40 iters), loss = 1.14034
I1030 11:10:12.807175  1046 solver.cpp:241]     Train net output #0: loss = 1.14034 (* 1 = 1.14034 loss)
I1030 11:10:12.807193  1046 sgd_solver.cpp:105] Iteration 24160, lr = 0.000500123
I1030 11:10:43.824686  1046 solver.cpp:222] Iteration 24200 (1.28964 iter/s, 31.0163s/40 iters), loss = 1.36685
I1030 11:10:43.824877  1046 solver.cpp:241]     Train net output #0: loss = 1.36685 (* 1 = 1.36685 loss)
I1030 11:10:43.824895  1046 sgd_solver.cpp:105] Iteration 24200, lr = 0.000497649
I1030 11:11:14.679962  1046 solver.cpp:222] Iteration 24240 (1.29643 iter/s, 30.8539s/40 iters), loss = 1.55279
I1030 11:11:14.680187  1046 solver.cpp:241]     Train net output #0: loss = 1.55279 (* 1 = 1.55279 loss)
I1030 11:11:14.680204  1046 sgd_solver.cpp:105] Iteration 24240, lr = 0.000495187
I1030 11:11:45.653884  1046 solver.cpp:222] Iteration 24280 (1.29147 iter/s, 30.9725s/40 iters), loss = 1.57523
I1030 11:11:45.654086  1046 solver.cpp:241]     Train net output #0: loss = 1.57523 (* 1 = 1.57523 loss)
I1030 11:11:45.654103  1046 sgd_solver.cpp:105] Iteration 24280, lr = 0.000492737
I1030 11:12:16.386363  1046 solver.cpp:222] Iteration 24320 (1.30161 iter/s, 30.7311s/40 iters), loss = 1.49845
I1030 11:12:16.386526  1046 solver.cpp:241]     Train net output #0: loss = 1.49845 (* 1 = 1.49845 loss)
I1030 11:12:16.386543  1046 sgd_solver.cpp:105] Iteration 24320, lr = 0.0004903
I1030 11:12:47.093741  1046 solver.cpp:222] Iteration 24360 (1.30267 iter/s, 30.7061s/40 iters), loss = 1.50008
I1030 11:12:47.093940  1046 solver.cpp:241]     Train net output #0: loss = 1.50008 (* 1 = 1.50008 loss)
I1030 11:12:47.093957  1046 sgd_solver.cpp:105] Iteration 24360, lr = 0.000487874
I1030 11:13:17.578727  1046 solver.cpp:222] Iteration 24400 (1.31218 iter/s, 30.4836s/40 iters), loss = 1.35968
I1030 11:13:17.578922  1046 solver.cpp:241]     Train net output #0: loss = 1.35968 (* 1 = 1.35968 loss)
I1030 11:13:17.578938  1046 sgd_solver.cpp:105] Iteration 24400, lr = 0.00048546
I1030 11:13:47.960085  1046 solver.cpp:222] Iteration 24440 (1.31665 iter/s, 30.38s/40 iters), loss = 1.72353
I1030 11:13:47.960240  1046 solver.cpp:241]     Train net output #0: loss = 1.72353 (* 1 = 1.72353 loss)
I1030 11:13:47.960256  1046 sgd_solver.cpp:105] Iteration 24440, lr = 0.000483059
I1030 11:14:18.547107  1046 solver.cpp:222] Iteration 24480 (1.3078 iter/s, 30.5857s/40 iters), loss = 1.47428
I1030 11:14:18.547341  1046 solver.cpp:241]     Train net output #0: loss = 1.47428 (* 1 = 1.47428 loss)
I1030 11:14:18.547372  1046 sgd_solver.cpp:105] Iteration 24480, lr = 0.000480669
I1030 11:14:33.325587  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_24500.caffemodel
I1030 11:14:33.357844  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_24500.solverstate
I1030 11:14:33.374707  1046 solver.cpp:334] Iteration 24500, Testing net (#0)
I1030 11:15:04.247839  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 11:15:04.453652  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58624
I1030 11:15:04.453716  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813199
I1030 11:15:04.453730  1046 solver.cpp:401]     Test net output #2: loss = 1.83947 (* 1 = 1.83947 loss)
I1030 11:15:20.581516  1046 solver.cpp:222] Iteration 24520 (0.64483 iter/s, 62.0319s/40 iters), loss = 1.74977
I1030 11:15:20.581588  1046 solver.cpp:241]     Train net output #0: loss = 1.74977 (* 1 = 1.74977 loss)
I1030 11:15:20.581604  1046 sgd_solver.cpp:105] Iteration 24520, lr = 0.000478291
I1030 11:15:51.066018  1046 solver.cpp:222] Iteration 24560 (1.31219 iter/s, 30.4833s/40 iters), loss = 1.37684
I1030 11:15:51.066212  1046 solver.cpp:241]     Train net output #0: loss = 1.37684 (* 1 = 1.37684 loss)
I1030 11:15:51.066229  1046 sgd_solver.cpp:105] Iteration 24560, lr = 0.000475925
I1030 11:16:21.594280  1046 solver.cpp:222] Iteration 24600 (1.31032 iter/s, 30.5269s/40 iters), loss = 1.47301
I1030 11:16:21.594475  1046 solver.cpp:241]     Train net output #0: loss = 1.47301 (* 1 = 1.47301 loss)
I1030 11:16:21.594493  1046 sgd_solver.cpp:105] Iteration 24600, lr = 0.000473571
I1030 11:16:52.198554  1046 solver.cpp:222] Iteration 24640 (1.30706 iter/s, 30.6029s/40 iters), loss = 1.57266
I1030 11:16:52.198740  1046 solver.cpp:241]     Train net output #0: loss = 1.57266 (* 1 = 1.57266 loss)
I1030 11:16:52.198757  1046 sgd_solver.cpp:105] Iteration 24640, lr = 0.000471228
I1030 11:17:23.302482  1046 solver.cpp:222] Iteration 24680 (1.28607 iter/s, 31.1026s/40 iters), loss = 1.27394
I1030 11:17:23.302651  1046 solver.cpp:241]     Train net output #0: loss = 1.27394 (* 1 = 1.27394 loss)
I1030 11:17:23.302669  1046 sgd_solver.cpp:105] Iteration 24680, lr = 0.000468896
I1030 11:17:57.969719  1046 solver.cpp:222] Iteration 24720 (1.15388 iter/s, 34.6658s/40 iters), loss = 1.49489
I1030 11:17:57.969909  1046 solver.cpp:241]     Train net output #0: loss = 1.49489 (* 1 = 1.49489 loss)
I1030 11:17:57.969928  1046 sgd_solver.cpp:105] Iteration 24720, lr = 0.000466577
I1030 11:18:30.933740  1046 solver.cpp:222] Iteration 24760 (1.2135 iter/s, 32.9626s/40 iters), loss = 1.38996
I1030 11:18:30.933953  1046 solver.cpp:241]     Train net output #0: loss = 1.38996 (* 1 = 1.38996 loss)
I1030 11:18:30.933969  1046 sgd_solver.cpp:105] Iteration 24760, lr = 0.000464269
I1030 11:19:03.834264  1046 solver.cpp:222] Iteration 24800 (1.21584 iter/s, 32.8991s/40 iters), loss = 1.71947
I1030 11:19:03.834475  1046 solver.cpp:241]     Train net output #0: loss = 1.71947 (* 1 = 1.71947 loss)
I1030 11:19:03.834493  1046 sgd_solver.cpp:105] Iteration 24800, lr = 0.000461972
I1030 11:19:35.780764  1046 solver.cpp:222] Iteration 24840 (1.25215 iter/s, 31.9451s/40 iters), loss = 1.3078
I1030 11:19:35.780973  1046 solver.cpp:241]     Train net output #0: loss = 1.3078 (* 1 = 1.3078 loss)
I1030 11:19:35.780997  1046 sgd_solver.cpp:105] Iteration 24840, lr = 0.000459686
I1030 11:20:11.239262  1046 solver.cpp:222] Iteration 24880 (1.12813 iter/s, 35.4569s/40 iters), loss = 1.60551
I1030 11:20:11.239497  1046 solver.cpp:241]     Train net output #0: loss = 1.60551 (* 1 = 1.60551 loss)
I1030 11:20:11.239523  1046 sgd_solver.cpp:105] Iteration 24880, lr = 0.000457412
I1030 11:20:43.178912  1046 solver.cpp:222] Iteration 24920 (1.25242 iter/s, 31.9382s/40 iters), loss = 1.32263
I1030 11:20:43.179162  1046 solver.cpp:241]     Train net output #0: loss = 1.32263 (* 1 = 1.32263 loss)
I1030 11:20:43.179188  1046 sgd_solver.cpp:105] Iteration 24920, lr = 0.000455149
I1030 11:21:14.148280  1046 solver.cpp:222] Iteration 24960 (1.29166 iter/s, 30.968s/40 iters), loss = 1.40201
I1030 11:21:14.148596  1046 solver.cpp:241]     Train net output #0: loss = 1.40201 (* 1 = 1.40201 loss)
I1030 11:21:14.148633  1046 sgd_solver.cpp:105] Iteration 24960, lr = 0.000452898
I1030 11:21:44.453939  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_25000.caffemodel
I1030 11:21:44.485378  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_25000.solverstate
I1030 11:21:44.511083  1046 solver.cpp:334] Iteration 25000, Testing net (#0)
I1030 11:22:15.432829  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58672
I1030 11:22:15.433010  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80928
I1030 11:22:15.433027  1046 solver.cpp:401]     Test net output #2: loss = 1.83675 (* 1 = 1.83675 loss)
I1030 11:22:16.196768  1046 solver.cpp:222] Iteration 25000 (0.644684 iter/s, 62.0459s/40 iters), loss = 1.47041
I1030 11:22:16.196827  1046 solver.cpp:241]     Train net output #0: loss = 1.47041 (* 1 = 1.47041 loss)
I1030 11:22:16.196844  1046 sgd_solver.cpp:105] Iteration 25000, lr = 0.000450657
I1030 11:22:30.171483  1096 data_layer.cpp:73] Restarting data prefetching from start.
I1030 11:22:46.812922  1046 solver.cpp:222] Iteration 25040 (1.30655 iter/s, 30.6149s/40 iters), loss = 1.4912
I1030 11:22:46.813122  1046 solver.cpp:241]     Train net output #0: loss = 1.4912 (* 1 = 1.4912 loss)
I1030 11:22:46.813140  1046 sgd_solver.cpp:105] Iteration 25040, lr = 0.000448428
I1030 11:23:17.310300  1046 solver.cpp:222] Iteration 25080 (1.31165 iter/s, 30.496s/40 iters), loss = 1.43016
I1030 11:23:17.310477  1046 solver.cpp:241]     Train net output #0: loss = 1.43016 (* 1 = 1.43016 loss)
I1030 11:23:17.310499  1046 sgd_solver.cpp:105] Iteration 25080, lr = 0.000446209
I1030 11:23:48.269814  1046 solver.cpp:222] Iteration 25120 (1.29207 iter/s, 30.9582s/40 iters), loss = 1.02173
I1030 11:23:48.270001  1046 solver.cpp:241]     Train net output #0: loss = 1.02173 (* 1 = 1.02173 loss)
I1030 11:23:48.270018  1046 sgd_solver.cpp:105] Iteration 25120, lr = 0.000444002
I1030 11:24:19.461156  1046 solver.cpp:222] Iteration 25160 (1.28246 iter/s, 31.19s/40 iters), loss = 1.27473
I1030 11:24:19.461618  1046 solver.cpp:241]     Train net output #0: loss = 1.27473 (* 1 = 1.27473 loss)
I1030 11:24:19.461634  1046 sgd_solver.cpp:105] Iteration 25160, lr = 0.000441805
I1030 11:24:49.916414  1046 solver.cpp:222] Iteration 25200 (1.31347 iter/s, 30.4536s/40 iters), loss = 1.36889
I1030 11:24:49.916618  1046 solver.cpp:241]     Train net output #0: loss = 1.36889 (* 1 = 1.36889 loss)
I1030 11:24:49.916635  1046 sgd_solver.cpp:105] Iteration 25200, lr = 0.000439619
I1030 11:25:21.260546  1046 solver.cpp:222] Iteration 25240 (1.27621 iter/s, 31.3427s/40 iters), loss = 1.45522
I1030 11:25:21.260798  1046 solver.cpp:241]     Train net output #0: loss = 1.45522 (* 1 = 1.45522 loss)
I1030 11:25:21.260828  1046 sgd_solver.cpp:105] Iteration 25240, lr = 0.000437445
I1030 11:25:52.929085  1046 solver.cpp:222] Iteration 25280 (1.26314 iter/s, 31.6671s/40 iters), loss = 1.19289
I1030 11:25:52.929294  1046 solver.cpp:241]     Train net output #0: loss = 1.19289 (* 1 = 1.19289 loss)
I1030 11:25:52.929317  1046 sgd_solver.cpp:105] Iteration 25280, lr = 0.000435281
I1030 11:26:23.668089  1046 solver.cpp:222] Iteration 25320 (1.30134 iter/s, 30.7376s/40 iters), loss = 1.37503
I1030 11:26:23.668269  1046 solver.cpp:241]     Train net output #0: loss = 1.37503 (* 1 = 1.37503 loss)
I1030 11:26:23.668285  1046 sgd_solver.cpp:105] Iteration 25320, lr = 0.000433127
I1030 11:26:54.442508  1046 solver.cpp:222] Iteration 25360 (1.29984 iter/s, 30.7731s/40 iters), loss = 1.44375
I1030 11:26:54.442704  1046 solver.cpp:241]     Train net output #0: loss = 1.44375 (* 1 = 1.44375 loss)
I1030 11:26:54.442721  1046 sgd_solver.cpp:105] Iteration 25360, lr = 0.000430984
I1030 11:27:27.051295  1046 solver.cpp:222] Iteration 25400 (1.22672 iter/s, 32.6074s/40 iters), loss = 1.27171
I1030 11:27:27.051571  1046 solver.cpp:241]     Train net output #0: loss = 1.27171 (* 1 = 1.27171 loss)
I1030 11:27:27.051591  1046 sgd_solver.cpp:105] Iteration 25400, lr = 0.000428852
I1030 11:27:57.850772  1046 solver.cpp:222] Iteration 25440 (1.29878 iter/s, 30.798s/40 iters), loss = 1.21954
I1030 11:27:57.850968  1046 solver.cpp:241]     Train net output #0: loss = 1.21954 (* 1 = 1.21954 loss)
I1030 11:27:57.850986  1046 sgd_solver.cpp:105] Iteration 25440, lr = 0.000426731
I1030 11:28:28.911530  1046 solver.cpp:222] Iteration 25480 (1.28786 iter/s, 31.0594s/40 iters), loss = 1.32595
I1030 11:28:28.911736  1046 solver.cpp:241]     Train net output #0: loss = 1.32595 (* 1 = 1.32595 loss)
I1030 11:28:28.911756  1046 sgd_solver.cpp:105] Iteration 25480, lr = 0.00042462
I1030 11:28:43.441524  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_25500.caffemodel
I1030 11:28:43.473449  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_25500.solverstate
I1030 11:28:43.490361  1046 solver.cpp:334] Iteration 25500, Testing net (#0)
I1030 11:29:15.053330  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 11:29:15.260552  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58604
I1030 11:29:15.260617  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81312
I1030 11:29:15.260630  1046 solver.cpp:401]     Test net output #2: loss = 1.84007 (* 1 = 1.84007 loss)
I1030 11:29:31.551486  1046 solver.cpp:222] Iteration 25520 (0.638596 iter/s, 62.6374s/40 iters), loss = 1.68912
I1030 11:29:31.551553  1046 solver.cpp:241]     Train net output #0: loss = 1.68912 (* 1 = 1.68912 loss)
I1030 11:29:31.551568  1046 sgd_solver.cpp:105] Iteration 25520, lr = 0.000422519
I1030 11:30:02.826817  1046 solver.cpp:222] Iteration 25560 (1.27901 iter/s, 31.2741s/40 iters), loss = 1.12762
I1030 11:30:02.827016  1046 solver.cpp:241]     Train net output #0: loss = 1.12762 (* 1 = 1.12762 loss)
I1030 11:30:02.827034  1046 sgd_solver.cpp:105] Iteration 25560, lr = 0.000420429
I1030 11:30:32.987810  1046 solver.cpp:222] Iteration 25600 (1.32627 iter/s, 30.1597s/40 iters), loss = 1.51393
I1030 11:30:32.987992  1046 solver.cpp:241]     Train net output #0: loss = 1.51393 (* 1 = 1.51393 loss)
I1030 11:30:32.988008  1046 sgd_solver.cpp:105] Iteration 25600, lr = 0.000418349
I1030 11:31:03.568846  1046 solver.cpp:222] Iteration 25640 (1.30806 iter/s, 30.5797s/40 iters), loss = 1.46869
I1030 11:31:03.569032  1046 solver.cpp:241]     Train net output #0: loss = 1.46869 (* 1 = 1.46869 loss)
I1030 11:31:03.569051  1046 sgd_solver.cpp:105] Iteration 25640, lr = 0.000416279
I1030 11:31:34.697809  1046 solver.cpp:222] Iteration 25680 (1.28503 iter/s, 31.1276s/40 iters), loss = 1.34679
I1030 11:31:34.698021  1046 solver.cpp:241]     Train net output #0: loss = 1.34679 (* 1 = 1.34679 loss)
I1030 11:31:34.698038  1046 sgd_solver.cpp:105] Iteration 25680, lr = 0.00041422
I1030 11:32:05.620121  1046 solver.cpp:222] Iteration 25720 (1.29362 iter/s, 30.9209s/40 iters), loss = 1.46871
I1030 11:32:05.620326  1046 solver.cpp:241]     Train net output #0: loss = 1.46871 (* 1 = 1.46871 loss)
I1030 11:32:05.620347  1046 sgd_solver.cpp:105] Iteration 25720, lr = 0.000412171
I1030 11:32:36.409248  1046 solver.cpp:222] Iteration 25760 (1.29922 iter/s, 30.7878s/40 iters), loss = 1.46975
I1030 11:32:36.409420  1046 solver.cpp:241]     Train net output #0: loss = 1.46975 (* 1 = 1.46975 loss)
I1030 11:32:36.409436  1046 sgd_solver.cpp:105] Iteration 25760, lr = 0.000410131
I1030 11:33:06.989053  1046 solver.cpp:222] Iteration 25800 (1.30811 iter/s, 30.5785s/40 iters), loss = 1.19719
I1030 11:33:06.989217  1046 solver.cpp:241]     Train net output #0: loss = 1.19719 (* 1 = 1.19719 loss)
I1030 11:33:06.989233  1046 sgd_solver.cpp:105] Iteration 25800, lr = 0.000408103
I1030 11:33:37.418592  1046 solver.cpp:222] Iteration 25840 (1.31457 iter/s, 30.4282s/40 iters), loss = 1.25269
I1030 11:33:37.418864  1046 solver.cpp:241]     Train net output #0: loss = 1.25269 (* 1 = 1.25269 loss)
I1030 11:33:37.418884  1046 sgd_solver.cpp:105] Iteration 25840, lr = 0.000406084
I1030 11:34:08.304067  1046 solver.cpp:222] Iteration 25880 (1.29517 iter/s, 30.884s/40 iters), loss = 1.40161
I1030 11:34:08.304338  1046 solver.cpp:241]     Train net output #0: loss = 1.40161 (* 1 = 1.40161 loss)
I1030 11:34:08.304363  1046 sgd_solver.cpp:105] Iteration 25880, lr = 0.000404075
I1030 11:34:39.474462  1046 solver.cpp:222] Iteration 25920 (1.28333 iter/s, 31.169s/40 iters), loss = 1.45085
I1030 11:34:39.474669  1046 solver.cpp:241]     Train net output #0: loss = 1.45085 (* 1 = 1.45085 loss)
I1030 11:34:39.474686  1046 sgd_solver.cpp:105] Iteration 25920, lr = 0.000402076
I1030 11:35:10.593619  1046 solver.cpp:222] Iteration 25960 (1.28544 iter/s, 31.1178s/40 iters), loss = 1.43814
I1030 11:35:10.593806  1046 solver.cpp:241]     Train net output #0: loss = 1.43814 (* 1 = 1.43814 loss)
I1030 11:35:10.593823  1046 sgd_solver.cpp:105] Iteration 25960, lr = 0.000400086
I1030 11:35:40.724000  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_26000.caffemodel
I1030 11:35:40.763084  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_26000.solverstate
I1030 11:35:40.786501  1046 solver.cpp:334] Iteration 26000, Testing net (#0)
I1030 11:36:11.855403  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58736
I1030 11:36:11.855576  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80964
I1030 11:36:11.855592  1046 solver.cpp:401]     Test net output #2: loss = 1.83667 (* 1 = 1.83667 loss)
I1030 11:36:12.619864  1046 solver.cpp:222] Iteration 26000 (0.644914 iter/s, 62.0237s/40 iters), loss = 1.58483
I1030 11:36:12.619926  1046 solver.cpp:241]     Train net output #0: loss = 1.58483 (* 1 = 1.58483 loss)
I1030 11:36:12.619943  1046 sgd_solver.cpp:105] Iteration 26000, lr = 0.000398107
I1030 11:36:43.116262  1046 solver.cpp:222] Iteration 26040 (1.31168 iter/s, 30.4952s/40 iters), loss = 1.40624
I1030 11:36:43.116443  1046 solver.cpp:241]     Train net output #0: loss = 1.40624 (* 1 = 1.40624 loss)
I1030 11:36:43.116461  1046 sgd_solver.cpp:105] Iteration 26040, lr = 0.000396138
I1030 11:37:13.936002  1046 solver.cpp:222] Iteration 26080 (1.29793 iter/s, 30.8184s/40 iters), loss = 1.63561
I1030 11:37:13.936233  1046 solver.cpp:241]     Train net output #0: loss = 1.63561 (* 1 = 1.63561 loss)
I1030 11:37:13.936251  1046 sgd_solver.cpp:105] Iteration 26080, lr = 0.000394178
I1030 11:37:45.033818  1046 solver.cpp:222] Iteration 26120 (1.28632 iter/s, 31.0964s/40 iters), loss = 1.62779
I1030 11:37:45.034080  1046 solver.cpp:241]     Train net output #0: loss = 1.62779 (* 1 = 1.62779 loss)
I1030 11:37:45.034107  1046 sgd_solver.cpp:105] Iteration 26120, lr = 0.000392228
I1030 11:38:15.995052  1046 solver.cpp:222] Iteration 26160 (1.292 iter/s, 30.9598s/40 iters), loss = 1.46966
I1030 11:38:15.995249  1046 solver.cpp:241]     Train net output #0: loss = 1.46966 (* 1 = 1.46966 loss)
I1030 11:38:15.995265  1046 sgd_solver.cpp:105] Iteration 26160, lr = 0.000390288
I1030 11:38:46.191319  1046 solver.cpp:222] Iteration 26200 (1.32473 iter/s, 30.1949s/40 iters), loss = 1.61327
I1030 11:38:46.191514  1046 solver.cpp:241]     Train net output #0: loss = 1.61327 (* 1 = 1.61327 loss)
I1030 11:38:46.191530  1046 sgd_solver.cpp:105] Iteration 26200, lr = 0.000388357
I1030 11:39:17.431128  1046 solver.cpp:222] Iteration 26240 (1.28047 iter/s, 31.2384s/40 iters), loss = 1.38998
I1030 11:39:17.431316  1046 solver.cpp:241]     Train net output #0: loss = 1.38998 (* 1 = 1.38998 loss)
I1030 11:39:17.431337  1046 sgd_solver.cpp:105] Iteration 26240, lr = 0.000386435
I1030 11:39:48.433681  1046 solver.cpp:222] Iteration 26280 (1.29027 iter/s, 31.0012s/40 iters), loss = 1.39068
I1030 11:39:48.433897  1046 solver.cpp:241]     Train net output #0: loss = 1.39068 (* 1 = 1.39068 loss)
I1030 11:39:48.433912  1046 sgd_solver.cpp:105] Iteration 26280, lr = 0.000384524
I1030 11:40:19.395582  1046 solver.cpp:222] Iteration 26320 (1.29197 iter/s, 30.9605s/40 iters), loss = 1.21855
I1030 11:40:19.395946  1046 solver.cpp:241]     Train net output #0: loss = 1.21855 (* 1 = 1.21855 loss)
I1030 11:40:19.395998  1046 sgd_solver.cpp:105] Iteration 26320, lr = 0.000382621
I1030 11:40:50.379634  1046 solver.cpp:222] Iteration 26360 (1.29105 iter/s, 30.9825s/40 iters), loss = 1.47634
I1030 11:40:50.379817  1046 solver.cpp:241]     Train net output #0: loss = 1.47634 (* 1 = 1.47634 loss)
I1030 11:40:50.379834  1046 sgd_solver.cpp:105] Iteration 26360, lr = 0.000380729
I1030 11:41:21.367808  1046 solver.cpp:222] Iteration 26400 (1.29087 iter/s, 30.9868s/40 iters), loss = 1.3407
I1030 11:41:21.367998  1046 solver.cpp:241]     Train net output #0: loss = 1.3407 (* 1 = 1.3407 loss)
I1030 11:41:21.368016  1046 sgd_solver.cpp:105] Iteration 26400, lr = 0.000378845
I1030 11:41:52.299620  1046 solver.cpp:222] Iteration 26440 (1.29322 iter/s, 30.9305s/40 iters), loss = 1.30196
I1030 11:41:52.299818  1046 solver.cpp:241]     Train net output #0: loss = 1.30196 (* 1 = 1.30196 loss)
I1030 11:41:52.299836  1046 sgd_solver.cpp:105] Iteration 26440, lr = 0.000376971
I1030 11:42:23.283417  1046 solver.cpp:222] Iteration 26480 (1.29105 iter/s, 30.9824s/40 iters), loss = 1.71495
I1030 11:42:23.283596  1046 solver.cpp:241]     Train net output #0: loss = 1.71495 (* 1 = 1.71495 loss)
I1030 11:42:23.283613  1046 sgd_solver.cpp:105] Iteration 26480, lr = 0.000375106
I1030 11:42:37.990073  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_26500.caffemodel
I1030 11:42:38.022198  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_26500.solverstate
I1030 11:42:38.039603  1046 solver.cpp:334] Iteration 26500, Testing net (#0)
I1030 11:43:08.771486  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 11:43:08.978111  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58728
I1030 11:43:08.978173  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813159
I1030 11:43:08.978188  1046 solver.cpp:401]     Test net output #2: loss = 1.84096 (* 1 = 1.84096 loss)
I1030 11:43:25.043324  1046 solver.cpp:222] Iteration 26520 (0.647695 iter/s, 61.7574s/40 iters), loss = 1.41958
I1030 11:43:25.043388  1046 solver.cpp:241]     Train net output #0: loss = 1.41958 (* 1 = 1.41958 loss)
I1030 11:43:25.043404  1046 sgd_solver.cpp:105] Iteration 26520, lr = 0.00037325
I1030 11:43:55.849272  1046 solver.cpp:222] Iteration 26560 (1.2985 iter/s, 30.8047s/40 iters), loss = 1.30047
I1030 11:43:55.849475  1046 solver.cpp:241]     Train net output #0: loss = 1.30047 (* 1 = 1.30047 loss)
I1030 11:43:55.849493  1046 sgd_solver.cpp:105] Iteration 26560, lr = 0.000371404
I1030 11:44:26.808334  1046 solver.cpp:222] Iteration 26600 (1.29209 iter/s, 30.9577s/40 iters), loss = 1.70106
I1030 11:44:26.808526  1046 solver.cpp:241]     Train net output #0: loss = 1.70106 (* 1 = 1.70106 loss)
I1030 11:44:26.808544  1046 sgd_solver.cpp:105] Iteration 26600, lr = 0.000369566
I1030 11:44:57.505277  1046 solver.cpp:222] Iteration 26640 (1.30312 iter/s, 30.6956s/40 iters), loss = 1.2313
I1030 11:44:57.505470  1046 solver.cpp:241]     Train net output #0: loss = 1.2313 (* 1 = 1.2313 loss)
I1030 11:44:57.505489  1046 sgd_solver.cpp:105] Iteration 26640, lr = 0.000367738
I1030 11:45:28.064198  1046 solver.cpp:222] Iteration 26680 (1.309 iter/s, 30.5576s/40 iters), loss = 1.51174
I1030 11:45:28.064412  1046 solver.cpp:241]     Train net output #0: loss = 1.51174 (* 1 = 1.51174 loss)
I1030 11:45:28.064430  1046 sgd_solver.cpp:105] Iteration 26680, lr = 0.000365919
I1030 11:45:58.880781  1046 solver.cpp:222] Iteration 26720 (1.29806 iter/s, 30.8152s/40 iters), loss = 1.4852
I1030 11:45:58.880982  1046 solver.cpp:241]     Train net output #0: loss = 1.4852 (* 1 = 1.4852 loss)
I1030 11:45:58.881000  1046 sgd_solver.cpp:105] Iteration 26720, lr = 0.000364109
I1030 11:46:29.923230  1046 solver.cpp:222] Iteration 26760 (1.28862 iter/s, 31.0411s/40 iters), loss = 1.18263
I1030 11:46:29.923475  1046 solver.cpp:241]     Train net output #0: loss = 1.18263 (* 1 = 1.18263 loss)
I1030 11:46:29.923494  1046 sgd_solver.cpp:105] Iteration 26760, lr = 0.000362307
I1030 11:47:00.547226  1046 solver.cpp:222] Iteration 26800 (1.30622 iter/s, 30.6226s/40 iters), loss = 1.48864
I1030 11:47:00.547420  1046 solver.cpp:241]     Train net output #0: loss = 1.48864 (* 1 = 1.48864 loss)
I1030 11:47:00.547437  1046 sgd_solver.cpp:105] Iteration 26800, lr = 0.000360515
I1030 11:47:31.475457  1046 solver.cpp:222] Iteration 26840 (1.29337 iter/s, 30.9269s/40 iters), loss = 1.38374
I1030 11:47:31.475668  1046 solver.cpp:241]     Train net output #0: loss = 1.38374 (* 1 = 1.38374 loss)
I1030 11:47:31.475684  1046 sgd_solver.cpp:105] Iteration 26840, lr = 0.000358731
I1030 11:48:02.183037  1046 solver.cpp:222] Iteration 26880 (1.30267 iter/s, 30.7062s/40 iters), loss = 1.36749
I1030 11:48:02.183245  1046 solver.cpp:241]     Train net output #0: loss = 1.36749 (* 1 = 1.36749 loss)
I1030 11:48:02.183262  1046 sgd_solver.cpp:105] Iteration 26880, lr = 0.000356957
I1030 11:48:34.061153  1046 solver.cpp:222] Iteration 26920 (1.25484 iter/s, 31.8767s/40 iters), loss = 1.16597
I1030 11:48:34.061430  1046 solver.cpp:241]     Train net output #0: loss = 1.16597 (* 1 = 1.16597 loss)
I1030 11:48:34.061447  1046 sgd_solver.cpp:105] Iteration 26920, lr = 0.000355191
I1030 11:49:06.113442  1046 solver.cpp:222] Iteration 26960 (1.24802 iter/s, 32.0508s/40 iters), loss = 1.44847
I1030 11:49:06.113685  1046 solver.cpp:241]     Train net output #0: loss = 1.44847 (* 1 = 1.44847 loss)
I1030 11:49:06.113703  1046 sgd_solver.cpp:105] Iteration 26960, lr = 0.000353434
I1030 11:49:37.287909  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_27000.caffemodel
I1030 11:49:37.319839  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_27000.solverstate
I1030 11:49:37.336905  1046 solver.cpp:334] Iteration 27000, Testing net (#0)
I1030 11:50:08.283197  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58732
I1030 11:50:08.284405  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80972
I1030 11:50:08.284422  1046 solver.cpp:401]     Test net output #2: loss = 1.83655 (* 1 = 1.83655 loss)
I1030 11:50:09.047628  1046 solver.cpp:222] Iteration 27000 (0.635611 iter/s, 62.9316s/40 iters), loss = 1.39343
I1030 11:50:09.047695  1046 solver.cpp:241]     Train net output #0: loss = 1.39343 (* 1 = 1.39343 loss)
I1030 11:50:09.047711  1046 sgd_solver.cpp:105] Iteration 27000, lr = 0.000351685
I1030 11:50:39.825724  1046 solver.cpp:222] Iteration 27040 (1.29968 iter/s, 30.7769s/40 iters), loss = 1.62921
I1030 11:50:39.825915  1046 solver.cpp:241]     Train net output #0: loss = 1.62921 (* 1 = 1.62921 loss)
I1030 11:50:39.825935  1046 sgd_solver.cpp:105] Iteration 27040, lr = 0.000349945
I1030 11:51:10.300154  1046 solver.cpp:222] Iteration 27080 (1.31263 iter/s, 30.4731s/40 iters), loss = 1.55004
I1030 11:51:10.300343  1046 solver.cpp:241]     Train net output #0: loss = 1.55004 (* 1 = 1.55004 loss)
I1030 11:51:10.300360  1046 sgd_solver.cpp:105] Iteration 27080, lr = 0.000348214
I1030 11:51:41.147939  1046 solver.cpp:222] Iteration 27120 (1.29675 iter/s, 30.8464s/40 iters), loss = 1.02796
I1030 11:51:41.148147  1046 solver.cpp:241]     Train net output #0: loss = 1.02796 (* 1 = 1.02796 loss)
I1030 11:51:41.148166  1046 sgd_solver.cpp:105] Iteration 27120, lr = 0.000346491
I1030 11:52:12.051813  1046 solver.cpp:222] Iteration 27160 (1.29439 iter/s, 30.9025s/40 iters), loss = 1.20652
I1030 11:52:12.052018  1046 solver.cpp:241]     Train net output #0: loss = 1.20652 (* 1 = 1.20652 loss)
I1030 11:52:12.052037  1046 sgd_solver.cpp:105] Iteration 27160, lr = 0.000344777
I1030 11:52:42.927754  1046 solver.cpp:222] Iteration 27200 (1.29556 iter/s, 30.8746s/40 iters), loss = 1.68519
I1030 11:52:42.928040  1046 solver.cpp:241]     Train net output #0: loss = 1.68519 (* 1 = 1.68519 loss)
I1030 11:52:42.928084  1046 sgd_solver.cpp:105] Iteration 27200, lr = 0.000343072
I1030 11:53:14.289491  1046 solver.cpp:222] Iteration 27240 (1.2755 iter/s, 31.3603s/40 iters), loss = 1.53516
I1030 11:53:14.289685  1046 solver.cpp:241]     Train net output #0: loss = 1.53516 (* 1 = 1.53516 loss)
I1030 11:53:14.289701  1046 sgd_solver.cpp:105] Iteration 27240, lr = 0.000341374
I1030 11:53:45.012809  1046 solver.cpp:222] Iteration 27280 (1.302 iter/s, 30.722s/40 iters), loss = 1.29077
I1030 11:53:45.013029  1046 solver.cpp:241]     Train net output #0: loss = 1.29077 (* 1 = 1.29077 loss)
I1030 11:53:45.013046  1046 sgd_solver.cpp:105] Iteration 27280, lr = 0.000339685
I1030 11:54:16.031533  1046 solver.cpp:222] Iteration 27320 (1.2896 iter/s, 31.0173s/40 iters), loss = 1.31541
I1030 11:54:16.031730  1046 solver.cpp:241]     Train net output #0: loss = 1.31541 (* 1 = 1.31541 loss)
I1030 11:54:16.031749  1046 sgd_solver.cpp:105] Iteration 27320, lr = 0.000338005
I1030 11:54:47.041304  1046 solver.cpp:222] Iteration 27360 (1.28997 iter/s, 31.0084s/40 iters), loss = 1.45911
I1030 11:54:47.041512  1046 solver.cpp:241]     Train net output #0: loss = 1.45911 (* 1 = 1.45911 loss)
I1030 11:54:47.041530  1046 sgd_solver.cpp:105] Iteration 27360, lr = 0.000336333
I1030 11:55:17.510534  1046 solver.cpp:222] Iteration 27400 (1.31286 iter/s, 30.4679s/40 iters), loss = 1.35056
I1030 11:55:17.510746  1046 solver.cpp:241]     Train net output #0: loss = 1.35056 (* 1 = 1.35056 loss)
I1030 11:55:17.510764  1046 sgd_solver.cpp:105] Iteration 27400, lr = 0.000334669
I1030 11:55:48.145635  1046 solver.cpp:222] Iteration 27440 (1.30575 iter/s, 30.6337s/40 iters), loss = 1.50363
I1030 11:55:48.145853  1046 solver.cpp:241]     Train net output #0: loss = 1.50363 (* 1 = 1.50363 loss)
I1030 11:55:48.145874  1046 sgd_solver.cpp:105] Iteration 27440, lr = 0.000333013
I1030 11:56:18.793557  1046 solver.cpp:222] Iteration 27480 (1.3052 iter/s, 30.6466s/40 iters), loss = 1.40388
I1030 11:56:18.793751  1046 solver.cpp:241]     Train net output #0: loss = 1.40388 (* 1 = 1.40388 loss)
I1030 11:56:18.793769  1046 sgd_solver.cpp:105] Iteration 27480, lr = 0.000331366
I1030 11:56:33.211724  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_27500.caffemodel
I1030 11:56:33.246675  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_27500.solverstate
I1030 11:56:33.265578  1046 solver.cpp:334] Iteration 27500, Testing net (#0)
I1030 11:57:04.092334  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 11:57:04.298712  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58664
I1030 11:57:04.298774  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8128
I1030 11:57:04.298787  1046 solver.cpp:401]     Test net output #2: loss = 1.83801 (* 1 = 1.83801 loss)
I1030 11:57:21.045076  1046 solver.cpp:222] Iteration 27520 (0.642581 iter/s, 62.249s/40 iters), loss = 1.37041
I1030 11:57:21.045166  1046 solver.cpp:241]     Train net output #0: loss = 1.37041 (* 1 = 1.37041 loss)
I1030 11:57:21.045181  1046 sgd_solver.cpp:105] Iteration 27520, lr = 0.000329727
I1030 11:57:21.865347  1096 data_layer.cpp:73] Restarting data prefetching from start.
I1030 11:57:52.468372  1046 solver.cpp:222] Iteration 27560 (1.27299 iter/s, 31.422s/40 iters), loss = 1.32561
I1030 11:57:52.468667  1046 solver.cpp:241]     Train net output #0: loss = 1.32561 (* 1 = 1.32561 loss)
I1030 11:57:52.468698  1046 sgd_solver.cpp:105] Iteration 27560, lr = 0.000328095
I1030 11:58:23.635226  1046 solver.cpp:222] Iteration 27600 (1.28347 iter/s, 31.1654s/40 iters), loss = 1.49386
I1030 11:58:23.635428  1046 solver.cpp:241]     Train net output #0: loss = 1.49386 (* 1 = 1.49386 loss)
I1030 11:58:23.635445  1046 sgd_solver.cpp:105] Iteration 27600, lr = 0.000326472
I1030 11:58:54.404570  1046 solver.cpp:222] Iteration 27640 (1.30005 iter/s, 30.768s/40 iters), loss = 1.29764
I1030 11:58:54.404799  1046 solver.cpp:241]     Train net output #0: loss = 1.29764 (* 1 = 1.29764 loss)
I1030 11:58:54.404829  1046 sgd_solver.cpp:105] Iteration 27640, lr = 0.000324857
I1030 11:59:25.154863  1046 solver.cpp:222] Iteration 27680 (1.30086 iter/s, 30.7489s/40 iters), loss = 1.356
I1030 11:59:25.155071  1046 solver.cpp:241]     Train net output #0: loss = 1.356 (* 1 = 1.356 loss)
I1030 11:59:25.155086  1046 sgd_solver.cpp:105] Iteration 27680, lr = 0.00032325
I1030 11:59:56.455338  1046 solver.cpp:222] Iteration 27720 (1.27799 iter/s, 31.2991s/40 iters), loss = 1.16517
I1030 11:59:56.455559  1046 solver.cpp:241]     Train net output #0: loss = 1.16517 (* 1 = 1.16517 loss)
I1030 11:59:56.455576  1046 sgd_solver.cpp:105] Iteration 27720, lr = 0.000321651
I1030 12:00:27.902514  1046 solver.cpp:222] Iteration 27760 (1.27203 iter/s, 31.4458s/40 iters), loss = 1.22127
I1030 12:00:27.902736  1046 solver.cpp:241]     Train net output #0: loss = 1.22127 (* 1 = 1.22127 loss)
I1030 12:00:27.902753  1046 sgd_solver.cpp:105] Iteration 27760, lr = 0.00032006
I1030 12:00:59.557121  1046 solver.cpp:222] Iteration 27800 (1.2637 iter/s, 31.6532s/40 iters), loss = 1.37318
I1030 12:00:59.557322  1046 solver.cpp:241]     Train net output #0: loss = 1.37318 (* 1 = 1.37318 loss)
I1030 12:00:59.557339  1046 sgd_solver.cpp:105] Iteration 27800, lr = 0.000318476
I1030 12:01:31.529202  1046 solver.cpp:222] Iteration 27840 (1.25115 iter/s, 31.9707s/40 iters), loss = 1.49726
I1030 12:01:31.529417  1046 solver.cpp:241]     Train net output #0: loss = 1.49726 (* 1 = 1.49726 loss)
I1030 12:01:31.529435  1046 sgd_solver.cpp:105] Iteration 27840, lr = 0.000316901
I1030 12:02:02.579850  1046 solver.cpp:222] Iteration 27880 (1.28828 iter/s, 31.0493s/40 iters), loss = 1.54992
I1030 12:02:02.580035  1046 solver.cpp:241]     Train net output #0: loss = 1.54992 (* 1 = 1.54992 loss)
I1030 12:02:02.580052  1046 sgd_solver.cpp:105] Iteration 27880, lr = 0.000315333
I1030 12:02:33.396620  1046 solver.cpp:222] Iteration 27920 (1.29805 iter/s, 30.8154s/40 iters), loss = 1.71918
I1030 12:02:33.396812  1046 solver.cpp:241]     Train net output #0: loss = 1.71918 (* 1 = 1.71918 loss)
I1030 12:02:33.396829  1046 sgd_solver.cpp:105] Iteration 27920, lr = 0.000313773
I1030 12:03:03.942917  1046 solver.cpp:222] Iteration 27960 (1.30955 iter/s, 30.545s/40 iters), loss = 1.26797
I1030 12:03:03.943090  1046 solver.cpp:241]     Train net output #0: loss = 1.26797 (* 1 = 1.26797 loss)
I1030 12:03:03.943109  1046 sgd_solver.cpp:105] Iteration 27960, lr = 0.000312221
I1030 12:03:34.010229  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_28000.caffemodel
I1030 12:03:34.046535  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_28000.solverstate
I1030 12:03:34.069542  1046 solver.cpp:334] Iteration 28000, Testing net (#0)
I1030 12:04:05.166154  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5872
I1030 12:04:05.166330  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81028
I1030 12:04:05.166345  1046 solver.cpp:401]     Test net output #2: loss = 1.83536 (* 1 = 1.83536 loss)
I1030 12:04:05.926513  1046 solver.cpp:222] Iteration 28000 (0.645358 iter/s, 61.9811s/40 iters), loss = 0.969951
I1030 12:04:05.926574  1046 solver.cpp:241]     Train net output #0: loss = 0.969951 (* 1 = 0.969951 loss)
I1030 12:04:05.926589  1046 sgd_solver.cpp:105] Iteration 28000, lr = 0.000310676
I1030 12:04:36.681414  1046 solver.cpp:222] Iteration 28040 (1.30066 iter/s, 30.7537s/40 iters), loss = 1.07453
I1030 12:04:36.681668  1046 solver.cpp:241]     Train net output #0: loss = 1.07453 (* 1 = 1.07453 loss)
I1030 12:04:36.681690  1046 sgd_solver.cpp:105] Iteration 28040, lr = 0.000309139
I1030 12:05:07.382558  1046 solver.cpp:222] Iteration 28080 (1.30294 iter/s, 30.6997s/40 iters), loss = 1.2903
I1030 12:05:07.382750  1046 solver.cpp:241]     Train net output #0: loss = 1.2903 (* 1 = 1.2903 loss)
I1030 12:05:07.382766  1046 sgd_solver.cpp:105] Iteration 28080, lr = 0.00030761
I1030 12:05:39.596958  1046 solver.cpp:222] Iteration 28120 (1.24173 iter/s, 32.213s/40 iters), loss = 1.17805
I1030 12:05:39.597224  1046 solver.cpp:241]     Train net output #0: loss = 1.17805 (* 1 = 1.17805 loss)
I1030 12:05:39.597252  1046 sgd_solver.cpp:105] Iteration 28120, lr = 0.000306088
I1030 12:06:10.377334  1046 solver.cpp:222] Iteration 28160 (1.29959 iter/s, 30.779s/40 iters), loss = 1.3324
I1030 12:06:10.377517  1046 solver.cpp:241]     Train net output #0: loss = 1.3324 (* 1 = 1.3324 loss)
I1030 12:06:10.377535  1046 sgd_solver.cpp:105] Iteration 28160, lr = 0.000304574
I1030 12:06:41.274636  1046 solver.cpp:222] Iteration 28200 (1.29467 iter/s, 30.896s/40 iters), loss = 0.972251
I1030 12:06:41.274811  1046 solver.cpp:241]     Train net output #0: loss = 0.972251 (* 1 = 0.972251 loss)
I1030 12:06:41.274828  1046 sgd_solver.cpp:105] Iteration 28200, lr = 0.000303067
I1030 12:07:12.351549  1046 solver.cpp:222] Iteration 28240 (1.28718 iter/s, 31.0756s/40 iters), loss = 1.21385
I1030 12:07:12.351752  1046 solver.cpp:241]     Train net output #0: loss = 1.21385 (* 1 = 1.21385 loss)
I1030 12:07:12.351770  1046 sgd_solver.cpp:105] Iteration 28240, lr = 0.000301568
I1030 12:07:43.287081  1046 solver.cpp:222] Iteration 28280 (1.29307 iter/s, 30.9342s/40 iters), loss = 1.46351
I1030 12:07:43.287286  1046 solver.cpp:241]     Train net output #0: loss = 1.46351 (* 1 = 1.46351 loss)
I1030 12:07:43.287309  1046 sgd_solver.cpp:105] Iteration 28280, lr = 0.000300076
I1030 12:08:13.976840  1046 solver.cpp:222] Iteration 28320 (1.30342 iter/s, 30.6884s/40 iters), loss = 1.37891
I1030 12:08:13.977044  1046 solver.cpp:241]     Train net output #0: loss = 1.37891 (* 1 = 1.37891 loss)
I1030 12:08:13.977061  1046 sgd_solver.cpp:105] Iteration 28320, lr = 0.000298591
I1030 12:08:44.795145  1046 solver.cpp:222] Iteration 28360 (1.29799 iter/s, 30.8169s/40 iters), loss = 1.50909
I1030 12:08:44.795344  1046 solver.cpp:241]     Train net output #0: loss = 1.50909 (* 1 = 1.50909 loss)
I1030 12:08:44.795361  1046 sgd_solver.cpp:105] Iteration 28360, lr = 0.000297114
I1030 12:09:15.526087  1046 solver.cpp:222] Iteration 28400 (1.30168 iter/s, 30.7296s/40 iters), loss = 1.47404
I1030 12:09:15.526305  1046 solver.cpp:241]     Train net output #0: loss = 1.47404 (* 1 = 1.47404 loss)
I1030 12:09:15.526324  1046 sgd_solver.cpp:105] Iteration 28400, lr = 0.000295644
I1030 12:09:46.435302  1046 solver.cpp:222] Iteration 28440 (1.29417 iter/s, 30.9078s/40 iters), loss = 1.28287
I1030 12:09:46.435513  1046 solver.cpp:241]     Train net output #0: loss = 1.28287 (* 1 = 1.28287 loss)
I1030 12:09:46.435531  1046 sgd_solver.cpp:105] Iteration 28440, lr = 0.000294182
I1030 12:10:17.461695  1046 solver.cpp:222] Iteration 28480 (1.28928 iter/s, 31.025s/40 iters), loss = 1.32631
I1030 12:10:17.461916  1046 solver.cpp:241]     Train net output #0: loss = 1.32631 (* 1 = 1.32631 loss)
I1030 12:10:17.461933  1046 sgd_solver.cpp:105] Iteration 28480, lr = 0.000292726
I1030 12:10:32.088790  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_28500.caffemodel
I1030 12:10:32.120499  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_28500.solverstate
I1030 12:10:32.137364  1046 solver.cpp:334] Iteration 28500, Testing net (#0)
I1030 12:11:02.846712  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 12:11:03.053040  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58644
I1030 12:11:03.053099  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813439
I1030 12:11:03.053112  1046 solver.cpp:401]     Test net output #2: loss = 1.83914 (* 1 = 1.83914 loss)
I1030 12:11:19.023524  1046 solver.cpp:222] Iteration 28520 (0.64978 iter/s, 61.5593s/40 iters), loss = 1.58672
I1030 12:11:19.023597  1046 solver.cpp:241]     Train net output #0: loss = 1.58672 (* 1 = 1.58672 loss)
I1030 12:11:19.023613  1046 sgd_solver.cpp:105] Iteration 28520, lr = 0.000291278
I1030 12:11:50.124291  1046 solver.cpp:222] Iteration 28560 (1.28619 iter/s, 31.0995s/40 iters), loss = 1.22602
I1030 12:11:50.124539  1046 solver.cpp:241]     Train net output #0: loss = 1.22602 (* 1 = 1.22602 loss)
I1030 12:11:50.124558  1046 sgd_solver.cpp:105] Iteration 28560, lr = 0.000289837
I1030 12:12:20.965869  1046 solver.cpp:222] Iteration 28600 (1.29701 iter/s, 30.8402s/40 iters), loss = 1.71464
I1030 12:12:20.966079  1046 solver.cpp:241]     Train net output #0: loss = 1.71464 (* 1 = 1.71464 loss)
I1030 12:12:20.966096  1046 sgd_solver.cpp:105] Iteration 28600, lr = 0.000288403
I1030 12:12:51.323215  1046 solver.cpp:222] Iteration 28640 (1.3177 iter/s, 30.356s/40 iters), loss = 1.64812
I1030 12:12:51.323388  1046 solver.cpp:241]     Train net output #0: loss = 1.64812 (* 1 = 1.64812 loss)
I1030 12:12:51.323405  1046 sgd_solver.cpp:105] Iteration 28640, lr = 0.000286976
I1030 12:13:21.697365  1046 solver.cpp:222] Iteration 28680 (1.31697 iter/s, 30.3728s/40 iters), loss = 1.13512
I1030 12:13:21.697548  1046 solver.cpp:241]     Train net output #0: loss = 1.13512 (* 1 = 1.13512 loss)
I1030 12:13:21.697566  1046 sgd_solver.cpp:105] Iteration 28680, lr = 0.000285557
I1030 12:13:52.242897  1046 solver.cpp:222] Iteration 28720 (1.30958 iter/s, 30.5442s/40 iters), loss = 1.53677
I1030 12:13:52.243093  1046 solver.cpp:241]     Train net output #0: loss = 1.53677 (* 1 = 1.53677 loss)
I1030 12:13:52.243110  1046 sgd_solver.cpp:105] Iteration 28720, lr = 0.000284144
I1030 12:14:22.992004  1046 solver.cpp:222] Iteration 28760 (1.30091 iter/s, 30.7478s/40 iters), loss = 1.22734
I1030 12:14:22.992204  1046 solver.cpp:241]     Train net output #0: loss = 1.22734 (* 1 = 1.22734 loss)
I1030 12:14:22.992221  1046 sgd_solver.cpp:105] Iteration 28760, lr = 0.000282738
I1030 12:14:53.597575  1046 solver.cpp:222] Iteration 28800 (1.30701 iter/s, 30.6042s/40 iters), loss = 1.63765
I1030 12:14:53.597771  1046 solver.cpp:241]     Train net output #0: loss = 1.63765 (* 1 = 1.63765 loss)
I1030 12:14:53.597789  1046 sgd_solver.cpp:105] Iteration 28800, lr = 0.00028134
I1030 12:15:24.520905  1046 solver.cpp:222] Iteration 28840 (1.29358 iter/s, 30.922s/40 iters), loss = 1.39876
I1030 12:15:24.521134  1046 solver.cpp:241]     Train net output #0: loss = 1.39876 (* 1 = 1.39876 loss)
I1030 12:15:24.521152  1046 sgd_solver.cpp:105] Iteration 28840, lr = 0.000279948
I1030 12:15:55.561276  1046 solver.cpp:222] Iteration 28880 (1.2887 iter/s, 31.039s/40 iters), loss = 1.09402
I1030 12:15:55.561481  1046 solver.cpp:241]     Train net output #0: loss = 1.09402 (* 1 = 1.09402 loss)
I1030 12:15:55.561501  1046 sgd_solver.cpp:105] Iteration 28880, lr = 0.000278563
I1030 12:16:25.961704  1046 solver.cpp:222] Iteration 28920 (1.31583 iter/s, 30.3991s/40 iters), loss = 1.6033
I1030 12:16:25.961911  1046 solver.cpp:241]     Train net output #0: loss = 1.6033 (* 1 = 1.6033 loss)
I1030 12:16:25.961927  1046 sgd_solver.cpp:105] Iteration 28920, lr = 0.000277185
I1030 12:16:56.312867  1046 solver.cpp:222] Iteration 28960 (1.31797 iter/s, 30.3498s/40 iters), loss = 1.57294
I1030 12:16:56.313076  1046 solver.cpp:241]     Train net output #0: loss = 1.57294 (* 1 = 1.57294 loss)
I1030 12:16:56.313093  1046 sgd_solver.cpp:105] Iteration 28960, lr = 0.000275813
I1030 12:17:26.172222  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_29000.caffemodel
I1030 12:17:26.212307  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_29000.solverstate
I1030 12:17:26.233943  1046 solver.cpp:334] Iteration 29000, Testing net (#0)
I1030 12:17:57.168109  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58868
I1030 12:17:57.168308  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8098
I1030 12:17:57.168328  1046 solver.cpp:401]     Test net output #2: loss = 1.83562 (* 1 = 1.83562 loss)
I1030 12:17:57.929891  1046 solver.cpp:222] Iteration 29000 (0.649198 iter/s, 61.6145s/40 iters), loss = 1.4935
I1030 12:17:57.929951  1046 solver.cpp:241]     Train net output #0: loss = 1.4935 (* 1 = 1.4935 loss)
I1030 12:17:57.929980  1046 sgd_solver.cpp:105] Iteration 29000, lr = 0.000274449
I1030 12:18:28.792651  1046 solver.cpp:222] Iteration 29040 (1.29611 iter/s, 30.8615s/40 iters), loss = 1.50477
I1030 12:18:28.792896  1046 solver.cpp:241]     Train net output #0: loss = 1.50477 (* 1 = 1.50477 loss)
I1030 12:18:28.792912  1046 sgd_solver.cpp:105] Iteration 29040, lr = 0.000273091
I1030 12:18:59.970147  1046 solver.cpp:222] Iteration 29080 (1.28304 iter/s, 31.1761s/40 iters), loss = 1.39089
I1030 12:18:59.970343  1046 solver.cpp:241]     Train net output #0: loss = 1.39089 (* 1 = 1.39089 loss)
I1030 12:18:59.970362  1046 sgd_solver.cpp:105] Iteration 29080, lr = 0.00027174
I1030 12:19:31.404990  1046 solver.cpp:222] Iteration 29120 (1.27253 iter/s, 31.4335s/40 iters), loss = 1.20272
I1030 12:19:31.405233  1046 solver.cpp:241]     Train net output #0: loss = 1.20272 (* 1 = 1.20272 loss)
I1030 12:19:31.405261  1046 sgd_solver.cpp:105] Iteration 29120, lr = 0.000270396
I1030 12:20:05.987023  1046 solver.cpp:222] Iteration 29160 (1.15672 iter/s, 34.5805s/40 iters), loss = 1.3603
I1030 12:20:05.987310  1046 solver.cpp:241]     Train net output #0: loss = 1.3603 (* 1 = 1.3603 loss)
I1030 12:20:05.987339  1046 sgd_solver.cpp:105] Iteration 29160, lr = 0.000269058
I1030 12:20:39.736325  1046 solver.cpp:222] Iteration 29200 (1.18526 iter/s, 33.7477s/40 iters), loss = 1.14121
I1030 12:20:39.736531  1046 solver.cpp:241]     Train net output #0: loss = 1.14121 (* 1 = 1.14121 loss)
I1030 12:20:39.736560  1046 sgd_solver.cpp:105] Iteration 29200, lr = 0.000267727
I1030 12:21:11.740579  1046 solver.cpp:222] Iteration 29240 (1.24989 iter/s, 32.0028s/40 iters), loss = 1.42674
I1030 12:21:11.740784  1046 solver.cpp:241]     Train net output #0: loss = 1.42674 (* 1 = 1.42674 loss)
I1030 12:21:11.740802  1046 sgd_solver.cpp:105] Iteration 29240, lr = 0.000266403
I1030 12:21:42.786007  1046 solver.cpp:222] Iteration 29280 (1.28849 iter/s, 31.0441s/40 iters), loss = 1.54638
I1030 12:21:42.786208  1046 solver.cpp:241]     Train net output #0: loss = 1.54638 (* 1 = 1.54638 loss)
I1030 12:21:42.786226  1046 sgd_solver.cpp:105] Iteration 29280, lr = 0.000265085
I1030 12:22:14.996922  1046 solver.cpp:222] Iteration 29320 (1.24187 iter/s, 32.2095s/40 iters), loss = 1.26782
I1030 12:22:14.997104  1046 solver.cpp:241]     Train net output #0: loss = 1.26782 (* 1 = 1.26782 loss)
I1030 12:22:14.997122  1046 sgd_solver.cpp:105] Iteration 29320, lr = 0.000263773
I1030 12:22:45.709108  1046 solver.cpp:222] Iteration 29360 (1.30247 iter/s, 30.7108s/40 iters), loss = 1.16808
I1030 12:22:45.709280  1046 solver.cpp:241]     Train net output #0: loss = 1.16808 (* 1 = 1.16808 loss)
I1030 12:22:45.709303  1046 sgd_solver.cpp:105] Iteration 29360, lr = 0.000262468
I1030 12:23:16.286821  1046 solver.cpp:222] Iteration 29400 (1.3082 iter/s, 30.5764s/40 iters), loss = 1.60773
I1030 12:23:16.287006  1046 solver.cpp:241]     Train net output #0: loss = 1.60773 (* 1 = 1.60773 loss)
I1030 12:23:16.287024  1046 sgd_solver.cpp:105] Iteration 29400, lr = 0.00026117
I1030 12:23:47.120095  1046 solver.cpp:222] Iteration 29440 (1.29736 iter/s, 30.8319s/40 iters), loss = 1.43988
I1030 12:23:47.120283  1046 solver.cpp:241]     Train net output #0: loss = 1.43988 (* 1 = 1.43988 loss)
I1030 12:23:47.120307  1046 sgd_solver.cpp:105] Iteration 29440, lr = 0.000259878
I1030 12:24:18.010512  1046 solver.cpp:222] Iteration 29480 (1.29496 iter/s, 30.8891s/40 iters), loss = 1.48636
I1030 12:24:18.010689  1046 solver.cpp:241]     Train net output #0: loss = 1.48636 (* 1 = 1.48636 loss)
I1030 12:24:18.010704  1046 sgd_solver.cpp:105] Iteration 29480, lr = 0.000258592
I1030 12:24:32.472820  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_29500.caffemodel
I1030 12:24:32.503671  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_29500.solverstate
I1030 12:24:32.520572  1046 solver.cpp:334] Iteration 29500, Testing net (#0)
I1030 12:25:03.259249  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 12:25:03.466976  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5868
I1030 12:25:03.467033  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813799
I1030 12:25:03.467046  1046 solver.cpp:401]     Test net output #2: loss = 1.83801 (* 1 = 1.83801 loss)
I1030 12:25:19.710431  1046 solver.cpp:222] Iteration 29520 (0.648325 iter/s, 61.6974s/40 iters), loss = 1.25641
I1030 12:25:19.710515  1046 solver.cpp:241]     Train net output #0: loss = 1.25641 (* 1 = 1.25641 loss)
I1030 12:25:19.710537  1046 sgd_solver.cpp:105] Iteration 29520, lr = 0.000257313
I1030 12:25:51.134189  1046 solver.cpp:222] Iteration 29560 (1.27297 iter/s, 31.4225s/40 iters), loss = 1.63248
I1030 12:25:51.134392  1046 solver.cpp:241]     Train net output #0: loss = 1.63248 (* 1 = 1.63248 loss)
I1030 12:25:51.134409  1046 sgd_solver.cpp:105] Iteration 29560, lr = 0.00025604
I1030 12:26:21.075871  1046 solver.cpp:222] Iteration 29600 (1.33599 iter/s, 29.9403s/40 iters), loss = 1.33759
I1030 12:26:21.075938  1046 solver.cpp:241]     Train net output #0: loss = 1.33759 (* 1 = 1.33759 loss)
I1030 12:26:21.075954  1046 sgd_solver.cpp:105] Iteration 29600, lr = 0.000254773
I1030 12:26:52.177647  1046 solver.cpp:222] Iteration 29640 (1.28615 iter/s, 31.1005s/40 iters), loss = 1.36394
I1030 12:26:52.177841  1046 solver.cpp:241]     Train net output #0: loss = 1.36394 (* 1 = 1.36394 loss)
I1030 12:26:52.177861  1046 sgd_solver.cpp:105] Iteration 29640, lr = 0.000253513
I1030 12:27:23.430299  1046 solver.cpp:222] Iteration 29680 (1.27995 iter/s, 31.2513s/40 iters), loss = 1.21746
I1030 12:27:23.430521  1046 solver.cpp:241]     Train net output #0: loss = 1.21746 (* 1 = 1.21746 loss)
I1030 12:27:23.430538  1046 sgd_solver.cpp:105] Iteration 29680, lr = 0.000252259
I1030 12:27:54.132879  1046 solver.cpp:222] Iteration 29720 (1.30288 iter/s, 30.7012s/40 iters), loss = 1.39141
I1030 12:27:54.133126  1046 solver.cpp:241]     Train net output #0: loss = 1.39141 (* 1 = 1.39141 loss)
I1030 12:27:54.133142  1046 sgd_solver.cpp:105] Iteration 29720, lr = 0.000251011
I1030 12:28:24.423604  1046 solver.cpp:222] Iteration 29760 (1.3206 iter/s, 30.2893s/40 iters), loss = 1.4491
I1030 12:28:24.423794  1046 solver.cpp:241]     Train net output #0: loss = 1.4491 (* 1 = 1.4491 loss)
I1030 12:28:24.423811  1046 sgd_solver.cpp:105] Iteration 29760, lr = 0.000249769
I1030 12:28:55.160765  1046 solver.cpp:222] Iteration 29800 (1.30141 iter/s, 30.7358s/40 iters), loss = 1.74765
I1030 12:28:55.160971  1046 solver.cpp:241]     Train net output #0: loss = 1.74765 (* 1 = 1.74765 loss)
I1030 12:28:55.160989  1046 sgd_solver.cpp:105] Iteration 29800, lr = 0.000248533
I1030 12:29:25.819545  1046 solver.cpp:222] Iteration 29840 (1.30474 iter/s, 30.6574s/40 iters), loss = 1.32959
I1030 12:29:25.819751  1046 solver.cpp:241]     Train net output #0: loss = 1.32959 (* 1 = 1.32959 loss)
I1030 12:29:25.819768  1046 sgd_solver.cpp:105] Iteration 29840, lr = 0.000247304
I1030 12:29:56.538594  1046 solver.cpp:222] Iteration 29880 (1.30218 iter/s, 30.7177s/40 iters), loss = 1.40056
I1030 12:29:56.538790  1046 solver.cpp:241]     Train net output #0: loss = 1.40056 (* 1 = 1.40056 loss)
I1030 12:29:56.538808  1046 sgd_solver.cpp:105] Iteration 29880, lr = 0.00024608
I1030 12:30:26.924809  1046 solver.cpp:222] Iteration 29920 (1.31644 iter/s, 30.3849s/40 iters), loss = 1.2512
I1030 12:30:26.924993  1046 solver.cpp:241]     Train net output #0: loss = 1.2512 (* 1 = 1.2512 loss)
I1030 12:30:26.925010  1046 sgd_solver.cpp:105] Iteration 29920, lr = 0.000244863
I1030 12:30:57.728085  1046 solver.cpp:222] Iteration 29960 (1.29862 iter/s, 30.8019s/40 iters), loss = 1.27585
I1030 12:30:57.728313  1046 solver.cpp:241]     Train net output #0: loss = 1.27585 (* 1 = 1.27585 loss)
I1030 12:30:57.728334  1046 sgd_solver.cpp:105] Iteration 29960, lr = 0.000243652
I1030 12:31:27.979820  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_30000.caffemodel
I1030 12:31:28.012599  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_30000.solverstate
I1030 12:31:28.030880  1046 solver.cpp:334] Iteration 30000, Testing net (#0)
I1030 12:31:58.940104  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58744
I1030 12:31:58.940279  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.810079
I1030 12:31:58.940295  1046 solver.cpp:401]     Test net output #2: loss = 1.83326 (* 1 = 1.83326 loss)
I1030 12:31:59.709513  1046 solver.cpp:222] Iteration 30000 (0.645381 iter/s, 61.9789s/40 iters), loss = 1.33386
I1030 12:31:59.709574  1046 solver.cpp:241]     Train net output #0: loss = 1.33386 (* 1 = 1.33386 loss)
I1030 12:31:59.709591  1046 sgd_solver.cpp:105] Iteration 30000, lr = 0.000242446
I1030 12:32:17.312080  1096 data_layer.cpp:73] Restarting data prefetching from start.
I1030 12:32:30.214262  1046 solver.cpp:222] Iteration 30040 (1.31132 iter/s, 30.5035s/40 iters), loss = 1.28133
I1030 12:32:30.214449  1046 solver.cpp:241]     Train net output #0: loss = 1.28133 (* 1 = 1.28133 loss)
I1030 12:32:30.214465  1046 sgd_solver.cpp:105] Iteration 30040, lr = 0.000241247
I1030 12:33:01.241106  1046 solver.cpp:222] Iteration 30080 (1.28926 iter/s, 31.0255s/40 iters), loss = 1.42946
I1030 12:33:01.241312  1046 solver.cpp:241]     Train net output #0: loss = 1.42946 (* 1 = 1.42946 loss)
I1030 12:33:01.241330  1046 sgd_solver.cpp:105] Iteration 30080, lr = 0.000240053
I1030 12:33:32.194036  1046 solver.cpp:222] Iteration 30120 (1.29234 iter/s, 30.9516s/40 iters), loss = 1.16122
I1030 12:33:32.194242  1046 solver.cpp:241]     Train net output #0: loss = 1.16122 (* 1 = 1.16122 loss)
I1030 12:33:32.194259  1046 sgd_solver.cpp:105] Iteration 30120, lr = 0.000238866
I1030 12:34:02.629597  1046 solver.cpp:222] Iteration 30160 (1.31431 iter/s, 30.4342s/40 iters), loss = 1.24113
I1030 12:34:02.629781  1046 solver.cpp:241]     Train net output #0: loss = 1.24113 (* 1 = 1.24113 loss)
I1030 12:34:02.629801  1046 sgd_solver.cpp:105] Iteration 30160, lr = 0.000237684
I1030 12:34:34.098438  1046 solver.cpp:222] Iteration 30200 (1.27115 iter/s, 31.4675s/40 iters), loss = 1.59024
I1030 12:34:34.098655  1046 solver.cpp:241]     Train net output #0: loss = 1.59024 (* 1 = 1.59024 loss)
I1030 12:34:34.098682  1046 sgd_solver.cpp:105] Iteration 30200, lr = 0.000236508
I1030 12:35:05.838861  1046 solver.cpp:222] Iteration 30240 (1.26028 iter/s, 31.739s/40 iters), loss = 1.35243
I1030 12:35:05.839066  1046 solver.cpp:241]     Train net output #0: loss = 1.35243 (* 1 = 1.35243 loss)
I1030 12:35:05.839087  1046 sgd_solver.cpp:105] Iteration 30240, lr = 0.000235338
I1030 12:35:36.398051  1046 solver.cpp:222] Iteration 30280 (1.30899 iter/s, 30.5578s/40 iters), loss = 1.34616
I1030 12:35:36.398260  1046 solver.cpp:241]     Train net output #0: loss = 1.34616 (* 1 = 1.34616 loss)
I1030 12:35:36.398277  1046 sgd_solver.cpp:105] Iteration 30280, lr = 0.000234174
I1030 12:36:06.763913  1046 solver.cpp:222] Iteration 30320 (1.31733 iter/s, 30.3645s/40 iters), loss = 1.4341
I1030 12:36:06.764088  1046 solver.cpp:241]     Train net output #0: loss = 1.4341 (* 1 = 1.4341 loss)
I1030 12:36:06.764104  1046 sgd_solver.cpp:105] Iteration 30320, lr = 0.000233015
I1030 12:36:36.982621  1046 solver.cpp:222] Iteration 30360 (1.32374 iter/s, 30.2174s/40 iters), loss = 1.4608
I1030 12:36:36.982801  1046 solver.cpp:241]     Train net output #0: loss = 1.4608 (* 1 = 1.4608 loss)
I1030 12:36:36.982817  1046 sgd_solver.cpp:105] Iteration 30360, lr = 0.000231863
I1030 12:37:07.428841  1046 solver.cpp:222] Iteration 30400 (1.31385 iter/s, 30.4449s/40 iters), loss = 1.28204
I1030 12:37:07.429069  1046 solver.cpp:241]     Train net output #0: loss = 1.28204 (* 1 = 1.28204 loss)
I1030 12:37:07.429092  1046 sgd_solver.cpp:105] Iteration 30400, lr = 0.000230716
I1030 12:37:38.851969  1046 solver.cpp:222] Iteration 30440 (1.27301 iter/s, 31.4217s/40 iters), loss = 1.55572
I1030 12:37:38.852226  1046 solver.cpp:241]     Train net output #0: loss = 1.55572 (* 1 = 1.55572 loss)
I1030 12:37:38.852255  1046 sgd_solver.cpp:105] Iteration 30440, lr = 0.000229574
I1030 12:38:09.565134  1046 solver.cpp:222] Iteration 30480 (1.30243 iter/s, 30.7118s/40 iters), loss = 1.38371
I1030 12:38:09.565407  1046 solver.cpp:241]     Train net output #0: loss = 1.38371 (* 1 = 1.38371 loss)
I1030 12:38:09.565424  1046 sgd_solver.cpp:105] Iteration 30480, lr = 0.000228438
I1030 12:38:24.063040  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_30500.caffemodel
I1030 12:38:24.094908  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_30500.solverstate
I1030 12:38:24.113018  1046 solver.cpp:334] Iteration 30500, Testing net (#0)
I1030 12:38:54.851052  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 12:38:55.059084  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5868
I1030 12:38:55.059147  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81356
I1030 12:38:55.059161  1046 solver.cpp:401]     Test net output #2: loss = 1.83876 (* 1 = 1.83876 loss)
I1030 12:39:11.277096  1046 solver.cpp:222] Iteration 30520 (0.6482 iter/s, 61.7094s/40 iters), loss = 1.24092
I1030 12:39:11.277164  1046 solver.cpp:241]     Train net output #0: loss = 1.24092 (* 1 = 1.24092 loss)
I1030 12:39:11.277182  1046 sgd_solver.cpp:105] Iteration 30520, lr = 0.000227308
I1030 12:39:42.088662  1046 solver.cpp:222] Iteration 30560 (1.29827 iter/s, 30.8103s/40 iters), loss = 1.27944
I1030 12:39:42.088874  1046 solver.cpp:241]     Train net output #0: loss = 1.27944 (* 1 = 1.27944 loss)
I1030 12:39:42.088891  1046 sgd_solver.cpp:105] Iteration 30560, lr = 0.000226184
I1030 12:40:13.318934  1046 solver.cpp:222] Iteration 30600 (1.28087 iter/s, 31.2289s/40 iters), loss = 1.459
I1030 12:40:13.319201  1046 solver.cpp:241]     Train net output #0: loss = 1.459 (* 1 = 1.459 loss)
I1030 12:40:13.319231  1046 sgd_solver.cpp:105] Iteration 30600, lr = 0.000225065
I1030 12:40:44.560986  1046 solver.cpp:222] Iteration 30640 (1.28039 iter/s, 31.2406s/40 iters), loss = 1.68654
I1030 12:40:44.561184  1046 solver.cpp:241]     Train net output #0: loss = 1.68654 (* 1 = 1.68654 loss)
I1030 12:40:44.561203  1046 sgd_solver.cpp:105] Iteration 30640, lr = 0.000223951
I1030 12:41:15.496515  1046 solver.cpp:222] Iteration 30680 (1.29307 iter/s, 30.9342s/40 iters), loss = 1.29137
I1030 12:41:15.496709  1046 solver.cpp:241]     Train net output #0: loss = 1.29137 (* 1 = 1.29137 loss)
I1030 12:41:15.496727  1046 sgd_solver.cpp:105] Iteration 30680, lr = 0.000222844
I1030 12:41:46.497620  1046 solver.cpp:222] Iteration 30720 (1.29033 iter/s, 30.9997s/40 iters), loss = 1.31584
I1030 12:41:46.497817  1046 solver.cpp:241]     Train net output #0: loss = 1.31584 (* 1 = 1.31584 loss)
I1030 12:41:46.497839  1046 sgd_solver.cpp:105] Iteration 30720, lr = 0.000221741
I1030 12:42:17.579004  1046 solver.cpp:222] Iteration 30760 (1.287 iter/s, 31.08s/40 iters), loss = 1.34551
I1030 12:42:17.579188  1046 solver.cpp:241]     Train net output #0: loss = 1.34551 (* 1 = 1.34551 loss)
I1030 12:42:17.579205  1046 sgd_solver.cpp:105] Iteration 30760, lr = 0.000220644
I1030 12:42:48.539677  1046 solver.cpp:222] Iteration 30800 (1.29202 iter/s, 30.9593s/40 iters), loss = 1.38038
I1030 12:42:48.539887  1046 solver.cpp:241]     Train net output #0: loss = 1.38038 (* 1 = 1.38038 loss)
I1030 12:42:48.539906  1046 sgd_solver.cpp:105] Iteration 30800, lr = 0.000219553
I1030 12:43:19.029968  1046 solver.cpp:222] Iteration 30840 (1.31195 iter/s, 30.4889s/40 iters), loss = 1.31656
I1030 12:43:19.030184  1046 solver.cpp:241]     Train net output #0: loss = 1.31656 (* 1 = 1.31656 loss)
I1030 12:43:19.030201  1046 sgd_solver.cpp:105] Iteration 30840, lr = 0.000218466
I1030 12:43:49.502949  1046 solver.cpp:222] Iteration 30880 (1.3127 iter/s, 30.4716s/40 iters), loss = 1.30312
I1030 12:43:49.503165  1046 solver.cpp:241]     Train net output #0: loss = 1.30312 (* 1 = 1.30312 loss)
I1030 12:43:49.503188  1046 sgd_solver.cpp:105] Iteration 30880, lr = 0.000217386
I1030 12:44:20.615583  1046 solver.cpp:222] Iteration 30920 (1.28571 iter/s, 31.1112s/40 iters), loss = 1.61021
I1030 12:44:20.615799  1046 solver.cpp:241]     Train net output #0: loss = 1.61021 (* 1 = 1.61021 loss)
I1030 12:44:20.615823  1046 sgd_solver.cpp:105] Iteration 30920, lr = 0.00021631
I1030 12:44:51.839834  1046 solver.cpp:222] Iteration 30960 (1.28111 iter/s, 31.2229s/40 iters), loss = 1.20898
I1030 12:44:51.840024  1046 solver.cpp:241]     Train net output #0: loss = 1.20898 (* 1 = 1.20898 loss)
I1030 12:44:51.840041  1046 sgd_solver.cpp:105] Iteration 30960, lr = 0.00021524
I1030 12:45:22.163537  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_31000.caffemodel
I1030 12:45:22.196619  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_31000.solverstate
I1030 12:45:22.214776  1046 solver.cpp:334] Iteration 31000, Testing net (#0)
I1030 12:45:53.116544  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58656
I1030 12:45:53.116725  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80976
I1030 12:45:53.116742  1046 solver.cpp:401]     Test net output #2: loss = 1.83397 (* 1 = 1.83397 loss)
I1030 12:45:53.876699  1046 solver.cpp:222] Iteration 31000 (0.644804 iter/s, 62.0344s/40 iters), loss = 0.964903
I1030 12:45:53.876760  1046 solver.cpp:241]     Train net output #0: loss = 0.964903 (* 1 = 0.964903 loss)
I1030 12:45:53.876776  1046 sgd_solver.cpp:105] Iteration 31000, lr = 0.000214175
I1030 12:46:24.962018  1046 solver.cpp:222] Iteration 31040 (1.28683 iter/s, 31.0841s/40 iters), loss = 1.22785
I1030 12:46:24.962208  1046 solver.cpp:241]     Train net output #0: loss = 1.22785 (* 1 = 1.22785 loss)
I1030 12:46:24.962226  1046 sgd_solver.cpp:105] Iteration 31040, lr = 0.000213116
I1030 12:46:55.481773  1046 solver.cpp:222] Iteration 31080 (1.31068 iter/s, 30.5184s/40 iters), loss = 1.14217
I1030 12:46:55.481987  1046 solver.cpp:241]     Train net output #0: loss = 1.14217 (* 1 = 1.14217 loss)
I1030 12:46:55.482005  1046 sgd_solver.cpp:105] Iteration 31080, lr = 0.000212061
I1030 12:47:26.447861  1046 solver.cpp:222] Iteration 31120 (1.29179 iter/s, 30.9647s/40 iters), loss = 1.29804
I1030 12:47:26.448071  1046 solver.cpp:241]     Train net output #0: loss = 1.29804 (* 1 = 1.29804 loss)
I1030 12:47:26.448089  1046 sgd_solver.cpp:105] Iteration 31120, lr = 0.000211012
I1030 12:47:57.216941  1046 solver.cpp:222] Iteration 31160 (1.30006 iter/s, 30.7677s/40 iters), loss = 1.42278
I1030 12:47:57.217139  1046 solver.cpp:241]     Train net output #0: loss = 1.42278 (* 1 = 1.42278 loss)
I1030 12:47:57.217159  1046 sgd_solver.cpp:105] Iteration 31160, lr = 0.000209968
I1030 12:48:27.856256  1046 solver.cpp:222] Iteration 31200 (1.30557 iter/s, 30.638s/40 iters), loss = 1.54103
I1030 12:48:27.856521  1046 solver.cpp:241]     Train net output #0: loss = 1.54103 (* 1 = 1.54103 loss)
I1030 12:48:27.856547  1046 sgd_solver.cpp:105] Iteration 31200, lr = 0.00020893
I1030 12:48:58.583884  1046 solver.cpp:222] Iteration 31240 (1.30182 iter/s, 30.7262s/40 iters), loss = 1.32421
I1030 12:48:58.584085  1046 solver.cpp:241]     Train net output #0: loss = 1.32421 (* 1 = 1.32421 loss)
I1030 12:48:58.584101  1046 sgd_solver.cpp:105] Iteration 31240, lr = 0.000207896
I1030 12:49:29.499285  1046 solver.cpp:222] Iteration 31280 (1.29391 iter/s, 30.914s/40 iters), loss = 1.22696
I1030 12:49:29.499492  1046 solver.cpp:241]     Train net output #0: loss = 1.22696 (* 1 = 1.22696 loss)
I1030 12:49:29.499510  1046 sgd_solver.cpp:105] Iteration 31280, lr = 0.000206868
I1030 12:50:00.444224  1046 solver.cpp:222] Iteration 31320 (1.29268 iter/s, 30.9436s/40 iters), loss = 1.22016
I1030 12:50:00.444422  1046 solver.cpp:241]     Train net output #0: loss = 1.22016 (* 1 = 1.22016 loss)
I1030 12:50:00.444442  1046 sgd_solver.cpp:105] Iteration 31320, lr = 0.000205844
I1030 12:50:31.309017  1046 solver.cpp:222] Iteration 31360 (1.29603 iter/s, 30.8634s/40 iters), loss = 1.35133
I1030 12:50:31.309307  1046 solver.cpp:241]     Train net output #0: loss = 1.35133 (* 1 = 1.35133 loss)
I1030 12:50:31.309365  1046 sgd_solver.cpp:105] Iteration 31360, lr = 0.000204826
I1030 12:51:02.208513  1046 solver.cpp:222] Iteration 31400 (1.29458 iter/s, 30.8981s/40 iters), loss = 1.54963
I1030 12:51:02.208691  1046 solver.cpp:241]     Train net output #0: loss = 1.54963 (* 1 = 1.54963 loss)
I1030 12:51:02.208709  1046 sgd_solver.cpp:105] Iteration 31400, lr = 0.000203812
I1030 12:51:33.369047  1046 solver.cpp:222] Iteration 31440 (1.28373 iter/s, 31.1592s/40 iters), loss = 1.31947
I1030 12:51:33.369247  1046 solver.cpp:241]     Train net output #0: loss = 1.31947 (* 1 = 1.31947 loss)
I1030 12:51:33.369264  1046 sgd_solver.cpp:105] Iteration 31440, lr = 0.000202804
I1030 12:52:04.543324  1046 solver.cpp:222] Iteration 31480 (1.28317 iter/s, 31.1729s/40 iters), loss = 1.6221
I1030 12:52:04.543519  1046 solver.cpp:241]     Train net output #0: loss = 1.6221 (* 1 = 1.6221 loss)
I1030 12:52:04.543537  1046 sgd_solver.cpp:105] Iteration 31480, lr = 0.000201801
I1030 12:52:19.215941  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_31500.caffemodel
I1030 12:52:19.247158  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_31500.solverstate
I1030 12:52:19.264075  1046 solver.cpp:334] Iteration 31500, Testing net (#0)
I1030 12:52:49.992743  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 12:52:50.199453  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58668
I1030 12:52:50.199512  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813359
I1030 12:52:50.199525  1046 solver.cpp:401]     Test net output #2: loss = 1.83823 (* 1 = 1.83823 loss)
I1030 12:53:06.396775  1046 solver.cpp:222] Iteration 31520 (0.646716 iter/s, 61.8509s/40 iters), loss = 1.24903
I1030 12:53:06.396843  1046 solver.cpp:241]     Train net output #0: loss = 1.24903 (* 1 = 1.24903 loss)
I1030 12:53:06.396859  1046 sgd_solver.cpp:105] Iteration 31520, lr = 0.000200803
I1030 12:53:47.575516  1046 solver.cpp:222] Iteration 31560 (0.971414 iter/s, 41.1771s/40 iters), loss = 1.63665
I1030 12:53:47.575742  1046 solver.cpp:241]     Train net output #0: loss = 1.63665 (* 1 = 1.63665 loss)
I1030 12:53:47.575764  1046 sgd_solver.cpp:105] Iteration 31560, lr = 0.000199809
I1030 12:54:23.101981  1046 solver.cpp:222] Iteration 31600 (1.12597 iter/s, 35.5249s/40 iters), loss = 1.28527
I1030 12:54:23.102226  1046 solver.cpp:241]     Train net output #0: loss = 1.28527 (* 1 = 1.28527 loss)
I1030 12:54:23.102249  1046 sgd_solver.cpp:105] Iteration 31600, lr = 0.000198821
I1030 12:54:56.593894  1046 solver.cpp:222] Iteration 31640 (1.19437 iter/s, 33.4904s/40 iters), loss = 1.11007
I1030 12:54:56.594105  1046 solver.cpp:241]     Train net output #0: loss = 1.11007 (* 1 = 1.11007 loss)
I1030 12:54:56.594122  1046 sgd_solver.cpp:105] Iteration 31640, lr = 0.000197837
I1030 12:55:26.910306  1046 solver.cpp:222] Iteration 31680 (1.31948 iter/s, 30.3151s/40 iters), loss = 1.4866
I1030 12:55:26.910540  1046 solver.cpp:241]     Train net output #0: loss = 1.4866 (* 1 = 1.4866 loss)
I1030 12:55:26.910557  1046 sgd_solver.cpp:105] Iteration 31680, lr = 0.000196858
I1030 12:55:57.772831  1046 solver.cpp:222] Iteration 31720 (1.29613 iter/s, 30.8611s/40 iters), loss = 1.22882
I1030 12:55:57.773021  1046 solver.cpp:241]     Train net output #0: loss = 1.22882 (* 1 = 1.22882 loss)
I1030 12:55:57.773038  1046 sgd_solver.cpp:105] Iteration 31720, lr = 0.000195884
I1030 12:56:28.792403  1046 solver.cpp:222] Iteration 31760 (1.28956 iter/s, 31.0182s/40 iters), loss = 1.40651
I1030 12:56:28.792579  1046 solver.cpp:241]     Train net output #0: loss = 1.40651 (* 1 = 1.40651 loss)
I1030 12:56:28.792598  1046 sgd_solver.cpp:105] Iteration 31760, lr = 0.000194915
I1030 12:56:59.245838  1046 solver.cpp:222] Iteration 31800 (1.31354 iter/s, 30.4521s/40 iters), loss = 1.32968
I1030 12:56:59.246069  1046 solver.cpp:241]     Train net output #0: loss = 1.32968 (* 1 = 1.32968 loss)
I1030 12:56:59.246111  1046 sgd_solver.cpp:105] Iteration 31800, lr = 0.000193951
I1030 12:57:29.596822  1046 solver.cpp:222] Iteration 31840 (1.31797 iter/s, 30.3496s/40 iters), loss = 1.23376
I1030 12:57:29.596993  1046 solver.cpp:241]     Train net output #0: loss = 1.23376 (* 1 = 1.23376 loss)
I1030 12:57:29.597010  1046 sgd_solver.cpp:105] Iteration 31840, lr = 0.000192992
I1030 12:57:59.911051  1046 solver.cpp:222] Iteration 31880 (1.31957 iter/s, 30.3129s/40 iters), loss = 1.45286
I1030 12:57:59.911202  1046 solver.cpp:241]     Train net output #0: loss = 1.45286 (* 1 = 1.45286 loss)
I1030 12:57:59.911217  1046 sgd_solver.cpp:105] Iteration 31880, lr = 0.000192037
I1030 12:58:30.269810  1046 solver.cpp:222] Iteration 31920 (1.31763 iter/s, 30.3575s/40 iters), loss = 1.3233
I1030 12:58:30.269999  1046 solver.cpp:241]     Train net output #0: loss = 1.3233 (* 1 = 1.3233 loss)
I1030 12:58:30.270016  1046 sgd_solver.cpp:105] Iteration 31920, lr = 0.000191087
I1030 12:59:01.018939  1046 solver.cpp:222] Iteration 31960 (1.30091 iter/s, 30.7478s/40 iters), loss = 1.38356
I1030 12:59:01.019127  1046 solver.cpp:241]     Train net output #0: loss = 1.38356 (* 1 = 1.38356 loss)
I1030 12:59:01.019145  1046 sgd_solver.cpp:105] Iteration 31960, lr = 0.000190142
I1030 12:59:30.855072  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_32000.caffemodel
I1030 12:59:30.887310  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_32000.solverstate
I1030 12:59:30.906172  1046 solver.cpp:334] Iteration 32000, Testing net (#0)
I1030 13:00:01.811413  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58808
I1030 13:00:01.811584  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80972
I1030 13:00:01.811600  1046 solver.cpp:401]     Test net output #2: loss = 1.83268 (* 1 = 1.83268 loss)
I1030 13:00:02.575307  1046 solver.cpp:222] Iteration 32000 (0.649837 iter/s, 61.5539s/40 iters), loss = 1.37596
I1030 13:00:02.575362  1046 solver.cpp:241]     Train net output #0: loss = 1.37596 (* 1 = 1.37596 loss)
I1030 13:00:02.575378  1046 sgd_solver.cpp:105] Iteration 32000, lr = 0.000189201
I1030 13:00:33.507668  1046 solver.cpp:222] Iteration 32040 (1.2932 iter/s, 30.9311s/40 iters), loss = 1.60955
I1030 13:00:33.507875  1046 solver.cpp:241]     Train net output #0: loss = 1.60955 (* 1 = 1.60955 loss)
I1030 13:00:33.507892  1046 sgd_solver.cpp:105] Iteration 32040, lr = 0.000188265
I1030 13:01:04.107179  1046 solver.cpp:222] Iteration 32080 (1.30727 iter/s, 30.5982s/40 iters), loss = 1.27459
I1030 13:01:04.107378  1046 solver.cpp:241]     Train net output #0: loss = 1.27459 (* 1 = 1.27459 loss)
I1030 13:01:04.107395  1046 sgd_solver.cpp:105] Iteration 32080, lr = 0.000187333
I1030 13:01:34.871276  1046 solver.cpp:222] Iteration 32120 (1.30027 iter/s, 30.7627s/40 iters), loss = 1.5648
I1030 13:01:34.871465  1046 solver.cpp:241]     Train net output #0: loss = 1.5648 (* 1 = 1.5648 loss)
I1030 13:01:34.871482  1046 sgd_solver.cpp:105] Iteration 32120, lr = 0.000186407
I1030 13:02:05.569569  1046 solver.cpp:222] Iteration 32160 (1.30306 iter/s, 30.697s/40 iters), loss = 1.27176
I1030 13:02:05.569756  1046 solver.cpp:241]     Train net output #0: loss = 1.27176 (* 1 = 1.27176 loss)
I1030 13:02:05.569775  1046 sgd_solver.cpp:105] Iteration 32160, lr = 0.000185485
I1030 13:02:36.507809  1046 solver.cpp:222] Iteration 32200 (1.29295 iter/s, 30.9369s/40 iters), loss = 1.31749
I1030 13:02:36.508015  1046 solver.cpp:241]     Train net output #0: loss = 1.31749 (* 1 = 1.31749 loss)
I1030 13:02:36.508033  1046 sgd_solver.cpp:105] Iteration 32200, lr = 0.000184567
I1030 13:03:07.147351  1046 solver.cpp:222] Iteration 32240 (1.30556 iter/s, 30.6382s/40 iters), loss = 1.30094
I1030 13:03:07.147531  1046 solver.cpp:241]     Train net output #0: loss = 1.30094 (* 1 = 1.30094 loss)
I1030 13:03:07.147548  1046 sgd_solver.cpp:105] Iteration 32240, lr = 0.000183654
I1030 13:03:38.379287  1046 solver.cpp:222] Iteration 32280 (1.2808 iter/s, 31.2306s/40 iters), loss = 1.72797
I1030 13:03:38.379597  1046 solver.cpp:241]     Train net output #0: loss = 1.72797 (* 1 = 1.72797 loss)
I1030 13:03:38.379636  1046 sgd_solver.cpp:105] Iteration 32280, lr = 0.000182745
I1030 13:04:09.433990  1046 solver.cpp:222] Iteration 32320 (1.28811 iter/s, 31.0532s/40 iters), loss = 1.46626
I1030 13:04:09.434208  1046 solver.cpp:241]     Train net output #0: loss = 1.46626 (* 1 = 1.46626 loss)
I1030 13:04:09.434224  1046 sgd_solver.cpp:105] Iteration 32320, lr = 0.000181841
I1030 13:04:40.355237  1046 solver.cpp:222] Iteration 32360 (1.29367 iter/s, 30.9199s/40 iters), loss = 1.60254
I1030 13:04:40.355443  1046 solver.cpp:241]     Train net output #0: loss = 1.60254 (* 1 = 1.60254 loss)
I1030 13:04:40.355459  1046 sgd_solver.cpp:105] Iteration 32360, lr = 0.000180942
I1030 13:05:10.823642  1046 solver.cpp:222] Iteration 32400 (1.31289 iter/s, 30.4671s/40 iters), loss = 1.30657
I1030 13:05:10.823813  1046 solver.cpp:241]     Train net output #0: loss = 1.30657 (* 1 = 1.30657 loss)
I1030 13:05:10.823829  1046 sgd_solver.cpp:105] Iteration 32400, lr = 0.000180046
I1030 13:05:41.406582  1046 solver.cpp:222] Iteration 32440 (1.30798 iter/s, 30.5816s/40 iters), loss = 1.52549
I1030 13:05:41.406780  1046 solver.cpp:241]     Train net output #0: loss = 1.52549 (* 1 = 1.52549 loss)
I1030 13:05:41.406797  1046 sgd_solver.cpp:105] Iteration 32440, lr = 0.000179156
I1030 13:06:12.027683  1046 solver.cpp:222] Iteration 32480 (1.30635 iter/s, 30.6197s/40 iters), loss = 1.31381
I1030 13:06:12.027851  1046 solver.cpp:241]     Train net output #0: loss = 1.31381 (* 1 = 1.31381 loss)
I1030 13:06:12.027868  1046 sgd_solver.cpp:105] Iteration 32480, lr = 0.000178269
I1030 13:06:26.459040  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_32500.caffemodel
I1030 13:06:26.497392  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_32500.solverstate
I1030 13:06:26.539192  1046 solver.cpp:334] Iteration 32500, Testing net (#0)
I1030 13:06:57.298403  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 13:06:57.503897  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58712
I1030 13:06:57.503958  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81324
I1030 13:06:57.503971  1046 solver.cpp:401]     Test net output #2: loss = 1.83658 (* 1 = 1.83658 loss)
I1030 13:07:13.827901  1046 solver.cpp:222] Iteration 32520 (0.647273 iter/s, 61.7977s/40 iters), loss = 1.29971
I1030 13:07:13.827991  1046 solver.cpp:241]     Train net output #0: loss = 1.29971 (* 1 = 1.29971 loss)
I1030 13:07:13.828009  1046 sgd_solver.cpp:105] Iteration 32520, lr = 0.000177388
I1030 13:07:18.189327  1096 data_layer.cpp:73] Restarting data prefetching from start.
I1030 13:07:45.276060  1046 solver.cpp:222] Iteration 32560 (1.27199 iter/s, 31.4469s/40 iters), loss = 1.32508
I1030 13:07:45.276278  1046 solver.cpp:241]     Train net output #0: loss = 1.32508 (* 1 = 1.32508 loss)
I1030 13:07:45.276294  1046 sgd_solver.cpp:105] Iteration 32560, lr = 0.00017651
I1030 13:08:16.483953  1046 solver.cpp:222] Iteration 32600 (1.28178 iter/s, 31.2065s/40 iters), loss = 1.38313
I1030 13:08:16.484171  1046 solver.cpp:241]     Train net output #0: loss = 1.38313 (* 1 = 1.38313 loss)
I1030 13:08:16.484189  1046 sgd_solver.cpp:105] Iteration 32600, lr = 0.000175637
I1030 13:08:47.214730  1046 solver.cpp:222] Iteration 32640 (1.30169 iter/s, 30.7294s/40 iters), loss = 1.2987
I1030 13:08:47.214968  1046 solver.cpp:241]     Train net output #0: loss = 1.2987 (* 1 = 1.2987 loss)
I1030 13:08:47.214998  1046 sgd_solver.cpp:105] Iteration 32640, lr = 0.000174768
I1030 13:09:18.793028  1046 solver.cpp:222] Iteration 32680 (1.26675 iter/s, 31.5769s/40 iters), loss = 1.25922
I1030 13:09:18.793257  1046 solver.cpp:241]     Train net output #0: loss = 1.25922 (* 1 = 1.25922 loss)
I1030 13:09:18.793277  1046 sgd_solver.cpp:105] Iteration 32680, lr = 0.000173903
I1030 13:09:50.038252  1046 solver.cpp:222] Iteration 32720 (1.28025 iter/s, 31.2438s/40 iters), loss = 1.29958
I1030 13:09:50.038519  1046 solver.cpp:241]     Train net output #0: loss = 1.29958 (* 1 = 1.29958 loss)
I1030 13:09:50.038545  1046 sgd_solver.cpp:105] Iteration 32720, lr = 0.000173043
I1030 13:10:21.568042  1046 solver.cpp:222] Iteration 32760 (1.2687 iter/s, 31.5283s/40 iters), loss = 1.54721
I1030 13:10:21.568246  1046 solver.cpp:241]     Train net output #0: loss = 1.54721 (* 1 = 1.54721 loss)
I1030 13:10:21.568264  1046 sgd_solver.cpp:105] Iteration 32760, lr = 0.000172187
I1030 13:10:53.343371  1046 solver.cpp:222] Iteration 32800 (1.25889 iter/s, 31.7739s/40 iters), loss = 0.867148
I1030 13:10:53.343574  1046 solver.cpp:241]     Train net output #0: loss = 0.867148 (* 1 = 0.867148 loss)
I1030 13:10:53.343592  1046 sgd_solver.cpp:105] Iteration 32800, lr = 0.000171335
I1030 13:11:24.585814  1046 solver.cpp:222] Iteration 32840 (1.28037 iter/s, 31.2411s/40 iters), loss = 1.68459
I1030 13:11:24.586004  1046 solver.cpp:241]     Train net output #0: loss = 1.68459 (* 1 = 1.68459 loss)
I1030 13:11:24.586020  1046 sgd_solver.cpp:105] Iteration 32840, lr = 0.000170487
I1030 13:11:56.131356  1046 solver.cpp:222] Iteration 32880 (1.26806 iter/s, 31.5442s/40 iters), loss = 1.4666
I1030 13:11:56.131546  1046 solver.cpp:241]     Train net output #0: loss = 1.4666 (* 1 = 1.4666 loss)
I1030 13:11:56.131564  1046 sgd_solver.cpp:105] Iteration 32880, lr = 0.000169644
I1030 13:12:27.024175  1046 solver.cpp:222] Iteration 32920 (1.29486 iter/s, 30.8915s/40 iters), loss = 1.42287
I1030 13:12:27.024375  1046 solver.cpp:241]     Train net output #0: loss = 1.42287 (* 1 = 1.42287 loss)
I1030 13:12:27.024394  1046 sgd_solver.cpp:105] Iteration 32920, lr = 0.000168805
I1030 13:12:57.768679  1046 solver.cpp:222] Iteration 32960 (1.3011 iter/s, 30.7431s/40 iters), loss = 1.65365
I1030 13:12:57.768873  1046 solver.cpp:241]     Train net output #0: loss = 1.65365 (* 1 = 1.65365 loss)
I1030 13:12:57.768893  1046 sgd_solver.cpp:105] Iteration 32960, lr = 0.00016797
I1030 13:13:28.127161  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_33000.caffemodel
I1030 13:13:28.158850  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_33000.solverstate
I1030 13:13:28.176115  1046 solver.cpp:334] Iteration 33000, Testing net (#0)
I1030 13:13:59.094413  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58768
I1030 13:13:59.094605  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.810399
I1030 13:13:59.094620  1046 solver.cpp:401]     Test net output #2: loss = 1.83457 (* 1 = 1.83457 loss)
I1030 13:13:59.867242  1046 solver.cpp:222] Iteration 33000 (0.644163 iter/s, 62.096s/40 iters), loss = 1.32344
I1030 13:13:59.867303  1046 solver.cpp:241]     Train net output #0: loss = 1.32344 (* 1 = 1.32344 loss)
I1030 13:13:59.867321  1046 sgd_solver.cpp:105] Iteration 33000, lr = 0.000167139
I1030 13:14:31.114047  1046 solver.cpp:222] Iteration 33040 (1.28018 iter/s, 31.2456s/40 iters), loss = 1.27671
I1030 13:14:31.114271  1046 solver.cpp:241]     Train net output #0: loss = 1.27671 (* 1 = 1.27671 loss)
I1030 13:14:31.114287  1046 sgd_solver.cpp:105] Iteration 33040, lr = 0.000166312
I1030 13:15:01.834866  1046 solver.cpp:222] Iteration 33080 (1.30211 iter/s, 30.7194s/40 iters), loss = 1.53123
I1030 13:15:01.835063  1046 solver.cpp:241]     Train net output #0: loss = 1.53123 (* 1 = 1.53123 loss)
I1030 13:15:01.835080  1046 sgd_solver.cpp:105] Iteration 33080, lr = 0.000165489
I1030 13:15:33.014652  1046 solver.cpp:222] Iteration 33120 (1.28294 iter/s, 31.1784s/40 iters), loss = 1.51234
I1030 13:15:33.014847  1046 solver.cpp:241]     Train net output #0: loss = 1.51234 (* 1 = 1.51234 loss)
I1030 13:15:33.014865  1046 sgd_solver.cpp:105] Iteration 33120, lr = 0.00016467
I1030 13:16:03.424314  1046 solver.cpp:222] Iteration 33160 (1.31543 iter/s, 30.4083s/40 iters), loss = 1.35716
I1030 13:16:03.424630  1046 solver.cpp:241]     Train net output #0: loss = 1.35716 (* 1 = 1.35716 loss)
I1030 13:16:03.424685  1046 sgd_solver.cpp:105] Iteration 33160, lr = 0.000163856
I1030 13:16:34.131279  1046 solver.cpp:222] Iteration 33200 (1.3027 iter/s, 30.7055s/40 iters), loss = 1.62747
I1030 13:16:34.131482  1046 solver.cpp:241]     Train net output #0: loss = 1.62747 (* 1 = 1.62747 loss)
I1030 13:16:34.131500  1046 sgd_solver.cpp:105] Iteration 33200, lr = 0.000163045
I1030 13:17:04.888917  1046 solver.cpp:222] Iteration 33240 (1.30055 iter/s, 30.7563s/40 iters), loss = 1.76471
I1030 13:17:04.889119  1046 solver.cpp:241]     Train net output #0: loss = 1.76471 (* 1 = 1.76471 loss)
I1030 13:17:04.889137  1046 sgd_solver.cpp:105] Iteration 33240, lr = 0.000162238
I1030 13:17:36.080554  1046 solver.cpp:222] Iteration 33280 (1.28245 iter/s, 31.1903s/40 iters), loss = 1.56606
I1030 13:17:36.080739  1046 solver.cpp:241]     Train net output #0: loss = 1.56606 (* 1 = 1.56606 loss)
I1030 13:17:36.080757  1046 sgd_solver.cpp:105] Iteration 33280, lr = 0.000161436
I1030 13:18:07.200601  1046 solver.cpp:222] Iteration 33320 (1.2854 iter/s, 31.1187s/40 iters), loss = 1.39525
I1030 13:18:07.200783  1046 solver.cpp:241]     Train net output #0: loss = 1.39525 (* 1 = 1.39525 loss)
I1030 13:18:07.200799  1046 sgd_solver.cpp:105] Iteration 33320, lr = 0.000160637
I1030 13:18:38.187611  1046 solver.cpp:222] Iteration 33360 (1.29092 iter/s, 30.9857s/40 iters), loss = 1.2091
I1030 13:18:38.187826  1046 solver.cpp:241]     Train net output #0: loss = 1.2091 (* 1 = 1.2091 loss)
I1030 13:18:38.187849  1046 sgd_solver.cpp:105] Iteration 33360, lr = 0.000159843
I1030 13:19:09.375597  1046 solver.cpp:222] Iteration 33400 (1.2826 iter/s, 31.1866s/40 iters), loss = 1.41031
I1030 13:19:09.375818  1046 solver.cpp:241]     Train net output #0: loss = 1.41031 (* 1 = 1.41031 loss)
I1030 13:19:09.375835  1046 sgd_solver.cpp:105] Iteration 33400, lr = 0.000159052
I1030 13:19:40.815771  1046 solver.cpp:222] Iteration 33440 (1.27231 iter/s, 31.4388s/40 iters), loss = 1.1918
I1030 13:19:40.815978  1046 solver.cpp:241]     Train net output #0: loss = 1.1918 (* 1 = 1.1918 loss)
I1030 13:19:40.815995  1046 sgd_solver.cpp:105] Iteration 33440, lr = 0.000158265
I1030 13:20:11.961263  1046 solver.cpp:222] Iteration 33480 (1.28435 iter/s, 31.1441s/40 iters), loss = 1.56851
I1030 13:20:11.961493  1046 solver.cpp:241]     Train net output #0: loss = 1.56851 (* 1 = 1.56851 loss)
I1030 13:20:11.961513  1046 sgd_solver.cpp:105] Iteration 33480, lr = 0.000157482
I1030 13:20:26.514762  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_33500.caffemodel
I1030 13:20:26.549381  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_33500.solverstate
I1030 13:20:26.568102  1046 solver.cpp:334] Iteration 33500, Testing net (#0)
I1030 13:20:57.288542  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 13:20:57.495507  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58644
I1030 13:20:57.495568  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.814079
I1030 13:20:57.495580  1046 solver.cpp:401]     Test net output #2: loss = 1.83806 (* 1 = 1.83806 loss)
I1030 13:21:13.593256  1046 solver.cpp:222] Iteration 33520 (0.64904 iter/s, 61.6295s/40 iters), loss = 1.24796
I1030 13:21:13.593328  1046 solver.cpp:241]     Train net output #0: loss = 1.24796 (* 1 = 1.24796 loss)
I1030 13:21:13.593346  1046 sgd_solver.cpp:105] Iteration 33520, lr = 0.000156703
I1030 13:21:44.554877  1046 solver.cpp:222] Iteration 33560 (1.29197 iter/s, 30.9604s/40 iters), loss = 1.68967
I1030 13:21:44.555109  1046 solver.cpp:241]     Train net output #0: loss = 1.68967 (* 1 = 1.68967 loss)
I1030 13:21:44.555135  1046 sgd_solver.cpp:105] Iteration 33560, lr = 0.000155928
I1030 13:22:15.599876  1046 solver.cpp:222] Iteration 33600 (1.28851 iter/s, 31.0436s/40 iters), loss = 1.76342
I1030 13:22:15.600113  1046 solver.cpp:241]     Train net output #0: loss = 1.76342 (* 1 = 1.76342 loss)
I1030 13:22:15.600143  1046 sgd_solver.cpp:105] Iteration 33600, lr = 0.000155156
I1030 13:22:46.717914  1046 solver.cpp:222] Iteration 33640 (1.28549 iter/s, 31.1166s/40 iters), loss = 1.33857
I1030 13:22:46.718133  1046 solver.cpp:241]     Train net output #0: loss = 1.33857 (* 1 = 1.33857 loss)
I1030 13:22:46.718150  1046 sgd_solver.cpp:105] Iteration 33640, lr = 0.000154389
I1030 13:23:18.818971  1046 solver.cpp:222] Iteration 33680 (1.24612 iter/s, 32.0996s/40 iters), loss = 1.49361
I1030 13:23:18.819203  1046 solver.cpp:241]     Train net output #0: loss = 1.49361 (* 1 = 1.49361 loss)
I1030 13:23:18.819231  1046 sgd_solver.cpp:105] Iteration 33680, lr = 0.000153625
I1030 13:23:49.701750  1046 solver.cpp:222] Iteration 33720 (1.29528 iter/s, 30.8814s/40 iters), loss = 1.46122
I1030 13:23:49.701938  1046 solver.cpp:241]     Train net output #0: loss = 1.46122 (* 1 = 1.46122 loss)
I1030 13:23:49.701956  1046 sgd_solver.cpp:105] Iteration 33720, lr = 0.000152865
I1030 13:24:20.524868  1046 solver.cpp:222] Iteration 33760 (1.29778 iter/s, 30.8218s/40 iters), loss = 1.16351
I1030 13:24:20.525058  1046 solver.cpp:241]     Train net output #0: loss = 1.16351 (* 1 = 1.16351 loss)
I1030 13:24:20.525075  1046 sgd_solver.cpp:105] Iteration 33760, lr = 0.000152109
I1030 13:24:51.176843  1046 solver.cpp:222] Iteration 33800 (1.30503 iter/s, 30.6506s/40 iters), loss = 1.5537
I1030 13:24:51.177057  1046 solver.cpp:241]     Train net output #0: loss = 1.5537 (* 1 = 1.5537 loss)
I1030 13:24:51.177074  1046 sgd_solver.cpp:105] Iteration 33800, lr = 0.000151356
I1030 13:25:22.173481  1046 solver.cpp:222] Iteration 33840 (1.29052 iter/s, 30.9952s/40 iters), loss = 1.56633
I1030 13:25:22.173744  1046 solver.cpp:241]     Train net output #0: loss = 1.56633 (* 1 = 1.56633 loss)
I1030 13:25:22.173774  1046 sgd_solver.cpp:105] Iteration 33840, lr = 0.000150607
I1030 13:25:53.272277  1046 solver.cpp:222] Iteration 33880 (1.28628 iter/s, 31.0974s/40 iters), loss = 1.53964
I1030 13:25:53.272490  1046 solver.cpp:241]     Train net output #0: loss = 1.53964 (* 1 = 1.53964 loss)
I1030 13:25:53.272507  1046 sgd_solver.cpp:105] Iteration 33880, lr = 0.000149862
I1030 13:26:24.537418  1046 solver.cpp:222] Iteration 33920 (1.27944 iter/s, 31.2638s/40 iters), loss = 1.60524
I1030 13:26:24.537595  1046 solver.cpp:241]     Train net output #0: loss = 1.60524 (* 1 = 1.60524 loss)
I1030 13:26:24.537611  1046 sgd_solver.cpp:105] Iteration 33920, lr = 0.000149121
I1030 13:27:01.112867  1046 solver.cpp:222] Iteration 33960 (1.09368 iter/s, 36.5739s/40 iters), loss = 1.74278
I1030 13:27:01.113119  1046 solver.cpp:241]     Train net output #0: loss = 1.74278 (* 1 = 1.74278 loss)
I1030 13:27:01.113147  1046 sgd_solver.cpp:105] Iteration 33960, lr = 0.000148383
I1030 13:27:31.182555  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_34000.caffemodel
I1030 13:27:31.215772  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_34000.solverstate
I1030 13:27:31.233878  1046 solver.cpp:334] Iteration 34000, Testing net (#0)
I1030 13:28:02.166492  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58828
I1030 13:28:02.166688  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.810039
I1030 13:28:02.166703  1046 solver.cpp:401]     Test net output #2: loss = 1.8332 (* 1 = 1.8332 loss)
I1030 13:28:02.933455  1046 solver.cpp:222] Iteration 34000 (0.64706 iter/s, 61.818s/40 iters), loss = 1.44394
I1030 13:28:02.933517  1046 solver.cpp:241]     Train net output #0: loss = 1.44394 (* 1 = 1.44394 loss)
I1030 13:28:02.933532  1046 sgd_solver.cpp:105] Iteration 34000, lr = 0.000147649
I1030 13:28:33.449249  1046 solver.cpp:222] Iteration 34040 (1.31085 iter/s, 30.5146s/40 iters), loss = 1.43456
I1030 13:28:33.449435  1046 solver.cpp:241]     Train net output #0: loss = 1.43456 (* 1 = 1.43456 loss)
I1030 13:28:33.449452  1046 sgd_solver.cpp:105] Iteration 34040, lr = 0.000146919
I1030 13:29:04.005554  1046 solver.cpp:222] Iteration 34080 (1.30912 iter/s, 30.5549s/40 iters), loss = 1.35697
I1030 13:29:04.005805  1046 solver.cpp:241]     Train net output #0: loss = 1.35697 (* 1 = 1.35697 loss)
I1030 13:29:04.005826  1046 sgd_solver.cpp:105] Iteration 34080, lr = 0.000146192
I1030 13:29:34.448678  1046 solver.cpp:222] Iteration 34120 (1.31399 iter/s, 30.4417s/40 iters), loss = 1.40656
I1030 13:29:34.448866  1046 solver.cpp:241]     Train net output #0: loss = 1.40656 (* 1 = 1.40656 loss)
I1030 13:29:34.448884  1046 sgd_solver.cpp:105] Iteration 34120, lr = 0.000145469
I1030 13:30:04.783464  1046 solver.cpp:222] Iteration 34160 (1.31868 iter/s, 30.3335s/40 iters), loss = 1.61227
I1030 13:30:04.783659  1046 solver.cpp:241]     Train net output #0: loss = 1.61227 (* 1 = 1.61227 loss)
I1030 13:30:04.783677  1046 sgd_solver.cpp:105] Iteration 34160, lr = 0.000144749
I1030 13:30:35.220868  1046 solver.cpp:222] Iteration 34200 (1.31423 iter/s, 30.436s/40 iters), loss = 1.36576
I1030 13:30:35.221040  1046 solver.cpp:241]     Train net output #0: loss = 1.36576 (* 1 = 1.36576 loss)
I1030 13:30:35.221056  1046 sgd_solver.cpp:105] Iteration 34200, lr = 0.000144033
I1030 13:31:05.947544  1046 solver.cpp:222] Iteration 34240 (1.30186 iter/s, 30.7253s/40 iters), loss = 1.62659
I1030 13:31:05.947724  1046 solver.cpp:241]     Train net output #0: loss = 1.62659 (* 1 = 1.62659 loss)
I1030 13:31:05.947741  1046 sgd_solver.cpp:105] Iteration 34240, lr = 0.00014332
I1030 13:31:36.307160  1046 solver.cpp:222] Iteration 34280 (1.3176 iter/s, 30.3583s/40 iters), loss = 1.47734
I1030 13:31:36.307341  1046 solver.cpp:241]     Train net output #0: loss = 1.47734 (* 1 = 1.47734 loss)
I1030 13:31:36.307359  1046 sgd_solver.cpp:105] Iteration 34280, lr = 0.000142611
I1030 13:32:06.965606  1046 solver.cpp:222] Iteration 34320 (1.30475 iter/s, 30.6571s/40 iters), loss = 1.59525
I1030 13:32:06.965802  1046 solver.cpp:241]     Train net output #0: loss = 1.59525 (* 1 = 1.59525 loss)
I1030 13:32:06.965822  1046 sgd_solver.cpp:105] Iteration 34320, lr = 0.000141906
I1030 13:32:37.612561  1046 solver.cpp:222] Iteration 34360 (1.30524 iter/s, 30.6456s/40 iters), loss = 1.18023
I1030 13:32:37.612716  1046 solver.cpp:241]     Train net output #0: loss = 1.18023 (* 1 = 1.18023 loss)
I1030 13:32:37.612733  1046 sgd_solver.cpp:105] Iteration 34360, lr = 0.000141204
I1030 13:33:08.016180  1046 solver.cpp:222] Iteration 34400 (1.31569 iter/s, 30.4023s/40 iters), loss = 1.64106
I1030 13:33:08.016394  1046 solver.cpp:241]     Train net output #0: loss = 1.64106 (* 1 = 1.64106 loss)
I1030 13:33:08.016413  1046 sgd_solver.cpp:105] Iteration 34400, lr = 0.000140505
I1030 13:33:38.779016  1046 solver.cpp:222] Iteration 34440 (1.30033 iter/s, 30.7615s/40 iters), loss = 1.38742
I1030 13:33:38.779232  1046 solver.cpp:241]     Train net output #0: loss = 1.38742 (* 1 = 1.38742 loss)
I1030 13:33:38.779251  1046 sgd_solver.cpp:105] Iteration 34440, lr = 0.00013981
I1030 13:34:09.295531  1046 solver.cpp:222] Iteration 34480 (1.31082 iter/s, 30.5152s/40 iters), loss = 1.32001
I1030 13:34:09.295696  1046 solver.cpp:241]     Train net output #0: loss = 1.32001 (* 1 = 1.32001 loss)
I1030 13:34:09.295722  1046 sgd_solver.cpp:105] Iteration 34480, lr = 0.000139118
I1030 13:34:23.870651  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_34500.caffemodel
I1030 13:34:23.902287  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_34500.solverstate
I1030 13:34:23.919425  1046 solver.cpp:334] Iteration 34500, Testing net (#0)
I1030 13:34:54.731542  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 13:34:54.937088  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58656
I1030 13:34:54.937146  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813519
I1030 13:34:54.937160  1046 solver.cpp:401]     Test net output #2: loss = 1.83703 (* 1 = 1.83703 loss)
I1030 13:35:10.963496  1046 solver.cpp:222] Iteration 34520 (0.648661 iter/s, 61.6655s/40 iters), loss = 1.38302
I1030 13:35:10.963577  1046 solver.cpp:241]     Train net output #0: loss = 1.38302 (* 1 = 1.38302 loss)
I1030 13:35:10.963594  1046 sgd_solver.cpp:105] Iteration 34520, lr = 0.00013843
I1030 13:35:42.030719  1046 solver.cpp:222] Iteration 34560 (1.28758 iter/s, 31.066s/40 iters), loss = 1.43052
I1030 13:35:42.031100  1046 solver.cpp:241]     Train net output #0: loss = 1.43052 (* 1 = 1.43052 loss)
I1030 13:35:42.031157  1046 sgd_solver.cpp:105] Iteration 34560, lr = 0.000137745
I1030 13:36:12.963318  1046 solver.cpp:222] Iteration 34600 (1.2932 iter/s, 30.9311s/40 iters), loss = 1.36602
I1030 13:36:12.963482  1046 solver.cpp:241]     Train net output #0: loss = 1.36602 (* 1 = 1.36602 loss)
I1030 13:36:12.963500  1046 sgd_solver.cpp:105] Iteration 34600, lr = 0.000137064
I1030 13:36:43.723891  1046 solver.cpp:222] Iteration 34640 (1.30042 iter/s, 30.7593s/40 iters), loss = 1.34631
I1030 13:36:43.724066  1046 solver.cpp:241]     Train net output #0: loss = 1.34631 (* 1 = 1.34631 loss)
I1030 13:36:43.724090  1046 sgd_solver.cpp:105] Iteration 34640, lr = 0.000136386
I1030 13:37:14.215364  1046 solver.cpp:222] Iteration 34680 (1.3119 iter/s, 30.4902s/40 iters), loss = 1.54635
I1030 13:37:14.215538  1046 solver.cpp:241]     Train net output #0: loss = 1.54635 (* 1 = 1.54635 loss)
I1030 13:37:14.215557  1046 sgd_solver.cpp:105] Iteration 34680, lr = 0.000135711
I1030 13:37:44.951210  1046 solver.cpp:222] Iteration 34720 (1.30147 iter/s, 30.7345s/40 iters), loss = 1.54012
I1030 13:37:44.951390  1046 solver.cpp:241]     Train net output #0: loss = 1.54012 (* 1 = 1.54012 loss)
I1030 13:37:44.951408  1046 sgd_solver.cpp:105] Iteration 34720, lr = 0.00013504
I1030 13:38:50.706714  1046 solver.cpp:222] Iteration 34760 (0.608339 iter/s, 65.7529s/40 iters), loss = 1.31793
I1030 13:38:50.706961  1046 solver.cpp:241]     Train net output #0: loss = 1.31793 (* 1 = 1.31793 loss)
I1030 13:38:50.706990  1046 sgd_solver.cpp:105] Iteration 34760, lr = 0.000134372
I1030 13:39:21.339331  1046 solver.cpp:222] Iteration 34800 (1.30586 iter/s, 30.6312s/40 iters), loss = 1.15103
I1030 13:39:21.339538  1046 solver.cpp:241]     Train net output #0: loss = 1.15103 (* 1 = 1.15103 loss)
I1030 13:39:21.339555  1046 sgd_solver.cpp:105] Iteration 34800, lr = 0.000133707
I1030 13:39:52.155503  1046 solver.cpp:222] Iteration 34840 (1.29808 iter/s, 30.8148s/40 iters), loss = 1.59371
I1030 13:39:52.155711  1046 solver.cpp:241]     Train net output #0: loss = 1.59371 (* 1 = 1.59371 loss)
I1030 13:39:52.155730  1046 sgd_solver.cpp:105] Iteration 34840, lr = 0.000133045
I1030 13:40:22.683542  1046 solver.cpp:222] Iteration 34880 (1.31033 iter/s, 30.5267s/40 iters), loss = 1.23783
I1030 13:40:22.683754  1046 solver.cpp:241]     Train net output #0: loss = 1.23783 (* 1 = 1.23783 loss)
I1030 13:40:22.683771  1046 sgd_solver.cpp:105] Iteration 34880, lr = 0.000132387
I1030 13:40:53.263608  1046 solver.cpp:222] Iteration 34920 (1.3081 iter/s, 30.5787s/40 iters), loss = 1.23813
I1030 13:40:53.263808  1046 solver.cpp:241]     Train net output #0: loss = 1.23813 (* 1 = 1.23813 loss)
I1030 13:40:53.263824  1046 sgd_solver.cpp:105] Iteration 34920, lr = 0.000131732
I1030 13:41:24.361268  1046 solver.cpp:222] Iteration 34960 (1.28633 iter/s, 31.0963s/40 iters), loss = 1.3865
I1030 13:41:24.361476  1046 solver.cpp:241]     Train net output #0: loss = 1.3865 (* 1 = 1.3865 loss)
I1030 13:41:24.361495  1046 sgd_solver.cpp:105] Iteration 34960, lr = 0.000131081
I1030 13:41:54.652024  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_35000.caffemodel
I1030 13:41:54.699594  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_35000.solverstate
I1030 13:41:54.725364  1046 solver.cpp:334] Iteration 35000, Testing net (#0)
I1030 13:42:25.787916  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5882
I1030 13:42:25.788108  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80916
I1030 13:42:25.788125  1046 solver.cpp:401]     Test net output #2: loss = 1.83361 (* 1 = 1.83361 loss)
I1030 13:42:26.559221  1046 solver.cpp:222] Iteration 35000 (0.643134 iter/s, 62.1954s/40 iters), loss = 1.3332
I1030 13:42:26.559283  1046 solver.cpp:241]     Train net output #0: loss = 1.3332 (* 1 = 1.3332 loss)
I1030 13:42:26.559303  1046 sgd_solver.cpp:105] Iteration 35000, lr = 0.000130432
I1030 13:42:47.360497  1096 data_layer.cpp:73] Restarting data prefetching from start.
I1030 13:42:57.115725  1046 solver.cpp:222] Iteration 35040 (1.3091 iter/s, 30.5553s/40 iters), loss = 1.34951
I1030 13:42:57.115953  1046 solver.cpp:241]     Train net output #0: loss = 1.34951 (* 1 = 1.34951 loss)
I1030 13:42:57.115973  1046 sgd_solver.cpp:105] Iteration 35040, lr = 0.000129787
I1030 13:43:27.756772  1046 solver.cpp:222] Iteration 35080 (1.3055 iter/s, 30.6397s/40 iters), loss = 0.954949
I1030 13:43:27.756971  1046 solver.cpp:241]     Train net output #0: loss = 0.954949 (* 1 = 0.954949 loss)
I1030 13:43:27.756990  1046 sgd_solver.cpp:105] Iteration 35080, lr = 0.000129145
I1030 13:43:58.679498  1046 solver.cpp:222] Iteration 35120 (1.2936 iter/s, 30.9214s/40 iters), loss = 1.12518
I1030 13:43:58.679699  1046 solver.cpp:241]     Train net output #0: loss = 1.12518 (* 1 = 1.12518 loss)
I1030 13:43:58.679716  1046 sgd_solver.cpp:105] Iteration 35120, lr = 0.000128506
I1030 13:44:30.673390  1046 solver.cpp:222] Iteration 35160 (1.25029 iter/s, 31.9925s/40 iters), loss = 1.29402
I1030 13:44:30.673596  1046 solver.cpp:241]     Train net output #0: loss = 1.29402 (* 1 = 1.29402 loss)
I1030 13:44:30.673612  1046 sgd_solver.cpp:105] Iteration 35160, lr = 0.00012787
I1030 13:45:01.141440  1046 solver.cpp:222] Iteration 35200 (1.31291 iter/s, 30.4667s/40 iters), loss = 1.39447
I1030 13:45:01.141623  1046 solver.cpp:241]     Train net output #0: loss = 1.39447 (* 1 = 1.39447 loss)
I1030 13:45:01.141639  1046 sgd_solver.cpp:105] Iteration 35200, lr = 0.000127238
I1030 13:45:32.015561  1046 solver.cpp:222] Iteration 35240 (1.29564 iter/s, 30.8727s/40 iters), loss = 1.37802
I1030 13:45:32.015753  1046 solver.cpp:241]     Train net output #0: loss = 1.37802 (* 1 = 1.37802 loss)
I1030 13:45:32.015772  1046 sgd_solver.cpp:105] Iteration 35240, lr = 0.000126608
I1030 13:46:02.349323  1046 solver.cpp:222] Iteration 35280 (1.31872 iter/s, 30.3324s/40 iters), loss = 1.49662
I1030 13:46:02.349519  1046 solver.cpp:241]     Train net output #0: loss = 1.49662 (* 1 = 1.49662 loss)
I1030 13:46:02.349536  1046 sgd_solver.cpp:105] Iteration 35280, lr = 0.000125982
I1030 13:46:32.781597  1046 solver.cpp:222] Iteration 35320 (1.31445 iter/s, 30.4309s/40 iters), loss = 1.14636
I1030 13:46:32.781780  1046 solver.cpp:241]     Train net output #0: loss = 1.14636 (* 1 = 1.14636 loss)
I1030 13:46:32.781797  1046 sgd_solver.cpp:105] Iteration 35320, lr = 0.000125359
I1030 13:47:03.589390  1046 solver.cpp:222] Iteration 35360 (1.29843 iter/s, 30.8064s/40 iters), loss = 1.26002
I1030 13:47:03.589587  1046 solver.cpp:241]     Train net output #0: loss = 1.26002 (* 1 = 1.26002 loss)
I1030 13:47:03.589604  1046 sgd_solver.cpp:105] Iteration 35360, lr = 0.000124738
I1030 13:47:35.021270  1046 solver.cpp:222] Iteration 35400 (1.27265 iter/s, 31.4305s/40 iters), loss = 1.48922
I1030 13:47:35.021550  1046 solver.cpp:241]     Train net output #0: loss = 1.48922 (* 1 = 1.48922 loss)
I1030 13:47:35.021579  1046 sgd_solver.cpp:105] Iteration 35400, lr = 0.000124121
I1030 13:48:06.270053  1046 solver.cpp:222] Iteration 35440 (1.28011 iter/s, 31.2473s/40 iters), loss = 1.57386
I1030 13:48:06.270264  1046 solver.cpp:241]     Train net output #0: loss = 1.57386 (* 1 = 1.57386 loss)
I1030 13:48:06.270282  1046 sgd_solver.cpp:105] Iteration 35440, lr = 0.000123507
I1030 13:48:37.085170  1046 solver.cpp:222] Iteration 35480 (1.29812 iter/s, 30.8137s/40 iters), loss = 1.17032
I1030 13:48:37.085374  1046 solver.cpp:241]     Train net output #0: loss = 1.17032 (* 1 = 1.17032 loss)
I1030 13:48:37.085391  1046 sgd_solver.cpp:105] Iteration 35480, lr = 0.000122896
I1030 13:48:51.539417  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_35500.caffemodel
I1030 13:48:51.576035  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_35500.solverstate
I1030 13:48:51.597872  1046 solver.cpp:334] Iteration 35500, Testing net (#0)
I1030 13:49:22.385550  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 13:49:22.594625  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58648
I1030 13:49:22.594683  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81368
I1030 13:49:22.594697  1046 solver.cpp:401]     Test net output #2: loss = 1.839 (* 1 = 1.839 loss)
I1030 13:49:38.546645  1046 solver.cpp:222] Iteration 35520 (0.650841 iter/s, 61.459s/40 iters), loss = 1.48893
I1030 13:49:38.546710  1046 solver.cpp:241]     Train net output #0: loss = 1.48893 (* 1 = 1.48893 loss)
I1030 13:49:38.546726  1046 sgd_solver.cpp:105] Iteration 35520, lr = 0.000122288
I1030 13:50:08.729780  1046 solver.cpp:222] Iteration 35560 (1.3253 iter/s, 30.1819s/40 iters), loss = 1.18781
I1030 13:50:08.729969  1046 solver.cpp:241]     Train net output #0: loss = 1.18781 (* 1 = 1.18781 loss)
I1030 13:50:08.729985  1046 sgd_solver.cpp:105] Iteration 35560, lr = 0.000121683
I1030 13:50:39.155056  1046 solver.cpp:222] Iteration 35600 (1.31475 iter/s, 30.4239s/40 iters), loss = 1.45687
I1030 13:50:39.155237  1046 solver.cpp:241]     Train net output #0: loss = 1.45687 (* 1 = 1.45687 loss)
I1030 13:50:39.155254  1046 sgd_solver.cpp:105] Iteration 35600, lr = 0.000121081
I1030 13:51:09.776959  1046 solver.cpp:222] Iteration 35640 (1.30631 iter/s, 30.6206s/40 iters), loss = 1.52676
I1030 13:51:09.777160  1046 solver.cpp:241]     Train net output #0: loss = 1.52676 (* 1 = 1.52676 loss)
I1030 13:51:09.777179  1046 sgd_solver.cpp:105] Iteration 35640, lr = 0.000120482
I1030 13:51:40.360571  1046 solver.cpp:222] Iteration 35680 (1.30795 iter/s, 30.5823s/40 iters), loss = 1.2135
I1030 13:51:40.360738  1046 solver.cpp:241]     Train net output #0: loss = 1.2135 (* 1 = 1.2135 loss)
I1030 13:51:40.360755  1046 sgd_solver.cpp:105] Iteration 35680, lr = 0.000119886
I1030 13:52:11.251605  1046 solver.cpp:222] Iteration 35720 (1.29493 iter/s, 30.8897s/40 iters), loss = 1.40898
I1030 13:52:11.251816  1046 solver.cpp:241]     Train net output #0: loss = 1.40898 (* 1 = 1.40898 loss)
I1030 13:52:11.251833  1046 sgd_solver.cpp:105] Iteration 35720, lr = 0.000119293
I1030 13:52:42.173954  1046 solver.cpp:222] Iteration 35760 (1.29362 iter/s, 30.921s/40 iters), loss = 1.20593
I1030 13:52:42.174183  1046 solver.cpp:241]     Train net output #0: loss = 1.20593 (* 1 = 1.20593 loss)
I1030 13:52:42.174201  1046 sgd_solver.cpp:105] Iteration 35760, lr = 0.000118703
I1030 13:53:14.454501  1046 solver.cpp:222] Iteration 35800 (1.23919 iter/s, 32.2791s/40 iters), loss = 1.16759
I1030 13:53:14.454699  1046 solver.cpp:241]     Train net output #0: loss = 1.16759 (* 1 = 1.16759 loss)
I1030 13:53:14.454715  1046 sgd_solver.cpp:105] Iteration 35800, lr = 0.000118116
I1030 13:53:44.960078  1046 solver.cpp:222] Iteration 35840 (1.31129 iter/s, 30.5042s/40 iters), loss = 1.56794
I1030 13:53:44.960237  1046 solver.cpp:241]     Train net output #0: loss = 1.56794 (* 1 = 1.56794 loss)
I1030 13:53:44.960261  1046 sgd_solver.cpp:105] Iteration 35840, lr = 0.000117531
I1030 13:54:15.224789  1046 solver.cpp:222] Iteration 35880 (1.32173 iter/s, 30.2634s/40 iters), loss = 1.24546
I1030 13:54:15.224984  1046 solver.cpp:241]     Train net output #0: loss = 1.24546 (* 1 = 1.24546 loss)
I1030 13:54:15.225003  1046 sgd_solver.cpp:105] Iteration 35880, lr = 0.00011695
I1030 13:54:51.823566  1046 solver.cpp:222] Iteration 35920 (1.09298 iter/s, 36.5972s/40 iters), loss = 1.2738
I1030 13:54:51.823782  1046 solver.cpp:241]     Train net output #0: loss = 1.2738 (* 1 = 1.2738 loss)
I1030 13:54:51.823807  1046 sgd_solver.cpp:105] Iteration 35920, lr = 0.000116371
I1030 13:55:23.961943  1046 solver.cpp:222] Iteration 35960 (1.24467 iter/s, 32.137s/40 iters), loss = 1.35727
I1030 13:55:23.962196  1046 solver.cpp:241]     Train net output #0: loss = 1.35727 (* 1 = 1.35727 loss)
I1030 13:55:23.962229  1046 sgd_solver.cpp:105] Iteration 35960, lr = 0.000115796
I1030 13:55:54.532120  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_36000.caffemodel
I1030 13:55:54.578476  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_36000.solverstate
I1030 13:55:54.602846  1046 solver.cpp:334] Iteration 36000, Testing net (#0)
I1030 13:56:25.655882  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5874
I1030 13:56:25.656061  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.810479
I1030 13:56:25.656078  1046 solver.cpp:401]     Test net output #2: loss = 1.83289 (* 1 = 1.83289 loss)
I1030 13:56:26.417135  1046 solver.cpp:222] Iteration 36000 (0.640486 iter/s, 62.4526s/40 iters), loss = 1.58262
I1030 13:56:26.417197  1046 solver.cpp:241]     Train net output #0: loss = 1.58262 (* 1 = 1.58262 loss)
I1030 13:56:26.417214  1046 sgd_solver.cpp:105] Iteration 36000, lr = 0.000115223
I1030 13:56:57.817337  1046 solver.cpp:222] Iteration 36040 (1.27393 iter/s, 31.399s/40 iters), loss = 1.31522
I1030 13:56:57.817512  1046 solver.cpp:241]     Train net output #0: loss = 1.31522 (* 1 = 1.31522 loss)
I1030 13:56:57.817529  1046 sgd_solver.cpp:105] Iteration 36040, lr = 0.000114653
I1030 13:57:28.450749  1046 solver.cpp:222] Iteration 36080 (1.30582 iter/s, 30.6321s/40 iters), loss = 1.54415
I1030 13:57:28.450909  1046 solver.cpp:241]     Train net output #0: loss = 1.54415 (* 1 = 1.54415 loss)
I1030 13:57:28.450927  1046 sgd_solver.cpp:105] Iteration 36080, lr = 0.000114086
I1030 13:57:59.970747  1046 solver.cpp:222] Iteration 36120 (1.26909 iter/s, 31.5187s/40 iters), loss = 1.24766
I1030 13:57:59.970924  1046 solver.cpp:241]     Train net output #0: loss = 1.24766 (* 1 = 1.24766 loss)
I1030 13:57:59.970942  1046 sgd_solver.cpp:105] Iteration 36120, lr = 0.000113521
I1030 13:58:31.092408  1046 solver.cpp:222] Iteration 36160 (1.28533 iter/s, 31.1203s/40 iters), loss = 1.35843
I1030 13:58:31.092608  1046 solver.cpp:241]     Train net output #0: loss = 1.35843 (* 1 = 1.35843 loss)
I1030 13:58:31.092625  1046 sgd_solver.cpp:105] Iteration 36160, lr = 0.00011296
I1030 13:59:01.610272  1046 solver.cpp:222] Iteration 36200 (1.31077 iter/s, 30.5165s/40 iters), loss = 1.25808
I1030 13:59:01.610473  1046 solver.cpp:241]     Train net output #0: loss = 1.25808 (* 1 = 1.25808 loss)
I1030 13:59:01.610491  1046 sgd_solver.cpp:105] Iteration 36200, lr = 0.000112401
I1030 13:59:32.565945  1046 solver.cpp:222] Iteration 36240 (1.29223 iter/s, 30.9543s/40 iters), loss = 1.34931
I1030 13:59:32.566148  1046 solver.cpp:241]     Train net output #0: loss = 1.34931 (* 1 = 1.34931 loss)
I1030 13:59:32.566171  1046 sgd_solver.cpp:105] Iteration 36240, lr = 0.000111845
I1030 14:00:03.442337  1046 solver.cpp:222] Iteration 36280 (1.29555 iter/s, 30.875s/40 iters), loss = 1.3381
I1030 14:00:03.442540  1046 solver.cpp:241]     Train net output #0: loss = 1.3381 (* 1 = 1.3381 loss)
I1030 14:00:03.442559  1046 sgd_solver.cpp:105] Iteration 36280, lr = 0.000111291
I1030 14:00:35.222687  1046 solver.cpp:222] Iteration 36320 (1.2587 iter/s, 31.7789s/40 iters), loss = 1.3367
I1030 14:00:35.222882  1046 solver.cpp:241]     Train net output #0: loss = 1.3367 (* 1 = 1.3367 loss)
I1030 14:00:35.222906  1046 sgd_solver.cpp:105] Iteration 36320, lr = 0.000110741
I1030 14:01:05.838899  1046 solver.cpp:222] Iteration 36360 (1.30656 iter/s, 30.6149s/40 iters), loss = 1.36433
I1030 14:01:05.839092  1046 solver.cpp:241]     Train net output #0: loss = 1.36433 (* 1 = 1.36433 loss)
I1030 14:01:05.839109  1046 sgd_solver.cpp:105] Iteration 36360, lr = 0.000110193
I1030 14:01:36.218039  1046 solver.cpp:222] Iteration 36400 (1.31675 iter/s, 30.3778s/40 iters), loss = 1.45074
I1030 14:01:36.218252  1046 solver.cpp:241]     Train net output #0: loss = 1.45074 (* 1 = 1.45074 loss)
I1030 14:01:36.218269  1046 sgd_solver.cpp:105] Iteration 36400, lr = 0.000109648
I1030 14:02:06.514462  1046 solver.cpp:222] Iteration 36440 (1.32035 iter/s, 30.2951s/40 iters), loss = 1.31615
I1030 14:02:06.514731  1046 solver.cpp:241]     Train net output #0: loss = 1.31615 (* 1 = 1.31615 loss)
I1030 14:02:06.514750  1046 sgd_solver.cpp:105] Iteration 36440, lr = 0.000109105
I1030 14:02:36.866201  1046 solver.cpp:222] Iteration 36480 (1.31794 iter/s, 30.3503s/40 iters), loss = 1.5243
I1030 14:02:36.866375  1046 solver.cpp:241]     Train net output #0: loss = 1.5243 (* 1 = 1.5243 loss)
I1030 14:02:36.866391  1046 sgd_solver.cpp:105] Iteration 36480, lr = 0.000108566
I1030 14:02:51.276816  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_36500.caffemodel
I1030 14:02:51.314333  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_36500.solverstate
I1030 14:02:51.332612  1046 solver.cpp:334] Iteration 36500, Testing net (#0)
I1030 14:03:22.086537  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 14:03:22.293459  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58696
I1030 14:03:22.293521  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813359
I1030 14:03:22.293535  1046 solver.cpp:401]     Test net output #2: loss = 1.83627 (* 1 = 1.83627 loss)
I1030 14:03:38.218289  1046 solver.cpp:222] Iteration 36520 (0.652001 iter/s, 61.3496s/40 iters), loss = 1.47957
I1030 14:03:38.218363  1046 solver.cpp:241]     Train net output #0: loss = 1.47957 (* 1 = 1.47957 loss)
I1030 14:03:38.218379  1046 sgd_solver.cpp:105] Iteration 36520, lr = 0.000108029
I1030 14:04:08.473387  1046 solver.cpp:222] Iteration 36560 (1.32214 iter/s, 30.2539s/40 iters), loss = 1.50554
I1030 14:04:08.473564  1046 solver.cpp:241]     Train net output #0: loss = 1.50554 (* 1 = 1.50554 loss)
I1030 14:04:08.473582  1046 sgd_solver.cpp:105] Iteration 36560, lr = 0.000107494
I1030 14:04:38.851322  1046 solver.cpp:222] Iteration 36600 (1.3168 iter/s, 30.3766s/40 iters), loss = 1.47535
I1030 14:04:38.851511  1046 solver.cpp:241]     Train net output #0: loss = 1.47535 (* 1 = 1.47535 loss)
I1030 14:04:38.851527  1046 sgd_solver.cpp:105] Iteration 36600, lr = 0.000106962
I1030 14:05:09.171854  1046 solver.cpp:222] Iteration 36640 (1.3193 iter/s, 30.3192s/40 iters), loss = 1.22007
I1030 14:05:09.172027  1046 solver.cpp:241]     Train net output #0: loss = 1.22007 (* 1 = 1.22007 loss)
I1030 14:05:09.172045  1046 sgd_solver.cpp:105] Iteration 36640, lr = 0.000106433
I1030 14:05:39.328752  1046 solver.cpp:222] Iteration 36680 (1.32645 iter/s, 30.1556s/40 iters), loss = 1.45898
I1030 14:05:39.328938  1046 solver.cpp:241]     Train net output #0: loss = 1.45898 (* 1 = 1.45898 loss)
I1030 14:05:39.328965  1046 sgd_solver.cpp:105] Iteration 36680, lr = 0.000105907
I1030 14:06:10.291046  1046 solver.cpp:222] Iteration 36720 (1.29195 iter/s, 30.9609s/40 iters), loss = 1.57661
I1030 14:06:10.291230  1046 solver.cpp:241]     Train net output #0: loss = 1.57661 (* 1 = 1.57661 loss)
I1030 14:06:10.291246  1046 sgd_solver.cpp:105] Iteration 36720, lr = 0.000105383
I1030 14:06:42.208173  1046 solver.cpp:222] Iteration 36760 (1.2533 iter/s, 31.9157s/40 iters), loss = 1.54057
I1030 14:06:42.208365  1046 solver.cpp:241]     Train net output #0: loss = 1.54057 (* 1 = 1.54057 loss)
I1030 14:06:42.208385  1046 sgd_solver.cpp:105] Iteration 36760, lr = 0.000104861
I1030 14:07:13.723839  1046 solver.cpp:222] Iteration 36800 (1.26927 iter/s, 31.5143s/40 iters), loss = 1.66006
I1030 14:07:13.724030  1046 solver.cpp:241]     Train net output #0: loss = 1.66006 (* 1 = 1.66006 loss)
I1030 14:07:13.724054  1046 sgd_solver.cpp:105] Iteration 36800, lr = 0.000104343
I1030 14:07:47.687551  1046 solver.cpp:222] Iteration 36840 (1.17778 iter/s, 33.9622s/40 iters), loss = 1.74935
I1030 14:07:47.687752  1046 solver.cpp:241]     Train net output #0: loss = 1.74935 (* 1 = 1.74935 loss)
I1030 14:07:47.687768  1046 sgd_solver.cpp:105] Iteration 36840, lr = 0.000103826
I1030 14:08:18.633301  1046 solver.cpp:222] Iteration 36880 (1.29264 iter/s, 30.9444s/40 iters), loss = 1.31315
I1030 14:08:18.633640  1046 solver.cpp:241]     Train net output #0: loss = 1.31315 (* 1 = 1.31315 loss)
I1030 14:08:18.633671  1046 sgd_solver.cpp:105] Iteration 36880, lr = 0.000103313
I1030 14:08:49.584841  1046 solver.cpp:222] Iteration 36920 (1.29241 iter/s, 30.95s/40 iters), loss = 1.68454
I1030 14:08:49.585075  1046 solver.cpp:241]     Train net output #0: loss = 1.68454 (* 1 = 1.68454 loss)
I1030 14:08:49.585103  1046 sgd_solver.cpp:105] Iteration 36920, lr = 0.000102802
I1030 14:09:21.264993  1046 solver.cpp:222] Iteration 36960 (1.26268 iter/s, 31.6787s/40 iters), loss = 1.49159
I1030 14:09:21.265154  1046 solver.cpp:241]     Train net output #0: loss = 1.49159 (* 1 = 1.49159 loss)
I1030 14:09:21.265172  1046 sgd_solver.cpp:105] Iteration 36960, lr = 0.000102293
I1030 14:09:51.138561  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_37000.caffemodel
I1030 14:09:51.170258  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_37000.solverstate
I1030 14:09:51.196475  1046 solver.cpp:334] Iteration 37000, Testing net (#0)
I1030 14:10:22.145107  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5882
I1030 14:10:22.145324  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81016
I1030 14:10:22.145341  1046 solver.cpp:401]     Test net output #2: loss = 1.83224 (* 1 = 1.83224 loss)
I1030 14:10:22.909642  1046 solver.cpp:222] Iteration 37000 (0.648906 iter/s, 61.6422s/40 iters), loss = 1.23246
I1030 14:10:22.909703  1046 solver.cpp:241]     Train net output #0: loss = 1.23246 (* 1 = 1.23246 loss)
I1030 14:10:22.909718  1046 sgd_solver.cpp:105] Iteration 37000, lr = 0.000101787
I1030 14:10:53.763835  1046 solver.cpp:222] Iteration 37040 (1.29647 iter/s, 30.853s/40 iters), loss = 1.49507
I1030 14:10:53.764055  1046 solver.cpp:241]     Train net output #0: loss = 1.49507 (* 1 = 1.49507 loss)
I1030 14:10:53.764075  1046 sgd_solver.cpp:105] Iteration 37040, lr = 0.000101283
I1030 14:11:24.690274  1046 solver.cpp:222] Iteration 37080 (1.29345 iter/s, 30.925s/40 iters), loss = 1.36601
I1030 14:11:24.690526  1046 solver.cpp:241]     Train net output #0: loss = 1.36601 (* 1 = 1.36601 loss)
I1030 14:11:24.690552  1046 sgd_solver.cpp:105] Iteration 37080, lr = 0.000100782
I1030 14:11:55.408705  1046 solver.cpp:222] Iteration 37120 (1.30221 iter/s, 30.717s/40 iters), loss = 1.62458
I1030 14:11:55.408905  1046 solver.cpp:241]     Train net output #0: loss = 1.62458 (* 1 = 1.62458 loss)
I1030 14:11:55.408921  1046 sgd_solver.cpp:105] Iteration 37120, lr = 0.000100284
I1030 14:12:26.119397  1046 solver.cpp:222] Iteration 37160 (1.30254 iter/s, 30.7093s/40 iters), loss = 1.65067
I1030 14:12:26.119577  1046 solver.cpp:241]     Train net output #0: loss = 1.65067 (* 1 = 1.65067 loss)
I1030 14:12:26.119598  1046 sgd_solver.cpp:105] Iteration 37160, lr = 9.97877e-05
I1030 14:12:57.296965  1046 solver.cpp:222] Iteration 37200 (1.28303 iter/s, 31.1762s/40 iters), loss = 1.42679
I1030 14:12:57.297186  1046 solver.cpp:241]     Train net output #0: loss = 1.42679 (* 1 = 1.42679 loss)
I1030 14:12:57.297204  1046 sgd_solver.cpp:105] Iteration 37200, lr = 9.9294e-05
I1030 14:13:28.341905  1046 solver.cpp:222] Iteration 37240 (1.28851 iter/s, 31.0436s/40 iters), loss = 1.37401
I1030 14:13:28.342113  1046 solver.cpp:241]     Train net output #0: loss = 1.37401 (* 1 = 1.37401 loss)
I1030 14:13:28.342130  1046 sgd_solver.cpp:105] Iteration 37240, lr = 9.88028e-05
I1030 14:13:58.699772  1046 solver.cpp:222] Iteration 37280 (1.31767 iter/s, 30.3565s/40 iters), loss = 1.35699
I1030 14:13:58.699955  1046 solver.cpp:241]     Train net output #0: loss = 1.35699 (* 1 = 1.35699 loss)
I1030 14:13:58.699972  1046 sgd_solver.cpp:105] Iteration 37280, lr = 9.8314e-05
I1030 14:14:29.159847  1046 solver.cpp:222] Iteration 37320 (1.31325 iter/s, 30.4588s/40 iters), loss = 1.33118
I1030 14:14:29.160076  1046 solver.cpp:241]     Train net output #0: loss = 1.33118 (* 1 = 1.33118 loss)
I1030 14:14:29.160109  1046 sgd_solver.cpp:105] Iteration 37320, lr = 9.78276e-05
I1030 14:14:59.501812  1046 solver.cpp:222] Iteration 37360 (1.31837 iter/s, 30.3406s/40 iters), loss = 1.44876
I1030 14:14:59.502004  1046 solver.cpp:241]     Train net output #0: loss = 1.44876 (* 1 = 1.44876 loss)
I1030 14:14:59.502020  1046 sgd_solver.cpp:105] Iteration 37360, lr = 9.73437e-05
I1030 14:15:29.879106  1046 solver.cpp:222] Iteration 37400 (1.31683 iter/s, 30.376s/40 iters), loss = 1.37918
I1030 14:15:29.879282  1046 solver.cpp:241]     Train net output #0: loss = 1.37918 (* 1 = 1.37918 loss)
I1030 14:15:29.879305  1046 sgd_solver.cpp:105] Iteration 37400, lr = 9.68621e-05
I1030 14:16:00.256500  1046 solver.cpp:222] Iteration 37440 (1.31683 iter/s, 30.3761s/40 iters), loss = 1.55
I1030 14:16:00.256685  1046 solver.cpp:241]     Train net output #0: loss = 1.55 (* 1 = 1.55 loss)
I1030 14:16:00.256701  1046 sgd_solver.cpp:105] Iteration 37440, lr = 9.63829e-05
I1030 14:16:30.728193  1046 solver.cpp:222] Iteration 37480 (1.31275 iter/s, 30.4704s/40 iters), loss = 1.50742
I1030 14:16:30.728385  1046 solver.cpp:241]     Train net output #0: loss = 1.50742 (* 1 = 1.50742 loss)
I1030 14:16:30.728402  1046 sgd_solver.cpp:105] Iteration 37480, lr = 9.59061e-05
I1030 14:16:45.318462  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_37500.caffemodel
I1030 14:16:45.349895  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_37500.solverstate
I1030 14:16:45.368649  1046 solver.cpp:334] Iteration 37500, Testing net (#0)
I1030 14:17:16.043395  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 14:17:16.249594  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58704
I1030 14:17:16.249656  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81376
I1030 14:17:16.249670  1046 solver.cpp:401]     Test net output #2: loss = 1.83703 (* 1 = 1.83703 loss)
I1030 14:17:32.535243  1046 solver.cpp:222] Iteration 37520 (0.647202 iter/s, 61.8045s/40 iters), loss = 1.27505
I1030 14:17:32.535317  1046 solver.cpp:241]     Train net output #0: loss = 1.27505 (* 1 = 1.27505 loss)
I1030 14:17:32.535333  1046 sgd_solver.cpp:105] Iteration 37520, lr = 9.54316e-05
I1030 14:17:40.363399  1096 data_layer.cpp:73] Restarting data prefetching from start.
I1030 14:18:03.426930  1046 solver.cpp:222] Iteration 37560 (1.2949 iter/s, 30.8904s/40 iters), loss = 1.54367
I1030 14:18:03.427124  1046 solver.cpp:241]     Train net output #0: loss = 1.54367 (* 1 = 1.54367 loss)
I1030 14:18:03.427142  1046 sgd_solver.cpp:105] Iteration 37560, lr = 9.49595e-05
I1030 14:18:39.112542  1046 solver.cpp:222] Iteration 37600 (1.12095 iter/s, 35.6841s/40 iters), loss = 1.25699
I1030 14:18:39.112730  1046 solver.cpp:241]     Train net output #0: loss = 1.25699 (* 1 = 1.25699 loss)
I1030 14:18:39.112747  1046 sgd_solver.cpp:105] Iteration 37600, lr = 9.44897e-05
I1030 14:19:10.383489  1046 solver.cpp:222] Iteration 37640 (1.2792 iter/s, 31.2696s/40 iters), loss = 1.33891
I1030 14:19:10.383678  1046 solver.cpp:241]     Train net output #0: loss = 1.33891 (* 1 = 1.33891 loss)
I1030 14:19:10.383698  1046 sgd_solver.cpp:105] Iteration 37640, lr = 9.40223e-05
I1030 14:19:40.571581  1046 solver.cpp:222] Iteration 37680 (1.32508 iter/s, 30.1868s/40 iters), loss = 1.31773
I1030 14:19:40.571761  1046 solver.cpp:241]     Train net output #0: loss = 1.31773 (* 1 = 1.31773 loss)
I1030 14:19:40.571779  1046 sgd_solver.cpp:105] Iteration 37680, lr = 9.35572e-05
I1030 14:20:10.560261  1046 solver.cpp:222] Iteration 37720 (1.33389 iter/s, 29.9874s/40 iters), loss = 1.72501
I1030 14:20:10.560331  1046 solver.cpp:241]     Train net output #0: loss = 1.72501 (* 1 = 1.72501 loss)
I1030 14:20:10.560348  1046 sgd_solver.cpp:105] Iteration 37720, lr = 9.30943e-05
I1030 14:20:40.713078  1046 solver.cpp:222] Iteration 37760 (1.32663 iter/s, 30.1516s/40 iters), loss = 1.26962
I1030 14:20:40.713311  1046 solver.cpp:241]     Train net output #0: loss = 1.26962 (* 1 = 1.26962 loss)
I1030 14:20:40.713340  1046 sgd_solver.cpp:105] Iteration 37760, lr = 9.26338e-05
I1030 14:21:10.951195  1046 solver.cpp:222] Iteration 37800 (1.32289 iter/s, 30.2367s/40 iters), loss = 1.40859
I1030 14:21:10.951424  1046 solver.cpp:241]     Train net output #0: loss = 1.40859 (* 1 = 1.40859 loss)
I1030 14:21:10.951442  1046 sgd_solver.cpp:105] Iteration 37800, lr = 9.21755e-05
I1030 14:21:42.467948  1046 solver.cpp:222] Iteration 37840 (1.26922 iter/s, 31.5153s/40 iters), loss = 1.11248
I1030 14:21:42.468134  1046 solver.cpp:241]     Train net output #0: loss = 1.11248 (* 1 = 1.11248 loss)
I1030 14:21:42.468152  1046 sgd_solver.cpp:105] Iteration 37840, lr = 9.17195e-05
I1030 14:22:13.788242  1046 solver.cpp:222] Iteration 37880 (1.27718 iter/s, 31.3189s/40 iters), loss = 1.40397
I1030 14:22:13.788483  1046 solver.cpp:241]     Train net output #0: loss = 1.40397 (* 1 = 1.40397 loss)
I1030 14:22:13.788511  1046 sgd_solver.cpp:105] Iteration 37880, lr = 9.12657e-05
I1030 14:22:45.433189  1046 solver.cpp:222] Iteration 37920 (1.26408 iter/s, 31.6435s/40 iters), loss = 1.27922
I1030 14:22:45.433387  1046 solver.cpp:241]     Train net output #0: loss = 1.27922 (* 1 = 1.27922 loss)
I1030 14:22:45.433404  1046 sgd_solver.cpp:105] Iteration 37920, lr = 9.08142e-05
I1030 14:23:15.927399  1046 solver.cpp:222] Iteration 37960 (1.31178 iter/s, 30.4929s/40 iters), loss = 1.17426
I1030 14:23:15.927588  1046 solver.cpp:241]     Train net output #0: loss = 1.17426 (* 1 = 1.17426 loss)
I1030 14:23:15.927605  1046 sgd_solver.cpp:105] Iteration 37960, lr = 9.0365e-05
I1030 14:23:45.578436  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_38000.caffemodel
I1030 14:23:45.610586  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_38000.solverstate
I1030 14:23:45.627671  1046 solver.cpp:334] Iteration 38000, Testing net (#0)
I1030 14:24:16.552212  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58848
I1030 14:24:16.552426  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.810679
I1030 14:24:16.552443  1046 solver.cpp:401]     Test net output #2: loss = 1.83546 (* 1 = 1.83546 loss)
I1030 14:24:17.313439  1046 solver.cpp:222] Iteration 38000 (0.65164 iter/s, 61.3835s/40 iters), loss = 1.46345
I1030 14:24:17.313499  1046 solver.cpp:241]     Train net output #0: loss = 1.46345 (* 1 = 1.46345 loss)
I1030 14:24:17.313515  1046 sgd_solver.cpp:105] Iteration 38000, lr = 8.99179e-05
I1030 14:24:47.642454  1046 solver.cpp:222] Iteration 38040 (1.31892 iter/s, 30.3278s/40 iters), loss = 1.37859
I1030 14:24:47.642643  1046 solver.cpp:241]     Train net output #0: loss = 1.37859 (* 1 = 1.37859 loss)
I1030 14:24:47.642663  1046 sgd_solver.cpp:105] Iteration 38040, lr = 8.94731e-05
I1030 14:25:17.955817  1046 solver.cpp:222] Iteration 38080 (1.31961 iter/s, 30.312s/40 iters), loss = 1.29374
I1030 14:25:17.955960  1046 solver.cpp:241]     Train net output #0: loss = 1.29374 (* 1 = 1.29374 loss)
I1030 14:25:17.955976  1046 sgd_solver.cpp:105] Iteration 38080, lr = 8.90304e-05
I1030 14:25:48.377979  1046 solver.cpp:222] Iteration 38120 (1.31489 iter/s, 30.4209s/40 iters), loss = 1.52009
I1030 14:25:48.378187  1046 solver.cpp:241]     Train net output #0: loss = 1.52009 (* 1 = 1.52009 loss)
I1030 14:25:48.378204  1046 sgd_solver.cpp:105] Iteration 38120, lr = 8.859e-05
I1030 14:26:18.805675  1046 solver.cpp:222] Iteration 38160 (1.31465 iter/s, 30.4263s/40 iters), loss = 1.53768
I1030 14:26:18.805856  1046 solver.cpp:241]     Train net output #0: loss = 1.53768 (* 1 = 1.53768 loss)
I1030 14:26:18.805872  1046 sgd_solver.cpp:105] Iteration 38160, lr = 8.81517e-05
I1030 14:26:49.187320  1046 solver.cpp:222] Iteration 38200 (1.31664 iter/s, 30.3803s/40 iters), loss = 1.24411
I1030 14:26:49.187500  1046 solver.cpp:241]     Train net output #0: loss = 1.24411 (* 1 = 1.24411 loss)
I1030 14:26:49.187520  1046 sgd_solver.cpp:105] Iteration 38200, lr = 8.77156e-05
I1030 14:27:19.749919  1046 solver.cpp:222] Iteration 38240 (1.30885 iter/s, 30.5613s/40 iters), loss = 1.46756
I1030 14:27:19.750162  1046 solver.cpp:241]     Train net output #0: loss = 1.46756 (* 1 = 1.46756 loss)
I1030 14:27:19.750181  1046 sgd_solver.cpp:105] Iteration 38240, lr = 8.72817e-05
I1030 14:27:50.915427  1046 solver.cpp:222] Iteration 38280 (1.28353 iter/s, 31.1641s/40 iters), loss = 1.49292
I1030 14:27:50.915627  1046 solver.cpp:241]     Train net output #0: loss = 1.49292 (* 1 = 1.49292 loss)
I1030 14:27:50.915655  1046 sgd_solver.cpp:105] Iteration 38280, lr = 8.68499e-05
I1030 14:28:22.069339  1046 solver.cpp:222] Iteration 38320 (1.284 iter/s, 31.1525s/40 iters), loss = 1.37316
I1030 14:28:22.069532  1046 solver.cpp:241]     Train net output #0: loss = 1.37316 (* 1 = 1.37316 loss)
I1030 14:28:22.069548  1046 sgd_solver.cpp:105] Iteration 38320, lr = 8.64202e-05
I1030 14:28:53.986564  1046 solver.cpp:222] Iteration 38360 (1.2533 iter/s, 31.9158s/40 iters), loss = 1.71269
I1030 14:28:53.986815  1046 solver.cpp:241]     Train net output #0: loss = 1.71269 (* 1 = 1.71269 loss)
I1030 14:28:53.986837  1046 sgd_solver.cpp:105] Iteration 38360, lr = 8.59927e-05
I1030 14:29:32.246330  1046 solver.cpp:222] Iteration 38400 (1.04553 iter/s, 38.2581s/40 iters), loss = 1.64379
I1030 14:29:32.246508  1046 solver.cpp:241]     Train net output #0: loss = 1.64379 (* 1 = 1.64379 loss)
I1030 14:29:32.246525  1046 sgd_solver.cpp:105] Iteration 38400, lr = 8.55673e-05
I1030 14:30:03.685009  1046 solver.cpp:222] Iteration 38440 (1.27237 iter/s, 31.4373s/40 iters), loss = 1.43714
I1030 14:30:03.685207  1046 solver.cpp:241]     Train net output #0: loss = 1.43714 (* 1 = 1.43714 loss)
I1030 14:30:03.685225  1046 sgd_solver.cpp:105] Iteration 38440, lr = 8.5144e-05
I1030 14:30:34.489055  1046 solver.cpp:222] Iteration 38480 (1.29859 iter/s, 30.8027s/40 iters), loss = 1.41081
I1030 14:30:34.489238  1046 solver.cpp:241]     Train net output #0: loss = 1.41081 (* 1 = 1.41081 loss)
I1030 14:30:34.489253  1046 sgd_solver.cpp:105] Iteration 38480, lr = 8.47228e-05
I1030 14:30:49.637214  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_38500.caffemodel
I1030 14:30:49.668643  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_38500.solverstate
I1030 14:30:49.686367  1046 solver.cpp:334] Iteration 38500, Testing net (#0)
I1030 14:31:20.423054  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 14:31:20.632161  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58592
I1030 14:31:20.632221  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813919
I1030 14:31:20.632235  1046 solver.cpp:401]     Test net output #2: loss = 1.83648 (* 1 = 1.83648 loss)
I1030 14:31:37.099934  1046 solver.cpp:222] Iteration 38520 (0.638892 iter/s, 62.6083s/40 iters), loss = 1.53825
I1030 14:31:37.100028  1046 solver.cpp:241]     Train net output #0: loss = 1.53825 (* 1 = 1.53825 loss)
I1030 14:31:37.100052  1046 sgd_solver.cpp:105] Iteration 38520, lr = 8.43036e-05
I1030 14:32:07.870843  1046 solver.cpp:222] Iteration 38560 (1.29998 iter/s, 30.7697s/40 iters), loss = 1.54439
I1030 14:32:07.871064  1046 solver.cpp:241]     Train net output #0: loss = 1.54439 (* 1 = 1.54439 loss)
I1030 14:32:07.871081  1046 sgd_solver.cpp:105] Iteration 38560, lr = 8.38866e-05
I1030 14:32:38.565471  1046 solver.cpp:222] Iteration 38600 (1.30322 iter/s, 30.6933s/40 iters), loss = 1.52342
I1030 14:32:38.565663  1046 solver.cpp:241]     Train net output #0: loss = 1.52342 (* 1 = 1.52342 loss)
I1030 14:32:38.565680  1046 sgd_solver.cpp:105] Iteration 38600, lr = 8.34716e-05
I1030 14:33:09.048925  1046 solver.cpp:222] Iteration 38640 (1.31224 iter/s, 30.4821s/40 iters), loss = 1.35043
I1030 14:33:09.049095  1046 solver.cpp:241]     Train net output #0: loss = 1.35043 (* 1 = 1.35043 loss)
I1030 14:33:09.049113  1046 sgd_solver.cpp:105] Iteration 38640, lr = 8.30586e-05
I1030 14:33:40.032397  1046 solver.cpp:222] Iteration 38680 (1.29107 iter/s, 30.9821s/40 iters), loss = 1.46369
I1030 14:33:40.032660  1046 solver.cpp:241]     Train net output #0: loss = 1.46369 (* 1 = 1.46369 loss)
I1030 14:33:40.032682  1046 sgd_solver.cpp:105] Iteration 38680, lr = 8.26477e-05
I1030 14:34:11.219544  1046 solver.cpp:222] Iteration 38720 (1.28264 iter/s, 31.1857s/40 iters), loss = 1.59628
I1030 14:34:11.219746  1046 solver.cpp:241]     Train net output #0: loss = 1.59628 (* 1 = 1.59628 loss)
I1030 14:34:11.219763  1046 sgd_solver.cpp:105] Iteration 38720, lr = 8.22388e-05
I1030 14:34:41.602536  1046 solver.cpp:222] Iteration 38760 (1.31658 iter/s, 30.3817s/40 iters), loss = 1.48199
I1030 14:34:41.602702  1046 solver.cpp:241]     Train net output #0: loss = 1.48199 (* 1 = 1.48199 loss)
I1030 14:34:41.602720  1046 sgd_solver.cpp:105] Iteration 38760, lr = 8.1832e-05
I1030 14:35:12.072361  1046 solver.cpp:222] Iteration 38800 (1.31283 iter/s, 30.4685s/40 iters), loss = 1.40933
I1030 14:35:12.072563  1046 solver.cpp:241]     Train net output #0: loss = 1.40933 (* 1 = 1.40933 loss)
I1030 14:35:12.072579  1046 sgd_solver.cpp:105] Iteration 38800, lr = 8.14272e-05
I1030 14:35:42.486013  1046 solver.cpp:222] Iteration 38840 (1.31526 iter/s, 30.4123s/40 iters), loss = 1.52551
I1030 14:35:42.486238  1046 solver.cpp:241]     Train net output #0: loss = 1.52551 (* 1 = 1.52551 loss)
I1030 14:35:42.486254  1046 sgd_solver.cpp:105] Iteration 38840, lr = 8.10243e-05
I1030 14:36:13.048465  1046 solver.cpp:222] Iteration 38880 (1.30885 iter/s, 30.5611s/40 iters), loss = 1.07206
I1030 14:36:13.048655  1046 solver.cpp:241]     Train net output #0: loss = 1.07206 (* 1 = 1.07206 loss)
I1030 14:36:13.048672  1046 sgd_solver.cpp:105] Iteration 38880, lr = 8.06235e-05
I1030 14:37:08.673997  1046 solver.cpp:222] Iteration 38920 (0.719124 iter/s, 55.6232s/40 iters), loss = 1.72896
I1030 14:37:08.674201  1046 solver.cpp:241]     Train net output #0: loss = 1.72896 (* 1 = 1.72896 loss)
I1030 14:37:08.674218  1046 sgd_solver.cpp:105] Iteration 38920, lr = 8.02246e-05
I1030 14:37:40.749431  1046 solver.cpp:222] Iteration 38960 (1.24711 iter/s, 32.074s/40 iters), loss = 1.116
I1030 14:37:40.749637  1046 solver.cpp:241]     Train net output #0: loss = 1.116 (* 1 = 1.116 loss)
I1030 14:37:40.749655  1046 sgd_solver.cpp:105] Iteration 38960, lr = 7.98278e-05
I1030 14:38:10.878564  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_39000.caffemodel
I1030 14:38:10.910778  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_39000.solverstate
I1030 14:38:10.929390  1046 solver.cpp:334] Iteration 39000, Testing net (#0)
I1030 14:38:41.918848  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5884
I1030 14:38:41.919018  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.810279
I1030 14:38:41.919035  1046 solver.cpp:401]     Test net output #2: loss = 1.83218 (* 1 = 1.83218 loss)
I1030 14:38:42.689787  1046 solver.cpp:222] Iteration 39000 (0.645809 iter/s, 61.9378s/40 iters), loss = 1.16314
I1030 14:38:42.689851  1046 solver.cpp:241]     Train net output #0: loss = 1.16314 (* 1 = 1.16314 loss)
I1030 14:38:42.689867  1046 sgd_solver.cpp:105] Iteration 39000, lr = 7.94328e-05
I1030 14:39:13.567632  1046 solver.cpp:222] Iteration 39040 (1.29548 iter/s, 30.8766s/40 iters), loss = 1.1813
I1030 14:39:13.567822  1046 solver.cpp:241]     Train net output #0: loss = 1.1813 (* 1 = 1.1813 loss)
I1030 14:39:13.567839  1046 sgd_solver.cpp:105] Iteration 39040, lr = 7.90399e-05
I1030 14:39:44.090726  1046 solver.cpp:222] Iteration 39080 (1.31054 iter/s, 30.5217s/40 iters), loss = 1.29517
I1030 14:39:44.090906  1046 solver.cpp:241]     Train net output #0: loss = 1.29517 (* 1 = 1.29517 loss)
I1030 14:39:44.090924  1046 sgd_solver.cpp:105] Iteration 39080, lr = 7.86488e-05
I1030 14:40:14.631861  1046 solver.cpp:222] Iteration 39120 (1.30977 iter/s, 30.5398s/40 iters), loss = 1.38644
I1030 14:40:14.632086  1046 solver.cpp:241]     Train net output #0: loss = 1.38644 (* 1 = 1.38644 loss)
I1030 14:40:14.632102  1046 sgd_solver.cpp:105] Iteration 39120, lr = 7.82598e-05
I1030 14:40:45.740182  1046 solver.cpp:222] Iteration 39160 (1.28589 iter/s, 31.1069s/40 iters), loss = 1.37445
I1030 14:40:45.740442  1046 solver.cpp:241]     Train net output #0: loss = 1.37445 (* 1 = 1.37445 loss)
I1030 14:40:45.740460  1046 sgd_solver.cpp:105] Iteration 39160, lr = 7.78726e-05
I1030 14:41:17.043316  1046 solver.cpp:222] Iteration 39200 (1.27789 iter/s, 31.3017s/40 iters), loss = 1.26534
I1030 14:41:17.043512  1046 solver.cpp:241]     Train net output #0: loss = 1.26534 (* 1 = 1.26534 loss)
I1030 14:41:17.043536  1046 sgd_solver.cpp:105] Iteration 39200, lr = 7.74874e-05
I1030 14:41:47.996089  1046 solver.cpp:222] Iteration 39240 (1.29235 iter/s, 30.9514s/40 iters), loss = 1.22059
I1030 14:41:47.996280  1046 solver.cpp:241]     Train net output #0: loss = 1.22059 (* 1 = 1.22059 loss)
I1030 14:41:47.996301  1046 sgd_solver.cpp:105] Iteration 39240, lr = 7.7104e-05
I1030 14:42:19.127480  1046 solver.cpp:222] Iteration 39280 (1.28493 iter/s, 31.13s/40 iters), loss = 1.15218
I1030 14:42:19.127667  1046 solver.cpp:241]     Train net output #0: loss = 1.15218 (* 1 = 1.15218 loss)
I1030 14:42:19.127684  1046 sgd_solver.cpp:105] Iteration 39280, lr = 7.67226e-05
I1030 14:42:49.848456  1046 solver.cpp:222] Iteration 39320 (1.3021 iter/s, 30.7196s/40 iters), loss = 1.37936
I1030 14:42:49.848649  1046 solver.cpp:241]     Train net output #0: loss = 1.37936 (* 1 = 1.37936 loss)
I1030 14:42:49.848666  1046 sgd_solver.cpp:105] Iteration 39320, lr = 7.6343e-05
I1030 14:43:20.802702  1046 solver.cpp:222] Iteration 39360 (1.29229 iter/s, 30.9529s/40 iters), loss = 1.22616
I1030 14:43:20.802911  1046 solver.cpp:241]     Train net output #0: loss = 1.22616 (* 1 = 1.22616 loss)
I1030 14:43:20.802928  1046 sgd_solver.cpp:105] Iteration 39360, lr = 7.59653e-05
I1030 14:43:51.670244  1046 solver.cpp:222] Iteration 39400 (1.29592 iter/s, 30.8662s/40 iters), loss = 1.42759
I1030 14:43:51.670464  1046 solver.cpp:241]     Train net output #0: loss = 1.42759 (* 1 = 1.42759 loss)
I1030 14:43:51.670485  1046 sgd_solver.cpp:105] Iteration 39400, lr = 7.55895e-05
I1030 14:44:22.707223  1046 solver.cpp:222] Iteration 39440 (1.28884 iter/s, 31.0356s/40 iters), loss = 1.59183
I1030 14:44:22.707406  1046 solver.cpp:241]     Train net output #0: loss = 1.59183 (* 1 = 1.59183 loss)
I1030 14:44:22.707422  1046 sgd_solver.cpp:105] Iteration 39440, lr = 7.52156e-05
I1030 14:44:53.377759  1046 solver.cpp:222] Iteration 39480 (1.30424 iter/s, 30.6692s/40 iters), loss = 1.33217
I1030 14:44:53.377969  1046 solver.cpp:241]     Train net output #0: loss = 1.33217 (* 1 = 1.33217 loss)
I1030 14:44:53.377985  1046 sgd_solver.cpp:105] Iteration 39480, lr = 7.48435e-05
I1030 14:45:08.016940  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_39500.caffemodel
I1030 14:45:08.050333  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_39500.solverstate
I1030 14:45:08.068826  1046 solver.cpp:334] Iteration 39500, Testing net (#0)
I1030 14:45:38.833089  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 14:45:39.041174  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.587
I1030 14:45:39.041236  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813239
I1030 14:45:39.041251  1046 solver.cpp:401]     Test net output #2: loss = 1.83584 (* 1 = 1.83584 loss)
I1030 14:45:55.326090  1046 solver.cpp:222] Iteration 39520 (0.645726 iter/s, 61.9458s/40 iters), loss = 1.51606
I1030 14:45:55.326156  1046 solver.cpp:241]     Train net output #0: loss = 1.51606 (* 1 = 1.51606 loss)
I1030 14:45:55.326171  1046 sgd_solver.cpp:105] Iteration 39520, lr = 7.44732e-05
I1030 14:46:26.220587  1046 solver.cpp:222] Iteration 39560 (1.29478 iter/s, 30.8933s/40 iters), loss = 1.42032
I1030 14:46:26.220767  1046 solver.cpp:241]     Train net output #0: loss = 1.42032 (* 1 = 1.42032 loss)
I1030 14:46:26.220787  1046 sgd_solver.cpp:105] Iteration 39560, lr = 7.41048e-05
I1030 14:46:57.410563  1046 solver.cpp:222] Iteration 39600 (1.28252 iter/s, 31.1886s/40 iters), loss = 1.20352
I1030 14:46:57.410825  1046 solver.cpp:241]     Train net output #0: loss = 1.20352 (* 1 = 1.20352 loss)
I1030 14:46:57.410847  1046 sgd_solver.cpp:105] Iteration 39600, lr = 7.37382e-05
I1030 14:47:28.103466  1046 solver.cpp:222] Iteration 39640 (1.30329 iter/s, 30.6915s/40 iters), loss = 1.282
I1030 14:47:28.103667  1046 solver.cpp:241]     Train net output #0: loss = 1.282 (* 1 = 1.282 loss)
I1030 14:47:28.103684  1046 sgd_solver.cpp:105] Iteration 39640, lr = 7.33734e-05
I1030 14:47:59.668552  1046 solver.cpp:222] Iteration 39680 (1.26728 iter/s, 31.5637s/40 iters), loss = 1.48551
I1030 14:47:59.668745  1046 solver.cpp:241]     Train net output #0: loss = 1.48551 (* 1 = 1.48551 loss)
I1030 14:47:59.668762  1046 sgd_solver.cpp:105] Iteration 39680, lr = 7.30104e-05
I1030 14:48:30.202194  1046 solver.cpp:222] Iteration 39720 (1.31009 iter/s, 30.5323s/40 iters), loss = 1.46128
I1030 14:48:30.202389  1046 solver.cpp:241]     Train net output #0: loss = 1.46128 (* 1 = 1.46128 loss)
I1030 14:48:30.202405  1046 sgd_solver.cpp:105] Iteration 39720, lr = 7.26492e-05
I1030 14:49:00.970317  1046 solver.cpp:222] Iteration 39760 (1.3001 iter/s, 30.7668s/40 iters), loss = 1.45989
I1030 14:49:00.970480  1046 solver.cpp:241]     Train net output #0: loss = 1.45989 (* 1 = 1.45989 loss)
I1030 14:49:00.970499  1046 sgd_solver.cpp:105] Iteration 39760, lr = 7.22898e-05
I1030 14:49:32.241595  1046 solver.cpp:222] Iteration 39800 (1.27918 iter/s, 31.2699s/40 iters), loss = 1.73971
I1030 14:49:32.241770  1046 solver.cpp:241]     Train net output #0: loss = 1.73971 (* 1 = 1.73971 loss)
I1030 14:49:32.241787  1046 sgd_solver.cpp:105] Iteration 39800, lr = 7.19322e-05
I1030 14:50:02.997135  1046 solver.cpp:222] Iteration 39840 (1.30063 iter/s, 30.7542s/40 iters), loss = 1.27798
I1030 14:50:02.997334  1046 solver.cpp:241]     Train net output #0: loss = 1.27798 (* 1 = 1.27798 loss)
I1030 14:50:02.997351  1046 sgd_solver.cpp:105] Iteration 39840, lr = 7.15763e-05
I1030 14:50:33.828160  1046 solver.cpp:222] Iteration 39880 (1.29745 iter/s, 30.8297s/40 iters), loss = 1.6202
I1030 14:50:33.828464  1046 solver.cpp:241]     Train net output #0: loss = 1.6202 (* 1 = 1.6202 loss)
I1030 14:50:33.828481  1046 sgd_solver.cpp:105] Iteration 39880, lr = 7.12222e-05
I1030 14:51:04.884203  1046 solver.cpp:222] Iteration 39920 (1.28806 iter/s, 31.0546s/40 iters), loss = 1.03404
I1030 14:51:04.884409  1046 solver.cpp:241]     Train net output #0: loss = 1.03404 (* 1 = 1.03404 loss)
I1030 14:51:04.884426  1046 sgd_solver.cpp:105] Iteration 39920, lr = 7.08699e-05
I1030 14:51:35.728494  1046 solver.cpp:222] Iteration 39960 (1.29689 iter/s, 30.8429s/40 iters), loss = 1.31132
I1030 14:51:35.728694  1046 solver.cpp:241]     Train net output #0: loss = 1.31132 (* 1 = 1.31132 loss)
I1030 14:51:35.728713  1046 sgd_solver.cpp:105] Iteration 39960, lr = 7.05193e-05
I1030 14:52:06.230481  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_40000.caffemodel
I1030 14:52:06.277015  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_40000.solverstate
I1030 14:52:06.301971  1046 solver.cpp:334] Iteration 40000, Testing net (#0)
I1030 14:52:37.378675  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58868
I1030 14:52:37.378842  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.80984
I1030 14:52:37.378857  1046 solver.cpp:401]     Test net output #2: loss = 1.83261 (* 1 = 1.83261 loss)
I1030 14:52:38.141935  1046 solver.cpp:222] Iteration 40000 (0.640913 iter/s, 62.4109s/40 iters), loss = 1.03782
I1030 14:52:38.141999  1046 solver.cpp:241]     Train net output #0: loss = 1.03782 (* 1 = 1.03782 loss)
I1030 14:52:38.142014  1046 sgd_solver.cpp:105] Iteration 40000, lr = 7.01704e-05
I1030 14:53:03.337498  1096 data_layer.cpp:73] Restarting data prefetching from start.
I1030 14:53:09.343458  1046 solver.cpp:222] Iteration 40040 (1.28204 iter/s, 31.2003s/40 iters), loss = 1.55016
I1030 14:53:09.343701  1046 solver.cpp:241]     Train net output #0: loss = 1.55016 (* 1 = 1.55016 loss)
I1030 14:53:09.343721  1046 sgd_solver.cpp:105] Iteration 40040, lr = 6.98232e-05
I1030 14:53:39.951468  1046 solver.cpp:222] Iteration 40080 (1.30691 iter/s, 30.6066s/40 iters), loss = 1.50224
I1030 14:53:39.951647  1046 solver.cpp:241]     Train net output #0: loss = 1.50224 (* 1 = 1.50224 loss)
I1030 14:53:39.951664  1046 sgd_solver.cpp:105] Iteration 40080, lr = 6.94778e-05
I1030 14:54:10.552716  1046 solver.cpp:222] Iteration 40120 (1.30719 iter/s, 30.5999s/40 iters), loss = 1.60638
I1030 14:54:10.552911  1046 solver.cpp:241]     Train net output #0: loss = 1.60638 (* 1 = 1.60638 loss)
I1030 14:54:10.552928  1046 sgd_solver.cpp:105] Iteration 40120, lr = 6.91341e-05
I1030 14:54:41.502866  1046 solver.cpp:222] Iteration 40160 (1.29246 iter/s, 30.9488s/40 iters), loss = 1.17602
I1030 14:54:41.503065  1046 solver.cpp:241]     Train net output #0: loss = 1.17602 (* 1 = 1.17602 loss)
I1030 14:54:41.503082  1046 sgd_solver.cpp:105] Iteration 40160, lr = 6.87921e-05
I1030 14:55:12.037508  1046 solver.cpp:222] Iteration 40200 (1.31005 iter/s, 30.5333s/40 iters), loss = 1.76216
I1030 14:55:12.037675  1046 solver.cpp:241]     Train net output #0: loss = 1.76216 (* 1 = 1.76216 loss)
I1030 14:55:12.037698  1046 sgd_solver.cpp:105] Iteration 40200, lr = 6.84518e-05
I1030 14:55:42.838419  1046 solver.cpp:222] Iteration 40240 (1.29872 iter/s, 30.7996s/40 iters), loss = 1.68486
I1030 14:55:42.838665  1046 solver.cpp:241]     Train net output #0: loss = 1.68486 (* 1 = 1.68486 loss)
I1030 14:55:42.838692  1046 sgd_solver.cpp:105] Iteration 40240, lr = 6.81131e-05
I1030 14:56:13.580135  1046 solver.cpp:222] Iteration 40280 (1.30122 iter/s, 30.7403s/40 iters), loss = 1.26816
I1030 14:56:13.580312  1046 solver.cpp:241]     Train net output #0: loss = 1.26816 (* 1 = 1.26816 loss)
I1030 14:56:13.580329  1046 sgd_solver.cpp:105] Iteration 40280, lr = 6.77762e-05
I1030 14:56:44.279891  1046 solver.cpp:222] Iteration 40320 (1.303 iter/s, 30.6984s/40 iters), loss = 1.50783
I1030 14:56:44.280107  1046 solver.cpp:241]     Train net output #0: loss = 1.50783 (* 1 = 1.50783 loss)
I1030 14:56:44.280124  1046 sgd_solver.cpp:105] Iteration 40320, lr = 6.74409e-05
I1030 14:57:15.263624  1046 solver.cpp:222] Iteration 40360 (1.29106 iter/s, 30.9823s/40 iters), loss = 1.2769
I1030 14:57:15.263785  1046 solver.cpp:241]     Train net output #0: loss = 1.2769 (* 1 = 1.2769 loss)
I1030 14:57:15.263803  1046 sgd_solver.cpp:105] Iteration 40360, lr = 6.71072e-05
I1030 14:57:45.991874  1046 solver.cpp:222] Iteration 40400 (1.30179 iter/s, 30.7269s/40 iters), loss = 1.16352
I1030 14:57:45.992063  1046 solver.cpp:241]     Train net output #0: loss = 1.16352 (* 1 = 1.16352 loss)
I1030 14:57:45.992080  1046 sgd_solver.cpp:105] Iteration 40400, lr = 6.67752e-05
I1030 14:58:17.885977  1046 solver.cpp:222] Iteration 40440 (1.25421 iter/s, 31.8927s/40 iters), loss = 1.41675
I1030 14:58:17.886186  1046 solver.cpp:241]     Train net output #0: loss = 1.41675 (* 1 = 1.41675 loss)
I1030 14:58:17.886204  1046 sgd_solver.cpp:105] Iteration 40440, lr = 6.64449e-05
I1030 14:58:49.113977  1046 solver.cpp:222] Iteration 40480 (1.28096 iter/s, 31.2266s/40 iters), loss = 1.46632
I1030 14:58:49.114162  1046 solver.cpp:241]     Train net output #0: loss = 1.46632 (* 1 = 1.46632 loss)
I1030 14:58:49.114179  1046 sgd_solver.cpp:105] Iteration 40480, lr = 6.61162e-05
I1030 14:59:03.734691  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_40500.caffemodel
I1030 14:59:03.765537  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_40500.solverstate
I1030 14:59:03.781921  1046 solver.cpp:334] Iteration 40500, Testing net (#0)
I1030 14:59:34.502562  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 14:59:34.709266  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58636
I1030 14:59:34.709326  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813479
I1030 14:59:34.709355  1046 solver.cpp:401]     Test net output #2: loss = 1.83952 (* 1 = 1.83952 loss)
I1030 14:59:50.975965  1046 solver.cpp:222] Iteration 40520 (0.646627 iter/s, 61.8595s/40 iters), loss = 1.63813
I1030 14:59:50.976033  1046 solver.cpp:241]     Train net output #0: loss = 1.63813 (* 1 = 1.63813 loss)
I1030 14:59:50.976049  1046 sgd_solver.cpp:105] Iteration 40520, lr = 6.57891e-05
I1030 15:00:22.028547  1046 solver.cpp:222] Iteration 40560 (1.28819 iter/s, 31.0513s/40 iters), loss = 1.11941
I1030 15:00:22.028759  1046 solver.cpp:241]     Train net output #0: loss = 1.11941 (* 1 = 1.11941 loss)
I1030 15:00:22.028779  1046 sgd_solver.cpp:105] Iteration 40560, lr = 6.54636e-05
I1030 15:00:52.872098  1046 solver.cpp:222] Iteration 40600 (1.29693 iter/s, 30.8422s/40 iters), loss = 1.22792
I1030 15:00:52.872313  1046 solver.cpp:241]     Train net output #0: loss = 1.22792 (* 1 = 1.22792 loss)
I1030 15:00:52.872331  1046 sgd_solver.cpp:105] Iteration 40600, lr = 6.51398e-05
I1030 15:01:23.590894  1046 solver.cpp:222] Iteration 40640 (1.30219 iter/s, 30.7174s/40 iters), loss = 1.25144
I1030 15:01:23.591075  1046 solver.cpp:241]     Train net output #0: loss = 1.25144 (* 1 = 1.25144 loss)
I1030 15:01:23.591092  1046 sgd_solver.cpp:105] Iteration 40640, lr = 6.48175e-05
I1030 15:01:54.290050  1046 solver.cpp:222] Iteration 40680 (1.30302 iter/s, 30.6978s/40 iters), loss = 1.0725
I1030 15:01:54.290252  1046 solver.cpp:241]     Train net output #0: loss = 1.0725 (* 1 = 1.0725 loss)
I1030 15:01:54.290284  1046 sgd_solver.cpp:105] Iteration 40680, lr = 6.44969e-05
I1030 15:02:25.219525  1046 solver.cpp:222] Iteration 40720 (1.29332 iter/s, 30.9281s/40 iters), loss = 1.27234
I1030 15:02:25.219743  1046 solver.cpp:241]     Train net output #0: loss = 1.27234 (* 1 = 1.27234 loss)
I1030 15:02:25.219760  1046 sgd_solver.cpp:105] Iteration 40720, lr = 6.41778e-05
I1030 15:02:56.145206  1046 solver.cpp:222] Iteration 40760 (1.29348 iter/s, 30.9243s/40 iters), loss = 1.44072
I1030 15:02:56.145386  1046 solver.cpp:241]     Train net output #0: loss = 1.44072 (* 1 = 1.44072 loss)
I1030 15:02:56.145404  1046 sgd_solver.cpp:105] Iteration 40760, lr = 6.38603e-05
I1030 15:03:26.772716  1046 solver.cpp:222] Iteration 40800 (1.30607 iter/s, 30.6262s/40 iters), loss = 1.77418
I1030 15:03:26.772895  1046 solver.cpp:241]     Train net output #0: loss = 1.77418 (* 1 = 1.77418 loss)
I1030 15:03:26.772912  1046 sgd_solver.cpp:105] Iteration 40800, lr = 6.35444e-05
I1030 15:03:57.506371  1046 solver.cpp:222] Iteration 40840 (1.30156 iter/s, 30.7323s/40 iters), loss = 1.51501
I1030 15:03:57.506570  1046 solver.cpp:241]     Train net output #0: loss = 1.51501 (* 1 = 1.51501 loss)
I1030 15:03:57.506587  1046 sgd_solver.cpp:105] Iteration 40840, lr = 6.323e-05
I1030 15:04:28.195691  1046 solver.cpp:222] Iteration 40880 (1.30344 iter/s, 30.688s/40 iters), loss = 0.950452
I1030 15:04:28.195888  1046 solver.cpp:241]     Train net output #0: loss = 0.950452 (* 1 = 0.950452 loss)
I1030 15:04:28.195905  1046 sgd_solver.cpp:105] Iteration 40880, lr = 6.29172e-05
I1030 15:04:58.792001  1046 solver.cpp:222] Iteration 40920 (1.3074 iter/s, 30.595s/40 iters), loss = 1.33466
I1030 15:04:58.792214  1046 solver.cpp:241]     Train net output #0: loss = 1.33466 (* 1 = 1.33466 loss)
I1030 15:04:58.792232  1046 sgd_solver.cpp:105] Iteration 40920, lr = 6.26059e-05
I1030 15:05:29.480725  1046 solver.cpp:222] Iteration 40960 (1.30347 iter/s, 30.6874s/40 iters), loss = 1.47656
I1030 15:05:29.480921  1046 solver.cpp:241]     Train net output #0: loss = 1.47656 (* 1 = 1.47656 loss)
I1030 15:05:29.480938  1046 sgd_solver.cpp:105] Iteration 40960, lr = 6.22962e-05
I1030 15:05:59.913516  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_41000.caffemodel
I1030 15:05:59.947646  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_41000.solverstate
I1030 15:05:59.965970  1046 solver.cpp:334] Iteration 41000, Testing net (#0)
I1030 15:06:30.890152  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58808
I1030 15:06:30.890386  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81068
I1030 15:06:30.890404  1046 solver.cpp:401]     Test net output #2: loss = 1.83282 (* 1 = 1.83282 loss)
I1030 15:06:31.658243  1046 solver.cpp:222] Iteration 41000 (0.643345 iter/s, 62.175s/40 iters), loss = 1.47823
I1030 15:06:31.658308  1046 solver.cpp:241]     Train net output #0: loss = 1.47823 (* 1 = 1.47823 loss)
I1030 15:06:31.658325  1046 sgd_solver.cpp:105] Iteration 41000, lr = 6.1988e-05
I1030 15:07:03.491477  1046 solver.cpp:222] Iteration 41040 (1.2566 iter/s, 31.832s/40 iters), loss = 1.32387
I1030 15:07:03.491739  1046 solver.cpp:241]     Train net output #0: loss = 1.32387 (* 1 = 1.32387 loss)
I1030 15:07:03.491762  1046 sgd_solver.cpp:105] Iteration 41040, lr = 6.16814e-05
I1030 15:07:34.543773  1046 solver.cpp:222] Iteration 41080 (1.28821 iter/s, 31.0509s/40 iters), loss = 1.35465
I1030 15:07:34.543936  1046 solver.cpp:241]     Train net output #0: loss = 1.35465 (* 1 = 1.35465 loss)
I1030 15:07:34.543951  1046 sgd_solver.cpp:105] Iteration 41080, lr = 6.13762e-05
I1030 15:08:04.880133  1046 solver.cpp:222] Iteration 41120 (1.31861 iter/s, 30.3351s/40 iters), loss = 1.47819
I1030 15:08:04.880331  1046 solver.cpp:241]     Train net output #0: loss = 1.47819 (* 1 = 1.47819 loss)
I1030 15:08:04.880349  1046 sgd_solver.cpp:105] Iteration 41120, lr = 6.10726e-05
I1030 15:08:35.737418  1046 solver.cpp:222] Iteration 41160 (1.29635 iter/s, 30.8559s/40 iters), loss = 1.29575
I1030 15:08:35.737586  1046 solver.cpp:241]     Train net output #0: loss = 1.29575 (* 1 = 1.29575 loss)
I1030 15:08:35.737603  1046 sgd_solver.cpp:105] Iteration 41160, lr = 6.07704e-05
I1030 15:09:06.524477  1046 solver.cpp:222] Iteration 41200 (1.2993 iter/s, 30.7857s/40 iters), loss = 1.34328
I1030 15:09:06.524683  1046 solver.cpp:241]     Train net output #0: loss = 1.34328 (* 1 = 1.34328 loss)
I1030 15:09:06.524701  1046 sgd_solver.cpp:105] Iteration 41200, lr = 6.04698e-05
I1030 15:09:37.530253  1046 solver.cpp:222] Iteration 41240 (1.29014 iter/s, 31.0044s/40 iters), loss = 1.11094
I1030 15:09:37.530436  1046 solver.cpp:241]     Train net output #0: loss = 1.11094 (* 1 = 1.11094 loss)
I1030 15:09:37.530457  1046 sgd_solver.cpp:105] Iteration 41240, lr = 6.01706e-05
I1030 15:10:08.296700  1046 solver.cpp:222] Iteration 41280 (1.30018 iter/s, 30.7651s/40 iters), loss = 1.14308
I1030 15:10:08.296988  1046 solver.cpp:241]     Train net output #0: loss = 1.14308 (* 1 = 1.14308 loss)
I1030 15:10:08.297015  1046 sgd_solver.cpp:105] Iteration 41280, lr = 5.9873e-05
I1030 15:10:39.173616  1046 solver.cpp:222] Iteration 41320 (1.29553 iter/s, 30.8755s/40 iters), loss = 1.63199
I1030 15:10:39.173811  1046 solver.cpp:241]     Train net output #0: loss = 1.63199 (* 1 = 1.63199 loss)
I1030 15:10:39.173835  1046 sgd_solver.cpp:105] Iteration 41320, lr = 5.95768e-05
I1030 15:11:09.873946  1046 solver.cpp:222] Iteration 41360 (1.30298 iter/s, 30.699s/40 iters), loss = 1.4479
I1030 15:11:09.874212  1046 solver.cpp:241]     Train net output #0: loss = 1.4479 (* 1 = 1.4479 loss)
I1030 15:11:09.874238  1046 sgd_solver.cpp:105] Iteration 41360, lr = 5.9282e-05
I1030 15:11:41.078066  1046 solver.cpp:222] Iteration 41400 (1.28194 iter/s, 31.2027s/40 iters), loss = 1.44243
I1030 15:11:41.078256  1046 solver.cpp:241]     Train net output #0: loss = 1.44243 (* 1 = 1.44243 loss)
I1030 15:11:41.078276  1046 sgd_solver.cpp:105] Iteration 41400, lr = 5.89888e-05
I1030 15:12:11.812965  1046 solver.cpp:222] Iteration 41440 (1.30151 iter/s, 30.7335s/40 iters), loss = 1.36494
I1030 15:12:11.813133  1046 solver.cpp:241]     Train net output #0: loss = 1.36494 (* 1 = 1.36494 loss)
I1030 15:12:11.813150  1046 sgd_solver.cpp:105] Iteration 41440, lr = 5.86969e-05
I1030 15:12:42.409179  1046 solver.cpp:222] Iteration 41480 (1.30741 iter/s, 30.5949s/40 iters), loss = 1.47028
I1030 15:12:42.409476  1046 solver.cpp:241]     Train net output #0: loss = 1.47028 (* 1 = 1.47028 loss)
I1030 15:12:42.409507  1046 sgd_solver.cpp:105] Iteration 41480, lr = 5.84066e-05
I1030 15:12:56.393456  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_41500.caffemodel
I1030 15:12:56.426288  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_41500.solverstate
I1030 15:12:56.445413  1046 solver.cpp:334] Iteration 41500, Testing net (#0)
I1030 15:13:27.504746  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 15:13:27.711787  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58716
I1030 15:13:27.711846  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813439
I1030 15:13:27.711859  1046 solver.cpp:401]     Test net output #2: loss = 1.83559 (* 1 = 1.83559 loss)
I1030 15:13:43.461768  1046 solver.cpp:222] Iteration 41520 (0.655201 iter/s, 61.05s/40 iters), loss = 1.40472
I1030 15:13:43.461836  1046 solver.cpp:241]     Train net output #0: loss = 1.40472 (* 1 = 1.40472 loss)
I1030 15:13:43.461853  1046 sgd_solver.cpp:105] Iteration 41520, lr = 5.81176e-05
I1030 15:14:13.817507  1046 solver.cpp:222] Iteration 41560 (1.31776 iter/s, 30.3545s/40 iters), loss = 1.43595
I1030 15:14:13.817708  1046 solver.cpp:241]     Train net output #0: loss = 1.43595 (* 1 = 1.43595 loss)
I1030 15:14:13.817726  1046 sgd_solver.cpp:105] Iteration 41560, lr = 5.78301e-05
I1030 15:14:45.246987  1046 solver.cpp:222] Iteration 41600 (1.27275 iter/s, 31.4281s/40 iters), loss = 1.54089
I1030 15:14:45.247208  1046 solver.cpp:241]     Train net output #0: loss = 1.54089 (* 1 = 1.54089 loss)
I1030 15:14:45.247231  1046 sgd_solver.cpp:105] Iteration 41600, lr = 5.7544e-05
I1030 15:15:21.649262  1046 solver.cpp:222] Iteration 41640 (1.09888 iter/s, 36.4007s/40 iters), loss = 1.51166
I1030 15:15:21.649458  1046 solver.cpp:241]     Train net output #0: loss = 1.51166 (* 1 = 1.51166 loss)
I1030 15:15:21.649477  1046 sgd_solver.cpp:105] Iteration 41640, lr = 5.72593e-05
I1030 15:15:51.785676  1046 solver.cpp:222] Iteration 41680 (1.32736 iter/s, 30.1351s/40 iters), loss = 1.28325
I1030 15:15:51.785892  1046 solver.cpp:241]     Train net output #0: loss = 1.28325 (* 1 = 1.28325 loss)
I1030 15:15:51.785909  1046 sgd_solver.cpp:105] Iteration 41680, lr = 5.69761e-05
I1030 15:16:21.955283  1046 solver.cpp:222] Iteration 41720 (1.3259 iter/s, 30.1683s/40 iters), loss = 1.35213
I1030 15:16:21.955469  1046 solver.cpp:241]     Train net output #0: loss = 1.35213 (* 1 = 1.35213 loss)
I1030 15:16:21.955489  1046 sgd_solver.cpp:105] Iteration 41720, lr = 5.66942e-05
I1030 15:16:52.500171  1046 solver.cpp:222] Iteration 41760 (1.30961 iter/s, 30.5436s/40 iters), loss = 1.40662
I1030 15:16:52.500337  1046 solver.cpp:241]     Train net output #0: loss = 1.40662 (* 1 = 1.40662 loss)
I1030 15:16:52.500353  1046 sgd_solver.cpp:105] Iteration 41760, lr = 5.64137e-05
I1030 15:17:22.476758  1046 solver.cpp:222] Iteration 41800 (1.33443 iter/s, 29.9753s/40 iters), loss = 1.72229
I1030 15:17:22.476824  1046 solver.cpp:241]     Train net output #0: loss = 1.72229 (* 1 = 1.72229 loss)
I1030 15:17:22.476838  1046 sgd_solver.cpp:105] Iteration 41800, lr = 5.61346e-05
I1030 15:17:52.838279  1046 solver.cpp:222] Iteration 41840 (1.31751 iter/s, 30.3603s/40 iters), loss = 1.06149
I1030 15:17:52.838485  1046 solver.cpp:241]     Train net output #0: loss = 1.06149 (* 1 = 1.06149 loss)
I1030 15:17:52.838502  1046 sgd_solver.cpp:105] Iteration 41840, lr = 5.58569e-05
I1030 15:18:24.248474  1046 solver.cpp:222] Iteration 41880 (1.27353 iter/s, 31.4088s/40 iters), loss = 1.43822
I1030 15:18:24.248658  1046 solver.cpp:241]     Train net output #0: loss = 1.43822 (* 1 = 1.43822 loss)
I1030 15:18:24.248674  1046 sgd_solver.cpp:105] Iteration 41880, lr = 5.55806e-05
I1030 15:18:54.916268  1046 solver.cpp:222] Iteration 41920 (1.30436 iter/s, 30.6664s/40 iters), loss = 1.02071
I1030 15:18:54.916505  1046 solver.cpp:241]     Train net output #0: loss = 1.02071 (* 1 = 1.02071 loss)
I1030 15:18:54.916530  1046 sgd_solver.cpp:105] Iteration 41920, lr = 5.53056e-05
I1030 15:19:26.567154  1046 solver.cpp:222] Iteration 41960 (1.26384 iter/s, 31.6495s/40 iters), loss = 1.37566
I1030 15:19:26.567395  1046 solver.cpp:241]     Train net output #0: loss = 1.37566 (* 1 = 1.37566 loss)
I1030 15:19:26.567414  1046 sgd_solver.cpp:105] Iteration 41960, lr = 5.5032e-05
I1030 15:19:57.354140  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_42000.caffemodel
I1030 15:19:57.406998  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_42000.solverstate
I1030 15:19:57.436060  1046 solver.cpp:334] Iteration 42000, Testing net (#0)
I1030 15:20:29.263950  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58896
I1030 15:20:29.264128  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.810359
I1030 15:20:29.264144  1046 solver.cpp:401]     Test net output #2: loss = 1.83168 (* 1 = 1.83168 loss)
I1030 15:20:30.025316  1046 solver.cpp:222] Iteration 42000 (0.630363 iter/s, 63.4555s/40 iters), loss = 1.43085
I1030 15:20:30.025378  1046 solver.cpp:241]     Train net output #0: loss = 1.43085 (* 1 = 1.43085 loss)
I1030 15:20:30.025393  1046 sgd_solver.cpp:105] Iteration 42000, lr = 5.47598e-05
I1030 15:21:00.894943  1046 solver.cpp:222] Iteration 42040 (1.29582 iter/s, 30.8684s/40 iters), loss = 1.30238
I1030 15:21:00.895117  1046 solver.cpp:241]     Train net output #0: loss = 1.30238 (* 1 = 1.30238 loss)
I1030 15:21:00.895134  1046 sgd_solver.cpp:105] Iteration 42040, lr = 5.44889e-05
I1030 15:21:31.308722  1046 solver.cpp:222] Iteration 42080 (1.31525 iter/s, 30.4125s/40 iters), loss = 1.45676
I1030 15:21:31.308905  1046 solver.cpp:241]     Train net output #0: loss = 1.45676 (* 1 = 1.45676 loss)
I1030 15:21:31.308923  1046 sgd_solver.cpp:105] Iteration 42080, lr = 5.42193e-05
I1030 15:22:01.952563  1046 solver.cpp:222] Iteration 42120 (1.30538 iter/s, 30.6425s/40 iters), loss = 1.31542
I1030 15:22:01.952728  1046 solver.cpp:241]     Train net output #0: loss = 1.31542 (* 1 = 1.31542 loss)
I1030 15:22:01.952744  1046 sgd_solver.cpp:105] Iteration 42120, lr = 5.39511e-05
I1030 15:22:32.787387  1046 solver.cpp:222] Iteration 42160 (1.29729 iter/s, 30.8335s/40 iters), loss = 1.50623
I1030 15:22:32.787575  1046 solver.cpp:241]     Train net output #0: loss = 1.50623 (* 1 = 1.50623 loss)
I1030 15:22:32.787590  1046 sgd_solver.cpp:105] Iteration 42160, lr = 5.36842e-05
I1030 15:23:03.821822  1046 solver.cpp:222] Iteration 42200 (1.28895 iter/s, 31.0331s/40 iters), loss = 1.52472
I1030 15:23:03.822021  1046 solver.cpp:241]     Train net output #0: loss = 1.52472 (* 1 = 1.52472 loss)
I1030 15:23:03.822039  1046 sgd_solver.cpp:105] Iteration 42200, lr = 5.34186e-05
I1030 15:23:34.412391  1046 solver.cpp:222] Iteration 42240 (1.30765 iter/s, 30.5892s/40 iters), loss = 1.51681
I1030 15:23:34.412595  1046 solver.cpp:241]     Train net output #0: loss = 1.51681 (* 1 = 1.51681 loss)
I1030 15:23:34.412613  1046 sgd_solver.cpp:105] Iteration 42240, lr = 5.31543e-05
I1030 15:24:05.337072  1046 solver.cpp:222] Iteration 42280 (1.29352 iter/s, 30.9233s/40 iters), loss = 1.44637
I1030 15:24:05.337255  1046 solver.cpp:241]     Train net output #0: loss = 1.44637 (* 1 = 1.44637 loss)
I1030 15:24:05.337280  1046 sgd_solver.cpp:105] Iteration 42280, lr = 5.28914e-05
I1030 15:24:36.335891  1046 solver.cpp:222] Iteration 42320 (1.29043 iter/s, 30.9975s/40 iters), loss = 1.29425
I1030 15:24:36.336107  1046 solver.cpp:241]     Train net output #0: loss = 1.29425 (* 1 = 1.29425 loss)
I1030 15:24:36.336134  1046 sgd_solver.cpp:105] Iteration 42320, lr = 5.26297e-05
I1030 15:25:07.155629  1046 solver.cpp:222] Iteration 42360 (1.29793 iter/s, 30.8184s/40 iters), loss = 1.34449
I1030 15:25:07.155797  1046 solver.cpp:241]     Train net output #0: loss = 1.34449 (* 1 = 1.34449 loss)
I1030 15:25:07.155814  1046 sgd_solver.cpp:105] Iteration 42360, lr = 5.23693e-05
I1030 15:25:38.065138  1046 solver.cpp:222] Iteration 42400 (1.29416 iter/s, 30.9082s/40 iters), loss = 1.36181
I1030 15:25:38.065407  1046 solver.cpp:241]     Train net output #0: loss = 1.36181 (* 1 = 1.36181 loss)
I1030 15:25:38.065428  1046 sgd_solver.cpp:105] Iteration 42400, lr = 5.21102e-05
I1030 15:26:08.416152  1046 solver.cpp:222] Iteration 42440 (1.31797 iter/s, 30.3496s/40 iters), loss = 1.3599
I1030 15:26:08.416368  1046 solver.cpp:241]     Train net output #0: loss = 1.3599 (* 1 = 1.3599 loss)
I1030 15:26:08.416386  1046 sgd_solver.cpp:105] Iteration 42440, lr = 5.18525e-05
I1030 15:26:38.943838  1046 solver.cpp:222] Iteration 42480 (1.31034 iter/s, 30.5263s/40 iters), loss = 1.36844
I1030 15:26:38.944026  1046 solver.cpp:241]     Train net output #0: loss = 1.36844 (* 1 = 1.36844 loss)
I1030 15:26:38.944044  1046 sgd_solver.cpp:105] Iteration 42480, lr = 5.15959e-05
I1030 15:26:53.312542  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_42500.caffemodel
I1030 15:26:53.345975  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_42500.solverstate
I1030 15:26:53.365180  1046 solver.cpp:334] Iteration 42500, Testing net (#0)
I1030 15:27:24.139307  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 15:27:24.348909  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.587
I1030 15:27:24.348973  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813559
I1030 15:27:24.348986  1046 solver.cpp:401]     Test net output #2: loss = 1.83698 (* 1 = 1.83698 loss)
I1030 15:27:40.400641  1046 solver.cpp:222] Iteration 42520 (0.65089 iter/s, 61.4543s/40 iters), loss = 1.44459
I1030 15:27:40.400709  1046 solver.cpp:241]     Train net output #0: loss = 1.44459 (* 1 = 1.44459 loss)
I1030 15:27:40.400724  1046 sgd_solver.cpp:105] Iteration 42520, lr = 5.13407e-05
I1030 15:27:51.496527  1096 data_layer.cpp:73] Restarting data prefetching from start.
I1030 15:28:11.886052  1046 solver.cpp:222] Iteration 42560 (1.27048 iter/s, 31.4842s/40 iters), loss = 1.28473
I1030 15:28:11.886301  1046 solver.cpp:241]     Train net output #0: loss = 1.28473 (* 1 = 1.28473 loss)
I1030 15:28:11.886327  1046 sgd_solver.cpp:105] Iteration 42560, lr = 5.10867e-05
I1030 15:28:42.954113  1046 solver.cpp:222] Iteration 42600 (1.28755 iter/s, 31.0667s/40 iters), loss = 1.29864
I1030 15:28:42.954300  1046 solver.cpp:241]     Train net output #0: loss = 1.29864 (* 1 = 1.29864 loss)
I1030 15:28:42.954319  1046 sgd_solver.cpp:105] Iteration 42600, lr = 5.0834e-05
I1030 15:29:13.257412  1046 solver.cpp:222] Iteration 42640 (1.32005 iter/s, 30.302s/40 iters), loss = 1.42997
I1030 15:29:13.257614  1046 solver.cpp:241]     Train net output #0: loss = 1.42997 (* 1 = 1.42997 loss)
I1030 15:29:13.257634  1046 sgd_solver.cpp:105] Iteration 42640, lr = 5.05825e-05
I1030 15:29:43.440420  1046 solver.cpp:222] Iteration 42680 (1.32531 iter/s, 30.1817s/40 iters), loss = 1.44446
I1030 15:29:43.440549  1046 solver.cpp:241]     Train net output #0: loss = 1.44446 (* 1 = 1.44446 loss)
I1030 15:29:43.440568  1046 sgd_solver.cpp:105] Iteration 42680, lr = 5.03322e-05
I1030 15:30:13.656908  1046 solver.cpp:222] Iteration 42720 (1.32384 iter/s, 30.2152s/40 iters), loss = 1.36054
I1030 15:30:13.657105  1046 solver.cpp:241]     Train net output #0: loss = 1.36054 (* 1 = 1.36054 loss)
I1030 15:30:13.657126  1046 sgd_solver.cpp:105] Iteration 42720, lr = 5.00832e-05
I1030 15:30:43.969259  1046 solver.cpp:222] Iteration 42760 (1.31965 iter/s, 30.311s/40 iters), loss = 1.29936
I1030 15:30:43.969429  1046 solver.cpp:241]     Train net output #0: loss = 1.29936 (* 1 = 1.29936 loss)
I1030 15:30:43.969451  1046 sgd_solver.cpp:105] Iteration 42760, lr = 4.98355e-05
I1030 15:31:14.988186  1046 solver.cpp:222] Iteration 42800 (1.28959 iter/s, 31.0176s/40 iters), loss = 1.19682
I1030 15:31:14.988458  1046 solver.cpp:241]     Train net output #0: loss = 1.19682 (* 1 = 1.19682 loss)
I1030 15:31:14.988489  1046 sgd_solver.cpp:105] Iteration 42800, lr = 4.95889e-05
I1030 15:31:47.491015  1046 solver.cpp:222] Iteration 42840 (1.23072 iter/s, 32.5013s/40 iters), loss = 1.27235
I1030 15:31:47.491320  1046 solver.cpp:241]     Train net output #0: loss = 1.27235 (* 1 = 1.27235 loss)
I1030 15:31:47.491348  1046 sgd_solver.cpp:105] Iteration 42840, lr = 4.93436e-05
I1030 15:32:19.639423  1046 solver.cpp:222] Iteration 42880 (1.24429 iter/s, 32.1469s/40 iters), loss = 1.58076
I1030 15:32:19.639771  1046 solver.cpp:241]     Train net output #0: loss = 1.58076 (* 1 = 1.58076 loss)
I1030 15:32:19.639814  1046 sgd_solver.cpp:105] Iteration 42880, lr = 4.90995e-05
I1030 15:32:51.170547  1046 solver.cpp:222] Iteration 42920 (1.26865 iter/s, 31.5296s/40 iters), loss = 1.27049
I1030 15:32:51.170753  1046 solver.cpp:241]     Train net output #0: loss = 1.27049 (* 1 = 1.27049 loss)
I1030 15:32:51.170771  1046 sgd_solver.cpp:105] Iteration 42920, lr = 4.88566e-05
I1030 15:33:22.043984  1046 solver.cpp:222] Iteration 42960 (1.29567 iter/s, 30.8721s/40 iters), loss = 1.13046
I1030 15:33:22.044185  1046 solver.cpp:241]     Train net output #0: loss = 1.13046 (* 1 = 1.13046 loss)
I1030 15:33:22.044203  1046 sgd_solver.cpp:105] Iteration 42960, lr = 4.86149e-05
I1030 15:33:52.354588  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_43000.caffemodel
I1030 15:33:52.396119  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_43000.solverstate
I1030 15:33:52.413183  1046 solver.cpp:334] Iteration 43000, Testing net (#0)
I1030 15:34:23.347910  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58832
I1030 15:34:23.348069  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81056
I1030 15:34:23.348085  1046 solver.cpp:401]     Test net output #2: loss = 1.83585 (* 1 = 1.83585 loss)
I1030 15:34:24.110146  1046 solver.cpp:222] Iteration 43000 (0.6445 iter/s, 62.0636s/40 iters), loss = 1.36526
I1030 15:34:24.110205  1046 solver.cpp:241]     Train net output #0: loss = 1.36526 (* 1 = 1.36526 loss)
I1030 15:34:24.110225  1046 sgd_solver.cpp:105] Iteration 43000, lr = 4.83744e-05
I1030 15:34:54.890673  1046 solver.cpp:222] Iteration 43040 (1.29957 iter/s, 30.7793s/40 iters), loss = 1.22566
I1030 15:34:54.890862  1046 solver.cpp:241]     Train net output #0: loss = 1.22566 (* 1 = 1.22566 loss)
I1030 15:34:54.890880  1046 sgd_solver.cpp:105] Iteration 43040, lr = 4.81351e-05
I1030 15:35:25.855754  1046 solver.cpp:222] Iteration 43080 (1.29184 iter/s, 30.9637s/40 iters), loss = 1.69763
I1030 15:35:25.855990  1046 solver.cpp:241]     Train net output #0: loss = 1.69763 (* 1 = 1.69763 loss)
I1030 15:35:25.856017  1046 sgd_solver.cpp:105] Iteration 43080, lr = 4.78969e-05
I1030 15:35:57.492163  1046 solver.cpp:222] Iteration 43120 (1.26442 iter/s, 31.635s/40 iters), loss = 1.17115
I1030 15:35:57.492401  1046 solver.cpp:241]     Train net output #0: loss = 1.17115 (* 1 = 1.17115 loss)
I1030 15:35:57.492419  1046 sgd_solver.cpp:105] Iteration 43120, lr = 4.766e-05
I1030 15:36:30.104462  1046 solver.cpp:222] Iteration 43160 (1.22659 iter/s, 32.6108s/40 iters), loss = 1.42944
I1030 15:36:30.104707  1046 solver.cpp:241]     Train net output #0: loss = 1.42944 (* 1 = 1.42944 loss)
I1030 15:36:30.104743  1046 sgd_solver.cpp:105] Iteration 43160, lr = 4.74242e-05
I1030 15:37:03.713708  1046 solver.cpp:222] Iteration 43200 (1.1902 iter/s, 33.6077s/40 iters), loss = 1.50202
I1030 15:37:03.713925  1046 solver.cpp:241]     Train net output #0: loss = 1.50202 (* 1 = 1.50202 loss)
I1030 15:37:03.713943  1046 sgd_solver.cpp:105] Iteration 43200, lr = 4.71896e-05
I1030 15:37:34.740703  1046 solver.cpp:222] Iteration 43240 (1.28926 iter/s, 31.0256s/40 iters), loss = 1.69951
I1030 15:37:34.740886  1046 solver.cpp:241]     Train net output #0: loss = 1.69951 (* 1 = 1.69951 loss)
I1030 15:37:34.740903  1046 sgd_solver.cpp:105] Iteration 43240, lr = 4.69561e-05
I1030 15:38:05.133478  1046 solver.cpp:222] Iteration 43280 (1.31616 iter/s, 30.3914s/40 iters), loss = 1.17941
I1030 15:38:05.133726  1046 solver.cpp:241]     Train net output #0: loss = 1.17941 (* 1 = 1.17941 loss)
I1030 15:38:05.133755  1046 sgd_solver.cpp:105] Iteration 43280, lr = 4.67238e-05
I1030 15:38:35.627194  1046 solver.cpp:222] Iteration 43320 (1.31181 iter/s, 30.4923s/40 iters), loss = 1.59545
I1030 15:38:35.627382  1046 solver.cpp:241]     Train net output #0: loss = 1.59545 (* 1 = 1.59545 loss)
I1030 15:38:35.627398  1046 sgd_solver.cpp:105] Iteration 43320, lr = 4.64927e-05
I1030 15:39:06.078583  1046 solver.cpp:222] Iteration 43360 (1.31363 iter/s, 30.45s/40 iters), loss = 1.52194
I1030 15:39:06.078754  1046 solver.cpp:241]     Train net output #0: loss = 1.52194 (* 1 = 1.52194 loss)
I1030 15:39:06.078770  1046 sgd_solver.cpp:105] Iteration 43360, lr = 4.62627e-05
I1030 15:39:36.454288  1046 solver.cpp:222] Iteration 43400 (1.3169 iter/s, 30.3744s/40 iters), loss = 1.31924
I1030 15:39:36.454464  1046 solver.cpp:241]     Train net output #0: loss = 1.31924 (* 1 = 1.31924 loss)
I1030 15:39:36.454483  1046 sgd_solver.cpp:105] Iteration 43400, lr = 4.60338e-05
I1030 15:40:07.174923  1046 solver.cpp:222] Iteration 43440 (1.30211 iter/s, 30.7193s/40 iters), loss = 1.52462
I1030 15:40:07.175117  1046 solver.cpp:241]     Train net output #0: loss = 1.52462 (* 1 = 1.52462 loss)
I1030 15:40:07.175134  1046 sgd_solver.cpp:105] Iteration 43440, lr = 4.58061e-05
I1030 15:40:37.771440  1046 solver.cpp:222] Iteration 43480 (1.3074 iter/s, 30.5952s/40 iters), loss = 1.48984
I1030 15:40:37.771612  1046 solver.cpp:241]     Train net output #0: loss = 1.48984 (* 1 = 1.48984 loss)
I1030 15:40:37.771631  1046 sgd_solver.cpp:105] Iteration 43480, lr = 4.55795e-05
I1030 15:40:52.241468  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_43500.caffemodel
I1030 15:40:52.272895  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_43500.solverstate
I1030 15:40:52.293948  1046 solver.cpp:334] Iteration 43500, Testing net (#0)
I1030 15:41:23.012610  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 15:41:23.220662  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5864
I1030 15:41:23.220721  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813879
I1030 15:41:23.220736  1046 solver.cpp:401]     Test net output #2: loss = 1.83699 (* 1 = 1.83699 loss)
I1030 15:41:39.127701  1046 solver.cpp:222] Iteration 43520 (0.651956 iter/s, 61.3538s/40 iters), loss = 1.57188
I1030 15:41:39.127768  1046 solver.cpp:241]     Train net output #0: loss = 1.57188 (* 1 = 1.57188 loss)
I1030 15:41:39.127784  1046 sgd_solver.cpp:105] Iteration 43520, lr = 4.5354e-05
I1030 15:42:09.469882  1046 solver.cpp:222] Iteration 43560 (1.31835 iter/s, 30.341s/40 iters), loss = 1.27888
I1030 15:42:09.470036  1046 solver.cpp:241]     Train net output #0: loss = 1.27888 (* 1 = 1.27888 loss)
I1030 15:42:09.470053  1046 sgd_solver.cpp:105] Iteration 43560, lr = 4.51296e-05
I1030 15:42:40.611349  1046 solver.cpp:222] Iteration 43600 (1.28452 iter/s, 31.1401s/40 iters), loss = 1.27245
I1030 15:42:40.611536  1046 solver.cpp:241]     Train net output #0: loss = 1.27245 (* 1 = 1.27245 loss)
I1030 15:42:40.611552  1046 sgd_solver.cpp:105] Iteration 43600, lr = 4.49064e-05
I1030 15:43:11.913259  1046 solver.cpp:222] Iteration 43640 (1.27793 iter/s, 31.3005s/40 iters), loss = 1.37796
I1030 15:43:11.913439  1046 solver.cpp:241]     Train net output #0: loss = 1.37796 (* 1 = 1.37796 loss)
I1030 15:43:11.913456  1046 sgd_solver.cpp:105] Iteration 43640, lr = 4.46842e-05
I1030 15:43:42.580564  1046 solver.cpp:222] Iteration 43680 (1.30438 iter/s, 30.666s/40 iters), loss = 1.24445
I1030 15:43:42.580739  1046 solver.cpp:241]     Train net output #0: loss = 1.24445 (* 1 = 1.24445 loss)
I1030 15:43:42.580759  1046 sgd_solver.cpp:105] Iteration 43680, lr = 4.44631e-05
I1030 15:44:12.889567  1046 solver.cpp:222] Iteration 43720 (1.3198 iter/s, 30.3077s/40 iters), loss = 1.3979
I1030 15:44:12.889744  1046 solver.cpp:241]     Train net output #0: loss = 1.3979 (* 1 = 1.3979 loss)
I1030 15:44:12.889760  1046 sgd_solver.cpp:105] Iteration 43720, lr = 4.42432e-05
I1030 15:44:43.284404  1046 solver.cpp:222] Iteration 43760 (1.31607 iter/s, 30.3935s/40 iters), loss = 1.24204
I1030 15:44:43.284644  1046 solver.cpp:241]     Train net output #0: loss = 1.24204 (* 1 = 1.24204 loss)
I1030 15:44:43.284663  1046 sgd_solver.cpp:105] Iteration 43760, lr = 4.40243e-05
I1030 15:45:13.801432  1046 solver.cpp:222] Iteration 43800 (1.3108 iter/s, 30.5156s/40 iters), loss = 1.57912
I1030 15:45:13.801627  1046 solver.cpp:241]     Train net output #0: loss = 1.57912 (* 1 = 1.57912 loss)
I1030 15:45:13.801645  1046 sgd_solver.cpp:105] Iteration 43800, lr = 4.38065e-05
I1030 15:45:44.263025  1046 solver.cpp:222] Iteration 43840 (1.31319 iter/s, 30.4603s/40 iters), loss = 1.55689
I1030 15:45:44.263216  1046 solver.cpp:241]     Train net output #0: loss = 1.55689 (* 1 = 1.55689 loss)
I1030 15:45:44.263236  1046 sgd_solver.cpp:105] Iteration 43840, lr = 4.35898e-05
I1030 15:46:15.862498  1046 solver.cpp:222] Iteration 43880 (1.2659 iter/s, 31.5981s/40 iters), loss = 1.50636
I1030 15:46:15.862697  1046 solver.cpp:241]     Train net output #0: loss = 1.50636 (* 1 = 1.50636 loss)
I1030 15:46:15.862716  1046 sgd_solver.cpp:105] Iteration 43880, lr = 4.33741e-05
I1030 15:46:47.731463  1046 solver.cpp:222] Iteration 43920 (1.25519 iter/s, 31.8676s/40 iters), loss = 1.63692
I1030 15:46:47.731647  1046 solver.cpp:241]     Train net output #0: loss = 1.63692 (* 1 = 1.63692 loss)
I1030 15:46:47.731664  1046 sgd_solver.cpp:105] Iteration 43920, lr = 4.31596e-05
I1030 15:47:18.788421  1046 solver.cpp:222] Iteration 43960 (1.28801 iter/s, 31.0556s/40 iters), loss = 1.34165
I1030 15:47:18.788631  1046 solver.cpp:241]     Train net output #0: loss = 1.34165 (* 1 = 1.34165 loss)
I1030 15:47:18.788650  1046 sgd_solver.cpp:105] Iteration 43960, lr = 4.2946e-05
I1030 15:47:54.253268  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_44000.caffemodel
I1030 15:47:54.305261  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_44000.solverstate
I1030 15:47:54.329391  1046 solver.cpp:334] Iteration 44000, Testing net (#0)
I1030 15:48:25.880399  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58844
I1030 15:48:25.880589  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81044
I1030 15:48:25.880605  1046 solver.cpp:401]     Test net output #2: loss = 1.83273 (* 1 = 1.83273 loss)
I1030 15:48:26.630532  1046 solver.cpp:222] Iteration 44000 (0.589628 iter/s, 67.8394s/40 iters), loss = 1.26527
I1030 15:48:26.630600  1046 solver.cpp:241]     Train net output #0: loss = 1.26527 (* 1 = 1.26527 loss)
I1030 15:48:26.630616  1046 sgd_solver.cpp:105] Iteration 44000, lr = 4.27336e-05
I1030 15:48:57.087720  1046 solver.cpp:222] Iteration 44040 (1.31337 iter/s, 30.456s/40 iters), loss = 1.31542
I1030 15:48:57.087935  1046 solver.cpp:241]     Train net output #0: loss = 1.31542 (* 1 = 1.31542 loss)
I1030 15:48:57.087954  1046 sgd_solver.cpp:105] Iteration 44040, lr = 4.25222e-05
I1030 15:49:28.487493  1046 solver.cpp:222] Iteration 44080 (1.27395 iter/s, 31.3984s/40 iters), loss = 1.24687
I1030 15:49:28.487679  1046 solver.cpp:241]     Train net output #0: loss = 1.24687 (* 1 = 1.24687 loss)
I1030 15:49:28.487695  1046 sgd_solver.cpp:105] Iteration 44080, lr = 4.23118e-05
I1030 15:49:59.797088  1046 solver.cpp:222] Iteration 44120 (1.27762 iter/s, 31.3082s/40 iters), loss = 1.28829
I1030 15:49:59.797276  1046 solver.cpp:241]     Train net output #0: loss = 1.28829 (* 1 = 1.28829 loss)
I1030 15:49:59.797292  1046 sgd_solver.cpp:105] Iteration 44120, lr = 4.21025e-05
I1030 15:50:30.402120  1046 solver.cpp:222] Iteration 44160 (1.30703 iter/s, 30.6037s/40 iters), loss = 1.29311
I1030 15:50:30.402304  1046 solver.cpp:241]     Train net output #0: loss = 1.29311 (* 1 = 1.29311 loss)
I1030 15:50:30.402323  1046 sgd_solver.cpp:105] Iteration 44160, lr = 4.18942e-05
I1030 15:51:02.277266  1046 solver.cpp:222] Iteration 44200 (1.25495 iter/s, 31.8737s/40 iters), loss = 1.50977
I1030 15:51:02.277549  1046 solver.cpp:241]     Train net output #0: loss = 1.50977 (* 1 = 1.50977 loss)
I1030 15:51:02.277600  1046 sgd_solver.cpp:105] Iteration 44200, lr = 4.16869e-05
I1030 15:51:33.942174  1046 solver.cpp:222] Iteration 44240 (1.26329 iter/s, 31.6634s/40 iters), loss = 1.40052
I1030 15:51:33.942368  1046 solver.cpp:241]     Train net output #0: loss = 1.40052 (* 1 = 1.40052 loss)
I1030 15:51:33.942384  1046 sgd_solver.cpp:105] Iteration 44240, lr = 4.14807e-05
I1030 15:52:05.192384  1046 solver.cpp:222] Iteration 44280 (1.28005 iter/s, 31.2488s/40 iters), loss = 1.17119
I1030 15:52:05.192601  1046 solver.cpp:241]     Train net output #0: loss = 1.17119 (* 1 = 1.17119 loss)
I1030 15:52:05.192617  1046 sgd_solver.cpp:105] Iteration 44280, lr = 4.12755e-05
I1030 15:52:36.094265  1046 solver.cpp:222] Iteration 44320 (1.29448 iter/s, 30.9005s/40 iters), loss = 1.43648
I1030 15:52:36.094460  1046 solver.cpp:241]     Train net output #0: loss = 1.43648 (* 1 = 1.43648 loss)
I1030 15:52:36.094478  1046 sgd_solver.cpp:105] Iteration 44320, lr = 4.10713e-05
I1030 15:53:06.872769  1046 solver.cpp:222] Iteration 44360 (1.29967 iter/s, 30.7771s/40 iters), loss = 1.31021
I1030 15:53:06.872954  1046 solver.cpp:241]     Train net output #0: loss = 1.31021 (* 1 = 1.31021 loss)
I1030 15:53:06.872973  1046 sgd_solver.cpp:105] Iteration 44360, lr = 4.08681e-05
I1030 15:53:37.629827  1046 solver.cpp:222] Iteration 44400 (1.30057 iter/s, 30.7557s/40 iters), loss = 1.73536
I1030 15:53:37.630008  1046 solver.cpp:241]     Train net output #0: loss = 1.73536 (* 1 = 1.73536 loss)
I1030 15:53:37.630024  1046 sgd_solver.cpp:105] Iteration 44400, lr = 4.06659e-05
I1030 15:54:08.229881  1046 solver.cpp:222] Iteration 44440 (1.30724 iter/s, 30.5987s/40 iters), loss = 1.69399
I1030 15:54:08.230069  1046 solver.cpp:241]     Train net output #0: loss = 1.69399 (* 1 = 1.69399 loss)
I1030 15:54:08.230085  1046 sgd_solver.cpp:105] Iteration 44440, lr = 4.04648e-05
I1030 15:54:39.341351  1046 solver.cpp:222] Iteration 44480 (1.28576 iter/s, 31.1101s/40 iters), loss = 1.23391
I1030 15:54:39.341547  1046 solver.cpp:241]     Train net output #0: loss = 1.23391 (* 1 = 1.23391 loss)
I1030 15:54:39.341564  1046 sgd_solver.cpp:105] Iteration 44480, lr = 4.02646e-05
I1030 15:54:54.390228  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_44500.caffemodel
I1030 15:54:54.424826  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_44500.solverstate
I1030 15:54:54.446193  1046 solver.cpp:334] Iteration 44500, Testing net (#0)
I1030 15:55:25.499609  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 15:55:25.706866  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5872
I1030 15:55:25.706930  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813319
I1030 15:55:25.706944  1046 solver.cpp:401]     Test net output #2: loss = 1.83561 (* 1 = 1.83561 loss)
I1030 15:55:42.018199  1046 solver.cpp:222] Iteration 44520 (0.63822 iter/s, 62.6743s/40 iters), loss = 1.32724
I1030 15:55:42.018267  1046 solver.cpp:241]     Train net output #0: loss = 1.32724 (* 1 = 1.32724 loss)
I1030 15:55:42.018282  1046 sgd_solver.cpp:105] Iteration 44520, lr = 4.00654e-05
I1030 15:56:13.144517  1046 solver.cpp:222] Iteration 44560 (1.28514 iter/s, 31.1251s/40 iters), loss = 1.31752
I1030 15:56:13.144716  1046 solver.cpp:241]     Train net output #0: loss = 1.31752 (* 1 = 1.31752 loss)
I1030 15:56:13.144734  1046 sgd_solver.cpp:105] Iteration 44560, lr = 3.98672e-05
I1030 15:56:43.657611  1046 solver.cpp:222] Iteration 44600 (1.31097 iter/s, 30.5117s/40 iters), loss = 1.36763
I1030 15:56:43.657788  1046 solver.cpp:241]     Train net output #0: loss = 1.36763 (* 1 = 1.36763 loss)
I1030 15:56:43.657804  1046 sgd_solver.cpp:105] Iteration 44600, lr = 3.96699e-05
I1030 15:57:14.085736  1046 solver.cpp:222] Iteration 44640 (1.31463 iter/s, 30.4268s/40 iters), loss = 1.37749
I1030 15:57:14.085994  1046 solver.cpp:241]     Train net output #0: loss = 1.37749 (* 1 = 1.37749 loss)
I1030 15:57:14.086026  1046 sgd_solver.cpp:105] Iteration 44640, lr = 3.94737e-05
I1030 15:57:44.971130  1046 solver.cpp:222] Iteration 44680 (1.29517 iter/s, 30.884s/40 iters), loss = 1.24115
I1030 15:57:44.971312  1046 solver.cpp:241]     Train net output #0: loss = 1.24115 (* 1 = 1.24115 loss)
I1030 15:57:44.971328  1046 sgd_solver.cpp:105] Iteration 44680, lr = 3.92784e-05
I1030 15:58:15.698338  1046 solver.cpp:222] Iteration 44720 (1.30183 iter/s, 30.7259s/40 iters), loss = 1.54714
I1030 15:58:15.698509  1046 solver.cpp:241]     Train net output #0: loss = 1.54714 (* 1 = 1.54714 loss)
I1030 15:58:15.698529  1046 sgd_solver.cpp:105] Iteration 44720, lr = 3.90841e-05
I1030 15:58:46.395823  1046 solver.cpp:222] Iteration 44760 (1.30309 iter/s, 30.6962s/40 iters), loss = 1.31762
I1030 15:58:46.396008  1046 solver.cpp:241]     Train net output #0: loss = 1.31762 (* 1 = 1.31762 loss)
I1030 15:58:46.396026  1046 sgd_solver.cpp:105] Iteration 44760, lr = 3.88907e-05
I1030 15:59:17.187526  1046 solver.cpp:222] Iteration 44800 (1.29911 iter/s, 30.7904s/40 iters), loss = 1.73366
I1030 15:59:17.187711  1046 solver.cpp:241]     Train net output #0: loss = 1.73366 (* 1 = 1.73366 loss)
I1030 15:59:17.187727  1046 sgd_solver.cpp:105] Iteration 44800, lr = 3.86983e-05
I1030 15:59:47.858255  1046 solver.cpp:222] Iteration 44840 (1.30423 iter/s, 30.6694s/40 iters), loss = 1.41801
I1030 15:59:47.858433  1046 solver.cpp:241]     Train net output #0: loss = 1.41801 (* 1 = 1.41801 loss)
I1030 15:59:47.858450  1046 sgd_solver.cpp:105] Iteration 44840, lr = 3.85069e-05
I1030 16:00:18.775717  1046 solver.cpp:222] Iteration 44880 (1.29382 iter/s, 30.9161s/40 iters), loss = 1.41271
I1030 16:00:18.775895  1046 solver.cpp:241]     Train net output #0: loss = 1.41271 (* 1 = 1.41271 loss)
I1030 16:00:18.775913  1046 sgd_solver.cpp:105] Iteration 44880, lr = 3.83164e-05
I1030 16:00:50.174002  1046 solver.cpp:222] Iteration 44920 (1.27401 iter/s, 31.3969s/40 iters), loss = 1.21629
I1030 16:00:50.174190  1046 solver.cpp:241]     Train net output #0: loss = 1.21629 (* 1 = 1.21629 loss)
I1030 16:00:50.174207  1046 sgd_solver.cpp:105] Iteration 44920, lr = 3.81268e-05
I1030 16:01:22.548583  1046 solver.cpp:222] Iteration 44960 (1.23559 iter/s, 32.3732s/40 iters), loss = 1.52495
I1030 16:01:22.548785  1046 solver.cpp:241]     Train net output #0: loss = 1.52495 (* 1 = 1.52495 loss)
I1030 16:01:22.548802  1046 sgd_solver.cpp:105] Iteration 44960, lr = 3.79382e-05
I1030 16:01:52.885962  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_45000.caffemodel
I1030 16:01:52.918835  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_45000.solverstate
I1030 16:01:52.936522  1046 solver.cpp:334] Iteration 45000, Testing net (#0)
I1030 16:02:23.908519  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58904
I1030 16:02:23.908730  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8102
I1030 16:02:23.908746  1046 solver.cpp:401]     Test net output #2: loss = 1.83246 (* 1 = 1.83246 loss)
I1030 16:02:24.674191  1046 solver.cpp:222] Iteration 45000 (0.643883 iter/s, 62.1231s/40 iters), loss = 1.43268
I1030 16:02:24.674247  1046 solver.cpp:241]     Train net output #0: loss = 1.43268 (* 1 = 1.43268 loss)
I1030 16:02:24.674263  1046 sgd_solver.cpp:105] Iteration 45000, lr = 3.77505e-05
I1030 16:02:54.939968  1096 data_layer.cpp:73] Restarting data prefetching from start.
I1030 16:02:57.227253  1046 solver.cpp:222] Iteration 45040 (1.22881 iter/s, 32.5518s/40 iters), loss = 1.84697
I1030 16:02:57.227324  1046 solver.cpp:241]     Train net output #0: loss = 1.84697 (* 1 = 1.84697 loss)
I1030 16:02:57.227341  1046 sgd_solver.cpp:105] Iteration 45040, lr = 3.75638e-05
I1030 16:03:27.534723  1046 solver.cpp:222] Iteration 45080 (1.31986 iter/s, 30.3063s/40 iters), loss = 1.38481
I1030 16:03:27.534972  1046 solver.cpp:241]     Train net output #0: loss = 1.38481 (* 1 = 1.38481 loss)
I1030 16:03:27.534989  1046 sgd_solver.cpp:105] Iteration 45080, lr = 3.73779e-05
I1030 16:03:58.281646  1046 solver.cpp:222] Iteration 45120 (1.301 iter/s, 30.7455s/40 iters), loss = 1.59533
I1030 16:03:58.281841  1046 solver.cpp:241]     Train net output #0: loss = 1.59533 (* 1 = 1.59533 loss)
I1030 16:03:58.281857  1046 sgd_solver.cpp:105] Iteration 45120, lr = 3.7193e-05
I1030 16:04:28.941742  1046 solver.cpp:222] Iteration 45160 (1.30468 iter/s, 30.6587s/40 iters), loss = 1.51876
I1030 16:04:28.941934  1046 solver.cpp:241]     Train net output #0: loss = 1.51876 (* 1 = 1.51876 loss)
I1030 16:04:28.941951  1046 sgd_solver.cpp:105] Iteration 45160, lr = 3.7009e-05
I1030 16:04:59.465137  1046 solver.cpp:222] Iteration 45200 (1.31053 iter/s, 30.5221s/40 iters), loss = 1.24613
I1030 16:04:59.465325  1046 solver.cpp:241]     Train net output #0: loss = 1.24613 (* 1 = 1.24613 loss)
I1030 16:04:59.465342  1046 sgd_solver.cpp:105] Iteration 45200, lr = 3.68259e-05
I1030 16:05:30.423660  1046 solver.cpp:222] Iteration 45240 (1.29211 iter/s, 30.9571s/40 iters), loss = 1.34344
I1030 16:05:30.423908  1046 solver.cpp:241]     Train net output #0: loss = 1.34344 (* 1 = 1.34344 loss)
I1030 16:05:30.423934  1046 sgd_solver.cpp:105] Iteration 45240, lr = 3.66438e-05
I1030 16:06:01.500370  1046 solver.cpp:222] Iteration 45280 (1.2872 iter/s, 31.0753s/40 iters), loss = 1.31834
I1030 16:06:01.500609  1046 solver.cpp:241]     Train net output #0: loss = 1.31834 (* 1 = 1.31834 loss)
I1030 16:06:01.500633  1046 sgd_solver.cpp:105] Iteration 45280, lr = 3.64625e-05
I1030 16:06:32.281747  1046 solver.cpp:222] Iteration 45320 (1.29955 iter/s, 30.78s/40 iters), loss = 1.4905
I1030 16:06:32.281966  1046 solver.cpp:241]     Train net output #0: loss = 1.4905 (* 1 = 1.4905 loss)
I1030 16:06:32.281983  1046 sgd_solver.cpp:105] Iteration 45320, lr = 3.62821e-05
I1030 16:07:03.513692  1046 solver.cpp:222] Iteration 45360 (1.2808 iter/s, 31.2305s/40 iters), loss = 1.53005
I1030 16:07:03.513875  1046 solver.cpp:241]     Train net output #0: loss = 1.53005 (* 1 = 1.53005 loss)
I1030 16:07:03.513891  1046 sgd_solver.cpp:105] Iteration 45360, lr = 3.61026e-05
I1030 16:07:34.502349  1046 solver.cpp:222] Iteration 45400 (1.29085 iter/s, 30.9873s/40 iters), loss = 1.63437
I1030 16:07:34.502547  1046 solver.cpp:241]     Train net output #0: loss = 1.63437 (* 1 = 1.63437 loss)
I1030 16:07:34.502564  1046 sgd_solver.cpp:105] Iteration 45400, lr = 3.5924e-05
I1030 16:08:05.665516  1046 solver.cpp:222] Iteration 45440 (1.28362 iter/s, 31.1618s/40 iters), loss = 1.17887
I1030 16:08:05.665761  1046 solver.cpp:241]     Train net output #0: loss = 1.17887 (* 1 = 1.17887 loss)
I1030 16:08:05.665782  1046 sgd_solver.cpp:105] Iteration 45440, lr = 3.57463e-05
I1030 16:08:36.370386  1046 solver.cpp:222] Iteration 45480 (1.30278 iter/s, 30.7035s/40 iters), loss = 1.28596
I1030 16:08:36.370565  1046 solver.cpp:241]     Train net output #0: loss = 1.28596 (* 1 = 1.28596 loss)
I1030 16:08:36.370584  1046 sgd_solver.cpp:105] Iteration 45480, lr = 3.55694e-05
I1030 16:08:51.129108  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_45500.caffemodel
I1030 16:08:51.168215  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_45500.solverstate
I1030 16:08:51.186290  1046 solver.cpp:334] Iteration 45500, Testing net (#0)
I1030 16:09:21.925338  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 16:09:22.130455  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58664
I1030 16:09:22.130518  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813639
I1030 16:09:22.130532  1046 solver.cpp:401]     Test net output #2: loss = 1.83907 (* 1 = 1.83907 loss)
I1030 16:09:38.038918  1046 solver.cpp:222] Iteration 45520 (0.648655 iter/s, 61.666s/40 iters), loss = 1.20773
I1030 16:09:38.038983  1046 solver.cpp:241]     Train net output #0: loss = 1.20773 (* 1 = 1.20773 loss)
I1030 16:09:38.039003  1046 sgd_solver.cpp:105] Iteration 45520, lr = 3.53935e-05
I1030 16:10:08.470883  1046 solver.cpp:222] Iteration 45560 (1.31446 iter/s, 30.4307s/40 iters), loss = 1.55823
I1030 16:10:08.471197  1046 solver.cpp:241]     Train net output #0: loss = 1.55823 (* 1 = 1.55823 loss)
I1030 16:10:08.471220  1046 sgd_solver.cpp:105] Iteration 45560, lr = 3.52184e-05
I1030 16:10:38.434581  1046 solver.cpp:222] Iteration 45600 (1.33501 iter/s, 29.9623s/40 iters), loss = 1.25956
I1030 16:10:38.434648  1046 solver.cpp:241]     Train net output #0: loss = 1.25956 (* 1 = 1.25956 loss)
I1030 16:10:38.434664  1046 sgd_solver.cpp:105] Iteration 45600, lr = 3.50441e-05
I1030 16:11:08.657174  1046 solver.cpp:222] Iteration 45640 (1.32357 iter/s, 30.2214s/40 iters), loss = 1.40849
I1030 16:11:08.657464  1046 solver.cpp:241]     Train net output #0: loss = 1.40849 (* 1 = 1.40849 loss)
I1030 16:11:08.657480  1046 sgd_solver.cpp:105] Iteration 45640, lr = 3.48708e-05
I1030 16:11:39.168998  1046 solver.cpp:222] Iteration 45680 (1.31103 iter/s, 30.5104s/40 iters), loss = 1.30773
I1030 16:11:39.169173  1046 solver.cpp:241]     Train net output #0: loss = 1.30773 (* 1 = 1.30773 loss)
I1030 16:11:39.169190  1046 sgd_solver.cpp:105] Iteration 45680, lr = 3.46983e-05
I1030 16:12:09.559702  1046 solver.cpp:222] Iteration 45720 (1.31625 iter/s, 30.3894s/40 iters), loss = 1.13215
I1030 16:12:09.559919  1046 solver.cpp:241]     Train net output #0: loss = 1.13215 (* 1 = 1.13215 loss)
I1030 16:12:09.559939  1046 sgd_solver.cpp:105] Iteration 45720, lr = 3.45266e-05
I1030 16:12:41.866591  1046 solver.cpp:222] Iteration 45760 (1.23818 iter/s, 32.3054s/40 iters), loss = 1.43158
I1030 16:12:41.866838  1046 solver.cpp:241]     Train net output #0: loss = 1.43158 (* 1 = 1.43158 loss)
I1030 16:12:41.866868  1046 sgd_solver.cpp:105] Iteration 45760, lr = 3.43558e-05
I1030 16:13:12.695854  1046 solver.cpp:222] Iteration 45800 (1.29753 iter/s, 30.8278s/40 iters), loss = 1.30576
I1030 16:13:12.696063  1046 solver.cpp:241]     Train net output #0: loss = 1.30576 (* 1 = 1.30576 loss)
I1030 16:13:12.696080  1046 sgd_solver.cpp:105] Iteration 45800, lr = 3.41858e-05
I1030 16:13:43.138429  1046 solver.cpp:222] Iteration 45840 (1.31401 iter/s, 30.4412s/40 iters), loss = 1.5957
I1030 16:13:43.138602  1046 solver.cpp:241]     Train net output #0: loss = 1.5957 (* 1 = 1.5957 loss)
I1030 16:13:43.138618  1046 sgd_solver.cpp:105] Iteration 45840, lr = 3.40167e-05
I1030 16:14:13.276013  1046 solver.cpp:222] Iteration 45880 (1.3273 iter/s, 30.1363s/40 iters), loss = 1.25621
I1030 16:14:13.276180  1046 solver.cpp:241]     Train net output #0: loss = 1.25621 (* 1 = 1.25621 loss)
I1030 16:14:13.276198  1046 sgd_solver.cpp:105] Iteration 45880, lr = 3.38484e-05
I1030 16:14:43.487685  1046 solver.cpp:222] Iteration 45920 (1.32405 iter/s, 30.2104s/40 iters), loss = 1.29095
I1030 16:14:43.487871  1046 solver.cpp:241]     Train net output #0: loss = 1.29095 (* 1 = 1.29095 loss)
I1030 16:14:43.487888  1046 sgd_solver.cpp:105] Iteration 45920, lr = 3.3681e-05
I1030 16:15:14.851922  1046 solver.cpp:222] Iteration 45960 (1.27539 iter/s, 31.3628s/40 iters), loss = 1.4103
I1030 16:15:14.852156  1046 solver.cpp:241]     Train net output #0: loss = 1.4103 (* 1 = 1.4103 loss)
I1030 16:15:14.852180  1046 sgd_solver.cpp:105] Iteration 45960, lr = 3.35144e-05
I1030 16:15:46.044862  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_46000.caffemodel
I1030 16:15:46.077522  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_46000.solverstate
I1030 16:15:46.104485  1046 solver.cpp:334] Iteration 46000, Testing net (#0)
I1030 16:16:17.163089  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58788
I1030 16:16:17.163242  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.810719
I1030 16:16:17.163259  1046 solver.cpp:401]     Test net output #2: loss = 1.83323 (* 1 = 1.83323 loss)
I1030 16:16:17.933184  1046 solver.cpp:222] Iteration 46000 (0.634129 iter/s, 63.0787s/40 iters), loss = 1.3646
I1030 16:16:17.933248  1046 solver.cpp:241]     Train net output #0: loss = 1.3646 (* 1 = 1.3646 loss)
I1030 16:16:17.933277  1046 sgd_solver.cpp:105] Iteration 46000, lr = 3.33486e-05
I1030 16:16:49.674612  1046 solver.cpp:222] Iteration 46040 (1.26023 iter/s, 31.7402s/40 iters), loss = 1.53246
I1030 16:16:49.674887  1046 solver.cpp:241]     Train net output #0: loss = 1.53246 (* 1 = 1.53246 loss)
I1030 16:16:49.674921  1046 sgd_solver.cpp:105] Iteration 46040, lr = 3.31836e-05
I1030 16:17:20.838201  1046 solver.cpp:222] Iteration 46080 (1.28361 iter/s, 31.1622s/40 iters), loss = 1.59741
I1030 16:17:20.838476  1046 solver.cpp:241]     Train net output #0: loss = 1.59741 (* 1 = 1.59741 loss)
I1030 16:17:20.838495  1046 sgd_solver.cpp:105] Iteration 46080, lr = 3.30194e-05
I1030 16:17:51.570621  1046 solver.cpp:222] Iteration 46120 (1.30162 iter/s, 30.731s/40 iters), loss = 1.53914
I1030 16:17:51.570808  1046 solver.cpp:241]     Train net output #0: loss = 1.53914 (* 1 = 1.53914 loss)
I1030 16:17:51.570833  1046 sgd_solver.cpp:105] Iteration 46120, lr = 3.28561e-05
I1030 16:18:22.444378  1046 solver.cpp:222] Iteration 46160 (1.29566 iter/s, 30.8724s/40 iters), loss = 1.45824
I1030 16:18:22.444600  1046 solver.cpp:241]     Train net output #0: loss = 1.45824 (* 1 = 1.45824 loss)
I1030 16:18:22.444619  1046 sgd_solver.cpp:105] Iteration 46160, lr = 3.26935e-05
I1030 16:18:53.041808  1046 solver.cpp:222] Iteration 46200 (1.30736 iter/s, 30.5961s/40 iters), loss = 1.59199
I1030 16:18:53.041987  1046 solver.cpp:241]     Train net output #0: loss = 1.59199 (* 1 = 1.59199 loss)
I1030 16:18:53.042006  1046 sgd_solver.cpp:105] Iteration 46200, lr = 3.25318e-05
I1030 16:19:23.451848  1046 solver.cpp:222] Iteration 46240 (1.31541 iter/s, 30.4087s/40 iters), loss = 1.29107
I1030 16:19:23.452066  1046 solver.cpp:241]     Train net output #0: loss = 1.29107 (* 1 = 1.29107 loss)
I1030 16:19:23.452083  1046 sgd_solver.cpp:105] Iteration 46240, lr = 3.23708e-05
I1030 16:19:54.219770  1046 solver.cpp:222] Iteration 46280 (1.30011 iter/s, 30.7666s/40 iters), loss = 1.31014
I1030 16:19:54.220003  1046 solver.cpp:241]     Train net output #0: loss = 1.31014 (* 1 = 1.31014 loss)
I1030 16:19:54.220021  1046 sgd_solver.cpp:105] Iteration 46280, lr = 3.22107e-05
I1030 16:20:25.563202  1046 solver.cpp:222] Iteration 46320 (1.27624 iter/s, 31.342s/40 iters), loss = 1.05413
I1030 16:20:25.563412  1046 solver.cpp:241]     Train net output #0: loss = 1.05413 (* 1 = 1.05413 loss)
I1030 16:20:25.563429  1046 sgd_solver.cpp:105] Iteration 46320, lr = 3.20513e-05
I1030 16:20:56.877678  1046 solver.cpp:222] Iteration 46360 (1.27742 iter/s, 31.3131s/40 iters), loss = 1.28624
I1030 16:20:56.877884  1046 solver.cpp:241]     Train net output #0: loss = 1.28624 (* 1 = 1.28624 loss)
I1030 16:20:56.877904  1046 sgd_solver.cpp:105] Iteration 46360, lr = 3.18928e-05
I1030 16:21:27.735318  1046 solver.cpp:222] Iteration 46400 (1.29633 iter/s, 30.8563s/40 iters), loss = 1.3535
I1030 16:21:27.735512  1046 solver.cpp:241]     Train net output #0: loss = 1.3535 (* 1 = 1.3535 loss)
I1030 16:21:27.735528  1046 sgd_solver.cpp:105] Iteration 46400, lr = 3.1735e-05
I1030 16:21:58.329594  1046 solver.cpp:222] Iteration 46440 (1.30749 iter/s, 30.5929s/40 iters), loss = 1.56877
I1030 16:21:58.329779  1046 solver.cpp:241]     Train net output #0: loss = 1.56877 (* 1 = 1.56877 loss)
I1030 16:21:58.329797  1046 sgd_solver.cpp:105] Iteration 46440, lr = 3.1578e-05
I1030 16:22:28.884682  1046 solver.cpp:222] Iteration 46480 (1.30917 iter/s, 30.5538s/40 iters), loss = 1.23494
I1030 16:22:28.884899  1046 solver.cpp:241]     Train net output #0: loss = 1.23494 (* 1 = 1.23494 loss)
I1030 16:22:28.884917  1046 sgd_solver.cpp:105] Iteration 46480, lr = 3.14218e-05
I1030 16:22:43.291491  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_46500.caffemodel
I1030 16:22:43.329728  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_46500.solverstate
I1030 16:22:43.347985  1046 solver.cpp:334] Iteration 46500, Testing net (#0)
I1030 16:23:14.276717  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 16:23:14.488324  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58656
I1030 16:23:14.488374  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813599
I1030 16:23:14.488389  1046 solver.cpp:401]     Test net output #2: loss = 1.83657 (* 1 = 1.83657 loss)
I1030 16:23:30.481762  1046 solver.cpp:222] Iteration 46520 (0.649408 iter/s, 61.5946s/40 iters), loss = 1.64277
I1030 16:23:30.481838  1046 solver.cpp:241]     Train net output #0: loss = 1.64277 (* 1 = 1.64277 loss)
I1030 16:23:30.481858  1046 sgd_solver.cpp:105] Iteration 46520, lr = 3.12663e-05
I1030 16:24:01.242316  1046 solver.cpp:222] Iteration 46560 (1.30042 iter/s, 30.7593s/40 iters), loss = 1.44149
I1030 16:24:01.242535  1046 solver.cpp:241]     Train net output #0: loss = 1.44149 (* 1 = 1.44149 loss)
I1030 16:24:01.242554  1046 sgd_solver.cpp:105] Iteration 46560, lr = 3.11117e-05
I1030 16:24:31.891002  1046 solver.cpp:222] Iteration 46600 (1.30517 iter/s, 30.6473s/40 iters), loss = 1.21882
I1030 16:24:31.891187  1046 solver.cpp:241]     Train net output #0: loss = 1.21882 (* 1 = 1.21882 loss)
I1030 16:24:31.891206  1046 sgd_solver.cpp:105] Iteration 46600, lr = 3.09577e-05
I1030 16:25:02.923712  1046 solver.cpp:222] Iteration 46640 (1.28902 iter/s, 31.0313s/40 iters), loss = 1.44813
I1030 16:25:02.923920  1046 solver.cpp:241]     Train net output #0: loss = 1.44813 (* 1 = 1.44813 loss)
I1030 16:25:02.923945  1046 sgd_solver.cpp:105] Iteration 46640, lr = 3.08046e-05
I1030 16:25:49.714072  1046 solver.cpp:222] Iteration 46680 (0.854913 iter/s, 46.7884s/40 iters), loss = 1.73855
I1030 16:25:49.714257  1046 solver.cpp:241]     Train net output #0: loss = 1.73855 (* 1 = 1.73855 loss)
I1030 16:25:49.714274  1046 sgd_solver.cpp:105] Iteration 46680, lr = 3.06522e-05
I1030 16:26:21.739994  1046 solver.cpp:222] Iteration 46720 (1.24904 iter/s, 32.0245s/40 iters), loss = 1.01755
I1030 16:26:21.740294  1046 solver.cpp:241]     Train net output #0: loss = 1.01755 (* 1 = 1.01755 loss)
I1030 16:26:21.740330  1046 sgd_solver.cpp:105] Iteration 46720, lr = 3.05006e-05
I1030 16:26:52.194228  1046 solver.cpp:222] Iteration 46760 (1.31351 iter/s, 30.4528s/40 iters), loss = 1.22047
I1030 16:26:52.194434  1046 solver.cpp:241]     Train net output #0: loss = 1.22047 (* 1 = 1.22047 loss)
I1030 16:26:52.194453  1046 sgd_solver.cpp:105] Iteration 46760, lr = 3.03497e-05
I1030 16:27:23.335423  1046 solver.cpp:222] Iteration 46800 (1.28453 iter/s, 31.1398s/40 iters), loss = 1.16321
I1030 16:27:23.335626  1046 solver.cpp:241]     Train net output #0: loss = 1.16321 (* 1 = 1.16321 loss)
I1030 16:27:23.335644  1046 sgd_solver.cpp:105] Iteration 46800, lr = 3.01995e-05
I1030 16:27:53.871206  1046 solver.cpp:222] Iteration 46840 (1.31 iter/s, 30.5344s/40 iters), loss = 1.33572
I1030 16:27:53.871398  1046 solver.cpp:241]     Train net output #0: loss = 1.33572 (* 1 = 1.33572 loss)
I1030 16:27:53.871417  1046 sgd_solver.cpp:105] Iteration 46840, lr = 3.00501e-05
I1030 16:28:24.958081  1046 solver.cpp:222] Iteration 46880 (1.28677 iter/s, 31.0855s/40 iters), loss = 1.2659
I1030 16:28:24.958292  1046 solver.cpp:241]     Train net output #0: loss = 1.2659 (* 1 = 1.2659 loss)
I1030 16:28:24.958313  1046 sgd_solver.cpp:105] Iteration 46880, lr = 2.99015e-05
I1030 16:28:55.577087  1046 solver.cpp:222] Iteration 46920 (1.30644 iter/s, 30.6176s/40 iters), loss = 1.35646
I1030 16:28:55.577304  1046 solver.cpp:241]     Train net output #0: loss = 1.35646 (* 1 = 1.35646 loss)
I1030 16:28:55.577322  1046 sgd_solver.cpp:105] Iteration 46920, lr = 2.97535e-05
I1030 16:29:26.664415  1046 solver.cpp:222] Iteration 46960 (1.28676 iter/s, 31.0859s/40 iters), loss = 1.38236
I1030 16:29:26.664672  1046 solver.cpp:241]     Train net output #0: loss = 1.38236 (* 1 = 1.38236 loss)
I1030 16:29:26.664700  1046 sgd_solver.cpp:105] Iteration 46960, lr = 2.96063e-05
I1030 16:29:57.589268  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_47000.caffemodel
I1030 16:29:57.625107  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_47000.solverstate
I1030 16:29:57.649792  1046 solver.cpp:334] Iteration 47000, Testing net (#0)
I1030 16:30:28.580034  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58848
I1030 16:30:28.580219  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.810319
I1030 16:30:28.580235  1046 solver.cpp:401]     Test net output #2: loss = 1.83275 (* 1 = 1.83275 loss)
I1030 16:30:29.341934  1046 solver.cpp:222] Iteration 47000 (0.638214 iter/s, 62.6749s/40 iters), loss = 1.24463
I1030 16:30:29.342000  1046 solver.cpp:241]     Train net output #0: loss = 1.24463 (* 1 = 1.24463 loss)
I1030 16:30:29.342015  1046 sgd_solver.cpp:105] Iteration 47000, lr = 2.94599e-05
I1030 16:30:59.799273  1046 solver.cpp:222] Iteration 47040 (1.31336 iter/s, 30.4561s/40 iters), loss = 1.63189
I1030 16:30:59.799453  1046 solver.cpp:241]     Train net output #0: loss = 1.63189 (* 1 = 1.63189 loss)
I1030 16:30:59.799471  1046 sgd_solver.cpp:105] Iteration 47040, lr = 2.93141e-05
I1030 16:31:30.147128  1046 solver.cpp:222] Iteration 47080 (1.31811 iter/s, 30.3465s/40 iters), loss = 1.55889
I1030 16:31:30.147305  1046 solver.cpp:241]     Train net output #0: loss = 1.55889 (* 1 = 1.55889 loss)
I1030 16:31:30.147325  1046 sgd_solver.cpp:105] Iteration 47080, lr = 2.91691e-05
I1030 16:32:00.593731  1046 solver.cpp:222] Iteration 47120 (1.31383 iter/s, 30.4453s/40 iters), loss = 1.45434
I1030 16:32:00.593919  1046 solver.cpp:241]     Train net output #0: loss = 1.45434 (* 1 = 1.45434 loss)
I1030 16:32:00.593936  1046 sgd_solver.cpp:105] Iteration 47120, lr = 2.90248e-05
I1030 16:32:31.092710  1046 solver.cpp:222] Iteration 47160 (1.31158 iter/s, 30.4976s/40 iters), loss = 1.6623
I1030 16:32:31.092914  1046 solver.cpp:241]     Train net output #0: loss = 1.6623 (* 1 = 1.6623 loss)
I1030 16:32:31.092931  1046 sgd_solver.cpp:105] Iteration 47160, lr = 2.88812e-05
I1030 16:33:01.576556  1046 solver.cpp:222] Iteration 47200 (1.31223 iter/s, 30.4825s/40 iters), loss = 1.49514
I1030 16:33:01.576730  1046 solver.cpp:241]     Train net output #0: loss = 1.49514 (* 1 = 1.49514 loss)
I1030 16:33:01.576746  1046 sgd_solver.cpp:105] Iteration 47200, lr = 2.87383e-05
I1030 16:33:32.289880  1046 solver.cpp:222] Iteration 47240 (1.30242 iter/s, 30.712s/40 iters), loss = 1.49437
I1030 16:33:32.290112  1046 solver.cpp:241]     Train net output #0: loss = 1.49437 (* 1 = 1.49437 loss)
I1030 16:33:32.290138  1046 sgd_solver.cpp:105] Iteration 47240, lr = 2.85962e-05
I1030 16:34:03.298051  1046 solver.cpp:222] Iteration 47280 (1.29004 iter/s, 31.0068s/40 iters), loss = 1.73622
I1030 16:34:03.298249  1046 solver.cpp:241]     Train net output #0: loss = 1.73622 (* 1 = 1.73622 loss)
I1030 16:34:03.298269  1046 sgd_solver.cpp:105] Iteration 47280, lr = 2.84547e-05
I1030 16:34:34.003903  1046 solver.cpp:222] Iteration 47320 (1.30274 iter/s, 30.7045s/40 iters), loss = 1.45984
I1030 16:34:34.004082  1046 solver.cpp:241]     Train net output #0: loss = 1.45984 (* 1 = 1.45984 loss)
I1030 16:34:34.004101  1046 sgd_solver.cpp:105] Iteration 47320, lr = 2.83139e-05
I1030 16:35:04.826243  1046 solver.cpp:222] Iteration 47360 (1.29782 iter/s, 30.821s/40 iters), loss = 1.08289
I1030 16:35:04.826402  1046 solver.cpp:241]     Train net output #0: loss = 1.08289 (* 1 = 1.08289 loss)
I1030 16:35:04.826419  1046 sgd_solver.cpp:105] Iteration 47360, lr = 2.81739e-05
I1030 16:35:35.449623  1046 solver.cpp:222] Iteration 47400 (1.30625 iter/s, 30.6221s/40 iters), loss = 1.13715
I1030 16:35:35.449817  1046 solver.cpp:241]     Train net output #0: loss = 1.13715 (* 1 = 1.13715 loss)
I1030 16:35:35.449834  1046 sgd_solver.cpp:105] Iteration 47400, lr = 2.80345e-05
I1030 16:36:06.050328  1046 solver.cpp:222] Iteration 47440 (1.30722 iter/s, 30.5994s/40 iters), loss = 1.51164
I1030 16:36:06.050534  1046 solver.cpp:241]     Train net output #0: loss = 1.51164 (* 1 = 1.51164 loss)
I1030 16:36:06.050550  1046 sgd_solver.cpp:105] Iteration 47440, lr = 2.78958e-05
I1030 16:36:37.396762  1046 solver.cpp:222] Iteration 47480 (1.27612 iter/s, 31.345s/40 iters), loss = 1.67001
I1030 16:36:37.397034  1046 solver.cpp:241]     Train net output #0: loss = 1.67001 (* 1 = 1.67001 loss)
I1030 16:36:37.397073  1046 sgd_solver.cpp:105] Iteration 47480, lr = 2.77578e-05
I1030 16:36:52.043220  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_47500.caffemodel
I1030 16:36:52.080569  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_47500.solverstate
I1030 16:36:52.103294  1046 solver.cpp:334] Iteration 47500, Testing net (#0)
I1030 16:37:22.895936  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 16:37:23.102494  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58684
I1030 16:37:23.102552  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81332
I1030 16:37:23.102566  1046 solver.cpp:401]     Test net output #2: loss = 1.83701 (* 1 = 1.83701 loss)
I1030 16:37:39.107969  1046 solver.cpp:222] Iteration 47520 (0.648208 iter/s, 61.7086s/40 iters), loss = 1.51548
I1030 16:37:39.108036  1046 solver.cpp:241]     Train net output #0: loss = 1.51548 (* 1 = 1.51548 loss)
I1030 16:37:39.108054  1046 sgd_solver.cpp:105] Iteration 47520, lr = 2.76205e-05
I1030 16:37:53.570700  1096 data_layer.cpp:73] Restarting data prefetching from start.
I1030 16:38:09.443140  1046 solver.cpp:222] Iteration 47560 (1.31865 iter/s, 30.334s/40 iters), loss = 1.4267
I1030 16:38:09.443205  1046 solver.cpp:241]     Train net output #0: loss = 1.4267 (* 1 = 1.4267 loss)
I1030 16:38:09.443220  1046 sgd_solver.cpp:105] Iteration 47560, lr = 2.74838e-05
I1030 16:38:40.283802  1046 solver.cpp:222] Iteration 47600 (1.29704 iter/s, 30.8394s/40 iters), loss = 1.41429
I1030 16:38:40.283995  1046 solver.cpp:241]     Train net output #0: loss = 1.41429 (* 1 = 1.41429 loss)
I1030 16:38:40.284013  1046 sgd_solver.cpp:105] Iteration 47600, lr = 2.73478e-05
I1030 16:39:10.935878  1046 solver.cpp:222] Iteration 47640 (1.30503 iter/s, 30.6507s/40 iters), loss = 1.11392
I1030 16:39:10.936075  1046 solver.cpp:241]     Train net output #0: loss = 1.11392 (* 1 = 1.11392 loss)
I1030 16:39:10.936091  1046 sgd_solver.cpp:105] Iteration 47640, lr = 2.72126e-05
I1030 16:39:41.481964  1046 solver.cpp:222] Iteration 47680 (1.30955 iter/s, 30.5447s/40 iters), loss = 1.1967
I1030 16:39:41.482128  1046 solver.cpp:241]     Train net output #0: loss = 1.1967 (* 1 = 1.1967 loss)
I1030 16:39:41.482144  1046 sgd_solver.cpp:105] Iteration 47680, lr = 2.70779e-05
I1030 16:40:12.521283  1046 solver.cpp:222] Iteration 47720 (1.28874 iter/s, 31.038s/40 iters), loss = 1.19729
I1030 16:40:12.521507  1046 solver.cpp:241]     Train net output #0: loss = 1.19729 (* 1 = 1.19729 loss)
I1030 16:40:12.521524  1046 sgd_solver.cpp:105] Iteration 47720, lr = 2.6944e-05
I1030 16:40:43.023551  1046 solver.cpp:222] Iteration 47760 (1.31144 iter/s, 30.5009s/40 iters), loss = 1.47467
I1030 16:40:43.023746  1046 solver.cpp:241]     Train net output #0: loss = 1.47467 (* 1 = 1.47467 loss)
I1030 16:40:43.023763  1046 sgd_solver.cpp:105] Iteration 47760, lr = 2.68107e-05
I1030 16:41:13.508262  1046 solver.cpp:222] Iteration 47800 (1.31219 iter/s, 30.4834s/40 iters), loss = 1.57486
I1030 16:41:13.508464  1046 solver.cpp:241]     Train net output #0: loss = 1.57486 (* 1 = 1.57486 loss)
I1030 16:41:13.508483  1046 sgd_solver.cpp:105] Iteration 47800, lr = 2.6678e-05
I1030 16:41:44.242468  1046 solver.cpp:222] Iteration 47840 (1.30154 iter/s, 30.7328s/40 iters), loss = 1.52402
I1030 16:41:44.242641  1046 solver.cpp:241]     Train net output #0: loss = 1.52402 (* 1 = 1.52402 loss)
I1030 16:41:44.242661  1046 sgd_solver.cpp:105] Iteration 47840, lr = 2.65461e-05
I1030 16:42:15.269398  1046 solver.cpp:222] Iteration 47880 (1.28926 iter/s, 31.0256s/40 iters), loss = 1.2884
I1030 16:42:15.269616  1046 solver.cpp:241]     Train net output #0: loss = 1.2884 (* 1 = 1.2884 loss)
I1030 16:42:15.269639  1046 sgd_solver.cpp:105] Iteration 47880, lr = 2.64147e-05
I1030 16:42:46.894629  1046 solver.cpp:222] Iteration 47920 (1.26487 iter/s, 31.6238s/40 iters), loss = 1.26027
I1030 16:42:46.894908  1046 solver.cpp:241]     Train net output #0: loss = 1.26027 (* 1 = 1.26027 loss)
I1030 16:42:46.894933  1046 sgd_solver.cpp:105] Iteration 47920, lr = 2.62841e-05
I1030 16:43:17.783839  1046 solver.cpp:222] Iteration 47960 (1.29501 iter/s, 30.8878s/40 iters), loss = 1.26364
I1030 16:43:17.784060  1046 solver.cpp:241]     Train net output #0: loss = 1.26364 (* 1 = 1.26364 loss)
I1030 16:43:17.784080  1046 sgd_solver.cpp:105] Iteration 47960, lr = 2.6154e-05
I1030 16:43:47.685086  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_48000.caffemodel
I1030 16:43:47.716764  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_48000.solverstate
I1030 16:43:47.733562  1046 solver.cpp:334] Iteration 48000, Testing net (#0)
I1030 16:44:18.615598  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58856
I1030 16:44:18.615794  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81044
I1030 16:44:18.615810  1046 solver.cpp:401]     Test net output #2: loss = 1.8353 (* 1 = 1.8353 loss)
I1030 16:44:19.381536  1046 solver.cpp:222] Iteration 48000 (0.649402 iter/s, 61.5952s/40 iters), loss = 1.64477
I1030 16:44:19.381603  1046 solver.cpp:241]     Train net output #0: loss = 1.64477 (* 1 = 1.64477 loss)
I1030 16:44:19.381620  1046 sgd_solver.cpp:105] Iteration 48000, lr = 2.60246e-05
I1030 16:44:50.158639  1046 solver.cpp:222] Iteration 48040 (1.29972 iter/s, 30.7759s/40 iters), loss = 1.13557
I1030 16:44:50.158828  1046 solver.cpp:241]     Train net output #0: loss = 1.13557 (* 1 = 1.13557 loss)
I1030 16:44:50.158850  1046 sgd_solver.cpp:105] Iteration 48040, lr = 2.58959e-05
I1030 16:45:20.461462  1046 solver.cpp:222] Iteration 48080 (1.32007 iter/s, 30.3015s/40 iters), loss = 1.49996
I1030 16:45:20.461688  1046 solver.cpp:241]     Train net output #0: loss = 1.49996 (* 1 = 1.49996 loss)
I1030 16:45:20.461704  1046 sgd_solver.cpp:105] Iteration 48080, lr = 2.57678e-05
I1030 16:45:51.196043  1046 solver.cpp:222] Iteration 48120 (1.30152 iter/s, 30.7332s/40 iters), loss = 1.31386
I1030 16:45:51.196234  1046 solver.cpp:241]     Train net output #0: loss = 1.31386 (* 1 = 1.31386 loss)
I1030 16:45:51.196251  1046 sgd_solver.cpp:105] Iteration 48120, lr = 2.56403e-05
I1030 16:46:24.548606  1046 solver.cpp:222] Iteration 48160 (1.19936 iter/s, 33.3511s/40 iters), loss = 1.61338
I1030 16:46:24.548825  1046 solver.cpp:241]     Train net output #0: loss = 1.61338 (* 1 = 1.61338 loss)
I1030 16:46:24.548849  1046 sgd_solver.cpp:105] Iteration 48160, lr = 2.55135e-05
I1030 16:47:22.222117  1046 solver.cpp:222] Iteration 48200 (0.693588 iter/s, 57.6711s/40 iters), loss = 1.45859
I1030 16:47:22.222334  1046 solver.cpp:241]     Train net output #0: loss = 1.45859 (* 1 = 1.45859 loss)
I1030 16:47:22.222352  1046 sgd_solver.cpp:105] Iteration 48200, lr = 2.53872e-05
I1030 16:47:53.161695  1046 solver.cpp:222] Iteration 48240 (1.2929 iter/s, 30.9382s/40 iters), loss = 1.18597
I1030 16:47:53.161888  1046 solver.cpp:241]     Train net output #0: loss = 1.18597 (* 1 = 1.18597 loss)
I1030 16:47:53.161906  1046 sgd_solver.cpp:105] Iteration 48240, lr = 2.52616e-05
I1030 16:48:23.964179  1046 solver.cpp:222] Iteration 48280 (1.29865 iter/s, 30.8011s/40 iters), loss = 1.44161
I1030 16:48:23.964406  1046 solver.cpp:241]     Train net output #0: loss = 1.44161 (* 1 = 1.44161 loss)
I1030 16:48:23.964426  1046 sgd_solver.cpp:105] Iteration 48280, lr = 2.51367e-05
I1030 16:48:55.186650  1046 solver.cpp:222] Iteration 48320 (1.28119 iter/s, 31.2211s/40 iters), loss = 1.57402
I1030 16:48:55.186832  1046 solver.cpp:241]     Train net output #0: loss = 1.57402 (* 1 = 1.57402 loss)
I1030 16:48:55.186848  1046 sgd_solver.cpp:105] Iteration 48320, lr = 2.50123e-05
I1030 16:49:26.134271  1046 solver.cpp:222] Iteration 48360 (1.29256 iter/s, 30.9463s/40 iters), loss = 1.72436
I1030 16:49:26.134541  1046 solver.cpp:241]     Train net output #0: loss = 1.72436 (* 1 = 1.72436 loss)
I1030 16:49:26.134558  1046 sgd_solver.cpp:105] Iteration 48360, lr = 2.48886e-05
I1030 16:49:57.350829  1046 solver.cpp:222] Iteration 48400 (1.28143 iter/s, 31.2151s/40 iters), loss = 1.48825
I1030 16:49:57.350996  1046 solver.cpp:241]     Train net output #0: loss = 1.48825 (* 1 = 1.48825 loss)
I1030 16:49:57.351013  1046 sgd_solver.cpp:105] Iteration 48400, lr = 2.47654e-05
I1030 16:50:28.773982  1046 solver.cpp:222] Iteration 48440 (1.273 iter/s, 31.4218s/40 iters), loss = 1.51502
I1030 16:50:28.774191  1046 solver.cpp:241]     Train net output #0: loss = 1.51502 (* 1 = 1.51502 loss)
I1030 16:50:28.774209  1046 sgd_solver.cpp:105] Iteration 48440, lr = 2.46429e-05
I1030 16:50:59.978022  1046 solver.cpp:222] Iteration 48480 (1.28194 iter/s, 31.2026s/40 iters), loss = 1.54171
I1030 16:50:59.978233  1046 solver.cpp:241]     Train net output #0: loss = 1.54171 (* 1 = 1.54171 loss)
I1030 16:50:59.978252  1046 sgd_solver.cpp:105] Iteration 48480, lr = 2.4521e-05
I1030 16:51:14.645730  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_48500.caffemodel
I1030 16:51:14.677798  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_48500.solverstate
I1030 16:51:14.695302  1046 solver.cpp:334] Iteration 48500, Testing net (#0)
I1030 16:51:45.440809  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 16:51:45.647967  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58636
I1030 16:51:45.648028  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.813959
I1030 16:51:45.648041  1046 solver.cpp:401]     Test net output #2: loss = 1.83757 (* 1 = 1.83757 loss)
I1030 16:52:01.783718  1046 solver.cpp:222] Iteration 48520 (0.647216 iter/s, 61.8032s/40 iters), loss = 1.23667
I1030 16:52:01.783787  1046 solver.cpp:241]     Train net output #0: loss = 1.23667 (* 1 = 1.23667 loss)
I1030 16:52:01.783803  1046 sgd_solver.cpp:105] Iteration 48520, lr = 2.43997e-05
I1030 16:52:32.114589  1046 solver.cpp:222] Iteration 48560 (1.31884 iter/s, 30.3296s/40 iters), loss = 1.52598
I1030 16:52:32.114861  1046 solver.cpp:241]     Train net output #0: loss = 1.52598 (* 1 = 1.52598 loss)
I1030 16:52:32.114887  1046 sgd_solver.cpp:105] Iteration 48560, lr = 2.4279e-05
I1030 16:53:03.477351  1046 solver.cpp:222] Iteration 48600 (1.27546 iter/s, 31.3613s/40 iters), loss = 1.33557
I1030 16:53:03.477566  1046 solver.cpp:241]     Train net output #0: loss = 1.33557 (* 1 = 1.33557 loss)
I1030 16:53:03.477583  1046 sgd_solver.cpp:105] Iteration 48600, lr = 2.41589e-05
I1030 16:53:34.442636  1046 solver.cpp:222] Iteration 48640 (1.29183 iter/s, 30.9639s/40 iters), loss = 1.00541
I1030 16:53:34.442829  1046 solver.cpp:241]     Train net output #0: loss = 1.00541 (* 1 = 1.00541 loss)
I1030 16:53:34.442847  1046 sgd_solver.cpp:105] Iteration 48640, lr = 2.40394e-05
I1030 16:54:05.080906  1046 solver.cpp:222] Iteration 48680 (1.30561 iter/s, 30.6369s/40 iters), loss = 1.39185
I1030 16:54:05.081102  1046 solver.cpp:241]     Train net output #0: loss = 1.39185 (* 1 = 1.39185 loss)
I1030 16:54:05.081123  1046 sgd_solver.cpp:105] Iteration 48680, lr = 2.39204e-05
I1030 16:54:35.556015  1046 solver.cpp:222] Iteration 48720 (1.3126 iter/s, 30.4738s/40 iters), loss = 1.55211
I1030 16:54:35.556182  1046 solver.cpp:241]     Train net output #0: loss = 1.55211 (* 1 = 1.55211 loss)
I1030 16:54:35.556200  1046 sgd_solver.cpp:105] Iteration 48720, lr = 2.38021e-05
I1030 16:55:06.053031  1046 solver.cpp:222] Iteration 48760 (1.31166 iter/s, 30.4957s/40 iters), loss = 1.39491
I1030 16:55:06.053217  1046 solver.cpp:241]     Train net output #0: loss = 1.39491 (* 1 = 1.39491 loss)
I1030 16:55:06.053234  1046 sgd_solver.cpp:105] Iteration 48760, lr = 2.36844e-05
I1030 16:55:36.575093  1046 solver.cpp:222] Iteration 48800 (1.31058 iter/s, 30.5207s/40 iters), loss = 1.47158
I1030 16:55:36.575336  1046 solver.cpp:241]     Train net output #0: loss = 1.47158 (* 1 = 1.47158 loss)
I1030 16:55:36.575368  1046 sgd_solver.cpp:105] Iteration 48800, lr = 2.35672e-05
I1030 16:56:07.793959  1046 solver.cpp:222] Iteration 48840 (1.28133 iter/s, 31.2174s/40 iters), loss = 1.19915
I1030 16:56:07.794129  1046 solver.cpp:241]     Train net output #0: loss = 1.19915 (* 1 = 1.19915 loss)
I1030 16:56:07.794145  1046 sgd_solver.cpp:105] Iteration 48840, lr = 2.34506e-05
I1030 16:56:39.371048  1046 solver.cpp:222] Iteration 48880 (1.2668 iter/s, 31.5757s/40 iters), loss = 1.39833
I1030 16:56:39.371228  1046 solver.cpp:241]     Train net output #0: loss = 1.39833 (* 1 = 1.39833 loss)
I1030 16:56:39.371244  1046 sgd_solver.cpp:105] Iteration 48880, lr = 2.33346e-05
I1030 16:57:09.737504  1046 solver.cpp:222] Iteration 48920 (1.3173 iter/s, 30.3651s/40 iters), loss = 1.36704
I1030 16:57:09.737674  1046 solver.cpp:241]     Train net output #0: loss = 1.36704 (* 1 = 1.36704 loss)
I1030 16:57:09.737692  1046 sgd_solver.cpp:105] Iteration 48920, lr = 2.32191e-05
I1030 16:57:40.148947  1046 solver.cpp:222] Iteration 48960 (1.31535 iter/s, 30.4101s/40 iters), loss = 1.73935
I1030 16:57:40.149116  1046 solver.cpp:241]     Train net output #0: loss = 1.73935 (* 1 = 1.73935 loss)
I1030 16:57:40.149134  1046 sgd_solver.cpp:105] Iteration 48960, lr = 2.31043e-05
I1030 16:58:10.014169  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_49000.caffemodel
I1030 16:58:10.055055  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_49000.solverstate
I1030 16:58:10.078248  1046 solver.cpp:334] Iteration 49000, Testing net (#0)
I1030 16:58:41.029559  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58832
I1030 16:58:41.029750  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81088
I1030 16:58:41.029767  1046 solver.cpp:401]     Test net output #2: loss = 1.83253 (* 1 = 1.83253 loss)
I1030 16:58:41.792438  1046 solver.cpp:222] Iteration 49000 (0.648919 iter/s, 61.641s/40 iters), loss = 1.31372
I1030 16:58:41.792501  1046 solver.cpp:241]     Train net output #0: loss = 1.31372 (* 1 = 1.31372 loss)
I1030 16:58:41.792518  1046 sgd_solver.cpp:105] Iteration 49000, lr = 2.299e-05
I1030 16:59:12.704831  1046 solver.cpp:222] Iteration 49040 (1.29403 iter/s, 30.9112s/40 iters), loss = 1.64406
I1030 16:59:12.705021  1046 solver.cpp:241]     Train net output #0: loss = 1.64406 (* 1 = 1.64406 loss)
I1030 16:59:12.705039  1046 sgd_solver.cpp:105] Iteration 49040, lr = 2.28762e-05
I1030 16:59:44.162852  1046 solver.cpp:222] Iteration 49080 (1.27159 iter/s, 31.4566s/40 iters), loss = 1.43882
I1030 16:59:44.163069  1046 solver.cpp:241]     Train net output #0: loss = 1.43882 (* 1 = 1.43882 loss)
I1030 16:59:44.163460  1046 sgd_solver.cpp:105] Iteration 49080, lr = 2.27631e-05
I1030 17:00:15.324548  1046 solver.cpp:222] Iteration 49120 (1.28368 iter/s, 31.1603s/40 iters), loss = 1.57701
I1030 17:00:15.324771  1046 solver.cpp:241]     Train net output #0: loss = 1.57701 (* 1 = 1.57701 loss)
I1030 17:00:15.324800  1046 sgd_solver.cpp:105] Iteration 49120, lr = 2.26505e-05
I1030 17:00:46.286299  1046 solver.cpp:222] Iteration 49160 (1.29197 iter/s, 30.9604s/40 iters), loss = 1.01175
I1030 17:00:46.286511  1046 solver.cpp:241]     Train net output #0: loss = 1.01175 (* 1 = 1.01175 loss)
I1030 17:00:46.286527  1046 sgd_solver.cpp:105] Iteration 49160, lr = 2.25384e-05
I1030 17:01:17.034945  1046 solver.cpp:222] Iteration 49200 (1.30093 iter/s, 30.7473s/40 iters), loss = 1.34896
I1030 17:01:17.035197  1046 solver.cpp:241]     Train net output #0: loss = 1.34896 (* 1 = 1.34896 loss)
I1030 17:01:17.035213  1046 sgd_solver.cpp:105] Iteration 49200, lr = 2.24269e-05
I1030 17:01:47.105911  1046 solver.cpp:222] Iteration 49240 (1.33025 iter/s, 30.0696s/40 iters), loss = 1.58463
I1030 17:01:47.106091  1046 solver.cpp:241]     Train net output #0: loss = 1.58463 (* 1 = 1.58463 loss)
I1030 17:01:47.106108  1046 sgd_solver.cpp:105] Iteration 49240, lr = 2.2316e-05
I1030 17:02:18.017853  1046 solver.cpp:222] Iteration 49280 (1.29405 iter/s, 30.9106s/40 iters), loss = 1.40813
I1030 17:02:18.018092  1046 solver.cpp:241]     Train net output #0: loss = 1.40813 (* 1 = 1.40813 loss)
I1030 17:02:18.018110  1046 sgd_solver.cpp:105] Iteration 49280, lr = 2.22056e-05
I1030 17:02:48.666782  1046 solver.cpp:222] Iteration 49320 (1.30516 iter/s, 30.6475s/40 iters), loss = 1.75437
I1030 17:02:48.666980  1046 solver.cpp:241]     Train net output #0: loss = 1.75437 (* 1 = 1.75437 loss)
I1030 17:02:48.666997  1046 sgd_solver.cpp:105] Iteration 49320, lr = 2.20957e-05
I1030 17:03:18.998184  1046 solver.cpp:222] Iteration 49360 (1.31882 iter/s, 30.3301s/40 iters), loss = 1.40632
I1030 17:03:18.998389  1046 solver.cpp:241]     Train net output #0: loss = 1.40632 (* 1 = 1.40632 loss)
I1030 17:03:18.998406  1046 sgd_solver.cpp:105] Iteration 49360, lr = 2.19864e-05
I1030 17:03:49.420303  1046 solver.cpp:222] Iteration 49400 (1.31489 iter/s, 30.4208s/40 iters), loss = 1.57873
I1030 17:03:49.420475  1046 solver.cpp:241]     Train net output #0: loss = 1.57873 (* 1 = 1.57873 loss)
I1030 17:03:49.420492  1046 sgd_solver.cpp:105] Iteration 49400, lr = 2.18776e-05
I1030 17:04:19.759287  1046 solver.cpp:222] Iteration 49440 (1.31849 iter/s, 30.3377s/40 iters), loss = 1.61871
I1030 17:04:19.759501  1046 solver.cpp:241]     Train net output #0: loss = 1.61871 (* 1 = 1.61871 loss)
I1030 17:04:19.759518  1046 sgd_solver.cpp:105] Iteration 49440, lr = 2.17694e-05
I1030 17:04:49.782352  1046 solver.cpp:222] Iteration 49480 (1.33237 iter/s, 30.0217s/40 iters), loss = 1.16271
I1030 17:04:49.782543  1046 solver.cpp:241]     Train net output #0: loss = 1.16271 (* 1 = 1.16271 loss)
I1030 17:04:49.782560  1046 sgd_solver.cpp:105] Iteration 49480, lr = 2.16617e-05
I1030 17:05:04.260507  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_49500.caffemodel
I1030 17:05:04.292330  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_49500.solverstate
I1030 17:05:04.309238  1046 solver.cpp:334] Iteration 49500, Testing net (#0)
I1030 17:05:35.046775  1097 data_layer.cpp:73] Restarting data prefetching from start.
I1030 17:05:35.253942  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.58704
I1030 17:05:35.254001  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.81376
I1030 17:05:35.254014  1046 solver.cpp:401]     Test net output #2: loss = 1.83665 (* 1 = 1.83665 loss)
I1030 17:05:51.266103  1046 solver.cpp:222] Iteration 49520 (0.650605 iter/s, 61.4813s/40 iters), loss = 1.29473
I1030 17:05:51.266167  1046 solver.cpp:241]     Train net output #0: loss = 1.29473 (* 1 = 1.29473 loss)
I1030 17:05:51.266183  1046 sgd_solver.cpp:105] Iteration 49520, lr = 2.15545e-05
I1030 17:06:21.759726  1046 solver.cpp:222] Iteration 49560 (1.3118 iter/s, 30.4924s/40 iters), loss = 1.47466
I1030 17:06:21.759922  1046 solver.cpp:241]     Train net output #0: loss = 1.47466 (* 1 = 1.47466 loss)
I1030 17:06:21.759939  1046 sgd_solver.cpp:105] Iteration 49560, lr = 2.14479e-05
I1030 17:06:52.121837  1046 solver.cpp:222] Iteration 49600 (1.31749 iter/s, 30.3608s/40 iters), loss = 1.36694
I1030 17:06:52.122004  1046 solver.cpp:241]     Train net output #0: loss = 1.36694 (* 1 = 1.36694 loss)
I1030 17:06:52.122022  1046 sgd_solver.cpp:105] Iteration 49600, lr = 2.13418e-05
I1030 17:07:22.165568  1046 solver.cpp:222] Iteration 49640 (1.33145 iter/s, 30.0424s/40 iters), loss = 1.39395
I1030 17:07:22.165736  1046 solver.cpp:241]     Train net output #0: loss = 1.39395 (* 1 = 1.39395 loss)
I1030 17:07:22.165752  1046 sgd_solver.cpp:105] Iteration 49640, lr = 2.12362e-05
I1030 17:07:51.820034  1046 solver.cpp:222] Iteration 49680 (1.34893 iter/s, 29.6532s/40 iters), loss = 1.33489
I1030 17:07:51.820099  1046 solver.cpp:241]     Train net output #0: loss = 1.33489 (* 1 = 1.33489 loss)
I1030 17:07:51.820117  1046 sgd_solver.cpp:105] Iteration 49680, lr = 2.11312e-05
I1030 17:08:21.948786  1046 solver.cpp:222] Iteration 49720 (1.32769 iter/s, 30.1275s/40 iters), loss = 1.51058
I1030 17:08:21.949060  1046 solver.cpp:241]     Train net output #0: loss = 1.51058 (* 1 = 1.51058 loss)
I1030 17:08:21.949079  1046 sgd_solver.cpp:105] Iteration 49720, lr = 2.10266e-05
I1030 17:08:52.086673  1046 solver.cpp:222] Iteration 49760 (1.3273 iter/s, 30.1365s/40 iters), loss = 1.21686
I1030 17:08:52.086868  1046 solver.cpp:241]     Train net output #0: loss = 1.21686 (* 1 = 1.21686 loss)
I1030 17:08:52.086884  1046 sgd_solver.cpp:105] Iteration 49760, lr = 2.09226e-05
I1030 17:09:21.923317  1046 solver.cpp:222] Iteration 49800 (1.34069 iter/s, 29.8353s/40 iters), loss = 1.31716
I1030 17:09:21.923385  1046 solver.cpp:241]     Train net output #0: loss = 1.31716 (* 1 = 1.31716 loss)
I1030 17:09:21.923400  1046 sgd_solver.cpp:105] Iteration 49800, lr = 2.08191e-05
I1030 17:09:51.679790  1046 solver.cpp:222] Iteration 49840 (1.3443 iter/s, 29.7553s/40 iters), loss = 1.12712
I1030 17:09:51.679972  1046 solver.cpp:241]     Train net output #0: loss = 1.12712 (* 1 = 1.12712 loss)
I1030 17:09:51.679988  1046 sgd_solver.cpp:105] Iteration 49840, lr = 2.07161e-05
I1030 17:10:22.216825  1046 solver.cpp:222] Iteration 49880 (1.30994 iter/s, 30.5357s/40 iters), loss = 1.53458
I1030 17:10:22.216997  1046 solver.cpp:241]     Train net output #0: loss = 1.53458 (* 1 = 1.53458 loss)
I1030 17:10:22.217013  1046 sgd_solver.cpp:105] Iteration 49880, lr = 2.06136e-05
I1030 17:10:52.609700  1046 solver.cpp:222] Iteration 49920 (1.31615 iter/s, 30.3916s/40 iters), loss = 1.58796
I1030 17:10:52.609939  1046 solver.cpp:241]     Train net output #0: loss = 1.58796 (* 1 = 1.58796 loss)
I1030 17:10:52.609956  1046 sgd_solver.cpp:105] Iteration 49920, lr = 2.05116e-05
I1030 17:11:23.330189  1046 solver.cpp:222] Iteration 49960 (1.30212 iter/s, 30.7191s/40 iters), loss = 1.76026
I1030 17:11:23.330401  1046 solver.cpp:241]     Train net output #0: loss = 1.76026 (* 1 = 1.76026 loss)
I1030 17:11:23.330418  1046 sgd_solver.cpp:105] Iteration 49960, lr = 2.04102e-05
I1030 17:11:53.452955  1046 solver.cpp:451] Snapshotting to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_50000.caffemodel
I1030 17:11:53.483985  1046 sgd_solver.cpp:329] Snapshotting solver state to binary proto file SqueezeNet/SqueezeNet_v1.1/sqznet_inq_90_iter_50000.solverstate
I1030 17:11:53.653782  1046 solver.cpp:314] Iteration 50000, loss = 1.34081
I1030 17:11:53.653822  1046 solver.cpp:334] Iteration 50000, Testing net (#0)
I1030 17:12:24.698961  1046 solver.cpp:401]     Test net output #0: accuracy_top1 = 0.5888
I1030 17:12:24.699128  1046 solver.cpp:401]     Test net output #1: accuracy_top5 = 0.8108
I1030 17:12:24.699144  1046 solver.cpp:401]     Test net output #2: loss = 1.83298 (* 1 = 1.83298 loss)
I1030 17:12:24.699151  1046 solver.cpp:319] Optimization Done.
I1030 17:12:44.446157  1046 caffe.cpp:259] Optimization Done.
